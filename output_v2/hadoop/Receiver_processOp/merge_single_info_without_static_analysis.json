{
  "org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:processOp(org.apache.hadoop.hdfs.protocol.datatransfer.Op)": "```xml\n<merge_result>\n  <valid_paths>\n    <path>\n      <id>P1-C1</id>\n      <eval>true</eval>\n      <exec_flow>\n        Parent method: ENTRY\n        ├─Parent method: CALL: processOp\n        │ └─Child method: SWITCH: op\n        │   ├─Case: REQUEST_SHORT_CIRCUIT_FDS\n        │   │ └─Child method: CALL: opRequestShortCircuitFds\n        │   │   ├─Child method: IF: proto.hasSlotId\n        │   │   │ ├─Submethod: [DEBUG] SlotId conversion initiated\n        │   │   │ └─Submethod: [INFO] TraceScope created for {description}\n        │   │   ├─Child method: CALL: continueTraceSpan\n        │   │   │ └─Child method: IF: header.getTraceInfo().getSpanContext != null\n        │   │   │   └─Submethod: [DEBUG] Continuing trace span\n        └─Parent method: EXIT\n      </exec_flow>\n      <log_sequence>\n        org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opRequestShortCircuitFds(java.io.DataInputStream)[DEBUG] SlotId conversion initiated\n        org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opRequestShortCircuitFds(java.io.DataInputStream)[INFO] TraceScope created for {description}\n        org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:continueTraceSpan(org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$BaseHeaderProto,java.lang.String)[DEBUG] Continuing trace span\n      </log_sequence>\n    </path>\n    <path>\n      <id>P1-C2</id>\n      <eval>true</eval>\n      <exec_flow>\n        Parent method: ENTRY\n        ├─Parent method: CALL: processOp\n        │ └─Child method: SWITCH: op\n        │   ├─Case: REQUEST_SHORT_CIRCUIT_FDS\n        │   │ └─Child method: CALL: opRequestShortCircuitFds\n        │   │   ├─Child method: IF: proto.hasSlotId\n        │   │   │ ├─Submethod: [DEBUG] SlotId conversion initiated\n        │   │   │ └─Submethod: [INFO] TraceScope created for {description}\n        │   │   ├─Child method: CALL: continueTraceSpan\n        │   │   │ └─Child method: IF: header.getTraceInfo().getSpanContext != null\n        │   │   │   └─Submethod: [DEBUG] Continuing trace span\n        │   │   ├─Child method: CALL: close\n        │   │   │ └─Child method: IF: span != null\n        │   │   │   └─Submethod: [DEBUG] Closing span\n        └─Parent method: EXIT\n      </exec_flow>\n      <log_sequence>\n        org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opRequestShortCircuitFds(java.io.DataInputStream)[DEBUG] SlotId conversion initiated\n        org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opRequestShortCircuitFds(java.io.DataInputStream)[INFO] TraceScope created for {description}\n        org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:continueTraceSpan(org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$BaseHeaderProto,java.lang.String)[DEBUG] Continuing trace span\n        org.apache.hadoop.tracing.TraceScope:close()[DEBUG] Closing span\n      </log_sequence>\n    </path>\n    <path>\n      <id>P1-C3</id>\n      <eval>true</eval>\n      <exec_flow>\n        Parent method: ENTRY\n        ├─Parent method: CALL: processOp\n        │ └─Child method: SWITCH: op\n        │   ├─Case: RELEASE_SHORT_CIRCUIT_FDS\n        │   │ └─Child method: CALL: opReleaseShortCircuitFds\n        │   │   ├─Child method: IF: traceScope != null\n        │   │   │ ├─Submethod: [DEBUG] Continuing trace span\n        │   │   │ └─Submethod: [DEBUG] Closing trace scope\n        └─Parent method: EXIT\n      </exec_flow>\n      <log_sequence>\n        org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opReleaseShortCircuitFds(java.io.DataInputStream)[DEBUG] Continuing trace span\n        org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opReleaseShortCircuitFds(java.io.DataInputStream)[DEBUG] Closing trace scope\n      </log_sequence>\n    </path>\n    <path>\n      <id>P1-C4</id>\n      <eval>true</eval>\n      <exec_flow>\n        Parent method: ENTRY\n        ├─Parent method: CALL: processOp\n        │ └─Child method: SWITCH: op\n        │   ├─Case: RELEASE_SHORT_CIRCUIT_FDS\n        │   │ └─Child method: CALL: opReleaseShortCircuitFds\n        │   │   ├─Child method: CALL: getTraceInfo\n        │   │   │ ├─Submethod: [DEBUG] Accessing trace info\n        │   │   │ └─Submethod: [INFO] Default trace info used\n        └─Parent method: EXIT\n      </exec_flow>\n      <log_sequence>\n        org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ReleaseShortCircuitAccessRequestProto:getTraceInfo()[DEBUG] Accessing trace info\n        org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ReleaseShortCircuitAccessRequestProto:getTraceInfo()[INFO] Default trace info used\n      </log_sequence>\n    </path>\n    <path>\n      <id>P1-C5</id>\n      <eval>true</eval>\n      <exec_flow>\n        Parent method: ENTRY\n        ├─Parent method: CALL: processOp\n        │ └─Child method: SWITCH: op\n        │   ├─Case: REQUEST_SHORT_CIRCUIT_SHM\n        │   │ └─Child method: CALL: opRequestShortCircuitShm\n        │   │   ├─Child method: CALL: continueTraceSpan\n        │   │   │ └─Submethod: CALL: getTraceInfo\n        │   │   │   └─Submethod: CALL: getSpanContext\n        │   │   │     └─Submethod: [DEBUG] TraceInfo retrieved successfully\n        │   │   ├─Parent method: CALL: requestShortCircuitShm\n        └─Parent method: EXIT\n      </exec_flow>\n      <log_sequence>\n        org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opRequestShortCircuitShm(java.io.DataInputStream)[DEBUG] TraceInfo retrieved successfully\n      </log_sequence>\n    </path>\n  </valid_paths>\n  <wrong_path></wrong_path>\n</merge_result>\n```",
  "org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opReadBlock()": "```xml\n<merge_result>\n  <valid_paths>\n    <path>\n      <id>P1-C1</id>\n      <eval>true</eval>\n      <exec_flow>\n        Parent method: ENTRY\n        ├─Parent method: CALL: opReadBlock\n        │ └─Child method: CALL: continueTraceSpan\n        │   └─Submethod: [DEBUG] Continuing trace span with description: {description} <!-- Log node -->\n        ├─Parent method: CALL: readBlock\n        │ └─Child method: IF: proto.hasCachingStrategy() <!-- Labeling conditions -->\n        │   ├─Submethod: [INFO] Using caching strategy: {strategy} <!-- Log node -->\n        │   └─Submethod: [DEBUG] Default caching strategy applied <!-- Log node -->\n        └─Parent method: EXIT\n      </exec_flow>\n      <log_sequence>\n        [org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:continueTraceSpan][DEBUG] Continuing trace span with description: {description}\n        [org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opReadBlock][INFO] Using caching strategy: {strategy}\n        [org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opReadBlock][DEBUG] Default caching strategy applied\n      </log_sequence>\n    </path>\n    <path>\n      <id>P1-C2</id>\n      <eval>true</eval>\n      <exec_flow>\n        Parent method: ENTRY\n        ├─Parent method: CALL: opReadBlock\n        │ └─Child method: CALL: continueTraceSpan\n        │   └─Submethod: [DEBUG] Continuing trace span with description: {description} <!-- Log node -->\n        ├─Parent method: CALL: readBlock\n        │ └─Child method: IF: proto.hasCachingStrategy() <!-- Labeling conditions -->\n        │   ├─Submethod: [INFO] Using caching strategy: {strategy} <!-- Log node -->\n        │   └─Submethod: [DEBUG] Default caching strategy applied <!-- Log node -->\n        ├─Parent method: CALL: close\n        │ └─Child method: CALL: span.close <!-- No log node -->\n        └─Parent method: EXIT\n      </exec_flow>\n      <log_sequence>\n        [org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:continueTraceSpan][DEBUG] Continuing trace span with description: {description}\n        [org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opReadBlock][INFO] Using caching strategy: {strategy}\n        [org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opReadBlock][DEBUG] Default caching strategy applied\n      </log_sequence>\n    </path>\n  </valid_paths>\n  <wrong_path></wrong_path>\n</merge_result>\n```",
  "org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:continueTraceSpan(org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ClientOperationHeaderProto,java.lang.String)": "",
  "org.apache.hadoop.tracing.TraceScope:close()": "",
  "org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opReplaceBlock(java.io.DataInputStream)": "```xml\n<merge_result>\n  <valid_paths>\n    <path>\n      <id>P1-C1</id>\n      <eval>true</eval>\n      <exec_flow>\n        Parent method: ENTRY\n        ├─Parent method: CALL: opReplaceBlock\n        │ └─Child method: CALL: continueTraceSpan\n        │   └─Submethod: [DEBUG] Continuing trace span with description: {description} <!-- Log node -->\n        ├─Parent method: CALL: replaceBlock\n        │ └─Submethod: [INFO] Replacing block with storage ID: {storageId} <!-- Log node -->\n        └─Parent method: EXIT\n      </exec_flow>\n      <log_sequence>\n        [org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:continueTraceSpan][DEBUG] Continuing trace span with description: {description}\n        [org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opReplaceBlock][INFO] Replacing block with storage ID: {storageId}\n      </log_sequence>\n    </path>\n  </valid_paths>\n  <wrong_path></wrong_path>\n</merge_result>\n```",
  "org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opWriteBlock(java.io.DataInputStream)": "```xml\n<merge_result>\n  <valid_paths>\n    <path>\n      <id>P1-C1</id>\n      <eval>true</eval>\n      <exec_flow>\n        Parent method: ENTRY\n        ├─Parent method: CALL: opWriteBlock\n        │ └─Child method: CALL: continueTraceSpan\n        │   └─Submethod: [DEBUG] Continuing trace span with description: {description}\n        ├─Parent method: CALL: writeBlock\n        └─Parent method: EXIT\n      </exec_flow>\n      <log_sequence>\n        [org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:continueTraceSpan][DEBUG] Continuing trace span with description: {description}\n      </log_sequence>\n    </path>\n    <path>\n      <id>P1-C2</id>\n      <eval>true</eval>\n      <exec_flow>\n        Parent method: ENTRY\n        ├─Parent method: CALL: opWriteBlock\n        │ └─Child method: CALL: continueTraceSpan\n        │   └─Submethod: [DEBUG] Continuing trace span with description: {description}\n        ├─Parent method: CALL: writeBlock\n        │ └─Child method: CALL: close\n        │   └─Submethod: [DEBUG] Closing trace span\n        └─Parent method: EXIT\n      </exec_flow>\n      <log_sequence>\n        [org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:continueTraceSpan][DEBUG] Continuing trace span with description: {description}\n        [org.apache.hadoop.tracing.TraceScope:close][DEBUG] Closing trace span\n      </log_sequence>\n    </path>\n  </valid_paths>\n  <wrong_path></wrong_path>\n</merge_result>\n```",
  "org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:continueTraceSpan(org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$BaseHeaderProto,java.lang.String)": "",
  "org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opBlockChecksum(java.io.DataInputStream)": "```xml\n<merge_result>\n  <valid_paths>\n    <path>\n      <id>P1-C1</id>\n      <eval>true</eval>\n      <exec_flow>\n        Parent method: ENTRY\n        ├─Parent method: CALL: opBlockChecksum\n        │ └─Child method: CALL: continueTraceSpan\n        │   └─Submethod: [DEBUG] Continuing trace span with description: {description} <!-- Log node -->\n        ├─Parent method: CALL: blockChecksum\n        │ └─Child method: IF: traceScope != null <!-- Labeling conditions -->\n        │   └─Submethod: [DEBUG] Closing trace scope <!-- Log node -->\n        └─Parent method: EXIT\n      </exec_flow>\n      <log_sequence>\n        [org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:continueTraceSpan][DEBUG] Continuing trace span with description: {description}\n        [org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opBlockChecksum][DEBUG] Closing trace scope\n      </log_sequence>\n    </path>\n  </valid_paths>\n  <wrong_path></wrong_path>\n</merge_result>\n```",
  "org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opCopyBlock(java.io.DataInputStream)": "```xml\n<merge_result>\n  <valid_paths>\n    <path>\n      <id>P1-C1</id>\n      <eval>true</eval>\n      <exec_flow>\n        Parent method: ENTRY\n        ├─Parent method: CALL: opCopyBlock\n        │ └─Child method: CALL: continueTraceSpan\n        │ └─Child method: CALL: copyBlock\n        │ └─Child method: FINALLY: closeTraceScope\n        └─Parent method: EXIT\n      </exec_flow>\n      <log_sequence>\n        [org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opCopyBlock(java.io.DataInputStream)][INFO] Received OP_COPY_BLOCK\n        [org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:continueTraceSpan(org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$BaseHeaderProto,java.lang.String)][DEBUG] Continuing trace span\n      </log_sequence>\n    </path>\n  </valid_paths>\n  <wrong_path></wrong_path>\n</merge_result>\n```",
  "org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opStripedBlockChecksum(java.io.DataInputStream)": "```xml\n<merge_result>\n  <valid_paths>\n    <path>\n      <id>P1-C1</id>\n      <eval>true</eval>\n      <exec_flow>\n        Parent method: ENTRY\n        ├─Parent method: CALL: opStripedBlockChecksum\n        │ └─Child method: IF: traceScope != null\n        │ └─Submethod: [DEBUG] Closing trace scope\n        └─Parent method: EXIT\n      </exec_flow>\n      <log_sequence>\n        org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opStripedBlockChecksum(java.io.DataInputStream)[DEBUG] Closing trace scope\n      </log_sequence>\n    </path>\n    <path>\n      <id>P1-C2</id>\n      <eval>true</eval>\n      <exec_flow>\n        Parent method: ENTRY\n        ├─Parent method: CALL: continueTraceSpan\n        │ └─Child method: IF: header.getTraceInfo().getSpanContext != null\n        │ └─Submethod: [DEBUG] Continuing trace span\n        └─Parent method: EXIT\n      </exec_flow>\n      <log_sequence>\n        org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:continueTraceSpan(org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$BaseHeaderProto,java.lang.String)[DEBUG] Continuing trace span\n      </log_sequence>\n    </path>\n  </valid_paths>\n  <wrong_path></wrong_path>\n</merge_result>\n```",
  "org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opTransferBlock(java.io.DataInputStream)": "```xml\n<merge_result>\n  <valid_paths>\n    <path>\n      <id>P1-C1</id>\n      <eval>true</eval>\n      <exec_flow>\n        Parent method: ENTRY\n        ├─Parent method: CALL: opTransferBlock\n        │ └─Child method: CALL: continueTraceSpan\n        │   └─Submethod: [DEBUG] Continuing trace span with description: {description} <!-- Log node -->\n        ├─Parent method: CALL: transferBlock\n        │ └─Child method: IF: block != null <!-- Labeling conditions -->\n        │   ├─Submethod: [INFO] Transferring block: {block} <!-- Log node -->\n        │   └─Submethod: [INFO] Target storage types: {targetStorageTypes} <!-- Log node -->\n        └─Parent method: EXIT\n      </exec_flow>\n      <log_sequence>\n        [org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:continueTraceSpan][DEBUG] Continuing trace span with description: {description}\n        [org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opTransferBlock][INFO] Transferring block: {block}\n        [org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opTransferBlock][INFO] Target storage types: {targetStorageTypes}\n      </log_sequence>\n    </path>\n    <path>\n      <id>P1-C2</id>\n      <eval>true</eval>\n      <exec_flow>\n        Parent method: ENTRY\n        ├─Parent method: CALL: opTransferBlock\n        │ └─Child method: CALL: continueTraceSpan\n        │   └─Submethod: [DEBUG] Continuing trace span with description: {description} <!-- Log node -->\n        ├─Parent method: CALL: transferBlock\n        │ └─Child method: IF: block != null <!-- Labeling conditions -->\n        │   ├─Submethod: [INFO] Transferring block: {block} <!-- Log node -->\n        │   └─Submethod: [INFO] Target storage types: {targetStorageTypes} <!-- Log node -->\n        ├─Parent method: CALL: close\n        │ └─Child method: IF: span != null <!-- Labeling conditions -->\n        │   └─Submethod: [DEBUG] Closing trace span <!-- Log node -->\n        └─Parent method: EXIT\n      </exec_flow>\n      <log_sequence>\n        [org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:continueTraceSpan][DEBUG] Continuing trace span with description: {description}\n        [org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opTransferBlock][INFO] Transferring block: {block}\n        [org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opTransferBlock][INFO] Target storage types: {targetStorageTypes}\n        [org.apache.hadoop.tracing.TraceScope:close][DEBUG] Closing trace span\n      </log_sequence>\n    </path>\n  </valid_paths>\n  <wrong_path></wrong_path>\n</merge_result>\n```",
  "org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opReleaseShortCircuitFds(java.io.DataInputStream)": "```xml\n<merge_result>\n  <valid_paths>\n    <path>\n      <id>P1-C1</id>\n      <eval>true</eval>\n      <exec_flow>\n        Parent method: ENTRY\n        ├─Parent method: CALL: opReleaseShortCircuitFds\n        │ └─Child method: IF: traceScope != null\n        │ ├─Submethod: [DEBUG] Continuing trace span\n        │ └─Submethod: [DEBUG] Closing trace scope\n        └─Parent method: EXIT\n      </exec_flow>\n      <log_sequence>\n        [org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opReleaseShortCircuitFds(java.io.DataInputStream)][DEBUG] Continuing trace span\n        [org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opReleaseShortCircuitFds(java.io.DataInputStream)][DEBUG] Closing trace scope\n      </log_sequence>\n    </path>\n    <path>\n      <id>P1-C2</id>\n      <eval>true</eval>\n      <exec_flow>\n        Parent method: ENTRY\n        ├─Parent method: CALL: opReleaseShortCircuitFds\n        │ └─Child method: CALL: getTraceInfo\n        │ ├─Submethod: [DEBUG] Accessing trace info\n        │ └─Submethod: [INFO] Default trace info used\n        └─Parent method: EXIT\n      </exec_flow>\n      <log_sequence>\n        [org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ReleaseShortCircuitAccessRequestProto:getTraceInfo()][DEBUG] Accessing trace info\n        [org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ReleaseShortCircuitAccessRequestProto:getTraceInfo()][INFO] Default trace info used\n      </log_sequence>\n    </path>\n  </valid_paths>\n  <wrong_path></wrong_path>\n</merge_result>\n```",
  "org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opRequestShortCircuitFds(java.io.DataInputStream)": "```xml\n<merge_result>\n  <valid_paths>\n    <path>\n      <id>P1-C1</id>\n      <eval>true</eval>\n      <exec_flow>\n        Parent method: ENTRY\n        ├─Parent method: CALL: opRequestShortCircuitFds\n        │ └─Child method: IF: proto.hasSlotId <! -- Labeling conditions -->\n        │ ├─Submethod: [DEBUG] SlotId conversion initiated <! -- Log node -->\n        │ └─Submethod: [INFO] TraceScope created for {description} <! -- Log node -->\n        ├─Parent method: CALL: continueTraceSpan\n        │ └─Child method: IF: header.getTraceInfo().getSpanContext != null <! -- Labeling conditions -->\n        │ └─Submethod: [DEBUG] Continuing trace span <! -- Log node -->\n        └─Parent method: EXIT\n      </exec_flow>\n      <log_sequence>\n        org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opRequestShortCircuitFds(java.io.DataInputStream)[DEBUG] SlotId conversion initiated\n        org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opRequestShortCircuitFds(java.io.DataInputStream)[INFO] TraceScope created for {description}\n        org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:continueTraceSpan(org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$BaseHeaderProto,java.lang.String)[DEBUG] Continuing trace span\n      </log_sequence>\n    </path>\n    <path>\n      <id>P1-C2</id>\n      <eval>true</eval>\n      <exec_flow>\n        Parent method: ENTRY\n        ├─Parent method: CALL: opRequestShortCircuitFds\n        │ └─Child method: IF: proto.hasSlotId <! -- Labeling conditions -->\n        │ ├─Submethod: [DEBUG] SlotId conversion initiated <! -- Log node -->\n        │ └─Submethod: [INFO] TraceScope created for {description} <! -- Log node -->\n        ├─Parent method: CALL: continueTraceSpan\n        │ └─Child method: IF: header.getTraceInfo().getSpanContext != null <! -- Labeling conditions -->\n        │ └─Submethod: [DEBUG] Continuing trace span <! -- Log node -->\n        ├─Parent method: CALL: close\n        │ └─Child method: IF: span != null <! -- Labeling conditions -->\n        │ └─Submethod: [DEBUG] Closing span <! -- Log node -->\n        └─Parent method: EXIT\n      </exec_flow>\n      <log_sequence>\n        org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opRequestShortCircuitFds(java.io.DataInputStream)[DEBUG] SlotId conversion initiated\n        org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opRequestShortCircuitFds(java.io.DataInputStream)[INFO] TraceScope created for {description}\n        org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:continueTraceSpan(org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$BaseHeaderProto,java.lang.String)[DEBUG] Continuing trace span\n        org.apache.hadoop.tracing.TraceScope:close()[DEBUG] Closing span\n      </log_sequence>\n    </path>\n  </valid_paths>\n  <wrong_path></wrong_path>\n</merge_result>\n```",
  "org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ReleaseShortCircuitAccessRequestProto:getTraceInfo()": "",
  "org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$DataTransferTraceInfoProto:getSpanContext()": "",
  "org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:continueTraceSpan(org.apache.hadoop.thirdparty.protobuf.ByteString,java.lang.String)": "",
  "org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opRequestShortCircuitShm(java.io.DataInputStream)": "```xml\n<merge_result>\n  <valid_paths>\n    <path>\n      <id>P1-C1</id>\n      <eval>true</eval>\n      <exec_flow>\n        Parent method: ENTRY\n        ├─Parent method: CALL: opRequestShortCircuitShm\n        │ └─Child method: CALL: continueTraceSpan\n        │   └─Submethod: CALL: getTraceInfo\n        │     └─Submethod: CALL: getSpanContext\n        │       └─Submethod: [DEBUG] TraceInfo retrieved successfully\n        ├─Parent method: CALL: requestShortCircuitShm\n        └─Parent method: EXIT\n      </exec_flow>\n      <log_sequence>\n        [org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opRequestShortCircuitShm(java.io.DataInputStream)][DEBUG] TraceInfo retrieved successfully\n      </log_sequence>\n    </path>\n  </valid_paths>\n  <wrong_path></wrong_path>\n</merge_result>\n```",
  "org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitShmRequestProto:getTraceInfo()": ""
}