{
  "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:processReport(org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo,org.apache.hadoop.hdfs.protocol.BlockListAsLongs)": "```xml\n<merge_result>\n  <valid_paths>\n    <path>\n      <id>P1-C1</id>\n      <eval>true</eval>\n      <exec_flow>\n        Parent method: ENTRY\n        ├─Parent method: CALL: processReport\n        │ └─Child method: CALL: reportDiff\n        │   ├─Submethod: [DEBUG] Reported block {block} on {datanode} size {size} replicaState = {state}\n        │   └─Submethod: [DEBUG] Reported block {block} on {datanode} size {size} replicaState = {state}\n        ├─Parent method: CALL: processReportedBlock\n        │ └─Child method: IF: shouldPostponeBlocksFromFuture && isGenStampInFuture(block)\n        │   ├─Submethod: [DEBUG] Reported block {block} on {dn} size {block.getNumBytes()} replicaState = {reportedState}\n        │   └─Submethod: [DEBUG] In memory blockUCState = {ucState}\n        ├─Parent method: CALL: addStoredBlockUnderConstruction\n        │ └─Child method: CALL: addStoredBlock\n        │   ├─Submethod: [DEBUG] BLOCK* addStoredBlock: {block} on {node} size {block.getNumBytes()} but it does not belong to any file\n        │   ├─Submethod: [DEBUG] BLOCK* addStoredBlock: {node} is added to {storedBlock} (size={storedBlock.getNumBytes()})\n        │   ├─Submethod: [WARN] BLOCK* addStoredBlock: block {storedBlock} moved to storageType {storageInfo.getStorageType()} on node {node}\n        │   ├─Submethod: [DEBUG] BLOCK* addStoredBlock: Redundant addStoredBlock request received for {storedBlock} on node {node} size {storedBlock.getNumBytes()}\n        │   └─Submethod: [WARN] Inconsistent number of corrupt replicas for {storedBlock}. blockMap has {numCorruptNodes} but corrupt replicas map has {corruptReplicasCount}\n        ├─Parent method: CALL: addToInvalidates\n        │ └─Child method: FOR: blocksMap.getStorages(storedBlock)\n        │   ├─Child method: IF: storage.getState() != State.NORMAL\n        │   │ └─Child method: CONTINUE\n        │   ├─Child method: CALL: getBlockOnStorage\n        │   ├─Child method: IF: b != null\n        │   │ ├─Child method: CALL: invalidateBlocks.add\n        │   │ │ └─Submethod: [DEBUG] BLOCK* InvalidateBlocks: add {block} to {datanode}\n        │   │ ├─Child method: IF: datanodes != null\n        │   │ │ └─Child method: APPEND: datanodes.append(node).append(\" \")\n        │   └─Child method: IF: datanodes != null && datanodes.length() != 0\n        │     └─Submethod: [DEBUG] BLOCK* addToInvalidates: {storedBlock} {datanodes}\n        └─Parent method: EXIT\n      </exec_flow>\n      <log_sequence>\n        [org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:reportDiff][DEBUG] Reported block {block} on {datanode} size {size} replicaState = {state}\n        [org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:reportDiff][DEBUG] Reported block {block} on {datanode} size {size} replicaState = {state}\n        [org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:processReportedBlock][DEBUG] Reported block {block} on {dn} size {block.getNumBytes()} replicaState = {reportedState}\n        [org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:processReportedBlock][DEBUG] In memory blockUCState = {ucState}\n        [org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:addStoredBlock][DEBUG] BLOCK* addStoredBlock: {block} on {node} size {block.getNumBytes()} but it does not belong to any file\n        [org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:addStoredBlock][DEBUG] BLOCK* addStoredBlock: {node} is added to {storedBlock} (size={storedBlock.getNumBytes()})\n        [org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:addStoredBlock][WARN] BLOCK* addStoredBlock: block {storedBlock} moved to storageType {storageInfo.getStorageType()} on node {node}\n        [org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:addStoredBlock][DEBUG] BLOCK* addStoredBlock: Redundant addStoredBlock request received for {storedBlock} on node {node} size {storedBlock.getNumBytes()}\n        [org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:addStoredBlock][WARN] Inconsistent number of corrupt replicas for {storedBlock}. blockMap has {numCorruptNodes} but corrupt replicas map has {corruptReplicasCount}\n        [org.apache.hadoop.hdfs.server.blockmanagement.InvalidateBlocks:add][DEBUG] BLOCK* InvalidateBlocks: add {block} to {datanode}\n        [org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:addToInvalidates][DEBUG] BLOCK* addToInvalidates: {storedBlock} {datanodes}\n      </log_sequence>\n    </path>\n    <path>\n      <id>P1-C2</id>\n      <eval>true</eval>\n      <exec_flow>\n        Parent method: ENTRY\n        ├─Parent method: CALL: markBlockAsCorrupt\n        │ └─Child method: IF: b.getStored().isDeleted\n        │   ├─Submethod: [DEBUG] BLOCK markBlockAsCorrupt: {b} cannot be marked as corrupt as it does not belong to any file\n        │   └─Submethod: CALL: addToInvalidates\n        │     └─Child method: FOR: blocksMap.getStorages(storedBlock)\n        │       ├─Child method: IF: storage.getState() != State.NORMAL\n        │       │ └─Child method: CONTINUE\n        │       ├─Child method: CALL: getBlockOnStorage\n        │       ├─Child method: IF: b != null\n        │       │ ├─Child method: CALL: invalidateBlocks.add\n        │       │ │ └─Submethod: [DEBUG] BLOCK* InvalidateBlocks: add {block} to {datanode}\n        │       │ ├─Child method: IF: datanodes != null\n        │       │ │ └─Child method: APPEND: datanodes.append(node).append(\" \")\n        │       └─Child method: IF: datanodes != null && datanodes.length() != 0\n        │         └─Submethod: [DEBUG] BLOCK* addToInvalidates: {storedBlock} {datanodes}\n        └─Parent method: EXIT\n      </exec_flow>\n      <log_sequence>\n        org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:markBlockAsCorrupt[DEBUG] BLOCK markBlockAsCorrupt: {b} cannot be marked as corrupt as it does not belong to any file\n        org.apache.hadoop.hdfs.server.blockmanagement.InvalidateBlocks:add[DEBUG] BLOCK* InvalidateBlocks: add {block} to {datanode}\n        org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:addToInvalidates[DEBUG] BLOCK* addToInvalidates: {storedBlock} {datanodes}\n      </log_sequence>\n    </path>\n  </valid_paths>\n  <wrong_path></wrong_path>\n</merge_result>\n```",
  "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:reportDiff(org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo,org.apache.hadoop.hdfs.protocol.BlockListAsLongs,java.util.Collection,java.util.Collection,java.util.Collection,java.util.Collection,java.util.Collection)": "```xml\n<merge_result>\n  <valid_paths>\n    <path>\n      <id>P1-C1</id>\n      <eval>true</eval>\n      <exec_flow>\n        Parent method: ENTRY\n        ├─Parent method: CALL: reportDiff\n        │ └─Child method: IF: newReport == null\n        │ ├─Submethod: [DEBUG] Reported block {block} on {datanode} size {size} replicaState = {state}\n        │ └─Submethod: [DEBUG] Reported block {block} on {datanode} size {size} replicaState = {state}\n        ├─Parent method: CALL: processReportedBlock\n        │ └─Child method: IF: shouldPostponeBlocksFromFuture && isGenStampInFuture(block)\n        │ ├─Submethod: [DEBUG] Reported block {block} on {dn} size {block.getNumBytes()} replicaState = {reportedState}\n        │ └─Submethod: [DEBUG] In memory blockUCState = {ucState}\n        ├─Parent method: CALL: getDatanodeDescriptor\n        │ └─Child method: RETURN: DatanodeDescriptor\n        └─Parent method: EXIT\n      </exec_flow>\n      <log_sequence>\n        [org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:reportDiff][DEBUG] Reported block {block} on {datanode} size {size} replicaState = {state}\n        [org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:reportDiff][DEBUG] Reported block {block} on {datanode} size {size} replicaState = {state}\n        [org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:processReportedBlock][DEBUG] Reported block {block} on {dn} size {block.getNumBytes()} replicaState = {reportedState}\n        [org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:processReportedBlock][DEBUG] In memory blockUCState = {ucState}\n      </log_sequence>\n    </path>\n    <path>\n      <id>P1-C2</id>\n      <eval>true</eval>\n      <exec_flow>\n        Parent method: ENTRY\n        ├─Parent method: CALL: reportDiff\n        │ └─Child method: CALL: addBlock\n        │ ├─Submethod: [DEBUG] Reported block {block} on {datanode} size {size} replicaState = {state}\n        │ └─Submethod: [DEBUG] Reported block {block} on {datanode} size {size} replicaState = {state}\n        ├─Parent method: CALL: processReportedBlock\n        │ └─Child method: IF: shouldPostponeBlocksFromFuture && isGenStampInFuture(block)\n        │ ├─Submethod: [DEBUG] Reported block {block} on {dn} size {block.getNumBytes()} replicaState = {reportedState}\n        │ └─Submethod: [DEBUG] In memory blockUCState = {ucState}\n        └─Parent method: EXIT\n      </exec_flow>\n      <log_sequence>\n        [org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:reportDiff][DEBUG] Reported block {block} on {datanode} size {size} replicaState = {state}\n        [org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:reportDiff][DEBUG] Reported block {block} on {datanode} size {size} replicaState = {state}\n        [org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:processReportedBlock][DEBUG] Reported block {block} on {dn} size {block.getNumBytes()} replicaState = {reportedState}\n        [org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:processReportedBlock][DEBUG] In memory blockUCState = {ucState}\n      </log_sequence>\n    </path>\n  </valid_paths>\n  <wrong_path></wrong_path>\n</merge_result>\n```",
  "org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo:getDatanodeDescriptor()": "",
  "org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo:addBlock(org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo,org.apache.hadoop.hdfs.protocol.Block)": "",
  "org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo:getBlockUCState()": "",
  "org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo:findStorageInfo(org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo)": "",
  "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:processReportedBlock(org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo,org.apache.hadoop.hdfs.protocol.Block,org.apache.hadoop.hdfs.server.common.HdfsServerConstants$ReplicaState,java.util.Collection,java.util.Collection,java.util.Collection,java.util.Collection)": "```xml\n<merge_result>\n  <valid_paths>\n    <path>\n      <id>P1-C1</id>\n      <eval>true</eval>\n      <exec_flow>\n        Parent method: ENTRY\n        ├─Parent method: CALL: processReportedBlock\n        │ └─Child method: IF: shouldPostponeBlocksFromFuture && isGenStampInFuture(block)\n        │ ├─Submethod: [DEBUG] Reported block {block} on {dn} size {block.getNumBytes()} replicaState = {reportedState}\n        │ └─Submethod: [DEBUG] In memory blockUCState = {ucState}\n        ├─Parent method: CALL: getDatanodeDescriptor\n        │ └─Child method: RETURN: dn\n        └─Parent method: EXIT\n      </exec_flow>\n      <log_sequence>\n        [org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:processReportedBlock][DEBUG] Reported block {block} on {dn} size {block.getNumBytes()} replicaState = {reportedState}\n        [org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:processReportedBlock][DEBUG] In memory blockUCState = {ucState}\n      </log_sequence>\n    </path>\n  </valid_paths>\n  <wrong_path></wrong_path>\n</merge_result>\n```",
  "org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo:moveBlockToHead(org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo,int,int)": "",
  "org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo$BlockIterator:hasNext()": "",
  "org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo$BlockIterator:next()": "",
  "org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo:removeBlock(org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo)": "",
  "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:addStoredBlockUnderConstruction(org.apache.hadoop.hdfs.server.blockmanagement.BlockManager$StatefulBlockInfo,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo)": "```xml\n<merge_result>\n  <valid_paths>\n    <path>\n      <id>P1-C1</id>\n      <eval>true</eval>\n      <exec_flow>\n        Parent method: ENTRY\n        ├─Parent method: CALL: addStoredBlockUnderConstruction\n        │ └─Child method: CALL: getUnderConstructionFeature\n        │   └─Child method: RETURN: BlockUnderConstructionFeature\n        ├─Parent method: IF: ucBlock.reportedState == ReplicaState.FINALIZED && (block.findStorageInfo(storageInfo) < 0) || corruptReplicas.isReplicaCorrupt(block, storageInfo.getDatanodeDescriptor())\n        │ └─Parent method: CALL: addStoredBlock\n        └─Parent method: EXIT\n      </exec_flow>\n      <log_sequence>\n        <!-- No logs present in either parent or child nodes -->\n      </log_sequence>\n    </path>\n    <path>\n      <id>P1-C2</id>\n      <eval>true</eval>\n      <exec_flow>\n        Parent method: ENTRY\n        ├─Parent method: CALL: addStoredBlock\n        │ ├─Child method: IF: !block.isComplete()\n        │ │ └─Child method: CALL: getStoredBlock\n        │ ├─Child method: IF: storedBlock == null || storedBlock.isDeleted()\n        │ │ └─Child method: LOG: [DEBUG] BLOCK* addStoredBlock: {block} on {node} size {block.getNumBytes()} but it does not belong to any file\n        │ ├─Child method: IF: result == AddBlockResult.ADDED\n        │ │ └─Child method: LOG: [DEBUG] BLOCK* addStoredBlock: {node} is added to {storedBlock} (size={storedBlock.getNumBytes()})\n        │ ├─Child method: IF: result == AddBlockResult.REPLACED\n        │ │ └─Child method: LOG: [WARN] BLOCK* addStoredBlock: block {storedBlock} moved to storageType {storageInfo.getStorageType()} on node {node}\n        │ ├─Child method: IF: result == AddBlockResult.REDUNDANT\n        │ │ └─Child method: LOG: [DEBUG] BLOCK* addStoredBlock: Redundant addStoredBlock request received for {storedBlock} on node {node} size {storedBlock.getNumBytes()}\n        │ ├─Child method: IF: numCorruptNodes != corruptReplicasCount\n        │ │ └─Child method: LOG: [WARN] Inconsistent number of corrupt replicas for {storedBlock}. blockMap has {numCorruptNodes} but corrupt replicas map has {corruptReplicasCount}\n        └─Parent method: EXIT\n      </exec_flow>\n      <log_sequence>\n        [DEBUG] BLOCK* addStoredBlock: {block} on {node} size {block.getNumBytes()} but it does not belong to any file\n        [DEBUG] BLOCK* addStoredBlock: {node} is added to {storedBlock} (size={storedBlock.getNumBytes()})\n        [WARN] BLOCK* addStoredBlock: block {storedBlock} moved to storageType {storageInfo.getStorageType()} on node {node}\n        [DEBUG] BLOCK* addStoredBlock: Redundant addStoredBlock request received for {storedBlock} on node {node} size {storedBlock.getNumBytes()}\n        [WARN] Inconsistent number of corrupt replicas for {storedBlock}. blockMap has {numCorruptNodes} but corrupt replicas map has {corruptReplicasCount}\n      </log_sequence>\n    </path>\n  </valid_paths>\n  <wrong_path>\n    <!-- No invalid paths detected -->\n  </wrong_path>\n</merge_result>\n```",
  "org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo:getUnderConstructionFeature()": "",
  "org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo:isComplete()": "",
  "org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo:isDeleted()": "",
  "org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo:getStorageType()": "",
  "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:addStoredBlock(org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo,org.apache.hadoop.hdfs.protocol.Block,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor,boolean)": "```xml\n<merge_result>\n  <valid_paths>\n    <path>\n      <id>P1-C1</id>\n      <eval>true</eval>\n      <exec_flow>\n        Parent method: ENTRY\n        ├─Parent method: CALL: addStoredBlock\n        │ └─Child method: IF: block.isComplete()\n        │ ├─Submethod: [DEBUG] BLOCK* addStoredBlock: {} on {} size {} but it does not belong to any file\n        │ ├─Submethod: [DEBUG] BLOCK* addStoredBlock: {} is added to {} (size={})\n        │ ├─Submethod: [WARN] BLOCK* addStoredBlock: block {} moved to storageType {} on node {}\n        │ ├─Submethod: [DEBUG] BLOCK* addStoredBlock: Redundant addStoredBlock request received for {} on node {} size {}\n        │ ├─Submethod: [WARN] Inconsistent number of corrupt replicas for {}. blockMap has {} but corrupt replicas map has {}\n        │ └─Submethod: [INFO] Invalidating corrupt replicas for block {}\n        ├─Parent method: CALL: incrementSafeBlockCount\n        │ └─Child method: IF: status == BMSafeModeStatus.OFF\n        │ ├─Submethod: RETURN\n        │ └─Child method: IF: storageNum == safeNumberOfNodes\n        │ ├─Submethod: [INFO] Incrementing safe block count\n        │ ├─Submethod: [DEBUG] Reporting startup progress\n        │ └─Submethod: CALL: checkSafeMode\n        └─Parent method: EXIT\n      </exec_flow>\n      <log_sequence>\n        [org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:addStoredBlock][DEBUG] BLOCK* addStoredBlock: {} on {} size {} but it does not belong to any file\n        [org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:addStoredBlock][DEBUG] BLOCK* addStoredBlock: {} is added to {} (size={})\n        [org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:addStoredBlock][WARN] BLOCK* addStoredBlock: block {} moved to storageType {} on node {}\n        [org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:addStoredBlock][DEBUG] BLOCK* addStoredBlock: Redundant addStoredBlock request received for {} on node {} size {}\n        [org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:addStoredBlock][WARN] Inconsistent number of corrupt replicas for {}. blockMap has {} but corrupt replicas map has {}\n        [org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:addStoredBlock][INFO] Invalidating corrupt replicas for block {}\n        [org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode:incrementSafeBlockCount][INFO] Incrementing safe block count\n        [org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode:incrementSafeBlockCount][DEBUG] Reporting startup progress\n      </log_sequence>\n    </path>\n    <path>\n      <id>P1-C2</id>\n      <eval>true</eval>\n      <exec_flow>\n        Parent method: ENTRY\n        ├─Parent method: CALL: invalidateCorruptReplicas\n        │ └─Child method: IF: blk.isStriped()\n        │ ├─Submethod: [DEBUG] invalidateCorruptReplicas error in deleting bad block {blk} on {node}\n        │ └─Submethod: [DEBUG] invalidateCorruptReplicas error in deleting bad block {blk} on {node}\n        ├─Parent method: CALL: corruptReplicas.removeFromCorruptReplicasMap\n        │ └─Child method: IF: removedFromBlocksMap\n        └─Parent method: EXIT\n      </exec_flow>\n      <log_sequence>\n        [org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:invalidateCorruptReplicas][DEBUG] invalidateCorruptReplicas error in deleting bad block {blk} on {node}\n        [org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:invalidateCorruptReplicas][DEBUG] invalidateCorruptReplicas error in deleting bad block {blk} on {node}\n      </log_sequence>\n    </path>\n    <path>\n      <id>P1-C3</id>\n      <eval>true</eval>\n      <exec_flow>\n        Parent method: ENTRY\n        ├─Parent method: CALL: incrementSafeBlockCount\n        │ └─Child method: CALL: isStriped\n        │ └─Submethod: [DEBUG] Checking if block is striped\n        └─Parent method: EXIT\n      </exec_flow>\n      <log_sequence>\n        [org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo:isStriped][DEBUG] Checking if block is striped\n      </log_sequence>\n    </path>\n    <path>\n      <id>P2-C1</id>\n      <eval>true</eval>\n      <exec_flow>\n        Parent method: ENTRY\n        ├─Parent method: CALL: updateNeededReconstructions\n        │ └─Child method: IF: !isPopulatingReplQueues() || !block.isComplete()\n        │ ├─Submethod: [DEBUG] Block is not complete or replication queues are not populated\n        │ └─Submethod: [INFO] Block reconstruction skipped\n        ├─Parent method: CALL: countNodes\n        │ └─Child method: IF: hasEnoughEffectiveReplicas(block, repl, pendingNum)\n        │ ├─Submethod: [DEBUG] Effective replicas are sufficient\n        │ └─Submethod: [INFO] Block removed from reconstruction queue\n        └─Parent method: EXIT\n      </exec_flow>\n      <log_sequence>\n        [org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:updateNeededReconstructions][DEBUG] Block is not complete or replication queues are not populated\n        [org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:updateNeededReconstructions][INFO] Block reconstruction skipped\n        [org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:updateNeededReconstructions][DEBUG] Effective replicas are sufficient\n        [org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:updateNeededReconstructions][INFO] Block removed from reconstruction queue\n      </log_sequence>\n    </path>\n    <path>\n      <id>P2-C2</id>\n      <eval>true</eval>\n      <exec_flow>\n        Parent method: ENTRY\n        ├─Parent method: CALL: updateNeededReconstructions\n        │ └─Child method: IF: !isPopulatingReplQueues() || !block.isComplete()\n        │ ├─Submethod: [DEBUG] Block is not complete or replication queues are not populated\n        │ └─Submethod: [INFO] Block reconstruction skipped\n        ├─Parent method: CALL: remove\n        │ └─Child method: IF: priLevel >= 0 && priLevel < LEVEL && priorityQueues.get(priLevel).remove(block)\n        │ ├─Submethod: [DEBUG] BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block {block} from priority queue {priLevel}\n        └─Parent method: EXIT\n      </exec_flow>\n      <log_sequence>\n        [org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:updateNeededReconstructions][DEBUG] Block is not complete or replication queues are not populated\n        [org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:updateNeededReconstructions][INFO] Block reconstruction skipped\n        [org.apache.hadoop.hdfs.server.blockmanagement.LowRedundancyBlocks:remove][DEBUG] BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block {block} from priority queue {priLevel}\n      </log_sequence>\n    </path>\n    <path>\n      <id>P3-C1</id>\n      <eval>true</eval>\n      <exec_flow>\n        Parent method: ENTRY\n        ├─Parent method: CALL: processExtraRedundancyBlock\n        │ └─Child method: IF: storage.getState() != State.NORMAL\n        │ ├─Submethod: [TRACE] BLOCK* processExtraRedundancyBlock: Postponing {block} since storage {storage} does not yet have up-to-date information.\n        │ └─Submethod: CALL: postponeBlock\n        ├─Parent method: CALL: chooseExcessRedundancies\n        └─Parent method: EXIT\n      </exec_flow>\n      <log_sequence>\n        [org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:processExtraRedundancyBlock][TRACE] BLOCK* processExtraRedundancyBlock: Postponing {block} since storage {storage} does not yet have up-to-date information.\n      </log_sequence>\n    </path>\n  </valid_paths>\n  <wrong_path></wrong_path>\n</merge_result>\n```",
  "org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo:numNodes()": "",
  "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:completeBlock(org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo,org.apache.hadoop.hdfs.server.namenode.INodesInPath,boolean)": "```xml\n<merge_result>\n  <valid_paths>\n    <path>\n      <id>P1-C1</id>\n      <eval>true</eval>\n      <exec_flow>\n        Parent method: ENTRY\n        ├─Parent method: CALL: completeBlock\n        │ └─Child method: IF: curBlock.isComplete() <! -- Labeling conditions -->\n        │ └─Submethod: [INFO] Block is already complete <! -- Log node -->\n        ├─Parent method: CALL: hasMinStorage\n        │ └─Child method: IF: !hasMinStorage(curBlock, numNodes) <! -- Labeling conditions -->\n        │ └─Submethod: THROW: IOException <! -- Exception node -->\n        ├─Parent method: CALL: getBlockUCState\n        │ └─Child method: IF: curBlock.getBlockUCState() != BlockUCState.COMMITTED <! -- Labeling conditions -->\n        │ └─Submethod: THROW: IOException <! -- Exception node -->\n        ├─Parent method: CALL: convertToCompleteBlock\n        │ └─Child method: EXECUTE: convertToCompleteBlock(curBlock, iip) <! -- Execution node -->\n        ├─Parent method: CALL: bmSafeMode.adjustBlockTotals\n        │ └─Child method: EXECUTE: bmSafeMode.adjustBlockTotals(0, 1) <! -- Execution node -->\n        ├─Parent method: CALL: bmSafeMode.incrementSafeBlockCount\n        │ └─Child method: EXECUTE: bmSafeMode.incrementSafeBlockCount(Math.min(numNodes, minStorage), curBlock) <! -- Execution node -->\n        └─Parent method: EXIT\n      </exec_flow>\n      <log_sequence>\n        [org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:completeBlock][INFO] Block is already complete\n      </log_sequence>\n    </path>\n    <path>\n      <id>P1-C3</id>\n      <eval>true</eval>\n      <exec_flow>\n        Parent method: ENTRY\n        ├─Parent method: CALL: getRealDataBlockNum\n        │ └─Child method: IF: isComplete() || getBlockUCState() == BlockUCState.COMMITTED <! -- Labeling conditions -->\n        │ └─Submethod: EXECUTE: Math.min(getDataBlockNum(), (getNumBytes() - 1) / ecPolicy.getCellSize() + 1) <! -- Execution node -->\n        └─Parent method: EXIT\n      </exec_flow>\n      <log_sequence>\n        [org.apache.hadoop.hdfs.server.blockmanagement.BlockInfoStriped:getRealDataBlockNum]\n      </log_sequence>\n    </path>\n  </valid_paths>\n  <wrong_path>\n    <path>\n      <id>P1-C2</id>\n      <reason>Child node does not contain valid logs</reason>\n    </path>\n  </wrong_path>\n</merge_result>\n```",
  "org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo:isStriped()": "",
  "org.apache.hadoop.hdfs.server.blockmanagement.BlockInfoStriped:getRealDataBlockNum()": "",
  "org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode:incrementSafeBlockCount(int,org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo)": "```xml\n<merge_result>\n  <valid_paths>\n    <path>\n      <id>P1-C1</id>\n      <eval>true</eval>\n      <exec_flow>\n        Parent method: ENTRY\n        ├─Parent method: CALL: incrementSafeBlockCount\n        │ └─Child method: IF: status == BMSafeModeStatus.OFF\n        │ ├─Submethod: RETURN\n        │ └─Child method: IF: storageNum == safeNumberOfNodes\n        │ ├─Submethod: [INFO] Incrementing safe block count\n        │ ├─Submethod: [DEBUG] Reporting startup progress\n        │ └─Submethod: CALL: checkSafeMode\n        └─Parent method: EXIT\n      </exec_flow>\n      <log_sequence>\n        [org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode:incrementSafeBlockCount][INFO] Incrementing safe block count\n        [org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode:incrementSafeBlockCount][DEBUG] Reporting startup progress\n      </log_sequence>\n    </path>\n    <path>\n      <id>P1-C2</id>\n      <eval>true</eval>\n      <exec_flow>\n        Parent method: ENTRY\n        ├─Parent method: CALL: incrementSafeBlockCount\n        │ └─Child method: CALL: isStriped\n        │ └─Submethod: [DEBUG] Checking if block is striped\n        └─Parent method: EXIT\n      </exec_flow>\n      <log_sequence>\n        [org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo:isStriped][DEBUG] Checking if block is striped\n      </log_sequence>\n    </path>\n  </valid_paths>\n  <wrong_path></wrong_path>\n</merge_result>\n```",
  "org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo:isCompleteOrCommitted()": "",
  "org.apache.hadoop.hdfs.server.blockmanagement.LowRedundancyBlocks:remove(org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo,int,int,int,int)": "",
  "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:updateNeededReconstructions(org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo,int,int)": "```xml\n<merge_result>\n  <valid_paths>\n    <path>\n      <id>P1-C1</id>\n      <eval>true</eval>\n      <exec_flow>\n        Parent method: ENTRY\n        ├─Parent method: CALL: updateNeededReconstructions\n        │ └─Child method: IF: !isPopulatingReplQueues() || !block.isComplete()\n        │ ├─Submethod: [DEBUG] Block is not complete or replication queues are not populated\n        │ └─Submethod: [INFO] Block reconstruction skipped\n        ├─Parent method: CALL: countNodes\n        │ └─Child method: IF: hasEnoughEffectiveReplicas(block, repl, pendingNum)\n        │ ├─Submethod: [DEBUG] Effective replicas are sufficient\n        │ └─Submethod: [INFO] Block removed from reconstruction queue\n        └─Parent method: EXIT\n      </exec_flow>\n      <log_sequence>\n        [org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:updateNeededReconstructions][DEBUG] Block is not complete or replication queues are not populated\n        [org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:updateNeededReconstructions][INFO] Block reconstruction skipped\n        [org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:updateNeededReconstructions][DEBUG] Effective replicas are sufficient\n        [org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:updateNeededReconstructions][INFO] Block removed from reconstruction queue\n      </log_sequence>\n    </path>\n    <path>\n      <id>P1-C2</id>\n      <eval>true</eval>\n      <exec_flow>\n        Parent method: ENTRY\n        ├─Parent method: CALL: updateNeededReconstructions\n        │ └─Child method: IF: !isPopulatingReplQueues() || !block.isComplete()\n        │ ├─Submethod: [DEBUG] Block is not complete or replication queues are not populated\n        │ └─Submethod: [INFO] Block reconstruction skipped\n        ├─Parent method: CALL: remove\n        │ └─Child method: IF: priLevel >= 0 && priLevel < LEVEL && priorityQueues.get(priLevel).remove(block)\n        │ ├─Submethod: [DEBUG] BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block {block} from priority queue {priLevel}\n        └─Parent method: EXIT\n      </exec_flow>\n      <log_sequence>\n        [org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:updateNeededReconstructions][DEBUG] Block is not complete or replication queues are not populated\n        [org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:updateNeededReconstructions][INFO] Block reconstruction skipped\n        [org.apache.hadoop.hdfs.server.blockmanagement.LowRedundancyBlocks:remove][DEBUG] BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block {block} from priority queue {priLevel}\n      </log_sequence>\n    </path>\n  </valid_paths>\n  <wrong_path></wrong_path>\n</merge_result>\n```",
  "org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo:getState()": "",
  "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:processExtraRedundancyBlock(org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo,short,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor)": "```xml\n<merge_result>\n  <valid_paths>\n    <path>\n      <id>P1-C1</id>\n      <eval>true</eval>\n      <exec_flow>\n        Parent method: ENTRY\n        ├─Parent method: CALL: processExtraRedundancyBlock\n        │ └─Child method: IF: storage.getState() != State.NORMAL <! -- Labeling conditions -->\n        │ ├─Submethod: [TRACE] BLOCK* processExtraRedundancyBlock: Postponing {block} since storage {storage} does not yet have up-to-date information. <! -- Log node -->\n        │ └─Submethod: CALL: postponeBlock\n        ├─Parent method: CALL: chooseExcessRedundancies\n        └─Parent method: EXIT\n      </exec_flow>\n      <log_sequence>\n        org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:processExtraRedundancyBlock(org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo,short,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor)[TRACE] BLOCK* processExtraRedundancyBlock: Postponing {block} since storage {storage} does not yet have up-to-date information.\n      </log_sequence>\n    </path>\n  </valid_paths>\n  <wrong_path></wrong_path>\n</merge_result>\n```",
  "org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo:areBlockContentsStale()": "",
  "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:invalidateCorruptReplicas(org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo,org.apache.hadoop.hdfs.protocol.Block,org.apache.hadoop.hdfs.server.blockmanagement.NumberReplicas)": "```xml\n<merge_result>\n  <valid_paths>\n    <path>\n      <id>P1-C1</id>\n      <eval>true</eval>\n      <exec_flow>\n        Parent method: ENTRY\n        ├─Parent method: CALL: invalidateCorruptReplicas\n        │ └─Child method: IF: blk.isStriped()\n        │ ├─Submethod: [DEBUG] invalidateCorruptReplicas error in deleting bad block {blk} on {node}\n        │ └─Submethod: [DEBUG] invalidateCorruptReplicas error in deleting bad block {blk} on {node}\n        ├─Parent method: CALL: corruptReplicas.removeFromCorruptReplicasMap\n        │ └─Child method: IF: removedFromBlocksMap\n        └─Parent method: EXIT\n      </exec_flow>\n      <log_sequence>\n        [org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:invalidateCorruptReplicas][DEBUG] invalidateCorruptReplicas error in deleting bad block {blk} on {node}\n        [org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:invalidateCorruptReplicas][DEBUG] invalidateCorruptReplicas error in deleting bad block {blk} on {node}\n      </log_sequence>\n    </path>\n    <path>\n      <id>P1-C2</id>\n      <eval>true</eval>\n      <exec_flow>\n        Parent method: ENTRY\n        ├─Parent method: CALL: invalidateBlock\n        │ └─Child method: IF: node == null\n        │ └─Submethod: THROW: IOException\n        │ ├─Child method: IF: nr.replicasOnStaleNodes() > 0 && !deleteCorruptReplicaImmediately\n        │ │ └─Submethod: [DEBUG] BLOCK* invalidateBlocks: postponing invalidation of {b} on {dn} because {nr.replicasOnStaleNodes()} replica(s) are located on nodes with potentially out-of-date block reports\n        │ └─Child method: ELSE\n        │ ├─Submethod: CALL: addToInvalidates\n        │ │ └─Child method: IF: isPopulatingReplQueues()\n        │ │ ├─Submethod: [DEBUG] BLOCK* addToInvalidates: {storedBlock} {datanodes}\n        │ └─Submethod: [DEBUG] BLOCK* invalidateBlocks: {b} on {dn} listed for deletion.\n        ├─Parent method: CALL: removeStoredBlock\n        │ └─Child method: IF: storedBlock == null || !blocksMap.removeNode(storedBlock, node)\n        │ ├─Submethod: [DEBUG] BLOCK* removeStoredBlock: {storedBlock} has already been removed from node {node}\n        │ └─Submethod: RETURN\n        │ └─Child method: IF: cblock != null\n        │ ├─Submethod: [DEBUG] BLOCK* removeStoredBlock: {storedBlock} removed from caching related lists on node {node}\n        │ └─Submethod: REMOVE: cblock from caching lists\n        │ └─Child method: IF: !storedBlock.isDeleted()\n        │ ├─Submethod: DECREMENT: bmSafeMode.decrementSafeBlockCount(storedBlock)\n        │ │ └─Child method: IF: status == BMSafeModeStatus.OFF\n        │ │ ├─Submethod: [DEBUG] Safe mode is off, skipping decrement\n        │ │ └─Child method: IF: storedBlock.isComplete() && blockManager.countNodes(b).liveReplicas() == safeNumberOfNodes - 1\n        │ │ ├─Submethod: [DEBUG] Block is complete and live replicas match safe number\n        │ │ ├─Submethod: [INFO] Decrementing safe block count\n        │ │ └─Submethod: CALL: isStriped\n        │ │ ├─Submethod: [DEBUG] Checking if block is striped\n        │ │ └─Submethod: CALL: getRealDataBlockNum\n        │ │ ├─Submethod: [DEBUG] Calculating real data block number based on erasure coding policy\n        │ └─Submethod: REMOVE: excessRedundancyMap and corruptReplicas\n        └─Parent method: EXIT\n      </exec_flow>\n      <log_sequence>\n        [org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:invalidateBlock][DEBUG] BLOCK* invalidateBlock: {b} on {dn}\n        [org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:invalidateBlock][DEBUG] BLOCK* invalidateBlocks: postponing invalidation of {b} on {dn} because {nr.replicasOnStaleNodes()} replica(s) are located on nodes with potentially out-of-date block reports\n        [org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:addToInvalidates][DEBUG] BLOCK* addToInvalidates: {storedBlock} {datanodes}\n        [org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:invalidateBlock][DEBUG] BLOCK* invalidateBlocks: {b} on {dn} listed for deletion.\n        [org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:removeStoredBlock][DEBUG] BLOCK* removeStoredBlock: {storedBlock} has already been removed from node {node}\n        [org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:removeStoredBlock][DEBUG] BLOCK* removeStoredBlock: {storedBlock} removed from caching related lists on node {node}\n        [org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode:decrementSafeBlockCount][DEBUG] Safe mode is off, skipping decrement\n        [org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode:decrementSafeBlockCount][DEBUG] Block is complete and live replicas match safe number\n        [org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode:decrementSafeBlockCount][INFO] Decrementing safe block count\n        [org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo:isStriped][DEBUG] Checking if block is striped\n        [org.apache.hadoop.hdfs.server.blockmanagement.BlockInfoStriped:getRealDataBlockNum][DEBUG] Calculating real data block number based on erasure coding policy\n      </log_sequence>\n    </path>\n  </valid_paths>\n  <wrong_path></wrong_path>\n</merge_result>\n```",
  "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:invalidateBlock(org.apache.hadoop.hdfs.server.blockmanagement.BlockToMarkCorrupt,org.apache.hadoop.hdfs.protocol.DatanodeInfo,org.apache.hadoop.hdfs.server.blockmanagement.NumberReplicas)": "```xml\n<merge_result>\n  <valid_paths>\n    <path>\n      <id>P1-C1</id>\n      <eval>true</eval>\n      <exec_flow>\n        Parent method: ENTRY\n        ├─Parent method: CALL: invalidateBlock\n        │ └─Child method: IF: node == null\n        │ └─Submethod: THROW: IOException\n        │ ├─Child method: IF: nr.replicasOnStaleNodes() > 0 && !deleteCorruptReplicaImmediately\n        │ │ └─Submethod: [DEBUG] BLOCK* invalidateBlocks: postponing invalidation of {b} on {dn} because {nr.replicasOnStaleNodes()} replica(s) are located on nodes with potentially out-of-date block reports\n        │ └─Child method: ELSE\n        │ ├─Submethod: CALL: addToInvalidates\n        │ │ └─Child method: IF: isPopulatingReplQueues()\n        │ │ ├─Submethod: [DEBUG] BLOCK* addToInvalidates: {storedBlock} {datanodes}\n        │ └─Submethod: [DEBUG] BLOCK* invalidateBlocks: {b} on {dn} listed for deletion.\n        ├─Parent method: CALL: removeStoredBlock\n        │ └─Child method: IF: storedBlock == null || !blocksMap.removeNode(storedBlock, node)\n        │ ├─Submethod: [DEBUG] BLOCK* removeStoredBlock: {storedBlock} has already been removed from node {node}\n        │ └─Submethod: RETURN\n        │ └─Child method: IF: cblock != null\n        │ ├─Submethod: [DEBUG] BLOCK* removeStoredBlock: {storedBlock} removed from caching related lists on node {node}\n        │ └─Submethod: REMOVE: cblock from caching lists\n        │ └─Child method: IF: !storedBlock.isDeleted()\n        │ ├─Submethod: DECREMENT: bmSafeMode.decrementSafeBlockCount(storedBlock)\n        │ │ └─Child method: IF: status == BMSafeModeStatus.OFF\n        │ │ ├─Submethod: [DEBUG] Safe mode is off, skipping decrement\n        │ │ └─Child method: IF: storedBlock.isComplete() && blockManager.countNodes(b).liveReplicas() == safeNumberOfNodes - 1\n        │ │ ├─Submethod: [DEBUG] Block is complete and live replicas match safe number\n        │ │ ├─Submethod: [INFO] Decrementing safe block count\n        │ │ └─Submethod: CALL: isStriped\n        │ │ ├─Submethod: [DEBUG] Checking if block is striped\n        │ │ └─Submethod: CALL: getRealDataBlockNum\n        │ │ ├─Submethod: [DEBUG] Calculating real data block number based on erasure coding policy\n        │ └─Submethod: REMOVE: excessRedundancyMap and corruptReplicas\n        └─Parent method: EXIT\n      </exec_flow>\n      <log_sequence>\n        [org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:invalidateBlock][DEBUG] BLOCK* invalidateBlock: {b} on {dn}\n        [org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:invalidateBlock][DEBUG] BLOCK* invalidateBlocks: postponing invalidation of {b} on {dn} because {nr.replicasOnStaleNodes()} replica(s) are located on nodes with potentially out-of-date block reports\n        [org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:addToInvalidates][DEBUG] BLOCK* addToInvalidates: {storedBlock} {datanodes}\n        [org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:invalidateBlock][DEBUG] BLOCK* invalidateBlocks: {b} on {dn} listed for deletion.\n        [org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:removeStoredBlock][DEBUG] BLOCK* removeStoredBlock: {storedBlock} has already been removed from node {node}\n        [org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:removeStoredBlock][DEBUG] BLOCK* removeStoredBlock: {storedBlock} removed from caching related lists on node {node}\n        [org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode:decrementSafeBlockCount][DEBUG] Safe mode is off, skipping decrement\n        [org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode:decrementSafeBlockCount][DEBUG] Block is complete and live replicas match safe number\n        [org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode:decrementSafeBlockCount][INFO] Decrementing safe block count\n        [org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo:isStriped][DEBUG] Checking if block is striped\n        [org.apache.hadoop.hdfs.server.blockmanagement.BlockInfoStriped:getRealDataBlockNum][DEBUG] Calculating real data block number based on erasure coding policy\n      </log_sequence>\n    </path>\n    <path>\n      <id>P1-C2</id>\n      <eval>true</eval>\n      <exec_flow>\n        Parent method: ENTRY\n        ├─Parent method: CALL: invalidateBlock\n        │ └─Child method: IF: node == null\n        │ └─Submethod: THROW: IOException\n        │ ├─Child method: IF: nr.replicasOnStaleNodes() > 0 && !deleteCorruptReplicaImmediately\n        │ │ └─Submethod: [DEBUG] BLOCK* invalidateBlocks: postponing invalidation of {b} on {dn} because {nr.replicasOnStaleNodes()} replica(s) are located on nodes with potentially out-of-date block reports\n        │ └─Child method: ELSE\n        │ ├─Submethod: CALL: addToInvalidates\n        │ │ └─Child method: IF: isPopulatingReplQueues()\n        │ │ ├─Submethod: [DEBUG] BLOCK* addToInvalidates: {storedBlock} {datanodes}\n        │ └─Submethod: [DEBUG] BLOCK* invalidateBlocks: {b} on {dn} listed for deletion.\n        ├─Parent method: CALL: removeStoredBlock\n        │ └─Child method: IF: storedBlock == null || !blocksMap.removeNode(storedBlock, node)\n        │ ├─Submethod: [DEBUG] BLOCK* removeStoredBlock: {storedBlock} has already been removed from node {node}\n        │ └─Submethod: RETURN\n        │ └─Child method: IF: cblock != null\n        │ ├─Submethod: [DEBUG] BLOCK* removeStoredBlock: {storedBlock} removed from caching related lists on node {node}\n        │ └─Submethod: REMOVE: cblock from caching lists\n        │ └─Child method: IF: !storedBlock.isDeleted()\n        │ ├─Submethod: DECREMENT: bmSafeMode.decrementSafeBlockCount(storedBlock)\n        │ │ └─Child method: IF: status == BMSafeModeStatus.OFF\n        │ │ ├─Submethod: [DEBUG] Safe mode is off, skipping decrement\n        │ │ └─Child method: IF: storedBlock.isComplete() && blockManager.countNodes(b).liveReplicas() == safeNumberOfNodes - 1\n        │ │ ├─Submethod: [DEBUG] Block is complete and live replicas match safe number\n        │ │ ├─Submethod: [INFO] Decrementing safe block count\n        │ │ └─Submethod: CALL: isStriped\n        │ │ ├─Submethod: [DEBUG] Checking if block is striped\n        │ │ └─Submethod: CALL: getRealDataBlockNum\n        │ │ ├─Submethod: [DEBUG] Calculating real data block number based on erasure coding policy\n        │ └─Submethod: REMOVE: excessRedundancyMap and corruptReplicas\n        │ └─Child method: IF: priLevel >= 0 && priLevel < LEVEL && priorityQueues.get(priLevel).remove(block)\n        │ ├─Submethod: [DEBUG] BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block {block} from priority queue {priLevel}\n        └─Parent method: EXIT\n      </exec_flow>\n      <log_sequence>\n        [org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:invalidateBlock][DEBUG] BLOCK* invalidateBlock: {b} on {dn}\n        [org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:invalidateBlock][DEBUG] BLOCK* invalidateBlocks: postponing invalidation of {b} on {dn} because {nr.replicasOnStaleNodes()} replica(s) are located on nodes with potentially out-of-date block reports\n        [org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:addToInvalidates][DEBUG] BLOCK* addToInvalidates: {storedBlock} {datanodes}\n        [org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:invalidateBlock][DEBUG] BLOCK* invalidateBlocks: {b} on {dn} listed for deletion.\n        [org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:removeStoredBlock][DEBUG] BLOCK* removeStoredBlock: {storedBlock} has already been removed from node {node}\n        [org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:removeStoredBlock][DEBUG] BLOCK* removeStoredBlock: {storedBlock} removed from caching related lists on node {node}\n        [org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode:decrementSafeBlockCount][DEBUG] Safe mode is off, skipping decrement\n        [org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode:decrementSafeBlockCount][DEBUG] Block is complete and live replicas match safe number\n        [org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode:decrementSafeBlockCount][INFO] Decrementing safe block count\n        [org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo:isStriped][DEBUG] Checking if block is striped\n        [org.apache.hadoop.hdfs.server.blockmanagement.BlockInfoStriped:getRealDataBlockNum][DEBUG] Calculating real data block number based on erasure coding policy\n        [org.apache.hadoop.hdfs.server.blockmanagement.LowRedundancyBlocks:remove][DEBUG] BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block {block} from priority queue {priLevel}\n      </log_sequence>\n    </path>\n  </valid_paths>\n  <wrong_path></wrong_path>\n</merge_result>\n```",
  "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:addToInvalidates(org.apache.hadoop.hdfs.protocol.Block,org.apache.hadoop.hdfs.protocol.DatanodeInfo)": "```xml\n<merge_result>\n  <valid_paths>\n    <path>\n      <id>P1-C1</id>\n      <eval>true</eval>\n      <exec_flow>\n        Parent method: ENTRY\n        ├─Parent method: CALL: addToInvalidates\n        │ └─Child method: FOR: blocksMap.getStorages(storedBlock)\n        │   ├─Child method: IF: storage.getState() != State.NORMAL\n        │   │ └─Child method: CONTINUE\n        │   ├─Child method: CALL: getBlockOnStorage\n        │   ├─Child method: IF: b != null\n        │   │ ├─Child method: CALL: invalidateBlocks.add\n        │   │ │ └─Submethod: [DEBUG] BLOCK* InvalidateBlocks: add {block} to {datanode}\n        │   │ ├─Child method: IF: datanodes != null\n        │   │ │ └─Child method: APPEND: datanodes.append(node).append(\" \")\n        │   └─Child method: IF: datanodes != null && datanodes.length() != 0\n        │     └─Submethod: [DEBUG] BLOCK* addToInvalidates: {storedBlock} {datanodes}\n        └─Parent method: EXIT\n      </exec_flow>\n      <log_sequence>\n        [org.apache.hadoop.hdfs.server.blockmanagement.InvalidateBlocks:add][DEBUG] BLOCK* InvalidateBlocks: add {block} to {datanode}\n        [org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:addToInvalidates][DEBUG] BLOCK* addToInvalidates: {storedBlock} {datanodes}\n      </log_sequence>\n    </path>\n  </valid_paths>\n  <wrong_path></wrong_path>\n</merge_result>\n```",
  "org.apache.hadoop.hdfs.server.blockmanagement.InvalidateBlocks:add(org.apache.hadoop.hdfs.protocol.Block,org.apache.hadoop.hdfs.protocol.DatanodeInfo,boolean)": "",
  "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:removeStoredBlock(org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor)": "```xml\n<merge_result>\n  <valid_paths>\n    <path>\n      <id>P1-C1</id>\n      <eval>true</eval>\n      <exec_flow>\n        Parent method: ENTRY\n        ├─Parent method: CALL: removeStoredBlock\n        │ └─Child method: IF: storedBlock == null || !blocksMap.removeNode(storedBlock, node)\n        │ ├─Submethod: [DEBUG] BLOCK* removeStoredBlock: {storedBlock} has already been removed from node {node}\n        │ └─Submethod: RETURN\n        ├─Parent method: CALL: removeStoredBlock\n        │ └─Child method: IF: cblock != null\n        │ ├─Submethod: [DEBUG] BLOCK* removeStoredBlock: {storedBlock} removed from caching related lists on node {node}\n        │ └─Submethod: REMOVE: cblock from caching lists\n        ├─Parent method: CALL: removeStoredBlock\n        │ └─Child method: IF: !storedBlock.isDeleted()\n        │ ├─Submethod: CALL: isDeleted\n        │ │ └─Child method: RETURN: bcId == INVALID_INODE_ID\n        │ ├─Submethod: DECREMENT: bmSafeMode.decrementSafeBlockCount(storedBlock)\n        │ │ └─Child method: IF: status == BMSafeModeStatus.OFF\n        │ │ ├─Submethod: [DEBUG] Safe mode is off, skipping decrement\n        │ │ └─Child method: IF: storedBlock.isComplete() && blockManager.countNodes(b).liveReplicas() == safeNumberOfNodes - 1\n        │ │ ├─Submethod: [DEBUG] Block is complete and live replicas match safe number\n        │ │ ├─Submethod: [INFO] Decrementing safe block count\n        │ │ └─Submethod: CALL: isStriped\n        │ │ ├─Submethod: [DEBUG] Checking if block is striped\n        │ │ └─Submethod: CALL: getRealDataBlockNum\n        │ │ ├─Submethod: [DEBUG] Calculating real data block number based on erasure coding policy\n        │ └─Submethod: REMOVE: excessRedundancyMap and corruptReplicas\n        ├─Parent method: CALL: updateNeededReconstructions\n        │ └─Child method: IF: !isPopulatingReplQueues() || !block.isComplete()\n        │ ├─Submethod: [DEBUG] Block is not complete or replication queues are not populated\n        │ └─Submethod: [INFO] Block reconstruction skipped\n        ├─Parent method: CALL: countNodes\n        │ └─Child method: IF: hasEnoughEffectiveReplicas(block, repl, pendingNum)\n        │ ├─Submethod: [DEBUG] Effective replicas are sufficient\n        │ └─Submethod: [INFO] Block removed from reconstruction queue\n        └─Parent method: EXIT\n      </exec_flow>\n      <log_sequence>\n        [org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:removeStoredBlock][DEBUG] BLOCK* removeStoredBlock: {storedBlock} has already been removed from node {node}\n        [org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:removeStoredBlock][DEBUG] BLOCK* removeStoredBlock: {storedBlock} removed from caching related lists on node {node}\n        [org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode:decrementSafeBlockCount][DEBUG] Safe mode is off, skipping decrement\n        [org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode:decrementSafeBlockCount][DEBUG] Block is complete and live replicas match safe number\n        [org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode:decrementSafeBlockCount][INFO] Decrementing safe block count\n        [org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo:isStriped][DEBUG] Checking if block is striped\n        [org.apache.hadoop.hdfs.server.blockmanagement.BlockInfoStriped:getRealDataBlockNum][DEBUG] Calculating real data block number based on erasure coding policy\n        [org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:updateNeededReconstructions][DEBUG] Block is not complete or replication queues are not populated\n        [org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:updateNeededReconstructions][INFO] Block reconstruction skipped\n        [org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:updateNeededReconstructions][DEBUG] Effective replicas are sufficient\n        [org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:updateNeededReconstructions][INFO] Block removed from reconstruction queue\n      </log_sequence>\n    </path>\n    <path>\n      <id>P1-C2</id>\n      <eval>true</eval>\n      <exec_flow>\n        Parent method: ENTRY\n        ├─Parent method: CALL: removeStoredBlock\n        │ └─Child method: IF: storedBlock == null || !blocksMap.removeNode(storedBlock, node)\n        │ ├─Submethod: [DEBUG] BLOCK* removeStoredBlock: {storedBlock} has already been removed from node {node}\n        │ └─Submethod: RETURN\n        ├─Parent method: CALL: removeStoredBlock\n        │ └─Child method: IF: cblock != null\n        │ ├─Submethod: [DEBUG] BLOCK* removeStoredBlock: {storedBlock} removed from caching related lists on node {node}\n        │ └─Submethod: REMOVE: cblock from caching lists\n        ├─Parent method: CALL: removeStoredBlock\n        │ └─Child method: IF: !storedBlock.isDeleted()\n        │ ├─Submethod: CALL: isDeleted\n        │ │ └─Child method: RETURN: bcId == INVALID_INODE_ID\n        │ ├─Submethod: DECREMENT: bmSafeMode.decrementSafeBlockCount(storedBlock)\n        │ │ └─Child method: IF: status == BMSafeModeStatus.OFF\n        │ │ ├─Submethod: [DEBUG] Safe mode is off, skipping decrement\n        │ │ └─Child method: IF: storedBlock.isComplete() && blockManager.countNodes(b).liveReplicas() == safeNumberOfNodes - 1\n        │ │ ├─Submethod: [DEBUG] Block is complete and live replicas match safe number\n        │ │ ├─Submethod: [INFO] Decrementing safe block count\n        │ │ └─Submethod: CALL: isStriped\n        │ │ ├─Submethod: [DEBUG] Checking if block is striped\n        │ │ └─Submethod: CALL: getRealDataBlockNum\n        │ │ ├─Submethod: [DEBUG] Calculating real data block number based on erasure coding policy\n        │ └─Submethod: REMOVE: excessRedundancyMap and corruptReplicas\n        ├─Parent method: CALL: updateNeededReconstructions\n        │ └─Child method: IF: !isPopulatingReplQueues() || !block.isComplete()\n        │ ├─Submethod: [DEBUG] Block is not complete or replication queues are not populated\n        │ └─Submethod: [INFO] Block reconstruction skipped\n        ├─Parent method: CALL: remove\n        │ └─Child method: IF: priLevel >= 0 && priLevel < LEVEL && priorityQueues.get(priLevel).remove(block)\n        │ ├─Submethod: [DEBUG] BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block {block} from priority queue {priLevel}\n        └─Parent method: EXIT\n      </exec_flow>\n      <log_sequence>\n        [org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:removeStoredBlock][DEBUG] BLOCK* removeStoredBlock: {storedBlock} has already been removed from node {node}\n        [org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:removeStoredBlock][DEBUG] BLOCK* removeStoredBlock: {storedBlock} removed from caching related lists on node {node}\n        [org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode:decrementSafeBlockCount][DEBUG] Safe mode is off, skipping decrement\n        [org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode:decrementSafeBlockCount][DEBUG] Block is complete and live replicas match safe number\n        [org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode:decrementSafeBlockCount][INFO] Decrementing safe block count\n        [org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo:isStriped][DEBUG] Checking if block is striped\n        [org.apache.hadoop.hdfs.server.blockmanagement.BlockInfoStriped:getRealDataBlockNum][DEBUG] Calculating real data block number based on erasure coding policy\n        [org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:updateNeededReconstructions][DEBUG] Block is not complete or replication queues are not populated\n        [org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:updateNeededReconstructions][INFO] Block reconstruction skipped\n        [org.apache.hadoop.hdfs.server.blockmanagement.LowRedundancyBlocks:remove][DEBUG] BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block {block} from priority queue {priLevel}\n      </log_sequence>\n    </path>\n  </valid_paths>\n  <wrong_path></wrong_path>\n</merge_result>\n```",
  "org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode:decrementSafeBlockCount(org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo)": "```xml\n<merge_result>\n  <valid_paths>\n    <path>\n      <id>P1-C1</id>\n      <eval>true</eval>\n      <exec_flow>\n        Parent method: ENTRY\n        ├─Parent method: CALL: decrementSafeBlockCount\n        │ └─Child method: IF: status == BMSafeModeStatus.OFF <! -- Labeling conditions -->\n        │ ├─Submethod: [DEBUG] Safe mode is off, skipping decrement <! -- Log node -->\n        │ └─Child method: IF: storedBlock.isComplete() && blockManager.countNodes(b).liveReplicas() == safeNumberOfNodes - 1 <! -- Labeling conditions -->\n        │ ├─Submethod: [DEBUG] Block is complete and live replicas match safe number <! -- Log node -->\n        │ └─Submethod: [INFO] Decrementing safe block count <! -- Log node -->\n        └─Parent method: EXIT\n      </exec_flow>\n      <log_sequence>\n        [org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode:decrementSafeBlockCount][DEBUG] Safe mode is off, skipping decrement\n        [org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode:decrementSafeBlockCount][DEBUG] Block is complete and live replicas match safe number\n        [org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode:decrementSafeBlockCount][INFO] Decrementing safe block count\n      </log_sequence>\n    </path>\n    <path>\n      <id>P1-C2</id>\n      <eval>true</eval>\n      <exec_flow>\n        Parent method: ENTRY\n        ├─Parent method: CALL: decrementSafeBlockCount\n        │ └─Child method: CALL: isStriped <! -- Labeling conditions -->\n        │ ├─Submethod: [DEBUG] Checking if block is striped <! -- Log node -->\n        └─Parent method: EXIT\n      </exec_flow>\n      <log_sequence>\n        [org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo:isStriped][DEBUG] Checking if block is striped\n      </log_sequence>\n    </path>\n    <path>\n      <id>P1-C3</id>\n      <eval>true</eval>\n      <exec_flow>\n        Parent method: ENTRY\n        ├─Parent method: CALL: decrementSafeBlockCount\n        │ └─Child method: CALL: getRealDataBlockNum <! -- Labeling conditions -->\n        │ ├─Submethod: [DEBUG] Calculating real data block number based on erasure coding policy <! -- Log node -->\n        └─Parent method: EXIT\n      </exec_flow>\n      <log_sequence>\n        [org.apache.hadoop.hdfs.server.blockmanagement.BlockInfoStriped:getRealDataBlockNum][DEBUG] Calculating real data block number based on erasure coding policy\n      </log_sequence>\n    </path>\n  </valid_paths>\n  <wrong_path></wrong_path>\n</merge_result>\n```",
  "org.apache.hadoop.hdfs.server.blockmanagement.ExcessRedundancyMap:remove(org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor,org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo)": "",
  "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:markBlockAsCorrupt(org.apache.hadoop.hdfs.server.blockmanagement.BlockToMarkCorrupt,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor)": "```xml\n<merge_result>\n  <valid_paths>\n    <path>\n      <id>P1-C1</id>\n      <eval>true</eval>\n      <exec_flow>\n        Parent method: ENTRY\n        ├─Parent method: CALL: markBlockAsCorrupt\n        │ └─Child method: IF: b.getStored().isDeleted\n        │   ├─Submethod: [DEBUG] BLOCK markBlockAsCorrupt: {b} cannot be marked as corrupt as it does not belong to any file\n        │   └─Submethod: CALL: addToInvalidates\n        │     └─Child method: FOR: blocksMap.getStorages(storedBlock)\n        │       ├─Child method: IF: storage.getState() != State.NORMAL\n        │       │ └─Child method: CONTINUE\n        │       ├─Child method: CALL: getBlockOnStorage\n        │       ├─Child method: IF: b != null\n        │       │ ├─Child method: CALL: invalidateBlocks.add\n        │       │ │ └─Submethod: [DEBUG] BLOCK* InvalidateBlocks: add {block} to {datanode}\n        │       │ ├─Child method: IF: datanodes != null\n        │       │ │ └─Child method: APPEND: datanodes.append(node).append(\" \")\n        │       └─Child method: IF: datanodes != null && datanodes.length() != 0\n        │         └─Submethod: [DEBUG] BLOCK* addToInvalidates: {storedBlock} {datanodes}\n        └─Parent method: EXIT\n      </exec_flow>\n      <log_sequence>\n        org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:markBlockAsCorrupt[DEBUG] BLOCK markBlockAsCorrupt: {b} cannot be marked as corrupt as it does not belong to any file\n        org.apache.hadoop.hdfs.server.blockmanagement.InvalidateBlocks:add[DEBUG] BLOCK* InvalidateBlocks: add {block} to {datanode}\n        org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:addToInvalidates[DEBUG] BLOCK* addToInvalidates: {storedBlock} {datanodes}\n      </log_sequence>\n    </path>\n    <path>\n      <id>P1-C2</id>\n      <eval>true</eval>\n      <exec_flow>\n        Parent method: ENTRY\n        ├─Parent method: CALL: markBlockAsCorrupt\n        │ └─Child method: IF: b.getStored().isStriped\n        │   ├─Submethod: [DEBUG] BLOCK markBlockAsCorrupt: {b} cannot be marked as corrupt as it does not belong to any file\n        │   ├─Submethod: CALL: corruptReplicas.addToCorruptReplicasMap\n        │     └─Submethod: [DEBUG] BLOCK NameSystem.addToCorruptReplicasMap: {blk} added as corrupt on {dn} by {Server.getRemoteIp()} {reasonText}\n        │   ├─Submethod: CALL: countNodes\n        │   ├─Submethod: IF: hasEnoughLiveReplicas || hasMoreCorruptReplicas || corruptedDuringWrite\n        │   │ ├─Submethod: CALL: corruptReplicas.removeFromCorruptReplicasMap\n        │   │ ├─Submethod: CALL: invalidateBlock\n        │   │ └─Submethod: CALL: storageInfo.removeBlock\n        │   └─Submethod: IF: isPopulatingReplQueues()\n        │     └─Submethod: CALL: updateNeededReconstructions\n        └─Parent method: EXIT\n      </exec_flow>\n      <log_sequence>\n        org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:markBlockAsCorrupt[DEBUG] BLOCK markBlockAsCorrupt: {b} cannot be marked as corrupt as it does not belong to any file\n        org.apache.hadoop.hdfs.server.blockmanagement.CorruptReplicasMap:addToCorruptReplicasMap[DEBUG] BLOCK NameSystem.addToCorruptReplicasMap: {blk} added as corrupt on {dn} by {Server.getRemoteIp()} {reasonText}\n      </log_sequence>\n    </path>\n    <path>\n      <id>P1-C3</id>\n      <eval>true</eval>\n      <exec_flow>\n        Parent method: ENTRY\n        ├─Parent method: CALL: invalidateBlock\n        │ └─Child method: IF: node == null\n        │   └─Submethod: THROW: IOException\n        │ ├─Child method: IF: nr.replicasOnStaleNodes() > 0 && !deleteCorruptReplicaImmediately\n        │ │ └─Submethod: [DEBUG] BLOCK* invalidateBlocks: postponing invalidation of {b} on {dn} because {nr.replicasOnStaleNodes()} replica(s) are located on nodes with potentially out-of-date block reports\n        │ └─Child method: ELSE\n        │   ├─Submethod: CALL: addToInvalidates\n        │   │ └─Child method: IF: isPopulatingReplQueues()\n        │   │   └─Submethod: [DEBUG] BLOCK* addToInvalidates: {storedBlock} {datanodes}\n        │   └─Submethod: [DEBUG] BLOCK* invalidateBlocks: {b} on {dn} listed for deletion.\n        ├─Parent method: CALL: removeStoredBlock\n        │ └─Child method: IF: storedBlock == null || !blocksMap.removeNode(storedBlock, node)\n        │   ├─Submethod: [DEBUG] BLOCK* removeStoredBlock: {storedBlock} has already been removed from node {node}\n        │   └─Submethod: RETURN\n        │ └─Child method: IF: cblock != null\n        │   ├─Submethod: [DEBUG] BLOCK* removeStoredBlock: {storedBlock} removed from caching related lists on node {node}\n        │   └─Submethod: REMOVE: cblock from caching lists\n        │ └─Child method: IF: !storedBlock.isDeleted()\n        │   ├─Submethod: DECREMENT: bmSafeMode.decrementSafeBlockCount(storedBlock)\n        │   │ └─Child method: IF: status == BMSafeModeStatus.OFF\n        │   │   ├─Submethod: [DEBUG] Safe mode is off, skipping decrement\n        │   │   └─Child method: IF: storedBlock.isComplete() && blockManager.countNodes(b).liveReplicas() == safeNumberOfNodes - 1\n        │   │     ├─Submethod: [DEBUG] Block is complete and live replicas match safe number\n        │   │     ├─Submethod: [INFO] Decrementing safe block count\n        │   │     └─Submethod: CALL: isStriped\n        │   │       ├─Submethod: [DEBUG] Checking if block is striped\n        │   │       └─Submethod: CALL: getRealDataBlockNum\n        │   │         └─Submethod: [DEBUG] Calculating real data block number based on erasure coding policy\n        │   └─Submethod: REMOVE: excessRedundancyMap and corruptReplicas\n        └─Parent method: EXIT\n      </exec_flow>\n      <log_sequence>\n        org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:invalidateBlock[DEBUG] BLOCK* invalidateBlock: {b} on {dn}\n        org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:invalidateBlock[DEBUG] BLOCK* invalidateBlocks: postponing invalidation of {b} on {dn} because {nr.replicasOnStaleNodes()} replica(s) are located on nodes with potentially out-of-date block reports\n        org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:addToInvalidates[DEBUG] BLOCK* addToInvalidates: {storedBlock} {datanodes}\n        org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:invalidateBlock[DEBUG] BLOCK* invalidateBlocks: {b} on {dn} listed for deletion.\n        org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:removeStoredBlock[DEBUG] BLOCK* removeStoredBlock: {storedBlock} has already been removed from node {node}\n        org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:removeStoredBlock[DEBUG] BLOCK* removeStoredBlock: {storedBlock} removed from caching related lists on node {node}\n        org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode:decrementSafeBlockCount[DEBUG] Safe mode is off, skipping decrement\n        org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode:decrementSafeBlockCount[DEBUG] Block is complete and live replicas match safe number\n        org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode:decrementSafeBlockCount[INFO] Decrementing safe block count\n        org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo:isStriped[DEBUG] Checking if block is striped\n        org.apache.hadoop.hdfs.server.blockmanagement.BlockInfoStriped:getRealDataBlockNum[DEBUG] Calculating real data block number based on erasure coding policy\n      </log_sequence>\n    </path>\n    <path>\n      <id>P1-C4</id>\n      <eval>true</eval>\n      <exec_flow>\n        Parent method: ENTRY\n        ├─Parent method: CALL: updateNeededReconstructions\n        │ └─Child method: IF: !isPopulatingReplQueues() || !block.isComplete()\n        │   ├─Submethod: [DEBUG] Block is not complete or replication queues are not populated\n        │   └─Submethod: [INFO] Block reconstruction skipped\n        ├─Parent method: CALL: countNodes\n        │ └─Child method: IF: hasEnoughEffectiveReplicas(block, repl, pendingNum)\n        │   ├─Submethod: [DEBUG] Effective replicas are sufficient\n        │   └─Submethod: [INFO] Block removed from reconstruction queue\n        └─Parent method: EXIT\n      </exec_flow>\n      <log_sequence>\n        org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:updateNeededReconstructions[DEBUG] Block is not complete or replication queues are not populated\n        org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:updateNeededReconstructions[INFO] Block reconstruction skipped\n        org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:updateNeededReconstructions[DEBUG] Effective replicas are sufficient\n        org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:updateNeededReconstructions[INFO] Block removed from reconstruction queue\n      </log_sequence>\n    </path>\n    <path>\n      <id>P1-C5</id>\n      <eval>true</eval>\n      <exec_flow>\n        Parent method: ENTRY\n        ├─Parent method: CALL: updateNeededReconstructions\n        │ └─Child method: IF: !isPopulatingReplQueues() || !block.isComplete()\n        │   ├─Submethod: [DEBUG] Block is not complete or replication queues are not populated\n        │   └─Submethod: [INFO] Block reconstruction skipped\n        ├─Parent method: CALL: remove\n        │ └─Child method: IF: priLevel >= 0 && priLevel < LEVEL && priorityQueues.get(priLevel).remove(block)\n        │   ├─Submethod: [DEBUG] BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block {block} from priority queue {priLevel}\n        └─Parent method: EXIT\n      </exec_flow>\n      <log_sequence>\n        org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:updateNeededReconstructions[DEBUG] Block is not complete or replication queues are not populated\n        org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:updateNeededReconstructions[INFO] Block reconstruction skipped\n        org.apache.hadoop.hdfs.server.blockmanagement.LowRedundancyBlocks:remove[DEBUG] BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block {block} from priority queue {priLevel}\n      </log_sequence>\n    </path>\n  </valid_paths>\n  <wrong_path></wrong_path>\n</merge_result>\n```",
  "org.apache.hadoop.hdfs.server.blockmanagement.CorruptReplicasMap:addToCorruptReplicasMap(org.apache.hadoop.hdfs.protocol.Block,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor,java.lang.String,org.apache.hadoop.hdfs.server.blockmanagement.CorruptReplicasMap$Reason,boolean)": ""
}