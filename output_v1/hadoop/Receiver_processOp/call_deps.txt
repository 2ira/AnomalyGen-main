org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:processOp(org.apache.hadoop.hdfs.protocol.datatransfer.Op)->org.apache.hadoop.hdfs.protocol.datatransfer.Op:ordinal(), depth 1
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:processOp(org.apache.hadoop.hdfs.protocol.datatransfer.Op)->org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opReadBlock(), depth 1
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:processOp(org.apache.hadoop.hdfs.protocol.datatransfer.Op)->org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opWriteBlock(java.io.DataInputStream), depth 1
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:processOp(org.apache.hadoop.hdfs.protocol.datatransfer.Op)->org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opReplaceBlock(java.io.DataInputStream), depth 1
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:processOp(org.apache.hadoop.hdfs.protocol.datatransfer.Op)->org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opCopyBlock(java.io.DataInputStream), depth 1
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:processOp(org.apache.hadoop.hdfs.protocol.datatransfer.Op)->org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opBlockChecksum(java.io.DataInputStream), depth 1
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:processOp(org.apache.hadoop.hdfs.protocol.datatransfer.Op)->org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opStripedBlockChecksum(java.io.DataInputStream), depth 1
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:processOp(org.apache.hadoop.hdfs.protocol.datatransfer.Op)->org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opTransferBlock(java.io.DataInputStream), depth 1
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:processOp(org.apache.hadoop.hdfs.protocol.datatransfer.Op)->org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opRequestShortCircuitFds(java.io.DataInputStream), depth 1
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:processOp(org.apache.hadoop.hdfs.protocol.datatransfer.Op)->org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opReleaseShortCircuitFds(java.io.DataInputStream), depth 1
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:processOp(org.apache.hadoop.hdfs.protocol.datatransfer.Op)->org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opRequestShortCircuitShm(java.io.DataInputStream), depth 1
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:processOp(org.apache.hadoop.hdfs.protocol.datatransfer.Op)->java.lang.StringBuilder:<init>(), depth 1
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:processOp(org.apache.hadoop.hdfs.protocol.datatransfer.Op)->java.lang.StringBuilder:append(java.lang.String), depth 1
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:processOp(org.apache.hadoop.hdfs.protocol.datatransfer.Op)->java.lang.StringBuilder:append(java.lang.Object), depth 1
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:processOp(org.apache.hadoop.hdfs.protocol.datatransfer.Op)->java.lang.StringBuilder:append(java.lang.String), depth 1
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:processOp(org.apache.hadoop.hdfs.protocol.datatransfer.Op)->java.lang.StringBuilder:toString(), depth 1
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:processOp(org.apache.hadoop.hdfs.protocol.datatransfer.Op)->java.io.IOException:<init>(java.lang.String), depth 1
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opRequestShortCircuitShm(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocolPB.PBHelperClient:vintPrefixed(java.io.InputStream), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opRequestShortCircuitShm(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitShmRequestProto:parseFrom(java.io.InputStream), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opRequestShortCircuitShm(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitShmRequestProto:getTraceInfo(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opRequestShortCircuitShm(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$DataTransferTraceInfoProto:getSpanContext(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opRequestShortCircuitShm(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitShmRequestProto:getClass(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opRequestShortCircuitShm(java.io.DataInputStream)->java.lang.Class:getSimpleName(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opRequestShortCircuitShm(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:continueTraceSpan(org.apache.hadoop.thirdparty.protobuf.ByteString,java.lang.String), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opRequestShortCircuitShm(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitShmRequestProto:getClientName(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opRequestShortCircuitShm(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:requestShortCircuitShm(java.lang.String), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opRequestShortCircuitShm(java.io.DataInputStream)->org.apache.hadoop.tracing.TraceScope:close(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opRequestShortCircuitShm(java.io.DataInputStream)->org.apache.hadoop.tracing.TraceScope:close(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:requestShortCircuitShm(java.lang.String)->org.apache.hadoop.hdfs.server.datanode.DataXceiver:requestShortCircuitShm(java.lang.String), depth 3
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opReleaseShortCircuitFds(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocolPB.PBHelperClient:vintPrefixed(java.io.InputStream), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opReleaseShortCircuitFds(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ReleaseShortCircuitAccessRequestProto:parseFrom(java.io.InputStream), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opReleaseShortCircuitFds(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ReleaseShortCircuitAccessRequestProto:getTraceInfo(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opReleaseShortCircuitFds(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$DataTransferTraceInfoProto:getSpanContext(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opReleaseShortCircuitFds(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ReleaseShortCircuitAccessRequestProto:getClass(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opReleaseShortCircuitFds(java.io.DataInputStream)->java.lang.Class:getSimpleName(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opReleaseShortCircuitFds(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:continueTraceSpan(org.apache.hadoop.thirdparty.protobuf.ByteString,java.lang.String), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opReleaseShortCircuitFds(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ReleaseShortCircuitAccessRequestProto:getSlotId(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opReleaseShortCircuitFds(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocolPB.PBHelperClient:convert(org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitShmSlotProto), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opReleaseShortCircuitFds(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:releaseShortCircuitFds(org.apache.hadoop.hdfs.shortcircuit.ShortCircuitShm$SlotId), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opReleaseShortCircuitFds(java.io.DataInputStream)->org.apache.hadoop.tracing.TraceScope:close(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opReleaseShortCircuitFds(java.io.DataInputStream)->org.apache.hadoop.tracing.TraceScope:close(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:releaseShortCircuitFds(org.apache.hadoop.hdfs.shortcircuit.ShortCircuitShm$SlotId)->org.apache.hadoop.hdfs.server.datanode.DataXceiver:releaseShortCircuitFds(org.apache.hadoop.hdfs.shortcircuit.ShortCircuitShm$SlotId), depth 3
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opRequestShortCircuitFds(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocolPB.PBHelperClient:vintPrefixed(java.io.InputStream), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opRequestShortCircuitFds(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpRequestShortCircuitAccessProto:parseFrom(java.io.InputStream), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opRequestShortCircuitFds(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpRequestShortCircuitAccessProto:hasSlotId(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opRequestShortCircuitFds(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpRequestShortCircuitAccessProto:getSlotId(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opRequestShortCircuitFds(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocolPB.PBHelperClient:convert(org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitShmSlotProto), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opRequestShortCircuitFds(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpRequestShortCircuitAccessProto:getHeader(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opRequestShortCircuitFds(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpRequestShortCircuitAccessProto:getClass(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opRequestShortCircuitFds(java.io.DataInputStream)->java.lang.Class:getSimpleName(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opRequestShortCircuitFds(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:continueTraceSpan(org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$BaseHeaderProto,java.lang.String), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opRequestShortCircuitFds(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpRequestShortCircuitAccessProto:getHeader(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opRequestShortCircuitFds(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$BaseHeaderProto:getBlock(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opRequestShortCircuitFds(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocolPB.PBHelperClient:convert(org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ExtendedBlockProto), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opRequestShortCircuitFds(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpRequestShortCircuitAccessProto:getHeader(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opRequestShortCircuitFds(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$BaseHeaderProto:getToken(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opRequestShortCircuitFds(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocolPB.PBHelperClient:convert(org.apache.hadoop.security.proto.SecurityProtos$TokenProto), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opRequestShortCircuitFds(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpRequestShortCircuitAccessProto:getMaxVersion(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opRequestShortCircuitFds(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpRequestShortCircuitAccessProto:getSupportsReceiptVerification(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opRequestShortCircuitFds(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:requestShortCircuitFds(org.apache.hadoop.hdfs.protocol.ExtendedBlock,org.apache.hadoop.security.token.Token,org.apache.hadoop.hdfs.shortcircuit.ShortCircuitShm$SlotId,int,boolean), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opRequestShortCircuitFds(java.io.DataInputStream)->org.apache.hadoop.tracing.TraceScope:close(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opRequestShortCircuitFds(java.io.DataInputStream)->org.apache.hadoop.tracing.TraceScope:close(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:requestShortCircuitFds(org.apache.hadoop.hdfs.protocol.ExtendedBlock,org.apache.hadoop.security.token.Token,org.apache.hadoop.hdfs.shortcircuit.ShortCircuitShm$SlotId,int,boolean)->org.apache.hadoop.hdfs.server.datanode.DataXceiver:requestShortCircuitFds(org.apache.hadoop.hdfs.protocol.ExtendedBlock,org.apache.hadoop.security.token.Token,org.apache.hadoop.hdfs.shortcircuit.ShortCircuitShm$SlotId,int,boolean), depth 3
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opTransferBlock(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocolPB.PBHelperClient:vintPrefixed(java.io.InputStream), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opTransferBlock(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpTransferBlockProto:parseFrom(java.io.InputStream), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opTransferBlock(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpTransferBlockProto:getTargetsList(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opTransferBlock(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocolPB.PBHelperClient:convert(java.util.List), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opTransferBlock(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpTransferBlockProto:getHeader(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opTransferBlock(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpTransferBlockProto:getClass(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opTransferBlock(java.io.DataInputStream)->java.lang.Class:getSimpleName(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opTransferBlock(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:continueTraceSpan(org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ClientOperationHeaderProto,java.lang.String), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opTransferBlock(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpTransferBlockProto:getHeader(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opTransferBlock(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ClientOperationHeaderProto:getBaseHeader(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opTransferBlock(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$BaseHeaderProto:getBlock(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opTransferBlock(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocolPB.PBHelperClient:convert(org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ExtendedBlockProto), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opTransferBlock(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpTransferBlockProto:getTargetStorageTypesList(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opTransferBlock(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocolPB.PBHelperClient:convertStorageTypes(java.util.List,int), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opTransferBlock(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpTransferBlockProto:getHeader(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opTransferBlock(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ClientOperationHeaderProto:getBaseHeader(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opTransferBlock(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$BaseHeaderProto:getToken(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opTransferBlock(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocolPB.PBHelperClient:convert(org.apache.hadoop.security.proto.SecurityProtos$TokenProto), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opTransferBlock(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpTransferBlockProto:getHeader(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opTransferBlock(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ClientOperationHeaderProto:getClientName(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opTransferBlock(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpTransferBlockProto:getTargetStorageIdsList(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opTransferBlock(java.io.DataInputStream)->org.apache.hadoop.thirdparty.protobuf.ProtocolStringList:toArray(java.lang.Object[]), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opTransferBlock(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:transferBlock(org.apache.hadoop.hdfs.protocol.ExtendedBlock,org.apache.hadoop.security.token.Token,java.lang.String,org.apache.hadoop.hdfs.protocol.DatanodeInfo[],org.apache.hadoop.fs.StorageType[],java.lang.String[]), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opTransferBlock(java.io.DataInputStream)->org.apache.hadoop.tracing.TraceScope:close(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opTransferBlock(java.io.DataInputStream)->org.apache.hadoop.tracing.TraceScope:close(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:transferBlock(org.apache.hadoop.hdfs.protocol.ExtendedBlock,org.apache.hadoop.security.token.Token,java.lang.String,org.apache.hadoop.hdfs.protocol.DatanodeInfo[],org.apache.hadoop.fs.StorageType[],java.lang.String[])->org.apache.hadoop.hdfs.server.datanode.DataXceiver:transferBlock(org.apache.hadoop.hdfs.protocol.ExtendedBlock,org.apache.hadoop.security.token.Token,java.lang.String,org.apache.hadoop.hdfs.protocol.DatanodeInfo[],org.apache.hadoop.fs.StorageType[],java.lang.String[]), depth 3
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opStripedBlockChecksum(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocolPB.PBHelperClient:vintPrefixed(java.io.InputStream), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opStripedBlockChecksum(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpBlockGroupChecksumProto:parseFrom(java.io.InputStream), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opStripedBlockChecksum(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpBlockGroupChecksumProto:getHeader(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opStripedBlockChecksum(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpBlockGroupChecksumProto:getClass(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opStripedBlockChecksum(java.io.DataInputStream)->java.lang.Class:getSimpleName(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opStripedBlockChecksum(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:continueTraceSpan(org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$BaseHeaderProto,java.lang.String), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opStripedBlockChecksum(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpBlockGroupChecksumProto:getHeader(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opStripedBlockChecksum(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$BaseHeaderProto:getBlock(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opStripedBlockChecksum(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocolPB.PBHelperClient:convert(org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ExtendedBlockProto), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opStripedBlockChecksum(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpBlockGroupChecksumProto:getDatanodes(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opStripedBlockChecksum(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocolPB.PBHelperClient:convert(org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeInfosProto), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opStripedBlockChecksum(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpBlockGroupChecksumProto:getBlockTokensList(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opStripedBlockChecksum(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocolPB.PBHelperClient:convertTokens(java.util.List), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opStripedBlockChecksum(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpBlockGroupChecksumProto:getBlockIndicesList(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opStripedBlockChecksum(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocolPB.PBHelperClient:convertBlockIndices(java.util.List), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opStripedBlockChecksum(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpBlockGroupChecksumProto:getEcPolicy(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opStripedBlockChecksum(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocolPB.PBHelperClient:convertErasureCodingPolicy(org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ErasureCodingPolicyProto), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opStripedBlockChecksum(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.StripedBlockInfo:<init>(org.apache.hadoop.hdfs.protocol.ExtendedBlock,org.apache.hadoop.hdfs.protocol.DatanodeInfo[],org.apache.hadoop.security.token.Token[],byte[],org.apache.hadoop.hdfs.protocol.ErasureCodingPolicy), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opStripedBlockChecksum(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpBlockGroupChecksumProto:getHeader(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opStripedBlockChecksum(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$BaseHeaderProto:getToken(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opStripedBlockChecksum(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocolPB.PBHelperClient:convert(org.apache.hadoop.security.proto.SecurityProtos$TokenProto), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opStripedBlockChecksum(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpBlockGroupChecksumProto:getRequestedNumBytes(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opStripedBlockChecksum(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpBlockGroupChecksumProto:getBlockChecksumOptions(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opStripedBlockChecksum(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocolPB.PBHelperClient:convert(org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockChecksumOptionsProto), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opStripedBlockChecksum(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:blockGroupChecksum(org.apache.hadoop.hdfs.protocol.StripedBlockInfo,org.apache.hadoop.security.token.Token,long,org.apache.hadoop.hdfs.protocol.BlockChecksumOptions), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opStripedBlockChecksum(java.io.DataInputStream)->org.apache.hadoop.tracing.TraceScope:close(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opStripedBlockChecksum(java.io.DataInputStream)->org.apache.hadoop.tracing.TraceScope:close(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:blockGroupChecksum(org.apache.hadoop.hdfs.protocol.StripedBlockInfo,org.apache.hadoop.security.token.Token,long,org.apache.hadoop.hdfs.protocol.BlockChecksumOptions)->org.apache.hadoop.hdfs.server.datanode.DataXceiver:blockGroupChecksum(org.apache.hadoop.hdfs.protocol.StripedBlockInfo,org.apache.hadoop.security.token.Token,long,org.apache.hadoop.hdfs.protocol.BlockChecksumOptions), depth 3
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opBlockChecksum(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocolPB.PBHelperClient:vintPrefixed(java.io.InputStream), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opBlockChecksum(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpBlockChecksumProto:parseFrom(java.io.InputStream), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opBlockChecksum(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpBlockChecksumProto:getHeader(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opBlockChecksum(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpBlockChecksumProto:getClass(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opBlockChecksum(java.io.DataInputStream)->java.lang.Class:getSimpleName(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opBlockChecksum(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:continueTraceSpan(org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$BaseHeaderProto,java.lang.String), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opBlockChecksum(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpBlockChecksumProto:getHeader(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opBlockChecksum(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$BaseHeaderProto:getBlock(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opBlockChecksum(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocolPB.PBHelperClient:convert(org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ExtendedBlockProto), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opBlockChecksum(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpBlockChecksumProto:getHeader(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opBlockChecksum(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$BaseHeaderProto:getToken(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opBlockChecksum(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocolPB.PBHelperClient:convert(org.apache.hadoop.security.proto.SecurityProtos$TokenProto), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opBlockChecksum(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpBlockChecksumProto:getBlockChecksumOptions(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opBlockChecksum(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocolPB.PBHelperClient:convert(org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockChecksumOptionsProto), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opBlockChecksum(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:blockChecksum(org.apache.hadoop.hdfs.protocol.ExtendedBlock,org.apache.hadoop.security.token.Token,org.apache.hadoop.hdfs.protocol.BlockChecksumOptions), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opBlockChecksum(java.io.DataInputStream)->org.apache.hadoop.tracing.TraceScope:close(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opBlockChecksum(java.io.DataInputStream)->org.apache.hadoop.tracing.TraceScope:close(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:blockChecksum(org.apache.hadoop.hdfs.protocol.ExtendedBlock,org.apache.hadoop.security.token.Token,org.apache.hadoop.hdfs.protocol.BlockChecksumOptions)->org.apache.hadoop.hdfs.server.datanode.DataXceiver:blockChecksum(org.apache.hadoop.hdfs.protocol.ExtendedBlock,org.apache.hadoop.security.token.Token,org.apache.hadoop.hdfs.protocol.BlockChecksumOptions), depth 3
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opCopyBlock(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocolPB.PBHelperClient:vintPrefixed(java.io.InputStream), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opCopyBlock(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpCopyBlockProto:parseFrom(java.io.InputStream), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opCopyBlock(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpCopyBlockProto:getHeader(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opCopyBlock(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpCopyBlockProto:getClass(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opCopyBlock(java.io.DataInputStream)->java.lang.Class:getSimpleName(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opCopyBlock(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:continueTraceSpan(org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$BaseHeaderProto,java.lang.String), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opCopyBlock(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpCopyBlockProto:getHeader(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opCopyBlock(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$BaseHeaderProto:getBlock(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opCopyBlock(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocolPB.PBHelperClient:convert(org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ExtendedBlockProto), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opCopyBlock(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpCopyBlockProto:getHeader(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opCopyBlock(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$BaseHeaderProto:getToken(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opCopyBlock(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocolPB.PBHelperClient:convert(org.apache.hadoop.security.proto.SecurityProtos$TokenProto), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opCopyBlock(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:copyBlock(org.apache.hadoop.hdfs.protocol.ExtendedBlock,org.apache.hadoop.security.token.Token), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opCopyBlock(java.io.DataInputStream)->org.apache.hadoop.tracing.TraceScope:close(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opCopyBlock(java.io.DataInputStream)->org.apache.hadoop.tracing.TraceScope:close(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:copyBlock(org.apache.hadoop.hdfs.protocol.ExtendedBlock,org.apache.hadoop.security.token.Token)->org.apache.hadoop.hdfs.server.datanode.DataXceiver:copyBlock(org.apache.hadoop.hdfs.protocol.ExtendedBlock,org.apache.hadoop.security.token.Token), depth 3
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opReplaceBlock(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocolPB.PBHelperClient:vintPrefixed(java.io.InputStream), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opReplaceBlock(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpReplaceBlockProto:parseFrom(java.io.InputStream), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opReplaceBlock(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpReplaceBlockProto:getHeader(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opReplaceBlock(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpReplaceBlockProto:getClass(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opReplaceBlock(java.io.DataInputStream)->java.lang.Class:getSimpleName(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opReplaceBlock(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:continueTraceSpan(org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$BaseHeaderProto,java.lang.String), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opReplaceBlock(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpReplaceBlockProto:getHeader(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opReplaceBlock(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$BaseHeaderProto:getBlock(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opReplaceBlock(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocolPB.PBHelperClient:convert(org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ExtendedBlockProto), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opReplaceBlock(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpReplaceBlockProto:getStorageType(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opReplaceBlock(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocolPB.PBHelperClient:convertStorageType(org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageTypeProto), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opReplaceBlock(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpReplaceBlockProto:getHeader(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opReplaceBlock(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$BaseHeaderProto:getToken(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opReplaceBlock(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocolPB.PBHelperClient:convert(org.apache.hadoop.security.proto.SecurityProtos$TokenProto), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opReplaceBlock(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpReplaceBlockProto:getDelHint(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opReplaceBlock(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpReplaceBlockProto:getSource(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opReplaceBlock(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocolPB.PBHelperClient:convert(org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeInfoProto), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opReplaceBlock(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpReplaceBlockProto:getStorageId(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opReplaceBlock(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:replaceBlock(org.apache.hadoop.hdfs.protocol.ExtendedBlock,org.apache.hadoop.fs.StorageType,org.apache.hadoop.security.token.Token,java.lang.String,org.apache.hadoop.hdfs.protocol.DatanodeInfo,java.lang.String), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opReplaceBlock(java.io.DataInputStream)->org.apache.hadoop.tracing.TraceScope:close(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opReplaceBlock(java.io.DataInputStream)->org.apache.hadoop.tracing.TraceScope:close(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:replaceBlock(org.apache.hadoop.hdfs.protocol.ExtendedBlock,org.apache.hadoop.fs.StorageType,org.apache.hadoop.security.token.Token,java.lang.String,org.apache.hadoop.hdfs.protocol.DatanodeInfo,java.lang.String)->org.apache.hadoop.hdfs.server.datanode.DataXceiver:replaceBlock(org.apache.hadoop.hdfs.protocol.ExtendedBlock,org.apache.hadoop.fs.StorageType,org.apache.hadoop.security.token.Token,java.lang.String,org.apache.hadoop.hdfs.protocol.DatanodeInfo,java.lang.String), depth 3
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opWriteBlock(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocolPB.PBHelperClient:vintPrefixed(java.io.InputStream), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opWriteBlock(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpWriteBlockProto:parseFrom(java.io.InputStream), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opWriteBlock(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpWriteBlockProto:getTargetsList(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opWriteBlock(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocolPB.PBHelperClient:convert(java.util.List), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opWriteBlock(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpWriteBlockProto:getHeader(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opWriteBlock(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpWriteBlockProto:getClass(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opWriteBlock(java.io.DataInputStream)->java.lang.Class:getSimpleName(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opWriteBlock(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:continueTraceSpan(org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ClientOperationHeaderProto,java.lang.String), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opWriteBlock(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpWriteBlockProto:getHeader(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opWriteBlock(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ClientOperationHeaderProto:getBaseHeader(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opWriteBlock(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$BaseHeaderProto:getBlock(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opWriteBlock(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocolPB.PBHelperClient:convert(org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ExtendedBlockProto), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opWriteBlock(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpWriteBlockProto:getStorageType(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opWriteBlock(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocolPB.PBHelperClient:convertStorageType(org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageTypeProto), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opWriteBlock(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpWriteBlockProto:getHeader(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opWriteBlock(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ClientOperationHeaderProto:getBaseHeader(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opWriteBlock(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$BaseHeaderProto:getToken(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opWriteBlock(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocolPB.PBHelperClient:convert(org.apache.hadoop.security.proto.SecurityProtos$TokenProto), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opWriteBlock(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpWriteBlockProto:getHeader(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opWriteBlock(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ClientOperationHeaderProto:getClientName(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opWriteBlock(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpWriteBlockProto:getTargetStorageTypesList(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opWriteBlock(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocolPB.PBHelperClient:convertStorageTypes(java.util.List,int), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opWriteBlock(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpWriteBlockProto:getSource(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opWriteBlock(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocolPB.PBHelperClient:convert(org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeInfoProto), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opWriteBlock(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpWriteBlockProto:getStage(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opWriteBlock(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil:fromProto(org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpWriteBlockProto$BlockConstructionStage), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opWriteBlock(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpWriteBlockProto:getPipelineSize(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opWriteBlock(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpWriteBlockProto:getMinBytesRcvd(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opWriteBlock(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpWriteBlockProto:getMaxBytesRcvd(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opWriteBlock(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpWriteBlockProto:getLatestGenerationStamp(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opWriteBlock(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpWriteBlockProto:getRequestedChecksum(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opWriteBlock(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil:fromProto(org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ChecksumProto), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opWriteBlock(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpWriteBlockProto:hasCachingStrategy(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opWriteBlock(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpWriteBlockProto:getCachingStrategy(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opWriteBlock(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:getCachingStrategy(org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$CachingStrategyProto), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opWriteBlock(java.io.DataInputStream)->org.apache.hadoop.hdfs.server.datanode.CachingStrategy:newDefaultStrategy(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opWriteBlock(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpWriteBlockProto:hasAllowLazyPersist(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opWriteBlock(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpWriteBlockProto:getAllowLazyPersist(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opWriteBlock(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpWriteBlockProto:hasPinning(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opWriteBlock(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpWriteBlockProto:getPinning(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opWriteBlock(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpWriteBlockProto:getTargetPinningsList(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opWriteBlock(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocolPB.PBHelperClient:convertBooleanList(java.util.List), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opWriteBlock(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpWriteBlockProto:getStorageId(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opWriteBlock(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpWriteBlockProto:getTargetStorageIdsList(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opWriteBlock(java.io.DataInputStream)->org.apache.hadoop.thirdparty.protobuf.ProtocolStringList:toArray(java.lang.Object[]), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opWriteBlock(java.io.DataInputStream)->org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:writeBlock(org.apache.hadoop.hdfs.protocol.ExtendedBlock,org.apache.hadoop.fs.StorageType,org.apache.hadoop.security.token.Token,java.lang.String,org.apache.hadoop.hdfs.protocol.DatanodeInfo[],org.apache.hadoop.fs.StorageType[],org.apache.hadoop.hdfs.protocol.DatanodeInfo,org.apache.hadoop.hdfs.protocol.datatransfer.BlockConstructionStage,int,long,long,long,org.apache.hadoop.util.DataChecksum,org.apache.hadoop.hdfs.server.datanode.CachingStrategy,boolean,boolean,boolean[],java.lang.String,java.lang.String[]), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opWriteBlock(java.io.DataInputStream)->org.apache.hadoop.tracing.TraceScope:close(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opWriteBlock(java.io.DataInputStream)->org.apache.hadoop.tracing.TraceScope:close(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:writeBlock(org.apache.hadoop.hdfs.protocol.ExtendedBlock,org.apache.hadoop.fs.StorageType,org.apache.hadoop.security.token.Token,java.lang.String,org.apache.hadoop.hdfs.protocol.DatanodeInfo[],org.apache.hadoop.fs.StorageType[],org.apache.hadoop.hdfs.protocol.DatanodeInfo,org.apache.hadoop.hdfs.protocol.datatransfer.BlockConstructionStage,int,long,long,long,org.apache.hadoop.util.DataChecksum,org.apache.hadoop.hdfs.server.datanode.CachingStrategy,boolean,boolean,boolean[],java.lang.String,java.lang.String[])->org.apache.hadoop.hdfs.server.datanode.DataXceiver:writeBlock(org.apache.hadoop.hdfs.protocol.ExtendedBlock,org.apache.hadoop.fs.StorageType,org.apache.hadoop.security.token.Token,java.lang.String,org.apache.hadoop.hdfs.protocol.DatanodeInfo[],org.apache.hadoop.fs.StorageType[],org.apache.hadoop.hdfs.protocol.DatanodeInfo,org.apache.hadoop.hdfs.protocol.datatransfer.BlockConstructionStage,int,long,long,long,org.apache.hadoop.util.DataChecksum,org.apache.hadoop.hdfs.server.datanode.CachingStrategy,boolean,boolean,boolean[],java.lang.String,java.lang.String[]), depth 3
org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil:fromProto(org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ChecksumProto)->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ChecksumProto:getBytesPerChecksum(), depth 3
org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil:fromProto(org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ChecksumProto)->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ChecksumProto:getType(), depth 3
org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil:fromProto(org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ChecksumProto)->org.apache.hadoop.hdfs.protocolPB.PBHelperClient:convert(org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ChecksumTypeProto), depth 3
org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil:fromProto(org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ChecksumProto)->org.apache.hadoop.util.DataChecksum:newDataChecksum(org.apache.hadoop.util.DataChecksum$Type,int), depth 3
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opReadBlock()->org.apache.hadoop.hdfs.protocolPB.PBHelperClient:vintPrefixed(java.io.InputStream), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opReadBlock()->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpReadBlockProto:parseFrom(java.io.InputStream), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opReadBlock()->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpReadBlockProto:getHeader(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opReadBlock()->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpReadBlockProto:getClass(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opReadBlock()->java.lang.Class:getSimpleName(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opReadBlock()->org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:continueTraceSpan(org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ClientOperationHeaderProto,java.lang.String), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opReadBlock()->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpReadBlockProto:getHeader(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opReadBlock()->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ClientOperationHeaderProto:getBaseHeader(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opReadBlock()->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$BaseHeaderProto:getBlock(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opReadBlock()->org.apache.hadoop.hdfs.protocolPB.PBHelperClient:convert(org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ExtendedBlockProto), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opReadBlock()->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpReadBlockProto:getHeader(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opReadBlock()->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ClientOperationHeaderProto:getBaseHeader(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opReadBlock()->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$BaseHeaderProto:getToken(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opReadBlock()->org.apache.hadoop.hdfs.protocolPB.PBHelperClient:convert(org.apache.hadoop.security.proto.SecurityProtos$TokenProto), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opReadBlock()->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpReadBlockProto:getHeader(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opReadBlock()->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ClientOperationHeaderProto:getClientName(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opReadBlock()->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpReadBlockProto:getOffset(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opReadBlock()->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpReadBlockProto:getLen(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opReadBlock()->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpReadBlockProto:getSendChecksums(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opReadBlock()->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpReadBlockProto:hasCachingStrategy(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opReadBlock()->org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpReadBlockProto:getCachingStrategy(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opReadBlock()->org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:getCachingStrategy(org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$CachingStrategyProto), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opReadBlock()->org.apache.hadoop.hdfs.server.datanode.CachingStrategy:newDefaultStrategy(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opReadBlock()->org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:readBlock(org.apache.hadoop.hdfs.protocol.ExtendedBlock,org.apache.hadoop.security.token.Token,java.lang.String,long,long,boolean,org.apache.hadoop.hdfs.server.datanode.CachingStrategy), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opReadBlock()->org.apache.hadoop.tracing.TraceScope:close(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opReadBlock()->org.apache.hadoop.tracing.TraceScope:close(), depth 2
org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:readBlock(org.apache.hadoop.hdfs.protocol.ExtendedBlock,org.apache.hadoop.security.token.Token,java.lang.String,long,long,boolean,org.apache.hadoop.hdfs.server.datanode.CachingStrategy)->org.apache.hadoop.hdfs.server.datanode.DataXceiver:readBlock(org.apache.hadoop.hdfs.protocol.ExtendedBlock,org.apache.hadoop.security.token.Token,java.lang.String,long,long,boolean,org.apache.hadoop.hdfs.server.datanode.CachingStrategy), depth 3
