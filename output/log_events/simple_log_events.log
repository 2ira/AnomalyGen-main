[INFO]:CORS filter not enabled. Please set + key + to 'true' to enable it
[DEBUG]:Processing + event.getTaskAttemptID() + of type + event.getType()
[DEBUG]:RMAuditLogger log failure due to static user
[INFO]:Application <*> user <*> mapping <*> to <*> override <*>, applicationId, user, queueName, mappedQueue.getQueue(), overrideWithQueueMappings
[INFO]:JvmMetrics singleton initialized
[DEBUG]:Processing Plan Command.
[DEBUG]:Skip downloading resource: <*> since it's in state: <*>
[INFO]:Loading history file: <*>
[INFO]:Finish information of application attempt + appAttemptFinish.getApplicationAttemptId() + is written
[INFO]:Killing taskAttempt:tid because it is running on unusable node:taskAttemptNodeId
[DEBUG]:Task failed
[DEBUG]:AADToken: starting to fetch token using MSI
[WARN]:Job <*> out of order
[DEBUG]:Operation unchecked
[ERROR]:Invalid syntax
[DEBUG]:LDAP authentication attempted
[DEBUG]:Starting to download <*> <*> <*>
[ERROR]:Unexpected exception
[INFO]:Deleted trash checkpoint: + dir
[DEBUG]:AzureBlobFileSystem.close
[INFO]:Timeline service v1 batch publishing enabled
[WARN]:<*> metrics system timer already stopped!
[ERROR]:Unable to read transaction ids from the configured shared edits storage. Error: <*>
[INFO]:Enabling preserving blocksize since <*> is passed.
[WARN]:Interrupted operation: + ioe.getMessage()
[WARN]:Exception get thrown in job commit, retry (<*>) time.
[DEBUG]:updateCgroup: <*>: <*>=<*>, path, param, value
[WARN]:Ignoring stale result from old client with sessionId 0x%08x
[INFO]:Cleaning master<*>
[INFO]:History Cleaner started
[WARN]:Failed to execute refreshLoadedJobCache: CachedHistoryStorage is not started
[INFO]:Parsing output: <*>
[DEBUG]:CSConf - setQueues: qPrefix=<*>, queues=<*>
[INFO]:Attempting to open state store driver.
[DEBUG]:seed: + seed
[INFO]:Ignore blacklisting set to true. Known: <*>, Blacklisted: <*>, <*>%
[ERROR]:Unable to store deletion task
[WARN]:Skip and continue on: IOException
[DEBUG]:Executing remove method with record class and query
[DEBUG]:BLOCK* processMisReplicatedBlocks: Re-scanned block <*>, result is <*>
[INFO]:Dead node <*> is put in maintenance state immediately.
[DEBUG]:storeContainerCompleted: containerId=<*>
[DEBUG]:Timeline entities are successfully put
[DEBUG]:Initializing job
[ERROR]:<*>, <*>
[WARN]:bpid + has some block files, cannot delete unless forced
[INFO]:Requested by <*> at <*> to cede active role.
[DEBUG]:NFS READDIRPLUS fileHandle: <*> cookie: <*> dirCount: <*> maxCount: <*> client: <*>
[INFO]:User group mappings retrieved
[DEBUG]:poking parent ' + getParent().getClass().getSimpleName() + ' for key: ' + key
[ERROR]:Cannot render ResourceManager, e
[DEBUG]:Adding in history for + fs.getPath()
[ERROR]:Error while creating Timeline Collections
[INFO]:ResourceRequest: C satisfied preempting D
[WARN]:Start information is missing for application attempt
[INFO]:User access checked
[DEBUG]:Submitting metrics when file system closed took <*> ms., (System.currentTimeMillis() - startTime)
[ERROR]:Exception in adding labels
[WARN]:Error while validating signature
[DEBUG]:Storing token master key to <*>
[DEBUG]:No delegation token found for url=<*>, authenticating with <*>
[WARN]:Failed to commit upload against unknown destination: <*>
[INFO]:Detected old JobDefinition format. Converting.
[INFO]:Loading service definition from + serviceJson
[DEBUG]:stream can be closed for fileId: <*>
[DEBUG]:User rule: parent rule failed
[INFO]:Started listening to TCP requests at port + boundPort + for + rpcProgram + with workerCount + workerCount
[DEBUG]:Delegation token from cache - <*>
[WARN]:Failed to delete old dfsUsed file in ...
[WARN]:IOException of NvidiaDockerV1CommandPlugin init:, e
[DEBUG]:Not scanning suspicious block <*> on <*>, because the block scanner is disabled.
[DEBUG]:Router heartbeat for router <*>
[INFO]:Built timestamp : <*>
[INFO]:Using keytab <*>, for principal <*>
[ERROR]:Error storing AMRMProxy application context entry for applicationAttemptId, e
[WARN]:Pending edits to IPCLoggerChannel.this is going to exceed limit size: queueSizeLimitBytes, current queued edits size: queuedEditsSizeBytes, will silently drop size bytes of edits!
[INFO]:Not attempting to recover. Recovery disabled. To enable recovery, set MRJobConfig.MR_AM_JOB_RECOVERY_ENABLE
[INFO]:Allowed Origins: + StringUtils.join(allowedOrigins, ',')
[INFO]:Validating paths for files
[WARN]:No file for jobconf with jobId found in cache!
[INFO]:amRegistrationResponse recovered for <*>
[DEBUG]:AzureBlobFileSystem.create path: <*> permission: <*> overwrite: <*> bufferSize: <*>
[DEBUG]:ReadBufferManager not initialized yet. Overriding readAheadBlockSize as <*>
[WARN]:SafeMode is in inconsistent filesystem state. BlockManagerSafeMode data: blockTotal=<*>, blockSafe=<*>; BlockManager data: activeBlocks=<*>
[DEBUG]:Query the skyline store for recurrenceId: <*>. + recurrenceId
[DEBUG]:Re-encryption handler throttling because total tasks pending re-encryption updater is <*>
[DEBUG]:Reset log
[ERROR]:Unable to create the reservation
[DEBUG]:Setting S3 client to <*>
[INFO]:Using traffic control bandwidth handler
[INFO]:storing RMDelegation token with sequence number: + identifier.getSequenceNumber()
[DEBUG]:Initializing the GangliaSink for Ganglia metrics.
[WARN]:Request remote address is NULL
[TRACE]:Entering invalidateCache Method.
[INFO]:Completed setting up app master command: <*>
[INFO]:<*>: scanning directory <*>, getName(), taskAttemptDir
[DEBUG]:NameNode host information not yet available
[DEBUG]:Lease renewed with RouterClientProtocol
[ERROR]:Init ClientRequestInterceptor error for user: <*>
[INFO]:YARN containers restricted to yarnProcessors cores
[ERROR]:Illegal column found, skipping this column.
[ERROR]:Error in parsing : <*> : value <*>
[DEBUG]:Checking if component is stable
[DEBUG]:Ignoring exception on hasCapability(<*>)
[INFO]:KMS unauthenticated access audited
[INFO]:Recovering + appStates.size() + applications
[DEBUG]:Removing re-encryption status of zone <*>
[WARN]:AsyncDataService has already shut down.
[DEBUG]:Namenode is in safemode, skipping scrubbing of corrupted lazy-persist files.
[INFO]:Container + containerId + already scheduled for + cleanup, no further processing
[ERROR]:DIAGNOSTIC_LIMIT_CONFIG_ERROR_MESSAGE
[INFO]:Using clusterid: <*>
[INFO]:The thread pool initial size is + this.initialPoolSize
[DEBUG]:Starting app allocation recording
[DEBUG]:AzureBlobFileSystem.listStatus path: <*>
[DEBUG]:AMRMProxy is ignoring event: <*>, event.getType()
[INFO]:Node not found, ignoring the unregister from node id : + nodeId
[DEBUG]:CacheReport of block(s) took createCost msecs to generate and sendCost msecs for RPC and NN processing
[DEBUG]:Block<*>: Deleting buffer file as upload did not start
[INFO]:RedundancyMonitor received an exception while shutting down.
[WARN]:Length of dest file <*>: <*> does not match that of manifest entry <*>
[ERROR]:StringUtils.stringifyException(e)
[WARN]:Metric name <*>, value <*> has no type.
[DEBUG]:Removing local resource at <*>
[DEBUG]:Rendering metrics div
[WARN]:Specified path envBinaryPath is a directory
[DEBUG]:allocate: pre-update applicationAttemptId= ...
[WARN]:Deleting <*> has failed
[DEBUG]:Report already exists: <*>
[DEBUG]:Exporting access keys
[DEBUG]:Extracting service records
[INFO]:Action set for property: MAX_RESOURCES
[DEBUG]:Checking file
[INFO]:Finish time set for task attempt
[DEBUG]:Deleting of <*> directory markers
[INFO]:Setting preemption bit for task: + yarnAttemptID + of type + yarnAttemptID.getTaskId().getTaskType()
[DEBUG]:Application <*> sends out requests for <*> reducers.
[INFO]:Shared Cache Manager overview
[INFO]:Emitting job history data to the timeline service is enabled
[INFO]:Done.
[TRACE]:program + procedure # + call.getProcedure()
[WARN]:Error Recovery for block in pipeline datanodes: datanode index is reason
[DEBUG]:Directory Delete encountered: <*>
[DEBUG]:Try to commit allocation proposal=<*>
[ERROR]:No application Attempt for application : <*> started on this NM.
[ERROR]:User doesn't have permissions to MODIFY_APP
[DEBUG]:Failed to get number of blocks under replicated
[INFO]:Downloaded file + dstFiles.get(0).getName() + size + dstFiles.get(0).length() + bytes.
[ERROR]:Looking to preempt container + container + . Container does not belong to app + getApplicationId()
[DEBUG]:Creating file in FileSystem
[DEBUG]:url=msgToEncode;encHash=encHash;replyHash=replyHash
[DEBUG]:getNewApplication try #<*> on SubCluster <*>
[INFO]:Prefixes generated
[WARN]:Missing Application Id. Please try again by specifying an Application Id.
[ERROR]:Error While Storing RMDelegationToken and SequenceNumber , e
[INFO]:NativeTask Combiner is enabled, class = â€¦
[ERROR]:Error aggregating log file. Log file : <*>. <*>
[WARN]:<*> response <*> <*>
[INFO]:Action set for property: USER_MAX_RUNNING_APPS
[WARN]:Metric was emitted with no name.
[WARN]:Unable to create a new ApplicationId in SubCluster
[INFO]:Ignoring not found attempt <*>
[DEBUG]:Storing state for app <*> at <*>
[INFO]:Loaded edits file(s)
[ERROR]:StoragePolicySatisfier thread received runtime exception.
[DEBUG]:Got exception while trying to read from stream <*>, client: <*> object: <*>, trying to recover:
[DEBUG]:Changing meta file offset of block <*> from <*> to <*>
[INFO]:Server <*> shutdown!, name
[DEBUG]:assignContainersOnNode: node= + node.getRMNode().getNodeAddress() + application= + application.getApplicationId().getId() + priority= + schedulerKey.getPriority() + #assigned= + (nodeLocalContainers + rackLocalContainers + offSwitchContainers)
[WARN]:Unable to delete <*>
[ERROR]:Interrupted waiting for countdown latch
[DEBUG]:Calculating UMask
[DEBUG]:DeadNode detection is not enabled, skip to add node <*>., datanodeInfo
[INFO]:<*>: no pending commits to abort
[INFO]:Super post response created for UNSETSTORAGEPOLICY
[WARN]:Missing Queue. Please try again by specifying a Queue.
[WARN]:Exception when scheduling the event of increasing resource of Container <*>
[INFO]:<*>: No pending component instance left, release surplus container <*>
[INFO]:Each line of output string
[WARN]:BR lease 0x<*> is not valid for DN <*>, because the DN is not in the pending set.
[DEBUG]:Checking block access token for block '<*>' with mode '<*>'
[INFO]:Verification result: <*>
[WARN]:isDirectory is deprecated
[INFO]:====== Fencing successful by method + method + ======
[INFO]:Updating lifetime of an service: serviceName = <*>, appId = <*>, lifetime = <*>
[INFO]:Node <*> is dead and there are no low redundancy blocks or blocks pending reconstruction. Safe to decommission or put in maintenance.
[ERROR]:Failure of S3 Select request against <*>
[ERROR]:The mapping provider, <*> does not have a valid class
[INFO]:Keytab is configured, will login using keytab.
[INFO]:OpenFileCtx is inactive, fileId: <*>
[DEBUG]:Debugging createJobClassLoader
[INFO]:updating RMDelegation token with sequence number: (actual sequence number retrieved from id.getSequenceNumber())
[DEBUG]:Checking if the delegation token operation is allowed
[DEBUG]:<*>: closing stale domain peer <*>
[WARN]:Failed to analyze storage directories for block pool <*>, nsInfo.getBlockPoolID(), e
[ERROR]:GenericObjectMapper cannot write + entity.getClass().getName() + into a byte array. Write aborted!
[INFO]:Removing RMDelegationToken and SequenceNumber
[INFO]:Got event <*> for appId <*>
[DEBUG]:Done
[INFO]:AM container preempted, current appAttemptId=%s, containerId=%s, resource=%s
[INFO]:Updating RMDelegationToken_SEQUENCE_NUMBER
[WARN]:Could not connect to History server.
[WARN]:Signature could not be verified
[ERROR]:<*> instantiation failed., className, e
[DEBUG]:Resource sizing: <*>
[WARN]:The value of DFS_NAMENODE_AVAILABLE_SPACE_RACK_FAULT_TOLERANT_BLOCK_PLACEMENT_POLICY_BALANCED_SPACE_PREFERENCE_FRACTION_KEY is greater than 1.0 but should be in the range 0.0 - 1.0
[ERROR]:Failed while checking for/creating history staging path
[INFO]:Unsuccessfully sent block report 0x...
[ERROR]:Error storing info for AMRMTokenSecretManager
[INFO]:Successfully cached one replica:<*> into persistent memory, <*>
[TRACE]:CleanerUtil.UNMAP_NOT_SUPPORTED_REASON
[WARN]:Deleted a metadata file without a block + diskMetaFile.getAbsolutePath()
[INFO]:Copied remote files
[INFO]:Creating policy manager of type: + configuration.getType()
[INFO]:Activated file cache and written
[WARN]:Attempt to define resource ' + key + ', but it is not allowed.
[DEBUG]:Add <*> to local dead nodes, previously was <*>.
[WARN]:Couldn't get current user
[INFO]:Starting Router ClientRMService
[DEBUG]:Block deletion is delayed during NameNode startup. The deletion will start after <*> ms.
[WARN]:OOM was not resolved in X ms
[ERROR]:SubCluster <*> not found
[INFO]:Unexpected error occurred
[DEBUG]:Failed to choose from the next rack (location = <*>), retry choosing randomly
[INFO]:Scheduling Request made: <*>
[INFO]:Starting DataNode with maxLockedMemory = <*>
[ERROR]:<*>: Invalid event <*> at <*>.
[DEBUG]:GroupCacheLoader - reload (async).
[ERROR]:Errors while recording the output of plan command.
[INFO]:Will run the balancer even during an ongoing HDFS upgrade
[DEBUG]:PrivilegedActionException as: <*>
[WARN]:Target queue + targetQueue + does not exist while trying to move + app.getApplicationId
[INFO]:Going to finish converging with remaining ...
[DEBUG]:Executor service has not shutdown yet. Forcing. Will wait up to an additional <*> <*> for shutdown
[TRACE]:No more elements
[INFO]:Service <*> is successfully flexed.
[INFO]:Task attempt finished event logged
[INFO]:Exception in getting events
[INFO]:Binary tokens merged successfully
[DEBUG]:Stopping webapp
[ERROR]:Not a symlink, fileId: <*>
[INFO]:Registering the Unmanaged application master <*>
[INFO]:localfetcher# + id + about to shuffle output
[DEBUG]:Progressing
[DEBUG]:SQLException committing split transaction: <*>
[DEBUG]:KeyStore loaded successfully from '%s' since '%s' was corrupted !!
[DEBUG]:NodeManager <*> released container (<*>).
[WARN]:No Output found for $<*>
[WARN]:Metrics system not started: + e.getMessage()
[WARN]:Could not initialize log dir <*>
[INFO]:Initializing request processing pipeline for application. ApplicationId: applicationAttemptId for the user: user
[ERROR]:RM could not transition to Active
[WARN]:Cannot parse the value for FS_FTP_TRANSFER_MODE: mode. Using default.
[WARN]:FPGA plugin failed to downloaded IP, please check the value of environment viable: <*> if you want YARN to program the device
[DEBUG]:Error while create symlink linkname to target. Exception: e
[ERROR]:Job resource skyline history is invalid, please try again with valid resource skyline history.
[INFO]:Perfect overwrite has same content, updating the mtime, then return success
[WARN]:Could not read or failed to verify checksum for data at offset <*> for block <*>
[DEBUG]:Updating info cache...
[ERROR]:The supplied range is not a valid integer: Supplied range:
[INFO]:Started plug-in <*>
[DEBUG]:Removing ZKDTSMDelegationToken_<*>
[INFO]:Starting Web-server for <*> at: <*>
[INFO]:dnUserName = <*>
[INFO]:Callback received for initializing request processing pipeline for an AM
[DEBUG]:running merge pass
[INFO]:logEdit
[INFO]:Processed URL + url + but entity not found + (Took + (Time.monotonicNow() - startTime) + ms.)
[INFO]:DefaultMetricsSystem initialized
[INFO]:Container killed by the ApplicationMaster.
[INFO]:Default file system is set solely by core-default.xml therefore - ignoring
[DEBUG]:trying: <*>
[ERROR]:Cannot disable <*>, it does not exists, nsId
[DEBUG]:Failed to assign to queue: + getQueuePath() + nodePartition: + nodePartition + , usedResources: + queueUsage.getUsed(nodePartition) + , clusterResources: + clusterResource + , reservedResources: + resourceCouldBeUnreserved + , maxLimitCapacity: + currentLimitResource + , currTotalUsed: + usedExceptKillable
[INFO]:Removing state for app + removeAppId
[INFO]:Disabling Erasure Coding for path: ...
[DEBUG]:Deleted <*> objects
[INFO]:Initializing Reservation system
[ERROR]:An unexpected exception occurred while pulling data from ZooKeeper
[TRACE]:<*>: released <*>, this, slot
[DEBUG]:Not closing <*>
[DEBUG]:Committer statistics logged
[INFO]:<*>: <*>
[DEBUG]:Adding: rd (not a dir): <*>
[ERROR]:Exception in closing <*>
[DEBUG]:Token sequence no received from heartbeat request: ... System credentials for apps size: ...
[INFO]:Recalculating schedule, headroom=
[DEBUG]:End parsing summary logs.
[WARN]:Access control exception for operation
[DEBUG]:get commit while still writing to the requested offset
[INFO]:Starting <*>
[DEBUG]:Unable to get task type, trying FileDeletionTask
[WARN]:Fsck: can't copy the remains of <*> to <*> because <*> already exists.
[INFO]:Size of <*> event-queue is <*>
[DEBUG]:Creating default URI query builder
[INFO]:Max virtual cores capability of resources in this cluster <*>
[DEBUG]:DataNode overwriting downstream QOP
[INFO]:Loaded key cache.
[ERROR]:Cannot get user: <*>
[DEBUG]:Loading application from znode: <*>
[INFO]:Searching for start times to evict earlier than <*>
[ERROR]:An error occurred when terminating
[INFO]:Service <*> unregistered with RM, with attemptId = <*>, diagnostics = <*>
[TRACE]:Returned Servlet info <*>
[INFO]:Renewing + DelegationTokenIdentifier.stringifyToken(token)
[INFO]:OUTCOME: SUCCESS, Reservation ID: + reservationId.toString() + , Contract: + contract.toString()
[WARN]:Type-specific cleanup of application <*> of type <*> did not succeed with exit code <*>
[INFO]:Container <*> pid file not set. Returning terminated error
[DEBUG]:<*> reported usable, eventNode
[DEBUG]:CustomTokenProvider Access token fetch failed with retry count <*>
[DEBUG]:deleted dir <*>, path
[DEBUG]:Processing <*> of type <*>
[TRACE]:Remove context entry <*>
[INFO]:Allocating asynchronously to home sub-cluster
[DEBUG]:Reading next element
[WARN]:Ignored <*> nodes while loading key cache.
[DEBUG]:Get root ACL status
[WARN]:reference to %s lost during creation, key
[INFO]:Registered DN <*> (<*>)., dn.getDatanodeUuid(), dn.getXferAddr()
[INFO]:onContainerResourceIncreased: <*>, <*>
[DEBUG]:Initializing node attribute store
[INFO]:Creating ProcfsBasedProcessTree for process <*>
[DEBUG]:storeContainerDiagnostics: containerId=<*>, diagnostics=
[INFO]:Received query <*>. Forwarding query <*>, name, qualifiedName
[INFO]:The pluggable device framework enabled, trying to load the vendor plugins
[DEBUG]:Removing state for app + appId + and + appState.attempts.size() + attempts + at + appKey
[WARN]:Execution of Node Labels script failed, Caught exception : + e.getMessage(), e
[WARN]:DFSConfigKeys.DFS_BALANCER_MOVERTHREADS_KEY=<*> is too small for moving blocks to <*> targets. Balancing may be slower.
[TRACE]:unregisterSlot: ShortCircuitRegistry is not enabled.
[ERROR]:Error in handling event type for applicationAttempt
[INFO]:Error getting groups for <*>: <*>
[DEBUG]:Not generating HistoryFinish event since start event not generated for task: $<*>
[DEBUG]:In flush timer task
[WARN]:Unexpected volume event received, event type is + event.getType().name() + , but the volumeId is null.
[DEBUG]:Found path as a file
[INFO]:Going to preempt " + toPreempt + " due to lack of space for maps
[DEBUG]:SASL server doing encrypted handshake for peer = <*>, datanodeId = <*>
[ERROR]:<*> doesnâ€™t exist. Aborting tmp segment move to current directory ; journal id: <*>
[ERROR]:Seems like client has been removed before the event could be published for $<*>
[ERROR]:Refresh super user groups configuration failed for proxy.getAddress()
[ERROR]:Unknown error happened in topology scheduler
[ERROR]:Error getting metrics from source + name, e
[INFO]:<*> RPC address: <*>
[DEBUG]:Cloning and getting container status
[DEBUG]:NFS SYMLINK, target: <*>, link: <*>, namenodeId: <*>, client: <*>
[DEBUG]:*DIR* NameNode.concat: src path <*> to target path <*>
[INFO]:Aggregator executed
[INFO]:Block report queue is full
[INFO]:DIR* addFile: failed to add <*>
[INFO]:<*> permission <*> override <*> replication <*> blockSize <*> unmaskedpermission <*>
[DEBUG]:Could not find <*> cookie, so user will not be set, WebAppProxyServlet.PROXY_USER_COOKIE_NAME
[TRACE]:Done read from Cache for <*> position <*> length <*>, stream.getPath(), position, bytesRead
[INFO]:Dumper got Throwable. dumpFilePath: <*>
[INFO]:Starting with arguments: <*>
[INFO]:Thread interrupted when waiting for volume reference to be released.
[ERROR]:Cannot fetch number of expired registrations from the store: <*>
[ERROR]:Failed to get FileSystem for registry, e
[DEBUG]:Failed to choose from local rack (location = <*>); the second replica is not found, retry choosing randomly
[DEBUG]:Cannot find location with namespace <*> in <*>
[INFO]:Deleting aggregated logs in + appDir.getPath()
[WARN]:Warn message with param
[DEBUG]:Authenticating with dt param: delegationParam
[DEBUG]:LIVE datanodes: <*>
[DEBUG]:Using localizerTokenSelector.
[INFO]:Setting maxEligibleApps to 0 accomplishes nothing. Please either set it to a negative value (default, all) or a more reasonable value.
[DEBUG]:Exception received while deleting temp files
[INFO]:CGroup controller already mounted at: existingMountPath
[ERROR]:Authentication required
[INFO]:Whitelisted /path/to/jar
[INFO]:Copying from <*> to <*>
[INFO]:Creating directory
[DEBUG]:Host list file <*> has not been modified from last refresh
[DEBUG]:Adding: <*>
[INFO]:Application completed successfully
[ERROR]:FileSystem is <*>
[DEBUG]:Get token info proto: + protocol + info: + tokenInfo
[INFO]:To let apps use this tarball, in yarn-site set config property <*> to <*>
[DEBUG]:Got the information about the specified application <*>. The AM is running in <*>
[INFO]:Copying fromPath to toPath
[INFO]:Finishing task: <*>
[INFO]:Running command as user <*>
[INFO]:Disabling Erasure Coding for path: <*>
[DEBUG]:Replica is being written!
[INFO]:Mis-replicated blocks that have been postponed:
[WARN]:Found no running containers to kill in order to release memory
[ERROR]:Exception caught in channelRead0
[INFO]:appId has aggregation status aggStatus
[ERROR]:Error in handling event type <*>
[INFO]:Changing resource-monitoring for <*>
[INFO]:Allowed Methods: allowedMethodsHeaderValue
[DEBUG]:Publishing the entity <*> JSON-style content: <*>
[INFO]:<*> : <*>
[INFO]:Shutting down all AsyncDiskService threads...
[INFO]:Loading resource <*>
[ERROR]:The Router metrics are not enabled
[DEBUG]:Processing event of type <*>
[DEBUG]:<*> Cluster underloaded in run! Stressing...
[ERROR]:Layout version on remote node (...) does not match this node's layout version (...)
[INFO]:Will take over writing edit logs at txnid ...
[ERROR]:Cannot find application with given appId
[INFO]:Checked <*> blocks and <*> nodes this tick. <*> nodes are now in maintenance or transitioning state. <*> nodes pending., numBlocksChecked, numNodesChecked, outOfServiceNodeBlocks.size(), getPendingNodes().size()
[DEBUG]:<*> is recovering. Skipping notifying ATTEMPT_ADDED
[WARN]:options parsing failed: + e.getMessage()
[WARN]:A map attempt status you don't know about is ...
[INFO]:ShuffleHandler listening on port <*>
[INFO]:Splitting resource requests and updating subClusters
[INFO]:Cleaning every <*> seconds
[INFO]:Collection by DirectMapOutputCollector started
[INFO]:Checksum calculation succeeded on block file
[INFO]:RECOVERY COMPLETE
[DEBUG]:IOException when iterating through <*>
[DEBUG]:Unable to perform a zero-copy read from offset <*> of <*>; 31-bit MappedByteBuffer limit exceeded. blockPos=<*>, curEnd=<*>
[INFO]:Using FileSystemAccess simple/pseudo authentication, principal <*>
[DEBUG]:renaming <*> to <*>
[TRACE]:<*> init complete
[INFO]:Purging old edit log <*>
[INFO]:Truncate <*> to length <*>
[WARN]:Unable to get operating system page size. Guessing 4096.
[DEBUG]:Storing info for attempt: $attemptState.getAttemptId()
[INFO]:Demotion Update requests : + demotionRequests
[TRACE]:Removing unknown block <*>
[WARN]:Failed to get server trash configuration
[DEBUG]:Created a new mem block of
[ERROR]:Calling allocate on removed or non existent application ...
[DEBUG]:Renewed token for <*> until: <*>
[INFO]:Planning Algorithm pool size <*>
[INFO]:<*> state is UNKNOWN and logs are stale, assuming COMPLETED
[DEBUG]:reset
[ERROR]:Error parsing simple UGI <*>>; falling back to current user
[INFO]:The directory marker policy of ... is "..."
[INFO]:Starting HBase timeline schema creation
[DEBUG]:Renewing the token
[WARN]:Cannot parse reporter line: <*>
[DEBUG]:, freeQueue.offer
[WARN]:The queried SubCluster: <*> does not exist.
[DEBUG]:Writing with DocumentStoreTimelineWriterImpl
[ERROR]:Exception occurred
[DEBUG]:loaded resources from <*>
[DEBUG]:Doing checkpoint. Last applied: <*>
[DEBUG]:Trying to recover task from ...
[ERROR]:Caught an exception while processing JMX request
[ERROR]:Disk Balancer - No such plan. Cancel plan failed. PlanID:
[WARN]:Access Point usage required
[DEBUG]:logRpcIds operation
[INFO]:Num completed Tasks: ...
[ERROR]:FSError from child ...
[WARN]:Error in reaping container <*> exit = <*>
[INFO]:Deleting state database at <*>
[INFO]:Starting ApplicationMaster
[DEBUG]:requested offset=<*> and current offset=<*>
[WARN]:Unknown method + methodName + called on + connectionProtocolName + protocol.
[ERROR]:Cannot create record type "<*>" from "<*>": <*>
[INFO]:Log <*> appears to be corrupted. Skip.
[DEBUG]:Publishing the entity, JSON-style content
[DEBUG]:Listing summary <*>
[DEBUG]:No scheme-specific factory defined in <*>
[INFO]:Application completed. Signalling finish to RM
[INFO]:Got an error when resolve hostNames. Falling back to default-rack for all.
[INFO]:this activateDelay <*> seconds
[INFO]:Temporary redirect to URI
[INFO]:UAM id <*> is unregistered
[DEBUG]:File not found <*>
[WARN]:Failed to move block file from + blockFile + to + targetBlockFile, e
[DEBUG]:WRITE_RPC_END + xid
[WARN]:Sum of stime () and utime () is greater than
[WARN]:Exception from container-launch with container ID: <*> and exit code: <*>
[DEBUG]:Unable to remove app parent node <*> as it has children., parentZnode
[WARN]:Exception thrown when retrieve key: ...
[INFO]:Starting periodic service <*>
[WARN]:Caught exception in thread <*> + : <*>
[INFO]:Action set for property: FAIR_AS_DRF
[WARN]:Security is not enabled for the Hadoop cluster
[DEBUG]:BLOCK* ask <*> to replicate <*> to <*>
[INFO]:Requesting for <*> container(s), componentSpec.getName(), count
[WARN]:Edits URI ... listed multiple times in ... Ignoring duplicates.
[WARN]:Storage directory ... contains no VERSION file. Skipping...
[ERROR]:Cannot get <*> nodes
[WARN]:rmApp.getApplicationId() + final state ( + appState + ) was recorded, but + appAttempt.applicationAttemptId + final state ( + appAttempt.recoveredFinalState + ) was not recorded.
[ERROR]:Illegal values in env for shell script path
[DEBUG]:Invoked sequential method
[INFO]:Swapping -min (...) and -max (...) values
[ERROR]:Cannot create a new connection
[ERROR]:<*> exiting because of exception
[INFO]:Discarded 0 entities for timestamp 0 and earlier in 0.0 seconds
[DEBUG]:<*> is not a desired LocalizationEvent which needs to be published by NMTimelinePublisher, event.getType()
[WARN]:ContainerRequest has duplicate racks: ...
[INFO]:Added new reservation
[DEBUG]:Exception encountered:
[WARN]:ApplicationMaster is out of sync with RM ... for ..., hence resyncing.
[INFO]:Delete task attempt path
[INFO]:Hosting <*> from <*> at <*>
[INFO]:Error :
[DEBUG]:Removing SPS hint
[INFO]:Added new job with <*> mapper and <*> reducers
[INFO]:Unknown application has completed!
[INFO]:Replica Cache file: path has gone stale
[DEBUG]:Header origins '<*>' not allowed. Returning
[DEBUG]:setAcl filesystem: <*> path: <*> aclspec: <*>
[ERROR]:Access control exception during renew delegation token
[DEBUG]:Getting locations for path
[WARN]:failed to register any UNIX signal loggers: , t
[WARN]:<*>] is not writable
[DEBUG]:Trying to use <*> to select preemption candidates
[INFO]:Stored the finish data of container <*>
[INFO]:Fetching devices from Nvidia GPU plugin
[DEBUG]:Current thread: <*>, COS key: <*>, upload id: <*>, part num: <*>, exception: <*>
[DEBUG]:Memory available: ... , CPUs available: ..., requested: ...
[DEBUG]:User: <*>
[WARN]:Cannot recover task <*>
[INFO]:LogAggregation enabled for application
[INFO]:logEdit called
[INFO]:Time taken to build splits for job: <*> ms.
[ERROR]:Aborted
[ERROR]:ERROR IN CONTACTING RM.
[DEBUG]:Adding <*> as a store for the query
[ERROR]:Unable to kill the application report for applicationId to SubCluster subClusterIdId
[DEBUG]:Creating SAS key from account instance <*>
[ERROR]:Could not start Capacity Scheduler
[INFO]:Created new instance of AMRMTokenSecretManagerState
[DEBUG]:Same amrmToken received from subClusterId, skip writing registry for appId
[INFO]:prefix + metrics system stopped.
[INFO]:Waiting for FileSystem at <*> to be available
[DEBUG]:<*> health check succeeded, assuming storage is up
[INFO]:Assigning multiple NUMA nodes ( + StringUtils.join(,, assignedNumaNodeInfo.getMemNodes()) + ) for memory, ( + StringUtils.join(,, assignedNumaNodeInfo.getCpuNodes()) + ) for cpus for + containerId
[WARN]:anomalous line #<*>:<*>
[ERROR]:FATAL, State store fenced even though the resource manager is not configured for high availability. Shutting down this resource manager to protect the integrity of the state store.
[DEBUG]:Received Heartbeat reply from RM. Allocated Containers:<*>
[INFO]:Router ClientRMService listening on address: + this.server.getListenerAddress()
[DEBUG]:Job Submitted
[ERROR]:Trying to schedule on a removed node, please double check, + nodeId= <*>
[INFO]:Found corruption while reading <*>. Error repairing corrupt blocks. Bad blocks remain., ie
[INFO]:<*> Transitioned from <*> to <*> on <*> event
[INFO]:Allocations created
[DEBUG]:no resource restrictions specified. not using docker's cgroup options
[DEBUG]:Kafka topic <*>
[DEBUG]:IOException:
[DEBUG]:Recovery message with actual state
[WARN]:Cannot kill container <*> pid -<*>.
[WARN]:"Got exception while serving <*> to <*>: ", block, remoteAddress, ioe
[INFO]:NodeHealthReport
[DEBUG]:Assign container precheck for queue + getName() + on node + node.getNodeName() + failed
[DEBUG]:Caught InterruptedException
[ERROR]:Error starting TimelineReaderWebServer
[TRACE]:#<*> processRetryInfo: retryInfo=<*>, waitTime=<*>, callId, retryInfo, waitTime
[ERROR]:Cannot warm up EDEKs.
[DEBUG]:Optimized read failed. Defaulting to readOneBlock <*>
[WARN]:Unsupported/invalid command:
[ERROR]:Failed to add volume: <*>
[DEBUG]:Access control method '<*>' not allowed. Returning
[INFO]:Adding csi-driver-adaptor for csi-driver <*>
[INFO]:Initiating Memory-to-Memory merge with + noInMemorySegments + segments of total-size: + mergeOutputSize
[INFO]:Zone <*> will retry re-encryption
[DEBUG]:Failed to get number of dead nodes
[WARN]:DIR* FSDirectory.unprotectedDelete: failed to remove $<*> because the root is not allowed to be deleted
[DEBUG]:So far, total <*> containers selected to be preempted, <*> containers selected this round\n
[DEBUG]:Delegation token encoded
[DEBUG]:<*> : <*>@<*>, <*>>
[DEBUG]:Making directory: <*>
[INFO]:Applications still running : ...
[DEBUG]:No logs available for container
[INFO]:Found <*> existing UAMs for application <*> in NMStateStore
[WARN]:Missing SubCluster Id information. Please try again by specifying Subcluster Id information.
[DEBUG]:Failed to choose from local rack (location = <*>), retry with the rack of the next replica (location = <*>)
[DEBUG]:Waiting for scheduler to shutdown
[ERROR]:Exception while registering
[INFO]:Processing node file
[WARN]:Unknown failure while trying to fence via ssh
[DEBUG]:Replaced expired token: <*>
[DEBUG]:Storing token <*>
[WARN]:Not able to find datanode <*> which has dependency with datanode <*>
[WARN]:Ignoring exception in LazyWriter:
[INFO]:Succeeded components: <*>
[DEBUG]:Flushing <*>
[INFO]:Inserting ClusterNode <*> with queue wait time <*> and wait queue length <*>
[INFO]:Starting Client
[WARN]:TaskType for a MapTask is not Map. task=... type=...
[INFO]:Application removed - appId: <*> user: <*> leaf-queue of parent: <*> #applications: <*>
[WARN]:Found no start time for related entity <*> of type <*> while deleting <*> of type <*>
[DEBUG]:Check the condition for main loop.
[INFO]:MergeQueue started merging
[INFO]:Job finished cleanly, recording last MRAppMaster retry
[INFO]:IP file path: <*>
[ERROR]:Gridmix input data directory <*> already exists when -generate option is used.
[ERROR]:The current job was submitted earlier than the previous one
[ERROR]:The conf property not set properly, it has been configured with different journalnode values
[DEBUG]:Creating handler for protocol <*>
[DEBUG]:Incoming log <*> not present in my summaryLogs list, add it
[DEBUG]:Configuring jobConf name to use numberOfThreads threads
[WARN]:createFailureLog(user, operation, target, description, null, null)
[DEBUG]:PendingReconstructionMonitor thread is interrupted.
[WARN]:Failed to renew lease for clientName for (elapsed / 1000) seconds (>= hard-limit = (dfsClientConf.getleaseHardLimitPeriod() / 1000) seconds.) Closing all files being written ...
[INFO]:Dispatcher initialized
[INFO]:<*> has expired hard limit
[ERROR]:Cannot remove records <*> query <*>
[INFO]:Initializing Default AMS Processor
[TRACE]:this: registered blockId with slot slotId (isCached=false)
[WARN]:File <*> is not under construction. Skipping add to low redundancy open files!
[DEBUG]:Failed to create <*> at fallback : <*>
[INFO]:Replication counts offset:%d blocks:%d
[DEBUG]:Retrying REST operation <*>. RetryCount = <*>
[WARN]:log.WARN:format,args
[WARN]:Task attempt is done from TaskUmbilicalProtocol's point of view. However, it stays in finishing state for too long
[INFO]:Updated reservation for periodic allocation
[DEBUG]:Loading services
[ERROR]:<*>: Upgrade to version <*> failed
[WARN]:Unable to determine disk scheduler type for partition <*>
[INFO]:Getting the active app list to initialize the in-memory scm store
[INFO]:Queue for application <*> not found during recovery. Placed in recovery queue.
[INFO]:included nodes = <*>
[INFO]:OnDiskMerger: We have <*> map outputs on disk. Triggering merge...
[INFO]:Initializing Document Store Writer for : storeType
[DEBUG]:Reduce tasks to process: this.numReduceTasks
[INFO]:LOGGER.info(msg)
[DEBUG]:Token kind is <*> and the token's service name is <*>
[INFO]:Invalid call marked
[WARN]:Bad checksum type: <*>. Using default <*>
[DEBUG]:Cleaning up expired peer
[DEBUG]:Exception cause details
[INFO]:Diagnostics report from <*>: <*>
[INFO]:Registering UAM id <*> for application <*>
[DEBUG]:Processing fileDiffEntry
[INFO]:KMS Stopped
[INFO]:Re-encrypting zone <*>(id=<*>)
[DEBUG]:PendingReconstructionMonitor checking Q
[DEBUG]:DIR* NameSystem.delete: <*>
[ERROR]:Failed to register the NFSv3 service.
[DEBUG]:NFS SYMLINK, target: <*> link: <*> namenodeId: <*> client: <*>
[INFO]:Set <*> to '<*>'<*>, name, redactor.redact(name, value), source == null ? : from + source
[DEBUG]:HEAD <*> with change tracker <*>
[INFO]:Connected to + host
[DEBUG]:Initializing S3AFileSystem for <*>
[TRACE]:<*>: got InvalidToken exception while trying to construct BlockReaderLocal via <*>, this, pathInfo.getPath()
[DEBUG]:block<*>: closeBlock(), index
[WARN]:Exception encountered while running the renewal command for <*>
[DEBUG]:Skipping statistical outlier detection as we don't have latency data for enough resources. Have <*>, need at least <*>
[DEBUG]:Concurrent invocation on src
[INFO]:Delete startJobCommitFile in case commit is not finished as successful or failed.
[WARN]:NodeManager configured with <*> physical memory allocated to containers, which is more than 80% of the total physical memory available (<*>). Thrashing might happen.
[INFO]:Directory with id <*> removed during re-encrypt, skipping
[INFO]:Found script: <*>
[INFO]:submitApplication appId <*> try #<*> on SubCluster <*>
[DEBUG]:Loaded <*> with onDiskVersion= + onDiskVersion + , layoutVersion= + layoutVersion + .
[WARN]:Last seen exception:
[INFO]:detachFile failed to delete temporary file
[INFO]:Not doing static UID/GID mapping because 'staticMappingFile' does not exist.
[DEBUG]:Recycle devices: <*>, type: <*> from <*>
[DEBUG]:Jiffy Comparison: + procfs.getCumulativeCpuTime() + + cgroup.getCumulativeCpuTime()
[ERROR]:Error parsing the policy.
[DEBUG]:Generated manifest for logs since
[INFO]:Using network-tagging-handler.
[WARN]:RM app submission failed in validating AM resource request for application
[INFO]:Refresh user to groups mapping successful
[DEBUG]:FileId: <*> Service time: <*>ns. Sent response for commit: <*>
[DEBUG]:Setting node count for blacklist to <*>
[DEBUG]:Renewed ticket. kinit output: <*>
[INFO]:Reloading keystore and truststore certificates.
[DEBUG]:Using java.security.SecureRandom as random number generator.
[INFO]:Could not complete <*> retrying...
[TRACE]:UC block <*> insufficiently-replicated since numLive (<*>) <*>)
[WARN]:There was a conflict while upserting, hence retrying...
[DEBUG]:Total # of splits generated by getSplits: + splits.size() + , TimeTaken: + sw.now(TimeUnit.MILLISECONDS)
[DEBUG]:Failed to load HDFS runC image to hash file. Config not set
[INFO]:Boosting the map phase progress.
[DEBUG]:initialized local file as 'file'.
[INFO]:Skipping download of remote edit log <*> since it's already stored locally at <*>
[TRACE]:<*>: returning new block reader local.
[DEBUG]:Skip updating node attributes since there is no change for <*> : <*>
[ERROR]:Cannot register subcluster: $<*>
[DEBUG]:Interrupted while waiting for processes to disappear
[ERROR]:Refusing to leave safe mode without a force flag. Exiting safe mode will cause a deletion of <*> byte(s). Please use -forceExit flag to exit safe mode forcefully if data loss is acceptable.
[ERROR]:Callback handler does not implement container resource update callback methods
[ERROR]:Error retrieving key <*> from ZK
[DEBUG]:Failed to create <*> at fallback fs : <*>
[INFO]:No auxiliary services changes detected
[WARN]:InMemoryAliasMap location <*> is missing. Creating it.
[INFO]:Removing <*> from application <*>
[DEBUG]:Average bytes per map: ..., Number of maps: ..., total size: ...
[INFO]:YARN Configuration: Scheduler RM Placement Constraints Handler + placement handler will be used. Scheduling requests will be handled by the main scheduler.
[INFO]:Sequential invocation executed
[INFO]:Start information of application attempt is written
[ERROR]:Failed to initialize queues
[DEBUG]:Container Status: id=<*>, status=<*>
[INFO]:Re-encryption using key version
[INFO]:File opened successfully
[ERROR]:Unknown WritingApplicationHistoryEvent type: <*>
[ERROR]:Illegal event type:
[DEBUG]:Establishing zookeeper connection for <*>
[WARN]:Application <*> cannot be found in scheduler.
[INFO]:Re-encryption caught exception, will retry
[DEBUG]:Launching DNS server
[DEBUG]:deleting simple file <*>
[DEBUG]:skipping skipAmt bytes at the end of edit log getName(): reached txid txId out of lastTxId
[ERROR]:Internal Server Error was encountered while making a request
[DEBUG]:File processed and submitted for upload
[DEBUG]:checkAccess operation completed
[INFO]:... (additional logs from dumpParsedTaskAttempt if any) ...
[INFO]:Loaded configuration store version info <*>
[INFO]:Diskspace quota set
[ERROR]:Fail to sync service spec: <*>
[ERROR]:Error retrieving tokenInfo <*> from ZK
[DEBUG]:Removing token master key at <*>
[DEBUG]:Tried to read from deleted edit log segment
[INFO]:Deleted 0 entities of type entityType
[INFO]:Available space block placement policy initialized: DFS_NAMENODE_AVAILABLE_SPACE_BLOCK_PLACEMENT_POLICY_BALANCED_SPACE_PREFERENCE_FRACTION_KEY = balancedPreferencePercent
[DEBUG]:Cannot execute <*> on <*>: <*>
[DEBUG]:rpcServer.isInvokeConcurrent returned TRUE
[INFO]:User + appSubmitterUgi.getUserName() + added suffix(.sh/.bat) to script file as + renamedScriptPath
[TRACE]:this + : replica refCount + (replica.refCount - 1) + -> + replica.refCount + StringUtils.getStackTrace(Thread.currentThread())
[ERROR]:Invalid MKDIR request
[INFO]:reencryptEncryptedKeys <*> keys for key <*> took
[INFO]:Environment <*> <*>
[INFO]:Redirecting to AHS ...
[INFO]:checking for deactivate of application : + this.applicationId
[INFO]:updatePipeline( + oldBlock.getLocalBlock() + => + newBlock.getLocalBlock() + ) success
[TRACE]:range.getMin()=<*> nextOffset=<*>
[DEBUG]:using cgroup parent: <*>
[DEBUG]:Token not required, returning default user parameters
[ERROR]:incomplete rm state store entry found : + record
[ERROR]:Failed to initialize authentication handler + authHandlerClassName, ex
[WARN]:Error registering RMInfo MBean
[INFO]:Applications Killed: countHere
[INFO]:Concurrent thread successfully re-registered, moving on.
[DEBUG]:sending PRC request
[DEBUG]:read requested b = null offset = <*> len = <*>, off, len
[DEBUG]:Lease renewed for client <*>
[DEBUG]:Started entry writer <*>
[ERROR]:Failed to move aside pre-upgrade storage in image directory
[DEBUG]:Date conversion error
[WARN]:Exception thrown in onDeviceReleased of + devicePlugin.getClass() + for container: + container.getContainerId().toString(), e
[INFO]:Initialized auxiliary service <*>
[DEBUG]:Write operation checked
[INFO]:Found tarball at: <*>
[DEBUG]:Adding containers for preemption
[DEBUG]:Service: <*> entered state <*>
[DEBUG]:Get volume create request from plugin:<*> for container: <*>
[DEBUG]:rename: renaming directory <*> to <*>
[DEBUG]:Handling NodesListManagerEvent
[DEBUG]:No new edits available in logs; requested starting from ID <*>
[ERROR]:Configuration must be suffixed with nameservice and namenode ID for HA configuration
[INFO]:Application completed. Stopping running containers
[INFO]:Waiting for service dependencies.
[ERROR]:Logger error message with arguments
[ERROR]:IOException during mapAttributesToNodes
[DEBUG]:scanning file: <*>}
[INFO]:Task attempt finalized
[WARN]:Exception while trying to get password for alias <*>:
[ERROR]:Got an exception while writing file
[INFO]:Connection to the State Store driver <*> is open and ready
[WARN]:The requested section for <*> is empty. It will not be output to the image
[DEBUG]:Destination file exists: <*>
[DEBUG]:New Resource Instance Created
[WARN]:Failed to manage OS cache for "<*>" fd <fd.toString()
[DEBUG]:Removing master key
[WARN]:Matched a 'bytes sent' line outside of a class stats segment : <*>
[INFO]:this + successfully registered with NN
[INFO]:amRegistrationRequest recovered for <*>
[INFO]:FSTrashRoot operation executed
[DEBUG]:Exception in closing <*>, <*>
[DEBUG]:Exception while removing old mirror
[DEBUG]:Not generating HistoryFinish event since start event not generated for taskAttempt: + taskAttempt.getID()
[DEBUG]:Requesting role <*> with duration <*>; policy = <*>, roleARN, duration, policy
[DEBUG]:buildTokenServiceForLogicalUri
[INFO]:Using conf database at storeRoot
[INFO]:The specified queue: + queueName + does not exist!
[INFO]:Got Cluster metric info from ASM, numNodeManagers=
[ERROR]:Unknown format of script output! Skipping this line
[INFO]:No files to commit
[INFO]:VolumeImpl + volumeId + transitioned from + oldState + to + newState
[INFO]:Allocated new BlockPoolId: <*>
[DEBUG]:Using CIDR match for 'host' and READ_ONLY
[INFO]:Success log for completed application state
[INFO]:Deleted <*> cache files
[DEBUG]:Satisifer Q - outstanding limit:<*>, current size:<*>
[DEBUG]:Application <*> has one container finished (<*>).
[DEBUG]:Receiving one packet for block xyz: header_info
[DEBUG]:Add dead node to check: <*>.
[INFO]:Computing partitions took (t3 - t2) ms
[INFO]:FSCreate operation executed
[DEBUG]:Scanning <*> for files to commit
[WARN]:Non device number provided, cannot decide the device type
[INFO]:taskId + Task Transitioned from + oldState + to + getInternalState()
[DEBUG]:Failed to accept this proposal because it tries to release an outdated reserved container
[ERROR]:Registry resolve key <*> failed
[DEBUG]:Stopping auxiliary service
[DEBUG]:Value of <*> is <*>, key, v
[DEBUG]:Appending instrumentation info
[ERROR]:Could not create KeyProvider for DFSClient !!
[INFO]:Saving image file <*> using <*>
[ERROR]:Ignoring invalid eventtype + event.getType()
[DEBUG]:rpcServer.isInvokeConcurrent returned FALSE
[WARN]:The log aggregation is disabled. There is no cached log aggregation status.
[WARN]:Thread interrupted while trying to acquire WRITE lock
[WARN]:The server is stopped.
[DEBUG]:Requesting all entries under <*> with delimiter '<*>'
[WARN]:Fsck: Block manager is able to process only + processedBlocks + mis-replicated blocks (Total count : + misReplicatedBlocks.size() + ) for path + path
[TRACE]:SPNEGO completed for client principal <*>
[ERROR]:Failed to launch container due to configuration error.
[WARN]:ClientServiceDelegate invoke call interrupted
[INFO]:FSOpen operation executed
[DEBUG]:ACL not found for queue access-type <*> for queue <*>
[DEBUG]:Ignore disabling erasure coding for path <*> because method disableErasureCodingForPath doesn't exist, probably talking to a lower version HDFS.
[INFO]:User doesn't have permissions to <*>
[ERROR]:File is not a regular file
[INFO]:Record too large for in-memory buffer
[INFO]:Splitting using BigDecimalSplitter
[WARN]:Exception while reading a range <*> from path <*>
[TRACE]:Fetching SharedKey credentials
[ERROR]:Unable to update current master key in state store, e
[INFO]:Service definition <*> doesn't belong to any user. Ignoring..
[INFO]:IOStatistics: <*>
[WARN]:DataNode<*>:Failed to transfer <*> to <*> got
[INFO]:Finalize upgrade for <*> is complete
[DEBUG]:Log that a snapshot is created
[INFO]:Excluded Cipher List: + excludeCiphers
[WARN]:Encountered exception while tailing edits >= + fromTxnId + via RPC; falling back to streaming.,ioe
[DEBUG]:Updating $<*> from $<*>
[DEBUG]:Verifying existence of source and it's a file
[INFO]:Balance succeed!
[ERROR]:Should not get commit return code: + ret.name()
[DEBUG]:Added priority= + priority
[INFO]:JobName got an error while submitting, ioe
[DEBUG]:Failed to publish Container metrics for container <*> with exception e
[WARN]:LazyWriter failed to create <*>
[INFO]:Node <*> <*> healthy. It needs to replicate <*> more blocks. <*> is still in progress.
[INFO]:Activating next master key with id: ...
[WARN]:Got a repeated request, same range, with xid: <*> nextOffset <*> req offset=<*>
[WARN]:Failed to update the access time of <*>
[INFO]:modifyCachePool of <*> successful; no changes.
[DEBUG]:delete filesystem: <*> path: <*> recursive: <*>
[DEBUG]:MOUNT NULLOP : client: client
[DEBUG]:<*>: the UNIX domain socket associated with this short-circuit memory closed before we could make use of the shm.
[INFO]:Token renewal for identifier: ...
[INFO]:Updated reservation
[INFO]:Unknown application + containerId.getApplicationAttemptId().getApplicationId() + launched container + containerId + on node: + node
[WARN]:Invalid key Operation '<*>'
[WARN]:Access denied for rename (options=<*>) src dst
[DEBUG]:<*>: Not scheduling suspect block <*> for rescanning, because we rescanned it recently.
[WARN]:Illegal value: there is no element in \" + s + \".
[TRACE]:#<*> processRetryInfo: waitTime=<*>, getCallId(), waitTime
[INFO]:System.out.println("No EC policy parsed out from " + filePath)
[DEBUG]:Clearing encryption key
[DEBUG]:NoOpTimelineWriter is configured. Not aggregating TimelineEntities.
[INFO]:Replacing MAP container
[DEBUG]:Sorting located block
[INFO]:Application <*> is shutting down.
[WARN]:Exception occurred while closing connection : + StringUtils.stringifyException(ex)
[TRACE]:this + ": allocAndRegisterSlot " + idx + ": allocatedSlots=" + allocatedSlots + StringUtils.getStackTrace(Thread.currentThread())
[DEBUG]:JWT token audience has been successfully validated
[INFO]:Successfully logged kill audit event.
[WARN]:NODEEXISTS_MSG
[WARN]:The root directory is not available, using <*>
[DEBUG]:offer window of metric: <*> userName: <*> sum: <*>
[DEBUG]:Is namenode in safemode? true; uri= + uri
[INFO]:HS Admin: + method + invoked by user + user.getShortUserName()
[ERROR]:The container <*> couldn\'t be found on the node specified: <*>
[DEBUG]:before cpuCheck <*>
[INFO]:Removed node <*> clusterResource: <*>
[DEBUG]:Running Timeline Storage monitor
[INFO]:Generated metrics table
[DEBUG]:Building token service
[WARN]:Another reconfiguration task is running.
[INFO]:Starting HTTP server
[DEBUG]:logSync(tx) synctxid=<*> lastJournalledTxId=<*> mytxid=<*>
[WARN]:Task cleanup failed for attempt_
[DEBUG]:Not a link
[DEBUG]:storeApplication: appId=<*>, proto=<*>
[INFO]:App-level aggregator shutdown timed out, shutdown now.
[ERROR]:e.toString()
[INFO]:current cluster id for sd=;lv=;cid=
[INFO]:PowerShell command: <*>
[INFO]:Downloaded file <*> of size <*> bytes.
[INFO]:Inserting new NN registration: <*>
[ERROR]:JAR does not exist or is not a normal file
[WARN]:Failed to get nodes report
[INFO]:Logging initialized
[ERROR]:The <*> cannot find a location for <*>, super.getClass().getSimpleName(), path
[WARN]:Timeline token does not have service and timeline service address is not yet set. Not updating the token
[DEBUG]:No source etag; unable to probe for the operation's success
[ERROR]:ReplayThread encountered exception; exiting.
[DEBUG]:SPS processing Q -> maximum capacity:<*>, current size:<*>, remaining size:<*>
[DEBUG]:Attempting to clean up iterator
[INFO]:Successfully deleted reservation
[DEBUG]:storeContainerQueued: containerId=<*>
[INFO]:Using <*> for creating Timeline Service Schema
[INFO]:Update collector information for application <*> with new address: <*> timestamp: <*>, <*>
[WARN]:Error closing the HTTP response's inputstream.
[INFO]:<*>: Directory entries containing files to delete: <*>
[DEBUG]:No mode specified, defaulting to -LIST,
[DEBUG]:Exception encountered while connecting to the server <*>
[ERROR]:Cannot sync as there is no other JN available for sync.
[WARN]:Error closing the stream /proc/diskstats
[INFO]:UserGroupInformation initialized to <*>
[INFO]:Written to memory cache
[ERROR]:Failed to initialize <*>
[DEBUG]:assignContainers: node= + node.getRMNode().getNodeAddress() + application= + application.getApplicationId().getId() + priority= + schedulerKey.getPriority().getPriority() + assignableContainers= + assignableContainers + capability= + capability + type= + type
[DEBUG]:Loading reservation from znode: <*>
[INFO]:Audit log for operation addErasureCodingPolicies
[TRACE]:FileSystem.<*>() full stack trace:
[DEBUG]:Arrays.toString(fullCommandArray)
[DEBUG]:Creating password for <*> for user <*> to be run on NM <*>, identifier.getContainerID(), identifier.getUser(), identifier.getNmHostAddress()
[DEBUG]:Initializing service
[INFO]:Found active RM <*>
[INFO]:Could not obtain <*> from any node: <*>. Will get new block locations from namenode and retry...
[DEBUG]:Finished refreshing <*> of <*> streams in <*>ms
[ERROR]:Invalid event + type + on Task + this.taskId
[INFO]:Start loading edits file <*> maxTxnsToRead = <*> <*>
[INFO]:Sleeping for <*> ms
[ERROR]:IOStatistics: <*>
[INFO]:Constraint <*> will not be added. There is already a constraint associated with tag <*>., placementConstraint, sourceTag
[WARN]:cachedDfsUsed not found in file:<*>, will proceed with Du for space computation calculation
[INFO]:Reading hosts file into set for type and filename
[WARN]:Shared cache does not support directories (see YARN-6097). Will not upload <*> to the shared cache.
[ERROR]:Error when publishing entity
[INFO]:Finished one round, will wait for <*> for next round
[DEBUG]:--container=<*> resource=<*>
[DEBUG]:Reinit compressor with new compression configuration
[TRACE]:Got user: <*>, remoteIp: <*>, path: <*>
[DEBUG]:AzureBlobFileSystem.setPermission path: <*>
[DEBUG]:Directory created
[INFO]:Initialized connection pool to the Federation StateStore database at address: <*>
[DEBUG]:Average bytes per map: + nBytesPerSplit + , Number of maps: + numSplits + , total size: + totalSizeBytes
[WARN]:Line does not have two columns. Ignoring. <*>
[DEBUG]:Configuring metrics system
[DEBUG]:Node + node.getNodeName() + offered to queue: + getName() + fairShare: + getFairShare()
[INFO]:RouterClientProtocol refresh invoked
[ERROR]:Cannot get local host name
[WARN]:Found non empty SchedulingRequest in AllocateRequest for application=...
[INFO]:FieldSelectionHelper.specToString(fieldSeparator, reduceOutputKeyValueSpec, allReduceValueFieldsFrom, reduceOutputKeyFieldList, reduceOutputValueFieldList)
[INFO]:...
[WARN]:Found null for clusterId. Not proceeding with writing to hbase
[INFO]:Retrying connect to server: + server + . Already tried + curRetries + time(s); retry policy is + connectionRetryPolicy
[INFO]:Stopping StoragePolicySatisfier.
[INFO]:Sending signal x to container y
[WARN]:Failed to finish unmanaged application master: RM address: <*> ApplicationId: <*>, e
[INFO]:Application Attempt Overview
[INFO]:mapRedFinished
[DEBUG]:Swallowing delete exception on retry: ...
[INFO]:Reserved VirtualCores: countHere
[INFO]:parts<*> = parts<*>
[DEBUG]:Using NN principal: + nameNodePrincipal
[DEBUG]:Scanner skips for unknown dir/file <*>
[ERROR]:Unable to locate any logs for container
[ERROR]:Could not retrieve owner information for path -
[ERROR]:Illegal event type: <*>
[DEBUG]:<*>: failed to load block iterator: + e.getMessage()
[INFO]:upload part request
[WARN]:Localized resource is null!
[INFO]:Transaction succeeded
[DEBUG]:Delegation token authentication attempted
[DEBUG]:Found volume-driver:volumeDriver
[INFO]:Container kill state stored
[DEBUG]:Error reading the error stream due to shell command timeout
[INFO]:<*> Container + relEvent.getContainer() + sent RELEASE event on a resource request + req + not present in cache.
[INFO]:Job configured successfully
[ERROR]:Sampler requires more than one reducer
[DEBUG]:RemoteIterator Statistics: <*>
[INFO]:Continuing re-encrypt handler after pausing.
[INFO]:Server <*> started!, status <*>
[DEBUG]:Watcher event type: ...
[INFO]:Container metrics released
[DEBUG]:Delete ClusterNode:
[DEBUG]:Set applogs <*> for group id <*>
[INFO]:Adding query param: UPN
[DEBUG]:Event handled by
[INFO]:POST: createService = <*> user = <*>
[DEBUG]:Renaming oldmeta to newmeta
[ERROR]:error parsing conf UNKNOWN_RESOURCE
[DEBUG]:<*>: masked=<*>, src, absPermission
[DEBUG]:Cleanup with logger
[INFO]:Selecting file with query
[WARN]:Exception handling the winning of election, e
[DEBUG]:Updating token + tokenId.getSequenceNumber()
[INFO]:Checkpoint finished successfully.
[INFO]:Copying file <*> to <*>
[INFO]:Thread pool created
[INFO]:Instantiating TimelineReaderWebApp at bindAddress
[WARN]:Exception while trying to close proxy
[TRACE]:Entering getKeysMetadata method.
[DEBUG]:Getting splits for the job context
[ERROR]:Node attributes sent from NM while registration were rejected by RM. ((errorMsgFromRM == null) ? Seems like RM is configured with Centralized Attributes. : And with message + regNMResponse.getDiagnosticsMessage())
[INFO]:Old Queue: + stringRepr(oldQ) + , + Replacement: + stringRepr(newQ)
[WARN]:Unable to return groups for user '...' as shell group lookup command '...' ran longer than the configured timeout limit of ... seconds.
[DEBUG]:Attempt to allocate on node successful
[DEBUG]:Job Finished in
[DEBUG]:stopping actual client because no more references remain: <*>
[DEBUG]:Waiting for task completion
[INFO]:Stopping service scheduler
[INFO]:<*> Service RPC address: <*>
[ERROR]:Initialization failed for this . Exiting.
[DEBUG]:File has been downloaded to <*> from <*>
[ERROR]:UnKnown execution type received
[ERROR]:Failed to stop DataNode Container + containerId
[INFO]:<*>: Executing Stage <*>, getName(), stageName
[WARN]:Failed to update re-encrypted progress to xattr for zone ..., ...
[ERROR]:Node Resolution failed. Please make sure that rack awareness scripts are functional.
[ERROR]:Cannot get stat from <*> using JMX
[ERROR]:Exception in doCheckpoint:
[INFO]:BR lease 0x<*> is not valid for unknown datanode <*>
[DEBUG]:Decided to move + this
[ERROR]:Failed to render attempts page with task type : + $(TASK_TYPE) + for job id : + $(JOB_ID)
[DEBUG]:Got invalid encryption key error in response to OP_BLOCK_CHECKSUM
[WARN]:Failed to reconstruct striped block <*>
[DEBUG]:Handling files with dangling temp data
[DEBUG]:Removed re-encryption tracker for zone ... because it completed with ... tasks.
[DEBUG]:Docker container deletion initiated
[ERROR]:User <*> is not authorized to view the logs for
[WARN]:Exception while trying to create default reservation queue for + plan: <*>, planQueueName, e
[INFO]:Initialized Docker runtime
[ERROR]:Couldn't find volume= + volumeName + driver= + driverName + for container= + container.getContainerId() + , please check error message in log to understand why this happens.
[DEBUG]:Choose redundant EC replicas to delete from blk_<*> which is located in <*>
[WARN]:Could not find serial portion from path: <*>. Continuing with next
[INFO]:Handling new committer job abort event
[DEBUG]:Retrieving schedule configuration
[DEBUG]:Creating default headers
[INFO]:Updated xattrs on <*>(<*>) files in zone <*> for re-encryption, starting:<*>.
[ERROR]:In the current state, queue + getName() + has + children.size() + but the new state has none!
[INFO]:Hadoop Metrics Updater executor shutdown interrupted.
[INFO]:Application finished, removing password for appAttemptId
[WARN]:Cannot parse counter increment ' + columns<*> + ' from line: + line
[INFO]:Recovering CA Certificate and Private Key
[DEBUG]:Recording a newly allocated block ID in the edit log
[WARN]:Ending command processor service for: + this
[WARN]:Cannot obtain the user-name. Got exception: ...
[INFO]:<*> retrieve status after <*>
[INFO]:Reconfiguring <*> to <*>
[DEBUG]:Cluster timestamp validation check
[INFO]:Container + containerId + succeeded
[ERROR]:<*>: Cancellation of upgrade failed
[ERROR]:NAME + failed:, e
[INFO]:Storing info for app: <*>
[INFO]:KMS Started
[WARN]:Gridmix will not emulate Distributed Cache load because the input trace source is a stream instead of file.
[DEBUG]:Exception in archives
[INFO]:Total size set
[TRACE]:hasDt=<*>, queryStr=<*>
[DEBUG]:SASL server context established. Negotiated QoP is...
[ERROR]:Couldn't find RM app for <*> to set queue name on.
[ERROR]:Encountered Exception for <*> operation for file <*>
[ERROR]:Cannot rename <*> to <*>, src, dst, e
[WARN]:TotalMaps for job ... is less than the total number of map task descriptions (...)
[DEBUG]:hostsReader: in= + conf.get(YarnConfiguration.RM_NODES_INCLUDE_FILE_PATH, YarnConfiguration.DEFAULT_RM_NODES_INCLUDE_FILE_PATH) + out= + conf.get(YarnConfiguration.RM_NODES_EXCLUDE_FILE_PATH, YarnConfiguration.DEFAULT_RM_NODES_EXCLUDE_FILE_PATH)
[INFO]:Thread.currentThread().getName() + ": skipped " + this
[ERROR]:Can't handle this event at current state for <*>
[INFO]:movedContainer queueMoveOut= usedCapacity= absoluteUsedCapacity= used= cluster=
[WARN]:name:an attempt to override final parameter: attr; Ignoring.
[WARN]:Finish information is missing for container
[ERROR]:Task: <*> - exited : <*>
[INFO]:Recovered <*> reservations
[DEBUG]:Using credentials from <*>
[DEBUG]:KMS region used: <*>
[DEBUG]:Running at: miniKdc.getHost():miniKdc.getHost()
[INFO]:Cleaning up the staging area submitJobDir
[DEBUG]:Processing arguments
[ERROR]:Unable to remove deletion task + taskId + from state store
[INFO]:File attributes set successfully
[ERROR]:Proxy error: proxyPort set without proxyHost
[INFO]:Updated reservation using AlignedPlannerWithGreedy
[INFO]:<*> Finished merging <*> map output files on disk of total-size <*>. Local output file is <*> of size <*>
[DEBUG]:PlacementManager active with new rule set
[INFO]:Unregistering slot because the requestShortCircuitFdsForRead operation failed.
[TRACE]:load(<*>, <*>): loaded iterator <*> from <*>: <*>, storageID, bpid, name, file.getAbsoluteFile(), WRITER.writeValueAsString(state)
[DEBUG]:AADToken: no token. Returning expiring=true
[INFO]:No interceptor pipeline for application <*>, likely because its AM is not run in this node.
[INFO]:Skip recovering container for already stopped attempt.
[DEBUG]:newInfo = <*>
[INFO]:ContainerManager started at <*>
[ERROR]:Failed to place application
[DEBUG]:Parse logFile: <*>., logFile
[DEBUG]:Error parsing <*> as an ApplicationId
[DEBUG]:STATE* Safe mode extension entered.
[ERROR]:Error in handling event type
[DEBUG]:Checksum type: ...
[WARN]:Failed to delete block file
[ERROR]:Error updating cache for <*>
[INFO]:Waiting for task completion
[DEBUG]:Activating span from request
[INFO]:Skipping scheduling as the node <*> has been removed
[INFO]:staleLogMSG.toString()
[INFO]:Adding <*> for user <*>
[INFO]:Volume removed successfully.
[ERROR]:Invalid resource request specified for property ...
[ERROR]:Exception thrown when formatting configuration.
[DEBUG]:msg
[DEBUG]:Canot execute <*> in <*>: <*>
[ERROR]:Error reported on storage directory <*>
[DEBUG]:added <*>
[DEBUG]:Error while changing permission : filename Exception: exception details
[TRACE]:Lexicographical comparer selected for byte aligned system architecture
[DEBUG]:SASL server skipping handshake in secured configuration with no SASL protection configured for peer = <*>, datanodeId = <*>
[INFO]:Starting ApplicationHistory
[DEBUG]:LIST <*>
[INFO]:Applications Completed: countHere
[WARN]:Failed to place enough replicas, still in need of X to reach Y (unavailableStorages=...,storagePolicy=...,newBlock=...) e.getMessage()
[ERROR]:Failed to report to name-node., e
[ERROR]:Failed to start JournalNode.
[INFO]:Forcefully decommission node with state not DECOMMISSIONED
[ERROR]:Invalid COMMIT request
[INFO]:logAuditEvent(true, getAclStatus, src)
[INFO]:Parsed <*> entities from <*> in <*> msec
[DEBUG]:cleanup container <*> files
[WARN]:getMaxVirtualMemoryForTask() is deprecated. Instead use getMemoryForMapTask() and getMemoryForReduceTask()
[ERROR]:Cannot remove records <*> query <*>, <*>
[ERROR]:Illegal event type: + event.getClass()
[WARN]:Exception while trying to merge periodic and non-periodic user allocations: <*>
[ERROR]:Error closing provider with url
[INFO]:Issuing kill to other attempt <*>
[DEBUG]:Generating key material
[DEBUG]:Redirecting <*> <*> to <*>
[INFO]:Available space rack fault tolerant block placement policy initialized
[DEBUG]:Initializing with protocol and prefix
[INFO]:line
[INFO]:Num completed Tasks: + job.completedTaskCount
[DEBUG]:Node remained UNHEALTHY
[INFO]:Adding new resource: type: + resourceName + , + deviceSet
[DEBUG]:getEntity: Found nothing
[DEBUG]:Sorting located striped block
[WARN]:User ' + userName + ' is not present in active/non-active. This is highly unlikely. + We can consider this user in non-active list in this case.
[DEBUG]:Task attempt dir not found
[INFO]:Quota verified for truncate
[ERROR]:Error getting domain
[INFO]:Start moving block
[INFO]:reInitializing container <*> with version <*>
[INFO]:Incrementing counter for each cache pool
[DEBUG]:Preallocated + total + bytes at the end of + the edit log (offset + oldSize + )
[DEBUG]:<*> is recovering. Skipping notifying ATTEMPT_ADDED, appAttemptId
[INFO]:Successfully moved block
[DEBUG]:Failed to refresh DFSInputStream for path <*>
[WARN]:Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
[INFO]:<*>: already has <*> instances, ignoring
[DEBUG]:AzureBlobFileSystem.getXAttr path: <*>
[WARN]:session.getRemoteAddress().getHostString() + " closed, status: " + status + " Reason: " + reason
[DEBUG]:It is not allowed to rename a parent directory: <*> to its subdirectory: <*>
[ERROR]:Getting is-exclusive-node-label, node-label = <*>, is not existed.
[DEBUG]:do write, fileHandle <*> offset: <*> length: <*> stableHow: <*>, handle.dumpFileHandle(), offset, count, stableHow.name()
[DEBUG]:rename failure
[DEBUG]:Retrieved pathInfo for + identifier + check for corresponding loaded messages to determine whether + it was loaded or cached
[ERROR]:Fsck: could not copy block <*> to <*>
[DEBUG]:Generating Container SAS Key: Storage Account <*>, Container <*>
[INFO]:Removing reservation <*> to repair physical-resource constraints in the plan: <*>
[WARN]:ResourceHandlerChain.reacquireContainer failed for containerId: <*> Exception:
[DEBUG]:Incrementing AUDIT_REQUEST_EXECUTION counter
[INFO]:rollingUpgrade QUERY
[DEBUG]:Initiating multipart upload from <*> to <*>
[INFO]:Unable to clean tmp directory
[WARN]:Get a negative backoff value from ShuffleHandler. Setting it to the default value 5000
[INFO]:Stopped federation membership heartbeat
[WARN]:copyMapOutput failed for tasks failedTasks
[INFO]:Shutting down CacheReplicationMonitor.
[DEBUG]:STATE* Safe mode ON.
[INFO]:TrashPolicyDefault#deleteCheckpoint for trashRoot: + trashRoot
[DEBUG]:System.currentTimeMillis() + " <*> Overloaded is " + Boolean.TRUE.toString() + " MapSlotsBackfill is " + loadStatus.getMapLoad()
[ERROR]:Failed to initialize the FederationStateStoreFacade object
[INFO]:rollingMonitorInterval is set as <*>. The log rolling monitoring interval is disabled. The logs will be aggregated after this application is finished.
[WARN]:A single batch of edits was too large to fit into the cache: startTxn = %d, endTxn = %d, input length = %d. The capacity of the cache (%s) must be increased for it to work properly (current capacity %d). Cache is now empty.
[DEBUG]:Closing Abfs: <*>
[DEBUG]:Created a new BR lease 0x<*> for DN <*>. numPending = <*>
[DEBUG]:The destination <*> is a symlink.
[ERROR]:Unable to update the ApplicationId <*> into the FederationStateStore
[ERROR]:Base IP address is invalid
[DEBUG]:List of plugins of ResourcePluginManager was empty while trying to add ResourceHandlers from configuration!
[DEBUG]:Processing help Command.
[INFO]:Waited X ms (timeout=Y ms) for a response for Z...
[INFO]:Adding block pool <*> to volume with id <*>
[WARN]:The atomic rename feature is not supported by the ABFS scheme; however rename, create and delete operations are atomic if Namespace is enabled for your Azure Storage account.
[INFO]:Got <*> = '<*>' (default '<*>')
[DEBUG]:Interrupted while waiting to retry, e
[INFO]:Block pool storage directory for location ... is not formatted. Formatting ...
[INFO]:Need to move <*> to make the cluster balanced.
[DEBUG]:Wrote input for Map
[WARN]:Configuring queue ACLs in mapred-site.xml or hadoop-site.xml is deprecated. Configure queue ACLs in QUEUE_CONF_FILE_NAME
[ERROR]:Error joining with heartbeat thread, ex
[ERROR]:IOException while listing entity types
[DEBUG]:Node <*> is currently in maintenance
[INFO]:Fail closing ViewFileSystem's child filesystem
[INFO]:Finalizing edits file inprogressFile -> dstFile
[DEBUG]:Copy result <*>: <*>
[TRACE]:Scanner volume report: <*>
[DEBUG]:<*> UGI: <*>
[INFO]:Chosen node: ...
[WARN]:<*> <*>
[WARN]:Incorrect RPC Header length
[ERROR]:Script <*> returned <*> values when <*> were expected.
[INFO]:Cleaner set to delete logs older than <*> seconds
[INFO]:Using ShuffleConsumerPlugin: ...
[INFO]:Found a renamed directory that was left undeleted at + path.toString() + . Deleting.
[DEBUG]:Signing request with shared key
[DEBUG]:PmemMappableBlockLoader used for block loading
[INFO]:new IP = <*>, host = <*>, updating registry
[INFO]:YARN containers restricted to ... cores.
[INFO]:Too many fetch-failures for output of task attempt: <*> ... raising fetch failure to map
[ERROR]:Failed removing registry directory key + key
[INFO]:Removed the global cleaner pid file at + pidPath.toString()
[DEBUG]:Executing privileged operation
[DEBUG]:Verifying the access of user on the timeline domain
[WARN]:Empty directories detected and created
[INFO]:Abort the multipart upload. COS key: <*>, upload id: <*>.
[ERROR]:Exception encountered , ignore
[WARN]:Error retrieving hostname:
[ERROR]:Illegal event type: event.getClass()
[INFO]:Running old API mapper
[DEBUG]:Loading filesystems
[ERROR]:YarnException ex
[WARN]:Failed to write replicas to cache
[INFO]:Service <*> unregistered with RM, with attemptId = <*> , diagnostics = <*>
[INFO]:Stopping HealthMonitor thread
[INFO]:Auxiliary services manifest is enabled, but no manifest file is specified in the configuration.
[ERROR]:Failed to read the container <*>.
[TRACE]:openFileMap size: + size()
[INFO]:Getting groups for user via RouterUserProtocol
[DEBUG]:<*> not created <*> Cannot write data into znode <*>: <*>
[WARN]:IPC_FCQ_DECAYSCHEDULER_PERIOD_KEY is deprecated. Please use IPC_SCHEDULER_DECAYSCHEDULER_PERIOD_KEY
[ERROR]:Application ID doesn't exist for <*>
[ERROR]:Failure in copying <*> <*>
[TRACE]:<*>: createNewShm: created <*>
[DEBUG]:Connecting to datanode dnAddr
[WARN]:Audit event failure: AccessControlException for operation: setErasureCodingPolicy on srcArg
[WARN]:Unable to delete %s, tried to delete for %d ms
[INFO]:Removal of AutoCreatedLeafQueue + queueName + has succeeded
[WARN]:AsyncDispatcher thread interrupted, e
[WARN]:The signer interface has changed in AWS SDK V2, custom signers will need to be updated once S3A is upgraded to SDK V2
[DEBUG]:User <*> has been removed!
[INFO]:Initializing queue path
[DEBUG]:App-level collector is empty, skip aggregation.
[DEBUG]:picking + result
[DEBUG]:NM deleting absolute path : <*>
[ERROR]:Interrupted while attempting to shutdown
[INFO]:Audit log creation successful
[DEBUG]:Get FPGA major-minor numbers from /dev/<*>
[DEBUG]:Attempting to create application info for the report
[INFO]:Placeholder for log message
[ERROR]:Unable to update the application <*>
[DEBUG]:Requesting an OAuth token by <*> to <*>
[INFO]:Node <*> hasn't sent its first block report.
[DEBUG]:Retrieved file status: not null
[DEBUG]:Received new token for : <*>
[ERROR]:UncheckedIOException thrown
[INFO]:S3 client-side encryption enabled: Ignore S3-CSE Warnings.
[DEBUG]:Node being looked for scheduling <*> availableResource: <*>
[INFO]:Unable to close file because dfsclient was unable to contact the HDFS servers. clientRunning false hdfsTimeout 0
[TRACE]:Validating directive <*> pool maxRelativeExpiryTime <*>
[DEBUG]:Delegation token requested
[WARN]:Invalid clusterId in journal request - expected <*> actual <*>
[DEBUG]:Started block recovery <*> lease <*>
[DEBUG]:Failed to get the used capacity
[INFO]:Expired: key Timed out after interval secs
[ERROR]:Aborting current sync attempt.
[INFO]:Loaded token cache.
[DEBUG]:Retrieving file size for: <*>
[INFO]:Loading the INodeDirectory section in parallel with <*> sub-sections
[DEBUG]:Ignoring added ACL - registry is insecure<*>, aclToString(acl)
[ERROR]:Error initializing Registry DNS Server, e
[DEBUG]:Log throwable from afterExecute
[ERROR]:Only specify cancel, renew or print.
[DEBUG]:Directive <*>: ignoring non-directive, non-file inode <*>
[DEBUG]:Using blacklist for AM: additions(<*>) and removals(<*>)
[DEBUG]:Loading using Default Loader
[INFO]:Name service ID <*> will use virtual IP <*> for failover, nameServiceID, virtualIP
[INFO]:Using ResourceCalculatorProcessTree: <*>
[INFO]:Will move <*> in this iteration for <*>
[DEBUG]:Value of <*> is <*>
[INFO]:Blacklisted host <*>
[INFO]:Initializing cluster for Job Tracker=...
[INFO]:Deregistered the SubCluster <*> state to <*>
[INFO]:Received completed container <*>
[DEBUG]:Creating new fake directory at <*>
[INFO]:nodeBlacklistingEnabled:<*>
[INFO]:Refresh super user groups configuration successful
[DEBUG]:Bad request: requires Application ID
[INFO]:Downloaded file <*> size <*> bytes.
[INFO]:File: <*> is not having any blocks. So, skipping the analysis.
[DEBUG]:Read block from receiver
[INFO]:Loading EC policy file + policyFile
[WARN]:Failed to replace datanode. Continue with the remaining datanodes since BEST_EFFORT_KEY is set to true.
[WARN]:User $<*> doesnâ€™t have permission to call '$<*>'
[DEBUG]:Creating encryption zone
[DEBUG]:Creating socket address for host
[INFO]:TrashPolicyDefault#deleteCheckpoint for trashRoot: ...
[INFO]:Metrics for the application created successfully
[DEBUG]:Retrieve COS key:<*>. range start:<*>.
[INFO]:Configuring job jar
[INFO]:======================================================
[DEBUG]:JWT token signature is not null
[INFO]:Registering with RM using containers :<*>
[WARN]:Got overwrite with appended data [<*>-<*>), current offset <*>, drop the overlapped section [<*>-<*>) and append new data [<*>-<*>)
[INFO]:Trying method + (++i) + / + methods.size() + : + method
[DEBUG]:Token of kind <*> is found
[ERROR]:Error while configuring container!
[INFO]:host freed by Thread.currentThread().getName() in (Time.monotonicNow() - SHUFFLE_START.get()) ms
[WARN]:Transitioning the resource manager to standby.
[DEBUG]:doSecureLogin
[INFO]:Written to file cache
[DEBUG]:BLOCK* <*>: ask <*> to delete <*>, getClass().getSimpleName(), dn, toInvalidate
[DEBUG]:Failed to get number of blocks pending replica
[WARN]:Failed to construct new object of type
[TRACE]:Starting VolumeScanner <*>
[ERROR]:Incompatible version for timeline store: expecting version + getCurrentVersion() + , but loading version + loadedVersion
[DEBUG]:Checking state of job
[INFO]:starting application
[WARN]:<*>: mkdir failure #<*> Failed to create directory "<*>": <*>
[INFO]:Starting BPOfferServices for nameservices: ...
[DEBUG]:Successfully wrote doc with id : <*> and type : <*> under Database : <*>
[WARN]:Ignored <*> nodes, including <*> in snapshots. Please turn on debug log for details
[ERROR]:Failed to cleanup staging dir:
[DEBUG]:<*> post complete, containerId
[INFO]:got stale replica ... Removing this replica from the replicaInfoMap and retrying.
[ERROR]:Failure in Retriable command: ...
[DEBUG]:Exceptions occurred: + ioe
[INFO]:<*>, Token=<*>
[INFO]:AM container = <*> reported to finish
[INFO]:MRAppMaster launching normal, non-uberized, multi-container job ...
[INFO]:Using a threshold of
[WARN]:Unknown method called
[INFO]:Deleting the path
[INFO]:Removed blocks associated with storage <*> from DataNode <*>
[INFO]:Containers recovered after AM registered: <*>
[DEBUG]:Value of CGroupsHandler is: <*>
[INFO]:Volume <*>: verification failed for <*> because of FileNotFoundException. This may be due to a race with write.
[DEBUG]:LocalFetcher going to fetch
[WARN]:name + "is not a known counter."
[INFO]:Received URL + url + from user + userName
[DEBUG]:Checking and resuming update operation
[DEBUG]:Loading the mount-table <*> into configuration.
[WARN]:ShutdownHook 'SimpleName' timeout, ex.toString(), ex
[INFO]:Stop + getName()
[INFO]:Recover RBW replica
[INFO]:Not tracking job + stats.getJob().getJobName() + as seq id is less than zero: + seq
[INFO]:Shutdown has been called
[DEBUG]:Created SASL server with mechanism = mechanism_value
[DEBUG]:Relation of units: + unitsRelation
[INFO]:Could not obtain block from any node: <*>
[INFO]:Open the file: <*> for reading.
[DEBUG]:Removing master key X
[DEBUG]:storeContainer: containerId= <*>, startRequest= <*>
[WARN]:Path is null
[INFO]:Thread.currentThread().getName() + "copying..."
[WARN]:Lost contact with Zookeeper. Transitioning to standby in <*> ms if connection is not reestablished.
[INFO]:Sorry it looks like the job has no counters.
[DEBUG]:Aborting old stream to open at pos ...
[DEBUG]:Store a empty file in COS failed., e
[WARN]:Original exception is
[WARN]:Rules after rule (i+1) in queue placement policy can never be reached
[INFO]:Server <*> starting
[INFO]:Write lock info after unlocking: ... <*>
[INFO]:Started federation membership heartbeat with interval: <*>
[INFO]:Error Recovery for + block + waiting for responder to exit.
[WARN]:delete(<*>) returned false
[INFO]:Discovered GPU information: ...
[DEBUG]:state = <*>
[DEBUG]:visiting <*> with outstandingMmapCount=<*>, replicas=<*>, failedLoads=<*>, evictable=<*>, evictableMmapped=<*>
[DEBUG]:Tracking ProcessTree <*> for the first time
[DEBUG]:mark at <*>, position()
[INFO]:Formatting block pool <*> directory <*>
[INFO]:Updating starved apps with remaining minshare
[WARN]:Shuffle failure
[DEBUG]:putDomain(domain=<*>, callerUgi=<*>)
[ERROR]:Uncaught exception in thread <*> -exiting
[INFO]:Deleting bread-crumb of active node...
[ERROR]:Trying to signal an absent container
[WARN]:(null == service ? The auxService is null : The auxService name is + service.getName()) + and it got an error at event: + eventType
[WARN]:DIR* FSDirectory.unprotectedRenameTo: rename source <*> is not found.
[DEBUG]:Resetting permissions to ' + permissions + '
[DEBUG]:Trying to assign %d GPUs to container: %s, #AvailableGPUs=%d, #ReleasingGPUs=%d
[DEBUG]:Error , cause
[INFO]:Temporary redirect response built
[INFO]:Total input files to process : <*>
[ERROR]:Failed to reload fair scheduler config file - will use existing allocations.
[ERROR]:nextValidOp: got exception while reading
[DEBUG]:Publishing the entity + entity + , JSON-style content: + TimelineUtils.dumpTimelineRecordtoJSON(entity)
[DEBUG]:Waiting for volume reference to be released.
[WARN]:Default configuration file not available in classpath <*>
[DEBUG]:set nextReadPos to <*>
[WARN]:"<*>" + outerrThreadsThrowable
[DEBUG]:Remote address for request is: <*>
[INFO]:Reading cluster info from file : dataFilePath
[DEBUG]:Excluding DataNodes when allocating new block: <*>
[WARN]:Unable to create app cache directory : <*>
[ERROR]:<*> encountered fatal exception and exit., getName(), t
[WARN]:Failed to get the checksum for block <*> at index <*> in blockGroup <*>
[WARN]:Start op not found: <*>(<*>)
[INFO]:Initializing HttpFSServerMetrics
[INFO]:Use nvidia gpu binary: pathOfGpuBinary
[DEBUG]:Skipped a canceled re-encryption task
[ERROR]:Exception renewing token + token + . Not rescheduled
[DEBUG]:<*> reported unusable, eventNode
[INFO]:Failed to getQueueInfo for <*>, <*>
[INFO]:Submitting reservation to ResourceManager
[WARN]:Failed to find class of specified policy=...
[DEBUG]:Driver class not found.
[DEBUG]:Token read from token storage: <*>
[ERROR]:Failed to load auxiliary service
[DEBUG]:nextRange startIndex: endIndex:
[ERROR]:File is not closed
[DEBUG]:taskId + ": RecordReader is null. No records to be read."
[INFO]:Got <*> = '<*>' (default '<*>'), name, value, defaultValue
[DEBUG]:Propagating entries under $<*>, accountPrefix
[DEBUG]:Released read lock
[DEBUG]:Appending kerberos realm to make <*>
[DEBUG]:Cleared digest ACLs
[DEBUG]:Generic options parsed
[INFO]:Audit event: getECTopologyResultForPolicies
[ERROR]:Failed to convert Credentials from ByteBuffer.
[INFO]:Initializing AMS Processing Chain
[INFO]:Use <*> as script name.
[ERROR]:IOException occurred while loading configuration file.
[DEBUG]:Removing master key + key.getKeyId()
[WARN]:Get corrupt file blocks returned error
[WARN]:Invalid capability information. Please try again by specifying valid Capability Information.
[INFO]:Event Writer setup for JobId: <*>, File: <*>
[DEBUG]:Caught exception when obtaining reference count on closed volume
[INFO]:System env: key=..., val=...
[DEBUG]:requestShortCircuitFdsForRead failed
[DEBUG]:waiting to acquire block: <*>
[DEBUG]:Queueing <*> entries
[DEBUG]:Start reading combined range <*> from path <*>
[INFO]:Entry to state <*> for <*>
[INFO]:Starting SchedulingMonitor=
[INFO]:Processing apps with fairshare starvation
[INFO]:logEdit executed
[WARN]:Missing Policy Type. Please try again by specifying a Policy Type.
[ERROR]:Disk Balancer : Scheduler did not terminate.
[INFO]:Waiting for application <*> to be killed.
[ERROR]:GenericObjectMapper cannot write <*> into a byte array. Write aborted!
[INFO]:Recovering <*> in state <*> with exit code <*>
[DEBUG]:Log audit event: failed operation addCachePool
[INFO]:Found devices:
[WARN]:JWT signature verification failed.
[ERROR]:Interrupted waiting for executor terminated.
[DEBUG]:Lease recovery for inode <*> is complete. File closed
[TRACE]:Token generated with type <*>
[INFO]:Synchronizing log <*> from <*>
[INFO]:Cleared trash for bpid <*>
[INFO]:Container : <*> is waiting for free <*> devices.
[WARN]:IOStatistics: <*>
[DEBUG]:No collectors to update RM
[WARN]:hostsFilePath + has legacy JSON format. + REFER_TO_DOC_MSG
[ERROR]:Cannot get local namespace for <*>, clientAddr
[WARN]:JWT expiration date validation failed.
[DEBUG]:Updating existing mount table entry
[INFO]:op=GETCONTENTSUMMARY target=path
[DEBUG]:Selected from StateStore the policy for the queue: <*>
[INFO]:<*> Component state changed from <*> to <*>
[DEBUG]:concat: firstchunk: + dstfs.getFileStatus(firstChunkFile)
[INFO]:delete temp configuration file: + tempConfigPath
[WARN]:Failed to place enough replicas, still in need of ...
[WARN]:'Authorization' does not start with 'Negotiate' : <*>
[WARN]:prefix + metrics system already started!, new MetricsException(Illegal start)
[DEBUG]:Container Status: <*> ContainerId: <*>
[INFO]:Copying path to target
[ERROR]:Failed to upgrade application:
[ERROR]:Registration failure with host:port, portmap entry: mapEntry
[WARN]:Environment variable truncated to fit system limits.
[INFO]:Shutting down the background thread.
[WARN]:The API setMaxPhysicalMemoryForTask() is deprecated. The value set is ignored. Refer to setMemoryForMapTask() and setMemoryForReduceTask() for details.
[DEBUG]:The first job has a submit time of ...<*>
[INFO]:Reading NUMA topology using configurations.
[ERROR]:Unable to store token
[DEBUG]:Destination directory exists; conflict policy permits this
[INFO]:<*>: could not load <*> due to InvalidToken exception.
[DEBUG]:*DIR* Namenode.delete: src=<*>, recursive=<*>
[WARN]:<*> has no corresponding application!
[DEBUG]:remove <*> <*>
[DEBUG]:Ignoring counter increment for unknown counter <*>
[ERROR]:Missing options: must have value for uri and api
[ERROR]:Shuffle failed with too many fetch failures and insufficient progress!
[WARN]:There is no policies configured for queue: + queue + we + fallback to default policy for: + YarnConfiguration.DEFAULT_FEDERATION_POLICY_KEY
[INFO]:Scanner skips for unknown dir <*>
[DEBUG]:Verbose set for marker tool
[DEBUG]:Removing ZKDTSMDelegationToken_ <*>
[INFO]:applicationId found existing hdfs token
[ERROR]:Timeout for waiting current attempt of + appId + to reach + attemptState
[WARN]:Proxy user '<*>' from application tag does not have access to queue '<*>'. The placement is done for user '<*>'
[WARN]:Failed to transfer block <*>
[INFO]:Scan Results: <*>
[ERROR]:Audit event failed
[INFO]:<*>: Cleanup of <*> disabled, getName(), baseDir
[INFO]:Mount table entries cache refresh successCount=<*>,failureCount=<*>
[ERROR]:Failed to parse persistent memory volume
[WARN]:Requested data length x is longer than maximum configured RPC length y. RPC came from z
[ERROR]:Failed to start + containerId, t
[DEBUG]:exact match for <*>: <*>
[INFO]:Analyzing storage directories for bpid <*>
[WARN]:Failed to updateBlock (newblock=, datanode=r.id)
[WARN]:Disallowed RPC access from <*> at <*>. Not listed in <*>
[WARN]:Fatal disk error on + dnName + : + msg
[INFO]:<*>: Deleted component instance dir: <*>
[DEBUG]:BLOCK* block RECEIVING_BLOCK: block <*> is received from <*>
[INFO]:Not overwriting <*> with smaller file from trash directory. This message can be safely ignored.
[WARN]:Error reading the stream <*>
[TRACE]:redirectURI=<*>
[INFO]:Recovered reservations for Plan: <*>
[ERROR]:Failed to start Container <*>, containerId, t
[WARN]:An interrupted exception occurred when waiting a read buffer.
[INFO]:Error while creating of RM app master service proxy for attemptId,..., user:...
[DEBUG]:Application <*> has one reducer killed (<*>)
[ERROR]:Cannot refresh mount table: state store not available
[INFO]:Home dir: <*>
[INFO]:Bytes Read: bytes
[TRACE]:read(arr.length=<*>, off=<*>, len=<*>, filename=<*>, block=<*>, canSkipChecksum=<*>): I/O error
[DEBUG]:Refreshing all components
[ERROR]:Error While Removing RMDelegationToken and SequenceNumber , e
[DEBUG]:Adding request to ask <*>
[INFO]:Checking script path: envBinaryPath
[DEBUG]:handleWrite org.apache.hadoop.nfs.nfs3.request.WRITE3Request
[WARN]:cleanup failed for container...
[DEBUG]:Allocating new block group. The previous block group: <*>
[ERROR]:Cannot get node mapping when resolving <*> at <*> from <*>, path, loc, clientAddr
[DEBUG]:Loading identity map from file <*>
[DEBUG]:logRpcIds
[WARN]:Last block locations not available. Datanodes might not have reported blocks completely. Will retry for $<*> times
[INFO]:Path <*> is not shared.
[DEBUG]:AADToken: refreshing token from MSI
[INFO]:Registering + attemptId + , + service.getName() + into registry
[INFO]:Reopened at position <*>
[DEBUG]:Updated map for non-Mac
[WARN]:auth_to_local rule mechanism not set. Using default of DEFAULT_MECHANISM
[INFO]:<*> : configured=<*>, counted=<*>, effected=<*>, DFSConfigKeys.DFS_BLOCK_INVALIDATE_LIMIT_KEY, configuredBlockInvalidateLimit, countedBlockInvalidateLimit, this.blockInvalidateLimit
[DEBUG]:Not merging the ranges as they are disjoint
[INFO]:Purging remote journals older than txid + minTxIdToKeep
[DEBUG]:Failed to get status of path <*>
[INFO]:isIgnoreFailures= + isIgnoreFailures
[TRACE]:nextTcpPeer: created newConnectedPeer <*>
[ERROR]:No edits directories configured!
[INFO]:Remove erasure coding policy + name
[DEBUG]:Metrics system inited <*>
[DEBUG]:Unexpected node event: ...
[DEBUG]:<*> was chosen by name node (favored=<*>).
[WARN]:Quitting election but indicating that fencing is necessary
[INFO]:unknown POST /webhdfs/v1/...
[INFO]:Unable to roll forward using only logs. Downloading image with txid <*>
[WARN]:Configuration property UPLOAD_PART_COUNT_LIMIT shouldn't be overridden by client
[ERROR]:Couldn't find dependency <*> for <*> (should never happen)
[TRACE]:Enabling fallbackToSimpleAuth for target, as we are allowed to fall back.
[WARN]:trying to get DT with no secret manager running
[INFO]:Cannot roll key: keyName within KeyProvider: provider.
[INFO]:Failed to satisfy the policy after retries. Removing inode from the queue.
[DEBUG]:opening listeners: <*>
[WARN]:Error when verifying access for user ...
[INFO]:SkipList is enabled with skipInterval= + skipInterval + , maxLevels= + maxLevels
[DEBUG]:Starting write operation
[DEBUG]:Creating base placement policy from config
[DEBUG]:Refresh superuser groups configuration in Router.
[WARN]:Placement rule specified a parent queue <*>, but it is ambiguous.
[DEBUG]:File closed
[WARN]:Caching not supported on block with id + blockId + since the volume is backed by RAM.
[DEBUG]:Try to allocate from reserved container, but node is not reserved
[WARN]:Using GPU plugin with disabled LinuxContainerExecutor is considered to be unsafe.
[ERROR]:Error running ApplicationMaster
[DEBUG]:Successfully retrieved next source value
[DEBUG]:getLogAggregationContext
[WARN]:Not all router admins updated their cache
[INFO]:UAM <*> reattached for <*>
[DEBUG]:Displaying error: message with object1, object2
[WARN]:Volume <*> detected as being unhealthy, reference.getVolume()
[INFO]:Parsed constraint Empty
[DEBUG]:Getting objects for directory prefix <*> to delete
[DEBUG]:Configuring job jobId with submitJobDir as the submit dir
[WARN]:Error sending metrics to StatsD, e
[WARN]:The storage policy <*> is not suitable for Striped EC files. So, ignoring to move the blocks
[INFO]:Mounting controller controller.getName() at requestedMountPath
[INFO]:Ignoring output of failed map TIP: '<*>'
[DEBUG]:Attempting to read aggregated logs using TFileController
[INFO]:Refreshing nodes resources
[DEBUG]:Illegal progress value found, progress is larger than 1. Progress will be changed to 1
[INFO]:The token was removed already. Token = <*>
[ERROR]:Failed while getting the configured log directories
[WARN]:Resource is missing: <*>
[DEBUG]:Directive <*>: the directive expired at <*> (now = <*>)
[INFO]:Scan for launch type on <*>
[WARN]:Repetitive policies in EC policy configuration file: <*>
[DEBUG]:Starting thread pool of <*> listStatus workers.
[DEBUG]:Parent queue = ... : Found ... leaf queues to be activated with ... apps
[ERROR]:format, args
[INFO]:validate reservation input
[INFO]:org.apache.hadoop.yarn.applications.distributedshell.ApplicationMaster$NMCallbackHandler:onContainerStopped called
[ERROR]:Encountered Storage Exception for read on Blob : <*> Exception details: <*> Error Code : <*>
[INFO]:keyName has been successfully rolled.
[INFO]:metrics system shutdown complete.
[INFO]:Starting shutdown message
[INFO]:Size of containertokens_dob is + taskCredentials.numberOfTokens()
[TRACE]:<*>: found waitable for <*>
[DEBUG]:cGroupsHandler is null. cgroups are not in use. nothing to do.
[DEBUG]:Delete event <*>
[INFO]:Scanning block pool <*> on volume <*>...
[WARN]:Found unexpected column for entity of type
[INFO]:Application <*> found, returning home sub-cluster
[WARN]:Only one image storage directory (DFS_NAMENODE_NAME_DIR_KEY) configured. Beware of data loss due to lack of redundant storage directories!
[INFO]:YarnConfiguration initialized
[ERROR]:Invalid event + event.getType() + on Node + this.nodeId + oldState + oldState
[ERROR]:Its submit time is + result.getSubmitTime() + ,but the previous one was + returnedLatestSubmitTime
[ERROR]:No component exists for + event.getName()
[INFO]:Error cleaning up job: <*>
[INFO]:Total bytes (blocks) moved in this iteration <*> (<*>)
[INFO]:Can't unregister DN <*> because it is not currently registered.
[WARN]:Payload size <*> too big for reencryptEncryptedKeys from user <*>.
[WARN]:The cleaner task was interrupted. Aborting.
[INFO]:Web server init done
[INFO]:Interval extends beyond the end time <*>
[INFO]:Finished recovery of GpuDevice for <*>.
[INFO]:Starting services required for active state
[INFO]:Reducer configuration started
[ERROR]:FSError: <*> from task: <*>
[WARN]:InterruptedException executing command: , ie
[DEBUG]:owner:<*>, group:<*>
[INFO]:Configurations = <*>
[DEBUG]:Preparing to delete a batch of <*> old start times
[DEBUG]:listStatus filesystem: <*> path: <*>, startFrom: <*>
[DEBUG]:Sending the heartbeat with capability: <*>
[WARN]:Usage of -Djava.library.path in + javaConf + can cause + programs to no longer function if hadoop native libraries + are used. These values should be set as part of the + LD_LIBRARY_PATH in the + component + JVM env using + envConf + config settings.
[DEBUG]:Creating a HadoopYarnProtoRpc proxy for protocol <*>
[INFO]:Killed container= + toKillContainer.getContainerId() + from queue= + lq.getQueuePath() + to make queue= + this.getQueuePath() + 's max-capacity enforced
[INFO]:Using OutputCommitter factory class <*> from key <*>
[ERROR]:Unexpected exception <*> proxying <*> to <*>
[DEBUG]:from system property: <*>
[DEBUG]:Got one inactive stream:
[INFO]:Thread.currentThread().getName() + ": readAndProcess from client " + c + " threw exception <*>"
[INFO]:Fields parameter adjusted
[INFO]:rmId + " did not transition to standby successfully."
[WARN]:Cannot get all encrypted trash roots
[INFO]:Application master for app: appId=<*>, clusterTimestamp=<*>, attemptId=<*>
[DEBUG]:Deleting entity type:<*> id:<*>
[DEBUG]:Exception raised with exit code <*>
[INFO]:No remoteRequestTable found with allocationRequestId= + req.getAllocationRequestId()
[DEBUG]:Default rule instantiated with default queue name: <*>, and create flag: <*>
[ERROR]:Unsupported operation exception thrown
[INFO]:Kill job <*> received from <*> at <*>
[INFO]:LazyWriter was interrupted, exiting
[INFO]:Initialized KeyProvider
[DEBUG]:Incoming requestAttribute:<*> is not present in <*>, skip such node.
[DEBUG]:Application <*> sends out request for <*> failed reducers.
[DEBUG]:Make directory: <*> in COS.
[DEBUG]:Removing from cache + fileInfo
[WARN]:Exception while uploading the file + localPath.getName()
[ERROR]:Cannot render ResourceManager
[WARN]:Failed to delete <*>, path, e
[DEBUG]:Queue placement policy is present
[WARN]:Invalid NM Heartbeat Configuration. Required: 0 < minimum â‰¤ interval â‰¤ maximum. Got: 0 < <*> â‰¤ <*> â‰¤ <*> Setting min and max to configured interval.
[DEBUG]:Progress of TaskAttempt ...
[DEBUG]:(isUpdate ? Updating : Storing ) + ZKDTSMDelegationToken_ + ident.getSequenceNumber()
[INFO]:Cannot re-encrypt directory with id <*> because it's not a directory.
[ERROR]:Exception in writeLock during removeCachePool, <*>}, false
[DEBUG]:allocateResource log message if debug enabled
[INFO]:op=GETFILESTATUS target=path
[DEBUG]:Headroom calculation for <*>:Min((queueFairShare=<*> - queueUsage=<*>), maxAvailableResource=<*> Headroom=<*>, this.getName(), queueFairShare, queueUsage, maxAvailableResource, headroom
[INFO]:Got Cluster metric info from ASM, numNodeManagers=<*>
[DEBUG]:Node heartbeat + nm.getNodeID() + available resource = + node.getUnallocatedResource()
[WARN]:Couldn't read "/proc/meminfo"; can't determine memory settings
[DEBUG]:Pipe child done
[INFO]:Do not start Router RPC metrics
[INFO]:Container kill event processed
[DEBUG]:Loading service provider type default
[ERROR]:Failed to read the application attempt
[DEBUG]:Scanner skips for unknown dir <*>.
[INFO]:Processed URL <*> but app not found (Took <*> ms.)
[ERROR]:Unable to obtain the policy information for all the queues.
[INFO]:Loading InMemoryAliasMapReader for block pool id <*>
[INFO]:Initializing tc state.
[INFO]:Done logSyncAll lastWrittenTxId= + lastWrittenTxId + lastSyncedTxid= + synctxid + mostRecentTxid= + txid
[DEBUG]:CPU Comparison: + procfs.getCumulativeCpuTime() + " " + cgroup.getCumulativeCpuTime()
[ERROR]:Failed to create an AM
[INFO]:Modification time set for file
[ERROR]:Unexpected exception thrown during in-memory store app check task. Rescheduling task.
[ERROR]:Error processing logs for (appId), t
[ERROR]:Error in dispatcher thread
[INFO]:Done acknowledgment from + taskAttemptID.toString()
[INFO]:Loading string table
[ERROR]:The shared cache root directory location was not found
[INFO]:getRole() + " RPC up at: " + getNameNodeAddress()
[ERROR]:Store empty file failed. COS key: <*>, exception: <*>.
[INFO]:<*> received stopped but cancellation pending
[INFO]:Applying ask limit of newReq.getNumContainers() for priority:reqLimit.getPriority() and capability:reqLimit.getCapability()
[ERROR]:Error while reading conf file: confPath
[INFO]:rpcClient.invokeConcurrent executed
[INFO]:Scheduler pool size <*>
[DEBUG]:Ignoring re-entrant call to stop()
[DEBUG]:Failed to get groups for user <*>
[ERROR]:Connection retry failed with <*> attempts in <*> seconds
[WARN]:Application failed to init aggregation
[DEBUG]:Cached location of block <*> as <*>, blk, pathinfo
[INFO]:Token file <*> does not exist
[WARN]:Storage directory is in use.
[INFO]:Conflict Resolution mode is <*>
[WARN]:Unable to rename checkpoint in directory
[INFO]:Fail to re-join election.
[INFO]:<*>: upload file count: <*>
[WARN]:<*>: rename failures were recovered from. Number of recoveries: <*>, committerConfig.getName(), recoveries
[DEBUG]:saveSecretManagerSection completed
[INFO]:Registry default system acls: ...
[WARN]:File is not a block filename, skipping.
[INFO]:Breaking hardlink for <*>x-linked block <*>
[DEBUG]:Have read input token of size $<*> for processing by saslServer.unwrap()
[DEBUG]:Queue <*> does not exist, checking parent <*>
[DEBUG]:Fetching job details
[DEBUG]:Found matching rule, subnet: <*>, path: <*>; returned true
[WARN]:No Kerberos keytab specified for service.getName()
[INFO]:"opReadBlock <*> received exception: <*>", block, e
[INFO]:no existing webapp instance found: <*>
[DEBUG]:BlockMovingInfo: <*>
[ERROR]:Unable to enter safemode.
[DEBUG]:Preparing to write atomic rename state to <*>
[WARN]:Failed to delete meta file for replica + replicaToDelete
[INFO]:Action set for property: MAX_CHILD_CAPACITY
[DEBUG]:Getting buffer size
[INFO]:Waiting for application to be successfully unregistered.
[DEBUG]:concat: other chunk: 0: + dstfs.getFileStatus(f)
[INFO]:Current attempt state of + appAttemptId + is + attemptReport.getYarnApplicationAttemptState() + , waiting for current attempt to reach + attemptState
[INFO]:Wait for all parts to finish their uploading.
[ERROR]:Cannot issue delegation tokens because the credential providers listed in $<*> are returning session tokens
[INFO]:Linked blocks from <*> to <*>. <*>
[DEBUG]:Autocloseables closed
[ERROR]:Problem while trying to process JMX query: + qry + with MBean + oname
[INFO]:Resource + rsrc.getLocalPath() + is missing, localizing it again
[INFO]:<*>: uploading from staging directory to S3 <*>
[INFO]:Executing operation action on path
[DEBUG]:Committer option is <*>
[WARN]:Block token verification failed: op=<*>, remoteAddress=<*>, message=<*>
[DEBUG]:removeDefaultAcl filesystem: <*> path: <*>
[WARN]:Incorrect reservation state key <*>
[DEBUG]:plugin <*> returns a non-null value on query <*>
[TRACE]:<*>.getMessage()
[INFO]:Recovered for AMRMProxy: current master key id ...
[INFO]:closing the flow run table
[DEBUG]:RPC client proxy stopped
[DEBUG]:: starting, having connections
[WARN]:DIR* FSDirectory.unprotectedRenameTo: rename destination parent ... not found.
[DEBUG]:<*>: suspect block <*> is already queued for rescanning.
[INFO]:RMAppImpl audit log kill event
[TRACE]:Skipped checking all volumes, time since last check <*> is less than the minimum gap between checks (<*> ms), gap, minDiskCheckGapMs
[DEBUG]:Considering jobs with submit time greater than ... Skipped ... jobs.<*>
[DEBUG]:Adding to cluster node labels in RouterRMAdminService
[WARN]:Unable to delete no-longer-needed data <*>
[DEBUG]:<*> reported decommissioning
[INFO]:Delete ResourceSkyline for recurrenceId: <*>.
[DEBUG]:a metric is reported: cmd: <*> user: <*>
[INFO]:Read in time
[INFO]:Checking script <*>:
[DEBUG]:Looking for Job + jobId
[DEBUG]:Scanning directory for history files
[INFO]:logRpcIds invoked
[INFO]:SliderFileSystem initialized
[INFO]:Unset ec policy <*>
[ERROR]:Dropping <*> from the SerialNumberIndex. We will no longer be able to see jobs that are in that serial index for <*>
[INFO]:Added new volume: volume.getStorageID()
[WARN]:Missing SubCluster Endpoint information. Please try again by specifying SubCluster Endpoint information.
[INFO]:error prefetching block <*>. <*>
[DEBUG]:Closing <*>
[INFO]:Map output collector class = + collector.getClass().getName()
[DEBUG]:Bound at <*> : ServiceRecord = <*>, path, record
[INFO]:Adding replicas to map for block pool on volume ...
[WARN]:Could not get valid GPU device for container 'some_container' as some other containers might not releasing GPUs.
[DEBUG]:set atime: <*> mtime: <*>
[INFO]:Application added - appId: <*> user: <*> leaf-queue of parent: <*> #applications: <*>
[INFO]:Hadoop Version:
[WARN]:CapacityScheduler configuration validation failed:...
[INFO]:Uploading resource <*> from <*> to <*>
[INFO]:Stopping Document Timeline Store reader...
[WARN]:!!! WARNING !!!\n\tThe NameNode currently runs without persistent storage.\n\tAny changes to the file system meta-data may be lost.\n\tRecommended actions:\n\t\t- shutdown and restart NameNode with configured "propertyName" in hdfs-site.xml;\n\t\t- use Backup Node as a persistent and up-to-date storage of the file system meta-data.
[INFO]:keyInfo.getWarningMessage(name, source)
[INFO]:Found nn: +info.getNameNodeID()+, ipc: +info.getIpcAddress()
[INFO]:Hadoop Metrics Updater executor could not be shutdown.
[INFO]:write temp capacity configuration successfully, schedulerConfigFile= + tempSchedulerConfigPath
[ERROR]:Skip recovering container for unknown application.
[INFO]:Successfully moved + this
[DEBUG]:RegexMatcher 'pattern', denying client 'address', 'hostname'
[INFO]:DNS zones:
[INFO]:Loaded timeline store version info
[DEBUG]:Deleting file: <*>
[ERROR]:Unable to load NameNode plugins. Specified list of plugins: conf.get(DFS_NAMENODE_PLUGINS_KEY)
[INFO]:Processing directory file
[ERROR]:Attempting to remove non-existent node
[INFO]:NodeManager information
[INFO]:Timeline service V1 client is enabled
[WARN]:JournalNodeSyncer interrupted
[WARN]:Storagespace quota violation in image for...
[DEBUG]:PrimaryGroup rule: parent rule result: <*>
[INFO]:report corrupt + block + from datanode + srcDataNode + to namenode
[WARN]:MarkedDeleteBlockScrubber encountered an exception during the block deletion process, the deletion of the block will retry in <*> millisecond.
[INFO]:Initialized pluggable runtime
[INFO]:No operation timeline writer used
[INFO]:Upper bound of the thread pool size is + maxThreadPoolSize
[DEBUG]:Failed to reset UGI: <*>
[WARN]:Error reading the stream
[DEBUG]:calling addAnswer
[INFO]:Initialized LogWeService with clusterid " + defaultClusterid + " for URI: " + base
[TRACE]:getNextSubDir(<*>, <*>): picking next subdirectory <*> within <*>
[ERROR]:Time out occurred while close() is waiting for IO request to finish in append for blob : <*> , key
[ERROR]:Failed to get token in SQL secret manager
[INFO]:Begin saveInodes and Snapshots
[INFO]:finalize temp configuration file successfully, finalConfigPath= + finalConfigPath
[INFO]:Compressed input; cannot compute number of records in the split
[DEBUG]:APPLICATION_ATTEMPT_ID: ...
[WARN]:No TGT after renewal. Aborting renew thread for <*>
[INFO]:Application <*> sends out event to clean up its AM container.
[DEBUG]:Requested resource information: + requestedRI
[WARN]:Could not get block locations. Source file \" + src + \" - Aborting... + this
[DEBUG]:The updated fairshare for + getName() + is + getFairShare()
[INFO]:Creating New Delegation Token
[DEBUG]:Lease renewed with RouterRpcServer
[INFO]:Privileged container requested for : <*>
[WARN]:Cleaner thread interrupted, will stop
[DEBUG]:Using stream seek algorithm <*>
[WARN]:AM vcore not specified, use <*> mb as AM vcores
[DEBUG]:Processing status
[INFO]:<*> Starting thread to transfer <*> to <*>
[WARN]:Failed to get current user, <*>
[INFO]:Indeterminate response from trying to kill service. Verifying whether it is running using nc...
[INFO]:Modifying permissions to ...
[DEBUG]:Storage policy satisfier service is running outside namenode, ignoring
[INFO]:ResourceBase = <*>
[INFO]:Instantiated application attempt report
[WARN]:Couldn't delete checkpoint: ... Ignoring.
[ERROR]:Unable to get service state for <*>
[DEBUG]:healthy streamer count= ...
[DEBUG]:Print usage for -shutdownDatanode
[INFO]:this + beginning handshake with NN
[DEBUG]:doGetGroups(<*>) returned <*>,user,groups
[ERROR]:Interrupted while running disk check, e
[INFO]:Triggering log roll on remote NameNode
[DEBUG]:Deferred uncaching of <*> completed. usedBytes = <*>
[INFO]:Using FPGA vendor plugin: + vendorPluginClass
[INFO]:Directory: <*> already exists.
[INFO]:Allocation done
[INFO]:CGroupsResourceCalculator currently is supported only on Linux.
[INFO]:Storage policy satisfier is already disabled, mode:<*> so ignoring change mode event.
[INFO]:Recovering Transition Read
[WARN]:Out of Memory in server select
[DEBUG]:Shutting down connection pool \"connectionPoolIdPlaceholder\" used timeSinceLastActivePlaceholder seconds ago
[INFO]:nodes are empty for write pipeline of + block
[INFO]:Fetching block byte range
[ERROR]:REDIRECT: sending redirect to redirect
[DEBUG]:Fallback to getPathStatus REST call as provided filestatus is not of type VersionedFileStatus
[DEBUG]:Step : <*>
[DEBUG]:Saving a subsection for <*>
[INFO]:excluded nodes = <*>
[INFO]:'QueueName' Queue Status: Queue State: ..., Minimum Queue Memory Capacity: ..., Maximum Queue Memory Capacity: ..., Number of Nodes: ..., Used Node Capacity: ..., Available Node Capacity: ..., Total Node Capacity: ..., Number of Node Containers: ...
[WARN]:Schema creation finished with the following exceptions
[WARN]:Total Nodes in scope : <*> are less than Available Nodes : <*>
[DEBUG]:RpcKind = rpcKind Protocol Name = protocolName version = version ProtocolImpl = protocolImpl.getClass().getName() protocolClass = protocolClass.getName()
[INFO]:Waiting for Client to exit loop
[INFO]:Application attempt <*> is not runnable, parallel limit reached
[DEBUG]:Copy source key: <*> to dest key: <*>.
[DEBUG]:Cannot add more than <*> connections to <*>
[ERROR]:Cannot serialize field <*> into JSON
[WARN]:Unexpectedly short length on <*>.
[INFO]:Merging X segments, Y bytes from memory into reduce
[WARN]:Unknown host name: <*>. Retrying to resolve the host name...
[INFO]:Processing item
[INFO]:Container is localizing: ...
[ERROR]:Invalid resource addition of null resource for + rmNode.getNodeAddress()
[DEBUG]:Creating FSNamesystem
[DEBUG]:Loading completed resource from <*>
[INFO]:Registered service under <*>; absolute path <*>
[DEBUG]:NFS FSINFO fileHandle: <*> client: <*>
[DEBUG]:listLocatedStatus(<*>, <*>)
[DEBUG]:Container <*> completed with exit code <*>, containerId, exitCode
[DEBUG]:copying <*> <*>
[DEBUG]:Another Diskbalancer instance is running ? - Target Directory already exists. <*>
[DEBUG]:HttpRequestFailure: <*>, <*>
[ERROR]:Native output collector doesn't support this key, this key is not comparable in native
[DEBUG]:Recovering container
[ERROR]:Authorization failed due to YarnException
[WARN]:Parsing job history file with partial data encoded into name: <*>
[INFO]:Service <*> is already in a terminated state <*>
[INFO]:RESERVATION SUCCESSFULLY SUBMITTED <*>
[WARN]:-file option is deprecated, please use generic option -files instead.
[DEBUG]:Connected to HistoryServer at: serviceAddr
[ERROR]:FSImageFormatPBINode#serializeINodeDirectorySection: Dangling child pointer found. Missing INode in inodeMap: id=; path=; parent=
[DEBUG]:Not found:
[INFO]:rollingUpgrade UNKNOWN_ACTION
[WARN]:Waiting to remove MOVE_FAILED state histories (e.g. firstMoveFailedKey) from JobListCache because it is not in done yet. Total count is moveFailedCount.
[DEBUG]:Headroom calculation for user <*>: userLimit=<*> queueMaxAvailRes=<*> consumed=<*> partition=<*>
[DEBUG]:Audit: setPermission successful for src
[ERROR]:Application <*> with appId <*> failed to be submitted.
[DEBUG]:Appending block size info
[DEBUG]:got
[INFO]:logUpdateMasterKey started
[DEBUG]:Completing multipart upload <*> with <*> parts
[WARN]:Failed to read topology table. DEFAULT_RACK will be used for all nodes.
[DEBUG]:KeyStore loaded successfully !!
[WARN]:Exception while stopping monitor= + mon.getName(), e
[DEBUG]:Not cleanup up pending uploads to <*> as <*> is false
[DEBUG]:Initializing services
[INFO]:Container started successfully
[INFO]:Application ' + applicationId + ' is submitted without priority hence considering default queue/cluster priority: + appPriority.getPriority()
[WARN]:<*>
[ERROR]:Edits cache is out of sync; looked for next txn id at %d but got start txn id for cache put request at %d. Reinitializing at new request.
[ERROR]:Failed to read token storage file
[INFO]:Retrieved trimmed value for namenode id
[ERROR]:Found ResourceRequest for a non-existent node/rack named + resourceName
[INFO]:Going to activate master-key with key-id keyid in activationDelay ms
[DEBUG]:executing <*>, untarCommand
[DEBUG]:createFilesystem for filesystem: <*>
[ERROR]:Exception thrown when store retrieves key: <*>, exception: <*>
[INFO]:Too far behind rm response id: + lastNodeHeartbeatResponse.getResponseId() + nm response id: + remoteNodeStatus.getResponseId()
[WARN]:reloadThread fails to join.
[INFO]:"No application attempt found for " + app.appReport.getApplicationId() + ". Use a placeholder for its latest attempt id. "
[WARN]:Unable to unlock bad storage directory: <*>
[WARN]:Logger warning with msg and throwable
[INFO]:Input Data Compression Ratio : <*>
[INFO]:Getting localization status for <*>
[WARN]:After resync, the position, <*> is not greater than the previous position <*>. Skipping remainder of this log.
[DEBUG]:Using thread pool for <*> operation with threads <*>, operation, threadCount
[DEBUG]:getName(): operation stack trace
[ERROR]:Invalid deduction of null resource for + rmNode.getNodeAddress()
[ERROR]:shuffleError: <*> from task: <*>
[WARN]:Error while closing serviceClient for user <*>
[INFO]:Current thread: <*>, COS key: <*>, upload id: <*>, part num: <*>, exception: <*>
[INFO]:Killed during application recovery
[INFO]:File + actualPath.getName() + was uploaded to the shared cache at + finalPath
[DEBUG]:got # + callId
[DEBUG]:Checking if dfsUsage is an instance of CachingGetSpaceUsed
[INFO]:File scanner interrupted
[INFO]:Top limit input is not numeric, using default top value %d.
[DEBUG]:Got host: <*> path: <*> â†’
[DEBUG]:Add replication task from source <*> to target <*> for EC block <*>
[INFO]:Maximum error count exceeded. Error count: <*> Max error:<*>
[INFO]:Executing re-encrypt commands on zone <*>. Current zones:<*>
[WARN]:Exception while scanning file inodes to satisfy the policy
[INFO]:System ACLs <*>
[INFO]:Log output complete
[WARN]:Couldnâ€™t delete State Store record <*>: <*>
[WARN]:Exception running disk checks against volume + reference.getVolume(), exception
[INFO]:NameNode container stopped: <*>
[ERROR]:Trying to updateHistory <*> with empty resource skyline
[ERROR]:Not creating intermediate history logDir: [... based on conf
[INFO]:Serialized logMutation
[DEBUG]:getting serverKey: ...
[INFO]:LoadBalancingKMSClientProvider Decryption successful
[INFO]:waiting for finish
[INFO]:JSON response created with location
[INFO]:Report a new collector for application: + appId + to the NM Collector Service.
[DEBUG]:<*> reported usable
[DEBUG]:Skipped checking <*>. Time since last check <*>ms is less than the min gap <*>ms., target, msSinceLastCheck, minMsBetweenChecks
[DEBUG]:BLOCK* NameSystem.abandonBlock: <*> of file <*>
[DEBUG]:Setting key <*> to <*>
[INFO]:Json Generation Exception
[INFO]:History file is at <*>
[DEBUG]:Tailing edits starting from txn ID ... via RPC mechanism
[DEBUG]:Log audit event: successful operation addCachePool
[INFO]:Iterating through items
[WARN]:Failed to recover block (block=<*>, datanode=<*>)
[INFO]:Processed URL but app not found (Took x ms.)
[ERROR]:UNKOWN_FAIL_ERROR_MSG, methodName
[ERROR]:Trying to get state of an absent application
[INFO]:Number of paths in the copy list: + this.getNumberOfPaths()
[DEBUG]:detail
[DEBUG]:Endpoint <*> is not the default; parsing
[ERROR]:Statestore update failed for move application ' + app.getApplicationId() + ' to queue ' + queue + ' with below exception: + ex.getMessage()
[WARN]:Etag of dest file <*>: <*> does not match that of manifest entry <*>
[INFO]:Get timeline collector context for + appId
[WARN]:Closing output stream statistics while data is still marked as pending upload in <*>
[INFO]:Manifest file + manifest + doesn't exist, stopping + auxiliary services
[DEBUG]:Local filesystem path determined
[DEBUG]:Delete path <*> - recursive <*>
[ERROR]:Failed to create NodeLabelsProvider based on Configuration, e
[WARN]:Failed to open rolling leveldb instance :<*>
[INFO]:<*> clearing ip and host
[ERROR]:Error in creating hbase tables:
[WARN]:Caught exception :
[DEBUG]:Failed to delete cache file <*>
[DEBUG]:<*>: wait for <*> milliseconds
[WARN]:Block + b + unfinalized and removed.
[INFO]:This is an earlier submitted application: <*>
[INFO]:session.getRemoteAddress().getHostString() connected!
[WARN]:createFailureLog(user, operation, perm, target, description)
[DEBUG]:Deleting entity type:<*> id:<*> from invisible reverse related entity entry of type:<*> id:<*>
[INFO]:Service ' + serviceName + ' doesn't exist at ZK path: + zkPath
[DEBUG]:Writing file: <*>
[WARN]:Unresolved nodemanager registration: hostname cannot be resolved
[DEBUG]:Begin parsing summary logs.
[DEBUG]:Considering jobs with submit time greater than <*> ms. Skipped <*> jobs.
[INFO]:addSymlink: failed to add <*>
[WARN]:Failed to retrieve major/minor number for device
[DEBUG]:Closing an already closed stream. <*>
[DEBUG]:reopen(<*>) for <*> range<*>, length=<*>, streamPosition=<*>, nextReadPosition=<*>, policy=<*>
[WARN]:Received non-NN/JN request for edits from <*>
[DEBUG]:Ignoring negative increment value <*> for counter <*>
[DEBUG]:<*> is not a desired ApplicationEvent which needs to be published by NMTimelinePublisher, event.getType()
[DEBUG]:Application's information created
[INFO]:Adding protocol + pbProtocol.getCanonicalName() + to the server
[INFO]:Service (appName)'s lifeTime is updated to newLifeTime, updateAppData.getLifetime() seconds remaining
[DEBUG]:userLimit is fetched. userLimit=<*>, userSpecificUserLimit=<*>, schedulingMode=<*>, partition=<*>
[INFO]:Upgrading storage directory <*>. old LV = <*>; old CTime = <*>. new LV = <*>; new CTime = <*>
[INFO]:Server status = <*>
[WARN]:Exception when sending signal to container y: e
[ERROR]:Already have a scanner for volume <*>.
[DEBUG]:Removed cache pool
[WARN]:Unknown HealthCheckerExitStatus - ignored.
[INFO]:MapFile writer created
[INFO]:Operation category checked
[WARN]:Failed to cache + key + : checksum verification failed.
[WARN]:Recovering old formatted token
[DEBUG]:End step SAVING_CHECKPOINT
[INFO]:Re-encryption was canceled.
[DEBUG]:Application <*> is registered for timeout monitor, type=<*> remaining timeout=<*> seconds
[INFO]:Thread.currentThread().getName() unexpectedly interrupted
[WARN]:<*>: Failed to write manifest for task <*>
[ERROR]:Can't handle this event at current state
[WARN]:Cannot locate configuration: tried <*>
[ERROR]:Exception while stopping httpserver
[WARN]:Checksum error in block + block + from + inAddr + , + specificOffset, ce
[ERROR]:Exception in retrieving block pool id <*>
[TRACE]:Failed to place enough replicas, still in need of...
[INFO]:AM container is null
[DEBUG]:Can't get path for fileId: <*>
[TRACE]:Exiting getCurrentVersion method.
[DEBUG]:User entry: "<*>"
[DEBUG]:DRConf - setOverCommitTimeoutPerNode: nodePrefix=<*>, overCommitTimeout=<*>
[WARN]:Got unexpected exception trying to acquire lease on key.<*>
[DEBUG]:stat failed on <*>: moved? <*>
[ERROR]:Couldn't delete data file for leveldb timeline store
[DEBUG]:Error when publishing entity
[INFO]:Container <*> not running, nothing to signal.
[INFO]:Task being rescheduled
[INFO]:<*> offset <*> len <*>
[DEBUG]:getECTopologyResultForPolicies
[DEBUG]:Call: methodName callTime
[DEBUG]:Try to parse summary log for log <*> in <*>
[ERROR]:Got error reading edit log input stream...
[DEBUG]:Sending signal to pid a as user b for container y
[INFO]:Initialized queue mappings, override: (value of overrideWithQueueMappings)
[ERROR]:Too many connection failures, would not try to connect again.
[INFO]:bufstart= + bufstart + ; bufend= + bufmark + ; bufvoid= + bufvoid
[INFO]:Using war file at: /path/to/war/file
[INFO]:Total num containers requested
[INFO]:Number of tracked deleted directories <*>
[DEBUG]:Reinstating vectored read operation for path <*>, pathStr
[DEBUG]:Can't create a new BR lease for DN <*>, because numPending equals maxPending at <*>. Current leases: <*>
[DEBUG]:Application is registered for timeout monitor
[INFO]:Processing returned re-encryption task for zone <*>(<*>,), batch size <*>, start:<*>
[ERROR]:Error when writing command to temp file, command=<*>
[DEBUG]:Work file for <*> extension '<*>' is <*>
[INFO]:Processing + numResources + resources in the shared cache
[ERROR]:App: + appID + can't handle this event at current state
[INFO]:Sending stop Signal to Client
[DEBUG]:Failed to getReplicaVisibleLength from datanode <*> for block <*>
[INFO]:Rolling forward previously half-completed synchronization: + tmp + -> + dst + ; journal id: + journalId
[INFO]:Record not found in registry for container <*> from previous attempt, releasing
[INFO]:Loaded state DB schema version info
[INFO]:Merging N sorted segments
[DEBUG]:org.apache.hadoop.yarn.webapp.Controller: renderJSON called with $<*>
[INFO]:Submit a new application <*>
[INFO]:attemptId + TaskAttempt Transitioned from + oldState + to + getInternalState()
[DEBUG]:Current time is <*>, next refresh is <*>
[DEBUG]:Checking and enabling app aggregators
[DEBUG]:finalize() called
[INFO]:Executing logEdit
[INFO]:Executing operation with tracing
[DEBUG]:Filesystem <*> doesn't support XAttr API
[INFO]:JOB_CREATE + event.getJobID()
[INFO]:OutputCommitter is <*>
[DEBUG]:Time taken to get FileStatuses: <*>
[DEBUG]:DIR* FSDirectory.addBlock: <*> with <*> block is added to the in-memory file system
[WARN]:logWarningWhenAuxServiceThrowExceptions during CONTAINER_INIT
[WARN]:Aggregation stop interrupted!
[DEBUG]:MXBean registered and service initialized
[WARN]:Failed to delete temporary file <*>
[DEBUG]:Caught exception was: ...
[DEBUG]:Base URI added
[DEBUG]:ResourceManager initialized with conf
[INFO]:Storage policy satisfier is disabled
[INFO]:Instance was null for decommissioned instance <*>
[DEBUG]:MOUNT UMNTALL : client: + client
[ERROR]:Failed to refresh maximum allocation
[ERROR]:Mismatched cluster! The other RM seems to be from a different cluster. Current cluster = clusterId Other RM's cluster = proto.getClusterId()
[DEBUG]:DIR* addFile: <*> is added
[DEBUG]:UGI Information: <*>
[INFO]:Node already renewed by peer <*> so this token should not be deleted
[DEBUG]:stage=<*>, <*>
[WARN]:The container will run without the java security manager due to an unsupported container command. The command will be permitted to run in Sandbox permissive mode: command
[INFO]:Loading rack into resolver: rackName --> subClusterId
[ERROR]:Could not stop Delegation Token Cache
[INFO]:No top limit specified, using default top value %d.
[DEBUG]:Loading token from + key
[WARN]:Could not update cgroup for container, re
[INFO]:Max number of completed apps kept in state store met: maxCompletedAppsInStateStore = <*>, removing app <*> from state store.
[TRACE]:Unsafe comparer selected for byte unaligned system architecture
[INFO]:Edit logging is async: true/false
[DEBUG]:Path <*> is not a prefix of the path <*>
[INFO]:Block analysis status:<*> for the file id:<*>. So, Cleaning up the Xattrs.
[WARN]:Failed to resolve address `%s` in `%s`. Ignoring in the %s list.
[DEBUG]:NameSystem.concat to <*>
[WARN]:Failed to delete block file for replica + replicaToDelete
[INFO]:This is standby RM. The redirect url is: ...
[DEBUG]:Cancelling delegation token <*> with url:<*>, as:<*>
[INFO]:Copied from: fromPath to done location: toPath
[INFO]:Write lock released
[INFO]:Update NODE_ID DecommissioningTimeout to be TIMEOUT_PLACEHOLDER
[WARN]:No file for job-history with jobId found in cache!
[DEBUG]:Trigger the write back task. Current nextOffset: <*>
[WARN]:Failed to mkdirs + targetDir
[ERROR]:Error when putting the timeline domain
[DEBUG]:Loading and committing files in pendingset %s
[DEBUG]:No node to choose.
[DEBUG]:Begin step SAVING_CHECKPOINT
[DEBUG]:getEntities type=<*> primary=<*>
[INFO]:Jetty bound to port
[INFO]:Edit operation logged
[TRACE]:<*>: trying to create a remote block reader from the UNIX domain socket at <*>
[INFO]:Initializing the GreedyReservationAgent to favor "late" (right) allocations (controlled by parameter: FAVOR_EARLY_ALLOCATION)
[WARN]:Cannot demote/decrease non-existent (or completed) Container <*>
[DEBUG]:<*>: finishing cache cleaner run started at <*>. Demoted <*> mmapped replicas; purged <*> replicas.
[INFO]:<*>: need upgrade to <*>
[INFO]:Got response from RM for container ask, completedCnt= <*>
[DEBUG]:AAD Token is missing or expired: Calling refresh-token from abstract base class
[ERROR]:This shouldn't happen, cannot get host in nodeCollection associated to the node being activated
[TRACE]:<*>: msync('<*>'), getName(), path
[ERROR]:Cannot locate RPC service address for NN <*>, using RPC address <*>
[DEBUG]:There is no pending items to satisfy the given path inodeId:<*>
[INFO]:
[DEBUG]:Finding a token for FS user
[INFO]:Timeline domains are successfully put
[ERROR]:Unsupported protocol for connection to NameNode: null
[INFO]:Got node report from ASM
[INFO]:Pausing the container <*>
[INFO]:Cookie couldnâ€™t be found: <*>, do listing from beginning
[WARN]:Unable to move edits file from <*> to <*> ; journal id: <*>
[DEBUG]:Write lock released
[DEBUG]:Failed to create raw erasure encoder <*>, fallback to next codec if possible
[WARN]:Duplicate device found:
[INFO]:Successfully updateHistory resource skylines for <*>.
[INFO]:Task attempt will be recovered as KILLED
[DEBUG]:BLOCK* block <*>: <*> is received from <*>
[DEBUG]:Broker list <*>
[INFO]:Configuration file being loaded: + CONFIG_FILE + . Found in classpath at + MawoConfiguration.class.getClassLoader().getResource(CONFIG_FILE)
[DEBUG]:IndexCache HIT: MapId + mapId + found
[ERROR]:Error closing writer for JobID: + jobId
[WARN]:DIR* FSDirRenameOp.unprotectedRenameTo: failed to rename srcIIP.getPath() to dstIIP.getPath() because the source can not be removed
[INFO]:OUTCOME: SUCCESS, Reservation ID: reservationId.toString(), Contract: contract.toString()
[ERROR]:Failed to start secondary namenode
[DEBUG]:Setting non NULL Credentials for Store connection
[WARN]:Could not store container <*> state. The Container has been queued.
[INFO]:adminAclList not set, hence setting it to ""
[DEBUG]:executing a request outside an audit span ...
[ERROR]:Attempt to remove absent resource: rem.getRequest() from getUser()
[INFO]:This csi-adaptor is configured to contact with the csi-driver <*> via gRPC endpoint: <*>, driverName, driverEndpoint
[INFO]:nodeId + Node Transitioned from + oldState + to + getState()
[WARN]:IOException occurred for block <*>!
[INFO]:Skipping satisfy storage policy on path:<*> as this file doesn't have any blocks!
[ERROR]:Exception thrown while removing dead appIds.
[INFO]:Login user acquired
[WARN]:Lock monitoring failed because session was lost
[INFO]:Already in active state
[INFO]:Instance created
[INFO]:Relaunching container with updated retry context
[DEBUG]:Creating key with name <*>, cipher being used<*>, length of key <*>, description of key <*>
[DEBUG]:header: mapId, len: compressedLength, decomp len: decompressedLength
[INFO]:Skip killing + rmContainer.getContainerId()
[INFO]:Image has not changed. Will not download image.
[ERROR]:Cannot delete non-empty directory without recursive flag
[DEBUG]:return byte<*>
[DEBUG]:OOM resolved successfully
[INFO]:Getting list of all Jobs.
[INFO]:couldn't find application + appID + while processing + FINISH_APPS event. The ResourceManager allocated resources + for this application to the NodeManager but no active + containers were found to process.
[WARN]:Rename failed. Perhaps data already moved. Verifying...
[INFO]:Uploaded image with txid 123 to namenode at http://example.com in 0.5 seconds
[INFO]:Add labels: <*>
[DEBUG]:loadIndexedLogsMeta
[ERROR]:Fsck: error deleting corrupted file
[ERROR]:Unable to locate dependency task for deletion task
[INFO]:Wiping tc state.
[ERROR]:Close the random access file occurs an exception.
[WARN]:Get error accessing file, fileId: <*>
[INFO]:Node <*> reported DECOMMISSIONED
[INFO]:task.commitAttempt + already given a go for committing the task output, so killing + attemptID
[ERROR]:Failed to render tasks page with task type : $(TASK_TYPE) for job id : $(JOB_ID)
[DEBUG]:Closing cache
[DEBUG]:Using credential provider <*>
[ERROR]:Exception while deserializing scheduler configuration from store
[INFO]:Initializing Constraint Placement Processor:
[DEBUG]:Creating non-HA Proxy
[DEBUG]:The node <*> does not have enough <*> space (required=<*>, scheduled=<*>, remaining=<*>).
[DEBUG]:Updating reservation: <*> in plan:<*> at: <*>
[INFO]:Log sync completed for non-HA setup <*> Rolling upgrade finalized audit event logged
[DEBUG]:SASL client skipping handshake in secured configuration with unsecured cluster for addr = <*>, datanodeId = <*>
[INFO]:No pending uploads were found
[DEBUG]:Setting connection close header...
[INFO]:<*>: scaling up from <*> to <*>
[DEBUG]:Loading service provider type <*>
[INFO]:e.getMessage()
[WARN]:Throwable: Failed to instantiate default resource calculator.
[ERROR]:Error occurred while aggregating the log for the application
[INFO]:Shutdown complete.
[DEBUG]:Job %s setting up
[ERROR]:Get service failed: <*>
[ERROR]:Fetching filestatuses failed
[INFO]:Operation check performed
[INFO]:Skipped app activity without allocation
[INFO]:Cancel moving + this + as iteration is already cancelled due to + dfs.balancer.max-iteration-time is passed.
[ERROR]:Exception thrown while running DiskBalancerCLI.
[WARN]:Failed to move meta file from + metaFile + to + targetMetaFile, e
[DEBUG]:Best effort placement failed: expecting <*> replicas, only chose <*>.
[WARN]:DistCpConstants.CONF_LABEL_MAX_CHUNKS_IDEAL + should be positive. Fall back to default value: + DistCpConstants.MAX_CHUNKS_IDEAL_DEFAULT
[INFO]:Set total cache pools
[INFO]:Can't get path for dir fileId: <*>
[DEBUG]:Application <*> sends out event to clean up its AM container.
[INFO]:Launching shell command on a new container, containerId=yarnContainerId, yarnShellId=yarnShellId, containerNode=nodeHost:nodePort, containerNodeURI=nodeHttpAddress, containerResourceMemory=memorySize, containerResourceVirtualCores=virtualCores
[DEBUG]:Start file with no key
[INFO]:done stopping Client
[DEBUG]:Try timeline store <*>:<*> for the request
[INFO]:Audit event logged
[DEBUG]:<*> is disabled. Try enabling it first to capture slow peer outliers.
[WARN]:<*>: Failed <*> times, exceeded the limit - <*>. Shutting down now...
[INFO]:Value deserialized
[INFO]:launchContainer: <*>
[DEBUG]:<*> blocks are now pending replication
[WARN]:Failed to cache block with id + blockId + , pool + bpid + : volume not found.
[INFO]:BLOCK* allocate ... for ...
[INFO]:Launching new container
[INFO]:Purging logs older than + minTxIdToKeep
[INFO]:Number of failed storages changes from <*> to <*>
[ERROR]:Failed to get tail of the container's prelaunch error log file
[INFO]:Got exception while resuming container: <*>
[INFO]:FSRename operation executed
[DEBUG]:Operation failed
[INFO]:Target file system not specified. Using default <*>
[WARN]:Inconsistent number of corrupt replicas for <*> + blockMap has <*> but corrupt replicas map has <*>, blk, numCorruptNodes, numCorruptReplicas
[INFO]:No nodes found to update, configuration is up-to-date
[INFO]:Stopping resourceestimator service at: <*>., baseURI.toString()
[INFO]:Reservation created successfully
[WARN]:Failed to register MBean \ + name + \, e
[ERROR]:Failed to start the TCP server.
[DEBUG]:storeContainerKilled: containerId=<*>
[INFO]:Next operation retrieved from backup input stream
[INFO]:Deleting original logs
[DEBUG]:Ldap group query string: + filter.toString()
[INFO]:getLoginUser called
[INFO]:Block: <*>, Expected Replicas: <*>, live replicas: <*>, corrupt replicas: <*>, decommissioned replicas: <*>, decommissioning replicas: <*>, maintenance replicas: <*>, live entering maintenance replicas: <*>, replicas on stale nodes: <*>, readonly replicas: <*>, excess replicas: <*>, Is Open File: <*>, Datanodes having this block: <*>, Current Datanode: <*>, Is current datanode decommissioning: <*>, Is current datanode entering maintenance: <*>
[DEBUG]:No blacklist for <*>
[ERROR]:Thread got interrupted: <*>
[DEBUG]:Seeker initiated
[INFO]:Signaled container init for app: <*>
[INFO]:Failed components: <*>
[DEBUG]:Cannot load customized ssl related configuration. Fallback to system-generic settings.
[WARN]:Error converting old JobDefinition format
[INFO]:Timeline v2 is enabled.
[INFO]:<*>: + event.getDesired() + instances.
[DEBUG]:DataTransferProtocol not using SaslPropertiesResolver, no QOP found in configuration for <*>
[INFO]:Search binary..
[DEBUG]:Reading success data from <*>
[DEBUG]:Source path and dest path refer to the same file or directory: <*>
[WARN]:AMRMToken not found in the application report for application: <*>
[DEBUG]:Received handleLifeline from nodeReg = + nodeReg
[DEBUG]:Initializing SSL Context to channel mode Default_JSSE_with_GCM
[WARN]:AttemptInfo is null for TaskAttemptUnsuccessfulCompletionEvent taskAttemptId: <*>
[DEBUG]:Stream closed
[INFO]:Processing <*> messages from DataNodes that were previously queued during standby state
[ERROR]:Application <*> does not exist
[TRACE]:openFileMap size:
[WARN]:Reserved storage <*> reported as non-provided from <*>
[TRACE]:Entering getKeyVersions method.
[DEBUG]:Error reading the contents of <*>, IOException logged
[INFO]:Saved output of task '<*>' to <*>
[DEBUG]:BLOCK NameSystem.addToCorruptReplicasMap: <*> added as corrupt on <*> by <*>
[INFO]:Exception while closing file <*>
[INFO]:Stopping MarkedDeleteBlockScrubber.
[INFO]:Re-encryption zone marked as completed
[INFO]:Provided storage transitioning to state State.NORMAL
[INFO]:Initializing <*>
[DEBUG]:Queue is already de-activated. Skipping de-activation : <*>
[DEBUG]:startJobs: parent= + path + child= + oldJobIDString
[INFO]:Scanned <*> INode directories to build namespace.
[ERROR]:Statistics io exception while polling JT
[WARN]:Some warning message
[INFO]:Updating lastPromisedEpoch from <*> to <*> for client <*> ; journal id: <*>
[INFO]:Verified that the service is down.
[ERROR]:Unable to get Local hostname and ip for <*>
[DEBUG]:Assigned container (allocated) to task assigned.attemptID on node allocated.getNodeId().toString()
[INFO]:Removing block pool + bpid
[DEBUG]:Acquiring write lock
[INFO]:Added filter (name) (class=classname) to context webAppContext.getDisplayName()
[DEBUG]:<*> is not a desired ContainerEvent which needs to be published by NMTimelinePublisher, event.getType()
[INFO]:TaskAttempt <*>: lastStatusRef changed by another thread, retrying...
[DEBUG]:Task attempt added
[WARN]:Exception closing executor service <*>
[INFO]:There is no available memory: + resource.getMemorySize() + in numa nodes for + containerId
[WARN]:Error while checking local directories: , t
[INFO]:Transitioning to active state
[INFO]:Journal created
[INFO]:STATE* Leaving safe mode after <*> secs
[DEBUG]:writeBlock receive buf size <*> tcp no delay <*>
[DEBUG]:Method <*> found in class <*>
[INFO]:Preserve original total capability: CAPABILITY_PLACEHOLDER
[INFO]:Handling application container finished event
[ERROR]:Interrupted
[INFO]:RMRegistration Success message
[INFO]:Container Log Monitor Enabled: <*>
[INFO]:Error during set operation type
[INFO]:Service + service.getName() + changed state: + service.getServiceState()
[WARN]:StorageLocation <*> detected as failed.
[INFO]:Services destroyed
[ERROR]:Failed to acquire lock on <*>. If this storage directory is mounted via NFS, ensure that the appropriate nfs lock services are running.
[ERROR]:Class instantiation error: <*>
[DEBUG]:setFilesystemProperties for filesystem: <*> path: <*> with properties: <*>
[DEBUG]:Accessing pid for container <*> from pid file <*>
[INFO]:Signal to container successful
[DEBUG]:Unexpected state filter for inactive RM node
[INFO]:RM rolled master-key for amrm-tokens
[INFO]:Setting block keys
[ERROR]:Fast fail the job because the cluster storage capacity was exceeded.
[ERROR]:Invalid node label <*> on configured leaf template on parent queue <*>
[INFO]:Removing state store due to decommission
[INFO]:Found <*> existing UAMs for application <*> in Yarn Registry
[DEBUG]:NFS MKDIR dirHandle: <*> filename: <*> client: <*>
[DEBUG]:refCount= + refCount
[DEBUG]:Waiting scan completion
[INFO]:Relaunch container with workDir = ..., logDir = ..., nmPrivateContainerScriptPath = ..., nmPrivateTokensPath = ..., pidFilePath = ...
[INFO]:Resolved OOM in X ms
[ERROR]:Error running ApplicationMaster, t
[INFO]:Updating info for app: + appId
[INFO]:Setting event type: LAUNCHED_EVENT_TYPE
[INFO]:No nodes currently available to allocate OPPORTUNISTIC containers.
[DEBUG]:Running plan follower edit policy for plan: <*>
[INFO]:Previous history file is at ...
[DEBUG]:Storing info for attempt: <*>
[INFO]:<*> is set to <*>
[INFO]:Service <*> is at <*> state
[TRACE]:<*>: <*> no-checksum anchor to slot <*>
[DEBUG]:Registering the metrics source
[DEBUG]:User error, retrying without 100 continue enabled for the given path <*>
[INFO]:You can either use the CLI tool: 'mapred job -history' to view large jobs or adjust the property <*>.
[ERROR]:Error freeing leases
[DEBUG]:<*> waiting for ack for: <*>
[WARN]:Gridmix will not emulate Distributed Cache load because creation of pseudo local file system failed.
[INFO]:Successfully destroyed service <*>
[WARN]:Failed attempt to delete cgroup: + cgf
[INFO]:Audit failed: renameSnapshot
[INFO]:Copying <*> to <*>
[ERROR]:Error while syncing
[ERROR]:Probe failed, datanode: <*>, type: <*>., datanodeInfo, type, e
[ERROR]:No filesystem specified in either fs or target.
[INFO]:Not able to copy block ... because threads quota exceeded
[INFO]:Application cache size is <*>
[TRACE]:<*>: No ReplicaAccessor created by <*>
[TRACE]:<*> is not stale because it's only <*> ms old and staleThresholdMs=<*>
[ERROR]:Error when initializing FileSystemHistoryStorage
[ERROR]:Can't get path for dirHandle: <*>
[DEBUG]:Found ... files
[INFO]:<*> spec state state changed from <*> -> <*>
[WARN]:Failed to fetch application attempts from ATS v2
[TRACE]:First execution of REST operation getTokenSingleCall
[DEBUG]:Submitting <*>
[INFO]:Router RMAdminService listening on address: + this.server.getListenerAddress()
[DEBUG]:Acquired read lock
[DEBUG]:Configuring multithread runner to use + numberOfThreads + threads
[INFO]:Shutting down FederationInterceptor for <*>
[DEBUG]:<*> is in multiple subclusters
[INFO]:logAuditEvent success
[DEBUG]:Removing RMDelegationKey_<*>
[INFO]:Node publish volume request initiated
[WARN]:truncating long string: + s.length() + chars, starting with + s.substring(0, 20)
[INFO]:No encryption info; returning direct stream
[TRACE]:Failed to place enough replicas, still in need of X to reach Y (unavailableStorages=...,storagePolicy=...,newBlock=...) e
[DEBUG]:Checking operation unchecked
[WARN]:Unable to get key for accountName from credential providers. ioe, ioe
[INFO]:Pseudo authentication attempted
[INFO]:logAuditEvent(false, "modifyAclEntries", src)
[DEBUG]:Creating placement context for user <*> using secondary group current user mapping
[DEBUG]:SASL server DIGEST-MD5 callback: setting canonicalized client ID: username
[TRACE]:<*>: created new block iterator for <*>.
[INFO]:Reacquiring <*> with pid <*>
[INFO]:Kill task $<*> received from $<*> at $<*>
[INFO]:<*>: Dependency <*> not satisfied, only <*> of <*> instances are ready or the dependent component has not completed
[ERROR]:Attempt to insert record <*> that already exists
[INFO]:Resource requests recovered for container
[INFO]:No Resource plugins found from configuration!
[INFO]:addCachePool of <*> successful.
[ERROR]:Setting file size is not supported when creating file: <*> + dir fileId: <*>
[INFO]:Call cos sdk failed, retryIndex: <*>, call method: uploadPart, exception: ...
[INFO]:Cannot find matching entity of type ...
[INFO]:cookieName + " cookie has been found and is being processed"
[DEBUG]:New entity type discovered: ...
[ERROR]:Failed to create service <*>
[INFO]:Application just finished : <*>
[WARN]:Configuring <*> flag in <*> is not valid. <*> Bad configuration no queues defined
[ERROR]:Error in RMCallbackHandler: <*>
[INFO]:Storing timeline store version info getCurrentVersion()
[TRACE]:checking for block <*> with storageLocation <*>
[ERROR]:Cannot get Namenodes from the State Store
[INFO]:Application log directory cleaned
[DEBUG]:Using line limit
[INFO]:Log aggregation debug mode enabled. Skipped checking minimum limit.
[TRACE]:Client State ID= <*> and Server State ID= <*>
[INFO]:Finding containerReq for allocated container:
[INFO]:Waiting in main loop.
[DEBUG]:block<*>: closeBlock()
[INFO]:modifyCachePool of <*> successful; set owner to <*>
[ERROR]:File/Directory does not exist: <*>
[WARN]:DatanodeAdminMonitor caught exception when processing node., e
[INFO]:<*> has been successfully deleted. <*>
[INFO]:Existing job initialization finished. + loadedPercent + % of cache is occupied.
[INFO]:Logout successful for user using keytab file
[WARN]:Bad checksum at <*>. Skipping entries.
[INFO]:Assigned container + container.getId() + of capacity + container.getResource() + on host + getRMNode().getNodeAddress() + ", which has " + getNumContainers() + " containers, " + getAllocatedResource() + " used and " + getUnallocatedResource() + " available after allocation
[WARN]:BLOCK* blockReceived: <*> is expected to be removed from an unrecorded node <*>
[WARN]:Abnormal shutdown of UAMPoolManager, still <*> UAMs in map
[DEBUG]:Becoming active for <*>\n
[WARN]:Configuration change validation only supported by MutableConfScheduler.
[DEBUG]:Returning null.
[INFO]:Retry policy created
[DEBUG]:scan for log file: <*>
[WARN]:An exception occurred while getting file information
[DEBUG]:Looking in service filesystems for implementation class
[INFO]:Added node + nodeManager.getNodeAddress() + clusterResource: + clusterResource
[DEBUG]:Missing configuration for fs.viewfs.mounttable.path. Proceeding with core-site.xml mount-table information if available.
[DEBUG]:Saved MD5 digestString to md5File
[INFO]:Retrieved container's allocated resource
[INFO]:Success state store call
[INFO]:ResourceCalculatorPlugin is unavailable on this system. org.apache.hadoop.yarn.server.nodemanager.NodeResourceMonitorImpl is disabled.
[INFO]:Initialized the Default Decommission and Maintenance monitor
[WARN]:<*> must be at least 5 MB; configured value is <*>
[DEBUG]:Logging in
[INFO]:<*>: Committing task \"<*>\"
[WARN]:Failed to cache + key + : failed to open file
[ERROR]:Setting file size is not supported when setattr, fileId: <*>
[WARN]:The block pool <*> is still running, cannot be deleted.
[TRACE]:this : registerSlot slotIdx : allocatedSlots= + allocatedSlots + StringUtils.getStackTrace(Thread.currentThread())
[DEBUG]:Have read input token of size + saslToken.length + for processing by saslServer.evaluateResponse()
[DEBUG]:Creating password for <*> for user <*> to be run on NM <*>
[DEBUG]:Distributed Node Labels is enabled with provider class as : <*>
[WARN]:File <*> for script "<*>" can not be executed.
[DEBUG]:Block <*>: Buffer file <*> exists â€”close upload stream
[DEBUG]:Re-encryption updater throttling expect: <*>, actual: <*>, throttleTimerAll:<*>
[INFO]:Loaded timeline store version info loadedVersion
[INFO]:Built information:
[INFO]:Node Resource monitoring interval is <=0. org.apache.hadoop.yarn.server.nodemanager.NodeResourceMonitorImpl is disabled.
[TRACE]:Exiting rolloverKey Method.
[INFO]:File rename has taken place: recovery <*>
[INFO]:File: <*> is under construction. So, postpone this to the next retry iteration
[DEBUG]:Pending replication tasks: X erasure-coded tasks: Y
[ERROR]:Error in Reader
[INFO]:Set distcp blocksPerChunk to ...
[INFO]:Forwarding registerApplicationMasterForDistributedScheduling request to the real YARN RM
[DEBUG]:Sorry, can't do anything without a JobID.
[DEBUG]:RMAuditLogger log failure for absent application
[WARN]:Log Aggregation is disabled. So is the LogAggregationStatusTracker.
[INFO]:RPC initialized
[WARN]:Start information is missing for application + appId
[DEBUG]:this + ": closing"
[INFO]:Cluster max priority refreshed
[INFO]:Skipping appId due to aggregation status being aggStatus
[INFO]:modifyCachePool of <*> successful; set group to <*>
[DEBUG]:Canceling delegation token <*>
[DEBUG]:Configuration set
[ERROR]:Error decoding se query parameter (<*>) from SAS.
[INFO]:Starting standby checkpoint thread...\nCheckpointing active NN to possible NNs: <*>\nServing checkpoints at <*>, activeNNAddresses, myNNAddress
[DEBUG]:No quantiles <*>
[DEBUG]:startNamenodeReconfiguration
[DEBUG]:Setting non NULL Username for Store connection
[ERROR]:Unable to create proxy to the ResourceManager , <*>
[WARN]:Rename: CopyBlob: StorageException: ServerBusy: Retry complete, will attempt client side copy for page blob
[DEBUG]:HtmlBlock.render called
[DEBUG]:Total time used= + (clock.getTime() - startTs) + ms.
[ERROR]:Error reported on file ... exiting
[WARN]:Failed to cache block with id + blockId + , pool + bpid + : replica is not finalized; it is in state + info.getState()
[DEBUG]:Application <*> has one streamer finished (<*>)
[WARN]:DataNode.handleDiskError on: <*> Keep Running: <*>
[DEBUG]:Failed to get number of blocks
[DEBUG]:All docker volumes in the system, command=<*>, dockerVolumeInspectCommand
[INFO]:Replica state finalized, adding stored block
[ERROR]:Audit failure, incrementing AUDIT_FAILURE counter
[DEBUG]:ResourceManager is not active. Can not <*>
[INFO]:Acknowledging ACTIVE Namenode during handshake
[DEBUG]:Send to scheduler: in app= + appAttemptId + #containers-to-be-preemptionCandidates= + e.getValue().size()
[INFO]:Dead node <*> is decommissioned immediately.
[WARN]:Failure in updating application priority
[INFO]:Found <*> volumes to be published on this node
[INFO]:Listener stopped before starting
[DEBUG]:Audit: setPermission failed due to AccessControlException
[ERROR]:Input validation fails, please specify with valid input parameters.
[INFO]:Number of map tasks determined
[INFO]:Preconditions check for jitter
[INFO]:dfsClient is null
[INFO]:Loading InMemoryAliasMapWriter for block pool id <*>
[INFO]:Ignoring the conversion of placement rules
[WARN]:Cannot unpack <*>
[WARN]:ShutdownHook 'SimpleName' failed, ex.toString(), ex
[INFO]:Shutting down all async lazy persist service threads
[ERROR]:Error when publishing entity <*>, server side error code: errorCode
[INFO]:Successfully loaded & initialized native-zlib library
[DEBUG]:Using existing subject: <*>
[ERROR]:Exception in creating null checksum stream: <*>
[INFO]:close the slow stream
[WARN]:<*><*>
[ERROR]:Failed to delete path
[INFO]:Task timeout must be as least twice as long as the task status report interval. Setting task timeout to <*>
[WARN]:Unrecognized value <*> for property ....
[INFO]:Blacklisted /path/to/jar
[WARN]:Log aggregation is not initialized for + containerId + , did it fail to start?
[DEBUG]:Metrics updated for deactivated node
[WARN]:<*> attempting to access <*> that is invalid, remoteUser, appId
[DEBUG]:Websocket exception: + e.getMessage()
[INFO]:Assigning NUMA node + numaNode.getNodeId() + for memory, + numaNode.getNodeId() + for cpus for the + containerId
[DEBUG]:TempUser:<*>
[INFO]:Updating application attempt with final state
[DEBUG]:Node <*> is excluded, continuing.
[DEBUG]:Time taken to list <*> blobs for delete operation: <*> ms
[TRACE]:Log message related to the deletion process
[DEBUG]:Failed to delete <*>
[INFO]:Secure cluster detected
[DEBUG]:Portmap remove key= + key
[INFO]:Successfully transitioned + target + to standby state without fencing
[DEBUG]:Token kind is and the token's service name is
[ERROR]:Unable to shutdown executor service after timeout <*> <*>
[ERROR]:size of input data to be generated specified using -generate option should be nonnegative.\n
[ERROR]:Cannot get children for <*>
[INFO]:Can't map group <*>. Use its string hashcode: <*>
[INFO]:Waiting for threadgroup to exit, active threads is <*>
[DEBUG]:AzureBlobFileSystem.openFileWithOptions path: <*>
[DEBUG]:Block recovery: Ignored replica with invalid original state: <*> from DataNode: <*>
[ERROR]:Failing commit by job <*> to write to existing output path <*>
[INFO]:Initialized App Name queue mappings, override: <*>
[INFO]:Processed URL
[INFO]:RMCommunicator notified that shouldUnregistered is: true/false
[DEBUG]:Service initialization with configuration.
[DEBUG]:Loaded RMDelegationTokenIdentifier: <*> renewDate=<*>
[DEBUG]:Closing stream <*>: <*>
[DEBUG]:ZooKeeper config:\n
[INFO]:Reading minimum sources...
[INFO]:Requests sent to resource managers for new sub-clusters
[INFO]:Added export: exportPath FileSystem URI: exportPath with namenodeId: namenodeId
[DEBUG]:Copy list entry idx: lastFileStatus.getPath().toUri().getPath()
[INFO]:startFile: recover + lease + , src= + src + client + clientName
[DEBUG]:Getting Configuration VMem PMem Ratio
[DEBUG]:Block <*>: can't cache this block, because it is not yet + complete.
[INFO]:AdminService: updateNodeResource successful
[INFO]:Issuing SQL request <*>
[INFO]:f + " " + srcNode + "->" + dstNode + ": Failed to repair"
[INFO]:<*> failures on node <*>
[INFO]:Adding + container.getContainerId() + to application + app.toString()
[INFO]:Connection from <*> for protocol <*> is unauthorized for user <*>
[DEBUG]:Adding resource type - name = MEMORY, units = ResourceInformation.MEMORY_MB.getUnits(), type = ResourceTypes.COUNTABLE
[WARN]:ex.getMessage(), ex
[DEBUG]:Start Opportunistic Containers
[ERROR]:CRC32C creation failed, switching to PureJavaCrc32C
[DEBUG]:Header origin is null. Returning
[DEBUG]:Searching for KMS delegation token in user <*>'s credentials
[INFO]:Read block from sender
[ERROR]:Error when creating symlink link -> rsrcEvent.getLocation()
[DEBUG]:<*> Skipping disk from computation. Minimum data size achieved., highVolume.getPath()
[INFO]:<*> Lifeline RPC address: <*>
[INFO]:Current attempt state of + appId + is + (attemptReport == null ? "N/A" : attemptReport.getYarnApplicationAttemptState()) + ", waiting for current attempt to reach " + attemptState
[ERROR]:User must be on the <*> or <*> list to have permission to upload AM dependency tarball
[INFO]:<*> was deactivated
[WARN]:MultiNode policy 'policyName' is configured, however yarn.scheduler.capacity.multi-node-placement-enabled is false
[INFO]:DelegateToFileSystem listStatus call invoked
[DEBUG]:Getting key versions for key <*>
[DEBUG]:Cannot find reserved container map.
[TRACE]:<*> REST operation complete
[INFO]:Nonpositive maxcount in invalid READDIRPLUS request: <*>
[DEBUG]:Getting output stream failed without expect header enabled, throwing exception
[DEBUG]:Init for readable endpoints
[INFO]:Fsck: deleted corrupt file
[INFO]:Preempting container <*> from queue: <*>
[ERROR]:IOException occurred during removeFromClusterNodeLabels
[INFO]:Successfully initialized Authentication handler of type + authHandlerClassName
[DEBUG]:getFlushedOffset=<*> commitOffset=<*> nextOffset=<*>
[INFO]:SkipList is disabled
[INFO]:Add token with service <*>
[DEBUG]:Updating info for attempt: <*>
[INFO]:Waiting for UnderReplicatedBlocks to fall below <*>...
[INFO]:Total number of compressed input data files : <*>
[INFO]:Explicitly setting permissions to : + fsp.toShort() + , + fsp
[ERROR]:Wrong number of parameters
[DEBUG]:getNNAddressCheckLogical
[DEBUG]:Now at <*>: bytes remaining in current request: <*>
[DEBUG]:Try to get device type from device path: <*>
[DEBUG]:JvmPauseMonitor started
[DEBUG]:Renaming map output file for task attempt + mapId.toString() + from original location + mapOut.toString() + to destination + reduceIn.toString()
[INFO]:Script not found under /sbin/DevicePluginScript/, falling back to default search directories
[INFO]:Exception when trying to resume container <*>: <*>
[INFO]:allowedUsersAclList=<*>
[WARN]:Cannot access storage directory <*>
[ERROR]:Seems like client has been removed before the container metric could be published for container.getContainerId()
[INFO]:Image has changed. Downloading updated image from NN.
[INFO]:Default name service: <*>, enabled to read or write
[WARN]:Missing SubClusterPolicyConfiguration. Please try again by specifying a SubClusterPolicyConfiguration.
[TRACE]:TRACE
[DEBUG]:Trying to assign containers to child-queue of <*>
[INFO]:Successfully deleted service <*>
[WARN]:Privileged container being requested but privileged containers are not enabled on this cluster
[WARN]:Update but the new block does not have a larger generation stamp
[ERROR]:Proxy error: proxyUsername or proxyPassword set without the other.
[ERROR]:Cannot check overrides for record
[ERROR]:Exception thrown when fetching configuration version.
[INFO]:Deleted <*> - missing at source
[DEBUG]:Getting the current user information
[DEBUG]:start process datanode/external error
[WARN]:Could not fetch OOM status. This is expected at shutdown. Exiting., ex
[INFO]:Failed to set setXIncludeAware(true) for parser + docBuilderFactory + NAME_SEPARATOR + e
[DEBUG]:Reported block:<*> not found in attempted blocks. Datanode:<*>, StorageType:<*>
[ERROR]:Status update was called with illegal TaskAttemptId: + yarnAttemptID
[ERROR]:Failed to init state store
[DEBUG]:Setting the title for the application
[INFO]:Rolling master-key for container-tokens, got key with id <*>
[WARN]:Failed to add type ... to the result set because there is a duplicated copy.
[DEBUG]:Attempting to acquire lease on <*>, retry <*>
[INFO]:Lookup for local group identity started
[INFO]:Got container status for DATANODE:
[WARN]:NotReplicatedYetException sleeping src retries left retries
[DEBUG]:initDialogs
[DEBUG]:logEdit
[WARN]:Scheduler terminated before removing the application collectors
[INFO]:Finalizing upgrade for storage directory <*>.\\n cur LV = <*>; cur CTime = <*>
[ERROR]:A task type you don't know about is "unknownType".
[INFO]:Call cos sdk failed, retryIndex: <*>, call method: putObject, exception: ...
[INFO]:Container <*> will be <*> to start the execution of guaranteed container <*>.
[WARN]:"Log Aggregation service failed to initialize, there will be no logs for this application"
[INFO]:New generation stamp and access token set
[ERROR]:Resource allocation for <*> is null.
[INFO]:Using already-accepted recovery for segment starting at txid + segmentTxId + : + bestEntry
[DEBUG]:Destroying service <*>
[DEBUG]:Awaiting all running Mappper.map calls to finish, job <*>
[INFO]:Received URL from user
[ERROR]:CONTAINER_REMOTE_LAUNCH contains a map task
[WARN]:Failed to recover block (block=" + block + ", datanode=" + id + ")
[INFO]:Starts-after time is specified. Initial job submit time : <*>
[DEBUG]:Start rolling upgrade
[ERROR]:dev mode does NOT work with ephemeral port!
[WARN]:Interrupted while waiting for current attempt of + appId + to reach + attemptState
[DEBUG]:action
[DEBUG]:Failure to retrieve storage account key for <*>, accountName, e
[ERROR]:FATAL, Error while starting FS configuration conversion, see previous error messages for details!
[INFO]:Recovered for AMRMProxy: next master key id ...
[INFO]:Continuing re-encryption updater after pausing.
[INFO]:Launched fencing command '...' with pid ...
[INFO]:Querying for all individual cached resource files
[WARN]:text
[DEBUG]:checkAccess operation started
[INFO]:Partition file written
[DEBUG]:Reserved container + container.getContainer().getId() + on node + this + for application attempt + application.getApplicationAttemptId()
[INFO]:Number of errors: <*>
[INFO]:Got an error parsing job-history file, ignoring incomplete events.
[ERROR]:FSError from child
[WARN]:Container allocated at unwanted priority: ...
[INFO]:PipeMapRed exec <*>
[DEBUG]:Listing found <*> upload(s)
[INFO]:GridMix is configured to use a compression ratio of ... for the map output data.
[INFO]:Running new API mapper
[WARN]:Start information is missing for container
[INFO]:Preempted state update from taskAttemptID.toString()
[DEBUG]:Not decrementing resource as ResourceRequestInfo with priority=<*> resourceName=<*> executionType=<*> capability=<*> is not present in request table
[DEBUG]:... (dumpState output)
[DEBUG]:Node doesn't have enough available resource
[ERROR]:<*> ignoring path <*> with scheme
[DEBUG]:Deleting path: <*> as user <*>
[WARN]:Exception shutting down web server
[DEBUG]:write to <*>: <*>, blockGroup=<*>, datanode, Op.BLOCK_GROUP_CHECKSUM, blockGroup
[INFO]:Can't map user $<*>. Use its string hashcode: $<*>
[INFO]:<*>: Files committed: <*>. Total size <*>
[DEBUG]:SASL server doing general handshake for peer = <*>, datanodeId = <*>
[ERROR]:FATAL, Thread <*> threw an Error. Shutting down now...
[ERROR]:Name-node ... is not active. Shutting down.
[DEBUG]:No gauge <*>
[DEBUG]:AzureBlobFileSystem.modifyAclEntries path: <*>
[DEBUG]:String.format(STATE_CHANGE_MESSAGE, appID, oldState, getState(), event.getType())
[INFO]:Fetched initial range of seq num, from 1 to 100
[WARN]:Unable to bind Path
[DEBUG]:deleted public resource dir <*>, publicResourceDir
[WARN]:Command output: <*>, exit code: <*>
[DEBUG]:Processing report command
[DEBUG]:Sorting directories
[INFO]:Caught exception while scanning <*>. Will throw later.
[WARN]:Failed to build URI for auditor: <*>
[INFO]:Completed update blocks map and name cache, total waiting duration <*>ms.
[INFO]:Cannot find active collector while renewing/regenerating token for appId
[INFO]:Stored the start data of application <*>
[DEBUG]:Customized device plugin scheduler is preferred but not implemented, use default logic
[INFO]:Recovering container
[DEBUG]:Retrieved containers
[DEBUG]:Failed to get number of live nodes
[INFO]:Currently being shutdown. Aborting reboot
[DEBUG]:checkAccess job acls, jobOwner: jobOwner jobacl: jobOperation.toString() user: callerUGI.getShortUserName()
[INFO]:Sequential invocation completed
[WARN]:Error trying to scan for all FileInfos
[INFO]:Source Revision : <*>
[WARN]:Error managing cache for writer of block <*>, <*>
[ERROR]:Unable to get json from Item.
[ERROR]:Unable to store master key ...
[ERROR]:Trying to updateHistory non-existing resource skylines for <*>
[INFO]:Starting scan to move intermediate done files
[DEBUG]:Ensuring existence of + prefixPath
[DEBUG]:getAdditionalDatanode: src= + src + , fileId= + fileId + , blk= + blk + , existings= + Arrays.asList(existings) + , excludes= + Arrays.asList(excludes) + , numAdditionalNodes= + numAdditionalNodes + , clientName= + clientName
[ERROR]:Cannot get children for "<*>": <*>
[ERROR]:ioe.toString()
[INFO]:Setting up storage: nsid=<*>;bpid=<*>;lv=<*>;nsInfo=<*>;dnuuid=<*>
[DEBUG]:Get corrupt file blocks returned error: <*>
[INFO]:Added service <*> for the user <*>, filename = <*>
[WARN]:Device <*> does not use the CFQ scheduler; disk isolation using CGroups will not work on this partition.
[INFO]:Persisted service service.getName() version service.getVersion() at appJson
[ERROR]:<*>: Invalid event <*> at <*>, componentSpec.getName(), event.getType(), oldState
[INFO]:reduceId + Memory-to-Memory merge of the + noInMemorySegments + files in-memory complete.
[DEBUG]:Result fetched from TextFileBasedIdentityHandler
[TRACE]:loadNodeChildren(expected= + expected + , terminators=<*>): + parent.dump()
[ERROR]:Error while creating a proxy user
[INFO]:START STRESS @ <*>
[DEBUG]:Read operation successful; bytes count reached
[DEBUG]:StreamerStreams initialized
[INFO]:Executing "query plan" command.
[DEBUG]:Loading all dependencies from <*>
[DEBUG]:Enabling OAuth2 in WebHDFS
[ERROR]:Incorrect path for PRIVATE localization.
[WARN]:Failed to remove application staging directory, e
[DEBUG]:To rename: ...
[DEBUG]:Timed out after 10 minutes waiting for IO requests to finish ioThreadPool.toString()
[INFO]:Deleted trash checkpoint: ...
[INFO]:Triggering initial evaluation of component <*>
[DEBUG]:Bypassing cache to create filesystem <*>
[ERROR]:Failed to read the application <*>.
[INFO]:Removing reservation allocation. reservationEvent.getReservationIdName()
[WARN]:Exception while trying to activate reservation: <*> for plan: <*>
[DEBUG]:ApplicationAttempt details printed
[INFO]:Setting destination locations
[WARN]:Disk Balancer - Source and destination volumes are same: <*>
[DEBUG]:Closed MPU to <*>, saved commit information to <*>; data=:\n<*>
[DEBUG]:Got interrupted while DeadNodeDetector is idle.
[INFO]:<*>: Retried <*>: <*>
[ERROR]:Unable to remove reservation: <*> from plan.
[DEBUG]:blacklist size <*> is less than failure threshold ratio <*> out of total usable nodes <*>, currentBlacklistSize, blacklistDisableFailureThreshold, numberOfNodeManagerHosts
[DEBUG]:Samples obtained from splits
[INFO]:Begin saveErasureCodingSection
[INFO]:KMSWebServer startup/shutdown message
[DEBUG]:RMAppManager processing event for applicationId of type APP_MOVE
[DEBUG]:previousRange
[DEBUG]:nodes <*> storageTypes <*> storageIDs <*>
[INFO]:Going to retain <*> images with txid >= <*>
[INFO]:Not joining election since service has not yet been reported as healthy.
[WARN]:output.toString()
[DEBUG]:Stopping metrics sink entry.getKey(): class=entry.getValue().sink().getClass()
[DEBUG]:Checking operation WRITE
[INFO]:Scheduling <*> storage monitor at interval <*>, this.storage, monitorInterval
[ERROR]:NO_MAPPING_ERR_MSG
[ERROR]:Exception in scheduler UpdateThread
[INFO]:FILE_COPIED: source=<*>, size=<*> --> target=<*>, size=<*>
[TRACE]:Directory list obtained
[DEBUG]:Performing readahead
[INFO]:this.getName() + " waiting for pending aggregation during exit"
[DEBUG]:Storing token
[WARN]:The counter string, "<*>" is badly formatted.
[DEBUG]:got reply from <*>: blockChecksum=<*>, blockChecksumType=<*>, datanode, blockChecksumForDebug, getBlockChecksumType()
[INFO]:Loaded NM state version info + loadedVersion
[WARN]:Only one namespace edits storage directory (DFS_NAMENODE_EDITS_DIR_KEY) configured. Beware of data loss due to lack of redundant storage directories!
[INFO]:Can't get path for fileId: <*>
[DEBUG]:assignContainers: node=... application=...
[INFO]:Loaded timeline state store version info <*>
[DEBUG]:Aborting %s uploads
[INFO]:Discarded + totalCount + entities for timestamp + timestamp + and earlier in + (t2 - t1) / 1000.0 + seconds
[DEBUG]:Resolved <*> to <*>
[INFO]:Uploading all dependency jars to HDFS. For faster submission of apps, set config property <*> to the dependency tarball location. Dependency tarball can be uploaded to any HDFS path directly or by using command: yarn app -<*> <*>
[INFO]:Abort operation completed
[DEBUG]:Job metrics end running
[DEBUG]:Exception in closing <*>
[DEBUG]:RM Node labels mapping provider class is : nodeLabelsMappingProvider.getClass()
[INFO]:Startup shutdown message
[INFO]:ProcfsBasedProcessTree currently is supported only on Linux.
[INFO]:Container <*> belongs to an application that is already killed, no further processing
[INFO]:<*> <*>
[DEBUG]:Got an error checking if <*> is local
[WARN]:prefix + metrics system not yet started!, new MetricsException(Illegal stop)
[DEBUG]:writeTo metafile is ... of size ...
[ERROR]:Not able to add suffix (.bat/.sh) to the shell script filename
[INFO]:Block recovery for block <*> succeeded
[INFO]:ImageServlet allowing administrator: + remoteUser
[INFO]:Exiting, bbye..
[DEBUG]:Translate to CSI proto message: <*>
[INFO]:Node: + nm.getNodeID() + has already been taken out of scheduling. Skip updating its resource
[INFO]:Super post called for TRUNCATE
[INFO]:Loading inode references
[ERROR]:Exception occurs when retry<*> to retrieve the block range start: <*>, end:<*>
[WARN]:<*> <*> Start <*>
[TRACE]:<*>: trying to create a remote block reader from a TCP socket
[INFO]:Error when parsing local resource URI for upgrade of + Container <*>, e
[ERROR]:Cannot fetch cluster ID metrics <*>
[INFO]:FSMkdirs operation executed
[DEBUG]:Token cancel failed: <*>
[INFO]:Configuring max capacity percentage for queue
[INFO]:Storing SEQUENCE_NUMBER
[ERROR]:Error scanning active files
[INFO]:Job completed successfully
[ERROR]:Unexpected exception while proxying API
[INFO]:Cannot rollback resource for container + containerId + . The application that the container + belongs to does not exist.
[INFO]:The secret znode already exists, retrieving data
[ERROR]:<*> exceptions occurred loading INodes
[DEBUG]:<*>: Full exception details
[DEBUG]:Updating <*><*>, DELEGATION_TOKEN_PREFIX, rmDTIdentifier.getSequenceNumber()
[WARN]:Node <*> is dead while in <*>. Cannot be safely decommissioned or be in maintenance since there is risk of reduced data durability or data loss. Either restart the failed node or force decommissioning or maintenance by removing, calling refreshNodes, then re-adding to the excludes or host config files.
[WARN]:Couldn't determine terminal height, setting to 24
[WARN]:BLOCK* getBlocks: Asking for blocks from an unrecorded node <*>
[DEBUG]:Scheduling deletion of <*> logs in <*> msec
[INFO]:Refresh super user groups configuration successful for proxy.getAddress()
[DEBUG]:Add current thread to localizingThreads
[WARN]:IOException in offerService
[INFO]:Services initialized
[DEBUG]:Failed to get number of dead in maintenance nodes
[INFO]:createAppSummary(app).toString()
[DEBUG]:getDatanodeListForReport with includedNodes = ..., excludedNodes = ..., foundNodes = ..., nodes = ...
[INFO]:Added node " + node.getNodeAddress() + " cluster capacity: " + clusterResource
[INFO]:Not allocating more containers as max allocations per AM heartbeat <*> has reached
[INFO]:Load plugin class <*>
[DEBUG]:Duplicate initApp detected for application
[INFO]:Shutdown requested. Stopping callback.
[INFO]:<*> Health has gone below threshold. Starting health threshold timer at ts = <*> (<*>)
[DEBUG]:Starting delete operation
[DEBUG]:Resource <*><*> size : <*> transitioned from <*> to <*>
[DEBUG]:set new mode: <*>
[DEBUG]:source & dest parents are different; fix up dir markers
[DEBUG]:Exception in getCurrentVersion., e
[INFO]:Checking operation category WRITE
[INFO]:FSListStatus operation executed
[INFO]:rc: <*>
[INFO]:Namespace quota set
[INFO]:Sucessfully deleted reservation: <*> in plan.
[DEBUG]:No space available. Available: availableSize MinSize: minSize
[WARN]:Interrupted while waiting for deletion thread to complete, closing db now
[ERROR]:Error while parsing mapping file
[ERROR]:Error warming up keys for provider with url <*>
[INFO]:Operation completed. Audit event logged successfully
[INFO]:Storage directory <*> has already been used.
[WARN]:Received non-NN/SNN/administrator request for image or edits from <*> at <*>
[INFO]:Starting web server as: <*>
[DEBUG]:Issuing AuthenticationToken for user.
[WARN]:We continue although there're mistakes in user's configuration ...
[INFO]:Timeline client stopped
[DEBUG]:Generated Encrypted key for <*> number of keys.
[WARN]:Could not find queue in scheduler while trying to deactivate for <*>
[DEBUG]:Credential provider class is <*>
[DEBUG]:Start to decay current costs.;
[ERROR]:Could not find the clause substitution token ...
[DEBUG]:Recovering Flow context: <*> for an application <*>
[DEBUG]:Getting pid for container y to send signal to from pid file z
[WARN]:Unable to start log segment txid at currentInProgress: e.getLocalizedMessage()
[INFO]:Adding # + credentials.numberOfTokens() + tokens and # + credentials.numberOfSecretKeys() + secret keys for NM use for launching container
[DEBUG]:Skip scheduling on node because it haven't heartbeated for + timeElapsedFromLastHeartbeat / 1000.0f + secs
[ERROR]:Failed to refresh mount table entries cache at router <*>, adminAddress, e
[ERROR]:Unknown queue: + queueName
[INFO]:Initializing RPC stats for <*> priority levels
[WARN]:Container launch failed : <*>
[INFO]:Starting 5 threads
[DEBUG]:Adding event to entity
[DEBUG]:Any job larger than <*> will not be loaded.
[ERROR]:Expecting boolean obj for setting checking recent image, but got ...
[INFO]:<*>: Committing job "<*>". resilient commit supported = <*>
[INFO]:movedContainer container= + rmContainer.getContainer() + containerState= + rmContainer.getState() + resource= + rmContainer.getContainer().getResource() + queueMoveOut= + this + usedCapacity= + getUsedCapacity() + absoluteUsedCapacity= + getAbsoluteUsedCapacity() + used= + queueUsage.getUsed() + cluster= + clusterResource
[INFO]:DN <*> joining cluster has expanded a formerly single-rack cluster to be multi-rack. Not checking for mis-replicated blocks because this NN is not yet processing repl queues.
[DEBUG]:Get RM web app URL without scheme
[WARN]:<*> metrics system timer already started!
[INFO]:Setting owner name and group
[INFO]:PostWrite processing with IndexedFileController
[DEBUG]:Checking NN startup
[INFO]:Perms after creating ... , Expected: ...
[INFO]:-- Local NN thread dump --
[INFO]:Shutting down DataXceiverServer before restart
[INFO]:Thread.currentThread().getName() + " was interrupted, exiting"
[ERROR]:Waiting app <*> expected to be in usersNonRunnableApps, but was not. This should never happen.
[WARN]:Failure processing re-encryption task for zone <*>
[INFO]:Skip recovering container for unknown SchedulerApplication. Application current state is <*>
[INFO]:block is already in the recovery queue
[INFO]:Would have joined master election, but this node is prohibited from doing so for ... more ms
[ERROR]:Could not delete reservation: reservationId
[INFO]:Found %d node(s)
[TRACE]:getSubdirEntries(<*>, <*>): no entries found in <*>
[INFO]:Another async task is already started before this one is finalized. fileId: <*> asyncStatus: <*> original startOffset: <*> new startOffset: <*>. Won't change asyncStatus here.
[WARN]:Exception when trying to heartbeat:
[ERROR]:Seems like client has been removed before the entity could be published for <*>
[INFO]:ops.getSummary(false)
[DEBUG]:Updating file xattrs for re-encrypting zone <*>, starting at <*>
[WARN]:PendingContainers queue is interrupted
[WARN]:File/directory <*> not found: it may have been deleted. If this is an object store, this can be a sign of eventual consistency problems.
[INFO]:Reinitializing SchedulingMonitorManager ...
[ERROR]:Re-encryption updater thread exiting.
[INFO]:Using state database at + storeRoot + for recovery
[WARN]:Ignored <*>. It is not a directory
[INFO]:Track the application at: ...
[ERROR]:A map attempt status you don't know about is "<*>".
[DEBUG]:<*> is set, will be used to run proxy.
[INFO]:Capacity scheduler was successfully started
[DEBUG]:<*>: masked=<*>
[WARN]:Bash is not supported by the OS
[DEBUG]:Error in resource usage emulation! Message: <*>
[INFO]:Found script: envBinaryPath
[DEBUG]:Next Step: <*>, nextStep
[DEBUG]:Checking access permissions for queue
[WARN]:Interrupted partUpload, ie
[WARN]:Proxy user Authentication exception
[DEBUG]:While waiting for upload completion
[INFO]:Handling event publish
[WARN]:Error in signalling container <*> with <*>; exit = <*>, pid, signal, retCode, e
[DEBUG]:Waiting to executor service terminated duration <*>ms.
[DEBUG]:User retrieved
[WARN]:src=<*>, datanodes<*>=<*>
[INFO]:Balancer concurrent dispatcher threads = <*>
[TRACE]:<*>: shared memory segment access is disabled.
[INFO]:Transition started
[DEBUG]:Thread.currentThread().getName(): call for RpcKind + call.rpcKind
[DEBUG]:Found <*> GPU devices
[INFO]:NameNode container completed; marking application as done
[ERROR]:%nInvalid argument found for command %s : %s%nValid arguments are : %n\t %s : %s %n
[ERROR]:Unable to remove path with exception
[INFO]:buildTokenServiceForLogicalUri
[DEBUG]:access for filesystem: <*>, path: <*>, mode: <*>
[DEBUG]:Invalid mode:<*>, ignoring
[DEBUG]:getName() + ": initing services, size=" + services.size()
[INFO]:LOG.INFO: value
[INFO]:<*>: removed output path to be replaced: <*>
[INFO]:<*> exiting.
[INFO]:Skipping jas + jas + since it's disabled
[DEBUG]:Succeeded to start Container <*>
[ERROR]:No war file or webapps found for ui2 !
[WARN]:Exception in LinuxContainerExecutor mountCgroups
[INFO]:FSFileChecksum operation executed
[WARN]:Failed to add the inode <*> to the directory <*>
[DEBUG]:NFS MKDIR dirHandle: dirHandle.dumpFileHandle() filename: fileName client: remoteAddress
[DEBUG]:Prefix: <*>
[DEBUG]:Could not resolve <*>. Falling back to <*>
[INFO]:Start MarkedDeleteBlockScrubber thread
[INFO]:Requested container ask: + request.toString()
[DEBUG]:Scheduling for deletion with children
[INFO]:Failed to get groups from the first lookup. Initiating the second LDAP query using the user's DN.
[DEBUG]:UserGroupInformation current user obtained
[INFO]:Start file before generating key
[WARN]:Could not list directory <*>
[DEBUG]:Ready to delete path: <*>. recursive: <*>.
[INFO]:Applications Running: countHere
[WARN]:No nodes available for placement at the moment !!
[INFO]:System CWD content: ...
[WARN]:Aborting already-finished MapOutput for TaskAttemptID
[DEBUG]:selected by alias=<*> token=<*>
[INFO]:List of errors:
[INFO]:Service address not found
[INFO]:Pause detected while waiting for QuorumCall response; increasing timeout threshold by pause time of <*> ms.
[DEBUG]:IP address returned for FQDN detected: <*>
[INFO]:delete config file <*>
[INFO]:Error deleting <*>: <*>
[DEBUG]:selected by service=<*> token=<*>, service, token
[INFO]:Launching NAMENODE on a new container. + ...
[INFO]:Application with id 'appId' doesn't exist in RM.
[WARN]:Output Path is null in recoverTask()
[WARN]:Unable to add the application to the delegation token renewer on recovery., t
[DEBUG]:Evicting <*> due to space limitations
[WARN]:Failed to create or write to temporary file in dir: + tmpDirPath
[INFO]:Found: <*>
[DEBUG]:waitForZKConnectionEvent completed
[INFO]:Group names
[INFO]:Initialized state store client class
[DEBUG]:Skipped App Activity recorded for blacklisted node
[INFO]:Checkpoint renamed from IMAGE_ROLLBACK to IMAGE
[ERROR]:Exception while computing policy changes for leaf queue : + getQueuePath(), ye
[ERROR]:Coder <*> cannot be registered because its coder name <*> has conflict with <*>
[INFO]:Cache directive removed
[INFO]:Start loading edits file
[INFO]:Refresh Responses:
[INFO]:Loading + numInodes + INodes.
[INFO]:ViewFs InternalDirOfViewFs listStatus call invoked
[INFO]:Erasure coding policy unset successfully
[WARN]:Timeout submitting entries to <*>
[TRACE]:Resources with zero amount: ...
[WARN]:Failed to check the status of <*>. Ignore it and continue.
[DEBUG]:Incrementing stat CALL_OPEN
[INFO]:JOB_DIR_LABEL=/jobdir_path
[DEBUG]:Block <*>: we only have <*> of <*> cached replicas. + <*> DataNodes have insufficient cache capacity.
[WARN]:The option %s value "%s" is not a long integer; using the default value %s
[ERROR]:Exception while parsing json: <*>\\n<*>
[INFO]:Generated new storageID <*> for directory <*> <*>
[WARN]:Log warning with msg and throwable
[INFO]:Attempting to delete existing output path
[DEBUG]:Starting vectored read on path <*> for ranges <*>, pathStr, ranges
[TRACE]:Exiting invalidateCache for key name <*>.
[DEBUG]:Closing Namenode metrics
[DEBUG]:AsyncScheduleThread<*> is running!
[DEBUG]:Updating NN registration: <*> -> <*>
[INFO]:Credential <*> has been successfully deleted.
[INFO]:updatePipeline( + oldBlock.getLocalBlock() + , newGS= + newBlock.getGenerationStamp() + , newLength= + newBlock.getNumBytes() + , newNodes= + Arrays.asList(newNodes) + , client= + clientName + )
[INFO]:Attempting to auto-create leaf queue
[INFO]:Duration of deletions: <*>
[INFO]:Completed writing <*> (<*> bytes)
[INFO]:<*>: Renaming manifests to <*>
[WARN]:WARNING: cannot delete directory + f.getAbsolutePath()
[ERROR]:Cannot get content summary for mount <*>: <*>
[TRACE]:startDecommission: Node <*> in <*>, nothing to do.
[DEBUG]:Sent signal <*> to pid <*> as user <*> for container <*>, result=<*>
[INFO]:New WatcherWithClientRef instance created
[DEBUG]:Setting task start time
[INFO]:Setting up data streams.
[DEBUG]:Rename source key: <*> to dest key: <*>
[TRACE]:Added block <*> to CACHED list.
[ERROR]:Fail to sync yarn sysfs for application ID: <*>, reason:
[INFO]:Interrupted. Trying to exit gracefully.
[WARN]:Plan based on reservation queue <*> already exists.
[ERROR]:Could not determine valid IPC address for other NameNode (+info.getNameNodeID()+) , got: +address
[DEBUG]:SASL server DIGEST-MD5 callback: setting password for client: tokenIdentifier.getUser()
[DEBUG]:Validating request made by...
[WARN]:Insufficient space for placing the block on a transient volume, fall back to persistent storage
[INFO]:Using leveldb path ...
[INFO]:nmCollectorServiceAddress:
[ERROR]:Exception raised <*>
[DEBUG]:getSpillFileCB... Path <*>; Pos: <*>
[INFO]:this.appId specifies ContainerLogAggregationPolicy of policyClass
[WARN]:No class configured for <*>, <*> is empty
[INFO]:Success
[ERROR]:Found duplicated storage UUID: %s in %s.
[ERROR]:Exception in NameNodeResourceMonitor: <*>
[TRACE]:DataNodePeerMetrics: Got stats: <*>
[DEBUG]:Cannot find class for token kind <*>
[WARN]:Unable to parse the JWT token.
[INFO]:Public cache exiting
[INFO]:doAsyncWrite threw exception <*>
[INFO]:<*> is accessing unchecked <*>, remoteUser, toFetch
[INFO]:Placement Algorithm <*>
[DEBUG]:Completing multipart upload <*> with <*> parts, uploadId, partETags.size()
[DEBUG]:Failed to get number of stale nodes
[DEBUG]:Error in resource usage emulation! Message:
[INFO]:Deleting <*>
[ERROR]:Unexpected health check result null for volume <*>
[TRACE]:CustomTokenProvider Access token fetch was successful with retry count <*>
[DEBUG]:Proxy for + uri + failed. cause: , cause
[DEBUG]:Trying ClientProtocolProvider : ...
[ERROR]:Cleanup invoked due to NoSuchElementException
[WARN]:Fsck: there were errors copying the remains of the corrupted file <*> to /lost+found
[INFO]:Using Agent: $<*> for queue: $<*>
[INFO]:Can perform rollback for sd
[INFO]:builder.toString()
[INFO]:key: + key.toString() + this.largestNumOfValues: + this.largestNumOfValues
[DEBUG]:Getting root interceptor
[ERROR]:Error encountered requiring NN shutdown. Shutting down immediately.
[ERROR]:Exception in BPOfferService for this
[INFO]:Initializing mounted controller ... at ...
[INFO]:Initialized HBaseTimelineWriterImpl UGI to ...
[DEBUG]:Initializing configuration store
[WARN]:Block <*> does not have a metafile!
[ERROR]:Cannot fetch block pool ID metrics: <*>
[INFO]:Current number of shuffle connections (%d) is greater than or equal to the max allowed shuffle connections (%d)
[INFO]:Service dependency is not satisfied for service: <*> state: <*>
[DEBUG]:read requested b.length = <*> offset = <*> len = <*>, b.length, off, len
[WARN]:oss: <*> capped to ~2.14GB(maximum allowed size with current output mechanism)
[INFO]:Resuming re-encrypt updater for testing.
[INFO]:TaskAttempt: <*> using containerId: <*>
[INFO]:Updated reserved container X on node Y for application Z
[DEBUG]:setsid is not allowed to run by the JVM security manager. So not using it.
[DEBUG]:rollEditLog
[DEBUG]:Time to output inodes: <*>ms
[DEBUG]:AM resource request: exceeds maximum AM resource allowed, dump state
[WARN]:Reporting bad <*> on <*>
[INFO]:Got exception while resuming container: + StringUtils.stringifyException(e)
[DEBUG]:BLOCK* NameSystem.LowRedundancyBlock.update: <*> has only <*> replicas and needs <*> replicas so is added to neededReconstructions at priority level <*>
[DEBUG]:Renaming + tmpFile + to + finalizedFile
[INFO]:Total number of application attempts: X
[ERROR]:Invalid BlockPoolId ...
[DEBUG]:Invalid Input Errors raised
[INFO]:Got response from RM for container ask, completedCnt=
[DEBUG]:Removing ZKDTSMDelegationKey_<*>
[DEBUG]:SASL client callback: setting realm: + rc.getDefaultText()
[TRACE]:No erasure coding policy is given.
[TRACE]:Got journal, state = <*>; firstTxId = <*>; numTxns = <*>
[DEBUG]:Query the skyline store for pipelineId: <*>. + pipelineId
[ERROR]:The specified Reservation with ID <*> does not exist in the plan
[INFO]:Finalize upgrade for + sd.getRoot() + is not required.
[WARN]:Exception thrown when copy from <*> to <*>, exception:<*>, this.srcKey, this.dstKey, e
[WARN]:Exception caught, ignoring node:<*>
[INFO]:Generating <*> using <*> and <*>
[INFO]:Starting reconfiguration task.
[INFO]:ResourceCalculatorProcessTree is unavailable on this system. <*> is disabled.
[INFO]:cliID: ..., src: 127.0.0.1, dest: 127.0.0.1, op: REQUEST_SHORT_CIRCUIT_SHM, shmId: ..., srvID: ..., success: true
[ERROR]:Unable to kill infrastructure app (<*>)
[DEBUG]:Initializing
[WARN]:Exception encountered while connecting to the server <*>
[ERROR]:EditLogManifest response does not have fromUrl field set. Aborting current sync attempt
[INFO]:JVM with ID: + jvmId + given task: + task.getTaskID()
[INFO]:Fsck: ignoring open file + path
[DEBUG]:Loading master key from + key
[INFO]:No binary token filename provided
[DEBUG]:Selecting stream
[WARN]:Could not store container <*>] state. The Container has been resumed.
[DEBUG]:Finished count -> <*>/<*>
[INFO]:Task scheduled
[DEBUG]:debugLogFileSystemClose
[DEBUG]:newly failed streamers: ...
[DEBUG]:KeyStore loaded successfully from '%s'!!
[ERROR]:Cannot parse JMX output for <*> from server <*>: <*>
[DEBUG]:BLOCK* NameSystem.allocateBlock: handling block allocation writing to a file with a complete previous block: src= /* src from code */ lastBlock= /* lastBlockInFile from code */
[WARN]:Cannot locate shuffle secret in credentials. + Using job token as shuffle secret.
[INFO]:Handling <*> from previous attempt
[WARN]:<*> Finished consuming the input trace. Exiting..
[INFO]:" NM=" + entry.getKey() + ", labels=<*>"
[INFO]:Calling process first blk report from storage: <*>
[WARN]:Interrupted, unable to determine if bash is supported
[INFO]:Recovered container <*> succeeded
[INFO]:String.format(isDead ? REPORT_REMOVE_DEAD_NODE_ENTRY : REPORT_REMOVE_STALE_NODE_ENTRY, d)
[INFO]:<*>: delete upgrade dir version <*>
[INFO]:Retrieving info from csi-driver-adaptor on address + addr
[INFO]:AM registration plus applicationAttemptId
[INFO]:Creating file
[DEBUG]:deleting %s
[ERROR]:Unexpected error when publishing entity
[DEBUG]:Application <*> starts to launch a container (<*>).
[WARN]:Unregistration of the Node + this.nodeId + failed., e
[ERROR]:Statistics interrupt while waiting for completion of a job.
[INFO]:numSplits= + numSplits + , splits.size()= + splits.size()
[ERROR]:Failed to get devices!, e
[DEBUG]:Check assign to queue: + getQueuePath() + nodePartition: + nodePartition + , usedResources: + queueUsage.getUsed(nodePartition) + , clusterResources: + clusterResource + , currentUsedCapacity: + Resources.divide(resourceCalculator, clusterResource, queueUsage.getUsed(nodePartition), labelManager.getResourceByLabel(nodePartition, clusterResource)) + , max-capacity: + queueCapacities.getAbsoluteMaximumCapacity(nodePartition)
[DEBUG]:AzureBlobFileSystem.getAclStatus path: <*>
[WARN]:Cannot find trash root of + fullPath, ex
[INFO]:Stopping resource-monitoring for <*>
[WARN]:Couldn't read <*>; can't determine cpu info
[INFO]:Temporary redirect with URI for file checksum
[DEBUG]:Retrieve file metadata. COS key: <*>, ETag: <*>, length: <*>.
[ERROR]:Failed to create RPC proxy to NameNode at <*>
[DEBUG]:Purged <*> filesystem instances
[WARN]:SIMULATING A CORRUPT BYTE IN IMAGE TRANSFER!
[DEBUG]:Setting work path to <*>
[DEBUG]:Processing event for <*> of type <*>, appAttemptID, event.getType()
[INFO]:Assigning container <*> to fast fail map
[INFO]:No keytab localized at <*>
[INFO]:OUTCOME: FAILURE, Reservation ID: reservationId.toString(), Contract: contract.toString()
[DEBUG]:Handling log event in NonAggregatingLogHandler
[WARN]:Unable to rename edits file from + tmpFile + to + finalizedFile
[WARN]:Skipping next heartbeat scan due to excessive pause
[ERROR]:Failed to set keys
[DEBUG]:Rendering info block
[INFO]:ACL entries removed successfully
[WARN]:Resource is missing:
[ERROR]:Error while starting the Secret Manager threads
[INFO]:Instantiating Proxy at <*>: <*>
[INFO]:Max vcores capability of resources in this cluster
[DEBUG]:Loaded IP list of size = + lines.size() + from file = + fileName
[TRACE]:Sending receipt verification byte for slot <*>
[ERROR]:Cache file <*> deletion would not be attempted as write lock could not be acquired within <*> <*>
[INFO]:FSFileStatus operation executed
[DEBUG]:Cluster URI : <*>
[DEBUG]:Created ugi: <*> for username: <*>
[WARN]:Host list file path <*> is empty or does not exist !!
[INFO]:Volumes to un-publish <*>
[INFO]:Application <*> does not exist in registry
[DEBUG]:BLOCK* invalidateBlocks: <*> on <*> listed for deletion.
[DEBUG]:Adding password for + identifier.getApplicationAttemptId()
[INFO]:FinishAM finished with isUnregistered = <*> in <*> ms for <*>
[DEBUG]:Get InputStream by cache file path.
[INFO]:Starting
[INFO]:Log success for user
[ERROR]:Got IOException at position + inputStream.getPosition()
[ERROR]:Error While Updating RMDelegationToken and SequenceNumber , e
[WARN]:Cannot list edit logs in <*>
[INFO]:attemptID given a go for committing the task output.
[ERROR]:Exception raised while stopping container
[ERROR]:Disk Balancer - Invalid plan version.
[DEBUG]:Recovering container with state: <*>
[DEBUG]:Trying to merge the ranges as they are not disjoint
[DEBUG]:Evicting block ...
[DEBUG]:CPU Comparison: + procfsUsage + + cgroupUsage
[INFO]:Pausing re-encrypt handler for testing.
[DEBUG]:NFS RMDIR dir fileHandle: <*> fileName: <*> client: <*>
[INFO]:There are <*> blocks pending replication and the limit is <*>. A further <*> blocks are waiting to be processed. The replication queue currently has <*> blocks
[ERROR]:Fail to reload auxiliary services, reason: <*>
[DEBUG]:marker scan %s
[INFO]:Docker inspect output for + containerId + : + output
[INFO]:NM recovery is not enabled. We'll wipe tc state before proceeding.
[INFO]:Writing znode <*> to indicate that the local node is the most recent active..., zkBreadCrumbPath
[ERROR]:"Exception when removing the matching requests. ", e
[DEBUG]:rechecking for electability from bad state
[INFO]:keyName has been successfully created with options options.toString().
[INFO]:Successfully deleted + znodeWorkingDir + from ZK.
[DEBUG]:Trying map output collector class: + subclazz.getName()
[INFO]:Recovering AMRMProxyService
[INFO]:Active Nodes: countHere
[INFO]:Raising locality level from <*> to <*> at priority <*>
[DEBUG]:Delegation token renewed successfully
[DEBUG]:Omitting duplicate service: <*>.
[DEBUG]:Allocation file loaded
[INFO]:Timeline service is enabled; version: [...
[INFO]:Storing info for app: + appId
[DEBUG]:Restricting metadata request to version <*>
[DEBUG]:Lease renewer daemon for <*> with renew id <*> expired
[WARN]:Error while closing the error stream
[DEBUG]:command array:
[ERROR]:Getting file length occurs an exception. COS key: %s, exception: %s
[ERROR]:error closing blockReader
[DEBUG]:Delete the file: <*>
[INFO]:Total size of input data : + StringUtils.humanReadableInt(dataSize)
[INFO]:Login successful for user <*> using keytab file <*>. Keytab auto renewal enabled : <*>
[INFO]:Operation mkdirs incremented
[DEBUG]:Bucket endpoint : <*>, Hostname : <*>, DNSAddress : <*>
[INFO]:Key deserialized
[DEBUG]:Path could not be found: target
[DEBUG]:Retrieved locations for path
[ERROR]:All specified directories have failed to load.
[DEBUG]:Found implementation of <*>: <*>
[DEBUG]:Creating directory: <*>
[INFO]:Can't remove lease for unknown datanode <*>
[DEBUG]:RECV: request.getUri() \nmapId: mapIds \nreduceId: reduceQ \njobId: jobQ \nkeepAlive: keepAliveParam
[DEBUG]:Looking for FS supporting <*>
[INFO]:Service ' + serviceName + ' doesn't exist at hdfs path: + appDir
[DEBUG]:Assigning host with numKnownMapOutputs to ThreadName
[INFO]:AMRMProxyService is enabled. All the AM->RM requests will be intercepted by the proxy
[DEBUG]:POST to <*>
[ERROR]:Block token with id doesn't have the correct token password
[DEBUG]:Comparing <*> and <*>
[ERROR]:The owner of the posted timeline entities is not set
[INFO]:LogHandlerAppFinishedEvent dispatched
[INFO]:Available resource value after conversion: + availableResourceValue
[DEBUG]:Application attempt <*> released container <*> on node: <*> with event: <*>
[ERROR]:Invalid Application ID: <*>
[INFO]:Current OpenFileCtx is already inactive, no need to cleanup.
[DEBUG]:Scheduling DeletionTask (delay <*>) : <*>
[WARN]:CPU device is duplicated: device
[ERROR]:FATAL, Failed to transition RM to Standby mode.
[INFO]:Audit log for success
[DEBUG]:Cannot rename source file: <*> to dest file: <*>, because the file already exists.
[DEBUG]:Application <*> sends out request for <*> mappers.
[WARN]:The volume<*> with the available space (=<*> B) is less than the block size (=<*> B).
[ERROR]:Failed to move temporary log file to final location
[INFO]:Using webapps at: /path/to/webapps
[INFO]:Build file listing completed.
[INFO]:Input Options: <*>
[DEBUG]:parsing input stream + is
[DEBUG]:Parent queue = ..., nodeLabel = ..., deactivated leaf queues = ...
[DEBUG]:Deleting %d keys
[INFO]:-delete option is enabled. About to remove entries from target that are missing in source
[ERROR]:Memory cannot be allocated in increments of zero. Assuming MB increment size. Please ensure the scheduler configuration is correct.
[DEBUG]:there is no metric system to unregister <*> from
[INFO]:<*> Health recovered above threshold at ts = <*> (<*>)
[DEBUG]:DIR* FSDirectory.unprotectedRenameTo: src is renamed to dst
[WARN]:NodeManager's totalPmem could not be calculated. Setting it to <*>
[DEBUG]:Actual length is + length
[WARN]:Could not find serial portion from path: + serialDirPath.toString() + . Continuing with next
[INFO]:Created directory for job submission
[INFO]:starting log segment
[ERROR]:Authorization failed with error
[DEBUG]:The async write task has no pending writes, fileId: <*>
[DEBUG]:The costTable is:...
[WARN]:checkAllVolumes timed out after <*> ms maxAllowedTimeForCheckMs
[INFO]:Application <*> goes to finish.
[INFO]:Stopping decommissioning of <*> node <*> <*>
[INFO]:Using random node as fallback
[WARN]:User + user.getShortUserName() + doesn't have permission to call ' + method + '
[WARN]:some warn message here
[INFO]:Looking for Hadoop tarball for version: <*>
[ERROR]:Failed to establish WebSocket connection with Client, e
[ERROR]:Invalid format for ...
[DEBUG]:NFS COMMIT fileHandle: <*> offset=<*> count=<*> client: <*>
[DEBUG]:SQLException closing statement: <*>
[INFO]:Old node exists: <*>
[DEBUG]:File size is <*>, number of parts to upload = <*>
[DEBUG]:LowRedundancyBlocks.update <*> curReplicas <*> curExpectedReplicas <*> oldReplicas <*> oldExpectedReplicas <*> curPri <*> oldPri <*>
[DEBUG]:Request to fence old active being ignored, as embedded leader election doesn't support fencing
[TRACE]:this can't register a slot because the ShortCircuitRegistry is not enabled.
[INFO]:Service state changed to <*>
[INFO]:Problem in submitting renew tasks in token renewer thread.
[DEBUG]:Skip app_attempt= + application.getApplicationAttemptId() + , because it doesn't need more resource, schedulingMode= + schedulingMode.name() + node-label= + candidates.getPartition()
[ERROR]:Invalid parent directory, throwing PathNotFoundException
[DEBUG]:Skipping 'host' <*> for <*> since it has been blacklisted
[WARN]:Configuration overridingKey=get(overridingKey) is overriding the RM_SCHEDULER_INCREMENT_ALLOCATION_VCORES=get(RM_SCHEDULER_INCREMENT_ALLOCATION_VCORES) property
[ERROR]:Error starting service master
[DEBUG]:taskId + ": Current chunk exhausted. Attempting to pick up new one."
[INFO]:Enabling multicast for Ganglia with TTL ...
[INFO]:Beginning recovery of unclosed segment starting at txid + segmentTxId
[INFO]:Processing the event TASK_ABORT
[INFO]:closeInMemoryFile -> map-output of size: ... , inMemoryMapOutputs.size() -> ... , commitMemory -> ... , usedMemory -> ...
[TRACE]:Exiting getKey method.
[INFO]:Audit log created for failed operation
[ERROR]:e.getCause().getMessage()
[ERROR]:Trying to schedule for a finished app, please double check. nodeId= + node.getNodeID() + container= + reservedContainer.getContainerId()
[INFO]:NNTop conf: + DFSConfigKeys.NNTOP_BUCKETS_PER_WINDOW_KEY + = +
[INFO]:Downloading tarball from: <*> to <*>
[WARN]:Failed to delete test file <*> from persistent memory
[INFO]:Maxed out FS retries. Giving up!
[WARN]:Exit code from container <*> is : <*>
[DEBUG]:SQLException closing resultset: <*>
[INFO]:StreamMonitor got interrupted
[WARN]:Unable to fetch NameNode host information; retrying
[INFO]:Failed to cache + key + : failed to find backing files.
[INFO]:Starting upgrade of edits directory
[DEBUG]:Stopping client
[DEBUG]:Setting the flow name: <*>
[WARN]:Volume provisioning task failed
[INFO]:Temp dir: <*>
[WARN]:Error closing the stream
[DEBUG]:RBW replica created
[DEBUG]:Saving <*> pending commit(s)) to file <*>
[WARN]:Unknown method <*> called on <*> protocol.
[ERROR]:Invalid configuration for YARN_NODEMANAGER_DURATION_TO_TRACK_STOPPED_CONTAINERS default value is 10Min(600000).
[WARN]:Returning, interrupted : e
[INFO]:Loading timeline service state from leveldb
[WARN]:Couldn't determine terminal width, setting to 80
[INFO]:Opportunistic container <*> will be killed to meet NM queuing limits.
[DEBUG]:<*> requested reinit, containerId
[INFO]:Done launching container + masterContainer + for AM + application.getAppAttemptId()
[WARN]:Content of + childNodePath + is broken.
[ERROR]:queue + queueName + is not an leaf queue
[WARN]:Very low remaining capacity in the event-queue of RMContainerAllocator: + remCapacity
[DEBUG]:Codec classes obtained
[INFO]:estimated simulation time is <*> seconds
[DEBUG]:Source <*> doesn't exist. Failing rename.
[ERROR]:Bad persistent memory volume:
[DEBUG]:Stat <*> => <*>, path, status
[DEBUG]:Checking implemented interface's compatibility: <*>
[DEBUG]:Redirecting to URI
[WARN]:meta file <*> is missing!
[DEBUG]:Getting the block pool id
[DEBUG]:Active JournalAndStream detected
[ERROR]:Fencing method + method + misconfigured
[INFO]:POST
[DEBUG]:Connecting to <*>
[WARN]:Cannot heartbeat router <*>: State Store unavailable
[ERROR]:Cannot locate eligible NNs for <*>
[WARN]:Recovered container exited with a non-zero exit code <*>
[TRACE]:Excluded nodes: ...
[WARN]:Failed to renew lease for <*> for <*> seconds. Aborting ...
[ERROR]:Unexpected Event.. <*>
[DEBUG]:Trying to load plugin class <*>
[INFO]:Interrupted while waiting in SPSPathIdProcessor
[INFO]:PUT: update component instance <*> for component = <*> + service = <*> user = <*>
[DEBUG]:Instance directory is <*>
[WARN]:Resource + req + has been removed + and will no longer be localized
[INFO]:Configuration resolved
[INFO]:Interrupted while joining on delayed removal thread.
[INFO]:kvbuffer is null. Skipping flush.
[INFO]:Re-encrypt handler interrupted. Exiting
[WARN]:The Short Circuit Local Read latency, %d ms, is higher then the threshold (%d ms). Suppressing further warnings for this BlockReaderLocal.
[ERROR]:Cannot execute getter <*> on <*>
[INFO]:Cleaning up container <*>
[ERROR]:Disk Balancer - Plan was generated more than <*> ago
[DEBUG]:Upload data block started
[INFO]:This file, <*>/<*>, starts with line <*>.
[INFO]:State Store metrics not enabled
[INFO]:File created with overwrite rule set
[INFO]:Initializing application
[WARN]:DN <*> (<*>) requested a lease even though it wasn't yet registered. Registering now.
[DEBUG]:setScriptExecutable: <*> owner:<*>, script, owner
[DEBUG]:Jvm metrics set
[INFO]:START SERIAL @ ...
[DEBUG]:FileSystemAccess FileSystem configuration:
[INFO]:logRpcIds
[DEBUG]:Get quota usage for path: nsId: <*>, dest: <*>, nsCount: <*>, ssCount: <*>, typeCount: <*>.
[DEBUG]:Application <*> is done, trying to move to done dir <*>, appId, doneAppPath
[WARN]:Overwriting existing file ...
[ERROR]:Unknown event type on UpdateContainer: $<*>
[INFO]:<*> subcluster active, <*> subclusters active and enabled
[INFO]:replaying edit log: 1/10 transactions completed. (10%)
[INFO]:Resolving path <*>
[INFO]:Deletion thread received interrupt, exiting
[INFO]:Set entitlement for AutoCreatedLeafQueue + inQueue + to + queue.getCapacity() + request was (+entitlement.getCapacity()+)
[WARN]:Remote Root Log Dir <*> does not exist. Attempting to create it.
[INFO]:Creating password for identifier: <*>, currentKey: <*>
[INFO]:postComplete for container: + containerId.toString()
[DEBUG]:ioThreadPool.toString()
[DEBUG]:Executing <*>
[INFO]:Virtual memory check enabled: <*>
[INFO]:Skipping copy of <*> to <*>
[WARN]:BR lease 0x<*> is not valid for DN <*>. Expected BR lease 0x<*>.
[ERROR]:Cannot fetch mount table entries from State Store
[ERROR]:Automatic failover is not enabled for localTarget. Please ensure that automatic failover is enabled in the configuration before running the ZK failover controller.
[INFO]:TC configuration is incomplete. Wiping tc state before proceeding
[DEBUG]:Update nonSequentialWriteInMemory by <*> new value: <*>, count, newValue
[TRACE]:<*>: trying to construct a BlockReaderLocal for short-circuit reads., this
[DEBUG]:allocate(arrayLength): count=count, return byte<*>
[INFO]:Recovering storage directory <*> from failed checkpoint
[INFO]:Skipping monitoring container containerId because memory usage is not available.
[INFO]:event.getContainerId() + Container Transitioned from + oldState + to + getState()
[INFO]:logAuditEvent(true, "rename (options=" + Arrays.toString(options) + ")", src, dst, res.auditStat)
[INFO]:Not a recoverable state store. Nothing to recover.
[ERROR]:Error in AMRMClient callback handler
[DEBUG]:Created new DT for <*>
[INFO]:Processed URL ... but app not found (Took ... ms.)
[INFO]:Nodes checked and resources updated
[INFO]:Unchecked exception is thrown from onContainerStopped for Container <*>, thr
[DEBUG]:MEM Comparison:<*> <*>
[DEBUG]:Recovering files with dangling temp data in <*>
[ERROR]:IOException encountered during node publish volume
[DEBUG]:Getting configuration value for cipher suite
[DEBUG]:BLOCK* addBlock: block <*> on node <*> size <*> does not belong to any file
[INFO]:DFSConfigKeys.DFS_DATANODE_FILEIO_PROFILING_SAMPLING_PERCENTAGE_KEY set to $<*>. Enabling file IO profiling
[DEBUG]:Processing <*> of type <*>, event.getNodeId(), event.getType()
[DEBUG]:logRpcIds called
[DEBUG]:DIR* NameSystem.renameTo: with options - src to dst
[INFO]:Opportunistic allocation requested for <*> allocated = <*>
[INFO]:Namespaces retrieved
[ERROR]:Error while creating Timeline Schema : , e
[INFO]:strict preemption : X containers to kill
[DEBUG]:Invalidating <*> from <*>
[INFO]:assignedContainer queue= getQueuePath() usedCapacity= getUsedCapacity() absoluteUsedCapacity= getAbsoluteUsedCapacity() used= queueUsage.getUsed() cluster= cluster
[DEBUG]:Running URLRunner
[DEBUG]:Decrease reference count <= 0 on ...
[DEBUG]:Skips encoding and writing parity cells as there are no healthy parity data streamers: streamers
[DEBUG]:Sender: Block replaced
[INFO]:Renaming temporary target file path <*> to <*>
[ERROR]:Unable to mark container <*> killed in store <*>
[INFO]:<*> : docker inspect output <*>
[INFO]:Killing container <*>
[DEBUG]:Ignoring container completion status for unmanaged AM <*>
[WARN]:Unable to determine address of the host -falling back to 'localhost' address
[INFO]:Attempting to get RMApp for appId
[DEBUG]:Ignoring abort() as stream is already closed
[DEBUG]:before vMemCheck <*>
[DEBUG]:Exception in getKeysmetadata.
[DEBUG]:Not retrying anymore, already retried the urls <*> time(s)
[WARN]:Exception while reading from ...
[INFO]:op=GETXATTRS target=path
[DEBUG]:Creating filter configuration
[INFO]:Container + containerId + belongs to an application that is already killed, + no further processing
[WARN]:This committer will abort these uploads in job cleanup
[INFO]:<*>: Validating output.
[DEBUG]:Removed connection <*> used <*> seconds ago. Pool has <*>/<*> connections
[DEBUG]:Disabling cipher suite <*>.
[WARN]:Received exception in Datanode#join: <*>
[DEBUG]:Setting the flow run id: <*>
[INFO]:Allowed RPC access from <*> at <*>
[DEBUG]:Finished submitting vectored read to threadpool on path <*> for ranges <*>, pathStr, ranges
[ERROR]:Syntax error in URI + s + . Please check hdfs configuration.
[ERROR]:Fail to start application:
[ERROR]:Couldn't get the new Status, e
[INFO]:Successfully loaded <*> inodes
[WARN]:Detailed error code not set by server on rpc error
[WARN]:The quota calculated for the cgroup was too low. The minimum value is MIN_PERIOD_US, calculated value is quotaUS. Setting quota to minimum value.
[INFO]:Deleting all children under <*>
[DEBUG]:Target node's reservation status changed, moving cancelled.
[INFO]:Killing map task
[DEBUG]:deleteCGroup: <*>, cGroupPath
[ERROR]:Services initialization failure, destroying initialized services
[ERROR]:Cannot heartbeat router <*>
[DEBUG]:Attempt to authorize path
[INFO]:Adding job token for + oldJobIDString + to jobTokenSecretManager
[WARN]:Service did not shut down in time
[INFO]:Initializing audit logger <*>
[DEBUG]:No ACL available for key, denying access for <*>
[INFO]:Checked operation WRITE
[INFO]:Scheduling Request <*> has been rejected. Reason <*>
[DEBUG]:Found ancestor <*>, for path: <*>, ancestor.toString(), f.toString()
[INFO]:Finalizing upgrade for storage directory <*>.\n cur LV = <*>; cur CTime = <*>
[DEBUG]:doGetGroups(<*>) returned no groups because the user is not found.,user
[DEBUG]:HTTP request read bytes = <*>
[INFO]:Node health check passed
[WARN]:Failed attempt to delete cgroup: <*>
[INFO]:Max mem capability of resources in this cluster
[ERROR]:$<*>
[WARN]:Error executing shell command + shexec.toString() + ioe
[TRACE]:Execution trace
[INFO]:Deleted State Store record <*>: <*>
[INFO]:Queue + queueName + is not present
[DEBUG]:NULL Username specified for Store connection, so ignoring
[WARN]:Failed to delete image file: <*>
[ERROR]:Retrieving COS key: <*> with byteRangeStart: <*> occurs an exception: <*>.
[ERROR]:Application: <*> is not found
[INFO]:Skipping creating directory for block pool <*> for PROVIDED storage location <*>
[DEBUG]:No version ID to use as a constraint
[DEBUG]:Looking for a token with service <*>
[INFO]:Number of files = numFiles
[DEBUG]:Tracking duration of supplier
[INFO]:No output committer factory defined, defaulting to FileOutputCommitterFactory
[INFO]:hsync failed when processing possible perfect overwrite, path=<*> error: <*>, path, e.toString()
[DEBUG]:User rule: parent rule result: <*>
[ERROR]:<*> Missing entry for job + job.getJob().getJobID()
[ERROR]:Unknown localization event:
[DEBUG]:allocate: applicationId=<*> container=<*> host=<*> user=<*> resource=<*> type=<*>
[DEBUG]:Unregistering <*>
[INFO]:Starting upgrade of local storage directories. old LV = ...; old CTime = ... new LV = ...; new CTime = ...
[DEBUG]:File <*> skipped re-encryption because edek's key version name is not changed.
[ERROR]:Unable to remove application from state store
[WARN]:Cannot release the path <*> in the lease <*>. It will be retried.
[DEBUG]:Path to resolve: + pathStrToResolve + , srcPattern: + getSrcPathRegex()
[INFO]:Cancelled image saving for + sd.getRoot() + : + snce.getMessage()
[INFO]:AppNameMappingPlacementRule applied
[ERROR]:Failed to shutdown ScheduledExecutorService
[INFO]:Setting classloader + classLoader + on the configuration and as the thread context classloader
[WARN]:<*> does not appear to be a valid URL
[DEBUG]:When shutting down
[INFO]:op.name() + " labels on nodes:"
[INFO]:Stopping JobHistoryEventHandler. Size of the outstanding queue size is <*>
[DEBUG]:"Deferring response for callId: " + this.callId
[DEBUG]:Bootstrapping resource handler chain: <*>
[INFO]:All AsyncDiskService threads are terminated.
[DEBUG]:delete: Path is a directory: <*>
[DEBUG]:Sending Heartbeat to RM. AskList:<*>
[ERROR]:Error While Storing CA Certificate and Private Key, e
[DEBUG]:Reported block <*> on <*> size <*> replicaState = <*>
[ERROR]:TGT is destroyed. Aborting renew thread for <*>
[INFO]:BPOfferService + this + interrupted while + stateString
[ERROR]:Unable to free lease on key
[INFO]:Creating state database at + dbfile
[ERROR]:Could not initialize shared edits dir
[INFO]:Recovering node labels
[ERROR]:Could not create paxos dir: <*>
[DEBUG]:Send buf size <*>
[WARN]:Got an overlapping write <*>, nextOffset=<*>. Remove and trim it
[DEBUG]:FSSTAT operation initiated
[INFO]:Storing reservationallocation for <*> for plan <*>
[INFO]:Node <*> is sufficiently replicated and healthy, marked as <*>.
[ERROR]:Error in restarting application:
[ERROR]:Error when reading history file of container
[INFO]:Need to stop the specific queue: + queueName + first.
[INFO]:Superuser privileges verified
[DEBUG]:Found volume name for GPU:<*>
[WARN]:Shutdown called twice for AMRMClientRelayer for RM + this.rmId
[INFO]:Queue info: queueName=<*>, queueCurrentCapacity=<*>, queueMaxCapacity=<*>, queueApplicationCount=<*>, queueChildQueueCount=<*>
[INFO]:KMSClientProvider Decryption successful
[DEBUG]:storeAssignedResources: containerId= + container.getContainerId() + , assignedResources= + StringUtils.join(",", assignedResources)
[WARN]:Cannot initialize /lost+found .
[INFO]:Starting JVM pause monitor
[DEBUG]:All entries in batch were filtered...continuing
[INFO]:Parsed constraint: <*>
[ERROR]:Error in handling event type <*> for applicationAttempt <*> with <*>
[DEBUG]:Getting Resource Memory Size
[INFO]:Sorry, can't do anything without a JobID.
[ERROR]:JournalNode Proxy not found.
[WARN]:collectors are added when the registered collectors are initialized
[INFO]:Job Overview
[INFO]:Deleted zookeeper path: + zkPath
[WARN]:Logout failed while disconnecting, error code -
[INFO]:Container start failed event attempted to publish
[INFO]:Using hbase configuration at + timelineServiceHBaseConfFilePath
[ERROR]:Received finished container : <*> for unknown application <*> Skipping.
[INFO]:Initializing user <*>
[WARN]:Specified cache depth was less than or equal to zero. Using default value instead. Default: <*>, Specified: <*>
[DEBUG]:New write buffered with xid <*> nextOffset <*> req offset=<*> mapsize=<*>
[INFO]:aggregated log deletion started.
[INFO]:Replacing FAST_FAIL_MAP container
[WARN]:Stop interrupted
[INFO]:Expecting " + numRecordsRemainingInSplit + " records each with a length of " + recordLength + " bytes in the split with an effective size of " + splitSize + " bytes
[DEBUG]:Deleting dangling file <*>
[DEBUG]:Stopping service #i: <*>
[INFO]:msgPrefix + PendingReds: + numPendingReduces + ScheduledMaps: + numScheduledMaps + ScheduledReds: + numScheduledReduces + AssignedMaps: + numAssignedMaps + AssignedReds: + numAssignedReduces + CompletedMaps: + numCompletedMaps + CompletedReds: + numCompletedReduces + ContAlloc: + numContainersAllocated + ContRel: + numContainersReleased + HostLocal: + hostLocalAssigned + RackLocal: + rackLocalAssigned
[INFO]:All applications in FINISHED state
[DEBUG]:REL PATH: <*>, FULL PATH: <*>
[DEBUG]:RMAppManager processing event for applicationId of type UNKNOWN
[DEBUG]:Delete Successful for : <*>
[DEBUG]:retry #<*>
[ERROR]:Platform is not supported:OS. Can't update user map and group map and 'nobody' will be used for any user and group.
[WARN]:Could not find a target for file
[ERROR]:HttpServer fails to shut down!
[INFO]:Waiting until the NameNode rolls its edit logs in order to freeze the BackupNode namespace.
[INFO]:Total Pmem allocated for Container
[DEBUG]:updateChildQueues (action: add queue): + added + + getChildQueuesToPrint()
[INFO]:Creating a new database at th path: <*>
[ERROR]:Specified queue name not valid: '<*>'
[INFO]:movedContainer queueMoveIn=... usedCapacity=... absoluteUsedCapacity=... used=... cluster=...
[INFO]:Number of transactions: <*> Total time for transactions(ms): <*> Number of transactions batched in Syncs: <*> Number of syncs: <*> SyncTimes(ms): <*>
[INFO]:TC configuration is already in place. Not wiping state.
[INFO]:Audit log updated
[INFO]:Preconditions check for interval
[DEBUG]:getFilesystemProperties for filesystem: <*>
[INFO]:Node with node id : + nodeId + has shutdown, hence unregistering the node.
[INFO]:Exception while canceling delayed flush timer. Likely caused by a failed flush <*>
[DEBUG]:Closed potentially stale remote peer
[INFO]:Trying to discover GPU information ...
[DEBUG]:Propagating entries under <*>
[DEBUG]:Opening file: <*> for append
[INFO]:Completed reading history information of container
[DEBUG]:Change nextOffset (after trim) to <*>
[INFO]:Creating RMProxy to RM <*> for protocol <*> for user <*>
[WARN]:Gave up waiting for the app check task to shutdown.
[DEBUG]:Cancelling token <*>
[TRACE]:Got batchedListing: <*>
[INFO]:Status reporter thread exiting
[INFO]:Results of dry run:
[INFO]:Skipping <*> due to existing .har file
[ERROR]:Fail to stop application:
[INFO]:History url is <*>
[INFO]:write temp configuration to fileSystem took + (Time.monotonicNow() - start) + ms
[DEBUG]:Exception , ie
[DEBUG]:Copied <*> to <*>
[INFO]:Killing application appId
[DEBUG]:Getting interceptor chain
[ERROR]:AzureBlobFileSystemException thrown
[DEBUG]:Loaded delegation key: keyId=<*>, expirationDate=<*>
[DEBUG]:backing jks path initialized to ...
[INFO]:Log handler container finished
[INFO]:Queue x already has n applications, cannot accept submission of application: y
[WARN]:Unrecognized attribute value for HADOOP_SECURITY_AUTHENTICATION of <*>
[DEBUG]:Setting the flow version: <*>
[ERROR]:Key type not supported. Cannot find serializer for
[DEBUG]:val + is a zero-length value
[DEBUG]:Attempted to delete a non-existing znode <*>
[WARN]:Missing SubCluster State information. Please try again by specifying SubCluster State information.
[WARN]:Unable to create a new ApplicationId in SubCluster <*>
[INFO]:Operation completed
[WARN]:Intel FPGA for OpenCL diagnose failed!
[WARN]:Failed to shut down socket in error handler, e
[INFO]:Opened history file of application X
[DEBUG]:Current detector state <*>, the detected nodes: <*>.
[INFO]:Added Application Attempt + appAttemptId + to scheduler from user + application.getUser()
[INFO]:Renewed token for + appId + with new expiration + timestamp = + newExpirationTime
[WARN]:Can not read a null symLink
[DEBUG]:Got commit status: <*>
[INFO]:YARN sysfs synchronized.
[DEBUG]:Storing info for app: <*> at: <*>
[INFO]:Resuming the container <*>
[TRACE]:Entering getKeyVersion method.
[INFO]:Added new job with <*> streams, running for <*>
[WARN]:failed to get ...
[WARN]:Failed to shutdown the request processing pipeline for app:<*>, ex=""
[INFO]:Relaunching Container <*>. retry interval <*> ms
[INFO]:Localizer started on port + server.getPort()
[INFO]:Removing StorageLocation <*> with id <*> from FsDataset.
[INFO]:Provide <*>
[WARN]:aocl output is: ...
[DEBUG]:Stream <*> aborted: <*>; remaining=<*>
[INFO]:Exiting...
[INFO]:rpcClient.invokeSequential executed
[INFO]:onContainerResourceUpdated: <*>, <*>
[ERROR]:Error putting entities
[ERROR]:Error running Client
[INFO]:Starting SPSPathIdProcessor!.
[WARN]:Failed to cancel token <*> <*>
[INFO]:Clean up complete and service stopped
[DEBUG]:Encountered exception during uploading block for Blob <*> Exception : <*>
[ERROR]:Response from the timeline reader server is ...
[INFO]:Getting container-status for + containerIDStr
[INFO]:Appending SAS token to query
[INFO]:Reserved Memory: memoryHere
[DEBUG]:Auth parameters added for proxy user
[WARN]:Failed to choose target datanode for the required storage types <*>, block:<*>, existing storage type:<*>
[INFO]:removeCachePool of + poolName + failed: , e
[INFO]:Cleaning up temporary work folder: +
[ERROR]:Application <*> has one container killed (<*>).
[INFO]:Updating RMDelegationToken and SequenceNumber
[INFO]:Block pool storage directory for location ... does not exist
[INFO]:Device: major: <*>, minor: <*>, devNo: <*>, type: <*>
[DEBUG]:Handling Container Start Monitoring Event
[DEBUG]:Reflecting instance of the reducer class
[DEBUG]:Removing RMDelegationToken_<*>
[INFO]:StreamBaseRecordReader.init: start_=start_ end_=end_ length_=length_ start_ > in_.getPos() = (start_ > in_.getPos()) start_ > in_.getPos
[INFO]:Unexpected filter type
[WARN]:Unable to initialize MapOutputCollector + clazz.getName() + " (" + remainingCollectors + " more collector(s) to try)"
[INFO]:logAuditEvent: operationName, src
[INFO]:Conversion rules file is not defined, + using default conversion config!
[WARN]:Couldn't find application + applicationId
[DEBUG]:Verifying access-type <*> for <*> on application <*> owned by <*>
[INFO]:Application Master failed. exiting
[TRACE]:Rejecting interaction; no rule found
[WARN]:Unable to update diagnostics in state store for <*>, e
[INFO]:Ignoring obsolete output of <*> map-task: '<*>'
[INFO]:JVM with ID: + jvmId + is invalid and will be killed.
[ERROR]:Couldn't fence old active + target, e
[ERROR]:Throwable Exception in doCheckpoint:
[INFO]:Cannot rollback resource for container + containerId + . The container does not exist.
[DEBUG]:Set erasure coding policy <*> on <*>
[INFO]:Watcher for tokens is disabled in this secret manager
[INFO]:Storage version updated
[WARN]:Unable to process container ports mapping: <*>
[ERROR]:onStopContainerError received unknown containerID: + containerId
[DEBUG]:Name checkpoint time is newer than edits, not loading edits.
[DEBUG]:Tailing edits starting from txn ID + fromTxnId + via RPC mechanism
[DEBUG]:Storage policy satisfier is not enabled, ignoring
[INFO]:cleanUpPartialOutputForTask: removing everything belonging to + context.getTaskAttemptID().getTaskID() + in: + getCommittedTaskPath(context).getParent()
[INFO]:Insecure cluster detected
[DEBUG]:Ignoring job <*> from the input trace. Reason: <*>
[WARN]:Failed to close the timeline tables as Hbase is down
[WARN]:Interrupted before adjusting thread count: <*>
[DEBUG]:Directive <*>: caching <*>: <*>/<*> bytes
[WARN]:Received an invalid request file transfer request from a secondary with storage info <*>
[INFO]:After major compaction for qualifier= with currentColumnCells.size= returning finalCells.size= with sum=
[WARN]:No eviction candidate. All streams have pending work.
[DEBUG]:Create parent key: <*>
[ERROR]:Interrupted freeing leases
[ERROR]:No component exists for <*>
[DEBUG]:Response <*>
[INFO]:Minimum allocation = + ret
[INFO]:String.format(STATE_CHANGE_MESSAGE, appID, oldState, getState(), event.getType())
[INFO]:Starting CacheReplicationMonitor with interval <*> milliseconds
[INFO]:Periodic Directory Tree Verification scan starting in <*>ms with interval of <*>ms and throttle limit of <*>ms/s
[WARN]:Metric name <*> was emitted with a null value.
[ERROR]:The endTxId of the temporary file is not less than the last committed transaction id. Aborting move to final file <*> ; journal id: <*>
[ERROR]:Could not start proxy web server
[DEBUG]:using docker's cgroups options
[INFO]:Removing aux service
[DEBUG]:Container pre-start checks completed
[WARN]:Fencing method + method + was unsuccessful.
[DEBUG]:writeTo blockfile is ... of size ...
[DEBUG]:Retrieving Container SAS URI For <*>@<*>
[DEBUG]:Seeking if required
[DEBUG]:Html block rendering initiated
[DEBUG]:Setting erasure coding policy
[WARN]:Starting late by <*> ms
[INFO]:the collector for + appId + already exists!
[DEBUG]:allocate: applicationId=applicationAttemptId #ask=ask.size()
[INFO]:<*> allows retrying failed subclusters in <*>
[DEBUG]:Terminating container <*> Sending SIGKILL to -<*>
[DEBUG]:Closed <*>
[DEBUG]:Setting App ID: <*>
[INFO]:A checkpoint was triggered but the Standby Node has not received any transactions since the last checkpoint at txid <*>. Skipping...
[INFO]:Setting the includes file to <*>
[INFO]:Listening on UNIX domain socket: <*>
[WARN]:DIR* FSDirectory.unprotectedRenameTo: rename destination <*> already exists
[INFO]:Satisfy storage policy
[DEBUG]:Signer override = <*>
[DEBUG]:Pattern: <*>
[ERROR]:Async data service got error: , t
[DEBUG]:reading next wrapped RPC packet
[WARN]:Group + groupName + is deprecated. Use + newGroupName + instead
[INFO]:Found <*> directories in INode section.
[ERROR]:No commands found for line <*>
[DEBUG]:Forwarding allocate request to the Distributed Scheduler Service on YARN RM
[DEBUG]:Stopping metrics source <*>: class=<*>
[WARN]:I/O error while finding block <*> on volume <*>
[WARN]:Exception while getting file is for the given path:<*>
[INFO]:Finalize upgrade for + sd.getRoot() + is complete.
[INFO]:Deleting markers
[DEBUG]:Updating State Store cache
[DEBUG]:Client using encryption algorithm <*>
[WARN]:Unable to persist blocks in hflush for
[INFO]:Nonpositive dircount in invalid READDIRPLUS request: <*>
[DEBUG]:Invocation of <*> using <*> was successful
[ERROR]:Current thread: <*>, COS key: <*>, upload id: <*>, part num: <*>, exception: <*>
[DEBUG]:Cannot rename a directory to a subdirectory of self
[DEBUG]:New instance created
[DEBUG]:Interrupted while waiting to put on response queue, ex
[WARN]:Failed to delete as user <*>
[ERROR]:The thread of + eventDispatcherThread.getName() + didn't finish normally., e
[INFO]:The background thread stopped.
[INFO]:Moving aside edit log file that seems to have zero transactions elf
[INFO]:Create delegation token request failed
[INFO]:Suggested mapreduce.application.classpath $PWD/ + alias + /*
[WARN]:Could not store container <*> state. The Container has been paused.
[ERROR]:Failed to move aside pre-upgrade storage in image directory + sd.getRoot()
[INFO]:Application completed. Signalling finished to RM
[DEBUG]:Renewing delegation token
[ERROR]:Exception in secureMain
[INFO]:HSAuditLogger log success
[DEBUG]:Remove volume method invoked
[WARN]:Unknown key ..., remove and move on
[DEBUG]:Container <*> has completed
[INFO]:Added filter (name) (class=classname) to context ctx.getDisplayName()
[DEBUG]:Retrieved log file details for task
[DEBUG]:Touching success marker for job <*>: <*>, markerPath, successData
[ERROR]:Expected tag end event for <*>, but got: <*>
[INFO]:getResources() for applicationId: ask= ask.size release= release.size newContainers= allocateResponse.getAllocatedContainers().size finishedContainers= numCompletedContainers resourcelimit= availableResources knownNMs= clusterNmCount
[INFO]:BlocksStorageMovementAttemptMonitor thread is interrupted.
[DEBUG]:Picked ... as the ClientProtocolProvider
[INFO]:Service dependency is not satisified.
[DEBUG]:DIR* NameSystem.completeFile: String srcArg for String holder
[DEBUG]:HA configuration set and verified
[WARN]:Exception running child ...
[WARN]:Interrupted deletion of <*>
[DEBUG]:RPC Server's Kerberos principal name for protocol= + protocol.getCanonicalName() + is + serverPrincipal
[INFO]:Initializing AMS Processing chain. Root Processor=<*>.
[DEBUG]:command finished for <*> ms
[ERROR]:Cannot get data for <*> at <*>, cleaning corrupted data
[INFO]:Requested NameNode ask: %s
[WARN]:The format isn't valid. Min threshold falls back to the default value $<*>
[INFO]:Executor service shutdown
[INFO]:STATE* Network topology has <*> racks and <*> datanodes
[WARN]:FSDirectory.addChildNoQuotaCheck - unexpected
[DEBUG]:Policy initialization complete
[INFO]:<*> configured as false. Blob metadata will be treated case insensitive.
[INFO]:Allocating asynchronously to sub-cluster via UAM pool
[INFO]:Node <*> in DECOMMISSIONING is recommissioned back to RUNNING.
[DEBUG]:Configuring client
[INFO]:ContainerStatus: <*>
[DEBUG]:Skipping unreserve on removed node: <*>
[DEBUG]:Decreasing replication from <*> to <*> for <*>
[ERROR]:URL does not contain a service specification:
[WARN]:Clusterid mismatch - current clusterid: <*>, Ignoring given clusterid: <*>
[INFO]:Failing application attempt + attemptId
[DEBUG]:Updating attr cache...
[INFO]:<*> configured to be <*>, should be positive. Using default of <*>.
[DEBUG]:Creating split : + split + , bytes in split: + currentSplitSize
[ERROR]:Couldn't create parents for <*>, src
[DEBUG]:BP offer service run start time: <*>, sendHeartbeat: <*>
[INFO]:hostsReader include:<*> exclude:<*>
[INFO]:JVM metrics initialized
[DEBUG]:Setting up servlets
[DEBUG]:Using plugin jars: <*>
[WARN]:Thread.currentThread().getName(), call call: output error
[INFO]:Block token params received from NN: for block pool <*> keyUpdateInterval=<*> min(s), tokenLifetime=<*> min(s)
[INFO]:Connection closed by client...
[ERROR]:Could not stop KeyCache
[INFO]:End step SAVING_CHECKPOINT
[INFO]:Adding component <*> from external <*>
[DEBUG]:Received stat error from Zookeeper. code: + code.toString()
[ERROR]:Rename object unsuccessfully. source cos key: <*>, dest COS key: <*>, exception: <*>
[ERROR]:SubCluster does not exist; cannot heartbeat
[DEBUG]:Adding default headers
[DEBUG]:Node Labels <*> from Node <*> were Accepted from RM
[DEBUG]:getMapOutputInfo: jobId= + jobId + , mapId= + mapId + ,dataFile= + pathInfo.dataPath + , indexFile= + pathInfo.indexPath
[DEBUG]:read ahead disabled, reading remote
[DEBUG]:Loading filter handler <*>
[WARN]:Fsck on blockId
[INFO]:Inactive with pending write
[INFO]:name thread interrupted.
[DEBUG]:No delegation token for this instance
[WARN]:Directly referencing AWS SDK V1 credential provider <*>. AWS SDK V1 credential providers will be removed once S3A is upgraded to SDK V2
[INFO]:DNS Service added
[INFO]:schedulerConfDir=...
[ERROR]:Cannot initialize the ZK connection
[INFO]:Rss mem usage in bytes <*>
[INFO]:Lost Nodes: countHere
[INFO]:Resuming re-encrypt handler for testing.
[WARN]:Failure: removeCachePool, <*>}, false
[DEBUG]:persistBlocks: <*> with <*> blocks is persisted to the file system
[INFO]:Application mapping log details
[DEBUG]:Encountered exception during execution of command for Blob : + <*> Exception : <*>
[DEBUG]:addResourceRequest: applicationId=
[DEBUG]:Check operation
[INFO]:recovered container + id + from previous attempt + rmContainer.getApplicationAttemptId()
[WARN]:Exception during shutdown:
[INFO]:Start moving + this
[DEBUG]:Initiate multipart upload to <*>
[DEBUG]:App state before killing logged
[INFO]:Writing credentials to the nmPrivate file
[ERROR]:Unsupported protocol found when creating the proxy connection to NameNode:
[INFO]:Caught InterruptedException while scheduling replication work for mis-replicated blocks
[INFO]:Path: <*> added multiple times, ignoring the redundant entry.
[INFO]:Uploading logs for container + containerId + ". Current good log dirs are " + StringUtils.join(",", dirsHandler.getLogDirsForRead())
[DEBUG]:Fields parameter is empty, defaulting to INFO
[ERROR]:Error creating rate metrics for methodName
[DEBUG]:Removing state for reservation <*> plan <*> at <*>
[DEBUG]:Incremented counter StreamStatisticNames.BYTES_READ_BUFFER by <*>
[ERROR]:Fail to save application: , e
[DEBUG]:Cache new enough, skip refreshing
[INFO]:RegistryOperationsService added
[INFO]:Waiting on availability of NameNode information at %s
[DEBUG]:Decryption process started
[WARN]:Failed to match regex: regex Current state: state
[ERROR]:The specified Reservation with ID ... is not mapped to any user
[DEBUG]:removed previousRange
[TRACE]:Cache report from datanode <*> has block <*>
[DEBUG]:setsid exited with exit code (shexec != null ? shexec.getExitCode() : "(null executor)")
[DEBUG]:Writing domains for <*> to <*>
[ERROR]:Throwable Exception in doCheckpoint
[WARN]:Failed to delete restart meta file: <*>
[DEBUG]:refreshLocatedBlock for striped blocks, offset= ...
[INFO]:Initialized NMTimelinePublisher UGI to <*>
[INFO]:None of the responders had a log to recover: + QuorumCall.mapToString(prepareResponses)
[ERROR]:Unable to cleanup tmp dir: <*>, <*>
[DEBUG]:Verifying user access
[DEBUG]:Operation: + cmd + Status: + succeeded + TokenId: + tokenId
[INFO]:Concurrent invocation success
[INFO]:Directory <*> passed disk check, adding to list of valid directories.
[WARN]:Cannot parse counter line: + line
[INFO]:Action set for property: DYNAMIC_MAX_ASSIGN
[INFO]:<*>: Dependencies satisfied, ramping up.
[INFO]:Stopped applying edits to prepare for checkpoint.
[INFO]:Cache directive written
[INFO]:Starting up router
[ERROR]:BUG: Found lastValidNode <*> but not nth valid node. parentNode=<*>, excludedScopeNode=<*>, excludedNodes=<*>, totalInScopeNodes=<*>, availableNodes=<*>, nthValidToReturn=<*>, lastValidNode, parentNode, excludedScopeNode, excludedNodes, totalInScopeNodes, availableNodes, nthValidToReturn
[DEBUG]:Ignoring exception: <*>
[WARN]:Shuffle secret key missing from job credentials. Using job token secret as shuffle secret.
[WARN]:comment + message
[WARN]:-s is a deprecated option. Ignoring.
[DEBUG]:getNewApplication try #<*> on SubCluster <*>, i, subClusterId
[DEBUG]:Replacing token for : <*>
[INFO]:====== Beginning Service Fencing Process... ======
[ERROR]:Interrupt the part upload.
[WARN]:Message received before authentication is complete. Ignoring
[DEBUG]:load job token from a file
[DEBUG]:Logs rolled while catching up to current segment
[ERROR]:Failed to clean old logs
[INFO]:Alias has been successfully created.
[ERROR]:Error starting ResourceEstimatorServer
[INFO]:Cleaner interrupted
[WARN]:Error stopping the metrics system
[ERROR]:Error while removing reservation allocation., e
[WARN]:Unable to stop existing writer for block + b + after + writerStopMs + miniseconds.
[DEBUG]:Marking container <*> as inactive
[DEBUG]:NMToken password retrieved successfully!!
[ERROR]:Please specify the policy name.
[DEBUG]:Initializing priority preemption directed graph:
[WARN]:Exception running <*>, <*>
[ERROR]:Must provide a filename to all commands.
[INFO]:Request to remove more resources than what is available
[WARN]:Failed to delete the mapped File: <*>!
[INFO]:File system output stream created
[ERROR]:Fencing is not configured for localTarget.\nYou must configure a fencing method before using automatic failover.
[DEBUG]:SASL server skipping handshake in secured configuration for peer = <*>, datanodeId = <*>
[INFO]:Using pure-Java version of bzip2 library
[WARN]:Job setup failed, e
[INFO]:Got exception while pausing container: <*>
[DEBUG]:added + recRange
[ERROR]:Master key updating failed: (IOException e)
[INFO]:Got brand-new decompressor <*>
[WARN]:msg
[DEBUG]:Scan failed
[ERROR]:Can't handle this event at current state: Current: <*> eventType: <*>, container: <*>
[DEBUG]:auditing is disabled
[INFO]:Issuing kill to other attempt
[INFO]:Error storing info for RMDelegationToken: + rmDTIdentifier
[DEBUG]:Using exact match for 'host' and READ_ONLY
[DEBUG]:Processing dirDiffEntry
[ERROR]:Error in storing RMDelegationToken with sequence number
[TRACE]:<*> is stale because it's <*> ms old and staleThreadholdMS=<*>
[ERROR]:Unable to de-serialize block token identifier for user=userId, block=block, access mode=mode
[WARN]:Unable to create timeline client for app + appId, e
[INFO]:op=GETACLSTATUS target=path
[ERROR]:A problem was encountered while calculating resource availability that should not occur under normal circumstances. Please report this error to the Hadoop community by opening a JIRA ticket at http://issues.apache.org/jira and including the following information:\n* Exception encountered: <*>* Cluster resources: <*>\n* LHS resource: <*>\n* RHS resource: <*>
[WARN]:Unable to execute <*>
[INFO]:createSuccessLog(user, operation, target, null, null, null, null)
[INFO]:Removing block level storage: <*>
[DEBUG]:Saving namespace context
[ERROR]:Finalize upgrade for <*> failed
[DEBUG]:RegexMatcher 'pattern', allowing client 'address', 'hostname'
[WARN]:Failed to connect to ... for file ... for block ..., add to deadNodes and continue.
[WARN]:Failed to add storage directory <*>
[ERROR]:Can not find log metadata for container: <*>
[DEBUG]:Building HTTP server
[WARN]:Shutdown() is called but there are still unprocessed work!
[DEBUG]:UnresolvedPathException path: $<*> preceding: $<*> count: $<*> link: $<*> target: $<*> remainder: $<*>
[INFO]:Storing RM state version info <*>
[WARN]:AM Memory not specified, use <*> mb as AM memory
[WARN]:<*> gave an invalid proxy path <*>, remoteUser, pathInfo
[INFO]:Creating PlacementRule implementation: + ruleClass
[WARN]:<*> failed for <*> : <*>
[DEBUG]:Created keytab: keytabFile
[INFO]:Error in processing cluster status at <*>
[INFO]:Rollback of sd.getRoot() is complete
[INFO]:------------------------------------
[ERROR]:Native-Task doesn't support sort class
[DEBUG]:User: <*>, Type: <*> Result: <*>
[WARN]:User <*> doesn't have permission to call '<*>'
[INFO]:Created Certificate for <*>
[WARN]:The Auxiliary Service named <*> in the configuration...
[INFO]:transferBlock <*> received exception <*>
[INFO]:Down to the last merge-pass, with N segments left of total size: M bytes
[INFO]:Whitelisted <*>
[INFO]:<*>: scaling up from + before + to + event.getDesired()
[WARN]:Failed to create symlink: %s <- %s
[WARN]:Error reading the stream /sys/block/diskName/queue/hw_sector_size
[WARN]:Unable to delete cgroup at: <*> , tried to delete for <*> ms
[INFO]:Container resources localized
[DEBUG]:Deleting key with name <*>., name
[DEBUG]:Adding trackID:<*> for the file id:<*> back to retry queue as some of the blocks are low redundant.
[ERROR]:File not found exception caught
[DEBUG]:AFTER decResourceRequest: allocationRequestId= + req.getAllocationRequestId() + priority= + priority.getPriority() + resourceName= + resourceName + numContainers= + resourceRequestInfo.remoteRequest.getNumContainers() + #asks= + ask.size()
[DEBUG]:returning null
[DEBUG]:NFS PATHCONF fileHandle: <*> client: <*>, handle.dumpFileHandle(), remoteAddress
[WARN]:I/O error finding interface <*>
[WARN]:Failed to reconstruct striped block: <*>, <*>
[INFO]:Using FileSystemAccess JARs version <*>
[INFO]:Fail to connect to: <*>
[TRACE]:Initializing <*>,
[ERROR]:Error aggregating log file. Log file : someFilePath. Some exception message.
[TRACE]:skip(n=<*>, block=<*>, filename=<*>): discarded <*> bytes from dataBuf and advanced dataPos by <*>
[DEBUG]:Making dir: <*> in COS
[WARN]:Last block length <*> is less than reportedLastBlockSize <*>, length - sumBlockLengths, reportedLastBlockSize
[WARN]:Manifest file + manifest + doesn't exist
[INFO]:Size of event-queue in RMContainerAllocator is <*>
[DEBUG]:GetMapEventsThread about to sleep
[DEBUG]:NFS READLINK fileHandle: <*> client: <*>
[WARN]:Ignored <*> only jars are supported
[ERROR]:Unable to start failover controller. Parent znode does not exist.\nRun with -formatZK flag to initialize ZooKeeper.
[INFO]:Putting shuffle token in serviceData
[WARN]:may result in an incomplete import.
[DEBUG]:Checking superuser privilege
[ERROR]:Fail to shell to container: + t.getMessage()
[ERROR]:The interceptor for SubCluster <*> does not exist in the cache.
[WARN]:No Kerberos principal name specified for service.getName()
[WARN]:Only a single tag can be associated with a placement constraint currently.
[DEBUG]:Initiating commit for multipart upload
[DEBUG]:Time taken to process <*> files count for <*> operation: <*> ms
[ERROR]:Could not create exception <*>, <*>
[WARN]:Error while decoding:otherInfo
[ERROR]:Container <*> + re-initialization failure..
[WARN]:Could not get valid <*> device for container '<*>' as some other containers might not releasing them.
[INFO]:bufstart = <*>; bufvoid = <*>
[INFO]:ignore signal command x
[INFO]:Allowed GPU devices: + gpuDevices
[WARN]:Recovered container exited with a non-zero exit code $<*>
[DEBUG]:checkStreamers: ... <*>
[DEBUG]:PrimaryGroup rule: parent rule found: <*>
[DEBUG]:Using subject: ...
[INFO]:getECTopologyResultForPolicies called
[TRACE]:UserPasswordTokenProvider initialized
[INFO]:Loaded + counter + directories
[DEBUG]:cleanup magic directory Path
[DEBUG]:computePartialChunkCrc for block: sizePartialChunk=sizePartialChunk, block offset=blkoff, metafile offset=ckoff
[DEBUG]:Task report added]]>
[ERROR]:Unknown event arrived at FairScheduler
[DEBUG]:Disk Segment added to List. Size is <*>
[DEBUG]:Adding trackID:<*> for the file id:<*> back to retry queue as some of the blocks movement failed.
[ERROR]:Expected tag end event for <*>, but got tag end event for <*>
[INFO]:Application <*>'s AM is going to be killed. Waiting for rescheduling...
[INFO]:Ending log segment
[ERROR]:Invalid NFS Exports provided:
[TRACE]:Proceeding with interaction since the request doesn't access WebHDFS API
[WARN]:Portmap mapping registration failed, accept state: + acceptState
[INFO]:Next rolling time for + getName() + is + fdf.format(nextRollingCheckMillis)
[DEBUG]:Audit Event: removeAcl success
[WARN]:Failed to delete file or dir <*>: it still exists.
[DEBUG]:Setting input paths
[INFO]:<*>: Cannot cancel the upgrade in <*> state
[INFO]:DefaultSpeculator.addSpeculativeAttempt -- we are speculating + taskID
[WARN]:Failed to remove SPS xattr for track id <*>
[WARN]:Error synchronize YARN sysfs: <*>
[INFO]:Application recovery: ApplicationId=<*>, AttemptCount=<*>, FinalState=NONE
[DEBUG]:PUT <*> bytes to <*> via transfer manager
[WARN]:Error parsing protocol buffer of EZ XAttr <*> dir:<*>
[INFO]:Waiting for Applications to be Finished
[ERROR]:Exception on heartbeat
[INFO]:Initialized plan <*> based on reservable queue <*>
[ERROR]:Cannot get the datanodes from the RPC server
[DEBUG]:TaskType set to MAP
[DEBUG]:passing over + elf + because it is in progress + and we are ignoring in-progress logs.
[DEBUG]:Failed to accept this proposal because node is in state (not RUNNING)
[TRACE]:this: NotificationHandler: got EOF on sock.fd
[DEBUG]:version: <*>
[INFO]:Incrementing put completed statistics
[INFO]:Node <*> completed decommission and maintenance but has been moved back to in service
[INFO]:No directory to abort <*>
[WARN]:Failed to resolve the path as mount path
[ERROR]:Error removing attempt: someAttemptId, someException
[INFO]:Filter initializers set : <*>
[INFO]:IdentityProvider not specified, defaulting to UserIdentityProvider
[DEBUG]:BLOCK* addStoredBlock: Redundant addStoredBlock request received for <*> on node <*> size <*>
[DEBUG]:open file: + conn.getURL()
[DEBUG]:Storing master key ...
[INFO]:Releasing the assigned NUMA resources for + containerId
[ERROR]:Cannot delete app: e.getMessage()
[ERROR]:Exception while publishing configs on JOB_SUBMITTED Event for the job : <*>
[TRACE]:Using cached SAS token.
[DEBUG]:Compression codec created
[WARN]:The edits buffer is + size() + " bytes long with " + numTxns + " unflushed transactions. Below is the list of unflushed transactions:
[WARN]:Unable to load className
[DEBUG]:DFSStripedOutputStream does not support hflush. Caller should check StreamCapabilities before calling.
[DEBUG]:now pulling docker image. image name: <*>, container: <*>
[DEBUG]:Calling getLogsInfo
[DEBUG]:BPServiceActor ( <*> ) processing queued messages. Action item: <*>
[DEBUG]:Exception during striped read task
[WARN]:Can't get local NN thread dump due to Exception
[DEBUG]:Registering tokens for renewal for: appId = <*>
[INFO]:Size of event-queue in RMContainerAllocator is + qSize
[DEBUG]:Audit log true for operation listSnapshottableDirectory
[INFO]:Application ID doesn't exist for service <*>
[ERROR]:Unable to parse options
[WARN]:Found Checksum error for ...
[DEBUG]:Executing task
[INFO]:Possible loss of precision converting vStr with vUnit suffix to returnUnit for name
[WARN]:BlockReader failed to seek to targetPos. Instead, it seeked to pos.
[DEBUG]:Application submitted to RMWebServices
[DEBUG]:Checking operation
[INFO]:Successfully deleted service dir for + serviceName + : + appDir
[DEBUG]:Refresh dfs used, bpid: <*>, replicas size: <*>, dfsUsed: <*> on volume: <*>, duration: <*>ms
[INFO]:Deleting credential: <*> from CredentialProvider: <*>
[DEBUG]:Block token id is null, sending without handshake secret.
[DEBUG]:Failed to save summary to <*>, <*>
[WARN]:Exception + msg
[ERROR]:Exception while moving block replica to target storage type
[INFO]:Thread.currentThread().getName() + ": readAndProcess caught InterruptedException"
[ERROR]:Cannot create directory <*>
[ERROR]:Error getting HTTP response from the timeline server.
[INFO]:Finished requesting datanode containers
[DEBUG]:Start datablock<*> upload
[INFO]:Encryption zone removed for inode
[ERROR]:DtFetcher for service 'service' does not require a token. Check your configuration. Note: security may be disabled or there may be two DtFetcher providers for the same service designation.
[WARN]:Policy for queue: <*> does not exist.
[INFO]:Namenode is in safemode. It will retry again.
[DEBUG]:BLOCK* addToInvalidates: <*> <*>
[ERROR]:Unable to start failover controller. Unable to connect to ZooKeeper quorum at zkQuorum. Please check the configured value for ZK_QUORUM_KEY and ensure that ZooKeeper is running.
[ERROR]:Error while stopping listener for webapp + webAppContext.getDisplayName(), e
[DEBUG]:Block analysis status:<*> for the file id:<*>. Adding to attempt monitor queue for the storage movement attempt finished report.
[INFO]:ChRootedFs listStatus call invoked
[INFO]:Using leveldb path /path/to/leveldb
[DEBUG]:buffer dir: <*> already exists.
[WARN]:Nodes updated info: (detailed node information)
[DEBUG]:Resetting capacity with ignoreGuar set to false
[INFO]:Completed reading history information of application + appId
[DEBUG]:No resilient commit support under path <*>
[DEBUG]:closeFile: <*> with <*> blocks is persisted to the file system
[INFO]:Missed heartbeat
[INFO]:Skipping monitoring container containerId since CPU usage is not yet available.
[INFO]:System metrics publisher will put events every ... milliseconds
[ERROR]:Got null reader from BlockAliasMap
[INFO]:Obtained taskID from tid
[INFO]:Scheduling Monitor disabled, stopping all services
[DEBUG]:Converting recovered FileDeletionTask
[ERROR]:Unable to acquire file lock on path <*>
[ERROR]:Unexpected health check result <*> for volume <*>, result, reference.getVolume()
[TRACE]:<*>: no block pools are ready to scan yet. Waiting <*> ms., this, timeout
[WARN]:org.apache.hadoop.yarn.server.nodemanager.NodeResourceMonitorImpl$MonitoringThread is interrupted. Exiting.
[DEBUG]:Cancelling caching for block with id <*>, pool <*>.
[INFO]:DatanodeCommand action: DNA_ACCESSKEYUPDATE
[INFO]:Executing rollEditLog
[TRACE]:data: <*>
[WARN]:AUTHZ_FAILED_FOR ...
[ERROR]:Unknown option specified.\n
[INFO]:Using TextOutputFormat: $<*>
[DEBUG]:Checking if security is enabled
[WARN]:Failed to initialize rolling leveldb <*> for <*>
[INFO]:Directory + prevDir + does not exist.
[WARN]:key + is configured to + v + , will use default value: + defVal
[INFO]:JVM with ID: + jvmId + asking for task before AM launch registered. Given null task
[ERROR]:Failed to load image file.
[ERROR]:Cannot get "<*>" records from the State Store
[DEBUG]:Cannot delete <*> since some of its contents cannot be deleted
[WARN]:Balancer already running as a long-service!
[ERROR]:Unsupported operation attempted
[INFO]:Checked operation
[INFO]:Time to prepare directories <*>
[INFO]:Resource types
[INFO]:Container list rendered
[DEBUG]:Deleting fake directory marker at destination <*>
[DEBUG]:Directive <*>: not scanning file <*> because bytesNeeded for pool <*> is <*>, but the pool's limit is <*>
[INFO]:Creating a directory
[INFO]:Sending signal to all members of process group $<*>: $<*>. Exit code $<*>
[ERROR]:The resource manager is in an inconsistent state. It is safe for the resource manager to be restarted as the error encountered should be transitive. If high availability is enabled, failing over to a standby resource manager is also safe.
[DEBUG]:Merging statistics into FS statistics in <*>: <*>
[ERROR]:Cancelling plan on <*> failed. Result: <*>, Message: <*>
[ERROR]:Unauthorized request to start container. This token is expired. current time is ...
[DEBUG]:Invalid Application ID: <*>
[DEBUG]:dumpSchedulerLogs
[INFO]:Submitting application to RouterWebServices
[DEBUG]:Creating a HadoopYarnProtoRpc server for protocol <*> with <*> + handlers
[ERROR]:Error reading md5 file at <*>
[INFO]:Reading fully from block input stream
[ERROR]:Got stream error during data sync
[ERROR]:Cannot serialize credentials
[DEBUG]:creating password for <*> for user <*> to run on NM <*>
[DEBUG]:Match on record @ <*> with children,
[DEBUG]:Writing ContainerTokenIdentifier to RPC layer: <*>
[DEBUG]:Block read failed. Getting remote block reader using TCP
[WARN]:<*> has been set to <*>, which is less than the default minimum value <*>. This may impact NodeManager's performance.
[TRACE]:Basic auth starting
[ERROR]:Server response:\n
[DEBUG]:SASL client doing encrypted handshake for addr = <*>, datanodeId = <*>
[DEBUG]:Available resource information: + availableRI
[TRACE]:<*>: unregisterSlot <*>, this, slotIdx
[INFO]:Using RM authentication filter(kerberos/delegation-token) for RM webapp authentication
[INFO]:Block <*> has been invalidated. Marking short-circuit slots as invalid: <*>
[WARN]:Trash caught: <*>. Skipping <*>.
[ERROR]:Renaming operation executed
[INFO]:There are no available cpus: + resource.getVirtualCores() + in numa nodes for + containerId
[INFO]:Finishing UAM id <*> for application <*>
[INFO]:Creating symlink: %s <- %s
[INFO]:Fetching flow run apps for user
[WARN]:Shuffle secret missing from task credentials. Using job token secret as shuffle secret.
[INFO]:Recovered container $<*> succeeded
[WARN]:New counter created
[INFO]:CSRF Protection has been enabled for the <*> application. Please ensure that there is an authentication mechanism enabled (kerberos, custom, etc).
[INFO]:Deleting zero-length edit log file elf
[INFO]:org.apache.hadoop.tools.dynamometer.ApplicationMaster$NMCallbackHandler:onContainerStopped called
[DEBUG]:this + : + caller + : sendCallback processed fd + fd + in toRemove.
[INFO]:Submitting container request : <*>
[DEBUG]:Removing delegation token for appId=org.apache.hadoop.yarn.api.records.ApplicationId; token=dttr.token.getService()
[INFO]:Using SystemServiceManager: schedulerClassName
[WARN]:Encountered exception
[INFO]:Refreshing all user-to-groups mappings. Requested by user: (getRemoteUser().getShortUserName result)
[INFO]:Directory markers will be kept on authoritative paths
[DEBUG]:Created application tracking structs for app: <*>
[WARN]:Found nUsableGpus usable GPUs, however GPU_URI resource-type is not configured inside resource-types.xml, please configure it to enable GPU feature or remove GPU_URI from YarnConfiguration.NM_RESOURCE_PLUGINS
[DEBUG]:Exception in getkeyNames., e
[ERROR]:The AM's web app redirected the RM web proxy's request back to the web proxy. The typical cause is that the AM is resolving the RM's address as something other than what it expects. Check your network configuration and the value of the yarn.web-proxy.address property. Once the host resolution issue has been resolved, you will likely need to delete the misbehaving application, id
[ERROR]:History information of application "+" appId +" is not included into the result due to the exception
[INFO]:Submitted batch (start:<*>, size:<*>) of zone <*> to re-encrypt.
[DEBUG]:Trying to unassign GPU device from container
[DEBUG]:key <*>
[TRACE]:SchedulingOpportunities: ..., nodeLocalityThreshold: ..., change allowedLocality from NODE_LOCAL to RACK_LOCAL..., priority: ..., app attempt id: ...
[WARN]:Timeline token to be updated should be of kind TimelineDelegationTokenIdentifier.KIND_NAME
[ERROR]:Cannot remove <*>: <*>
[DEBUG]:created new buffer size <*>
[INFO]:Readiness check succeeded for <*>: <*>
[TRACE]:Entering getKey method.
[INFO]:EventFetcher: Got new map-outputs
[INFO]:Received new token <*>
[DEBUG]:Block blobs with compaction directories: <*>
[INFO]:Loading service definition from local FS: <*>
[ERROR]:Fail to destroy application:
[WARN]:DFS Read
[INFO]:Processed + numResources + resource(s) in + durationMs + ms.
[INFO]:MRAppMaster received a signal. Signaling RMCommunicator and JobHistoryEventHandler.
[INFO]:Track duration and span invoked
[INFO]:Ignoring exception during close for + c, ie
[INFO]:Operation hsync is not supported so far on path with erasure code policy set
[WARN]:Got unexpected exception trying to get lease on parentKey. e.getMessage
[INFO]:logAuditEvent - success
[DEBUG]:Starting reduce thread pool executor.
[DEBUG]:Sent close command
[WARN]:SDK_REGION_CHAIN_IN_USE
[INFO]:Finishing task: + mapId
[INFO]:Incrementing put start statistics
[ERROR]:Unable to perform upsert for Document Id : <*> under Collection : <*> under Database <*>
[INFO]:Should fence: + target
[INFO]:Generating <*> of test data...
[ERROR]:Failed to create DFSClient for user: <*>
[ERROR]:A task status you don't know about is "unknownStatus".
[INFO]:Found <*> INodes in the INode section
[ERROR]:Thread <*> threw an error: <*>. Shutting down Halting due to Out Of Memory Error...
[INFO]:Job is running in background.
[DEBUG]:Initiating re-login for <*>
[ERROR]:Number of partitions in stream exceeds limit for S3: + Constants.MAX_MULTIPART_COUNT + write may fail.
[WARN]:Unable to update finishTimeForRetryAttempts in state store for + containerId
[INFO]:DECOMMISSIONING <*> timeout
[WARN]:Allocated thread interrupted. Returning.
[DEBUG]:%d DataNodes are required for the erasure coding policies: %s. The number of DataNodes is only %d.
[DEBUG]:Closing Writer
[DEBUG]:Node transitioned to RUNNING state
[INFO]:Sleeping for ...ms before retrying again. Got null now.
[ERROR]:Error launching job , bad input path :
[ERROR]:Error when writing start information of application attempt
[DEBUG]:User 'userName' has become non-active.Hence move user to non-active list.Active users size = activeUsersSet.size() Non-active users size = nonActiveUsersSet.size() Total Resource usage for active users=totalResUsageForActiveUsers.getAllUsed().Total Resource usage for non-active users=totalResUsageForNonActiveUsers.getAllUsed().
[INFO]:The value for '-node' is neither specified or empty.
[INFO]:The storage policy of <*> is unspecified
[DEBUG]:Removing service <*>
[INFO]:Stopping yarnClient within the DS Client
[ERROR]:The dependency call returned null for host + node.getHostName()
[INFO]:drop FINISH_CONTAINERS event to + containerId + because container is recovering
[DEBUG]:Creating new Groups object
[DEBUG]:Scanned <*> records for <*> types
[INFO]:File committed successfully
[WARN]:Interrupted object upload
[ERROR]:args length condition failed, terminating.
[ERROR]:UNKNOWN_SUCCESS_ERROR_MSG, methodName
[DEBUG]:Ignoring closed channel error, cause
[INFO]:Successfully ensured local node is in standby mode
[INFO]:<*> retrieve localization statuses, compInstanceId
[DEBUG]:Delegation token retrieved
[INFO]:per directory file limit = $<*>
[WARN]:Skipping index <*>-<*>
[INFO]:MembershipNamenodeResolver cache loaded
[DEBUG]:getContainerLogsInfo
[WARN]:Error while decoding...
[ERROR]:Application Master failed. exiting
[DEBUG]:Datanode is not chosen
[INFO]:The number of failed attempts in previous + app.attemptFailuresValidityInterval + milliseconds is + numberOfFailure + . The max attempts is + app.maxAppAttempts
[INFO]:Instantiated SCMWebApp at bindAddress
[DEBUG]:Abort task %s
[DEBUG]:Kerberos krb5 configuration not found, setting default realm to empty
[INFO]:Connecting to Application History server at <*>
[WARN]:Treat this jumbo write as a real random write, no support.
[DEBUG]:Recalculated checksum for the block index:<*>, checksum=<*>
[ERROR]:Invalid arguments: , <*>
[DEBUG]:Performing satisfy storage policy operation
[DEBUG]:Concurrent invocation initiated
[INFO]:Total Memory: memoryHere
[DEBUG]:concat: result: + dstfs.getFileStatus(firstChunkFile)
[DEBUG]:Directive <*>: No inode found at <*>
[WARN]:Skipping unexpected file in history server token state
[TRACE]:Skipping XMLEvent of type <*>(<*>)
[DEBUG]:BLOCK* InvalidateBlocks: add Block to DatanodeInfo
[INFO]:Write lock acquired
[INFO]:Replacing the constraint associated with tag <*> with <*>., sourceTag, placementConstraint
[INFO]:++++++++++++++++++++++++++++++++++++++++++++++++++++++
[DEBUG]:nodePath + " znode already exists !!"
[ERROR]:Shuffle failed : local error on this node
[ERROR]:Cannot remove record <*>
[WARN]:excess types chosen for block <*> among storages <*> is empty
[INFO]:Containers Pending: countHere
[WARN]:Caught exception after scanning through ... ops from ... while determining its valid length. Position was ...
[DEBUG]:Incremented storage statistics OpCounter
[INFO]:<*> compatibility is ok.
[WARN]:Repeated interrupt: escalating to a JVM halt
[WARN]:Application invoked the Syncable API against stream writing to <*>. This is Unsupported
[DEBUG]:Call: <*> took <*>ms
[WARN]:Current time + current + is ahead of started time + started
[DEBUG]:*DIR* NameNode.mkdirs: <*>
[DEBUG]:this received versionRequest response: nsInfo
[WARN]:Could not update cgroup for container, e
[INFO]:Native Bzip2 library found; proceeding to use native library name
[WARN]:IOException executing command: , e
[DEBUG]:Renewing token:<*> with renewer:<*>.
[DEBUG]:Used resource= + queueUsage.getUsed(partition) + exceeded maxResourceLimit of the queue = + maxResourceLimit
[INFO]:Container <*> updated, updateType=<*>, resource=<*>, execType=<*>
[INFO]:Executing REST operation
[INFO]:Available VirtualCores: countHere
[INFO]:Updating layout version from <*> to <*> for storage <*>
[ERROR]:Cannot get available namenode for...
[DEBUG]:Try timeline store <*> for the request
[DEBUG]:Ignoring S3Guard store option of NULL_METADATA_STORE -no longer needed Origin <*>
[DEBUG]:Getting new token from <*>, renewer:<*>
[ERROR]:Unable to remove path
[DEBUG]:add file + clfs
[WARN]:Script envBinaryPath does not exist
[DEBUG]:Cleaning up logger
[WARN]:Shuffle output from host.getHostName() failed, retry it., ioe
[ERROR]:<*>: Failed to launch container., instance.getCompInstanceId()
[DEBUG]:Retrieve reduce input field separator
[ERROR]:Error while trying to delete history files that could not be moved to done.
[DEBUG]:mark at <*>
[INFO]:Help text displayed
[INFO]:Processed URL ... (Took ... ms.)
[WARN]:The API getMaxPhysicalMemoryForTask() is deprecated. Refer to the APIs getMemoryForMapTask() and getMemoryForReduceTask() for details.
[ERROR]:e.toString(), e
[INFO]:Added access for operation
[DEBUG]:path already present: <*>
[INFO]:Scanning active directory <*> every <*> seconds
[DEBUG]:stat output:<*>
[INFO]:Ramping down
[INFO]:instances to upgrade <*>
[WARN]:The credential provider interface has changed in AWS SDK V2, custom credential providers used in delegation tokens binding classes will need to be updated once S3A is upgraded to SDK V2
[DEBUG]:NativeAzureFileSystem. Initializing.
[DEBUG]:Waiting for <*> tasks to complete
[ERROR]:Encountered Storage Exception for write on Blob : <*> Exception details: <*> Error Code : <*>
[INFO]:<*> unexpectedly interrupted
[ERROR]:Cannot get Namenodes from the State Store.
[DEBUG]:The job has a total of <*> tasks.
[DEBUG]:<*> Marked container=<*> from queue=<*> to be preemption candidates
[INFO]:Container stop monitoring
[INFO]:Cleaning up ownerScanner
[DEBUG]:removeContainerQueued: containerId=<*>
[DEBUG]:Priority ACL group added: max-priority - <*> default-priority - <*>
[DEBUG]:persistNewBlock: <*> with new block <*>, current total block count is <*>
[INFO]:Device syspath: <*>
[INFO]:Starting InMemoryLevelDBAliasMapServer on <*>
[DEBUG]:Root cause: <*>
[WARN]:Interrupted while sleeping on container kill on resync
[DEBUG]:Auth failure: <*>, <*>
[ERROR]:Incorrect format for ip and host
[ERROR]:<*> ignoring relative path <*>
[INFO]:Saved output of task '$<*>' to $<*>
[TRACE]:No valid proxies left
[DEBUG]:Thread interrupted while performing keyId increment
[WARN]:Update (size=) to a smaller size block
[DEBUG]:Reading Manifest in file <*>
[ERROR]:Cannot initialize driver for driverName
[DEBUG]:Response JSON location configured
[INFO]:addDirective of <*> successful., info
[WARN]:Remote IP <*> checking available resources took <*>ms
[DEBUG]:mode.toString() + " KeyStore: " + keystoreLocation
[TRACE]:ClientCredsTokenProvider initialized
[WARN]:Script envBinaryPath is not executable
[WARN]:Failed to reconstruct striped block <*>, <*>
[WARN]:this.appId specified invalid log aggregation policy className
[INFO]:containerId signal request request.getCommand() by sentBy
[DEBUG]:Exception in parse path: <*>
[WARN]:Unable to create directory <*> error <*>, removing from the list of valid directories.
[WARN]:Rule '<*>' has multiple parent rules defined, only the last parent rule will be used
[DEBUG]:Failed to get security status.
[DEBUG]:Creating a request outside an audit span, unaudited
[INFO]:Getting groups for user via RouterRpcServer
[DEBUG]:DIR* NameSystem.mkdirs: src
[DEBUG]:check access mode <*> for <*>
[INFO]:Sending finish application request to RM <*>
[INFO]:currently disabled dir <*>; type=<*> ;canwrite=<*>
[DEBUG]:BLOCK* chooseExcessRedundancies: (<*>, <*>) is added to invalidated blocks set
[WARN]:closing file $<*>, but there are still unreleased ByteBuffers allocated by read(). Please release $<*>.
[WARN]:IGNORING ClusterNode <*> with queue wait time <*> and wait queue length <*>
[DEBUG]:Entering exist check
[DEBUG]:maxTxnsToRead = 1 actual edits read = 0
[DEBUG]:lastTxnId:
[WARN]:Unexpected parameters
[DEBUG]:Failed to load local runC image to hash file. Config not set
[WARN]:Cannot read symbolic link on
[ERROR]:Exception while parsing json resource <*>
[WARN]:Default name service is not set.
[DEBUG]:Initiating delete operation for <*> objects
[WARN]:Failed to get policy from FederationFacade with queue <*>: <*>
[ERROR]:Failed to communicate with NM Collector Service for + appId
[DEBUG]:post-assignContainers
[INFO]:<*>: Trying to recover <*> but event did not specify component instance
[TRACE]:<*>: waiting for loading to finish...
[ERROR]:Request short-circuit read file descriptor failed with unknown error.
[TRACE]:Exiting handleEncryptedKeyOp method.
[INFO]:Error writing to fileId <*> at offset <*> and length <*>
[ERROR]:Setting file size is not supported when mkdir: fileName in dirHandle dirHandle
[INFO]:Storing application with id <*>
[INFO]:Upgrading to sequential block IDs. Generation stamp for new blocks set to startingGenStamp
[DEBUG]:Waiting for <*> uploads to complete
[DEBUG]:While waiting for upload completion, ee
[DEBUG]:logCommitterStatisticsAtDebug
[ERROR]:Disk Balancer - Invalid plan.
[TRACE]:Waiting time: <*> ms, nodeLocalityDelay time: <*> ms, change allowedLocality from NODE_LOCAL to RACK_LOCAL, priority: <*>, app attempt id: <*>
[DEBUG]:DelegationKey readFields invoked
[WARN]:Failed to find log file
[DEBUG]:------------------- logged event for top service: allowed=<*>\tugi=<*>\tip=<*>\tcmd=<*>\tsrc=<*>\tdst=<*>\tperm=<*>
[DEBUG]:removing node <*>
[ERROR]:No more jobs to process in the trace with 'starts-after' set to ...
[INFO]:Upper limit on the thread pool size is + this.limitOnPoolSize
[ERROR]:Unexpected safe mode action
[DEBUG]:%s
[DEBUG]:Service <*> passed in <*> arguments:
[INFO]:Error cleaning master , e
[ERROR]:"rollBack" will remove the current state of the file system...
[INFO]:prefix + metrics system started
[INFO]:Available Memory: memoryHere
[DEBUG]:Skip selecting AM container on host=<*> AM container=<*>
[INFO]:Removed node address cluster capacity: resource
[DEBUG]:selectStreamingInputStream manifests:\n <*>
[DEBUG]:close socket cause client has closed.
[INFO]:Promotion Update requests : + promotionRequests
[ERROR]:Error while scanning intermediate done dir , e
[ERROR]:Unable to get key from credential providers.
[INFO]:\tNumber of suppressed read-lock reports: <*> \n\tLongest read-lock held at <*> for <*>ms via <*>
[INFO]:Rollback of <*> is complete
[WARN]:msg, e
[DEBUG]:<*>:<*>, this, msg
[DEBUG]:<*>: enqueue <*>
[INFO]:Fail task attempt TASK_ATTEMPT_ID received from USER_NAME at REMOTE_ADDRESS
[INFO]:Loading image file curFile of size curFile.length() bytes loaded in elapsedTime seconds.
[DEBUG]:Creating application entity
[INFO]:Completed setting up command for namenode: ...
[ERROR]:Cannot get Routers JSON from the State Store
[WARN]:Lazy persist file scrubber is disabled, configured scrub interval is zero.
[INFO]:FilterFs listStatus call invoked
[DEBUG]:selecting edit log stream + elf
[WARN]:Failed to write legacy OIV image: ...
[WARN]:Failed to delete this local Directory: <*>
[DEBUG]:Skipping queue management updates for parent queue <*> since configuration for auto creating queues beyond parent's guaranteed capacity is disabled
[ERROR]:Illegal event type: $event.getClass()
[WARN]:setMaxVirtualMemoryForTask() is deprecated. Instead use setMemoryForMapTask() and setMemoryForReduceTask()
[WARN]:The volume<*> with the available space (=... B) is less than the block size (=... B).
[DEBUG]:LOCAL_DIR for child : <*>
[DEBUG]:checkStreamers: ...
[INFO]:closing the application table
[ERROR]:RMAppManager received completed appId of null, skipping
[INFO]:Waiting for deletion thread to complete its current action
[INFO]:Failed to instantiate ClientProtocolProvider, please check the /META-INF/services/org.apache.hadoop.mapreduce.protocol.ClientProtocolProvider files on the classpath
[INFO]:Number of suppressed write-lock reports: <*> Longest write-lock held at <*> for <*>ms via <*> Total suppressed write-lock held time: <*>
[DEBUG]:Got access token error in response to OP_BLOCK_CHECKSUM
[DEBUG]:Application applicationId is recovering. Skip notifying APP_ACCEPTED
[DEBUG]:Failed to get output from <*>
[INFO]:<*>=<*> min(s), <*>=<*> min(s), <*>=<*>
[DEBUG]:replaying edit log: ...
[WARN]:RMContainer received unexpected recover event with container state report.getContainerState while recovering.
[DEBUG]:Using handler for protocol <*>
[WARN]:Incorrect version exception message DN: dnReg
[INFO]:Looking for the active RM in ...
[INFO]:Success in updating application priority
[DEBUG]:Target node is already occupied before moving
[ERROR]:Cannot call close method due to Exception. Ignoring.
[INFO]:Storing RMDelegationKey_ + masterKey.getKeyId()
[INFO]:Starting expired delegation token remover thread, tokenRemoverScanInterval= X min(s)
[INFO]:Fetching devices from NEC VE plugin
[INFO]:Container + containerId + not launched as + cleanup already called
[DEBUG]:Error changing permissions of <*>, <*>
[ERROR]:Queue named could not be auto-created during application recovery.
[DEBUG]:Deleting the temporary directory of '<*>': '<*>'
[WARN]:<*> Check failed!, ioe
[WARN]:Caught exception when adding fsVolume. Will throw later.
[TRACE]:Entering decryptEncryptedKey method.
[INFO]:Uploading file: <*> to <*>
[WARN]:Unable to transition local node to standby: <*>
[WARN]:Target queue + targetQueue + (cs.isAmbiguous(targetQueue) ? is ambiguous while trying to move : does not exist while trying to move ) + app.getApplicationId
[INFO]:Service <*> has successfully decommissioned instances.
[DEBUG]:RMAppManager processing event for ApplicationId of type eventType
[WARN]:Unexpected data length x!! from y
[INFO]:Trying to re-establish ZK session
[INFO]:% of the mappers will be scheduled using OPPORTUNISTIC containers
[DEBUG]:<*>: container <*>
[INFO]:Scanning storage
[DEBUG]:Retrieved job index info
[WARN]:-dfs option is deprecated, please use -fs instead.
[INFO]:Mover took X milliseconds
[INFO]:Deleting temporary files: + files
[DEBUG]:Finished events sent
[WARN]:setInputPolicy is no longer supported
[INFO]:Submission Context Preprocessor enabled: file=<*>, interval=<*>
[INFO]:Override State Store record <*>: <*>
[DEBUG]:Creating SendEntity task in PutEventThread
[INFO]:Unknown apps will be treated as complete after <*> seconds
[DEBUG]:action, ex
[ERROR]:Failed to bootstrap configured resource subsystems!
[DEBUG]:Not adding volume scanner for <*>, because the block scanner is disabled.
[WARN]:Slow name lookup for + hostname + . Took + elapsedMs + ms.
[INFO]:Number of HDFS based distributed cache files to be generated is $<*>. Total size of HDFS based distributed cache files to be generated is $<*>.
[INFO]:Hdfs listStatus call invoked
[INFO]:Relaunching Container <*> for re-initialization !!
[ERROR]:Storage exception encountered during block compaction phase: <*> Storage Exception: <*> Error Code: <*>
[DEBUG]:<*> reported decommissioning, eventNode
[INFO]:Creating Cosmos DB Reader Async Client...
[DEBUG]:Interrupted while waiting for queue
[WARN]:ACL configuration for '%s' is greater that cluster max priority. Resetting ACLs to %s
[ERROR]:Encountered error while making remote call to <*> retried <*> time(s).
[DEBUG]:Partial failure of delete, <*> errors
[DEBUG]:Initial report of block <*> on <*> size <*> replicaState = <*>
[INFO]:modifyCachePool of <*> successful; set mode to <*>
[WARN]:Unable to match classid in string: <*>
[WARN]:strategy not supported by BuiltInZlibDeflater.
[WARN]:logAuditEvent(false, "rename (options=" + Arrays.toString(options) + ")", src, dst, null)
[WARN]:Deprecated configuration key <*> will be ignored.
[ERROR]:must pass -service field with dtutil edit command
[ERROR]:Unable to abort stream <*>
[INFO]:Scheduled the shared cache cleaner task to run every + periodInMinutes + minutes.
[DEBUG]:Saved INodeReference ids of size <*>.
[INFO]:Starting NodeSortingService= + getName()
[INFO]:Network ACL closed to AM for job . Not going to try to reach the AM.
[WARN]:Could not obtain node HTTP address from provider.
[INFO]:Attempting to kill workload app: <*>
[INFO]:Generating script at: + localScript.getAbsolutePath()<*>
[INFO]:Token master key removed from file system state store
[DEBUG]:Publishing service metrics. <*>
[DEBUG]:No Gauge: + op
[INFO]:getStats()
[INFO]:job.getJobName() + " (" + job.getJobID() + ")" + " success"
[WARN]:Couldn't report bad block block to actor, e
[DEBUG]:Skip allocating AM container to app_attempt=<*>, don't allow to allocate AM container in non-exclusive mode
[DEBUG]:User information retrieved
[INFO]:<*>: Failed <*> times on this host, blacklisted <*>. Current list of blacklisted nodes: <*>
[ERROR]:We were not able to rename the directory to <*>. We will leave it intact.
[DEBUG]:New app directory created - <*>
[DEBUG]:Evict stream ctx: + pairs.getValue()
[WARN]:Unable to fetch valueName; retried retryCount times / waited time ms
[WARN]:Interrupted Exception while stopping, <*>
[WARN]:Can't find group name for gid + gid + . Use default group name + unknown
[INFO]:recoverLease: + lease + , src= + src + from client + clientName
[INFO]:Vmem enforcement enabled
[ERROR]:Exception in block key updater thread
[ERROR]:Invalid READ request
[INFO]:Token cancellation requested for identifier: + formatTokenId(id)
[WARN]:has a full queue and can't consume the given metrics.
[WARN]:Exception caught during context creation
[WARN]:Logging with INFO level to standard output
[DEBUG]:deleted dir <*>, path;
[INFO]:Could not find a node matching given resourceName
[INFO]:Remove HDFS delegation token <*>.
[INFO]:Quota update count info
[ERROR]:builder.toString()
[INFO]:Error report from + dnName + : + msg
[INFO]:FSCK started by UserGroupInformation from remoteAddress for path path at <*>
[INFO]:Processing split: + inputSplit
[DEBUG]:cleanup <*> from leveldb
[WARN]:Aggregated logs truncated by approximately ...
[DEBUG]:Traversing into source dir: <*>
[INFO]:Special commit success
[DEBUG]:DIR* FSDirectory.unprotectedDelete: " + iip.getPath() + " is removed
[INFO]:Problem connecting to server: + nnAddr
[WARN]:Received unwanted container allocation: + container
[WARN]:Invalid configuration detected
[INFO]:Unauthenticated call marked
[ERROR]:The shared cache root + location + was not found. The cleaner task will do nothing.
[WARN]:Storage directory <*> does not exist, rootPath
[DEBUG]:DataNode Z reported slow peers: <*>
[INFO]:MiniKdc stopped.
[INFO]:Registered webapp guice modules
[INFO]:<*>: <*>: <*> instances.
[WARN]:Connection failure: Failed to connect to <*> for file <*> for block <*>
[TRACE]:getBlockLocalPathInfo for block=<*> returning null
[ERROR]:Container start failed event could not be published for containerId
[DEBUG]:No container is allocated on node <*>
[INFO]:STATE* Safe mode is ON.\nIt was turned on manually. Use "hdfs dfsrouteradmin -safemode leave" to turn safe mode off.
[ERROR]:Thread <*> threw an exception: <*>
[ERROR]:Could not contact RM after retryInterval milliseconds.
[WARN]:Could not copy the file to the shared cache at + tempPath
[DEBUG]:Path is a file
[DEBUG]:No excess replica can be found. excessTypes: <*>. moreThanOne: <*>. exactlyOne: <*>.
[DEBUG]:Successfully retrieved successor IDs
[WARN]:InterruptedException executing command: ...
[INFO]:Resetting bytesOnDisk to match blockDataLength (=<*>) for replica <*>
[DEBUG]:createDirectory filesystem: <*> path: <*> permission: <*> umask: <*> isNamespaceEnabled: <*>
[DEBUG]:Writing summary log for <*> to <*>
[ERROR]:User does not have permissions to delete <*>. Parent directory has sticky bit set.
[INFO]:Failed to delete <*>, ignoring exception <*>
[DEBUG]:Storing token to <*>
[WARN]:DistCpConstants.CONF_LABEL_MIN_RECORDS_PER_CHUNK + " should be positive. Fall back to default value: " + DistCpConstants.MIN_RECORDS_PER_CHUNK_DEFAULT
[ERROR]:removing failed delegation token for appid= + applicationIds + ";t=" + t.token.getService()
[INFO]:Application did not finish. YarnState=?, DSFinalStatus=?. Breaking monitoring loop
[INFO]:Remove RMDT with sequence number <*>
[WARN]:IO/Network error: method getMaskedUrl() ex.getMessage()
[WARN]:A block with id <*> exists locally. Skipping PROVIDED replica
[INFO]:Added Application Attempt <*> to scheduler from user <*> in queue <*>
[INFO]:DataNode <*> completed successfully, containerId=<*>
[DEBUG]:Retrying getTokenSingleCall. RetryCount = <*>
[INFO]:Missing header hash for appid
[INFO]:Retry cache on namenode is disabled
[ERROR]:Interrupted while waiting for SlotReleaserThreadPool to terminate
[DEBUG]:INFO field filter added
[INFO]:Successfully added SchedulingRequest to app= + appSchedulingInfo.getApplicationAttemptId() + placementConstraint=<*>. nodePartition= + targetNodePartition
[DEBUG]:Datanode information accessed, block locations retrieved
[DEBUG]:Setting next expiration time
[INFO]:Will remove files: <*>
[DEBUG]:Running task cleanup task
[INFO]:Scheduler Configuration format only supported by MutableConfScheduler.
[WARN]:Exception when trying to get exclusivity
[WARN]:SecondaryNameNode principal not considered, ...
[DEBUG]:Building remote locations list
[DEBUG]:The exception for deleteOnExit is <*>
[DEBUG]:Cleaning up <*>
[INFO]:Updating balance throttler bandwidth from ... to: ...
[DEBUG]:Store empty file successfully. COS key: <*>, ETag: <*>.
[INFO]:Application + applicationAttemptId + has already been + stopped!
[INFO]:Trying to diagnose FPGA information ...
[INFO]:Created localizer for locId
[WARN]:Subcluster <*> doesn't have a successful heartbeat for <*> seconds for <*>
[TRACE]:$<*> invoked by user $<*>
[DEBUG]:Failed to move reservation, node updated or removed, moving cancelled.
[INFO]:Waiting for FileSystem at <*> to be out of safe mode
[INFO]:negotiable preemption : A resourceReq, B containers
[INFO]:Event type: <*>, Event record counter: <*>
[INFO]:Storage locations checked
[WARN]:No valid mount-table file exist at: <*>. At least one mount-table file should present with the name format: mount-table.<*>.xml
[DEBUG]:Used resource=<*> exceeded user-limit=<*>
[WARN]:Invalid file name. Skipping <*>
[INFO]:PUT: upgrade components <*> for service <*> + user = <*>
[DEBUG]:Sending cacheReport from service actor: this
[DEBUG]:Node resource information map is <*>
[DEBUG]:getRunCommand: %s exists:%b
[ERROR]:Should not get commit return code: <*>
[ERROR]:FederationStateStoreClientMetrics failed state store call
[DEBUG]:Retrieving priority for app: <*>
[INFO]:Deleting Queue
[INFO]:FSSTAT operation completed
[DEBUG]:mkdirs: created directory <*>
[WARN]:Log aggregation is not initialized for <*>, did it fail to start?
[INFO]:Service address obtained
[ERROR]:Exception while unregistering , are
[INFO]:Rendering FifoScheduler Queue with default queue
[INFO]:Setting up container + masterContainer + for AM + application.getAppAttemptId()
[DEBUG]:Resource handler chain enabled = false
[INFO]:Initialized workflow priority mappings, override: true
[ERROR]:Unable to update container resource in store
[INFO]:RMStatusInfoBean registered
[DEBUG]:Forward seek on <*>, of <*> bytes
[ERROR]:Error reattaching UAM to <*> for <*>
[DEBUG]:Flush invoked
[WARN]:Excluding datanode
[INFO]:Finished executing getErasureCodingPolicy for path src
[DEBUG]:PUT to <*>/<*>
[DEBUG]:Cleanup input stream with logger
[ERROR]:Could not contact RM after <*> milliseconds.
[DEBUG]:emptyLogDir
[DEBUG]:Sending AUTHENTICATION_REQ, digest=%s, challenge=%s
[ERROR]:Queue Management Change event cannot be applied for parent queue : + parentQueue.getQueuePath()
[INFO]:Nodemanager resources is set to: <*>
[ERROR]:Exception when recovering attemptId, removing it from NMStateStore and move on
[DEBUG]:<*> resources:
[DEBUG]:Application tag based placement is enabled, checking for 'userid' among the application tags
[DEBUG]:Realm: miniKdc.getRealm()
[ERROR]:Encountered Storage Exception for delete on Blob: ..., Exception Details: ... Error Code: ...
[DEBUG]:Skipping malformed line in machine list: line
[WARN]:Sync of transaction range <*>-<*> took <*>ms ; journal id: <*>
[INFO]:Disallowed NodeManager nodeId: + nodeId + hostname: + nodeId.getHost()
[INFO]:Attempting to initialize + dir
[DEBUG]:Creating ApplicationServiceRecordProcessor for <*>
[INFO]:Will retry operation on FS. Retry no. #<*> after sleeping for #<*> seconds
[INFO]:<*> doesnâ€™t exist. Add the container to the release request cache as it may be on recovery.
[ERROR]:No binary found from env variable: ENV_BINARY_PATH or path DEFAULT_BINARY_SEARCH_DIRS.toString()
[DEBUG]:Interrupted while waiting to put on response queue
[INFO]:Write operation checked
[INFO]:Stopping services started for active state
[WARN]:Error closing the stream <*>
[ERROR]:Error in stopping application: IOException
[ERROR]:RECEIVED SIGNAL X: SIGY
[WARN]:Timeline service is not enabled
[INFO]:FSQuotaUsage operation executed
[INFO]:Filter added
[DEBUG]:Skipping container release on removed node: <*>
[WARN]:Exception running logging thread
[WARN]:getObjectMetadata() called. This operation and it's response will be changed as part of upgrading S3A to AWS SDK V2
[DEBUG]:Error in streaming job
[INFO]:<*>: Saving manifest file to <*>
[DEBUG]:Block <*>: can't add new cached replicas, + because there is no record of this block + on the NameNode.
[INFO]:Transitioned to standby state
[DEBUG]:Getting UGI for current user
[DEBUG]:AzureBlobFileSystem.rename src: <*> dst: <*>\n
[INFO]:Minimum records per chunk calculated
[ERROR]:Cannot get mount point
[ERROR]:Exception in doCheckpoint
[INFO]:Continuing
[INFO]:instance.compInstanceId + IP = + status.getIPs() + , host = + status.getHost() + , cancel container status retriever
[INFO]:Job <*> Transitioned from <*> to <*>
[ERROR]:Unable to rename temp to previous for + sd.getRoot(), ioe
[DEBUG]:arg
[DEBUG]:Attempted to remove a non-existing znode <*>
[INFO]:Stopping InMemoryLevelDBAliasMapServer
[INFO]:Session disconnected. Entering neutral mode...
[ERROR]:Got IOException while deleting entities for type entityType, continuing to next type
[ERROR]:Failed to publish Container metrics for container $<*>
[INFO]:Replica <*> was not found in the VolumeMap for volume <*>
[INFO]:Source is a file
[WARN]:<*> doesn't support pausing., container.getContainerId()
[DEBUG]:Connecting to url <*> with token <*> as <*>
[INFO]:Submit application invoked
[DEBUG]:Aborting all pending commit filess under <*> (recursive=<*>)
[DEBUG]:Loaded map stats - File: <*>, Loaded: <*>, Error: <*>
[DEBUG]:BLOCK* invalidateBlock: <*> on <*>
[INFO]:could not locate JAR containing <*> URL=<*>
[INFO]:ContainerId=<*>, docker volume output for <*>: <*>
[TRACE]:Excluded nodes: <*>
[WARN]:User does not have permission to call method
[WARN]:DFS chooseDataNode: got #<*> IOException, will wait for <*> msec.
[WARN]:short-circuit read access is disabled for DataNode <*>. reason: <*>
[INFO]:The workload will start at + startTimestampMs + ms ( + startTimeString + )
[DEBUG]:scanForLogs on <*>
[WARN]:About to remove corresponding storage: <*>
[INFO]:Timeline service V2 client is enabled
[ERROR]:Trying to addHistory duplicate resource skylines for <*>. Use updateHistory function instead.
[INFO]:<*> Job Transitioned from <*> to <*>
[DEBUG]:JWT token has been successfully verified
[DEBUG]:<*>: Number of subdirectories under <*> found: <*>; file count ...
[INFO]:Number of dynamic-chunk-files created: <*>
[INFO]:logSyncAll toSyncToTxId= + lastWrittenTxId + lastSyncedTxid= + synctxid + mostRecentTxid= + txid
[DEBUG]:Authentication successful for <*>
[DEBUG]:NFS LOOKUP dir fileHandle: <*> name: <*> client: <*>
[INFO]:Successfully initialized MultiSchemeAuthenticationHandler
[DEBUG]:Successfully retrieved entity types
[INFO]:AMRMProxyService listening on address: + this.server.getListenerAddress()
[WARN]:Disk error on Unknown DataNode: ...
[INFO]:Cleaning resources
[WARN]:Falling back to getSnapshotDiffReport <*>
[INFO]:TaskAttempt had not completed, recovering as KILLED
[INFO]:Interceptor chain obtained
[WARN]:Invalid timestamp information. Please try again by specifying valid Timestamp Information.
[DEBUG]:The user credential is <*>
[DEBUG]:Successful completion of operation 'getErasureCodingPolicies'
[ERROR]:Calling allocate on previous or removed or non existent application attempt ...
[DEBUG]:Beginning to copy stream <*> to shared edits
[DEBUG]:Volumes are imbalanced. Selecting volume from high available space volumes for write of block size replicaSize
[DEBUG]:Flushing cache
[INFO]:Partial Directory listing
[DEBUG]:listStatus(<*>) failed; returning empty array
[ERROR]:FATAL, Error while starting FS configuration conversion!, t
[DEBUG]:Preparing file for truncate
[WARN]:NativeIO.getStat error (<*>): <*> -- file path: <*>
[DEBUG]:Trying to preempt following containers to make reserved container=<*> on node=<*> can be allocated:
[INFO]:Going to activate master-key with key-id ...
[DEBUG]:Purging outstanding multipart uploads older than <*>
[DEBUG]:#<*>: <*>, getCallId(), r.getState()
[DEBUG]:Local namespace for <*> is <*>, clientAddr, localSubcluster
[WARN]:Failed to set scheduling priority for client
[WARN]:Log Aggregation service failed to initialize, there will be no logs for this application
[INFO]:Cannot submit job to parent queue + q.getName()
[WARN]:The value of DFS_NAMENODE_AVAILABLE_SPACE_BLOCK_PLACEMENT_POLICY_BALANCED_SPACE_PREFERENCE_FRACTION_KEY is less than 0.5 so datanodes with more used percent will receive more block allocations.
[DEBUG]:Adding entity type to list
[INFO]:EC Topology Verifier Result for specified policies
[DEBUG]:Trying to assign to queue: <*> stats: <*>
[WARN]:found a <*> but it's not a <*>
[DEBUG]:Operation executed with detailed action and path
[INFO]:Edit pending queue is full
[ERROR]:Bug in read selector!
[DEBUG]:Authentication exception: <*>
[WARN]:Failed: <*>, <*>, <*>
[ERROR]:Unable to start log segment + segmentTxId: too few journals successfully started.
[ERROR]:Unable to complete the cleaner task, e1
[INFO]:Container state set to READY
[WARN]:Invocation returned exception on <*>, proxyInfo, ex
[INFO]:History Cleaner complete
[DEBUG]:No crypto codec classes with cipher suite configured.
[INFO]:Localized resource <*> for container <*>
[INFO]:capacity scheduler file max version = ...
[WARN]:There is no data saved
[DEBUG]:Pause monitor started
[INFO]:Service ACLs refreshed
[ERROR]:Error in handling event type + event.getType() + for node + nodeId, t
[DEBUG]:Finished write to <*>, len <*>. etag <*>, version <*>, key, length, eTag, versionId
[INFO]:Shell usage printed
[DEBUG]:getEditLogManifest
[WARN]:DataNode <*> cannot be found with UUID <*> + , removing block invalidation work., dn, dn.getDatanodeUuid()
[WARN]:Delete the tmp file: <*> failed.
[INFO]:RECONFIGURE* changed <*> to <*>, property, newVal
[INFO]:Created <*>
[TRACE]:removing shm + shm
[WARN]:Ignoring service <*> for the user <*> as it is already present, filename = <*>
[DEBUG]:Deleting Job attempt Path
[INFO]:DataNode$DataTransfer, at <*>: Transmitted <*> (numBytes=<*>) to <*>
[DEBUG]:setMemInfo : memInfo : <*>
[WARN]:Unknown request source: + proto.getReqSource()
[WARN]:Invalid RPC call program + call.getProgram()
[DEBUG]:Using PathOutputCommitter implementation <*>
[DEBUG]:fetchColumnsFromFilterList executed for IS_RELATED_TO
[ERROR]:Container end event could not be published for <*>
[INFO]:Unable to determine FileDescriptor
[DEBUG]:Handling event
[INFO]:Getting task report for <*> <*>. Report-size will be <*>
[INFO]:Application <*>.
[INFO]:Received URL
[INFO]:Set replication to ... for path: ...
[ERROR]:Audit event failed: AccessControlException
[INFO]:Start information of application X is written
[ERROR]:Error while trying to scan the directory + p
[TRACE]:Writing txid <*>-<*> ; journal id: <*>
[DEBUG]:Failed to get number of decommissioning nodes
[INFO]:Sending finish application request to <*> sub-cluster RMs
[INFO]:Checkpoint Period : + checkpointConf.getPeriod() + secs + ( + checkpointConf.getPeriod() / 60 + min
[INFO]:addJerseyResourcePackage: packageName= + packageName + , pathSpec= + pathSpec
[INFO]:Task java-opts do not specify heap size. Setting task attempt jvm max heap size to + xmxArg
[DEBUG]:Listing status for <*>
[INFO]:The AMRMToken has been rolled-over. Send new AMRMToken back to application
[WARN]:"Bad element in allocations file: " + tagName
[DEBUG]:NetworkTopology became:\n + this.toString()
[ERROR]:Error in storing RMDelegationToken with sequence number: + identifier.getSequenceNumber()
[WARN]:Fail to create symbolic links on Windows. The default security settings in Windows disallow non-elevated administrators and all non-administrators from creating symbolic links. This behavior can be changed in the Local Security Policy management console
[DEBUG]:Security login
[DEBUG]:No incoming metric to aggregate for : <*>
[INFO]:Error storing info for RMDTMasterKey with keyID: <*>
[TRACE]:Filesystem created
[INFO]:Source listing <*>
[ERROR]:Error message with throwable
[DEBUG]:doSecureLogin starts
[ERROR]:Failed to cancel upgrade: , e
[INFO]:Could not create log file: <*> for job <*>
[INFO]:Stopped the writer: <*>
[INFO]:Allocate processing finished in <*> ms for application <*>
[WARN]:Configuring <*> flag in <*> is not valid.
[INFO]:AM container found in context, has credentials: <*>
[DEBUG]:Dequeued latency info <*>: <*>, elapsed, latencyDetails
[ERROR]:Couldn't make localTarget active, Throwable t
[INFO]:Bulk delete operation failed to delete all objects; failure count = <*>
[INFO]:Total Vmem allocated for Containers
[DEBUG]:Activating DatanodeAdminManager with interval <*> seconds, <*> max blocks per interval, <*> max concurrently tracked nodes.
[WARN]:failed to update application state in state store, ex
[DEBUG]:Writing block # <*>
[DEBUG]:Closed channel exception
[DEBUG]:Blocking call to RM
[INFO]:Resource Manager started
[DEBUG]:block<*>: skipping re-entrant closeBlock()
[ERROR]:Couldn't find listing file at: + listingFilePath
[WARN]:<*> cannot be read.
[ERROR]:Disk Balancer - Invalid plan hash.
[INFO]:Error storing info for attempt: + appAttemptId, e
[TRACE]:<*>: about to release <*>, ShortCircuitCache.this, slot
[ERROR]:node to unreserve doesn't exist, nodeid: + idToUnreserve
[INFO]:Checking operation category
[DEBUG]:Retrieving storage account key
[WARN]:getSpillFileCB.. Could not find spilled file .. Path: <*>
[INFO]:Successfully executed refreshUserToGroupsMappings
[INFO]:delete app log dir,application_n_n_DEL_n
[ERROR]:<*>
[DEBUG]:Add new write to the list with nextOffset <*> and requested offset=<*>
[ERROR]:Failed to start router, e
[DEBUG]:Total Resource Usage stats in NM by all containers: Virtual Memory= vmemUsageByAllContainers, Physical Memory= pmemByAllContainers, Total CPU usage(% per core)= cpuUsagePercentPerCoreByAllContainers
[INFO]:Number of processors <*>
[DEBUG]:Task attempt succeeded event handled
[ERROR]:Symlink target should not be null, fileId: <*>
[DEBUG]:The destination <*> doesn't exist.
[DEBUG]:Getting key version for key with name <*>., name
[ERROR]:Trash dir for replica ...
[INFO]:Generating + totalRows + using + numSplits
[DEBUG]:capacityConfigType is '<*>' for queue <*>
[DEBUG]:: wait ...
[ERROR]:No component instance exists for <*>
[DEBUG]:getUGI is returning: <*>
[DEBUG]:S3A write delta changed after finished: <*> bytes
[DEBUG]:<*> is anchored, and can't be uncached now. Scheduling it for uncaching in <*>
[DEBUG]:Getting UGI from keytab....
[DEBUG]:List of plugins of ResourcePluginManager: <*>
[INFO]:Launching thread to trigger block reports...
[INFO]:Container + containerId + not launched as it has already + been marked for Killing
[DEBUG]:BLOCK* rescanPostponedMisreplicatedBlocks: Re-scanned block <*>, result is <*>
[DEBUG]:open AuthenticatedURL connection <*>
[DEBUG]:Building listing using iterator mode for %s
[DEBUG]:User <*> removed from activeUsers, currently: <*>
[ERROR]:Error message from YarnException
[INFO]:Attempt num: ... is last retry: true because the staging dir doesn't exist.
[WARN]:<*>: failed to load <*>
[INFO]:Merging intermediate segments
[INFO]:Wildcard expansion for directory: <*>
[INFO]:Adding a node "host" to the list of type hosts from filename
[DEBUG]:Started audit service <*>, auditor
[DEBUG]:sb.toString()
[WARN]:error creating ShortCircuitReplica., e
[INFO]:Success: removeCachePool, <*>}, true
[INFO]:Removing expired block report lease 0x<*> for DN <*>.
[DEBUG]:Fetching apps with pending demand
[ERROR]:Invalid READDIRPLUS request
[WARN]:Interrupted while waiting for available GPU
[INFO]:Failed to load config file: configFile, e
[DEBUG]:No audit span attached to request <*>
[DEBUG]:Registered + name
[TRACE]:<*>: trying to construct BlockReaderLocalLegacy
[TRACE]:UC block <*> sufficiently-replicated since numLive (<*>) >= minR (<*>)
[INFO]:Locking is disabled for <*>
[DEBUG]:Snapshotted source + sa.name()
[DEBUG]:Waiting for Event Handling thread to complete
[ERROR]:PingSocketCleaner exception
[DEBUG]:Writing bytes to output stream
[DEBUG]:Number of outstanding uploads: <*>
[ERROR]:Service <*> express upgrade to version <*> failed because <*>
[DEBUG]:Queue Info : <*>
[DEBUG]:Pre-check for node candidate set
[INFO]:Setting quota for mount table
[WARN]:Jetty request log can only be enabled using Log4j
[INFO]:Console mode is enabled, <*> and <*> will be only emitted to the console!
[WARN]:AM Resource capability=<*>
[INFO]:Loading INode directory section.
[INFO]:New namespace image has been created
[DEBUG]:Service <*> implements LaunchableService
[INFO]:getName(): operation raised an exception: exceptionMessage
[ERROR]:Cannot find BPOfferService for reporting block received + for bpid=<*>
[INFO]:Using mapred newApiCommitter.
[DEBUG]:No space available. Available: <*> MinSize: <*>
[INFO]:logSuccess called for GET_APPLICATIONS_REQUEST by user
[DEBUG]:SASL client skipping handshake in secured configuration with no SASL protection configured for addr = <*>, datanodeId = <*>
[INFO]:KILLING + taskAttemptID
[INFO]:Restored <*> block files from trash before the layout upgrade. These blocks will be moved to the previous directory during the upgrade, restored
[INFO]:Instantiated ClientAMService at + bindAddress
[DEBUG]:ByteBufferInputStream.close() for <*>
[INFO]:CachedHistoryStorage Init
[DEBUG]:RegisterUAM returned existing running container <*>
[WARN]:Failed to register MBean \ + name + \: Instance already exists.
[INFO]:ContainerId <*> is assigned to GpuDevice <*> on recovery.
[DEBUG]:Attempting secure login
[DEBUG]:Dispatching the event <*>.<*>, event.getClass().getName(), event
[DEBUG]:User resource is updated. Total Resource usage for active users=totalResUsageForActiveUsers.getAllUsed(). Total Resource usage for non-active users=totalResUsageForNonActiveUsers.getAllUsed()
[DEBUG]:Storing master key
[ERROR]:Error while storing reservation allocation., e
[INFO]:Content Length in shuffle : + contentLength
[INFO]:Start loading token cache
[DEBUG]:Edit log recorded
[DEBUG]:Failed getting node for hedged read: <*>
[INFO]:Balance failed, error code: <*>
[DEBUG]:The Path: <*> does not exist.
[DEBUG]:Using loginUser when Kerberos is enabled but the actual user does not have either KMS Delegation Token or Kerberos Credentials
[ERROR]:There are <*> duplicate block entries within the same volume.
[DEBUG]:AHS client stopped
[INFO]:Using app provided configurations for delegation token renewal, total size = <*>
[INFO]:Action set for property: SPECIFIED_NOT_FIRST
[INFO]:NameNode is ready for use!
[ERROR]:Failed to move aside pre-upgrade storage in image directory ...
[WARN]:Received an invalid request file transfer request from + request.getRemoteAddr() + : + msg
[INFO]:Log Aggregation deletion is disabled because retention is too small (retentionSecs)
[DEBUG]:The write back thread is working.
[ERROR]:onStartContainerError received unknown container ID: <*>
[WARN]:Exception in get all trash roots for mount points
[ERROR]:Application doesn't exist in cache ...
[ERROR]:Failed to retrieve configuration from zookeeper store
[INFO]:Failed to re-encrypting one batch of <*> edeks from KMS, time consumed: <*>, start: <*>., result, batch.size(), kmsSW.stop(), batch.getFirstFilePath()
[INFO]:BLOCK* processReport: logged info for <*> of <*> reported.
[ERROR]:Incompatible version for timeline state store: expecting version <*>, but loading version <*>
[DEBUG]:SASL client callback: setting username: + userName
[WARN]:Got error when sending OOB message.
[DEBUG]:Properties: <*>
[INFO]:Uncommitted data pending to file <*> commit metadata for <*> parts in <*>. size: <*> byte(s)
[ERROR]:Failed to update the node resource <*>.
[DEBUG]:Cancelling token:<*> with canceler:<*>.
[DEBUG]:Got valid challenge for host <*>
[WARN]:Unexpected exception from removeKeyRegistry, e
[DEBUG]:reconcile start DirectoryScanning
[ERROR]:Error on generating application report for <*>
[INFO]:Container state transitioned successfully
[WARN]:Task + task.getTaskID() + has nulll TaskType
[INFO]:Log parser interrupted
[INFO]:Generated a new token <*> for app <*>
[WARN]:Update resource on node: + node.getNodeName() + with the same resource: + newResource
[INFO]:Starting services required for standby state
[INFO]:$HADOOP_COMMON_HOME is not set
[DEBUG]:Processing event for <*> of type <*>
[INFO]:Log exception
[DEBUG]:AzureBlobFileSystem.listStatusIterator path : <*>
[ERROR]:YarnConfiguration.NM_GPU_ALLOWED_DEVICES is set to YarnConfiguration.AUTOMATICALLY_DISCOVER_GPU_DEVICES, however automatically discovering GPU information failed, please check NodeManager log for more details, as an alternative, admin can specify YarnConfiguration.NM_GPU_ALLOWED_DEVICES manually to enable GPU isolation.
[DEBUG]:enqueue full <*>, src=<*>, bytesCurBlock=<*>, blockSize=<*>, appendChunk=<*>, <*>, currentPacket, src, getStreamer().getBytesCurBlock(), blockSize, getStreamer().getAppendChunk(), getStreamer()
[DEBUG]:Unable to remove parent node <*> as it does not exist.
[DEBUG]:No snapshot name found for inode <*>
[INFO]:KEY_NAME '<*>' KEY_OP '<*>' ACL '<*>'
[WARN]:Unable to locate pid file for container $<*>
[INFO]:Applications Failed: countHere
[INFO]:Starting service as user
[INFO]:The job took seconds seconds.
[INFO]:Renewed delegation-token= <*>
[WARN]:Job Staging directory is null
[WARN]:Unable to delete upgrade definition for service <*> version <*>
[TRACE]:Exiting getKeyNames method.
[WARN]:Could not set permissions for local dir <*>, ie
[INFO]:No keytab exists: <*>
[DEBUG]:ComponentHealthThresholdMonitor run method
[WARN]:Failed to find FPGA discoverer executable from system environment ALTERAOCLSDKROOT_NAME, please check your environment!
[INFO]:Will fetch a new encryption key and retry, encryption key was invalid when connecting to dnInfo.addr : e
[DEBUG]:Access control headers '<*>' not allowed. Returning
[DEBUG]:adding node <*>
[WARN]:Output of aocl is: ...
[INFO]:Initializing secure datanode resources
[INFO]:Rendering FifoScheduler Queue with QueueInfoBlock
[DEBUG]:Storing <*> to <*>
[DEBUG]:Response=<*>(<*>), resetting authToken, conn.getResponseCode(), conn.getResponseMessage()
[INFO]:Giving handle (fileHandle: <*> file URI: <*>) to client for export <*>
[DEBUG]:Jersey retry operation initialized
[INFO]:Router RPC up at: ...
[INFO]:result=...
[WARN]:Received null queue for application <*> from home subcluster. Will use default queue name <*> for getting AMRMProxyPolicy
[WARN]:Resource is missing:...
[INFO]:Readiness check failed for <*>: <*>
[INFO]:<*>: Flex deferred because dependencies not satisfied., component.getName
[ERROR]:The application <*> does exist but was overwritten
[DEBUG]:Checking if source and destination paths are different
[ERROR]:Invalid RENAME request
[ERROR]:Incorrect endpoint: <*>
[ERROR]:Cannot get existing records
[WARN]:Error parsing smaps line : <*>; <*>
[ERROR]:Failed to setup deferred successful response. ThreadName= + Thread.currentThread().getName() + , Call= + this
[DEBUG]:Chosen node <*> from first random, ret
[INFO]:Previous job temporary files do not exist, no clean up was necessary.
[DEBUG]:Queue is already active. Skipping activation : <*>
[INFO]:Super post response created for TRUNCATE
[INFO]:End step DELEGATION_TOKENS
[INFO]:Service <*> version <*> saved.
[DEBUG]:this + : + caller + : sendCallback not + closing fd + fd
[WARN]:File skipped: Invalid file name
[DEBUG]:Rescanning because of pending operations
[ERROR]:Error removing log deletion state
[INFO]:There are <*> pending writes.
[INFO]:MRErrorThread done
[WARN]:Unexpected final state
[INFO]:Render job counters
[WARN]:error trying to open previous history file. No history data will be copied over.
[DEBUG]:Start to update quota cache.
[DEBUG]:Using delegation token <*> from service:<*>, dToken, service
[ERROR]:Cannot parse line <*> in file <*>
[INFO]:Stopping <*>
[TRACE]:Fetch SAS token for <*> on <*>
[TRACE]:Block <*>: DataNode <*> is not a valid possibility because the block has size <*>, but the DataNode only has <*> bytes of cache remaining (<*> pending bytes, <*> already cached.)
[DEBUG]:Counter value found and recorded
[WARN]:removeDirective of + id + failed: , e
[WARN]:Unable to clear quota at the destinations for <*>: <*>
[DEBUG]:skip this node:<*> for requestAttribute:<*>
[WARN]:Probe failed, add suspect node to dead node list: <*>.
[DEBUG]:Updating re-encryption checkpoint with completed task. last: ..., size:...
[ERROR]:The queue (planQueueName) cannot be found or is not a ParentQueue
[WARN]:MBean already initialized!
[INFO]:<*>: Committing job with file count: <*>; total size <*> bytes
[DEBUG]:About to load edits:\n <*>
[ERROR]:Failed to parse options
[INFO]:Insert into the state store the policy for the queue: <*>
[DEBUG]:Retrieving checksum from an earlier-version DataNode: inferring checksum by reading first byte
[WARN]:Interrupted when sending OOB message.
[INFO]:Found replacement:
[DEBUG]:<*> <*> Executing <*> with <*>; <*>
[DEBUG]:Requested datanode ask: %s
[ERROR]:Authorization check failed. Files or folders under <*> will not be processed for deletion.
[WARN]:Failed to move + this, e
[DEBUG]:Copying stream to target
[INFO]:available bytes: + valIn.available()
[INFO]:Original source <*>
[INFO]:JobConf set minRecWrittenToEnableSkip_ = + minRecWrittenToEnableSkip_
[ERROR]:Copy object unsuccessfully. source COS key: %s, dest COS key: %s, exception: %s
[DEBUG]:Closing AbfsOutputStream : <*>
[ERROR]:Retrieve file metadata file failed. COS key: <*>, CosServiceException: <*>.
[DEBUG]:Verifying the access of <*>
[WARN]:The client stateId: <*> is greater than the server stateId: <*>
[INFO]:Using longest log: + bestEntry
[INFO]:The block deletion will start around <*>
[WARN]:Could not parse history file <*> (Exception Details)
[DEBUG]:Cannot get listing from <*>
[ERROR]:log.error(msg)
[DEBUG]:Stopping service # i: service
[INFO]:initializing replication queues
[WARN]:Service is not ready to become active, but forcing: <*>
[DEBUG]:<*>: Stage failure:, getName(), e
[DEBUG]:ERROR resolving sub-cluster for resourceName: <*>, picked a random subcluster to forward: <*>
[WARN]:KMS provider at <*> threw an IOException:
[WARN]:The value of <*> is greater than 1.0 but should be in the range 0.0 - 1.0
[ERROR]:Failed to mount controller: controller.getName()
[DEBUG]:Stack trace
[WARN]:Logic error: we're trying to uncache more replicas than actually exist for cachedBlock
[DEBUG]:AM resource request: + amAsk.getPerAllocationResource() + exceeds maximum AM resource allowed, + getQueue().dumpState()
[DEBUG]:Remote directory retrieved
[INFO]:Scheduling reloading auxiliary services manifest file at interval <*> ms
[INFO]:Reacquired container classid: <*>
[DEBUG]:Forwarding allocate request to the real YARN RM
[INFO]:Stopping Journal Node Sync.
[ERROR]:Exception in generateEncryptedKeys:
[WARN]:The libjars file ... is not on the local filesystem. It will not be added to the local classpath.
[WARN]:Application placement failed for user
[DEBUG]:Using fallback authenticator sequence.
[INFO]:Do OutOfBand log aggregation
[WARN]:The value of DFS_NAMENODE_AVAILABLE_SPACE_RACK_FAULT_TOLERANT_BLOCK_PLACEMENT_POLICY_BALANCED_SPACE_TOLERANCE_KEY is invalid, Current value is balancedSpaceTolerance, Default value DFS_NAMENODE_AVAILABLE_SPACE_BLOCK_RACK_FAULT_TOLERANT_PLACEMENT_POLICY_BALANCED_SPACE_TOLERANCE_DEFAULT will be used instead.
[WARN]:Invalid container release by application + appAttemptId
[ERROR]:Failed to convert Credentials to ByteBuffer.
[WARN]:The file already exists under + finalPath + . Ignoring this attempt.
[INFO]:Killed <*> (<*>)
[WARN]:Requested IP file not found
[INFO]:Put Node NODE_ID in DECOMMISSIONING.
[INFO]:Starting log segment at + segmentTxId
[DEBUG]:DFSInputStream has been closed already
[ERROR]:Disk Balancer - Unable to support transient storage type.
[INFO]:MiniKdc started.
[WARN]:Failed to get major number from reading /dev/
[ERROR]:FATAL, Shutting down the resource manager.
[INFO]:Commit-pending state update from + taskAttemptID.toString()
[INFO]:Multipart upload committed successfully
[INFO]:valueName: value
[DEBUG]:Using UGI token: <*>
[ERROR]:Not all labels being replaced contained by known label collections, please check, new labels=<*>
[INFO]:Killing running jobs...
[DEBUG]:Call: Invocation object details
[INFO]:Start linking block files from <*> to <*>
[INFO]:New proxy instance created
[WARN]:Invalid shutdown event + event.getType() + . Ignoring.
[INFO]:Forcing reset of connection to <*>
[INFO]:Lease recovery started for src by clientName from clientMachine
[INFO]:Reading + editIn + expecting start txid # + (lastAppliedTxId + 1) + logSuppressed
[INFO]:NodeManager Version:
[INFO]:Full compaction cycle completed in + duration + msec
[INFO]:Moved block from StorageType to StorageType
[ERROR]:Cannot open read stream for record <*>
[INFO]:Resource capability of task type <*> is set to <*>
[INFO]:Evicting <*>
[TRACE]:Got Exception while checking, + DataStreamer.this, new Throwable(thrown)
[DEBUG]:DIR* FSDirectory.renameTo: path1 to path2
[WARN]:Got exception while signaling container + containerId + with command + signalEvent.getCommand()
[INFO]:strict mode is set to :<*><*>containers will be allowed to use spare YARN bandwidth.<*>containerBandwidthMbit soft limit (in mbit/sec) is set to : <*>
[INFO]:Version check passed
[WARN]:Time zone <*> could not be set on Oracle database.
[ERROR]:Failed creation of <*> directory\n
[INFO]:Creating intermediate history logDir: [... based on conf
[INFO]:RMApplicationHistoryWriter and TimelineCollectorManager set
[DEBUG]:Destination <*> is an already existing file, failing the rename.
[DEBUG]:Stacktrace: , e
[DEBUG]:enqueue full <*>, src=<*>, bytesCurBlock=<*>, blockSize=<*>, appendChunk=<*>, <*>
[DEBUG]:Uncaching <*> now that it is no longer in use by any clients.
[INFO]:Marking all datanodes as stale
[INFO]:Application + applicationAttemptId + is done. finalState= + rmAppAttemptFinalState
[ERROR]:Unable to decrease container resource
[INFO]:Update cache now
[WARN]:Failed to shuffle for fetcher#id
[INFO]:Added Application Attempt <*> to scheduler from user: <*>
[WARN]:Configuration overridingKey=get(overridingKey) is overriding the RM_SCHEDULER_INCREMENT_ALLOCATION_MB=get(RM_SCHEDULER_INCREMENT_ALLOCATION_MB) property
[INFO]:Sent signal x (...) to pid a as user b for container y, result=failed
[WARN]:Could not parse the old history file. Will not have old AMinfos
[INFO]:Retrying operation on FS. Retry no. x
[DEBUG]:this + : + caller + starting sendCallback for fd + fd
[DEBUG]:renameFileWithEtag source: <*> dest: <*> etag <*>
[WARN]:Failed to delete localDir: + localDir
[INFO]:Invalidating blocks in dataset
[DEBUG]:No sync response, expect an async response for request XID=<*>
[DEBUG]:Time taken to get FileStatuses: ...
[DEBUG]:Getting Namenode Name Service ID
[ERROR]:Error storing app: <*>, <*>
[ERROR]:Failed to start storage policy satisfier.
[DEBUG]:Interrupted Exception while waiting to join sps thread, ignoring it
[DEBUG]:Creating new parent rule: <*>
[INFO]:Finalizing upgrade for local dirs.
[ERROR]:Initialization failed for this because
[INFO]:Added a list of FPGA Devices:
[ERROR]:Failed to update service record in registry: + containerId +
[DEBUG]:AzureBlobFileSystem.setOwner path: <*>
[INFO]:DatanodeCommand action : DNA_REGISTER from + actor.nnAddr + with + actor.state + state
[ERROR]:Setting file size is not supported when mkdir: <*> in dirHandle <*>
[INFO]:Waiting for containers: <*>
[ERROR]:Error updating appAttempt: + attemptState.getAttemptId(), e
[INFO]:logAuditEvent
[DEBUG]:delete: path is a directory: <*>
[DEBUG]:Component <*>, patterned=<*>
[WARN]:paths<*> + " is not a valid path. Path should be with " + FILE_SCHEME + " scheme or without scheme"
[INFO]:List of warnings:
[ERROR]:Mkdirs failed to create $<*>
[WARN]:<*> is not a directory
[INFO]:CacheReplicationMonitor started
[WARN]:Please update your configuration to use <*> instead.
[WARN]:Unable to warm up EDEKs.
[ERROR]:Error in fetching application status: , e
[ERROR]:FSImageFormatPBSnapshot: Missing referred INodeId ...
[INFO]:Fast-forwarding stream...
[ERROR]:FederationStateStoreUtils log and throw retriable exception
[WARN]:Exception while checking whether encryption zone is supported
[WARN]:encountered exception
[DEBUG]:Loaded rule: user: <*>, network/bits: <*> path: <*>
[WARN]:Can't create(mkdir) trash directory: ...
[INFO]:Application is deleted from state store
[TRACE]:Start Queueing readAhead for <*> offset <*> length <*>
[ERROR]:The state code: <*> is unrecognized!
[DEBUG]:Failed to preserve last modified date from '<*>' to '<*>'
[INFO]:Layout version rolled back to DATANODE_LAYOUT_VERSION for storage sd.getRoot()
[WARN]:Unsuccessful allocation attempt <*> for <*>
[DEBUG]:Stalling shuffle since usedMemory (<*>) is greater than memoryLimit (<*>). CommitMemory is (<*>)
[WARN]:The device plugin: className returns null device runtime spec value for container: containerId
[INFO]:Edit log file + elf + appears to be empty. + Moving it aside... + ; journal id: + journalId
[WARN]:Volume <*> detected as being unhealthy
[INFO]:Bandwidth: MiB/s
[DEBUG]:Exception in getKeyVersion.
[INFO]:Renewing delegation token
[INFO]:There are now <*> entries in the list.
[WARN]:Could not initialize local dir <*>, e
[INFO]:Recommission node with state DECOMMISSIONING
[INFO]:File committed without rate limiting
[DEBUG]:Storing token + tokenId.getSequenceNumber()
[DEBUG]:Killing Daemon
[INFO]:The list of corrupt files under path 'dir' are:
[INFO]:Backup node ... re-registers
[INFO]:War = <*>
[INFO]:Loading the INode section in parallel with <*> sub-sections
[DEBUG]:DIR* NameSystem.truncate: src=<*> newLength=<*>
[WARN]:No valid image-tag-to-hash files
[WARN]:rename pending file <*> is already deleted
[INFO]:Application ... unreserved on node ..., currently has ... at priority ...; currentReservation ...
[WARN]:Clearing all the queues from StoragePolicySatisfier. So, user requests on satisfying block storages would be discarded.
[ERROR]:Unsupported protocol for connection to NameNode: ...
[ERROR]:Got Exception while build resolve result. ResultKind:%s, resolvedPathStr:%s, targetOfResolvedPathStr:%s, remainingPath:%s, will return null.
[ERROR]:ex.toString()
[INFO]:<*> already exists.
[INFO]:Ignore duplicate monitor lock-node request.
[WARN]:The same resources appear in both blacklistAdditions and blacklistRemovals in updateBlacklist.
[DEBUG]:Reading <*>
[DEBUG]:Unknown protocol <*>, delegating to default implementation
[WARN]:<*> is not a known counter.
[DEBUG]:ExactMatcher ' + ipOrHost + ', denying client ' + address + ', ' + hostname
[DEBUG]:EventHandler handling CommitterJobAbortEvent
[DEBUG]:Choosing data node
[TRACE]:In emitCells " + this.action + " currentColumnCells size= " + currentColumnCells.size() + " currentAggOp" + currentAggOp
[DEBUG]:Initiating caching for Block with id <*>, pool <*>
[INFO]:Real Authentication method: %s
[INFO]:Audit success: renameSnapshot
[ERROR]:Failed to fetch token from <*>
[DEBUG]:Aborting multipart uploads under <*>
[WARN]:Failed to find inode <*> in getNumUnderConstructionBlocks().
[INFO]:Application <*> mapping <*> to <*> override <*>
[DEBUG]:Authenticated User: <*> Requested User:<*>
[INFO]:Initialized container resources
[WARN]:Unable to update remainingRetryAttempts in state store for + containerId
[ERROR]:Error Launching job :
[DEBUG]:Initializing SSL Context to channel mode OpenSSL
[DEBUG]:Update SAS token
[INFO]:Renew delegation token operation started
[INFO]:Stopping periodic service <*>
[WARN]:Failed to resolve the uri as mount path
[INFO]:Http request log for <*> is not defined
[INFO]:Adding resource type - name = resourceName, units = resourceUnits, type = resourceTypeName
[INFO]:<*>: connection aborted from <*>
[DEBUG]:No credentials provided by <*>: <*>
[DEBUG]:Added priority=<*>
[INFO]:Avoiding JDK-8047340 on BSD-based systems.
[DEBUG]:retryCount == <*>. It's time to normally process the response
[INFO]:Deactivation request received for failed volume: <*>
[DEBUG]:Create proxy user with remote user
[INFO]:Done waiting for containers to be killed. Still alive: <*>
[INFO]:No summary file for job: + jobId
[INFO]:namenodes = <*>
[DEBUG]:Building listing using multi threaded approach for %s
[INFO]:Map Attributes to Nodes operation initiated
[DEBUG]:blockSize = <*>
[DEBUG]:Assigned container in queue:<*> container:<*>, getName(), assigned
[DEBUG]:String.format("SPEC(%d) %d -> %d %d %d %d %d %d %d", id(), i, i + j * maps, info.getOutputRecords(), info.getOutputBytes(), info.getResourceUsageMetrics().getCumulativeCpuUsage(), info.getResourceUsageMetrics().getPhysicalMemoryUsage(), info.getResourceUsageMetrics().getVirtualMemoryUsage(), info.getResourceUsageMetrics().getHeapUsage())
[INFO]:Time elapsed calculated
[DEBUG]:Handling uplink command
[DEBUG]:createCgroup: <*>
[WARN]:Encountered unexpected error during migration of application: <*> from reservation: <*>
[INFO]:Max mem capabililty of resources in this cluster <*>
[WARN]:Unable to inspect storage directory
[INFO]:Delegation token request processed
[INFO]:Replica Cache file: path doesn't exist
[INFO]:Launching master<*>
[ERROR]:Invocation to "<*>" for "<*>" timed out
[DEBUG]:Did not load hdfs image to hash file, file is unmodified
[DEBUG]:executing a request outside an audit span ..., ex
[INFO]:Leaving safe mode after <*> milliseconds
[ERROR]:Can't handle this event at current state for + this.attemptId, e
[DEBUG]:Checking operation UNCHECKED
[DEBUG]:OOM handler failed
[DEBUG]:AppMaster capability = <*>
[ERROR]:Cannot initialize State Store driver <*>
[ERROR]:Error while closing MultipleOutput file
[INFO]:NameNode is being shutdown, exit SafeModeMonitor thread
[DEBUG]:Failed to list uploads under <*>
[DEBUG]:flushing segment 0
[DEBUG]:Enough unallocated resources <*>
[INFO]:Cannot lock storage <*>. The directory is already locked
[ERROR]:Registration rejected by ... Shutting down.
[INFO]:<*>: Stage <*> completed after <*>, getName(), stageName, OperationDuration.humanTime(stageExecutionTracker.asDuration().toMillis())
[DEBUG]:Fetching InputFormat map
[INFO]:Change property: change.prop from ((change.oldVal == null) ? "<*>" : oldValRedacted) to ((change.newVal == null) ? "<*>" : newValRedacted)
[WARN]:RemoteException in register, e
[INFO]:User X successfully called transitionToActive
[INFO]:Resource mappings updated
[INFO]:Input value counter incremented
[WARN]:Could not update cgroup for container
[ERROR]:<*> operation failed for file <*>
[INFO]:MapFile reader created
[INFO]:File qualified
[ERROR]:error parsing filename
[WARN]:Could not find SUBSTITUTE_TOKEN token in query: $<*>; splits may not partition data.
[ERROR]:Edits file + f + has improperly formatted + transaction ID
[WARN]:<*>: error saving <*>., this, iter, e
[INFO]:Cached dfsUsed found for
[DEBUG]:Scheduler Info Initialized
[WARN]:Cannot heartbeat router <*>
[ERROR]:Failed to register the MOUNT service.
[DEBUG]:Check access completed successfully
[ERROR]:Can't make a speculator -- check MRJobConfig.MR_AM_JOB_SPECULATOR
[INFO]:Finalizing rolling upgrade
[INFO]:<*> combiner is not null
[DEBUG]:No files to abort under <*>
[DEBUG]:Dumper checking OpenFileCtx activeState: <*> enabledDump: <*>
[ERROR]:Failed to initialize storage directory <*>.Exception details: <*>
[INFO]:Manifest filesystem closed
[INFO]:Took <*> ms to collect <*> open files with leases <*>, (endTimeMs - startTimeMs), iipSet.size(), ((ancestorDir != null) ? " under " + ancestorDir.getFullPathName() : ".")
[INFO]:Allocated Memory: memoryHere
[WARN]:Failed to delete file <*>
[WARN]:Failed to delete temp file: <*>
[ERROR]:Error shutting down all UAM clients without killing them, e
[TRACE]:BR lease 0x<*> is valid for DN <*>.
[DEBUG]:SASL server skipping handshake in unsecured configuration for peer = <*>, datanodeId = <*>
[INFO]:Get locations for path
[DEBUG]:Decommissioning node: ...
[INFO]:FSDelete operation executed
[TRACE]:HTTP <*>: <*>, <*>, ugi=<*>, <*>, <*> <*>
[INFO]:Service AppAttemptId: applicationAttemptId
[ERROR]:Download of Edit Log file for Syncing failed. Deleting temp file: <*>
[INFO]:<*>: finished scanning block pool <*>
[INFO]:SystemMetricsPublisher created and set
[DEBUG]:MOUNT NULLOP : client: <*>
[INFO]:Stopped plug-in <*>
[INFO]:Time zone has been set to <*>
[DEBUG]:Statistics: <*>
[DEBUG]:, freeQueueSize=
[INFO]:Unknown application with id rendered
[ERROR]:Incrementing put completed statistics with exception
[DEBUG]:Exception while seek to <*> from <*> of <*> from <*>
[TRACE]:Exiting reencryptEncryptedKeys method.
[WARN]:Update native status got exception
[INFO]:Executing with tokens: <*>
[INFO]:Successfully authenticated to ZooKeeper using SASL.
[DEBUG]:passing over + elf + because it ends at + elf.lastTxId + , but we only care about transactions + as new as + fromTxId
[INFO]:Configuring zookeeper to use <*> as the server principal, zkPrincipal
[DEBUG]:Error formatting message
[WARN]:Thread sleep is interrupted.
[INFO]:mkdirs(<*>}: Access denied when looking for parent directory <*>; skipping checks
[INFO]:LazyPersistFileScrubber was interrupted, exiting
[DEBUG]:count=count
[DEBUG]:Binding <*> to <*>
[DEBUG]:BLOCK* Removing stale replica <*> of <*>
[DEBUG]:Removing <*>
[INFO]:Processed URL <*> (Took <*> ms.)
[DEBUG]:AzureBlobFileSystem.setAcl path: <*>
[DEBUG]:pipeline = + Arrays.toString(nodes) + , + this
[WARN]:Unsupported operation type: + op.getOperationType()
[WARN]:container %s killed by elastic cgroups OOM handler.
[DEBUG]:Scan not needed of + fs.getPath()
[DEBUG]:Read a container logs
[INFO]:Using <*> threads to upgrade data directories (<*>=<*>, dataDirs=<*>)
[INFO]:AMHeartbeatRequestHandler thread for <*> is exiting
[WARN]:ContainerRequest has duplicate nodes: ...
[DEBUG]:setting webapp host class to <*>
[INFO]:Initialized TimelineReader URI=... , clusterId=...
[DEBUG]:Event handler called
[DEBUG]:Logging legacy generation stamp
[DEBUG]:Debug message with throwable
[DEBUG]:<*>: commitTaskInternal
[WARN]:Queue %s has max resources %s less than min resources %s
[INFO]:<*> = <*>
[INFO]:Stored the finish data of application attempt <*>
[DEBUG]:NodeManager <*> releases an AM (<*>) or
[ERROR]:User request caused exception.
[DEBUG]:Registered <*>
[WARN]:pendingMutation or tempConfigPath is null, do nothing
[ERROR]:Cannot invoke <*> for <*> in <*>: <*>
[ERROR]:Exception raised while executing multinode sorter, skip this run..., exception=
[DEBUG]:Moving <*> to <*>, src, dst
[ERROR]:FS:fsScheme, Namenode ID collision for path:exportPath nnid:namenodeId uri being added:exportURI existing uri:value
[INFO]:Update IPID to + newIPID + for this allocated device: + device
[INFO]:Checking for any old active which needs to be fenced...
[WARN]:Error recovering pipeline for writing + block + . Already retried 5 times for the same packet.
[INFO]:DNS servers: ...
[DEBUG]:Keytab <*>
[WARN]:The InMemorySCMStore was interrupted while shutting down the app check task.
[DEBUG]:FileSystem.<*>() by method: <*>); <*>
[INFO]:Cannot assign container...
[WARN]:Couldn't delete checkpoint: + dir + Ignoring.
[DEBUG]:call blockReceivedAndDeleted: + Arrays.toString(reports)
[WARN]:Unable to place reservation: ...
[WARN]:Exception when scheduling the event of stopping Container + containerId
[INFO]:Dumper is interrupted, dumpFilePath = <*>
[WARN]:AppLogs for group id <*> is null
[INFO]:Deleting job directory
[WARN]:Exception while trying to create default reservation queue for plan: <*>, planQueueName, e
[INFO]:Reading <*> expecting start txid #<*> <*>
[DEBUG]:Command to launch container for ApplicationMaster is : <*>
[INFO]:Invoke sequential execution
[DEBUG]:map TaskAttemptID done
[DEBUG]:Service added
[DEBUG]:BLOCK* addBlock: logged info for <*> of <*> reported.
[DEBUG]:Waited <*>ms to read from <*>; spawning hedged read
[DEBUG]:Adding request to ask resourceRequestInfo.remoteRequest
[WARN]:e.toString()
[DEBUG]:Removing info for app: appId at: appIdRemovePath and its attempts
[DEBUG]:Ignoring socket shutdown exception
[INFO]:Scheduler logs dumped
[INFO]:Cannot find inode <*>, skip saving xattr for re-encryption
[INFO]:Resource Types Info Retrieved
[DEBUG]:Loaded edits starting from txid
[INFO]:Interrupted waiting for countdown latch
[INFO]:Connecting to ResourceManager at <*>
[INFO]:Will fetch a new encryption key and retry, encryption key was invalid when connecting to node<*>
[WARN]:Failed to unmap the buffer
[INFO]:got done
[DEBUG]:assigned + includedMaps + of + totalSize + to + host + to + Thread.currentThread().getName()
[DEBUG]:Groupsearch baseDN: <*>
[DEBUG]:AzureBlobFileSystem.breakLease path: <*>
[DEBUG]:Starting to add to replicas map
[DEBUG]:Added lastBlockCrc 0x<*> for block index <*> of size <*>, Integer.toString(lastBlockCrc, 16), locatedBlocks.size() - 1, consumedLastBlockLength
[WARN]:deleting + fromFile.getAbsolutePath() + FAILED
[TRACE]:this + ": the DfsClientShmManager is closed."
[INFO]:Setting client token master key
[DEBUG]:Failing deletion operation
[WARN]:System service directory <*> doesn't not exist.
[DEBUG]:DataNode instance created
[INFO]:===file===
[DEBUG]:NFS READLINK fileHandle: <*> client: <*>,
[INFO]:Service <*> is being gracefully stopped...
[WARN]:Failed to save replica <*>. re-enqueueing it.
[INFO]:Token lookup completed
[DEBUG]:Set vcores to <*>
[INFO]:System Service Directory is configured to <*>
[ERROR]:local path for PRIVATE localization could not be found. Disks might have failed.
[WARN]:Try to update resource on a + rmNode.getState().toString() + node: + rmNode.toString()
[WARN]:Invalid thread pool size. Setting it to the default value in YarnConfiguration
[INFO]:StagingCommitter staging dirs cleaned
[INFO]:Invalid value ... for config ... Resetting it to ...
[WARN]:Only able to place ... of total expected ...
[DEBUG]:Sending out <*> container statuses: <*>
[DEBUG]:Storing reservation: <*> in plan:<*> at: <*>
[INFO]:Selected loggers with >= maxAllowedTxns transactions starting from lowest txn ID
[TRACE]:Proceeding with interaction
[DEBUG]:Cleaning up partial output for task
[INFO]:Forwarding registration request to the real YARN RM
[WARN]:Found multiple CostProviders; using: <*>
[WARN]:ServiceTimelinePublisher has stopped. Not publishing any more metrics to ATS.
[INFO]:Reading conversion rules file from: + rulesFile
[DEBUG]:System.currentTimeMillis() + " <*> Overloaded is " + Boolean.TRUE.toString() + " NumJobsBackfill is " + loadStatus.getJobLoad()
[ERROR]:Killed container process with PID <*> but it is not a process group leader., <*>
[DEBUG]:Class name for prefix <*> is <*>
[INFO]:Bash execution is not allowed by the JVM security manager.Considering it not supported.
[INFO]:Bootstrapping the InMemoryAliasMap from <*>
[ERROR]:error closing DomainPeerServer: , e
[DEBUG]:Terminating ZK connection for
[DEBUG]:Displaying error: message
[WARN]:BLOCK* addStoredBlock: block <*> moved to storageType <*> on node <*>
[DEBUG]:storage.refreshStorage called
[DEBUG]:Connecting to target address.
[INFO]:Shutting down all async disk service threads
[ERROR]:Unable to obtain the application information for the specified application <*>
[DEBUG]:Directive <*>: Failed to resolve path <*> (<*>)
[INFO]:Completed setting up command for datanode: ...
[DEBUG]:Partial length is greater than zero
[WARN]:Ignoring state store operation failure because the resource manager is not configured to fail fast. See the yarn.fail-fast and yarn.resourcemanager.fail-fast properties.
[DEBUG]:Sum: + sum Bucket: updateTime: timeStr (bucketTime) isStale stale at time
[ERROR]:Exception occurred: <*>
[DEBUG]:Allocation proposal accepted=<*>
[INFO]:Containers still running on ON_NODEMANAGER_RESYNC : <*>
[DEBUG]:doAsUser = <*>, RemoteUser = <*> , RemoteAddress = <*>
[INFO]:No opened stream for fileId: + fileHandle.dumpFileHandle() + commitOffset= + commitOffset + . Return success in this case.
[TRACE]:we can read the local file.
[DEBUG]:Get HTTP scheme prefix
[WARN]:Error sending metrics to Graphite
[INFO]:Caught exception while adding replicas from ... Will throw later.
[DEBUG]:elapsedTimeMs > refreshIntervalMs : <*> > <*>, so refreshing cache
[TRACE]:SPNEGO starting for url: <*>
[INFO]:log the counters
[INFO]:<*>: Assigned <*> to component instance <*> and launch on host <*>
[ERROR]:Error: status failed for (journal journal_and_stream)
[INFO]:FileJournalManager.doRollback called
[DEBUG]:Closing RBF metrics
[INFO]:this.prefix + metrics system started (again)
[DEBUG]:Handling deprecation for all properties in config...
[INFO]:Initializing Plan Follower Policy:org.apache.hadoop.yarn.server.resourcemanager.reservation.FairSchedulerPlanFollower
[ERROR]:Aborting since the Request has failed with all KMS providers(depending on <*>=<*> setting and numProviders=<*>) in the group OR the exception is not recoverable
[DEBUG]:NFS WRITE fileHandle: <*> offset: <*> length: <*> stableHow: <*> xid: <*> client: <*>
[ERROR]:Error when reading history file of application attempt
[DEBUG]:nothing to commit for <*>
[WARN]:The provided SubCluster Endpoint does not contain a valid host:port authority: <*>
[INFO]:Stopping app master
[INFO]:executing REST operation
[WARN]:Unable to create file cache directory : <*>
[DEBUG]:MemInfo : key : Value : value
[INFO]:readAggregatedLogs
[WARN]:Skipping unknown log deleter key fullKey
[DEBUG]:Deprecation logged for name
[DEBUG]:DIR* NameSystem.startFile...
[WARN]:Unknown bucket probe option: falling back to check #2
[DEBUG]:Uploading files
[DEBUG]:SelectBinding toString: <*>
[WARN]:Interrupted waiting for namespace to freeze
[INFO]:About to preserve attributes: + attrSymbols
[INFO]:sending redirect to: + loginURL
[WARN]:formatMessage(extraSleepTime, gcTimesAfterSleep, gcTimesBeforeSleep)
[INFO]:Trying to make localTarget active...
[DEBUG]:ID: <*> WRITE TO DISK
[WARN]:The application: + appId + has already finished, and has been removed from NodeManager, we should not receive the log aggregation status update for this application.
[INFO]:RECONFIGURE* changed blockInvalidateLimit to <*>
[ERROR]:Error While Storing RMDTMasterKey., e
[INFO]:op.getDebugInfo()
[DEBUG]:Skip <*>
[INFO]:queue: + queue
[INFO]:Using Auto Created Queue Management Policy: queueManagementPolicyClassName for queue: queueName
[INFO]:Container metrics ended running container
[DEBUG]:Ignoring
[TRACE]:Exiting getKeysMetadata method.
[INFO]:Initialized queue management policy for parent queue <*> with leaf queue template capacities: <*>
[ERROR]:Cannot get data for <*>: <*>
[INFO]:Waiting for executor to terminate
[INFO]:Topology scheduler allocated: + allocation
[DEBUG]:Heartbeater interrupted
[DEBUG]:seed: <*>
[DEBUG]:Getting target path
[WARN]:EventType: UnrecognizedTask cannot be recognized and handled by timeline service
[INFO]:Setting unmanaged AM
[WARN]:NativeIO.chmod error (%d): %s
[INFO]:datanode.getDNRegistrationForBP(bpid):Exception writing block to mirror mirrorAddr
[WARN]:delete(<*>) returned false, bufferFile.getAbsoluteFile()
[INFO]:Returning JSON response with location for file checksum
[DEBUG]:Service stopped
[DEBUG]:Updated disk outliers.
[INFO]:updating the following ReservationRequest: ...
[INFO]:Using pre-installed keytab from localhost: <*>
[DEBUG]:Closing and removing stale pool <*>
[WARN]:Could not find timestamp portion from path: <*>. Continuing with next
[DEBUG]:Creating Delegation Token Identifier
[WARN]:Resource + rsrc + localized without a location
[ERROR]:Planning failed: No valid allocation found
[INFO]:Container + container + of + finished application + appId + completed with event + event
[INFO]:Journal node retrieved or created
[DEBUG]:updateCGroupParam for path: <*> with value <*>
[ERROR]:Aocl output: <*>
[INFO]:Additional docker CLI options from plugin to run GPU containers: cliOptions
[DEBUG]:appending SAS token to query
[DEBUG]:Updating token in FileSystem state store
[DEBUG]:After remove stream + handle.dumpFileHandle() + , the stream number: + size()
[ERROR]:Cannot wait for the updater to finish
[DEBUG]:Configured with port to QOP mapping as: + portPropMapping
[DEBUG]:Performing recovery in + latestNameSD + and + latestEditsSD
[ERROR]:Failed to create NodeAttributesProvider based on Configuration
[INFO]:Disallowed NodeManager from host, Sending SHUTDOWN signal to the NodeManager.
[INFO]:Storing CA Certificate and Private Key
[DEBUG]:GZIP stream written
[WARN]:Can not set up custom log4j properties.
[DEBUG]:logRpcIds started
[WARN]:Unexpected exception from listDirRegistry
[INFO]:MembeshipStoreImpl cache loaded
[DEBUG]:Delete working path
[WARN]:Re-encryption updater thread exception.
[DEBUG]:<*>: Saving _SUCCESS file to <*> via <*>, successFile, getName(), successTempFile
[WARN]:TraceBuilder got an error while processing the <*> file
[DEBUG]:getName(): closed
[WARN]:Attempting to complete rename of file <*>/<*> during folder rename redo, and file was not found in source or destination <*>/<*>. This must mean the rename of this file has already completed
[DEBUG]:Codec registered: codec = <*>, coder = <*>
[WARN]:The value of <*> is less than 0.5 so volumes with less available disk space will receive more block allocations
[DEBUG]:First trial failed, node has no type <*>, making second trial carrying this type
[INFO]:<*>: Directory count = <*>; maximum depth <*>, getName(), dirCount, depth
[ERROR]:Cannot retrieve nameservices for JMX: <*>
[DEBUG]:CompositeService: starting services, size=...
[TRACE]:<*> Start <*>, getSpanId(), getDescription()
[DEBUG]:mkdir <*> with perms <*>
[DEBUG]:Fields parameter provided
[INFO]:Allocated VirtualCores: countHere
[DEBUG]:Cleaner finished
[DEBUG]:Using default endpoint; setting region to <*>, region
[ERROR]:Unable to insert the newly generated application <*>
[WARN]:TaskInfo is null for TaskAttemptUnsuccessfulCompletionEvent taskId: <*>
[DEBUG]:interrupted
[DEBUG]:Scanning intermediate dir ...
[ERROR]:Disk Balancer - Unable to find source volume: <*>
[INFO]:<*> already existed and we are not updating
[ERROR]:Error during log aggregation
[INFO]:Completing previous finalize for storage directory <*>
[DEBUG]:Getting pid for container <*> to kill from pid file <*>
[TRACE]:Adding context entry <*>
[INFO]:Scheduler metrics set to running
[INFO]:Dispatching CHECK_STABLE event
[INFO]:op=LISTSTATUS target=path
[ERROR]:Retrieving COS key: <*> occurs an exception. byte range start: <*>, exception: <*>.
[WARN]:Gave up waiting for the cleaner task to shutdown.
[TRACE]:allocShmSlot used up our previous socket...
[DEBUG]:,
[INFO]:Explicitly setting permissions to : (permission), (fsp)
[DEBUG]:AzureBlobFileSystem.delete path: <*> recursive: <*>, f.toString(), recursive
[INFO]:Executor terminated
[INFO]:Persistent memory is used for caching data instead of DRAM. Max locked memory is set to zero to disable DRAM cache
[INFO]:Un-publishing Volumes
[ERROR]:Can't read back <*> bytes, partial read size: <*>, count, readCount
[INFO]:launching container <*>
[DEBUG]:securityConnectionDiagnostics
[DEBUG]:Throttling re-encryption, sleeping for <*> ms
[DEBUG]:try to use reserved: + getQueuePath() + usedResources: + queueUsage.getUsed() + , clusterResources: + clusterResource + , reservedResources: + resourceCouldBeUnreserved + , capacity-without-reserved: + newTotalWithoutReservedResource + , maxLimitCapacity: + currentLimitResource
[DEBUG]:Reloading + REGISTRY.keySet().size() + existing configurations
[ERROR]:param + " is null"
[INFO]:Bulk delete <*> keys throttled -first key = <*>; last = <*>
[INFO]:Perms after creating (permission) , Expected: (expected_permission)
[INFO]:Updated reservation using PlanningAlgorithm
[INFO]:modifyCachePool of <*> successful; set default replication to <*>
[WARN]:Log wait warning as the lock was held for too long
[DEBUG]:rename: renaming file <*> to <*>
[WARN]:Doesn't look like the class <*> has the needed constructor, <*>
[WARN]:DistCpConstants.CONF_LABEL_MAX_CHUNKS_TOLERABLE should be positive. Fall back to default value: DistCpConstants.MAX_CHUNKS_TOLERABLE_DEFAULT
[DEBUG]:Initializing StorageLocationChecker
[INFO]:maxTaskFailuresPerNode is <*>
[WARN]:DIR* FSDirectory.unprotectedRenameTo: rename destination parent ... is a file.
[INFO]:Initializing Client
[TRACE]:Thread.currentThread().getId() + ": Response <*>"
[WARN]:Received exception in BlockPoolManager#shutDownAll
[DEBUG]:<*>: CACHE PUT: <*>, <*>
[ERROR]:Exception in app dir creation, disabling log aggregation
[INFO]:launcherHandlingThread.getName() + " interrupted during join ", ie
[INFO]:Use the new authorization provider API
[ERROR]:Exception transitioning to active
[DEBUG]:pre-assignContainers
[DEBUG]:Aborting upload
[INFO]:Sorry, no counters for nonexistent job
[DEBUG]:Creating file system output stream
[WARN]:Cannot retrieve S3_ENCRYPTION_KEY for bucket %s
[INFO]:Provided block pool slice fetched and logged
[ERROR]:Failed to get request data offset: + getPlainOffset() + " " + "count:" + count + " error:" + e1
[DEBUG]:AADToken: starting to fetch token using refresh token for client ID <*>
[INFO]:Update reservation request failed
[WARN]:Ignoring S3Guard store option of S3GUARD_METASTORE_LOCAL -no longer needed or supported. Origin <*>
[INFO]:Network latency avoided with append operation
[DEBUG]:Lease renewer daemon for <*> with renew id <*> executed
[DEBUG]:Random text data generator is configured to use a dictionary with words of length <*>
[DEBUG]:Reloading placement policy from allocation config
[DEBUG]:Discarding refreshed blocks for path <*> because lastBlockLength was -1
[DEBUG]:open URL connection
[TRACE]:Initiate check for delegation token manager
[DEBUG]:Add timeline delegation token into credentials: <*>
[INFO]:GridMix is configured to use a compression ratio of <*> for the reduce output data.
[INFO]:Fsck: copied the remains of the corrupted file <*> to /lost+found
[INFO]:sendTransferBlock called
[INFO]:Completed re-encrypting one batch of <*> edeks from KMS, time consumed: <*>, start: <*>., result, batch.size(), kmsSW.stop(), batch.getFirstFilePath()
[INFO]:Initializing RollingLevelDB for <*>
[ERROR]:Shuffle error :<*>
[DEBUG]:Initiating select call <*> <*>
[DEBUG]:Expected split length of proc info to be <*>. Got <*>
[ERROR]:Number of reservations (...) does NOT match the number of reservationQueues (...), while it should.
[INFO]:String.format(STATE_CHANGE_MESSAGE, appAttemptID, oldState, getAppAttemptState(), event.getType())
[DEBUG]:active commands: <*> for <*>
[WARN]:Unexpected error reading responses on connection
[WARN]:Unable to allocate any opportunistic containers.
[INFO]:NMAuditLogger log success for container
[ERROR]:Error processing response
[DEBUG]:Securing socket communication.
[INFO]:Allocating <*> threads per target.
[DEBUG]:DataNode Z reported slow disks: <*>
[DEBUG]:Writing entity log for <*> to <*>
[INFO]:StreamBaseRecordReader.init: start_=... end_=... length_=... start_ > in_.getPos() =...
[DEBUG]:Setting the flow run id: <*>, flowRunId
[INFO]:<*>: Creating Job Attempt directory <*>
[INFO]:Initialized cache for UID to User mapping with a cache timeout of cacheTimeout / 1000 + seconds.
[DEBUG]:Error parsing procInfo.
[INFO]:Removed ProcessTree with root <*>, <*>
[ERROR]:AHSWebApp failed to start.
[DEBUG]:Job Selected: <*>
[INFO]:Max mem capability of resources in this cluster <*>
[INFO]:Application removed - appId: + application.getApplicationId() + user: + application.getUser() + queue: + getQueuePath() + #user-pending-applications: + user.getPendingApplications() + #user-active-applications: + user.getActiveApplications() + #queue-pending-applications: + getNumPendingApplications() + #queue-active-applications: + getNumActiveApplications
[INFO]:createStartupShutdownMessage(classname, hostname, args)
[DEBUG]:Deleting files with dangling temp data in <*>, root
[INFO]:Writing to <*> target file path <*>
[DEBUG]:upload block finished for <*> ms. block <*>
[DEBUG]:Using CIDR match for 'host' and READ_WRITE
[WARN]:Failed to register MBean "<*>", e
[DEBUG]:Container removed from killable list
[INFO]:Container Resumed as some resources freed up
[INFO]:Transferring data to targets...
[INFO]:Error while creating of RM app master service proxy for attemptId,...
[INFO]:dev mode restart requested
[INFO]:Begin saveNameSystemSection
[INFO]:Moving har to original location
[WARN]:Log4j is required to enable async auditlog
[INFO]:Track duration and span executed successfully
[WARN]:couldn't find container + containerId + while processing FINISH_CONTAINERS event
[INFO]:The local AMRMToken has been rolled-over. Send new local AMRMToken back to application: + pipeline.getApplicationId()
[INFO]:Auditing event: queryRollingUpgrade
[INFO]:Updating final state <*> for attempt: <*>
[DEBUG]:Cluster Metrics Initialized
[INFO]:Successfully connected to ...
[ERROR]:Error While Removing RMDTMasterKey.
[INFO]:Collection by NativeMapOutputCollectorDelegator started
[ERROR]:Interrupted while waiting for application
[DEBUG]:Fallback to getPathStatus REST call as provided filestatus + is not of type VersionedFileStatus
[DEBUG]:Active scan starting
[INFO]:Have to change stable write to unstable write: STABLE_HOW_PLACEHOLDER
[WARN]:User + user + is not authorized to upload file + localPath.getName()
[WARN]:Failed to compute snapshot diff on ...
[INFO]:Queue configuration is refreshed successfully.
[DEBUG]:Closed file for DEBUGOUT or PROFILE
[DEBUG]:Ensuring destination doesn't exist and its parent is a directory
[ERROR]:Unexpected health check result <*> for volume <*>
[WARN]:Failed to evict old db <*>
[DEBUG]:Copied srcReplica.getMetadataURI() meta to dstMeta and calculated checksum
[DEBUG]:getUGI is returning: + ugi.getShortUserName()
[ERROR]:Attempt to remove resource: rsrc with non-zero refcount
[ERROR]:Subcluster <*> failed to return nodeInfo.
[ERROR]:Can't handle this event at current state, e
[INFO]:Queue: <*> removed
[DEBUG]:Get login user for proxy
[DEBUG]:Getting path status for <*> (<*>); needEmptyDirectory=<*>
[DEBUG]:Block<*>: Buffer file <*> exists â€”close upload stream
[INFO]:The output stream has been close, and begin to upload the last block: <*>.
[INFO]:Speculator notified for request
[WARN]:Using deprecated num.key.fields.for.partition. Use mapreduce.partition.keypartitioner.options instead
[INFO]:Job submission failed notification for job + jobID
[INFO]:Using TimelineWriter: + timelineWriterClassName
[TRACE]:Log trace without throwable
[INFO]:Converting placement rules
[ERROR]:Unable to remove container ...
[INFO]:Initialized the Backoff Decommission and Maintenance Monitor
[INFO]:Task failed
[DEBUG]:Binding in <*> to <*>
[DEBUG]:Dest file: + f
[INFO]:Removing old db directory contents in <*>
[INFO]:Successfully instantiated LdapSslSocketFactory with keyStoreLocation = <*> and trustStoreLocation = <*>
[INFO]:Obtained number of VCores used from Windows
[INFO]:Exception when processing re-encryption task for zone <*>, retrying...
[INFO]:shutdownDatanode command received (upgrade=...)
[INFO]:Set registry user accounts: sasl:username
[DEBUG]:DRConf - setVcoresPerNode: nodePrefix=<*>, vcores=<*>
[DEBUG]:Adjusting block totals from <*>/<*> to <*>/<*>, blockSafe, blockTotal, blockSafe + deltaSafe, blockTotal + deltaTotal
[INFO]:Log reader initialized
[DEBUG]:Skip this queue= + getQueuePath() + , because it doesn't need more resource, schedulingMode= + schedulingMode.name() + node-partition= + candidates.getPartition()
[WARN]:Exception shutting down SecondaryNameNode
[WARN]:Unable to locate pid file for container <*>
[INFO]:In memory ZK started at <*>
[INFO]:Added new reservation for periodic allocation
[INFO]:Preparing <*> directory/directories; <*> parent dirs implicitly created
[TRACE]:Exiting generateEncryptedKeys method.
[WARN]:checkDiskErrorAsync callback got <*> failed volumes: <*>
[DEBUG]:Job event handled
[INFO]:Container not found: $<*>
[INFO]:glob path pattern
[INFO]:Starting flush of map output
[ERROR]:Shuffle error + e
[ERROR]:No shared edits directory configured for namespace + nsId + namenode + namenodeId
[DEBUG]:AADToken: token expiring: <*> : Five-minute window: <*>
[INFO]:Submitting unmanaged application <*>
[INFO]:kvstart= + kvstart + ( + (kvstart * 4) + ); kvend= + kvend + ( + (kvend * 4) + ); length= + (distanceTo(kvend, kvstart, kvmeta.capacity()) + 1) + / + maxRec
[DEBUG]:Increasing replication from <*> to <*> for <*>
[INFO]:<*> transitioned from state <*> to <*>, event type is <*> and nodeId=<*>
[ERROR]:Cannot finish application from non-leaf queue:
[INFO]:Preserved status on + preservedEntries + dir entries on target
[DEBUG]:rpcServer.checkOperation called
[ERROR]:Init RESTRequestInterceptor error for user: <*>
[TRACE]:<*>: got security exception while constructing a remote block reader from <*>
[INFO]:Queue Management Policy monitor: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.QueueManagementDynamicEditPolicy
[INFO]:Computing extent of minshare starvation
[WARN]:getLabelsToNodes : Label <*> cannot be found
[ERROR]:Unable to update token <*>, <*>
[DEBUG]:NMToken key updated for application attempt : identifier.getApplicationAttemptId().toString()
[ERROR]:Store file failed. COS key: <*>, exception: <*>
[ERROR]:Must specify a valid cluster ID after the CLUSTERID flag
[DEBUG]:Setting the flow name: <*>, flowName
[WARN]:The diagnostic has failed
[ERROR]:KerberosName(principal) failed: %s\n%s
[WARN]:Unable to renew/regenerate token for appId
[ERROR]:Real capacity is negative. This usually points to some kind of mis-configuration. Capacity : %d Reserved : %d realCap = capacity - reserved = %d. Skipping this volume from all processing. type : %s id :%s
[DEBUG]:allocate: pre-update applicationId=applicationAttemptId application=application
[ERROR]:Cancelling futures.
[ERROR]:Unexpected event for REDUCE task (event.getType())
[INFO]:Clients are to use <*> to access this namenode/service.
[WARN]:No KEY found for persisted identifier <*>
[INFO]:Found <*> containers from ZK registry: <*>
[INFO]:Successfully logged refreshAdminAcls action
[DEBUG]:Validating mount table record
[ERROR]:Callback handler does not implement container rollback callback methods
[DEBUG]:xRequest.getResquestInfo().toString()
[INFO]:Application <*> submitted by user <*> rejected by placement rules.
[INFO]:Initialized nodemanager with : physical-memory= ... virtual-memory= ... virtual-cores= ...
[INFO]:Removing attempt someAttemptId from app: someAppId
[ERROR]:instance.getCompInstanceId() + : Error in handling event type + event.getType(), t
[DEBUG]:NFS LOOKUP fileId: <*> name: <*> does not exist
[DEBUG]:Starting HttpServer
[INFO]:Looking for process running on port <*>
[ERROR]:Service already at version
[DEBUG]:Application <*> has one mapper killed (<*>)
[INFO]:Waiting for aggregation to complete for <*>
[WARN]:Unable to delete cancelled checkpoint in <*>
[WARN]:Removing uninitialized application + application
[INFO]:Added token for + jobId.toString()
[INFO]:Initializing MultiNodeSorter= + policySpec.getPolicyName() + , with sorting interval= + policySpec.getSortingInterval()
[INFO]:Unable to delete source folder during folder rename redo. If the source folder is already gone, this is not an error condition. Continuing with redo.
[DEBUG]:Inform scheduler of node transition
[ERROR]:Failed Router login
[INFO]:\nDatanode Volume Report
[INFO]:Timeline service v1 batch publishing disabled
[INFO]:Connecting to + host + ...
[INFO]:<*>: Saving pending data information to <*>
[WARN]:HadoopLogsAnalyzer.processMapAttemptLine: bad numerical format, at line<*>.
[WARN]:Got IOException <*>; returned false
[DEBUG]:Failed to get number of entering maintenance nodes
[DEBUG]:Failed to load token fetcher implementation exception
[INFO]:Removed node from inactive nodes list
[DEBUG]:Running docker command: <*>
[WARN]:Remote Root Log Dir <*> already exist, but with incorrect permissions. Expected: <*>, Found: <*>. The cluster may have problems with multiple users.
[DEBUG]:Logging setup debug
[DEBUG]:Parent-provided session credentials will be propagated
[ERROR]:Fatal error occurred: err
[INFO]:Displaying usage information
[WARN]:Unable to parse credentials for <*>
[ERROR]:Invalid Node Label(s) from Provider : ...
[WARN]:Job init failed
[WARN]:Ignored <*> nodes while loading token cache.
[ERROR]:No component instance exists for + event.getContainerId()
[ERROR]:Error when writing finish information of container ...
[INFO]:Initialized plugin <*>
[WARN]:Could not obtain block: <*><*>. Throwing a BlockMissingException
[WARN]:Failed to parse + pid, e
[DEBUG]:SASL client doing general handshake for addr = <*>, datanodeId = <*>
[INFO]:Log segment finalized
[ERROR]:Unable to free lease on parentKey e
[DEBUG]:Failed to get provided capacity
[INFO]:Permissions on staging directory are incorrect: ... Fixing permissions to correct value ...
[ERROR]:RPCUtil.getRemoteException(new AccessControlException)
[INFO]:Moved: '...' to trash at: ...
[INFO]:Refreshing hosts (include/exclude) list
[DEBUG]:Host <*> is already blacklisted.
[INFO]:Deleting ResourceManager state store...
[ERROR]:IOException occurred: Throwing YarnRuntimeException
[ERROR]:Error: status failed for too many journals
[INFO]:Validating service resource
[DEBUG]:RETRY <*>) policy=<*>
[INFO]:AMRMProxyService is disabled
[DEBUG]:Exception thrown when get object meta: + key + , exception: + osse
[DEBUG]:Receiver: Block replaced
[WARN]:couldn't find app + appId + while processing + FINISH_CONTAINERS event
[ERROR]:Unexpected IOException
[ERROR]:FederationPolicyInitializationException error message
[DEBUG]:Ignoring cache report from <*> because <*> = false. number of blocks: <*>
[WARN]:Error reading the error stream
[INFO]:BackupNode namespace frozen.
[DEBUG]:Removing token at <*>
[DEBUG]:Appending key-value pair
[INFO]:(RESET) equator <*> kv <*> (<*>) kvi <*> (<*>)
[DEBUG]:Creating part upload request for <*> #<*> size <*>, uploadId, partNumber, size
[ERROR]:Exception while parsing json input stream
[DEBUG]:Getting EditLog
[INFO]:RMStateStore state change from <*> to <*>
[INFO]:Zone <*> starts re-encryption processing
[ERROR]:Failed to read the AM container of the application attempt <*>
[INFO]:Input size for job + job.jobId + = + inputLength + . Number of splits = + splits.length
[TRACE]:Skipping XMLEvent ...
[DEBUG]:Logging enabled
[DEBUG]:BLOCK* block <*> is moved from neededReconstruction to pendingReconstruction
[WARN]:Failed to relaunch container.
[ERROR]:Failed to create RMNodeLabelsMappingProvider based on Configuration
[DEBUG]:DFSClient check open
[DEBUG]:Change nextOffset to <*>
[WARN]:Cannot find trash root of path
[WARN]:Plugin manager was null while trying to add ResourceHandlers from configuration!
[INFO]:All checks pass. Launching privileged container for : <*>
[TRACE]:Setting token value to null (<*>), resp=<*>
[INFO]:Can't get path for toHandle fileId: <*>
[INFO]:Logging setup info
[DEBUG]:S3GetFileStatus <*>
[INFO]:FSHomeDir operation executed
[DEBUG]:allocate: applicationAttemptId=<*> container=<*> host=<*> type=<*>
[DEBUG]:<*>: retrying <*>
[INFO]:Set total to size of currentTokens
[INFO]:assignedContainer application attempt=<*> container=<*> queue=<*> clusterResource=<*> type=<*> requestedPartition=<*>
[ERROR]:Error starting JobHistoryServer
[WARN]:Abandoning block: + block
[DEBUG]:Updated queue management changes for parent queue <*>: <*>
[INFO]:There is no active RM right now.
[WARN]:Unable to fence - it is running but we cannot kill it
[DEBUG]:Starting to preempt containers for selectedCandidates and size:<*>
[WARN]:Accessible node labels for root queue will be ignored, it will be automatically set to "*".
[TRACE]:Adding slow peer report is disabled. To enable it, please enable config <*>.
[DEBUG]:Last queued seqno retrieved
[INFO]:<*> Component instance state changed from <*> to <*>
[DEBUG]:DatanodeManager.addDatanode: node <*> is added to datanodeMap.
[INFO]:Remove RMDT master key with key id: <*>
[WARN]:Error in looking up block
[WARN]:Unable to abort multipart upload, you may need to purge uploaded parts
[INFO]:Dump debug output
[ERROR]:Could not construct Shared Edits Uri
[INFO]:Super post called for UNSETSTORAGEPOLICY
[INFO]:Refreshing call queue.
[DEBUG]:SPEC(%d) %d -> %d %d/%d
[INFO]:File not found, creating node
[INFO]:Completion Successful
[INFO]:restoring dir <*>
[DEBUG]:S3A Delegation support token <*> with <*>, identifierToString(), tokenBinding.getDescription()
[WARN]:The filesystem based application history store is deprecated.
[DEBUG]:getEntityTimelines type=<*> ids=<*>
[WARN]:Could not find ip address of "default" inteface.
[WARN]:Exception while changing ops : e
[WARN]:Exception while trying to refresh reservable queues
[WARN]:Content of path is broken.
[INFO]:Shuffling to disk since <*> is greater than maxSingleShuffleLimit (<*>)
[ERROR]:Dump data failed: <*> OpenFileCtx state: <*>
[WARN]:Error loading classloader
[ERROR]:interrupted while waiting for reportCompileThreadPool to terminate, e
[INFO]:Not allocating more containers as we have reached max allocations per AM heartbeat <*>
[DEBUG]:Failed to create fake dir above <*>
[ERROR]:Could not instantiate ApplicationHistoryWriter: <*>
[DEBUG]:Got overwrite with appended data
[WARN]:Ignoring duplicate Resource plugin definition: <*>
[DEBUG]:assignContainers: partition= + candidates.getPartition() + #applications= + orderingPolicy.getNumSchedulableEntities()
[WARN]:Failed to execute refreshLoadedJobCache: JobHistory service is not started
[DEBUG]:Using default endpoint -no need to generate a configuration
[DEBUG]:This partition '<*>' doesn't have available or killable resource
[WARN]:-cacheArchive option is deprecated, please use -archives instead.
[ERROR]:Application attempt Id doesn't exist in ApplicationMasterService cache.
[ERROR]:Unresolved topology mapping. Using + NetworkTopology.DEFAULT_RACK + for host + node.getHostName()
[INFO]:GET: getService for appName = <*> user = <*>
[WARN]:These favored nodes were specified but not chosen: + favoredSet + Specified favored nodes: + Arrays.toString(favoredNodes)
[DEBUG]:Fetcher request verfied. enc_str=enc_str;reply=reply
[ERROR]:<*> is at <*> state, flex can only be invoked when service is running
[INFO]:Stopping JobHistory
[INFO]:SLSRunner takes <*> ms to launch all nodes.
[DEBUG]:writing intermediate results to <*>
[INFO]:Destination listing completed in <*>
[DEBUG]:Creating endpoint configuration for "<*>"
[DEBUG]:Refresh logs for cache id <*>
[INFO]:rollingMonitorInterval is set as <*>. The logs will be aggregated every <*> seconds
[INFO]:Logger debug executed
[WARN]:Error refreshing groups cache
[DEBUG]:For the job configuration parameter ' + jobValueKey + ' and the cluster configuration parameter ' + clusterValueKey + ', the original job's configuration value is scaled from ' + originalJobValue + ' to ' + simulatedJobValue + ' using the default (unit) value of ' + originalClusterDefaultValue + ' for the original cluster and ' + simulatedClusterDefaultValue + ' for the simulated cluster.
[DEBUG]:Truncating file starting with recordModification
[WARN]:Unsupported operation
[INFO]:JobId\\tQueue\\tAMType\\tDuration\\t#Tasks
[DEBUG]:BLOCK* findAndMarkBlockAsCorrupt: <*> not found
[DEBUG]:Shuffling from host
[DEBUG]:Cannot find file/folder - '<*>'. Returning owner as empty string
[DEBUG]:Waiting for storageMovementNeeded queue to be free!
[INFO]:Closing output
[ERROR]:Invalid root directory, unable to initialize driver.
[DEBUG]:<*>", key
[DEBUG]:Unknown child node with name <*> under <*>
[DEBUG]:flatBlockChecksumData.length=<*>, numDataUnits=<*>, checksumLen=<*>, digest=<*>
[INFO]:The specified queue: + getQueuePath() + is already in the RUNNING state.
[WARN]:Planning Algorithm has rejected for application <*> the following <*>
[INFO]:LOG.info(msg)
[DEBUG]:Received node update event:<*> for node:<*> with state:
[INFO]:Map ID + mapId + not found in cache
[WARN]:Unable to convert <*> to DNS name
[INFO]:Enter safe mode after <*> ms without reaching the State Store
[DEBUG]:All volumes are within the configured free space balance threshold. Selecting volume for write of block size replicaSize
[INFO]:Session expired. Entering neutral mode and rejoining...
[DEBUG]:currentIndex <*> + next + <*> + <*>
[DEBUG]:Obtained history dirs for cleaning
[DEBUG]:beforeExecute in thread: + Thread.currentThread().getName() + , runnable type: + r.getClass().getName()
[INFO]:Unchecked exception is thrown in handler for event <*> for Container
[DEBUG]:NodeManager <*> completed container (<*>).
[ERROR]:decayCurrentCosts exception: ...;
[DEBUG]:Clearing active block
[ERROR]:Error when publishing entity:
[WARN]:Found unexpected column for entity ...
[DEBUG]:Creating signer initializer: <*> for signer: <*>
[WARN]:Failed to get token for service
[TRACE]:Reading empty packet at end of read
[INFO]:SchedulingEditPolicy=... removed, stopping it now ...
[DEBUG]:Namenode domain name will be resolved with <*>
[INFO]:Initialized Yarn-registry with Filesystem
[DEBUG]:ShutdownHookManager completed shutdown.
[INFO]:Edited log entry
[INFO]:IP already in device "<*>,<*>", skip reprogramming
[INFO]:Wrote <*> bytes to <*>.java
[INFO]:Placement Spec received
[DEBUG]:To-release container=<*>, for a reserved container, is in final state
[DEBUG]:initiating asynchronous drain of <*> bytes
[INFO]:Service <*> submitted with Application ID: <*>
[INFO]:SchedulerAttempt + getApplicationAttemptId() + is recovering container + rmContainer.getContainerId()
[ERROR]:Unable to update token <*>
[INFO]:BlockRecoveryWorker: block=<*> (length=<*>), isTruncateRecovery=<*>, syncList=<*>
[INFO]:Finalize rolling upgrade logged at time: rollingUpgradeInfo.getFinalizeTime()
[WARN]:<*>: unknown response code <*> while attempting to set up short-circuit access. <*>. Short-circuit read for DataNode <*> is <*> based on <*>., this, resp.getStatus(), resp.getMessage(), datanode, disableMsg, DFS_DOMAIN_SOCKET_DISABLE_INTERVAL_SECOND_KEY
[DEBUG]:Attempted to update a non-existing znode + nodeRemovePath
[INFO]:appId not in the ResourceManager
[DEBUG]:krb5conf: krb5conf
[TRACE]:url=<*>
[DEBUG]:From NM Context container <*>
[DEBUG]:No custom signers specified
[INFO]:truncateBlock: blockFile= + blockFile + , metaFile= + metaFile + , oldlen= + oldlen + , newlen= + newlen
[DEBUG]:S3 Select request against <*>:\n<*>
[DEBUG]:Logging debug message
[WARN]:There's something wrong, some RMContainers running on a node, but we cannot find SchedulerApplicationAttempt for it. Node= + node.getNodeID() + applicationAttemptId= + rmContainer.getApplicationAttemptId()
[DEBUG]:BLOCK NameSystem.addToCorruptReplicasMap: <*> added as corrupt on <*> by <*> <*>
[INFO]:FPGA Plugin bootstrap success.
[INFO]:<*> Web address: <*>
[INFO]:App ended with state: ... and status: ...
[INFO]:Delete current dump directory <*>
[INFO]:Got environment: <*>, search IP file in localized resources
[INFO]:Restart service by <*>
[INFO]:Failed to read expected SASL data transfer protection handshake from client at ...
[ERROR]:Illegal event type: someClass
[INFO]:scanEditLog
[INFO]:ATTEMPT_START + event.getTaskID()
[WARN]:Skipping unexpected file in history server token bucket: ...
[WARN]:IPC_FCQ_DECAYSCHEDULER_FACTOR_KEY is deprecated. Please use IPC_SCHEDULER_DECAYSCHEDULER_FACTOR_KEY.
[INFO]:Loading directories in INode section.
[DEBUG]:Created DelegationTokenManager <*>
[DEBUG]:Trying to move container=<*> to node=<*>
[ERROR]:Wrong behavior during the update of SubCluster <*>
[DEBUG]:Tokens substitution for component instance: <*>
[TRACE]:Failed to register MBean "<*>", iaee
[INFO]:Conversion of proto to deletion task
[INFO]:getEcTopologyVerifierResultForEnabledPolicies
[ERROR]:Error storing appAttempt: $attemptState.getAttemptId(), $e
[INFO]:Invalid container ID: $<*>
[INFO]:Update resource on node(<*>) with resource(<*>)
[TRACE]:Successfully scanned <*> on <*>
[INFO]:Copying file
[INFO]:mlocking
[WARN]:Cannot update collector info because application ID: <*> is not found in RMContext!
[WARN]:<*>: already enabled scanning on block pool <*>
[DEBUG]:before vMemCheck + <*>, getContainersMonitor().isVmemCheckEnabled(), this.containersAllocation.getVirtualMemory(), (vMemBytes >> 20), (getContainersMonitor().getVmemAllocatedForContainers() >> 20)
[DEBUG]:Deleting of <*> file objects
[WARN]:Warning, no kerberos ticket found while attempting to renew ticket
[INFO]:Sending out X NM container statuses: Y
[DEBUG]:Get kerberos info proto: ...
[DEBUG]:Verifying and creating remote log directory
[ERROR]:Error in handling event type + event.getType() + for node + nodeId
[INFO]:ConfigurationProvider initialized
[WARN]:DatanodeAdminMonitor caught exception when processing node.
[INFO]:Begin saveSecretManagerSection
[ERROR]:<*> failed as operation on subfolders and files failed., operation
[INFO]:nodeId + is not added to AM blacklist for + applicationAttemptId + , because it has been removed
[DEBUG]:Checking application log directory
[ERROR]:Authorization failed during setAuthenticationMethod
[INFO]:setting hostname in container to: + name
[DEBUG]:Illegal progress value found, progress is less than 0. Progress will be changed to 0
[INFO]:Starting DocumentStore schema creation
[INFO]:FieldSelectionHelper.specToString(fieldSeparator, mapOutputKeyValueSpec, allMapValueFieldsFrom, mapOutputKeyFieldList, mapOutputValueFieldList) + \nignoreInputKey: + ignoreInputKey
[DEBUG]:DFSStripedOutputStream does not support hsync <*>. Caller should check StreamCapabilities before calling.
[INFO]:Resource Info Retrieved
[ERROR]:<*> ignoring reserved path <*>
[ERROR]:Response from the timeline reader server is <*>
[INFO]:Found null currentLocatedBlock. pos=<*>, blockEnd=<*>, fileLength=<*>
[DEBUG]:Going to check the following volumes disk space: + volumes
[DEBUG]:Seek to position <*>. Bytes skipped <*>, pos, this.pos
[DEBUG]:Copy object ETag
[INFO]:Successfully stopped service <*>
[DEBUG]:Stack Trace
[INFO]:Inside shutdown, con2infoMap size= + con2infoMap.size()
[WARN]:Removing unknown + containerEvent.getContainerID() + from application + app.toString()
[INFO]:SPS hint already removed for the inodeId:<*>. Ignoring exception:<*>
[DEBUG]:Check if HA is enabled
[WARN]:Failed to track container <*>. It may have already completed.
[INFO]:Will skip existing tables and continue on htable creation exceptions!
[INFO]:Deleting path : <*>
[DEBUG]:DataNode container stopped: <*>
[TRACE]:getOutliers: List=<*>, MedianLatency=<*>, MedianAbsoluteDeviation=<*>, upperLimitLatency=<*>
[WARN]:Error during write properties to the VERSION file to <*>, sd, e
[WARN]:Enable aggregators failed
[DEBUG]:Becoming standby for <*>
[WARN]:DataNode volume info not available.
[DEBUG]:BEFORE decResourceRequest: applicationId= applicationId.getId() priority= priority.getPriority() resourceName= resourceName numContainers= remoteRequest.getNumContainers() #asks= ask.size()
[DEBUG]:In HistoryEventHandler, handle timelineEvent: EVENT_TYPE
[INFO]:YARN Configuration: Disabled RM Placement Constraints Handler + placement handler will be used, all scheduling requests will + be rejected.
[INFO]:Entering state <*>
[ERROR]:%d labels specified on host=%s after add labels...
[WARN]:** FAILURE INJECTION ENABLED. Do not run in production! **
[DEBUG]:Setting counter <*> to <*>, key, value
[ERROR]:EOFException encountered
[ERROR]:Unable to get application information
[WARN]:Exception in checking the encryption zone for the path
[INFO]:Max app attempts is 1 for <*>, preventing further attempts.
[WARN]:Warning, no mapping for key: + key
[INFO]:Total VirtualCores: countHere
[DEBUG]:Initializing Authentication handler of type + authHandlerClassName
[WARN]:Slow RPC : <*> took <*> <*> to process from client <*>, the processing detail is <*>
[DEBUG]:Upload complete to <*> by <*>, key, writeOperationHelper
[INFO]:Error while creating Router RMAdmin Service for user:, user: <*>
[INFO]:Starting inMemoryMerger's merge since commitMemory= ... > mergeThreshold= ... . Current usedMemory= ...
[WARN]:File <*> skipped re-encryption because it is not encrypted! This is very likely a bug.
[WARN]:<*>: No files to commit
[TRACE]:Evaluating rule, subnet: <*>, path: <*>
[INFO]:Total time to add all replicas to map for block pool : ms
[WARN]:Can't append file: <*>. Possibly the file is being closed. Drop the request: <*>, wait for the client to retry...
[ERROR]:Wrong behavior during the insertion of SubCluster <*>
[INFO]:Can't get path for fileId: <*>, handle.getFileId()
[INFO]:Unknown localizer with localizerId + locId + is sending heartbeat. Ordering it to DIE
[DEBUG]:%s: setup task attempt path %s
[INFO]:Checkpoint preemption policy activated
[ERROR]:Exception in RestCsrfPreventionFilterHandler
[ERROR]:The job trace is empty
[DEBUG]:parsing File + file
[ERROR]:Unable to obtain the information for all the SubClusters
[DEBUG]:Scheduling move to done of <*>}
[DEBUG]:saveInodes and Snapshots completed
[WARN]:Could not add proxy for Journal at addresss <*>
[ERROR]:Log Directory is null, returning
[WARN]:Exception occurred
[WARN]:Skipping device <*> because it's not healthy
[DEBUG]:exclude:
[DEBUG]:<*> token found in cache : <*>
[ERROR]:Unable to get the application report for <*> to SubCluster <*>
[INFO]:Number of blocks under construction: <*>
[DEBUG]:Only using the first part of the path: <*> -> <*>, path, trimmedPath
[WARN]:ContainersMonitorImpl$MonitoringThread is interrupted. Exiting.
[ERROR]:AM is trying to <*> a container <*> that does not exist. Might happen shortly after NM restart when NM recovery is enabled
[WARN]:Encountered exception loading fsimage
[INFO]:Retry cache will use 0.2 of total heap and retry cache entry expiry time is 600000 millis
[INFO]:Computing capacity for map <*>
[WARN]:Trying to getHistory non-existing resource skylines for <*>.
[INFO]:Using ResourceCalculatorPlugin : + this.resourceCalculatorPlugin
[INFO]:Restored <*> block files from trash., restored
[TRACE]:Hosts:<*>, CNs:<*> subjectAlts:<*>, ie6:<*>, strictWithSubDomains<*>
[DEBUG]:Adding service + service.getName()
[DEBUG]:Storing final state info for app: <*> at: <*>
[WARN]:Other JournalNode addresses not available. Journal Syncing cannot be done
[INFO]:Creating new network-tagging-handler.
[DEBUG]:Writing NMTokenIdentifier to RPC layer: <*>, this
[DEBUG]:Setting entity creation time
[DEBUG]:Will send state token of size replyToken.length from saslServer.
[INFO]:storing RMDelegation token with sequence number
[DEBUG]:Reading credentials from location <*>
[DEBUG]:Added attempt req to host <*>
[ERROR]:Disk Balancer - Executing another plan, submitPlan failed.
[INFO]:name not found
[INFO]:Now scanning bpid <*> on volume <*>
[INFO]:starting
[INFO]:Found csi-driver-adaptor socket address: + addr
[INFO]:Failed to open path 'dir': Permission denied
[WARN]:this.prefix + metrics system already initialized!
[INFO]:DataNode ... are congested. Backing off for ... ms
[DEBUG]:PUT completed success=<*>; <*> bytes
[WARN]:mtime not found in file:<*>, will proceed with Du for space computation calculation
[INFO]:No Modified Node label Mapping to replace
[DEBUG]:Queueing reported block <*> in state <*> from datanode <*> for later processing because <*>.
[INFO]:Cleared trash for storage directory <*>
[DEBUG]:Job history notified
[DEBUG]:Block mover to satisfy storage policy; pool threads=<*>
[DEBUG]:Starting communication
[DEBUG]:KMS log starting
[WARN]:Cannot register namenode <*>
[INFO]:Resource decrease requests : + decreaseRequests
[WARN]:Unable to get user name. Fall back to system property user.name
[INFO]:Initialized queue: + fullQueueName
[DEBUG]:Failed to get number of blocks pending deletion
[WARN]:Failed to fetch application attempt report from ATS v2
[WARN]:SSL config sslProp is missing. If dfs.server.https.keystore.resource is specified, make sure it is a relative path
[DEBUG]:StatNode result: rc for path: path connectionState: zkConnectionState for this
[INFO]:logAuditEvent(false, "createSymlink", link, target, null)
[INFO]:Registered FSDatasetState MBean
[DEBUG]:Repeated write request which is already served: xid=<*>, resend response.
[INFO]:Starting to load token cache.
[INFO]:YarnConfiguration.NVIDIA_DOCKER_PLUGIN_V1_ENDPOINT set to empty, skip init ..
[ERROR]:Can't handle this event at current state: Current: <*>, eventType: <*>, container: <*>
[INFO]:Waiting for application
[ERROR]:FORCEFENCE and FORCEACTIVE flags not supported with auto-failover enabled.
[DEBUG]:The account access key is not configured for <*>. Now try anonymous access.
[WARN]:failed to cleanup app log dir ...
[DEBUG]:Thread.currentThread().getName(): starting
[INFO]:Deleting in-progress localization for <*> at <*>
[ERROR]:Can't close stream for fileHandle: <*>, <*>
[DEBUG]:Downgrading EOFException raised trying to read <*> bytes at offset <*>
[INFO]:Starting Router RMAdmin Service
[WARN]:Failed to cache + key + : Underlying blocks are not backed by files.
[TRACE]:getSubdirEntries(<*>, <*>): purging entries cache for <*> + after <*> ms.
[ERROR]:onContainerStopped received unknown container ID: <*>
[DEBUG]:Releasing buffer
[WARN]:Out of Memory in server select <*>
[TRACE]:latch done for file <*> buffer idx <*> length <*>
[DEBUG]:Revision ID changed from <*> to <*>
[DEBUG]:Assigned based on host match <*>
[INFO]:Application Master completed successfully. exiting
[WARN]:While completing all active copies
[INFO]:Rolling back storage directory ...
[INFO]:Action set for property: RESERVATION_SYSTEM
[INFO]:Using ReservationSystem: reservationClassName
[WARN]:LazyPersistFileScrubber encountered an exception while scanning for lazyPersist files with missing blocks. Scanning will retry in <*> seconds.
[INFO]:Executing with tokens: ...
[ERROR]:Cannot remove <*>
[INFO]:Launching AM with application attempt id ...
[ERROR]:Error in handling event type + event.getType() + for application + appID, t
[WARN]:sample log statement for warning
[ERROR]:error closing TcpPeerServer: , e
[WARN]:Error while decoding tstype
[WARN]:NN actor tried to claim ACTIVE state at txid= txid but there was already a more recent claim at txid= lastActiveClaimTxId
[WARN]:Cannot get all trash roots
[WARN]:waiting to get block: <*>
[ERROR]:Failed to do topology scheduling. Skip to use basic scheduling
[WARN]:couldn't find any VERSION file containing valid ClusterId
[ERROR]:FETCH_FAILED
[WARN]:An exception occurred during the cleanup of localizer job
[INFO]:Summary of summaryInfo.manifestCount manifests loaded in manifestDir: summaryInfo
[ERROR]:Cannot invoke <*> for <*>: <*>
[INFO]:Current application state of <*> is <*>, will retry later.
[INFO]:Suffix IDs retrieved successfully
[WARN]:Event ... sent to absent application ...
[DEBUG]:Path <*> for <*> didn't exist. Creating a new znode to update the application state.
[DEBUG]:getRegistryClient exists check passed
[WARN]:BR lease 0x<*> is not valid for DN <*>, because the lease has expired.
[DEBUG]:Failed to move reservation, cannot find source node=<*>
[DEBUG]:validateSpillIndexFileCB.. Path: <*>
[INFO]:User: <*>
[WARN]:Exception while trying to get password for alias <*>: <*>
[WARN]:Container %s is out of its limits, using %d when requested only %d
[INFO]:Processing items with groupSize > 0
[DEBUG]:Current Caller: <*> Priority: <*>
[INFO]:Create dump file: <*>
[INFO]:Rollbacked update reservation: <*> from plan.
[DEBUG]:Uploading part <*> for id '<*>'
[INFO]:Begin saveCacheManagerSection
[INFO]:Compute Plan for Node : <*>:<*> took <*> ms, node.getDataNodeName(), node.getDataNodePort(), endTime - startTime
[WARN]:Placement rule specified a parent queue <*>, but it is not a managed parent queue, and no queue exists with name <*> under it.
[INFO]:Waiting for MissingBlocks to fall below <*>...
[DEBUG]:New token service set. Token: (<*>)
[DEBUG]:capacityConfigType is updated as '<*>' for queue <*>
[INFO]:Received an RBW replica for <*> on <*>: ignoring it, since it is complete with the same genstamp
[DEBUG]:Initialized active resources
[DEBUG]:Begin loading cache pools
[DEBUG]:unreserving for app: + getApplicationId() + on nodeId: + idToUnreserve + in order to replace reserved application and place it on node: + node.getNodeID() + needing: + minimumUnreservedResource
[ERROR]:Failed to load state.
[INFO]:Delegation token set
[INFO]:Cleaning logs every <*> seconds
[DEBUG]:Filesystem <*> is closed
[DEBUG]:Container FINISHED: <*>
[INFO]:Finishing application master for <*>. Tracking Url: <*>
[DEBUG]:add file/dir + clfs
[DEBUG]:User ' + userName + ' has become active. Hence move user to active list. Active users size = + activeUsersSet.size() + Non-active users size = + nonActiveUsersSet.size() + Total Resource usage for active users= + totalResUsageForActiveUsers.getAllUsed() + . Total Resource usage for non-active users= + totalResUsageForNonActiveUsers.getAllUsed()
[DEBUG]:Sending sasl message + message
[INFO]:<*> is accessing unchecked <*> which is the app master GUI of <*> owned by <*>, remoteUser, toFetch, appId, runningUser
[ERROR]:Error removing app: <*>, <*>
[ERROR]:Callback handler does not implement container commit last re-initialization callback methods
[ERROR]:Unable to leave safemode.
[DEBUG]:Getting key information for key with name <*>.
[WARN]:Found endTxId ...
[INFO]:Skip allocating containers. Scheduler is waiting for recovery.
[DEBUG]:AM launched
[TRACE]:<*>: updateScannedBytes is zeroing out slotIdx <*>. curMinute = <*>; newMinute = <*>
[INFO]:DNS address
[ERROR]:Cannot get location for <*>: <*>
[INFO]:compInstance.getCompInstanceId() + (!hasContainerFailed ? succeeded : failed) + without retry, exitStatus= + event.getStatus()
[WARN]:Authentication exception: <*>
[WARN]:Failed to re-encrypt one batch of <*> edeks, start:<*>
[INFO]:Updating edits cache to use layout version <*> starting from txn ID <*>
[INFO]:*DIR* reportBadBlocks for block: <*> on datanode: <*>
[TRACE]:<*>: <*> createNewDirectory('<*>'), getName(), operation, path
[INFO]:Submitting application to RM
[INFO]:Initializing edits cache starting from txn ID %d
[DEBUG]:Worker thread was interrupted while processing an item, or putting into outputQueue. Retrying...
[ERROR]:Seems like client has been removed before the entity + could be published for + entity
[DEBUG]:<*> is recovering. Skip notifying APP_ACCEPTED
[DEBUG]:Got no rules - will disallow anyone access
[INFO]:Reported DataNode version 'dnVersion' of DN dnReg does not match NameNode version 'nnVersion'. Note: This is normal during a rolling upgrade.
[WARN]:Received null remoteUser while authorizing access to getImage servlet
[INFO]:The bound port is X, different with configured port Y
[ERROR]:Unable to create the interface to reach the SubCluster
[INFO]:Audit event for listStatus operation denied on src
[DEBUG]:File is not splittable so no parallelization is possible: <*>
[DEBUG]:Invocation returned standby exception on <*>, proxyInfo, ex
[INFO]:Removing ...
[DEBUG]:Loading application attempt from node: <*>
[WARN]:-cacheFile option is deprecated, please use -files instead.
[DEBUG]:No summary directory set in OPT_SUMMARY_REPORT_DIR
[INFO]:Target listing <*>
[DEBUG]:setsid is not available on this machine. So not using it.
[ERROR]:Event not handled because previousFailedAttempt is null
[ERROR]:Error storing app: + appId, e
[INFO]:JobHistory Init
[INFO]:Initializing Constraint Placement Planner:
[ERROR]:Solver timeInterval <*> is invalid, please specify a positive value., timeInterval
[DEBUG]:Statistics incremented
[ERROR]:Error getting localhost name. Using 'localhost'...
[INFO]:Loading <*> strings
[INFO]:Invoking method sequentially
[ERROR]:Unable to record localization start for + rsrc, e
[INFO]:Running Client
[TRACE]:Entering deleteKey method.
[WARN]:Exception when trying to release lease <*> on <*>. Lease will need to be broken: <*>
[DEBUG]:got reply from datanode:<*> for blockIdx:<*>, checksum:<*>
[DEBUG]:Application <*> has one reducer finished (<*>)
[ERROR]:Following nodes does not exist: invalidNodes
[INFO]:Priority retrieved for app: <*>
[INFO]:Timeline entities are successfully put
[ERROR]:Unauthorized access or invalid container
[DEBUG]:Error changing ownership of + item, e
[ERROR]:RPC.stopProxy called on non proxy: class=
[INFO]:<*> has been successfully deleted.
[DEBUG]:Fetching Mapper type map
[INFO]:MountTableResolver cache loaded
[WARN]:Metric name + name + was emitted with a null value.
[INFO]:ComposableInputFormat split executed
[INFO]:Log dir: <*>
[DEBUG]:Privileged Execution Command Array: ...
[INFO]:Total duration of deletion operation: <*>
[DEBUG]:allocate(arrayLength): count=count
[DEBUG]:Credentials list in <*>
[WARN]:<*>: Failed to rename manifests to <*>
[ERROR]:Failed to setup deferred error response. ThreadName= + Thread.currentThread().getName() + , Call= + this
[DEBUG]:JWT token is in a SIGNED state
[INFO]:Executing "Cancel plan" command.
[INFO]:Successfully updated lifetime for an service: serviceName = <*>, appId = <*>. New expiry time in ISO8601 format is <*>
[INFO]:removeCachePool of + poolName + successful.
[ERROR]:Failed to start namenode container ID <*> with error: <*>
[WARN]:Failed to init hostsReader, disabling, ex
[WARN]:Error while reloading manifest:
[DEBUG]:Distributed Node Attributes is enabled with provider class as : ConfigurationNodeAttributesProvider
[ERROR]:Failed to delete dumpfile: <*>
[WARN]:this + I/O error requesting file descriptors. Disabling domain socket <*>
[DEBUG]:Renewing delegation token <*> with url:<*>, as:<*>
[WARN]:Jetty request log for <*> was of the wrong class
[ERROR]:Cannot get mount point: <*>
[ERROR]:Thread exiting
[DEBUG]:Service <*> is started
[ERROR]:Did not remove "<*>"
[DEBUG]:Tried to read from deleted or moved edit log segment
[INFO]:Finished loading FSImage in <*> msecs
[DEBUG]:Start dump. Before dump, nonSequentialWriteInMemory == <*>
[WARN]:Could not make + path + in local directories from + dirsProp
[DEBUG]:Using query: ...
[ERROR]:Must specify exactly one token file
[ERROR]:Failed to store attribute modification to storage
[INFO]:Unknown application: + appId + released container + container.getId() + on node: + node + with event: + event
[INFO]:Cpu usage <*>
[DEBUG]:RejectPlacementRule instantiated
[INFO]:Initiating final putEntities, remaining entities left in entityQueue: <*>
[INFO]:Removing all registry entries for <*>
[WARN]:Configured write packet exceeds <*> bytes as max, + using <*> bytes., PacketReceiver.MAX_PACKET_SIZE, PacketReceiver.MAX_PACKET_SIZE
[WARN]:Failed to connect to dnInfo.addr for block block.getBlock(), e
[DEBUG]:Served: <*>
[WARN]:Unable to purge old storage + nnf.getName(), e
[INFO]:Namenode actor trying to claim ACTIVE state with txid= txid
[DEBUG]:Get kerberos info proto: ...;
[INFO]:Skip killing
[WARN]:Cannot allocate parity block(index=<*>, policy=<*>). Exclude nodes=<*>. There may not be enough datanodes or racks...
[DEBUG]:AM env: \n<*>
[DEBUG]:"getFileStatus(<*>) failed; returning null"
[DEBUG]:fs.azure.read.request.size<*> is configured for higher size than fs.azure.read.readahead.blocksize<*>. Auto-align readAhead block size to be same as readRequestSize., readBufferSize, readAheadBlockSize
[INFO]:Containers Reserved: countHere
[DEBUG]:Block compaction: activated with <*> blocks for <*>
[INFO]:Sucessfully stopped monitor= + mon.getName()
[WARN]:Exit code from container <*> is: <*>
[INFO]:DefaultCryptoExtension Decryption successful
[DEBUG]:Keystore hasn't changed, returning.
[INFO]:Namespace ID found
[DEBUG]:Validity of parameters checked
[INFO]:Tracking file changes to directory <*>
[INFO]:<*> allowed snapshot
[ERROR]:failed to load misc.Unsafe, e
[WARN]:Cannot request to call satisfy storage policy on path: <*>, as this file/dir was already called for satisfying storage policy.
[INFO]:Application Attempt is done. finalState=
[ERROR]:Unable to fetch cluster metrics
[ERROR]:Native-Task doesn't support secure shuffle
[INFO]:Loaded <*> edits file(s) (the last named <*>) of total size <*>, total edits <*>, total load time <*> ms
[ERROR]:Disabling journal <*>
[ERROR]:-alias flag is not optional for remove or cancel
[WARN]:Ending block pool service for: this
[INFO]:ops= + ops
[ERROR]:Error when executing command., e
[DEBUG]:Handle called for event
[INFO]:Job Overview generated
[ERROR]:Disk Outlier Detection daemon did not shutdown
[ERROR]:Error removing AMRMProxy application context for <*>, e=""
[WARN]:Parallel Image loading and saving is not supported when <*> is set to true. Parallel will be disabled.
[DEBUG]:NFS CREATE dir fileHandle: <*> filename: <*> client: <*>
[ERROR]:Unable to extract metrics: <*>
[DEBUG]:Select counter statement: + query
[INFO]:FSListStatusBatch operation executed
[DEBUG]:Auto increment set to false
[DEBUG]:Block token with <*> doesn't have the correct token password
[DEBUG]:Using delegation tokens
[INFO]:Refreshing list of NNs for nameservices: ...
[DEBUG]:Portmap GETPORT key= + key + + mapping
[DEBUG]:<*> is completing, remove <*> from NM context.
[ERROR]:PROCESS_ERROR_MESSAGE + filePath.toString(), t
[WARN]:Reporting bad block
[INFO]:DatanodeCommand action: DNA_UNCACHE for ... of <*>
[ERROR]:Exception in IBRTaskHandler.
[DEBUG]:Processing <*> of type <*>, event.getContainerId(), event.getType()
[DEBUG]:Checked operation
[WARN]:Volume usage (%d) is greater than capacity (%d). Setting volume usage to the capacity
[WARN]:Service interrupted by <*>
[ERROR]:Solver requires job resource skyline history for at least <*> runs, but it only receives history info for <*> runs.
[DEBUG]:No such resourceName=<*>
[INFO]:finalMerge called with X in-memory map-outputs and Y on-disk map-outputs
[INFO]:Rolling master-key for amrm-tokens
[WARN]:No AMRMToken found for user
[DEBUG]:Creating a JsonNodeConnector
[DEBUG]:Full stack trace on exception
[DEBUG]:Path could not be found: <*>
[INFO]:AUTH success for ... from ...
[DEBUG]:Read loop exited after final operation attempt
[DEBUG]:topN users size for command <*> is: <*>
[ERROR]:Queue policy can't be DRF if the parent policy is FairSharePolicy. Choose FairSharePolicy or FifoPolicy for child queues instead. Please note that FifoPolicy is only for leaf queues.
[INFO]:Deletion service called
[TRACE]:Connection <*> will skip to set fallbackToSimpleAuth as it is null., remoteId
[WARN]:Sleep in connection retry get interrupted.
[ERROR]:Cannot initialize ZK node for <*>: <*>, className, e.getMessage()
[DEBUG]:Keytab: <*>
[TRACE]:this: : purged replica from the cache. Removed from the replicaInfoMap. Removed from evictionMapName
[DEBUG]:getUGI is returning: ugi.getShortUserName()
[ERROR]:Must provide -service with http/https URL.
[ERROR]:Pre-existing final-path found at: finalDir
[WARN]:Exception shutting down access key updater thread
[INFO]:<*>'s ip = <*>, and hostname = <*>
[DEBUG]:A packet was last sent <*>ms ago.
[ERROR]:output
[INFO]:Commit operation via AzureBlobFileSystem in progress
[ERROR]:No parent path found, throwing PathNotFoundException
[DEBUG]:Atomic rename directories: <*>
[WARN]:Found jobId <*> to have not been closed. Will close
[ERROR]:Failed to kill unmanaged application master
[WARN]:Waited ... seconds after process completed for AppReport to reach desired final state. Not waiting anymore. CurrentState = ..., ExpectedStates = ...
[ERROR]:Cleanup with logger due to failure
[INFO]:Submitting tokens for job: +jobId
[INFO]:DatanodeCommand action: DNA_CACHE for ... of <*>
[WARN]:Not a valid queue state for queue
[DEBUG]:Setting up task commit statistics
[WARN]:Audit Event: setOwner failed for src
[INFO]:Formatting storage directory
[DEBUG]:Request for appInfo of unknown attempt <*>
[ERROR]:Upgrade did not complete because unable to re-write the service definition
[DEBUG]:instance.getCompInstanceName() + ": Connecting " + sockAddr.toString() + ", timeout=" + MonitorUtils.millisToHumanTime(timeout)
[DEBUG]:try refresh cache <*> <*>
[ERROR]:Name-node will treat the image as the latest state of the namespace. Old edits will be discarded.
[WARN]:App-level collector is not ready, skip aggregation.
[DEBUG]:<*> Cluster overloaded in run! Sleeping...
[WARN]:JobConf.deprecatedString(JobConf.MAPRED_MAP_TASK_ULIMIT)
[INFO]:Adding a node "node" to the list of hosts from filename
[DEBUG]:SegmentContainer initialized
[INFO]:Receiving <*> src: <*> dest: <*>
[WARN]:Failed to get node report
[ERROR]:Unable to determine local loopback address of 'localhost' -this system's network configuration is unsupported
[TRACE]:"<*>: Ignoring exception while serving <*> to <*>", dnR, block, remoteAddress, ignored
[DEBUG]:Cleaning up resources
[ERROR]:No movable source blocks found. <*>, item.toJson()
[DEBUG]:Added <*>:<*> into tokenKindMap
[WARN]:Error caching groups
[INFO]:Removed storage <*> from DataNode <*>
[INFO]:Starting AMRMProxyService
[DEBUG]:Operation unsetErasureCodingPolicy started
[ERROR]:Exception reading log file <*>
[INFO]:Expiration validation failed.
[WARN]:Cannot construct TACEStatus from TaskAttemptState: <*> for taskAttemptId: <*>. Defaulting to KILLED
[INFO]:Scanner skips for unknown file extension, filename = <*>
[INFO]:Recovering Reservation system
[INFO]:Finished loading INode directory section in <*>ms
[INFO]:Stopping the request processing pipeline for application: <*>
[INFO]:Resource usage matcher thread started.
[DEBUG]:StatNode result: + rc + for path: + path + connectionState: + zkConnectionState + for + this
[ERROR]:Closing proxy or invocation handler caused exception
[ERROR]:Queue + getQueuePath() + is not an instance of PlanQueue or ManagedParentQueue. + + Ignoring update + queueManagementChanges
[DEBUG]:DatanodeAdminMonitor is running.
[DEBUG]:Taking snapshot of IOStatisticsContext id <*>
[INFO]:YARN API server running on <*>
[DEBUG]:Retrying getTokenSingleCall. RetryCount = 1
[DEBUG]:Checking access privileges
[INFO]:The job has a total of <*> tasks. Any job larger than <*> will not be loaded.
[ERROR]:Duplicate jar/path/to/jar
[DEBUG]:Recovering localized resource <*> at <*>
[INFO]:getLogFile called
[INFO]:Prepared recovery for segment <*>: <*> ; journal id: <*>
[DEBUG]:Run as user <*>
[WARN]:Failed to cancel token for app collector with appId + appId
[INFO]:Successfully added reservation: ... to plan.
[WARN]:No TokenRenewer defined for token kind <*>
[DEBUG]:<*> exception cannot be retried
[WARN]:YarnConfiguration.RESOURCEMANAGER_CONNECT_MAX_WAIT_MS is smaller than YarnConfiguration.RESOURCEMANAGER_CONNECT_RETRY_INTERVAL_MS. Only try connect once.
[DEBUG]:Failed to move reservation, two nodes are in different partition
[WARN]:Not cleaning up tc rules. classId unknown for container: + containerId.toString()
[ERROR]:Heartbeat is enabled but there are no namenodes to monitor
[DEBUG]:List objects. prefix: <*>, delimiter: <*>, maxListLength: <*>, priorLastKey: <*>.
[INFO]:User refreshLogRetentionSettings access
[DEBUG]:CSConf - setCapacity: queuePrefix=<*>, capacity=<*>
[ERROR]:Cannot get a connection to <*> because the manager isn't running
[INFO]:drop FINISH_APPS event to + appID + because + container + container.getContainerId() + is recovering
[DEBUG]:NFS NULL
[DEBUG]:Upserting document under collection : <*> with entity type : <*> under Database <*>
[INFO]:Successfully registered for federation subcluster: <*>
[ERROR]:IOException during finalizing upgrade
[DEBUG]:Current active thread number: + executor.getActiveCount() + queue size: + executor.getQueue().size() + scheduled task number: + executor.getTaskCount()
[DEBUG]:Copied <*> bytes
[WARN]:Could not parse line '<*>'. Lines should be of the form '<*> <*> <*>'. Blank lines and everything following a '#' on a line will be ignored.
[DEBUG]:Updating the overload status.
[INFO]:Formatting journal id : <*> with namespace info: <*> and force: <*>
[DEBUG]:No block has been moved for X iterations, maximum notChangedIterations before exit is: Y
[DEBUG]:prefix match2 for <*>: <*>
[DEBUG]:stats.toStringDetailed()
[INFO]:Version check started
[INFO]:No striped internal block on source <*>, block <*>. Skipping.
[WARN]:Error processing datanode Command, ioe
[DEBUG]:Deleting magic directory Path
[DEBUG]:Error during message receipt
[DEBUG]:Unable to de-serialize block token identifier for user=<*>, block=<*>, access mode=<*>
[DEBUG]:Getting output stream failed with expect header enabled, returning back
[WARN]:PendingReconstructionMonitor timed out <*>
[ERROR]:msg, e
[WARN]:Node exists exception
[DEBUG]:<*>: Not scheduling suspect block <*> for rescanning, because this volume scanner is stopping.
[INFO]:Using ResourceCalculatorPlugin: <*>
[INFO]:Checking removing StorageLocation <*> with id <*>
[INFO]:this starting to offer service
[DEBUG]:<*>: starting cache cleaner thread which will run every <*> ms, this, rateMs
[INFO]:Returning authentication parameters
[WARN]:writeTransactionIdToStorage failed on <*>
[WARN]:Periodic Directory Tree Verification scan is disabled because verification is not supported by SimulatedFSDataset
[INFO]:Logger for Server class initialized
[DEBUG]:rpcKind= + rpcKind + , rpcRequestWrapperClass= + rpcRequestWrapperClass + , rpcInvoker= + rpcInvoker
[INFO]:Stop the service by <*>
[INFO]:Waiting for AsyncDispatcher to drain. Thread state is :<*>
[ERROR]:NODE_LABELS_NOT_ENABLED_ERR
[WARN]:Cannot list more tasks in container <*> to kill.
[INFO]:Added rolling leveldb instance <*> to <*>
[DEBUG]:allocate(arrayLength)
[INFO]:Probe for isRecoverySupported(<*>): returning false
[ERROR]:Unknown resource reported: <*>
[DEBUG]:Updating <*> with <*> bytes
[INFO]:Reading auxiliary services manifest + manifest
[ERROR]:Error while adding input path
[ERROR]:Callback handler does not implement container resource increase callback methods
[INFO]:PostWrite processing with TFileController
[DEBUG]:Removing token
[INFO]:Error getting UGI
[INFO]:Exception while running the resource-usage-emulation matcher + thread! Exiting.
[INFO]:Replica <*> still can't be uncached because some clients continue to use it. Will wait for <*>
[TRACE]:<*>: thread starting.
[INFO]:Container information displayed
[DEBUG]:Did not find any metadata for path: <*>
[INFO]:Deleted block
[ERROR]:====== Fencing on target failed, skipping fencing on source ======
[DEBUG]:Loading application from node: <*>
[ERROR]:Delete failed for workDir
[DEBUG]:BLOCK* rescanPostponedMisreplicatedBlocks: Postponed mis-replicated block <*> no longer found in block map.
[TRACE]:<*>: can't construct BlockReaderLocalLegacy because the address + <*> is not local
[INFO]:closing the entity table
[INFO]:Blacklisted <*>
[INFO]:Localized resourcePath as path
[INFO]:<*> is at <*>, forcefully killed by user!
[ERROR]:Cannot build location, <*> not a child of <*>
[WARN]:Unable to delete our own bread-crumb of being active at <*>. . Expecting to be fenced by the next active.
[DEBUG]:Attempting to load UUID from log file
[WARN]:Gridmix will not emulate Distributed Cache load because <*> provided is on local file system.
[INFO]:LOG: Successfully finished killed container
[TRACE]:Processing operation for req=(<*>), token: <*>
[INFO]:System.out.println(response)
[INFO]:Update max queue length of app activities from <*> to <*>, configured=<*>, numNodes=<*>, numAsyncSchedulerThreads=<*> when multi-node placement disabled.
[INFO]:HTTP Server started
[INFO]:RECONFIGURE* changed heartbeatRecheckInterval to ...
[INFO]:Recovering application <*>
[DEBUG]:GetACLS <*>
[INFO]:Creating a request outside an audit span
[DEBUG]:looking for configuration option <*>
[TRACE]:SAS token fetch complete for <*> on <*>
[DEBUG]:removeAclEntries filesystem: <*> path: <*> aclSpec: <*>
[INFO]:<*> not found
[WARN]:Exception in Responder <*>
[INFO]:Received list of auxiliary services: + mapper.writeValueAsString(services)
[DEBUG]:Couldn't delete <*> - does not exist: <*>
[ERROR]:Returning, interrupted :
[ERROR]:Wrong Namenode to monitor
[WARN]:jwtToken failed validation: + jwtToken.serialize()
[ERROR]:Hadoop HttpServer2 App **failed**, <*>
[INFO]:Cancelled zone <*>(<*>) for re-encryption.
[INFO]:DatanodeCommand action: DNA_BALANCERBANDWIDTHUPDATE
[WARN]:"Failed to authorize when generating application report for " + app.appReport.getApplicationId() + ". Use a placeholder for its latest attempt id. "
[WARN]:unable to return groups for user <*> <*>
[INFO]:Job Abort statistics <*>
[WARN]:Can't find user name for uid + uid + . Use default user name + unknown
[DEBUG]:removing client from cache: <*>
[WARN]:dirsProp + "<*>=" + dirs<*>
[INFO]:AsyncDispatcher is draining to stop, ignoring any new events.
[DEBUG]:Resolved path is <*>
[ERROR]:Failed to upgrade component instance: <*>
[INFO]:Caught interrupted exception
[WARN]:Resolve Duplicate Replicas
[INFO]:resourceName + plugin update resource
[INFO]:Invoking method 'finalizeUpgrade' concurrently on namespaces
[DEBUG]:Processing XML
[WARN]:Please check the configuration value of NM_GPU_PATH_TO_EXEC. It should point to an DEFAULT_BINARY_NAME binary.
[DEBUG]:Queue=<*> partition=<*> resource-to-obtain=<*>
[DEBUG]:<*>: canâ€™t construct BlockReaderLocalLegacy because disableLegacyBlockReaderLocal is set.
[INFO]:Initializing Existing Jobs...
[INFO]:NN is transitioning from active to standby and FSEditLog is closed -- could not read edits
[DEBUG]:Buffer size and replication are not honored by ADL backend
[DEBUG]:Reading diskbalancer Status failed.
[INFO]:FS:<*> adding export Path:<*> with URI: <*>
[INFO]:Loading <*> inodes.
[DEBUG]:Attempting to service <*> using proxy <*>
[ERROR]:Cannot heartbeat for router: unknown router id
[WARN]:Could not run type-specific cleanup on application <*> of type <*>, <*>
[INFO]:FAIL: <*>, <*>
[DEBUG]:Assigning container failed on node '<*>' because queue resource usage is larger than MaxShare: <*>
[INFO]:Container completed without partition
[INFO]:Could not get Job info from RM for job
[DEBUG]:Admin button rendered
[INFO]:Deleting path
[INFO]:Using schema-specific factory for <*>
[INFO]:Remove labels: <*>
[WARN]:Error trying to clean up
[DEBUG]:Added Execution Type=<*>
[WARN]:Cannot parse GPU device numbers: device
[DEBUG]:Failed to connect to server: + server + : + action.reason, ioe
[DEBUG]:<*> reported unusable
[DEBUG]:logSync <*>
[INFO]:Start checkpoint at txid X<*>
[INFO]:Unchecked exception is thrown from onGetContainerStatusError for Container + containerId, thr
[INFO]:Resources subtracted
[DEBUG]:Queuing scan of directory <*>
[WARN]:chunkFilePath could not be assigned to taskId
[DEBUG]:listStatus: doing listObjects for directory <*>
[INFO]:pmdkSupportState.getMessage()
[DEBUG]:Authenticated from delegation token. url=<*>, token=<*>
[INFO]:Delete from the StateStore the application: <*>
[DEBUG]:Setup connection to ...
[DEBUG]:Decrypting key for <*>, the edek Operation is <*>.
[INFO]:Update RMDT with sequence number
[INFO]:Jersey resource package added
[DEBUG]:Removing master key <*>
[INFO]:LIST (continued)
[INFO]:Matcher matches and returns result
[DEBUG]:Check node: <*>, type: <*>., datanodeInfo, type
[WARN]:Couldn't disconnect ssh channel
[INFO]:Aborting Job <*> in state <*>
[DEBUG]:Refresh user groups mapping in Router.
[ERROR]:Cannot get <*> nodes, Router in safe mode
[WARN]:BlocksStorageMovementAttemptMonitor thread received exception and exiting.
[INFO]:Source Repository : <*>
[DEBUG]:Try allocate on node
[TRACE]:Exiting getKeyVersions method.
[INFO]:Using resource <*> directly from current location: <*>
[DEBUG]:Native library check initiated
[DEBUG]:Checking for old call responses.
[TRACE]:nextTcpPeer: reusing existing peer <*>
[ERROR]:Unable to obtain the SubCluster information for <*>
[INFO]:getting attribute: + CONF_SERVLET_RECONFIGURABLE_PREFIX + req.getServletPath()
[INFO]:Executing "execute plan" command
[WARN]:Can't handle this event at current state: Current: <*>, eventType: <*>, volumeId: <*>
[ERROR]:All components have NEVER restart policy
[WARN]:Failed to get device type from stat <*>
[DEBUG]:BLOCK* removeStoredBlock: <*> has already been removed from node <*>
[DEBUG]:Processing RPC with index <*> out of total <*> RPCs in processReport 0x<*>
[INFO]:ContainersMonitorImpl monitoring thread interrupted
[INFO]:Probe for needsTaskCommit(<*>)
[DEBUG]:Resource for node: nid; is adjusted from: capability; to: dynamicLoadCapability
[WARN]:Failed to load/initialize native-bzip2 library + libname + , will use pure-Java version
[INFO]:Not attempting to recover. Recovery is not supported by committer.getClass(). Use an OutputCommitter that supports recovery.
[DEBUG]:Configuring readable endpoints
[INFO]:AM process exited with value: <*>
[ERROR]:Error While Updating RMDelegationToken and SequenceNumber
[DEBUG]:Creating path <*> with mode <*> and ACL <*>
[INFO]:Endpoint details printed
[ERROR]:Balancer exiting as upgrade is not finalized, please finalize the HDFS upgrade before running the balancer.
[INFO]:blacklistDisablePercent is <*>
[DEBUG]:Loading section INODE length: <*>
[INFO]:Job received kill in SETUP state.
[INFO]:Update resource on node: <*> from: <*>, to: <*> in <*> ms
[INFO]:Nodes refreshed
[INFO]:Insert into the StateStore the application: <*> in SubCluster: <*>
[DEBUG]:Added attempt req to rack <*>
[ERROR]:CONTAINER_REMOTE_LAUNCH contains a reduce task
[ERROR]:Error when executing command, command=<*>
[ERROR]:Merging failed X times.
[ERROR]:ShutdownHookManager interrupted while waiting for termination.
[WARN]:Max block location exceeded for split: <*> splitsize: <*> maxsize: <*>
[ERROR]:Cannot read JMX bean <*> from server <*>
[DEBUG]:Initializing the ViewFileSystemOverloadScheme with the uri: ...
[WARN]:Failed to delete <*>
[DEBUG]:Authenticating request with OAuth2 access token
[WARN]:Exception while closing CheckpointStorage
[DEBUG]:DIR* FSDirectory.unprotectedDelete: failed to remove $<*> because it does not exist
[WARN]:BLOCK* BlockUnderConstructionFeature.initializeBlockRecovery: No blocks found, lease removed.
[INFO]:Storing configuration store version info <*>
[INFO]:FederationStateStoreClientMetrics succeeded state store call
[INFO]:canceling the task attempt
[TRACE]:createNewMemorySegment: ShortCircuitRegistry is not enabled.
[DEBUG]:Outputting container log
[DEBUG]:Meta folder location: + metaFolderPath
[DEBUG]:<*> Skipping disk from computation. Maximum data size achieved., lowVolume.getPath()
[INFO]:Edit logged
[INFO]:Runtime information:
[INFO]:Submitting reservation through RouterClient
[ERROR]:Thread <*> threw an Throwable, but we are shutting down, so ignoring this
[ERROR]:Unknown event arrived at FairScheduler: <*>
[DEBUG]:App-level real-time aggregation complete
[INFO]:logAuditEvent: success, operationName, src, null, auditStat
[ERROR]:Could not get inputStream position.. Path <*>
[INFO]:<*> pending cancellation
[INFO]:Error cleaning master , ie
[INFO]:Deleting key: <*> from KeyProvider: <*>
[INFO]:<*> failed.
[TRACE]:this: registered blockId with slot slotId (isCached=true)
[ERROR]:Error when writing start information of application X
[DEBUG]:Getting datanode storage report
[INFO]:Upload initiated
[DEBUG]:Initializing S3A FS to <*>
[INFO]:BlockRecoveryWorker: <*> calls recoverBlock(<*>, targets=<*>, newGenerationStamp=<*>, newBlock=<*>, isStriped=<*>)
[ERROR]:Wrong behavior during deleting the application <*>
[DEBUG]:Proceeding with shuffle since usedMemory (<*>) is lesser than memoryLimit (<*>). CommitMemory is (<*>)
[DEBUG]:Fetching document for entity type <*>
[ERROR]:FileNotFoundException exception in listStatus: <*>
[DEBUG]:Checked safe mode status
[DEBUG]:Gracefully shutting down executor service <*>. Waiting max <*> <*>
[ERROR]:<*>: Error in handling event type <*>
[TRACE]:RefreshTokenBasedTokenProvider initialized
[INFO]:Credential <*> has NOT been deleted.
[ERROR]:Exception encountered while running workload job
[INFO]:Intel aocl program <*> to <*> successfully
[WARN]:ServicePlugin + p + " could not be started"
[WARN]:JobConf.deprecatedString(JobConf.MAPRED_TASK_ULIMIT)
[DEBUG]:No previous Document found with id : <*> for Collection : <*> under Database : <*>
[INFO]:Input data generation successful.
[ERROR]:Application: %s is not found
[ERROR]:Could not commit job
[DEBUG]:Finished dispatching all Mappper.map calls, job <*>
[INFO]:Audit log creation failed
[INFO]:GridMix is configured to generate compressed input data with a compression ratio of ratio
[DEBUG]:CSConf - getCapacity: queuePrefix=<*>, capacity=<*>
[DEBUG]:TC state: <*> + output
[DEBUG]:Reverting to old configuration
[ERROR]:Failed to update node Labels
[DEBUG]:Exception thrown when copy file
[DEBUG]:BLOCK* NameSystem.abandonBlock: <*> is removed from pendingCreates
[ERROR]:Refresh user to groups mapping failed for address
[DEBUG]:Summary: <*> <*>
[WARN]:<*> exception trying to reap container. Ignoring. <*>
[INFO]:Reconfiguring <*> to <*>, property, newVal
[DEBUG]:Failed to get remaining capacity
[DEBUG]:NFS READ fileHandle: <*> offset: <*> count: <*> client: <*>
[DEBUG]:Error getting groups for <*>
[ERROR]:Multipart upload with id: <*> to COS key: <*>
[ERROR]:Error launching job , Output path already exists :
[DEBUG]:BLOCK* addToInvalidates: storedBlock datanodes
[INFO]:<*><*> <*>
[DEBUG]:<*>: sending response
[INFO]:Purging old legacy OIV images
[DEBUG]:End loading cache pools
[INFO]:Removing expired token ...
[WARN]:Continuous scheduling thread interrupted. Exiting.
[INFO]:Cancel service upgrade by <*>
[INFO]:Store file from input stream. COS key: <*>, length: <*>.
[INFO]:number of queues = <*> average number of apps = <*>
[INFO]:Starting task: + mapId
[ERROR]:instance.getCompInstanceId() + ": Error in handling event type " + event.getType()
[WARN]:Invalid value for + MRJobConfig.HEAP_MEMORY_MB_RATIO + , using the default.
[WARN]:Unknown DatanodeCommand action: <*> from standby NN <*>
[ERROR]:-alias flag is not optional for renew
[INFO]:Received URL ... from user ...
[DEBUG]:Store file successfully. COS key: <*>, ETag: <*>.
[WARN]:Cannot move meta file ... back to the finalized directory ...
[DEBUG]:MapOutput URL for host -> url
[WARN]:Fatal disk error on Unknown DataNode: ...
[INFO]:NativeHandler: direct buffer size: + bufferSize
[ERROR]:Cannot get the live nodes: <*>
[ERROR]:Name 'elementName' is repeated in the 'deleted' difflist of directory 'dirFullPath', INodeId=dir.getId()
[ERROR]:YARN Service is unavailable or disabled.
[DEBUG]:Ignoring exception while closing socket
[INFO]:Waiting for %d DataNodes to register with the NameNode...
[INFO]:Adding a new node:
[DEBUG]:Request timeout is too high(<*> ms). Setting to <*> ms instead
[INFO]:All tasks scheduled
[DEBUG]:Loaded RM delegation key from keyId=<*>, expirationDate=<*>
[INFO]:Exception while executing a FS operation.
[INFO]:BLOCK* allocateBlock: caught retry for allocation of a new block in /* src from code */. Returning previously allocated block /* lastBlockInFile from code */
[INFO]:Initializing ZooKeeper connection
[DEBUG]:Number of storages reported in heartbeat=<*>; Number of storages in storageMap=<*>
[INFO]:Adding cross-site request forgery (CSRF) protection, headerName = <*>, methodsToIgnore = <*>, browserUserAgents = <*>
[INFO]:Listening on %s with %s
[DEBUG]:Creating placement context for user <*> using primary group current user mapping
[INFO]:ApplicationId unregistered successfully.
[ERROR]:The specified Reservation with ID ... already exists
[DEBUG]:Unset <*>
[INFO]:Recovery ended
[DEBUG]:Adding scanner for volume <*> (StorageID <*>)
[INFO]:RegisterUAM returned <*> existing running container and <*> NM tokens
[INFO]:Setting truststore location to
[INFO]:Key creation with LoadBalancingKMSClientProvider successful
[DEBUG]:Created attempt attempt.getID
[INFO]:Action set for property: USER_MAX_APPS_DEFAULT
[DEBUG]:Couldn't create proxy provider <*>
[ERROR]:Trash and PreviousDir shouldn't both exist for storage directory <*>
[INFO]:Bytes array null, written -1
[WARN]:The value of DFS_NAMENODE_AVAILABLE_SPACE_BLOCK_PLACEMENT_POLICY_BALANCED_SPACE_PREFERENCE_FRACTION_KEY is greater than 1.0 but should be in the range 0.0 - 1.0
[DEBUG]:renameAsync filesystem: <*> source: <*> destination: <*>
[INFO]:storing master key with keyID
[WARN]:Requested range [%d, %d) is beyond EOF for path %s
[INFO]:Starting to clean up previous job's temporary files
[INFO]:Initializing request processing pipeline for application for the user: <*>
[DEBUG]:Secret keys
[INFO]:starting recovery...
[ERROR]:You must have an input cycle length.
[DEBUG]:MOUNT UMNT path: <*> client: <*>
[ERROR]:Interrupted while stopping
[INFO]:Using SequenceFileInputFormat: $<*>
[WARN]:Event <*> sent to absent application <*>
[WARN]:BLOCK* removeDatanode: node does not exist
[INFO]:Nodes for scheduling has a blacklisted node <*>.
[TRACE]:nextDomainPeer: reusing existing peer <*>
[INFO]:Starting task: <*>
[INFO]:Switching to Random IO seek policy
[DEBUG]:Action <*> failed
[ERROR]:Got exception in parsing URL of LocalResource:
[DEBUG]:Decoding FileEncryptionInfo
[DEBUG]:<*>
[WARN]:Could not verify Certificate, Public Key, and Private Key: regenerating
[INFO]:Sending OOB to peer: <*>
[ERROR]:Error closing read selector in <*>, <*>
[INFO]:Attempting to abort multipart uploads under path
[WARN]:report bad block <*> failed
[DEBUG]:DataInputStream initialized
[DEBUG]:Container allocated on a single node
[INFO]:RELATES_TO field filter added
[DEBUG]:Duplicate FS created for <*>; discarding <*>
[ERROR]:Attempting to remove non-existent node <*>
[INFO]:Creating CuratorService with connection <*>
[WARN]:Failed to connect to host: + url + after + fetchRetryTimeout + milliseconds.
[WARN]:Out of sync with RM $<*> for $<*>, hence resyncing.
[WARN]:Cannot register namenode, router ID is not known <*>
[WARN]:Proxy host set without port. Using HTTP default 80
[DEBUG]:Switching to seek policy Random after unbuffer() invoked
[DEBUG]:Summary of operations loaded from edit log:\n ...
[DEBUG]:Matched regex: regex
[DEBUG]:Stream statistics of <*>
[ERROR]:Cannot get stats info for <*>: <*>.
[INFO]:Found Resource plugins from configuration: <*>
[INFO]:Starting job class loader creation
[ERROR]:Failed to remove volume
[INFO]:<*> data directory doesn't exist, creating it
[INFO]:Running as loginUser.getShortUserName() but will impersonate user
[DEBUG]:Changing permissions for path <*> to perm <*>
[INFO]:Default key bitlength is <*>
[WARN]:Failed to bootstrap outbound bandwidth rules
[INFO]:Starting Web-server for name at: uri
[DEBUG]:Creates the UAM connection
[WARN]:Default network: ... is not in the set of allowed networks: ... Please check configuration
[WARN]:Got exception while looking for AMRMToken for user
[INFO]:Stopping server on
[DEBUG]:DIR* FSDirectory.renameTo: srcIIP.getPath() to dstIIP.getPath()
[DEBUG]:resetting default realm failed, current default realm will still be used.
[DEBUG]:Storing localized resource to <*>
[INFO]:Updated reservation using TryManyReservationAgents
[DEBUG]:Thread.currentThread().getName(): exiting
[DEBUG]:CosmosDB Sql Query with predicates : <*>
[DEBUG]:Could not sync with Journal at...
[WARN]:Failed to load commit file <*>
[INFO]:Successfully Unregistered the Node + this.nodeId + with ResourceManager.
[DEBUG]:wake up: org.apache.hadoop.hdfs.util.ByteArrayManager$FixedLengthManager instance, recycled? true
[WARN]:Fsck error_message
[INFO]:Failed to read config version at <*>
[INFO]:containers.size() + " containers allocated."
[INFO]:Adding credentials
[DEBUG]:localizeClasspathJar: jarPath target o:owner
[INFO]:Initializing cache loader: MemoryMappableBlockLoader.
[INFO]:<*> cancelling upgrade, container.getId()
[ERROR]:getCredentials is an invalid operation in SAS Key Mode
[INFO]:$<*>, $<*>
[WARN]:Exception while getting number of live datanodes.
[DEBUG]:Node's resource is updated
[ERROR]:Encountered SASKeyGeneration exception while generating SAS Key for relativePath : <*> inside container : <*> Storage account : <*>
[WARN]:Invalid SubCluster Id information. Please try again by specifying valid Subcluster Id.
[WARN]:Unsupported file system used for log dir
[ERROR]:Cannot check app home subcluster for appId
[DEBUG]:Processing SnapshotDiffSection
[DEBUG]:Operation <*> on path <*> failed with exception <*>, operation, pathArg, e, e
[WARN]:Got an error while fetching container report from ATSv2
[INFO]:trying to read block from datanode
[INFO]:USERNAME: + userName
[INFO]:# nodes = <*>, # racks = <*>, capacity of each node <*>.
[WARN]:FairSchedulerConfiguration.UPDATE_INTERVAL_MS is invalid, so using default value
[DEBUG]:Kerberos authentication attempted
[DEBUG]:<*> deleting <*>
[DEBUG]:getEntityTimeline type=<*> id=<*>
[ERROR]:Failed to get the AbstractFileSystem for path: + uri
[INFO]:Service <*> error cleaning up registry
[DEBUG]:Checking state store connection
[INFO]:Fields read
[ERROR]:Cannot remove "<*>"
[WARN]:Very low remaining capacity in the event-queue: + remCapacity
[INFO]:Not attempting to recover. The shuffle key is invalid for recovery.
[INFO]:Added persistent memory - <*> with size=<*>
[DEBUG]:Source is a directory
[WARN]:Not attempting to re-login since the last re-login was attempted less than (kerberosMinSecondsBeforeRelogin / 1000) seconds before. Last Login= user.getLastLogin()
[DEBUG]:logAuditEvent success
[WARN]:<*> Current health <*>% is below health threshold of <*>% for <*> secs (threshold window = <*> secs)
[DEBUG]:got reply from datanode:<*>, md5=<*>
[DEBUG]:emitted no cells for + this.action
[INFO]:Initializing Volume AMS Processor
[WARN]:tempPath + does not end with ' + TMP + ' return null
[WARN]:"Unable to gracefully make <*> standby (<*>)"
[DEBUG]:addResponseTime for call: <*> priority: <*> queueTime: <*> processingTime: <*>
[DEBUG]:cwdApp: /path/to/cwdApp
[ERROR]:Can't update mapName map
[DEBUG]:Datanode is not chosen since
[INFO]:HttpFSServerWebServer initialized
[ERROR]:failed to start web server
[INFO]:Node not found resyncing + remoteNodeStatus.getNodeId()
[ERROR]:Cannot open read stream for <*>
[DEBUG]:totalPreemptedResourceAllowed for preemption at this round is :<*>
[WARN]:logFile.getAbsolutePath() + " is a directory. Ignore it."
[WARN]:BLOCK* removeDatanode: <*> does not exist
[DEBUG]:There are no pending or blocks yet to be processed
[INFO]:Recursively deleting + znodeWorkingDir + from ZK...
[WARN]:Node : ... does not have sufficient resource...
[DEBUG]:unreserving node with reservation size: <*> in order to allocate container with size: <*>, reservedResource, resourceNeedUnreserve
[INFO]:'<*> ACL '<*>'
[DEBUG]:Freeing lease: path <*>, lease id <*>
[DEBUG]:client isn't using kerberos
[WARN]:Terminating execution of <*> operation now as some other thread already got exception or operation failed
[DEBUG]:Successful commit of file length <*>
[DEBUG]:resolveDuplicateReplicas decide to keep + replicaToKeep + . Will try to delete + replicaToDelete
[WARN]:Log4j <*> configuration file not found, using default configuration from classpath
[DEBUG]:Buffer dir: <*> is created successfully.
[DEBUG]:setChildQueues: + getChildQueuesToPrint()
[DEBUG]:read requested b = null offset = <*>, len = <*>
[INFO]:Discarding exception raised when listing <*>: <*>
[ERROR]:Error putting domain, e
[WARN]:\n + header + String.format("new entry (%d, %s), existing entry: (%d, %s).%n%s%n%s", key, value, ekey, evalue, "The new entry is to be ignored for the following reason.", DUPLICATE_NAME_ID_DEBUG_INFO)
[INFO]:attemptID + given a go for committing the task output.
[WARN]:Error reading the stream /proc/diskstats
[WARN]:You are strongly encouraged to choose an integral split column.
[INFO]:Forwarding registration request to the Distributed Scheduler Service on YARN RM
[ERROR]:Exception while edit logging: <*>
[ERROR]:Failed to stop NameNode container ID + containerId
[INFO]:Atomic commit enabled. Moving workDir to finalDir
[INFO]:List reservation request failed
[DEBUG]:Cancelled token for token.getService()
[INFO]:replaying edit log: 0/1 transactions completed. (0%)
[INFO]:delete config file <*>.getPath()]
[INFO]:User before logged in is: <*>
[WARN]:Output Path is null in commitTask()
[DEBUG]:logAuditEvent failure
[INFO]:LastNodeHealthTime
[DEBUG]:Shutting down timer for <*>
[WARN]:Privileged operation may have issues
[INFO]:modifyCachePool of <*> successful; set maxRelativeExpiry to <*>
[INFO]:STATE* Safe mode is OFF
[INFO]:Placement Algorithm Iterator<*>
[INFO]:Preemption thread interrupted! Exiting.
[INFO]:Created S3A Delegation Token: <*>
[DEBUG]:Storing master key <*>
[INFO]:Cleanup completed
[INFO]:Initialized CapacityScheduler with calculator=class org.apache.hadoop.yarn.util.resource.DominantResourceCalculator, minimumAllocation=<*>, maximumAllocation=<*>, asynchronousScheduling=false, asyncScheduleInterval=300000ms,multiNodePlacementEnabled=false, assignMultipleEnabled=false, maxAssignPerHeartbeat=1, offswitchPerHeartbeatLimit=4
[ERROR]:Failed checking for the existence of history intermediate done directory
[DEBUG]:Queued <*>, <*>
[DEBUG]:Creating ACL For , new UgiInfo(ugi)
[INFO]:Interrupted while waiting to reload alloc configuration
[INFO]:Using state database at <*> for recovery
[TRACE]:copying op: <*>
[INFO]:Can't get path for dir fileId: dirHandle.getFileId()
[INFO]:Fix Quota src=<*> dst=<*> type=<*> oldQuota=<*> newQuota=<*>, location.getSrc(), location, t, remoteQuota.getTypeQuota(t), gQuota.getTypeQuota(t)
[INFO]:<*> Container Transitioned from <*> to <*>
[WARN]:AsyncDiskService has already shut down.
[WARN]:Move Application has failed: e.getMessage()
[INFO]:Disabling StoragePolicySatisfier service as <*> set to <*>.
[INFO]:system metrics publisher with the timeline service V2 is configured
[ERROR]:BUG: Method <*> was unable to be found on any of the underlying proxies for <*>
[TRACE]:this: adding notificationSocket <*>, connected to <*>
[INFO]:status
[DEBUG]:No Gauge: <*>
[INFO]:RECONFIGURE* changed <*> to <*>
[INFO]:Moving + src.toString() + to + target.toString()
[DEBUG]:After decaying the stored costs, totalDecayedCost: ..., totalRawCallCost: ...;
[ERROR]:Too few arguments to Gridmix.\n
[WARN]:Exception thrown when retrieve key: ..., exception: ...
[INFO]:Storage directory with location <*> does not exist
[WARN]:Failed to reload fair scheduler config file because last modified returned 0. File exists:
[DEBUG]:Handling deprecation for (item)
[WARN]:couldn't find app + appId + while processing FINISH_CONTAINERS event
[DEBUG]:block<*>: skipping re-entrant closeBlock(), index
[TRACE]:: trimEvictionMaps is purging <*><*>
[DEBUG]:mkdirs of <*>=<*>
[WARN]:ServicePlugin <*> could not be started
[WARN]:Error happens when checking increase request, Ignoring.. exception=
[INFO]:File opened for read
[INFO]:Bad request: requires container ID
[WARN]:Excluding datanode: + badNode
[TRACE]:Address <*> is <*> local
[DEBUG]:Endpoint URI = <*>
[ERROR]:Exception while getting login user
[DEBUG]:Adding set replication record to edit log
[DEBUG]:No subject in context, logging in
[INFO]:Registering new backup node: ...
[INFO]:Sent signal x (...) to pid a as user b for container y, result=success
[WARN]:Error in cleanup, ex
[DEBUG]:Failed to connect to <*> while fetching HAServiceState
[INFO]:Failed to read expected encryption handshake from client at ...
[INFO]:Namenode actor taking over ACTIVE state from bpServiceToActive at higher txid= txid
[INFO]:getRole() + " service RPC up at: " + rpcServer.getServiceRpcAddress()
[DEBUG]:Token kind set
[INFO]:Got Cluster node info from ASM
[DEBUG]:<*>: no block pools are registered.
[INFO]:bpos.toString() + ": scheduling an incremental block report " + "to namenode: " + nnAddr + "."
[DEBUG]:Adding to cluster node labels in AdminService
[INFO]:Volume reference is released.
[WARN]:Unable to create the container-log directory : <*>, appLogDir, e
[DEBUG]:MBean for source registered.
[DEBUG]:Not activating application <*> as amIfStarted: <*> exceeds amLimit: <*>
[TRACE]:CacheCleaner: purging replica
[INFO]:Startup Shutdown message
[TRACE]:Connecting to ApplicationMaster at: + serviceAddr
[WARN]:Unsupported diagnose output
[WARN]:DFSConfigKeys.DFS_DATANODE_FILEIO_PROFILING_SAMPLING_PERCENTAGE_KEY + " value cannot be more than 100. Setting value to 100"
[INFO]:initReplicaRecovery: changing replica state for + block + from + replica.getState() + to + rur.getState()
[DEBUG]:Looking for committer factory for path <*>
[INFO]:Replacing labels on nodes
[ERROR]:persistedService.getName() + " is at " + appReport.getYarnApplicationState() + " state, decommission can only be invoked when service is running"
[INFO]:Bad request: requires Application ID
[ERROR]:Got exception starting
[ERROR]:Exception trying to read resource types configuration ' + resourceFile + '., ex
[INFO]:RegisterAM processing finished in ... ms for application ...
[ERROR]:Unable to remove token for container
[ERROR]:Error getting entities
[DEBUG]:Called getAllPartialJobs()
[DEBUG]:Performing our own SPNEGO sequence.
[ERROR]:Unable to set exit code for container <*>
[DEBUG]:SPS service mode is <*>, so external SPS service is not allowed to fetch the path Ids
[INFO]:Node delete event for: <*>
[ERROR]:Thread <*> threw an Exception.
[DEBUG]:User <*> in queue <*> will exceed limit based on reservations - consumed: <*> reserved: <*> limit: <*>
[DEBUG]:Will send state token of size null from saslServer.
[DEBUG]:AzureBlobFileSystem.createFileSystem uri: <*>
[ERROR]:Unable to add reservation: ... to plan.
[DEBUG]:LazyWriter: Finish persisting RamDisk block: block pool Id: bpId block id: blockId to block file savedFiles<*> and meta file savedFiles<*> on target volume targetVolume
[DEBUG]:BLOCK* block RECEIVED_BLOCK: block <*> is received from <*>
[DEBUG]:Creating IOStreamPair of CryptoInputStream and CryptoOutputStream.
[DEBUG]:AADToken: got exception when parsing json token <*>
[TRACE]:<*>: mkdirs('<*>')
[INFO]:Found <*> existing UAMs for application <*> in Yarn Registry. Reattaching in parallel
[DEBUG]:Reducing read length from <*> to <*> to avoid going more than one byte past the end of the block. blockPos=<*>; curPos=<*>; curEnd=<*>
[DEBUG]:New BlockReaderLocalLegacy for file <*> of size <*> startOffset <*> length <*> short circuit checksum <*>
[INFO]:Got application report from ASM for, appId=?, clientToAMToken=?, appDiagnostics=?, appMasterHost=?, appQueue=?, appMasterRpcPort=?, appStartTime=?, yarnAppState=?, distributedFinalState=?, appTrackingUrl=?, appUser=?
[WARN]:<*> AM hostname is empty
[DEBUG]:Path: <*> is a file. COS key: <*>
[INFO]:Recovered + numTokens + RM delegation tokens
[INFO]:Service <*> is already stopped
[DEBUG]:Calling logRpcIds
[DEBUG]:<*> bytes drained from stream , drainBytes
[INFO]:Compression not required
[DEBUG]:Renew delegation token
[INFO]:STATE* Safe mode is OFF.\n + It was turned off manually.
[ERROR]:Failed to publish Container metrics for container $<*> with exception <*>
[ERROR]:Could not destroy service <*>, <*>
[WARN]:Exception while checking the app status; will leave the entry in the list.
[INFO]:Interrupted Exception while stopping
[WARN]:DIR* FSDirectory.unprotectedRenameTo: Rename destination " + dst + " is a directory or file under source " + src
[INFO]:Applications Pending: countHere
[DEBUG]:local InetAddress for proxy host: <*>
[DEBUG]:Using summary store for <*>
[INFO]:CoprocessorJarPath=<*>
[DEBUG]:"Get allocation from deviceMappingManager: <*>, <*> for container: <*>" with args allocated, resourceName, containerId
[DEBUG]:<*>:<*>, SchedulerEventType.KILL_RESERVED_CONTAINER, container
[DEBUG]:Audit log false for operation listSnapshottableDirectory
[INFO]:Container <*> completed with event <*>, but corresponding RMContainer doesn't exist.
[INFO]:Recovered + numApps + applications and + numAppAttempts + application attempts
[WARN]:Block <*> has not released the reserved bytes. Releasing <*> bytes as part of close.
[INFO]:Retrieving service name from configuration
[INFO]:initialApps.size() + apps recorded as active at this time
[WARN]:logPrefix + ": " + line
[DEBUG]:The next sequential write has not arrived yet
[INFO]:Return JSON with location
[DEBUG]:Yarn-site XML loaded and validated
[WARN]:Can not create a symLink with a target = null and link = null
[DEBUG]:Setting bandwidth to <*>
[INFO]:Progress of TaskAttempt ...
[WARN]:Error while closing the input stream,
[DEBUG]:Failed to initialize filesystem
[WARN]:Proxy host set without port. Using HTTPS default 443
[WARN]:Inconsistent number of corrupt replicas for <*> blockMap has <*> but corrupt replicas map has <*>
[INFO]:Node labels removed from cluster
[DEBUG]:Failed to get number of missing blocks
[INFO]:Finished loading directories in <*>ms
[ERROR]:Error in stopping application: <*>
[DEBUG]:Appending to existing file
[DEBUG]:Added resourceName=<*>
[TRACE]:Auth method is not set, yield from setting auth fallback.
[INFO]:Usage text displayed
[INFO]:Storage directory " + sd.getRoot() + " does not contain previous fs state.
[DEBUG]:Skipping 'rack' <*> for <*> since it has been blacklisted
[INFO]:Skipping <*> due to not having enough log files (<*> < <*>)
[DEBUG]:Usersearch baseDN: <*>
[WARN]:The log aggregation is disabled. No need to update the log aggregation status
[DEBUG]:Updating context status
[INFO]:Upgrade of <*> is complete, name
[WARN]:Found unexpected column for entity...
[DEBUG]:IV read from Stream <*>
[TRACE]:<*>: pulled slot <*> out of <*>, this, slot.getSlotIdx(), shm
[INFO]:Added entry to result set
[DEBUG]:include:
[DEBUG]:timed poll(): poll() returned null, sleeping for <*> ms
[WARN]:The period calculated for the cgroup was too low. The minimum value is MIN_PERIOD_US, calculated value is periodUS. Using all available CPU.
[DEBUG]:mode.toString() + " TrustStore: " + truststoreLocation + ", reloading at " + truststoreReloadInterval + " millis."
[WARN]:Error trying to create an instance of <*>, <*>
[INFO]:Failed to get current user <*>
[WARN]:Error compiling report. Continuing.
[DEBUG]:Waiting for authentication response
[INFO]:Timeline delegation token secret manager created
[INFO]:Finish information of container ...
[INFO]:Configuring filter for proxies
[INFO]:Available numa nodes with capacities : %d
[ERROR]:Unable to locate user for <*>
[ERROR]:Return the buffer to buffer pool failed.
[DEBUG]:SecureWasbRemoteCallHelper#getHttpRequest() <*>
[DEBUG]:Aborting commit ID %s to path %s
[INFO]:Cleanup complete
[DEBUG]:After setting ACLs\n
[INFO]:App failed with state: FAILED
[DEBUG]:Moving source to destination
[INFO]:delete(<*>) returned false (<*>)
[DEBUG]:Creating Registry with root <*>
[ERROR]:NodeLabels sent from NM while registration were rejected by RM. + ((errorMsgFromRM == null) ? "Seems like RM is configured with Centralized Labels." : "And with message " + regNMResponse.getDiagnosticsMessage())
[DEBUG]:child: <*>, posixAclInheritanceEnabled: <*>, modes: <*>
[INFO]:Returning JSON response with location
[DEBUG]:<*>: no parent default ACL to inherit
[ERROR]:Cannot get address for <*>: <*>
[WARN]:Directory <*> error, <*>, removing from list of valid directories
[INFO]:Updated master key log
[ERROR]:Failed to get credentials for role <*>
[INFO]:Error launching <*>. Got exception: <*>
[DEBUG]:Exception in closing + domainSocketWatcher, e
[ERROR]:In-progress edits file + f + has improperly formatted transaction ID
[INFO]:Container status received
[DEBUG]:SASL client skipping handshake in unsecured configuration for addr = <*>, datanodeId = <*>
[INFO]:Completing previous upgrade for storage directory <*>
[ERROR]:Error putting entity <*> of type <*>
[DEBUG]:skipping from queue=<*> because it's a non-preemptable queue
[INFO]:Calling stop for all the services
[DEBUG]:time interval: <*>, container: <*>.
[WARN]:Failed to fetch TopUser metrics
[DEBUG]:Failed to get the number of dead decommissioned datanodes
[INFO]:Retrying request with TimelineClientRetryOp
[DEBUG]:Updating effective min resource for queue:childQueuePath as effMinResource=effectiveMinResource and Updating effective max resource as effMaxResource=effectiveMaxResource
[TRACE]:close(filename=<*>, block=<*>)
[WARN]:Unable to create the app-log directory : <*>, appLogDir, e
[DEBUG]:Adding block of <*> entries
[DEBUG]:Block <*>: Deleting buffer file as upload did not start
[INFO]:Initializing configured FPGA resources for the NodeManager.
[INFO]:Datanode storage report obtained
[INFO]:Task succeeded with attempt + successfulAttempt
[INFO]:Rolling back Container reInitialization for <*>
[TRACE]:Got request user: <*>, remoteIp: <*>, query: <*>, path: <*>
[DEBUG]:Copy file from %s to %s (length=%d)
[ERROR]:Given app to remove does not exist in queue
[DEBUG]:Block <*>: removing from PENDING_CACHED for node <*> because it cannot fit in remaining cache size <*>.
[TRACE]:Exiting getKeyVersion method.
[INFO]:Starting recovery process for unclosed journal segments...
[WARN]:The storage policy + policy.getName() + is not suitable for Striped EC files. + So, Ignoring to move the blocks
[INFO]:soft limit at <*>
[INFO]:YarnException occurred
[DEBUG]:Get major numbers from /dev/<*>
[DEBUG]:*BLOCK* NameNode.cacheReport: from ...
[INFO]:Instantiating NMWebApp at <*>
[INFO]:HTTP server started
[DEBUG]:PID: ...
[WARN]:Unable to monitor the registry. DNS support disabled.
[WARN]:Something wrong happened, container size reported by NM is not expected, ContainerID= + container.getContainerId() + rm-size-resource: + rmContainerResource + nm-size-resource: + nmContainerResource
[DEBUG]:Corruption detected! Parent node is not contained in the list of known ids!
[DEBUG]:To-be-moved container already updated.
[INFO]:DelegationToken authentication attempted
[ERROR]:Error: canâ€™t add leaf node <*> at depth <*> to topology:<*>\n
[ERROR]:Cannot set policy: <*>
[WARN]:Parallel is enabled and <*> is set to <*>. Setting to the default value <*>
[WARN]:Error while purging filesystem, ex.toString()
[DEBUG]:Error getting users for netgroup
[ERROR]:Registry remove key <*> failed
[INFO]:All async lazy persist service threads have been shut down
[INFO]:No rule set for <*>, defaulting to WARNING
[ERROR]:Unable to replace reservation: <*> from plan.
[INFO]:Latest log is ; journal id:
[DEBUG]:Connection received from <*>
[ERROR]:Got exception reading pid from pid-file <*>
[DEBUG]:NFS ACCESS fileHandle: <*> client: <*>
[INFO]:Killed application
[TRACE]:<*> <*> Activate <*>
[INFO]:TaskType + taskType + does not support custom resource types - this support can be added in + getClass().getSimpleName()
[DEBUG]:storeContainerPaused: containerId=<*>
[WARN]:Journal at ... has no edit logs
[DEBUG]:AzureBlobFileSystem.mkdirs path: <*> permissions: <*>
[DEBUG]:Recovered UAM in <*> from NMSS
[INFO]:New instance created
[TRACE]:<*>: the DfsClientShmManager has been closed.
[WARN]:delete returned false for path: <*>
[WARN]:Waited A ms (timeout=B ms) for a response for C...
[INFO]:Read unlock issued for getNumberOfDatanodes
[ERROR]:Can't find filters file
[ERROR]:oopsie... this can never happen: + StringUtils.stringifyException(ioe)
[WARN]:validateSpillIndexFileCB.. could not retrieve indexFile.. Path: <*>
[DEBUG]:Read in partial CRC chunk from disk for block
[DEBUG]:Planning Algorithm has placed for application <*> the following <*>
[INFO]:Stored the start data of container <*>
[WARN]:RMContainer received unexpected recover event with container state <*> while recovering.
[ERROR]:Can't handle this event at current state, <*>
[ERROR]:Status: ERROR, message: Exception message
[DEBUG]:Not enabling OAuth2 in WebHDFS
[WARN]:Missing DeleteApplicationHomeSubCluster Request. Please try again by specifying an ApplicationHomeSubCluster information.
[WARN]:Exception from remote name node + currentNN + , try next.
[INFO]:Accepted recovery for segment
[INFO]:Application has completed successfully. Breaking monitoring loop
[INFO]:Rolling back storage directory sd.getRoot(). target LV = DATANODE_LAYOUT_VERSION; target CTime = nsInfo.getCTime()
[INFO]:unknown GET someUri 200
[INFO]:Deleted item
[WARN]:Failed to find datanode <*>
[ERROR]:Unable to save new edits <*> due to exception when updating to new layout version %d
[DEBUG]:argumentString
[INFO]:Retrying operation on FS. Retry no. X
[INFO]:Storing state version info
[DEBUG]:Scanned <*> directive(s) and <*> block(s) in <*> millisecond(s).
[WARN]:Failed to cache + key + : could not reserve + more bytes in the cache: + cacheLoader.getCacheCapacity() + exceeded when try to reserve + length + bytes.
[DEBUG]:GOT EXCEPITION
[INFO]:DNS Caching enabled
[INFO]:entry.getKey() + "\\t" + am.getQueue() + "\\t" + am.getAMType() + "\\t" + am.getDuration() + "\\t" + am.getNumTasks()
[INFO]:<*>: <*> allocated, num pending component instances reduced to <*>
[DEBUG]:FilterList created for get is - <*>
[DEBUG]:Cached <*> closing after <*> ops...
[DEBUG]:some debug message here
[DEBUG]:Application <*> sends out requests for <*> failed mappers.
[INFO]:Didn't find any usable FPGAs on the NodeManager.
[INFO]:Updated NodeAttribute event to RM: <*>
[ERROR]:Error reading/writing job conf file for job: jobId
[DEBUG]:NoOpTimelineWriter is configured. Not storing TimelineEntities.
[INFO]:Lock on <*> acquired by nodename <*>
[ERROR]:Unable to insert the ApplicationId <*> into the FederationStateStore
[DEBUG]:Attempting operation: removeDefaultAcl
[INFO]:TokenCache is enabled
[DEBUG]:PUT <*> bytes to <*>
[DEBUG]:Skip to add dead node <*> to check since the node is already in the probe queue.
[ERROR]:Disk Balancer - Plan was generated for another node.
[DEBUG]:Signer override for <*>} = <*>, awsServiceIdentifier, signerOverride
[ERROR]:DiskBalancerException message
[WARN]:Counter already exists
[DEBUG]:Reached maximum limit of jobs in a polling interval + completedJobsInCurrentInterval
[ERROR]:ExpiredTokenRemover received (InterruptedException ie)
[INFO]:source nodes = <*>
[INFO]:Adding block pool
[DEBUG]:Connecting to + server
[DEBUG]:Container added for preemption
[INFO]:ShellExecutor: Interrupted while reading the error/out stream
[INFO]:=====================
[DEBUG]:Fetching all jobs for the given application ID
[TRACE]:Looking for delegation token to identify user
[DEBUG]:Storing state for reservation <*> plan <*> at <*>
[INFO]:Using state database at + dbPath + for recovery
[DEBUG]:Delete object key: <*> from bucket: <*>.
[WARN]:Exception when trying to cleanup container <*>: <*>
[DEBUG]:AzureBlobFileSystem.fileSystemExists uri: <*>
[INFO]:Creating configuration version/database at <*>
[DEBUG]:read ahead enabled issuing readheads num = ...
[ERROR]:*********** Upgrade is not supported from this older version <*> of storage to the current version. Please upgrade to <*> or a later version and then upgrade to current version. Old layout version is <*> and latest layout version this software version can upgrade from is <*>. ************
[INFO]:Not starting CacheReplicationMonitor as name-node caching is disabled.
[WARN]:Bulk delete operation interrupted: <*>
[DEBUG]:<*>: Closing block #<*>: current block= <*>, this, blockCount, hasBlock ? block : (none)
[ERROR]:logErrorMessage(logFile, e)
[DEBUG]:rpcServer.getLocationsForPath invoked
[DEBUG]:Got UserName/GroupName <*> for ID <*> from the native implementation
[DEBUG]:Commit completed without recovery or rate limiting
[DEBUG]:Beginning of the step. Phase: <*>, Step: <*>
[ERROR]:System Error during DirectoryScanner execution - permanently terminating periodic scanner
[DEBUG]:Setting input format
[INFO]:Flexing component <*> to <*>
[WARN]:Container <*> + about to be explicitly Rolledback !!
[INFO]:Saving work of <*> to <*>
[DEBUG]:Connecting to HistoryServer at: serviceAddr
[INFO]:Block locations retrieved
[WARN]:Configuring \MAPRED_QUEUE_NAMES_KEY\ in mapred-site.xml or hadoop-site.xml is deprecated and will overshadow QUEUE_CONF_FILE_NAME. Remove this property and configure queue hierarchy in QUEUE_CONF_FILE_NAME
[INFO]:Application lifelime monitor interval set to X ms.
[INFO]:Deleting ClusterNode <*> with queue wait time <*> and wait queue length <*>
[DEBUG]:drain or abort reason <*> remaining=<*> abort=<*>
[WARN]:Failed to get delegation token from the timeline server: <*>
[INFO]:Reading config from: configFile.getSrcFile(), writing to: remoteFile
[DEBUG]:Aborting %s
[WARN]:Metric name + name +, value + value + has no type.
[WARN]:INTERNAL_SERVER_ERROR
[INFO]:CSI Adaptor added to the cache, adaptor name: driverName, driver version: response.getVersion()
[INFO]:Process application start request
[DEBUG]:Return the buffer to the buffer pool.
[WARN]:failed to register any UNIX signal loggers:
[DEBUG]:Setting revision ID for object at <*>: <*>
[DEBUG]:version: x.y.z
[DEBUG]:Received service state: <*> from HA namenode: <*>
[INFO]:Max Running Applications:
[DEBUG]:getEntity type=<*> id=<*>
[INFO]:AUTHZ_SUCCESSFUL_FOR ...
[INFO]:Gracefully decommission node with state not DECOMMISSIONED/DECOMMISSIONING
[INFO]:Reserved container X on node Y for application Z
[ERROR]:Unable to commit data to finalDir
[INFO]:NN registration state has changed: <*> -> <*>
[INFO]:Activating next master key with id: $<*>
[WARN]:Timeout for copying MapOutput with retry on host host after fetchRetryTimeout milliseconds.
[DEBUG]:No such priority=<*>
[DEBUG]:Node added without containers
[DEBUG]:Current row key: ...
[DEBUG]:Host matched to the request list <*>
[WARN]:JobConf.deprecatedString(JobConf.MAPRED_REDUCE_TASK_ULIMIT)
[DEBUG]:Added ACL <*>, aclToString(acl)
[DEBUG]:Did not load hdfs image to hash file, file is null
[ERROR]:Cannot access the Router RPC server
[WARN]:Trash cannot close FileSystem: <*>
[ERROR]:Unexpected exception while initializing the cleaner task. This task will do nothing,, e
[INFO]:managedParentQueue.getQueuePath() + " : Removed queue" + queue + " from leaf queue state from partition " + partition
[WARN]:Application with id <*> already present! Cannot add a duplicate!
[WARN]:Resource description
[DEBUG]:verifying request. enc_str=enc_str; hash=...urlHashStr
[ERROR]:Cannot create State Store root directory <*>
[DEBUG]:Adding + path + to job list cache.
[DEBUG]:Path <*> doesn't exist, failing rename.
[INFO]:Queue x already has n applications from user z, cannot accept submission of application: y
[ERROR]:Cannot open write stream for <*>
[INFO]:Processed URL + url + (Took + latency + ms.)
[INFO]:Convert + b + from Temporary to RBW, visible length= + visible
[DEBUG]:Speculator event handled
[ERROR]:Error in AMRMClient callback handler. Following scheduling requests were rejected: <*>
[INFO]:taskId + " acquired " + chunkFile.getPath()
[INFO]:Generating distributed cache data of size + conf.getLong(GenerateDistCacheData.GRIDMIX_DISTCACHE_BYTE_COUNT, -1)
[WARN]:$<*> should not be used. Instead, use $<*>.
[INFO]:Failed to warm up EDEKs.
[INFO]:Unable to fence old active: <*>
[INFO]:"Records R/W=" + numRecRead_ + "/" + numRecWritten_
[WARN]:Unexpected exception:
[DEBUG]:Configuring job settings
[DEBUG]:idlest stream's idle time:
[DEBUG]:DatanodeManager.wipeDatanode(node): storage key is removed from datanodeMap.
[INFO]:Permission check passed
[WARN]:Exception while getting reportedBlock list
[DEBUG]:Created token <*> with token identifier <*>
[DEBUG]:Block <*> cannot be reconstructed due to shortage of source datanodes
[DEBUG]:Redirecting with URI
[INFO]:Adding new volumes: <*>
[DEBUG]:Updated map for Mac
[INFO]:Interrupted: <*>
[DEBUG]:Scanned <*> active applications
[ERROR]:userResolver.getClass() needs target user list. Use -users option.\n
[WARN]:A failover has occurred since the start of call # + callId + + proxyInfo.getString(method.getName())
[ERROR]:IOException encountered during write
[INFO]:Audit event failed for computeSnapshotDiff
[INFO]:Setup Task %s
[WARN]:e.getMessage()
[INFO]:Node report generated for each DiskBalancerDataNode
[DEBUG]:Publishing Component metrics. <*>
[ERROR]:Unable to obtain the filesystem for the cleaner service
[INFO]:Unchecked exception is thrown from onContainerStopped for Container event.getContainerId()
[INFO]:Making interactive connection to running docker container with ID: cId
[WARN]:createFailureLog(user, operation, perm, target, description, appId, null, null, null, callerContext, queueName, partition)
[DEBUG]:Execution exception when running task in <*>
[WARN]:Following requests of <*> were rejected by the PlacementAlgorithmOutput Algorithm: <*>
[DEBUG]:SASL client skipping handshake in secured configuration with privileged port for addr = <*>, datanodeId = <*>
[INFO]:Not able to copy block ... because it's pinned
[DEBUG]:Did not renew lease for client <*>
[WARN]:Caught exception
[DEBUG]:Received nodeUnpublishVolume call, request: <*>
[WARN]:Empty device path provided, try to get device type from major:minor device number
[WARN]:Allowing manual HA control from + Server.getRemoteAddress() + even though automatic HA is enabled, because the user + specified the force flag
[DEBUG]:Rename path <*> to <*>, src, dst
[DEBUG]:*BLOCK* NameNode.processIncrementalBlockReport: from <*> receiving: <*>, received: <*>, deleted: <*>
[WARN]:Exception when scheduling the event Rollback re-initialization of Container ...
[WARN]:Path ... is not accessible for all users. Current permissions are: ...
[ERROR]:Cannot get policies: <*>
[DEBUG]:requested seek to position <*>
[DEBUG]:Skipping deletion of <*>
[ERROR]:Trying to get priority of an absent application
[WARN]:Either jobs are running concurrently or failed jobs are not being cleaned up
[ERROR]:JournalNodeSyncer daemon received Runtime exception.
[WARN]:Failed to execute binary diagnose, exception message: e.getMessage(), output: output, continue ...
[WARN]:addDirective of + info + failed: , e
[DEBUG]:Can not access the aggregated log for the container:<*>
[TRACE]:reading flow app id sum=
[WARN]:Unable to parse submit time from job history file <*> : <*>
[DEBUG]:Freed lease <*> on <*>
[DEBUG]:Using striped block reconstruction; pool threads=<*>
[DEBUG]:ls <*>
[WARN]:Failed to close filesystems: , e
[INFO]:No opened stream for fileHandle: <*>
[INFO]:Exits the main loop.
[DEBUG]:Processing paths
[INFO]:Successfully moved reserved container=<*> from targetNode=<*> to targetNode=<*>
[WARN]:Unable to create directory: +tmpDirPath
[INFO]:Operation type set
[INFO]:Starting container log aggregation
[DEBUG]:Creating STS client for <*>
[ERROR]:onContainerStarted received unknown container ID: + containerId
[INFO]:editsSyncDir + " directory already exists."
[DEBUG]:Try to find method: <*>
[DEBUG]:AzureBlobFileSystem.access path : <*>, mode : <*>
[DEBUG]:Failed to purge multipart uploads against <*>, FS may be read only
[WARN]:No job found in traces
[DEBUG]:commit block list with <*> blocks for blob <*>
[INFO]:<*>: Executing Manifest Job Commit with <*> files
[INFO]:Un-publish volume <*>, request <*>
[WARN]:Serialization class not found: , e
[WARN]:Could not delete + taskAttemptPath
[INFO]:Will fetch a new encryption key and retry, encryption key was invalid when connecting to ...
[INFO]:logMsg
[ERROR]:Error compacting database
[WARN]:Output Path is null in setupJob()
[INFO]:Symlink file already exists: linkFile
[DEBUG]:<*> : Initializing CachingAuthorizer instance
[WARN]:Cannot find FsVolumeSpi to report bad block: <*>
[WARN]:Encountered error getting ec policy for inode path
[INFO]:Container <*> transitioned from <*> to <*>
[DEBUG]:Upload staged file from <*> to <*>
[ERROR]:Unauthorized request to start container. Attempt to relaunch the same container with id ...
[ERROR]:Unable to make <*> active (unable to connect). Failing back.
[DEBUG]:Kafka brokers: <*>
[WARN]:JWT audience validation failed.
[DEBUG]:DeadNode detection is not enabled or given block <*> is null, skip to remove node.
[DEBUG]:Received ping message
[WARN]:Namenode for <*> remains unresolved for ID <*>. Check your hdfs-site.xml file to ensure namenodes are configured properly.
[INFO]:Compactionrequest= ... MINOR_COMPACTION/Major_COMPATION ... RegionName= ...
[INFO]:Can't register DN <*> because it is already registered., dn.getDatanodeUuid()
[ERROR]:FATAL, Shutting down the resource manager because a state store operation failed, and the resource manager is configured to fail fast. See the yarn.fail-fast and yarn.resourcemanager.fail-fast properties.
[INFO]:NameNode container started at ID + containerId
[WARN]:Failed to create <*>]
[INFO]:FromId parameter added
[ERROR]:Could not stop Key Id Counter
[INFO]:Storing state DB schema version info
[INFO]:Deleting aggregated logs in + appDir.getPath() <*> logException
[INFO]:Finalizing upgrade of storage directory + sd.getRoot()
[WARN]:TaskAttempt found in unexpected state, recovering as KILLED
[ERROR]:Error trying to assign container token and NM token to an updated container
[WARN]:Exception when scheduling the event of increasing resource of Container container.getId()
[INFO]:Saving image to target directory
[WARN]:Please set EXECUTE permissions on this directory
[DEBUG]:%d racks are required for the erasure coding policies: %s. The number of racks is only %d.
[DEBUG]:logUtilizationCollections
[WARN]:(offset,count,nextOffset): (<*>,<*>,<*>)
[WARN]:Unable to get key for <*> from credential providers. <*>, accountName, ioe, ioe
[WARN]:ns + . + FairCallQueue.IPC_CALLQUEUE_PRIORITY_LEVELS_KEY + is deprecated. Please use + ns + . + CommonConfigurationKeys.IPC_SCHEDULER_PRIORITY_LEVELS_KEY + .
[WARN]:No Output path found for <*>
[INFO]:Executing Manifest Job Commit with manifests in manifestDir
[DEBUG]:Dumper woke up
[DEBUG]:copying dir marker from <*> to <*>
[DEBUG]:No filesystem found for the hdfs scheme
[DEBUG]:<*> uses <*> millisecond to run
[ERROR]:Node <*> is in an unexpected state <*> and has been removed from tracking for decommission or maintenance
[ERROR]:Error getting logs for logEntity
[WARN]:Service health check failed for <*>, targetToMonitor, t
[DEBUG]:Match on record @ <*> with children
[DEBUG]:SecondaryGroupExisting rule: parent rule found: <*>
[DEBUG]:hadoop login commit
[DEBUG]:No job directory to read uploads from
[TRACE]:Interrupted while waiting on all connections to be closed.
[WARN]:Failed to cache block with id + blockId + , pool + bpid + : ReplicaInfo not found.
[DEBUG]:Assigned based on * match
[ERROR]:Invalid SYMLINK request
[ERROR]:GenericObjectMapper cannot read key from key <*> into an object. Read aborted!
[DEBUG]:Reserve on target node failed, e=<*>
[DEBUG]:Message placeholder
[INFO]:Snapshot allowed for path
[ERROR]:The owner of the posted timeline domain is not set
[ERROR]:Call cos sdk failed, retryIndex: <*>, call method: putObject, exception: ...
[DEBUG]:ending log segment because of END_LOG_SEGMENT op in <*>
[WARN]:Failed to compute snapshot diff on <*>
[DEBUG]:Shutting down timer <*>
[WARN]:No mover threads available: skip moving + p
[WARN]:Exception when scheduling the event of restart of Container containerId
[INFO]:Error when reading history information of some containers of application attempt <*>
[INFO]:Adding <*> tp top of + AMS Processing chain.
[DEBUG]:Cleanup job %s
[DEBUG]:Initializing AzureBlobFileSystem for <*> complete
[WARN]:Got exception while signaling container <*> with command <*>
[INFO]:Added file for localization: symlink -> localResource.getResource().getFile()
[INFO]:Operation category WRITE checked
[ERROR]:Exception during version check
[DEBUG]:Loading site configuration from <*>
[DEBUG]:Metrics Config: <*>
[DEBUG]:Scheduling move to done of ...
[ERROR]:Unknown event arrived at OpportunisticContainerAllocatorAMService: <*>
[WARN]:Runtime spec in non-Docker container is not supported yet!
[WARN]:Cannot use /lost+found : a regular file with this name exists.
[INFO]:<*> cancel version <*>
[INFO]:Renew delegation token request failed
[ERROR]:Error closing writer for JobID:
[DEBUG]:IOStatisticsBinding track duration started
[DEBUG]:Key with path <*> already exists.. Updating !!
[ERROR]:Error in SerialJobFactory while waiting for job completion ...
[INFO]:Additional complete request on completed container <*>
[WARN]:Failed to get Operating System name.
[INFO]:Time to delete files <*>
[WARN]:Encountered exception during format
[ERROR]:Can not resolve DNS servers:
[INFO]:PrivilegedAction execution started
[DEBUG]:File was opened with a supplied FileStatus; skipping getFileStatus call in open() operation: <*>
[INFO]:Making reservation: node= + node.getNodeName() + app_id= + getApplicationId()
[DEBUG]:Running cmd: <*>
[DEBUG]:Audit event logged
[ERROR]:Cannot find subcluster for <*> (<*> -> <*>)
[INFO]:Cancelling token
[ERROR]:Invalid input: , <*>
[WARN]:Slow flushOrSync took <*> ms (threshold=<*> ms), isSync:<*>, flushTotalNanos=<*> ns, volume=<*>, blockId=<*>
[INFO]:Step DELEGATION_TOKENS started
[INFO]:deleteBlockPool command received for block pool <*>, force=<*>
[DEBUG]:File does not exist, skipping: <*>
[INFO]:New token created: (<*>)
[INFO]:Federated FSCK started by current_user from remoteAddress at current_time
[DEBUG]:Got interrupted while DeadNodeDetector is error.
[ERROR]:Callback handler does not implement container restart callback methods
[WARN]:Timeout waiting for recovered containers
[DEBUG]:Recovering application with state: <*>
[WARN]:Failed to load/initialize native-zlib library
[INFO]:In stop, writing event <*>
[WARN]:name + not defined for + id
[ERROR]:Container start event could not be published for <*>
[DEBUG]:Storing ZKDTSMDelegationKey_ + key.getKeyId()
[INFO]:Using committer <*> to output data to <*>
[INFO]:Available space volume choosing policy initialized: <*> = <*>, <*> = <*>
[DEBUG]:Yielded lock during decommission/maintenance check
[WARN]:MSG_REFRESH_FAILURE_WITH_CHANGE_OF_HIERARCHY
[ERROR]:Invalid eventtype + event.getType() + . Ignoring!
[INFO]:Config dir: <*>
[DEBUG]:Completed cross origin filter checks. Populating HttpServletResponse
[INFO]:Cleanup with logger
[INFO]:WebImageViewer started. Listening on + address.toString() + . Press Ctrl+C to stop the viewer.
[DEBUG]:Adjusting safe-mode totals for deletion. decreasing safeBlocks by <*>, totalBlocks by <*>
[WARN]:Directory <*> error <*>
[INFO]:<*>: <*> bytes}
[DEBUG]:AADToken: starting to fetch token using client creds for client ID $<*>
[INFO]:Current user = <*>
[DEBUG]:Transferring a replica to <*>
[WARN]:<*> is not active, returning terminated error
[INFO]:Updated the cluste max priority to maxClusterLevelAppPriority = ...
[DEBUG]:HandleAddBlockPoolError called with empty exception list
[ERROR]:Failed reading registry key, skipping subcluster <*>
[ERROR]:Unable to get queue information
[INFO]:No files in
[INFO]:Registered FederationRPCMBean: <*>
[ERROR]:Unable to get HomeDirectory from original File System
[DEBUG]:<*>:Number of active connections is: <*>
[WARN]:Incorrect version exception
[INFO]:Initializing SchedulingMonitor= + getName()
[DEBUG]:Creating plan node: <*> at: <*>
[INFO]:Successfully read replica from cache file : path
[INFO]:upload conf from fileSystem took X ms
[TRACE]:Chosen nodes: ...
[WARN]:Job History Server is not configured.
[DEBUG]:total(<*>, olderThanAge, p.getPid(), info, (total * KB_TO_BYTES))
[INFO]:Took <*> ms to collect <*> open files with leases <*>
[ERROR]:Invalid argument, data size is less than count in request
[DEBUG]:Checking user <*> for: <*> <*>
[DEBUG]:Sorry, <*> not found.
[INFO]:NNTop conf: + DFSConfigKeys.NNTOP_WINDOWS_MINUTES_KEY + = +
[INFO]:Exception while executing an FS operation.
[INFO]:Recovering <*> running applications for AMRMProxy
[DEBUG]:add + call
[WARN]:The format isn't valid. Sample rate falls back to the default value $<*>
[INFO]:toString method executed
[WARN]:Can not get log meta from the log file:
[ERROR]:Calling allocate on previous or removed or non existent application attempt <*>
[DEBUG]:Native Hadoop and required libraries loaded
[INFO]:Resource increase requests : + increaseRequests
[INFO]:Reached <*> attempts on <*>, failing over to <*>
[DEBUG]:setOwner filesystem: <*> path: <*> owner: <*> group: <*>
[INFO]:Data committed successfully to finalDir
[DEBUG]:Checking existence of the delete path
[INFO]:Processed URL + url + but entity not found + (Took + additionalTime + ms.)
[DEBUG]:Reading file
[DEBUG]:In memory blockUCState = <*>
[DEBUG]:Initializing RemoteWasbAuthorizerImpl instance
[TRACE]:Logging enabled, fetching clients string
[WARN]:The given interval for marking stale datanode = ...
[INFO]:Initializing rolling leveldb instance :<*> for start time: <*>
[WARN]:Allowed Origin pattern ' + discouragedAllowedOrigin + ' is discouraged, use the 'regex:' prefix and use a Java regular expression instead.
[INFO]:Action stop called on service client
[DEBUG]:postFlush store = + store.getColumnFamilyName() + flushableSize= + store.getFlushableSize() + flushedCellsCount= + store.getFlushedCellsCount() + compactedCellsCount= + store.getCompactedCellsCount() + majorCompactedCellsCount= + store.getMajorCompactedCellsCount() + memstoreSize= + store.getMemStoreSize() + size= + store.getSize() + storeFilesCount= + store.getStorefilesCount()
[INFO]:Storage directory + sd.getRoot() + is not formatted.
[INFO]:Deleting absolute path : <*>
[DEBUG]:BLOCK* markBlockReplicasAsCorrupt: mark block replica <*> on <*> as corrupt because the dn is not in the new committed storage list.
[DEBUG]:Copying Log4j property file
[DEBUG]:Transitioned to standby successfully
[INFO]:Removing a node: + NodeBase.getPath(node)
[ERROR]:Cannot get subclusters: exception message
[DEBUG]:Current ProcessTree list: <*>
[TRACE]:Exiting deleteKey method.
[WARN]:Container <*> is logging beyond the container single log directory limit... Killing container.
[ERROR]:Failed to create directory for downloading log segments: $<*>. Stopping Journal Node Sync.
[INFO]:Evicting <*> DBs scheduled for eviction
[WARN]:Exception while sending the block report after refreshing + volumes <*> to <*>
[ERROR]:MessageFormat.format(<*>: Error in handling event type <*>, component.getName(), event.getType()), t
[DEBUG]:Connection context details logged
[DEBUG]:getName() + ": stopping services, size=" + numOfServicesToStop
[DEBUG]:Failed to contact AM/History for job retrying..
[DEBUG]:Node is not chosen due to being too busy (load: <*> > <*>)
[DEBUG]:Pushing record
[INFO]:Queue Operations
[DEBUG]:allocate(arrayLength), return byte<*>
[DEBUG]:Thread.currentThread().getName() + ": processOneRpc from client " + this + " threw exception <*>"
[DEBUG]:the local file exists and is size 'file.length()'.
[INFO]:ParsedTaskAttempt details: <*>;DiagnosticInfo=<*> \n <*>;<*>;<*>;rack=<*>;host=<*>
[ERROR]:Unable to start log segment + segmentTxId
[INFO]:Checkpoint completed in <*> seconds. New Image Size: <*>
[ERROR]:The Plan is not an PlanQueue!
[DEBUG]:Node Labels <*>} were Accepted by RM, StringUtils.join(,, getPreviousValue())
[DEBUG]:BLOCK* removeStoredBlock: <*> removed from caching related lists on node <*>
[DEBUG]:The updated demand for FSParentQueueName is UpdatedDemand; the max is MaxShare
[INFO]:Moved tmp to done: + tmpPath + to + path
[INFO]:Removed BPOfferService
[WARN]:No live nodes contain block
[DEBUG]:IOUtils.cleanupWithLogger called
[INFO]:Initiating in-memory merge with noInMemorySegments segments...
[DEBUG]:No opened stream for fileId: <*> commitOffset=<*>. Return success in this case.
[DEBUG]:modifyAclEntries filesystem: <*> path: <*> aclSpec: <*>
[INFO]:All EC block group status: OK
[WARN]:Message from ResourceManager: + response.getDiagnosticsMessage()
[ERROR]:Failing NodeManager start since we're on a Unix-based system but bash doesn't seem to be available.
[WARN]:Exception shutting down DataNode HttpServer
[ERROR]:Application $<*> does not exist
[INFO]:Ensuring that ... does not participate in active master election
[INFO]:Refresh request received for nameservices: ...
[ERROR]:Error in removing master key with KeyID:
[DEBUG]:Application <*> is not registered in the Placement Constraint Manager.
[DEBUG]:Running refresh for <*> streams
[WARN]:Container <*> was running but not reported from <*>
[DEBUG]:NFS REMOVE dir fileHandle: <*> fileName: <*> client: <*>
[WARN]:Closing is Interrupted
[DEBUG]:Interrupted during wait interval
[WARN]:Default name service is disabled.
[ERROR]:Get connection for...
[ERROR]:Node health check failed
[DEBUG]:Handling volume failures
[DEBUG]:Queued latency info <*>: <*>
[WARN]:Invalid RPC call version + ver
[INFO]:Initialized Reservation system
[INFO]:OK response built with JSON location
[INFO]:Moved <*> to <*>
[INFO]:Stopping the InMemorySCMStore service.
[DEBUG]:Retrieving metadata for <*>
[TRACE]:op=
[WARN]:ResourceHandlerChain.postComplete failed for containerId: <*>. Exception: , containerId, e
[ERROR]:IOException during updateDynamicResourceConfiguration
[WARN]:Failed to seek on <*> to <*>. Current position <*>
[DEBUG]:Creating a new file: <*> in COS.
[ERROR]:Unable to kill workload app (<*>)
[INFO]:NODE_ID is already DECOMMISSIONING
[INFO]:The policy name already exists
[WARN]:ServicePlugin <*> could not be stopped
[INFO]:CGroupsResourceCalculator requires enabling CGroups cpu and memory
[INFO]:Add regex mount point: <*>, target: <*>, interceptor settings: <*>
[INFO]:<*>: scaling down from + before + to + event.getDesired()
[WARN]:The value + n + <= 0: it is parsed from the string \ + s + \ which is the index + i + element in \ + originalString + \
[TRACE]:Failed to register MBean \ + name + \, iaee
[DEBUG]:Trying to delete reservation
[INFO]:Wrong RPC AUTH flavor, <*> is not AUTH_SYS or RPCSEC_GSS.
[ERROR]:-format must be ' + DtFileOperations.FORMAT_JAVA + ' or ' + DtFileOperations.FORMAT_PB + ' not ' + format + '
[ERROR]:No active subclusters available
[WARN]:registryClient is null, skip attaching existing UAM if any
[INFO]:Timeline service is not enabled
[INFO]:Audit event: create, src, status
[INFO]:Next operation retrieved from redundant input stream
[WARN]:Unable to create SSH session
[INFO]:Stored the finish data of application <*>
[INFO]:<*> no container is assigned when destroying
[WARN]:Modify this write to write only the appended data
[INFO]:Container Report :
[ERROR]:No block listing files were found! Cannot run with 0 DataNodes.
[DEBUG]:JvmMetrics singleton initialized
[DEBUG]:AuthenticationMethod.TOKEN authentication enabled for secret manager
[DEBUG]:Enabling path style access!
[DEBUG]:Type = <*>
[INFO]:Triggering block report
[DEBUG]:Skipping set to false
[ERROR]:Couldn't upload logs for + containerId + ". Skipping this container."
[WARN]:Failed to list directory ... Ignore the directory and continue.
[ERROR]:Local service " + localTarget + " has changed the serviceState to " + changedState + ". Expected was " + serviceState + ". Quitting election marking fencing necessary.
[DEBUG]:Max local threads: maxReduceThreads
[INFO]:Audit log: Operation successful
[DEBUG]:%5.5s, %10d, %10d, %10d, %10d, %6.2f, %5d, %5d, %5d
[WARN]:logWarningWhenAuxServiceThrowExceptions during APPLICATION_INIT
[ERROR]:Cache update failed for cache <*>
[DEBUG]:Acquired token
[DEBUG]:User <*> has been removed!, userName
[INFO]:Failed to submit application to parent-queue: x
[INFO]:Processing the event
[ERROR]:Link size: <*> is larger than max transfer size: <*>
[WARN]:Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: <*>
[INFO]:Audit event succeeded: removeDefaultAcl
[TRACE]:<*>: getFileStatus('<*>'), getName(), path
[INFO]:Removed rsrc.getLocalPath() from localized cache
[INFO]:LeafQueue: + leafQueue.getQueuePath() + , maxApplications= + maxApplications + , maxApplicationsPerUser= + maxApplicationsPerUser + , Abs Cap: + childQueue.getQueueCapacities().getAbsoluteCapacity(label)
[ERROR]:InvalidEncryptionKeyException recorded
[INFO]:delete old aux service jar dir:...
[DEBUG]:Authorization: Negotiate <*>
[DEBUG]:Running job cleanup task
[ERROR]:caught exception initializing this
[DEBUG]:Mandatory Resource '<*>' is not configured in resource-types config file. Setting allocation specified using '<*>'
[WARN]:Problem connecting to server: nnAddr
[INFO]:Transitioning to standby state
[ERROR]:Image checkpoint time X > edits checkpoint time Y
[DEBUG]:PrivilegedAction <*><*>
[DEBUG]:Setting total cache pools
[DEBUG]:Thread.currentThread().getName() is uploading a part.
[INFO]:Application + appId + " is stopped and can't be moved!"
[ERROR]:Unable to remove resource + rsrc + for + appIDStr + from state store
[DEBUG]:Containers allocated on multiple nodes
[INFO]:getSegmentInfo( + segmentTxId + ): + elf + -> + TextFormat.shortDebugString(ret) + ; journal id: + journalId
[INFO]:Allocating resources
[DEBUG]:<*>, Requesting next <*> uploads prefix <*>, next key <*>, next upload id <*>
[DEBUG]:issuing HTTP GET request params position = <*> b.length = <*> offset = <*> length = <*>
[ERROR]:Can not find log metadata for any containers on <*>
[WARN]:Failed to find FPGA discoverer executable configured in YarnConfiguration.NM_FPGA_PATH_TO_EXEC, please check! Try default path
[WARN]:<*>: No pending uploads to commit
[ERROR]:Cannot get this state!! Error!!
[ERROR]:Disk Balancer - Unknown key in get balancer setting. Key: <*>
[INFO]:Node ID assigned is : + this.nodeId
[WARN]:EntryFile write queue inactive; discarding <*> entries submitted to <*>
[INFO]:Not scanning suspicious block <*> on <*>, because there is no volume scanner for that storageId.
[INFO]:Audit Event: setReplication
[ERROR]:Can't start StoragePolicySatisfier for the given mode:<*>
[DEBUG]:Effective user AM limit for "<*>":<*>. Effective weighted user AM limit: <*>. User weight: <*>
[INFO]:Choosing random node after resolving network location
[ERROR]:SchedulerDynamicEditException: Invalid parent queue
[DEBUG]:GroupCacheLoader - load.
[INFO]:Cleaning log directories
[ERROR]:Number of children for queue + newState.getName() + in newState is + newChildrenSize + which is not equal to + childrenSize + in the current state.
[INFO]:Container + container + of + removed node + container.getNodeId() + completed with event + event
[INFO]:Queue x is STOPPED. Cannot accept submission of application: y
[INFO]:SubCluster info validated and added
[TRACE]:Initializing <*>
[WARN]:Checkpoint done. New Image Size: ...
[DEBUG]:Starting Metrics Logger Timer
[ERROR]:Exception thrown when formating configuration
[WARN]:Missing SubCluster Information. Please try again by specifying SubCluster Information.
[INFO]:Transitioned from <*> to <*> on <*> event
[ERROR]:YarnConfiguration.NM_LOCAL_CACHE_MAX_FILES_PER_DIRECTORY parameter is configured with very low value.
[INFO]:Updating application with final state
[INFO]:Initialized Runc runtime
[DEBUG]:- Added priority ordering edge: <*> >> <*>
[TRACE]:Block <*> does not need replication.
[DEBUG]:Volume <*>: block <*> is no longer in the dataset.
[WARN]:interrupted while sleeping
[DEBUG]:Cannot rename the root of a filesystem
[INFO]:Storing NM state version info + getCurrentVersion()
[DEBUG]:Force release cache <*>.
[INFO]:Skipping logs under <*> due to <*>
[INFO]:Application summary logged
[INFO]:Stopping History Cleaner/Move To Done
[INFO]:Assigned to reduce
[DEBUG]:First Volume : %s, DataDensity : %f, Last Volume : %s, DataDensity : %f
[INFO]:Job is running, but the host is unknown. Verify user has VIEW_JOB access.
[INFO]:attemptId + transitioned from state + oldState + to + getInternalState() + , event type is + event.getType() + and nodeId= + nodeId
[DEBUG]:Original tracking url is '<*>'. Redirecting to RM app page
[INFO]:Downloaded file + tmpFiles.get(0).getName() + size + finalFiles.get(0).length() + bytes.
[DEBUG]:Cleaning up <*> files
[INFO]:Storing info for attempt: + appAttemptId + at: + nodeCreatePath
[INFO]:Namesystem is not running, skipping decommissioning/maintenance checks.
[DEBUG]:<*> status is <*>, skipping stop, containerId, containerStatus
[DEBUG]:Unset storage class property STORAGE_CLASS; falling back to default storage class
[INFO]:Gridmix is configured to use compressed input data.
[TRACE]:Fetching SAS token provider
[DEBUG]:TC stats output:<*>
[DEBUG]:New attempt directory created - <*>
[WARN]:Forcibly uncaching <*> after <*> because client(s) <*> refused to stop using it.
[WARN]:Unexpected volume event received, event type is EVENT_TYPE, but the volumeId is null.
[DEBUG]:Not generating HistoryFinish event since start event not generated for task: task.getID()
[DEBUG]:Completed container: <*> in state: <*> event:<*>
[DEBUG]:Can not find the container:<*> in this node.
[ERROR]:Caught interrupted exception while waiting for thread <*> to finish. Retrying join
[WARN]:Warning: reset job <*> start time to 0.
[INFO]:NameNode can be reached at: %s
[ERROR]:An unexpected exception occurred pushing data to ZooKeeper, ex
[DEBUG]:current list of storage dirs:<*>
[INFO]:Number of files under construction = + size
[ERROR]:Failed to transfer block <*>
[INFO]:Service <*> doesn't exist
[INFO]:Starting TimelineClient
[INFO]:Processing the event JOB_ABORT
[INFO]:Hadoop platform inited
[WARN]:IP_ID environment is empty, skip downloading
[WARN]:Invalid KEY_OP '<*>' for <*>, ignoring
[DEBUG]:Entity document writing process initiated
[DEBUG]:Entering neutral mode for <*>
[INFO]:Super post called for CONCAT
[TRACE]:Unsuccessful invocation on <*>
[DEBUG]:Got + events.length + map completion events from + fromEventIdx
[INFO]:YARN containers restricted to + yarnProcessors + cores
[INFO]:EventFetcher is interrupted.. Returning
[DEBUG]:BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for <*> to add as corrupt on <*> by <*>
[WARN]:Error transferring data from ...
[TRACE]:<*>: created mmap of size <*>, this, channel.size()
[DEBUG]:wrapping token of length: + len
[INFO]:fsync called in RouterClientProtocol
[DEBUG]:AMRMProxy is ignoring event: <*>
[DEBUG]:Writing with HBaseTimelineWriterImpl
[DEBUG]:Moving <*> to <*>
[INFO]:Warming up <*> EDEKs... (initialDelay=<*>, retryInterval=<*>)
[INFO]:Registered StateStoreMBean: <*>
[ERROR]:Service state not STABLE
[INFO]:Bad configuration no queues defined
[WARN]:Got unexpected exception trying to acquire lease on
[DEBUG]:The reading thread has been interrupted.
[DEBUG]:Remove collector data for done app <*>
[DEBUG]:Stop processing
[INFO]:Notify RMCommunicator isAMLastRetry: <*>
[INFO]:AllocateBlockIdOp instance created and block ID set
[INFO]:Could not send read status ( + statusCode + ) to datanode + peer.getRemoteAddressString() + : + e.getMessage()
[WARN]:Lost job
[INFO]:Removing info for app: <*>
[DEBUG]:Adding service timelineClient
[WARN]:Removing <*> as it's an old temporary record
[DEBUG]:Starting AsyncCallQueue.Processor + daemon
[DEBUG]:Setting HADOOP_SECURITY_TOKEN_SERVICE_USE_IP to true
[WARN]:File being created has a "magic" path, but the filesystem has magic file support disabled: <*>, path
[ERROR]:could not create failure file.
[INFO]:loadBlockPoolSliceStorage: <*> upgrade tasks
[DEBUG]:Ordered locations following <*> are <*>, order, mountTableResult
[TRACE]:AzureBlobFileSystemStore init complete
[INFO]:Scheduler recovery is done. Start allocating new containers.
[ERROR]:Invalid eventtype eventType. Ignoring!
[INFO]:Copy failed from: fromPath to done location: toPath
[DEBUG]:Deleting final batch of listed files
[INFO]:Created file: + tmp
[ERROR]:Received container status for unknown container:
[INFO]:Removing "<*>"
[DEBUG]:Interrupting Event Handling thread
[DEBUG]:adding the following namenodes' delegation tokens: <*>
[INFO]:Failed to process fileInfo for job: <*>}
[ERROR]:Cannot enable <*>, it was not disabled
[ERROR]:Access control exception in removeAclEntries
[DEBUG]:Authorization check failed for <*>
[DEBUG]:Closing output stream
[DEBUG]:Getting replication factor
[DEBUG]:logRpcIds executed
[TRACE]:read(arr.length=<*>, off=<*>, len=<*>, filename=<*>, block=<*>, canSkipChecksum=<*>): starting
[DEBUG]:Node update event from: <*>
[INFO]:Processing records with reducer
[INFO]:Registering application master. Host: ... Port: ... Tracking Url: ... for application ...
[ERROR]:Failed to initialize handler <*>
[INFO]:Upgrade in progress. Please wait..
[INFO]:Nameservice <*> enabled successfully.
[ERROR]:Cannot get State Store versions
[DEBUG]:The version of namenode doesn't support getQuotaUsage API. Fall back to use getContentSummary API.
[INFO]:Creating database and collections for DocumentStore : <*>
[WARN]:No missing internal block. Skip reconstruction for task:<*>
[INFO]:Outputting <*> more corrupted nodes.
[TRACE]:GOT EXCEPITION, e
[WARN]:Block group <*> failed to write <*> blocks.
[DEBUG]:<*>: <*> is not usable for short circuit; giving up on BlockReaderLocal., this, pathInfo
[DEBUG]:Your relevant debug message here
[WARN]:Error trying to contact the shared cache manager, disabling the SCMClient for the rest of this job submission
[DEBUG]:PUT start <*> bytes
[TRACE]:Failed to place enough replicas, still in need of ...
[INFO]:Container completed with partition
[DEBUG]:Failed to match <*> to named-volume regex pattern
[INFO]:<*> for KEY_OP '<*>' is set to '*'
[DEBUG]:Found existing <*> servlet at path <*>; will replace mapping with <*> servlet
[ERROR]:Its jobID is + result.getJobID()
[DEBUG]:Checking federal security status
[INFO]:Loading inode directory section
[ERROR]:Error while resolving the path : fullName, exception
[DEBUG]:toCopyListing: + fileStatus + chunkSize: + blocksPerChunk + isDFS: + (fileSystem instanceof DistributedFileSystem)
[DEBUG]:Committer statistics
[INFO]:Timeline service address: + getTimelineServiceAddress()
[TRACE]:createNewMemorySegment: created info.shmId
[INFO]:Begin step for saving cache pools
[INFO]:Cannot add constraint to application <*>, as it has not been registered yet.
[DEBUG]:Exception in channel handler, cause
[INFO]:trySendErrorReport encountered RemoteException errorMessage: <*> errorCode: <*>
[WARN]:Got interrupted while joining + getName(), ie
[INFO]:Stream closed
[DEBUG]:start scanning block <*>
[DEBUG]:Error: invalid data in znode
[INFO]:Node <*> reported UNHEALTHY with details: <*>
[WARN]:Proceeding with manual HA state management even though\n+ automatic failover is enabled for + target
[INFO]:Got container status for NAMENODE:
[WARN]:Illegal value: the number of elements in \" + s + \" is + elements.length + but an even number of elements is expected.
[DEBUG]:KeyStore resetting to previously flushed state !!
[WARN]:Storage volume: <*> missing for the replica block: <*>. Probably being removed!
[INFO]:Writing/Updating amrmToken for subClusterId to registry for appId
[DEBUG]:Application recovery: ApplicationId=<*>, AttemptCount=<*>, FinalState=<*>
[INFO]:commitBlockSynchronization(oldBlock=...
[DEBUG]:Propagating SSE-KMS settings from source <*>
[INFO]:The required MAP capability is more than the supported max container capability in the cluster. Killing the Job. mapResourceRequest: + mapResourceRequest + maxContainerCapability: + supportedMaxContainerCapability
[INFO]:Successfully killed process that was listening on port <*>
[INFO]:maxContainerCapability: + maxContainerCapability
[DEBUG]:AADToken: refreshing refresh-token based token
[DEBUG]:Configuration failed, falling back to default
[INFO]:update exist container (containerId), strExposedPorts = (strExposedPorts)
[ERROR]:Container <*> Re-init failed !! Resource <*> could not be localized !!
[INFO]:End checkpoint for + registration.getAddress()
[DEBUG]:Committing %s
[WARN]:Could not get information of requester, ignoring for now.
[WARN]:Unable to delete dir + curFile + before rename
[WARN]:AppLogs for groupId <*> is set to null!
[INFO]:Store RMDT master key with key id: <*>. Currently rmDTMasterKeyState size: <*>
[DEBUG]:Replication remains unchanged at <*> for <*>
[INFO]:DIR* completeFile: $<*> is closed by $<*>
[INFO]:Submitting scheduling request: <*>
[INFO]:Done waiting for Applications to be Finished. Still alive: ...
[DEBUG]:Executing regular upload for <*>
[DEBUG]:createFile filesystem: <*> path: <*> overwrite: <*> permission: <*> umask: <*> isNamespaceEnabled: <*>
[DEBUG]:CA Certificate: \n<*>
[WARN]:Failure killing <*>
[ERROR]:Failed to register State Store bean <*>
[DEBUG]:STS Endpoint=<*>; region='<*>'
[ERROR]:Could not sync enough journals to persistent storage due to No journals available to flush. Unsynced transactions: <*>
[INFO]:Initialized Java Sandbox runtime
[DEBUG]:Block compaction finished for <*> ms with <*> blocks for <*>
[INFO]:Application stop event received for stopping AppId: <*>
[DEBUG]:Expiry based on expires_in: <*>
[DEBUG]:Remove the node out from suspect node list: <*>.
[INFO]:Safemode status retrieved successfully.
[DEBUG]:ignoring enqueue of empty list
[INFO]:Audit Event: setOwner successful for src
[DEBUG]:Removing state for attempt <*> at <*>
[INFO]:Container Re-init Auto Rolled-Back
[DEBUG]:Number of original ranges size <*>, Number of combined ranges <*>, ranges.size(), combinedFileRanges.size()
[INFO]:EDEKCacheLoader interrupted before warming up.
[INFO]:Rolling master-key for container-tokens
[INFO]:update the launch time for applicationId: <*>, attemptId: <*>, launchTime: <*>
[WARN]:Could not get disk usage information for path <*>, getDirPath(), ioe
[INFO]:<*> Flexed down by user, destroying.
[WARN]:Logging warning with status code
[DEBUG]:Cleaner starting
[WARN]:Unable to dump remaining operations, remaining raw bytes: " + Hex.encodeHexString(remainingRawEdits), ioe
[INFO]:Applications fetched
[DEBUG]:Block files moved to rbw directory
[INFO]:Application: <*> already present with SubCluster: <*>
[ERROR]:Failed to report to name-node.
[ERROR]:Manifest must be owned by YARN admin: + manifest
[DEBUG]:Using user: "<*>" with name: <*>
[WARN]:The value of DFS_NAMENODE_AVAILABLE_SPACE_BLOCK_PLACEMENT_POLICY_BALANCED_SPACE_TOLERANCE_KEY is invalid, Current value is balancedSpaceTolerance, Default value DFS_NAMENODE_AVAILABLE_SPACE_BLOCK_PLACEMENT_POLICY_BALANCED_SPACE_TOLERANCE_DEFAULT will be used instead.
[ERROR]:Error storing AMRMProxy application context entry for <*>
[WARN]:Invalid file name format for mount-table version file: <*>. The valid file name format is mount-table-name.<*>.xml
[INFO]:Multi-node update recording started
[WARN]:Incurred exception while loading LevelDb database. Backing up at <*>
[ERROR]:Could not store token <*> !!
[ERROR]:Forcing SlotReleaserThreadPool to shutdown!
[WARN]:Very low remaining capacity in the event-queue of RMContainerAllocator: <*>
[INFO]:STATE* UnderReplicatedBlocks has <*> blocks
[INFO]:Reconfiguration task started
[WARN]:Exception message if any
[WARN]:Encountered exception while tailing edits >= ... via RPC; falling back to streaming.
[DEBUG]:Looking for a token with service
[INFO]:Updating info for app: <*>
[DEBUG]:Not root inode with id <*> having no parent.
[DEBUG]:NFS RENAME from: <*>/<*> to: <*>/<*> client: <*>
[INFO]:removeDirective of + id + successful.
[DEBUG]:Container metrics finished
[INFO]:ResourceCommitterService exited!
[WARN]:Removed block + blockId + from memory with missing block file on the disk
[WARN]:Uncaught exception in ContainerMemoryManager while monitoring log usage for containerId
[DEBUG]:Moved block with size <*> from <*> to <*>
[ERROR]:error handling URI: ...
[INFO]:Block recovery attempt for + block + rejected, as the + previous attempt times out in + timeoutIn + seconds.
[INFO]:rmId + is elected leader, transitioning to active
[DEBUG]:No matches found and there was no wildcard in the path <*>
[INFO]:Canceled tokenKind:tokenService
[INFO]:Stopping container with container Id: + containerIDStr
[DEBUG]:Secret key interval obtained
[INFO]:Container y not launched. Not sending the signal
[DEBUG]:Launched service <*>
[INFO]:Reinitialized Managed Parent Queue: <*> with capacity <*> with max capacity <*>
[INFO]:Error when parsing local resource URI for
[TRACE]:Added block <*> to cachedBlocks
[DEBUG]:Select counter statement: <*>
[DEBUG]:unwrapping token of length: ...
[INFO]:initReplicaRecovery: update recovery id for + block + from + oldRecoveryID + to + recoveryId
[WARN]:Missing GetSubClusterInfo Request. Please try again by specifying a Get SubCluster information.
[DEBUG]:Could not resolve hostName. Falling back to default-rack
[INFO]:Yielding from election
[ERROR]:SchedulerDynamicEditException: Parent queue not specified
[WARN]:Unknown block status code reported by <*>: <*>
[DEBUG]:Endpoint <*> is the standard one; declare region as null
[INFO]:Rolling back storage directory <*>. target LV = <*>; target CTime = <*>
[INFO]:Override allocate responseId from ... to ...
[ERROR]:RedundancyMonitor thread received Runtime exception.
[DEBUG]:the local file does not exist.
[ERROR]:Service returned StorageException when checking existence of container <*> in account <*>
[INFO]:Using/Reloading 'staticMappingFile' for static UID/GID mapping...
[ERROR]:Job not successful!
[INFO]:kvstart = <*>; length = <*>
[INFO]:Deleting block.getLocalBlock() replica replicaToDelete
[DEBUG]:Running archival at time: <*>
[INFO]:Formatting ...
[DEBUG]:NMTokenSecretManager app finished
[WARN]:Unknown key <*>, ignored
[ERROR]:Can't make app runnable that does not already exist in queue as non-runnable: <*>. This should never happen.
[WARN]:Failed to fully delete aliasmap archive: + tarname
[DEBUG]:Remove write <*> which is already written from the list
[WARN]:Found non empty SchedulingRequest of AllocateRequest for application=$<*>, however the configured scheduler=$<*> cannot handle placement constraints, rejecting this allocate operation
[INFO]:...(InterruptedException e.Message)
[WARN]:Kill preemption policy activated
[WARN]:Unable to add the application to the delegation token renewer.
[WARN]:-jobconf option is deprecated, please use -D instead.
[DEBUG]:The file list contains the COS key <*> to be listed.
[INFO]:Config key <*> 's value <*> does not correspond to enum values of java.util.concurrent.TimeUnit. Hence default unit <*> will be used
[INFO]:Validating configuration files
[DEBUG]:Connecting to datanode
[INFO]:Enqueue Container
[DEBUG]:removeContainerPaused: containerId=<*>
[ERROR]:Cannot retrieve numExpiredNamenodes for JMX: <*>
[INFO]:Localizer failed for + localizerId, exception
[INFO]:closeInMemoryMergedFile -> size: + mapOutput.getSize() + , inMemoryMergedMapOutputs.size() -> + inMemoryMergedMapOutputs.size()
[ERROR]:Could not stop Delegation Token Counter
[INFO]:Can't send invalid block
[DEBUG]:Sampling input to effect total-order sort...
[ERROR]:Exception while trying to create proxy to the ResourceManager for SubClusterId: ...
[INFO]:Privileged action performed
[INFO]:Service <*> cancelling upgrade
[INFO]:Provided storage <*> transitioning to state <*>
[DEBUG]:JDK performed authentication on our behalf.
[ERROR]:Native output collector doesn't support customized java comparator
[DEBUG]:NoOpTimelineReader is configured. Response to all the read requests would be empty
[ERROR]:The policy <*> was not insert into the StateStore
[ERROR]:Invalid FSINFO request
[INFO]:\nOpening file <*> *************************** .
[ERROR]:<*>: commit of task <*> failed
[DEBUG]:Failed to serialize statistics
[INFO]:Launching workload job using input path: + workloadInputPath
[ERROR]:Unsupported operation exception
[ERROR]:SubCluster <*> does not exist
[ERROR]:Unable to remove master key <*>
[INFO]:TaskAttempt killed because it ran on unusable node <*>. AttemptId:<*>
[DEBUG]:Portmap mapping registration failed, the response size is less than 28 bytes: <*>
[ERROR]:Region must be provided when requesting session credentials.
[DEBUG]:Loaded RMDelegationTokenIdentifier: <*> renewDate=<*>, identifier, renewDate
[DEBUG]:drained fewer bytes than expected; <*> remaining
[DEBUG]:Copying local file from <*> to <*>
[ERROR]:Exception transitioning to standby
[INFO]:ResponseId out of sync with RM, expect ... but ... used by .... Will override in the next allocate.
[ERROR]:Unexpected exception in getting the filesystem
[DEBUG]:Remote UGI obtained
[INFO]:MultiNode scheduling is '<*>', and configured policies are <*>
[ERROR]:Unable to remove token <*>
[INFO]:PrivilegedOperation type unsupported in launch: <*>
[TRACE]:<*>: returning new legacy block reader local.
[INFO]:Sending an out of band ack of type + ackStatus
[WARN]:Latest log has no transactions. moving it aside and looking for previous log ; journal id:
[WARN]:Client is requesting a new log segment ...
[INFO]:Running on 1 nodes to sort from input into output with 1 reduces.
[INFO]:CacheReplicationMonitor already running
[DEBUG]:responding to call
[ERROR]:Error creating temp dir in java.io.tmpdir
[WARN]:Received SHUTDOWN signal from Resourcemanager as part of heartbeat, hence shutting down.
[INFO]:OutputCommitter set in config <*>
[DEBUG]:Failure during shutdown: <*> , failure, failure
[INFO]:Renew <*> in <*> ms, appId = <*>
[INFO]:Super post response created for CONCAT
[ERROR]:Fail to create a new application.
[WARN]:Disk error on + dnName + : + msg
[DEBUG]:original failed streamers: ...
[ERROR]:Cannot get disabled name services
[ERROR]:Thread <*> failed unexpectedly
[DEBUG]:Exception in closing closeable
[DEBUG]:Storage is up
[INFO]:Completed reading history information of all application attempts of application appId
[WARN]:Could not reload ACLs file: '%s'
[ERROR]:Cancelling plan on <*> failed. Result: <*>, Message: <*>, plan.getNodeName(), ex.getResult().toString(), ex.getMessage()
[ERROR]:Device programming failed, aocl output is:
[DEBUG]:Reset - First segment offset is + firstSegmentOffset + Segment List Size is + segmentList.size()
[DEBUG]:Creating token with ugi:<*>, renewer:<*>, service:<*>.
[INFO]:Next operation retrieved from file input stream
[ERROR]:Service <*> upgrade to version <*> failed because <*>
[TRACE]:we can write the local file.
[WARN]:Found unexpected column for entity %s of type %s (0x%02x)
[INFO]:Validating log segment <*> about to be finalized ; journal id: <*>
[INFO]:Application finished
[DEBUG]:Set quota for path: nsId: <*>, dest: <*>.
[DEBUG]:Got DT: <*>
[WARN]:Found non empty placement constraints map in RegisterApplicationMasterRequest for application=...
[ERROR]:Method <*> is not found in plugin
[INFO]:Edit log sync completed
[WARN]:Event <*> sent to absent container <*>
[INFO]:Put the timeline domain: TimelineUtils.dumpTimelineRecordtoJSON(domain)
[DEBUG]:Try timeline store <*>:<*>
[WARN]:Output Path is null in cleanupJob()
[INFO]:Notify JHEH isAMLastRetry: <*>
[WARN]:File <*> for script "<*>" does not exist.
[DEBUG]:Downgrading Syncable call
[INFO]:Invoking method concurrently
[DEBUG]:For URI <*>, using credentials <*>
[INFO]:Checkpointer about to load edits from <*> stream(s).
[ERROR]:validate reservation input
[WARN]:timeoutMillis + ms timeout elapsed waiting for an attempt to become active
[INFO]:Found corruption while reading + file + . Error repairing corrupt blocks. Bad blocks remain.
[DEBUG]:Updated mapName map size: map.size()
[WARN]:Exception in the cleaner thread but it will continue to run
[ERROR]:e.getMessage()
[INFO]:Forcefully kill the service: <*>
[INFO]:Execute renaming operation
[INFO]:Zone <*> completed re-encryption.
[DEBUG]:CSConf - getQueues: queuePrefix=<*>, queues=<*>
[INFO]:Successfully added volume: <*>
[INFO]:Registered RMInfo MBean
[INFO]:Cleaning up <*>
[DEBUG]:afterExecute in thread: <*>, runnable type: <*>
[INFO]:Got an error when resolve hostNames. Falling back to DEFAULT_RACK for all.
[DEBUG]:Read task returned: <*>, for stripe <*>
[INFO]:Parsed source tag: <*>, number of allocations: <*>
[DEBUG]:Verifying QOP, requested QOP = <*>, negotiated QOP = <*>
[ERROR]:Error while processing URI: <*>
[INFO]:Heartbeat Scaling Configuration: defaultInterval: <*> minimumInterval: <*> maximumInterval: <*> speedupFactor: <*> slowdownFactor: <*>
[WARN]:Allowing manual failover from + org.apache.hadoop.ipc.Server.getRemoteAddress() + even though automatic failover is enabled, because the user specified the force flag
[WARN]:Event + event + sent to absent application + event.getApplicationID()
[ERROR]:Exception thrown when modifying configuration.
[ERROR]:Error putting entities, %s
[ERROR]:Submitting plan on <*> failed. Result: <*>, Message: <*>
[INFO]:Request #getBlocks to Standby NameNode success. remoteAddress: <*>
[INFO]:Retransmitted request, transaction still in progress <*>
[DEBUG]:Forwarding allocateForDistributedScheduling request to the real YARN RM
[WARN]:Exception thrown when copy from <*> to <*>, exception: <*>
[ERROR]:Container metrics failed container
[DEBUG]:Setting the flow version: <*>, flowVersion
[DEBUG]:Failed to choose remote rack (location = ~ + localMachine.getNetworkLocation() + ), fallback to local rack
[DEBUG]:Creating file: <*>
[INFO]:serviceRecord.description: No external endpoints defined.
[DEBUG]:Setting output format
[INFO]:Checking the initial app list for finished applications.
[DEBUG]:Application <*> has one mapper finished (<*>)
[INFO]:SCM Admin: method invoked by user
[INFO]:AdminService and EmbeddedElector configured for HA
[DEBUG]:Customized device plugin implemented, use customized logic
[INFO]:Releasing unassigned container ...
[INFO]:Got UserName <*> for UID <*> from the native implementation
[ERROR]:Unable to recover task attempt
[INFO]:Queue acls for user : <*>
[INFO]:Reporting volume information for DataNode(s). These DataNode(s) are parsed from '<*>'.
[INFO]:Signaling process $<*> with $<*>. Exit code $<*>
[INFO]:URI redirection initiated
[INFO]:Audit event for listStatus operation allowed on src
[INFO]:Subtracting minshare starvation subsumed by fairshare starvation
[DEBUG]:Assigning container failed on node '<*>' because it has reserved containers.
[ERROR]:Service <*> exception during status change to <*> -server shutting down-, <*>
[INFO]:BLOCK* fsync: <*> for <*>
[ERROR]:Error while parsing the line, returning empty string
[WARN]:Could not store container <*> update.., e
[WARN]:Failed to write dfsUsed to ...
[INFO]:placing the following ReservationRequest: contract
[DEBUG]:Cleanup of directory with
[ERROR]:Ambiguous queue reference: + queueName + please use full queue path instead.
[DEBUG]:copyFile <*> -> <*>
[INFO]:closing the hbase Connection
[INFO]:Adding query param: GET_ACCESS_CONTROL
[INFO]:Removing state for attempt: + appAttemptId
[INFO]:Killing container $<*>
[ERROR]:Checkpoint failed
[WARN]:got IOException closing stale peer <*>, which is <*> ms old
[INFO]:Get cpu usage <*>
[ERROR]:Fail to launch application:
[DEBUG]:Volume <*> is <*>.
[DEBUG]:Exception in deleteKey., e
[INFO]:Application resources initialized for user: <*>
[WARN]:Task cleanup failed for attempt + event.getAttemptID(), e
[INFO]:Initialized KeyProviderCryptoExtension
[TRACE]:Retrieval of slow peer reports as json string is disabled. To enable it, please enable config <*>.
[DEBUG]:No HA service delegation token found for logical URI + haUri
[DEBUG]:IOUtils.cleanupWithLogger invoked
[DEBUG]:Renaming directory
[INFO]:Entering getRemoteAppLogDir
[ERROR]:FATAL: Queue named queueName is no longer a leaf queue during application recovery. Changing a leaf queue to a parent queue during recovery is not presently supported by the capacity scheduler.
[DEBUG]:Attempting symlink resolution
[DEBUG]:NOT_A_WRAPPED_SPAN + : <*>
[INFO]:Changing the permissions for inputPath <*>
[INFO]:deleted dir <*>, path
[ERROR]:Unable to retrieve apps from ClientRMService
[ERROR]:Can't create queue ' + queueName + ', since + FifoPolicy.NAME + is only for leaf queues.
[INFO]:Scheduled the in-memory scm store app check task to run every + checkPeriodMin + minutes.
[ERROR]:Failed to read the container $<*>.
[ERROR]:Get Node GPU Utilization error: e
[ERROR]:Unable to store master key <*>, e
[DEBUG]:Renewing delegation token <*>
[DEBUG]:prefix match for <*>: <*>
[WARN]:Destroyed application resources
[DEBUG]:Requested Node Label Expression : <*>
[DEBUG]:AzureBlobFileSystem.removeAcl path: <*>
[INFO]:loading user's secret keys from + tokensFileName
[WARN]:Command 'cmd' failed returnVal with: ec.getMessage()
[DEBUG]:finding record
[WARN]:Couldn't find Proxy CA data
[DEBUG]:Random text data generator is configured to use a dictionary with <*> words
[DEBUG]:Stack
[INFO]:Exception while adding a block
[DEBUG]:Using local user: <*>
[DEBUG]:Auth is SASL user="..." JAAS context="..."
[WARN]:Unsupported permission configured in + JHAdminConfig.MR_HISTORY_INTERMEDIATE_USER_DONE_DIR_PERMISSIONS + , the user and the group permission must be 7 (rwx). + The permission was set to + permission.toString()
[ERROR]:IOException occurred in close
[INFO]:Sorry, no counters for nonexistent task
[INFO]:Active Volumes : X
[INFO]:Performing upgrade of storage directory + sd.getRoot()
[INFO]:Session connected.
[DEBUG]:Applying UMask
[WARN]:Unexpected throwable:
[ERROR]:Could not initialize shared edits dir, ioe
[DEBUG]:Listing status for job
[DEBUG]:Skipping sending lifeline for + BPServiceActor.this + , because heartbeats are disabled for tests.
[DEBUG]:Active services created and initialized
[WARN]:Killing <*> because <*> is in state <*>
[INFO]:Unchecked exception is thrown from onStartContainerError for Container event.getContainerId(), thr
[WARN]:<*> pending uploads were found -aborting
[INFO]:AsyncScheduleThread<*> exited!
[INFO]:Applications Submitted: countHere
[INFO]:Shelling to container
[DEBUG]:Error while changing permission : filename Exception: exceptionMessage
[INFO]:Vmem usage in bytes <*>
[DEBUG]:Loading plan from znode: <*>
[ERROR]:Fail to get containers <*>
[WARN]:Set the buffer dir: <*>'s permission <*> failed.
[WARN]:getAmazonS3ClientForTesting() will be removed as part of upgrading S3A to AWS SDK V2
[ERROR]:DtFetcher for service 'service' does not allow aliasing. Cannot apply alias 'alias'. Drop alias flag to get token for this service.
[DEBUG]:BLOCK* neededReconstruction = <*> pendingReconstruction = <*>
[INFO]:output
[ERROR]:Missing $<*> distributed cache files under the directory\n$<*>\nthat are needed for gridmix to emulate distributed cache load. Either use -generate\noption to generate distributed cache data along with input data OR disable\ndistributed cache emulation by configuring '$<*>' to false.
[INFO]:Add user <*> to the list that will bypass external attribute provider.
[INFO]:Set restart interval to minimum value + minimumRestartInterval + ms for container + containerId
[INFO]:Store RMDT with sequence number + rmDTIdentifier.getSequenceNumber()
[DEBUG]:Application <*> sends out request for <*> streams.
[INFO]:Notify AM launcher launched:<*>
[DEBUG]:While deleting keys <*>
[DEBUG]:parsedDestPath value is:$<*>
[WARN]:Unexpected item in trash: ... Ignoring.
[INFO]:Setting up container launch container for containerid= + container.getId() + with shellid= + shellId
[DEBUG]:maybeLogRecord called
[INFO]:state = <*>
[WARN]:Access to S3A client requested, reason <*>
[ERROR]:Error: Shutting down
[TRACE]:Joiner.on("\n").join(Thread.currentThread().getStackTrace())
[INFO]:Starting the cleanup phase.
[INFO]:logAuditEvent(true, "modifyAclEntries", src, null, auditStat)
[INFO]:Request to start an already existing user: <*> was received, so ignoring.
[INFO]:modifyCachePool of <*> successful; set limit to <*>
[DEBUG]:addFinalizedBlock: Moved replicaInfo.getMetadataURI() to dstmeta and replicaInfo.getBlockURI() to dstfile
[INFO]:message
[WARN]:CleanupThread:Unable to delete path <*>
[INFO]:Get log file
[INFO]:Util Timer Starting
[DEBUG]:BEFORE decResourceRequest: applicationId= priority=<*> resourceName=<*> numContainers=<*>
[WARN]:Skipping inaccessible cgroup mount point %s
[INFO]:Skipping cleaning up the staging dir. assuming AM will be retried.
[ERROR]:App Attempt start/end event could not be published for <*>, <*>
[INFO]:Auth info added
[DEBUG]:Pinned block can't be moved, so skipping block
[DEBUG]:DNS instance created
[ERROR]:Unable to release chunk at path: + chunkFilePath
[ERROR]:Failed to upgrade components: <*>
[INFO]:Version : <*>
[DEBUG]:Counter value found and recorded for non-taskID entries
[INFO]:Decoding to reconstruct targets...
[INFO]:Activating next master key with id: <*>
[DEBUG]:BLOCK* prepareFileForTruncate: Scheduling copy-on-truncate to new size <*> new block <*> old block <*>
[ERROR]:Script not found in scriptPaths
[WARN]:Resource update get failed on an unrecognized node: <*>
[DEBUG]:Converting recovered DockerContainerDeletionTask
[WARN]:Datanode + i + did not restart within + datanodeRestartTimeout + ms: + nodes<*>
[WARN]:Error cleaning up a HistoryFile that is out of date.
[DEBUG]:You can either use the CLI tool: 'mapred job -history' to view large jobs or adjust the property <*>.
[ERROR]:%d labels specified on host=%s, please note that we do not support specifying multiple labels on a single host for now.
[INFO]:Exhausted max retry attempts <*> in token renewer thread for <*>
[DEBUG]:this: selecting input streams starting at <*> <*> from among <*> candidate file(s)
[DEBUG]:BLOCK* removeStoredBlock: <*> from <*>
[INFO]:<*>: Executing Manifest Job Commit with manifests in <*>
[DEBUG]:closing connection
[INFO]:Failed to process fileInfo for job: ...
[DEBUG]:in.getClass().getName() + : + does not implement StreamCapabilities + and the unbuffer capability
[DEBUG]:DN <*> has no lease to remove.
[ERROR]:Cannot fetch cluster ID metrics: <*>
[INFO]:Refresh call queue unsuccessfully for <*>
[DEBUG]:issuing read ahead requestedOffset = ... requested size ...
[DEBUG]:Connecting to datanode <*> addr=<*>
[DEBUG]:setting conf tokensFile: <*>
[DEBUG]:INode <*> doesn't exist, skipping re-encrypt.
[INFO]:Not waiting to recover container <*>, releasing
[INFO]:Unchecked exception is thrown from onContainerStarted for Container <*>
[DEBUG]:Processing release list for subClusters
[INFO]:Generating <*> methods
[DEBUG]:Illegal progress value found, progress is Float.POSITIVE_INFINITY. Progress will be changed to 1
[INFO]:Rescan of postponedMisreplicatedBlocks completed in <*> msecs. <*> blocks are left. <*> blocks were removed.
[DEBUG]:getFileStatus filesystem: <*> path: <*> isNamespaceEnabled: <*>
[INFO]:numReduceTasks: x
[INFO]:Bootstrap check succeeded
[ERROR]:<*> is set to an invalid value, it must be greater than zero. Defaulting to <*>
[DEBUG]:Inode <*> existing edek changed, skipping re-encryption
[DEBUG]:Move no longer pending
[DEBUG]:AADToken: refreshing client-credential based token
[INFO]:DFSConfigKeys.DFS_DATANODE_FILEIO_PROFILING_SAMPLING_PERCENTAGE_KEY set to $<*>. Disabling file IO profiling
[ERROR]:Error while submitting services for user <*>
[DEBUG]:Creating URL
[WARN]:DIR* FSDirectory.unprotectedRenameTo: Source <*> and destination <*> must both be directories
[INFO]:Size of event-queue is + qSize
[INFO]:Credentials
[DEBUG]:Flow context: <*> created for an application <*>
[INFO]:<*>% max memory <*> = <*>
[ERROR]:No response when attempting to kill the application applicationId to SubCluster subClusterIdId
[TRACE]:<*>: listStatusIterator('<*>'), getName(), path
[TRACE]:Lexicographical comparer selected
[DEBUG]:Parsing for log dir <*> on attempt <*>
[WARN]:<*> exec failed to cleanup
[INFO]:Removing + containerEvent.getContainerID() + from application + app.toString()
[INFO]:Processing volume event, type= + event.getType().name() + , volumeId= + volumeId.toString()
[INFO]:Will fetch a new encryption key and retry, encryption key was invalid when connecting to <*>
[INFO]:Property %s is not configurable: old value: %s, new value: %s
[INFO]:Refresh call queue successfully for <*>
[INFO]:number of splits: maps
[INFO]:Completed loading all INode sections. Loaded <*> inodes.
[DEBUG]:IndexCache MISS: MapId mapId not found
[DEBUG]:Failed to get the router startup time
[INFO]:interrupted
[INFO]:Loaded RM state version info <*>
[ERROR]:Failed to send deferred response. ThreadName= + Thread.currentThread().getName() + , CallId= + callId + , hostname= + getHostAddress()
[DEBUG]:moveToDone: + historyFile
[DEBUG]:Created new connection for this
[WARN]:Invalid directory in: <*>: <*>
[INFO]:Starting directory copy
[DEBUG]:Next element retrieved from RemoteIterator
[INFO]:Problem connecting to server: + nnAddr + : + e.getLocalizedMessage()
[ERROR]:Error getting logs for
[INFO]:Unknown application + applicationAttemptId + has completed!
[WARN]:String.format(Queue %s has max resources %s less than + min resources %s, getName(), maxResource, minShare)
[DEBUG]:IOUtils cleanup with LOG
[INFO]:MapCompletionEvents request from <*>. startIndex <*> maxEvents <*>
[ERROR]:Can't sync for fileId: <*>. Channel closed with writes pending
[INFO]:logPrefix + ": " + line
[INFO]:The fsimage will be loaded in parallel using <*> threads
[DEBUG]:stopping client from cache: <*>
[INFO]:Interrupted while waiting for application to be removed from RMStateStore.
[DEBUG]:Found <*>} files
[DEBUG]:ProcessInitialInputPathCallable path <*>
[INFO]:Audit log for success: <*>
[INFO]:Recover failed append to +
[ERROR]:Invalid event <*> on container <*>
[DEBUG]:Renewing the delegation token
[INFO]:Yarn control group does not exist. Creating ...
[INFO]:OutputCommitter is ...
[ERROR]:copyBlocksToLostFound: error processing <*>
[DEBUG]:Requesting buffer of size <*>
[INFO]:Log info with throwable
[INFO]:Calling RouterRpcServer mkdirs
[INFO]:Loading history server state from <*>
[ERROR]:The connection creator was interrupted
[INFO]:Event from RM: shutting down Application Master
[WARN]:Waited above threshold(%d ms) to acquire lock: lock identifier: %s waitTimeMs=%d ms. Suppressed %d lock wait warnings. Longest suppressed WaitTimeMs=%d. The stack trace is: %s
[DEBUG]:Failed to get number of live in maintenance nodes
[INFO]:Decode placement spec: + decodedSpec
[DEBUG]:Handling NodeRemovedSchedulerEvent
[INFO]:write temp capacity configuration fail, schedulerConfigFile= + tempSchedulerConfigPath, e
[DEBUG]:Generating encrypted key with name <*>, the edek Operation is <*>.
[INFO]:Assuming 'file' scheme for path + s + in configuration.
[INFO]:Unable to close file because dfsclient was unable to contact the HDFS servers. clientRunning <*> hdfsTimeout <*>
[INFO]:Successfully connected to peer
[DEBUG]:Failed to read the application
[WARN]:Could not connect to local service at targetToMonitor: e.getMessage()
[WARN]:A placement constraint cannot be associated with an empty set of tags.
[WARN]:NativeIO.getFstat error (%d): %s
[DEBUG]:Setting the user in the context: <*>, userId
[DEBUG]:Entering run method
[DEBUG]:updating nodeId : <*>
[TRACE]:storageTypes=<*>
[INFO]:Recovered + numKeys + RM delegation token master keys
[INFO]:Getting splits for input paths
[DEBUG]:cleanup job directory Path
[INFO]:Complete the multipart upload. bucket: <*>, COS key: <*>, upload id: <*>.
[WARN]:The first kerberos ticket is not TGT(the server principal is <*>), remove and destroy it.
[DEBUG]:Adding resource configuration file
[DEBUG]:Stat <*>
[WARN]:Exception in connecting to InMemoryAliasMap at <*>
[INFO]:Total number of queued jobs:
[INFO]:Storing RMDelegationToken and SequenceNumber
[INFO]:Rename operation started
[DEBUG]:Deferring removal of stale storage <*> with <*> blocks
[INFO]:Service client action stop initiated
[DEBUG]:Aborting multipart upload <*> to <*> initiated by <*> on <*>, uploadId, destKey, upload.getInitiator(), df.format(upload.getInitiated())
[INFO]:Recovery prepare phase complete. Responses:\n + QuorumCall.mapToString(prepareResponses)
[DEBUG]:No policy name is specified, set the default policy name instead
[DEBUG]:Sequential invocation on src
[INFO]:Status of table creation for <*>
[DEBUG]:FilterList created for scan is - <*>
[ERROR]:Error in setting outputbuffer capacity
[INFO]:Queue refreshed
[INFO]:LifelineSender for + BPServiceActor.this + exiting.
[ERROR]:Transfer failed for all targets.
[INFO]:JVM with ID : + jvmId + asked for a task
[DEBUG]:Portmap set key= + key
[DEBUG]:List COS key: <*> to check the existence of the path.
[ERROR]:prefix: <*>, delimiter: <*>, maxListingLength: <*>, priorLastKey: <*>. List objects occur an exception: <*>.
[WARN]:A connection is closed for no cause and calls are not empty
[INFO]:The aux service: <*> is using the custom classloader with classpath <*>
[DEBUG]:Task succeeded
[DEBUG]:lastAckedSeqno = <*>
[ERROR]:IOException encountered in seek
[DEBUG]:Data field not found
[INFO]:A total of initialCachedEntries.size() files are now mapped
[INFO]:For namenode using...
[DEBUG]:Deleting the temporary directory of '$<*>': '$<*>'
[DEBUG]:Has kerberos credentials: %b
[TRACE]:Block <*>: added to PENDING_CACHED on DataNode <*>
[DEBUG]:Using User-Agent: <*>
[INFO]:createStartupShutdownMessage
[ERROR]:Error during scanning devices
[INFO]:DFS_BLOCKREPORT_INITIAL_DELAY_KEY is greater than or equal to DFS_BLOCKREPORT_INTERVAL_MSEC_KEY. Setting initial delay to 0 msec.
[INFO]:Listing succeeded
[DEBUG]:Starting Job
[ERROR]:Unable to insert the newly generated policy for the queue : <*>
[DEBUG]:Unset erasure coding policy on <*>
[DEBUG]:The option <*> has a negative value <*>, replacing with the default <*>
[ERROR]:No block pools found on volume. volume : <*>. Exiting.
[INFO]:Deleting key: <*> from KeyProvider: <*> <*>
[INFO]:Token master key removed from leveldb state store
[INFO]:Error when verifying access for user ... on the events of the timeline entity ...
[ERROR]:Error while stopping web app context for webapp + webAppContext.getDisplayName(), e
[WARN]:Error reading the out stream
[INFO]:Service map cleared
[INFO]:Scheduling provision volume task (with delay + delaySecond + s), + handling + volumeProvisioningTask.getVolumes().size() + volume provisioning
[DEBUG]:Loaded RM delegation token from <*>: tokenId=<*>, renewDate=<*>
[INFO]:Client trace information logged
[DEBUG]:Assigned based on rack match <*>
[ERROR]:No node in path <*>
[ERROR]:Cannot write <*>
[DEBUG]:recycle: array.length=
[ERROR]:Exception encountered , <*>
[DEBUG]:Ignoring: <*>
[ERROR]:Could not read the contents of <*>, <*>
[INFO]:After major compaction for qualifier= with currentColumnCells.size= returning finalCells.size= with zero sum=
[INFO]:KILLING <*>
[INFO]:Successfully started service + appName
[DEBUG]:AADToken: refreshing custom based token
[INFO]:Transitioning RM to Standby mode
[INFO]:Update max queue length of app activities from <*> to <*> when multi-node placement enabled.
[ERROR]:Usage: MapFile inFile outFile
[DEBUG]:Incoming requestAttribute:<*> is not present in <*>, however opcode is NE. Hence accept this node.
[DEBUG]:Emitting metric + name +, type + type +, value + value +, slope + gSlope.name() + from hostname + getHostName()
[DEBUG]:Finished sorting inodes
[INFO]:Killed workload app
[DEBUG]:ending log segment because of end of stream in <*>
[ERROR]:Failure during secure login
[INFO]:GET: component instances for service = <*>, compNames in <*>, version = <*>, containerStates in <*>, user = <*>
[INFO]:Multi-node update recording finished
[INFO]:Building PowerShell script to kill <*> at <*>
[WARN]:logWarningWhenAuxServiceThrowExceptions during CONTAINER_STOP
[INFO]:Interrupted waiting to join on checkpointer thread
[ERROR]:Caught OutOfMemoryError. One possible reason is that ulimit setting of 'max user processes' is too low. If so, do 'ulimit -u <*>' and try again.
[WARN]:Unflushed op <*>: " + op
[INFO]:Update numAllocation from old= + existingNumAllocations + to new= + newNumAllocations
[WARN]:Unable to parse configuration UMASK_LABEL with value confUmask as octal or symbolic umask.
[INFO]:Missing location for the node health check script "<*>".
[INFO]:Looking into <*> apps to see if they are still active.
[INFO]:Storing attempt: AppId: <*> AttemptId: <*> MasterContainer: <*>
[WARN]:Thread Interrupted waiting to refresh disk information: <*>
[ERROR]:Cannot get allocation for container: <*>
[DEBUG]:Executing command <*>
[DEBUG]:Resource usage of ProcessTree <*> for container-id <*>: <*> %CPU: <*> %CPU-cores: <*> vCores-used: <*> of <*> Cumulative-CPU-ms: <*>
[TRACE]:nextTcpPeer: failed to create newConnectedPeer connected to <*>
[DEBUG]:Writing out keystore.
[DEBUG]:<*>: cache cleaner running at <*>
[INFO]:...(IOException e.Message)
[INFO]:Creating state database at <*>
[INFO]:Sending the cached reply to retransmitted request <*>
[INFO]:Starting edit log roll due to rolling upgrade finalization
[INFO]:Read operation on path
[INFO]:Initializing cache for csi-driver-adaptors
[DEBUG]:Log types added
[WARN]:Failed to bootstrap outbound bandwidth configuration
[DEBUG]:Creating <*> with <*> bytes of data and ACL <*>
[WARN]:scanner close called but scanner is null
[INFO]:<*> running containers including AM recovered from home RM <*>
[DEBUG]:Block compaction: <*> blocks for <*>
[ERROR]:Cannot generate JSON of mount table from store: <*>
[DEBUG]:<*>: task attempt <*> added <*> directories
[ERROR]:Failed to execute GPU device information detection script for MAX_REPEATED_ERROR_ALLOWED times, skip following executions.
[INFO]:Audit log event: rename (options=<*>) src dst
[INFO]:Token read from Docker client configuration file: ...
[ERROR]:GPU is enabled, but could not find any usable GPUs on the NodeManager!
[DEBUG]:Fetching documents for entity type ...
[DEBUG]:getObjectMetadata(<*>) failed to find an expected file
[ERROR]:Unknown event arrived at ContainerScheduler: $<*>
[WARN]:Invalid tagName: + tagName
[INFO]:Target
[INFO]:Killing <*> due to recovered as killed
[WARN]:Existing client context ' + name + ' does not match + requested configuration. Existing: + existing + , Requested: + requested
[WARN]:HistoryEventEmitters: null counter detected:
[ERROR]:Thread <*> threw an error: <*>. Shutting down
[TRACE]:Done q-ing readAhead for file <*> offset <*> buffer idx <*>
[INFO]:<*>
[INFO]:NNStorage.attemptRestoreRemovedStorage: check removed(failed) storage. removedStorages size = <*>
[INFO]:Connecting to ... subClusterId ... with protocol ... without a proxy user
[WARN]:Using standard FileOutputCommitter to commit work. This is slow and potentially unsafe.
[INFO]:Skipping State Store cache update, driver is not ready.
[WARN]:ShortCircuitCache.this: failed to release short-circuit shared memory slot ...
[ERROR]:Cannot find BPOfferService for reporting block receiving for bpid=<*>
[INFO]:UGI instance = %s
[DEBUG]:Recalculate checksum for the missing/failed block index <*>
[INFO]:submitApplication appId <*> try #0 on SubCluster <*>
[INFO]:No principal name specified. Will use AM login identity <*> to attempt keytab-based login
[INFO]:Removing info for attempt: $<*> at: $<*>
[DEBUG]:Audit log for operation: listEncryptionZones, success: true
[DEBUG]:Sending lifeline with ...
[WARN]:Unable to get NameNode addresses.
[DEBUG]:Creating a GREEDY_PLANNER for Node : nodeName IP : nodeIP ID : nodeUUID
[INFO]:Built by : <*>
[DEBUG]:opWriteBlock: stage=<*>, clientname=<*> block=<*>, newGs=<*>, bytesRcvd=<*> targets=<*>; pipelineSize=<*>, srcDataNode=<*>, pinning=<*>
[ERROR]:Trying to set finish time for task + taskid + when no start time is set, stackTrace is : + StringUtils.stringifyException(new Exception())
[INFO]:Instantiated MRClientService at <*>
[ERROR]:UAM not found for attemptId in sub-cluster subClusterId
[DEBUG]:getPathStatus for filesystem: <*> path: <*>
[WARN]:Unknown storage class property STORAGE_CLASS
[DEBUG]:Clear markedDeleteQueue over <*> millisecond to release the write lock
[WARN]:Couldn't recover Proxy CA data
[TRACE]:getBlockLocalPathInfo successful block=<*> blockfile <*> metafile <*>
[WARN]:HadoopLogsAnalyzer.processJobLine: bad numerical format, at line
[DEBUG]:take(): poll() returned null, sleeping for <*> ms
[INFO]:Total size of compressed input data : <*>
[DEBUG]:DIR* NameSystem.startFile: added src inode id holder
[DEBUG]:Summary directory set in to <*><*><*>
[WARN]:Wrong output from sysInfo: ...
[INFO]:getLoginUser
[DEBUG]:SASL client skipping handshake on trusted connection for addr = <*>, datanodeId = <*>
[WARN]:Please set memory/vcore in the main section of resource, ignoring this entry=<*>
[INFO]:Leave startup safe mode after <*> ms
[ERROR]:Startup failed. <*>
[ERROR]:Dir <*> exists: <*>
[INFO]:New REQUEST_RESOURCE_LOCALIZATION localize request for locId, remove old private localizer.
[DEBUG]:Adding <*> to serial index
[ERROR]:Error when writing command to temp file, e
[WARN]:Unable to stop HTTP server for ...
[ERROR]:Failed to cleanup staging dir + jobTempDir, io
[DEBUG]:Pushing record <*>.<*>.<*> to <*>
[DEBUG]:Creating timeline event
[ERROR]:<*> is set to an invalid value, it must be zero or greater. Defaulting to <*>, DFSConfigKeys.DFS_NAMENODE_DECOMMISSION_MAX_CONCURRENT_TRACKED_NODES, DFSConfigKeys.DFS_NAMENODE_DECOMMISSION_MAX_CONCURRENT_TRACKED_NODES_DEFAULT
[INFO]:Sink + name + started
[DEBUG]:Generate delegation token with renewer
[TRACE]:getBlocks( + getDatanodeInfo() + , + StringUtils.TraditionalBinaryPrefix.long2String(size, B, 2) + ) returns + newBlksLocs.getBlocks().length + blocks.
[WARN]:Unable to find stream starting with ...
[ERROR]:Error while attempting scheduling for node <*>: <*>
[INFO]:Initialized Federation proxy for user: <*>
[INFO]:Merging external component <*> from external <*>
[INFO]:Application <*> sends out request for <*> containers.
[INFO]:Launching <*>
[INFO]:Rolled edit log using RouterRpcServer
[WARN]:Invalid value <*> for <*>; must be >= <*>
[WARN]:AsyncLazyPersistService has already shut down.
[INFO]:Resource usage emulation complete! Matcher exiting
[ERROR]:Failed to close outputstream of dump file <*>
[INFO]:Received new tokens for <*>. Received <*> tokens.
[TRACE]:startMaintenance: Node <*> in <*>, nothing to do.
[INFO]:The outputStream for key: <*> has been uploaded.
[DEBUG]:Recovering task information
[TRACE]:this + : + removedFrom + no longer contains + replica + . refCount + (replica.refCount - 1) + -> + replica.refCount + StringUtils.getStackTrace(Thread.currentThread())
[TRACE]:openFileMap size:<*>
[TRACE]:stopDecommission: Node <*> in <*>, nothing to do., node, node.getAdminState()
[INFO]:Successfully warmed up <*> EDEKs.
[DEBUG]:New listing state: <*>
[INFO]:Revert <*>
[INFO]:found local record? true
[INFO]:Initialized MemoryMappableBlockLoader
[ERROR]:Path not found
[WARN]:Unknown rpc kind + header.getRpcKind() + from client + getHostAddress()
[ERROR]:Exception analyzed and printed
[INFO]:Executing with tokens:
[ERROR]:Failed to updatePlacementRules
[DEBUG]:Reserved container application=<*> resource=<*> queue=<*> cluster=<*>
[DEBUG]:Checking if blockNumber is negative
[INFO]:Shuffle port returned by ContainerManager for <*> : <*>
[WARN]:imprecise representation of floating-point values in Java, this
[INFO]:Service stopped, return null for the storage
[DEBUG]:NativeIO.createDirectoryWithMode error, path = %s, mode = %o
[ERROR]:Trying to initialize resource plugin with name
[ERROR]:FSImageSaver cancel checkpoint threw an exception:, e
[DEBUG]:<*>: Cleaup of directory <*> with <*>, getName(), baseDir, args
[INFO]:Initializing Federation Interceptor
[INFO]:closing the app_flow table
[ERROR]:Please specify the path for setting the storage policy.
[ERROR]:Failed to query the status of Container + containerId
[INFO]:Retrying connect to namenode: <*>. Already retried <*> time(s); retry policy is <*>, delay <*>ms.
[TRACE]:Registering <*> for <*>
[DEBUG]:HTTP error code: <*> Server response : <*>
[WARN]:System service launcher thread interrupted
[WARN]:This cycle terminating immediately because 'shouldRun' has been deactivated
[INFO]:Initializing a csi-adaptor-client for csi-adaptor <*>, csi-driver <*>
[ERROR]:Cannot find resolver for order <*>, order
[ERROR]:Error while trying to run jobs.
[INFO]:$<*>: $<*>
[INFO]:Successfully loaded & initialized native-bzip2 library + libname
[INFO]:Task attempt timed out and removed
[INFO]:Generating class <*><*>
[ERROR]:User <*> is not authorized to view the logs for <*>
[INFO]:Emitting job history data to the timeline server is not enabled
[INFO]:Promoting container <*> to <*>
[ERROR]:Failed to create the workingDir:
[DEBUG]:Shutting down writer; entry lists in queue: <*>
[INFO]:Output directory:
[ERROR]:Error getting logs for <*> <*>
[INFO]:Received <*> containers from previous attempt.
[WARN]:Cannot load filesystem:
[DEBUG]:Traversing directory <*>
[TRACE]:Trigger client.read for path=<*> position=<*> offset=<*> length=<*>
[INFO]:rollingUpgrade FINALIZE
[DEBUG]:JMX URL: <*>
[INFO]:Application has completed successfully.
[DEBUG]:Rename source path: <*> to dest path: <*>
[INFO]:Storage policy satisfier is configured as external, please start external sps service explicitly to satisfy policy
[DEBUG]:Failed to load token renewer implementation
[DEBUG]:CSConf - getAbsolueResourcePerQueue: prefix= + getNodeLabelPrefix(queue, label) + , capacity= + resource
[DEBUG]:Opening file: <*>
[WARN]:<*>: exception in retry processing
[INFO]:Scheduling $<*> DBs older than $<*> for eviction
[INFO]:Error report from Unknown DataNode: ...
[INFO]:Configuration reloaded from store
[INFO]:Exception thrown in thread join:
[TRACE]:Delegation token found: <*>
[INFO]:The maximum iteration time ( + maxIterationTime / 1000 + seconds) has been reached. Stopping + this
[INFO]:<*>: Task Attempt <*> file <*>: File count: <*>; data size=<*>
[WARN]:Exception while trying to expire reservation: <*>, <*>
[INFO]:App succeeded with state: FINISHED
[ERROR]:Shuffle error in populating headers:
[INFO]:Adding new operation of type PREFETCH
[WARN]:Task + task.getTaskID() + has nulll TaskStatus
[INFO]:Nameservice <*> disabled successfully.
[DEBUG]:convertToByteBufferState is invoked, not efficiently. Please use direct ByteBuffer inputs/outputs
[DEBUG]:Status polling for job
[INFO]:Transitioned to active state
[DEBUG]:DFSClient <*>
[DEBUG]:Adding new framework-token for <*> for log-aggregation: <*>; userUgi=<*>
[ERROR]:IllegalArgumentException Wrong eekOp value, it must be EEK_GENERATE or EEK_DECRYPT
[INFO]:Assigned container <*> to <*>
[DEBUG]:Creating password for <*> for user <*> to run on NM <*>
[DEBUG]:DIR* FSDirectory.removeBlock: with block is removed from the file system
[TRACE]:Created Request <*> in span <*>
[DEBUG]:Exception occurred while modifying cache pool
[INFO]:Initialized PmemMappableBlockLoader
[INFO]:TimelineServicePublisher is not configured
[INFO]:fetchColumnsFromFilterList executed for RELATES_TO
[INFO]:Balance failed, error code: + retCode
[INFO]:Failed to write config version at <*>, <*>
[INFO]:Existing Working Dir detected: - FORCE_OPTION specified -> recreating Working Dir
[DEBUG]:Attempting to read aggregated logs using IndexedFileController
[DEBUG]:Illegal progress value found, progress is Float.NEGATIVE_INFINITY. Progress will be changed to 0
[INFO]:Creating Cosmos DB Writer Async Client...
[DEBUG]:Resource usage plus resource request: usagePlusAddition exceeds maximum resource allowed: getMaxShare in queue getName
[DEBUG]:Max local threads: <*>}
[WARN]:The file <*> is not under construction but has lease.
[INFO]:Submitted the job ...
[DEBUG]:Deleting root content
[INFO]:namenodes = + namenodes
[TRACE]:ReadBufferWorker picked file <*> for offset <*>
[ERROR]:must pass -alias field with dtutil edit command
[INFO]:Handling job abort event
[INFO]:Erasure coding policies added
[DEBUG]:MOUNT MNT path: <*> client: <*> â†’
[DEBUG]:Got recycled decompressor
[DEBUG]:Create remote user with remote user
[WARN]:Scheduler UpdateThread interrupted. Exiting.
[INFO]:Compression codec instance created
[INFO]:Unauthenticated access audited
[DEBUG]:Trying to fulfill reservation for application <*> on node: <*>, reservedApplication.getApplicationId(), node.getNodeID()
[INFO]:Loading standard ssl config
[ERROR]:Cannot get the remote user name
[DEBUG]:Sending System credentials for apps as part of NodeHeartbeat response.
[INFO]:Loading edits into backupnode to try to catch up from txid ...
[WARN]:Exception occurred: ...
[ERROR]:Cannot check app: e.getMessage()
[ERROR]:Unexpected error starting NodeStatusUpdater
[INFO]:Successfully uncached one replica:<*> from persistent memory, <*>
[DEBUG]:Creating setup context, jobSubmitDir url is ...
[DEBUG]:Attempted read operation; reached end of file or no bytes read
[WARN]:Audit log: Container failed with state: ...
[ERROR]:Incompatible build versions: active name-node BV = <*>; backup node BV = <*>
[INFO]:Downloaded file + aliasMap.getName() + size + aliasMap.length() + bytes.
[DEBUG]:AzureBlobFileSystem.getFileStatus path: <*>
[ERROR]:<*>: Failed to delete component instance dir: <*>
[INFO]:PUT: upgrade component instances <*> for service = <*> + user = <*>
[DEBUG]:Got pid <*> for container <*>
[DEBUG]:User <*> added to activeUsers, currently: <*>
[ERROR]:RMNodeLabelsMappingProvider should be configured when delegated-centralized node label configuration is enabled
[INFO]:finalizing upgrade completed by superuser
[INFO]:Upgrade process renamed reserved path + oldPath + to + path
[WARN]:Unable to parse credentials for applicationId
[INFO]:Downloading missing Edit Log from <*> to <*>
[DEBUG]:*DIR* NameNode.rename: " + src + " to " + dst
[INFO]:<*>: Recovered <*> for component instance <*> on host <*>, num pending component instances reduced to <*>
[INFO]:Need to save fs image? true (staleImage=false, haEnabled=false, isRollingUpgrade=false)
[INFO]:Interceptor chain acquired
[INFO]:Storing reservation allocation. + reservationEvent.getReservationIdName()
[WARN]:Got overwrite [<*>-<*>) smaller than current offset <*>, drop the request
[DEBUG]:Block <*> cannot be reconstructed from any node
[INFO]:Waiting up to 30 seconds for transfer threads to complete
[WARN]:<*> <*> Activate <*>, currentThreadID(), getSpanId(), getDescription()
[WARN]:Skipping date check on this plan. This could mean we are executing an old plan and may not be the right plan for this data node.
[ERROR]:No shared edits directory configured for namespace + nsId + namenodeId
[ERROR]:Exception while parsing json : <*> \n <*>
[INFO]:HA enabled check completed
[INFO]:Merging sorted segments
[DEBUG]:Hadoop login
[INFO]:Scheduling Log Deletion for application: <*> , with delay of <*> seconds
[TRACE]:Removing unknown block
[WARN]:Exception
[DEBUG]:Service initialized with configuration
[INFO]:Using FileSystemAccess Kerberos authentication, principal <*> keytab <*>
[DEBUG]:rename: destination path <*> not found
[INFO]:initReplicaRecovery: + block + , recoveryId= + recoveryId + , replica= + replica
[DEBUG]:config.json used:
[INFO]:Request for unknown token appid
[INFO]:No audit logger configured, using default.
[WARN]:Error in executing container interactive shell <*> exit = <*>
[DEBUG]:Retrying on error during bulk delete
[ERROR]:Can't create queue ' + queueName + ', the child scheduling policy is not allowed by parent queue!
[INFO]:History service stopped
[TRACE]:<*>: save('<*>, <*>, <*>')
[DEBUG]:Updating token in Leveldb state store
[WARN]:OFFSWITCH_PER_HEARTBEAT_LIMIT + "(" + limit + ") < 1. Using 1.
[INFO]:Total target DataNodes in this iteration: <*>
[DEBUG]:set bytesPerCRC=<*>, crcPerBlock=<*>
[DEBUG]:Succeeded to stop Container <*>
[DEBUG]:Logging RPC IDs
[INFO]:Application killed due to expiry of reservation queue <*>.
[DEBUG]:Sorting inodes
[DEBUG]:saveErasureCodingSection completed
[ERROR]:Only provide -service with http/https URL.
[DEBUG]:Interrupted while waiting for requests from inputQueue.
[WARN]:the container <*> will be killed because of the unknown key <*> during recovery.
[INFO]:Sleeping in the re-encryption updater for unit test.
[ERROR]:Proxy error: ...
[INFO]:Reacquired containerId -> classId mapping: + containerIdStr + -> + classId
[INFO]:stopping existing webapp instance
[ERROR]:Fail to check application status:
[INFO]:Synchronizing log
[ERROR]:Cannot get <*> nodes, subclusters timed out responding
[INFO]:updating RMDelegation token with sequence number: sequence_number_value
[DEBUG]:Created <*>, tracker
[ERROR]:Got sink exception and over retry limit, suppressing further error messages
[DEBUG]:Added track info for inode <*> to block storageMovementNeeded queue
[DEBUG]:Notifying handler for new re-encryption command.
[INFO]:fsync called in RouterRpcServer
[INFO]:Number of suppressed read-lock reports: <*> Longest read-lock held at <*> for <*>ms via <*>
[DEBUG]:Setting quota for...
[ERROR]:Unable to clear zk parent znode
[DEBUG]:logUtilizationCollection("below-average", belowAvgUtilized)
[ERROR]:Exception raised while executing preemption checker, skip this run..., exception=
[INFO]:Received duplicate heartbeat from node + rmNode.getNodeAddress() + responseId= + remoteNodeStatus.getResponseId()
[INFO]:Shutting down CacheReplicationMonitor
[DEBUG]:Closing log when already closed
[DEBUG]:checkDiskError encountered no failures
[ERROR]:Access Control Exception: removeAcl failed
[ERROR]:ResourceHandlerChain.preStart() failed!
[INFO]:User after logged in is: <*>
[WARN]:Encountered exception while exiting state
[DEBUG]:Location cache after invalidation: <*>
[INFO]:Connecting to ZooKeeper without authentication
[INFO]:Docker volume-name= + volumeName + driver-name= + driverName + already exists for container= + container.getContainerId() + , continue...
[INFO]:Invoke single method executed
[WARN]:Forwarding existing session credentials to <*> -duration unknown
[INFO]:Storing RMDelegationToken_SEQUENCE_NUMBER
[DEBUG]:Cannot pick ... as the ClientProtocolProvider - returned null protocol
[WARN]:Delay set too low, using default
[INFO]:Audit success: satisfyStoragePolicy
[DEBUG]:Writing event
[INFO]:ContainersMonitor enabled: <*>
[WARN]:path + " does not have jars in it. It will be ignored."
[DEBUG]:isDatanode=<*>, isClient=<*>, isTransfer=<*>
[DEBUG]:Metrics system initialized
[WARN]:Failed to initialize filesystem <*>: <*>, uri, e.toString()
[INFO]:Container finished
[INFO]:Successfully deleted public resource dir for + serviceName + : + publicResourceDir
[ERROR]:Audit failed: satisfyStoragePolicy
[INFO]:Unknown application + containerId.getApplicationAttemptId().getApplicationId() + increased container + containerId + on node: + node
[INFO]:Successfully became active. Attempt succeeded
[DEBUG]:Submission successful
[ERROR]:configuration exception
[DEBUG]:No space available. Available: + availableSize + MinSize: + minSize
[INFO]:Updated NodeAttribute event to RM: + newNodeToAttributesMap
[DEBUG]:BlockTokenIdentifier id: <*>
[INFO]:Subcommand executed
[TRACE]:SPNEGO in progress
[DEBUG]:Backup store written
[DEBUG]:Got pid <*> from path <*>
[INFO]:Submit app request failed, ue
[INFO]:fetcher#id - MergeManager returned status WAIT ...
[ERROR]:Error removing attempt: + attemptId, e
[ERROR]:Unknown event arrived at ContainerScheduler: <*>
[WARN]:Unable to connect to + host + as user + args.user
[WARN]:The cleaner service was interrupted while shutting down the task.
[DEBUG]:Start reading range <*> from path <*>
[DEBUG]:Exception while reading a range <*> from path <*>
[DEBUG]:Scanning intermediate dir <*>}
[WARN]:Getting exception while validating integrity and setting length for blockFile
[WARN]:Skipping extraneous data + key
[DEBUG]:isValidRequestor is comparing to valid requestor: ...
[WARN]:This run effectively has a -seed of randomSeed
[TRACE]:GOT EXCEPTION
[ERROR]:Exception during StoragePolicySatisfier execution - will continue next cycle
[WARN]:Doesn't handle app activities at level level.
[INFO]:Begin step SAVING_CHECKPOINT
[DEBUG]:emitted cells. + addedCnt + for + this.action + rowKey= + FlowRunRowKey.parseRowKey(CellUtil.cloneRow(cells.get(0)))
[INFO]:Node update recording finished
[DEBUG]:Loading section INODE_REFERENCE length: <*>
[DEBUG]:Error parsing <*> as an ContainerId
[WARN]:interrupted when wait a read buffer
[INFO]:Stopping security manager
[DEBUG]:User limit computation for + userName + , in queue: + lQueue.getQueuePath() + , userLimitPercent= + lQueue.getUserLimit() + , userLimitFactor= + lQueue.getUserLimitFactor() + , required= + required + , consumed= + consumed + , user-limit-resource= + userLimitResource + , queueCapacity= + queueCapacity + , qconsumed= + lQueue.getQueueResourceUsage().getUsed() + , currentCapacity= + currentCapacity + , activeUsers= + usersSummedByWeight + , clusterCapacity= + clusterResource + , resourceByLabel= + partitionResource + , usageratio= + getUsageRatio(nodePartition) + , Partition= + nodePartition + , resourceUsed= + resourceUsed + , maxUserLimit= + maxUserLimit + , userWeight= + getUser(userName).getWeight()
[DEBUG]:Resource handler chain enabled = true
[WARN]:Exception when scheduling the event of re-initializing of Container containerId
[DEBUG]:FairScheduler state: Cluster Capacity: ... Allocations: ... Availability: ... Demand: ...
[WARN]:Could not obtain appInfo object from provider.
[DEBUG]:createDir: <*> perm:<*> owner:<*>, dirPath, perms, owner
[DEBUG]:Requested resource value after conversion: + requestedResourceValue
[DEBUG]:Generating new application ID
[INFO]:Skipping <*> due to total file size being too large (<*> > <*>)
[INFO]:Skipping localization request for recently cleaned localizer locId resource: req.getResource()
[DEBUG]:IOStatisticsBinding track duration completed
[WARN]:Connection rejected by the host <*>. Will retry later.
[WARN]:"Exact path handle not supported by filesystem "
[WARN]:Problem connecting to server: + nnAddr
[INFO]:Container <*> already scheduled for cleanup, no further processing
[INFO]:Starting <*> StoragePolicySatisfier.
[WARN]:getBlacklistedTrackers - Not implemented yet
[WARN]:Leaving safe mode due to forceExit. This will cause a data loss of <*> byte(s).
[DEBUG]:Removing thread capacity: <*>. Max wait: <*>
[WARN]:History file not found
[INFO]:The filesystem under path 'dir' has numCorrupt CORRUPT files
[DEBUG]:SASL client callback: setting userPassword
[DEBUG]:Initializing SSL Context to channel mode Default_JSSE
[INFO]:Schema creation finished successfully
[DEBUG]:<*>: CACHE HIT: <*>, <*>
[WARN]:Edit log tailer thread exited with an exception
[DEBUG]:Trying to retrieve password for <*>
[ERROR]:Misordered entries in the 'deleted' difflist of directory 'dirFullPath', INodeId=dir.getId(). The full list is 'deletedArray'
[ERROR]:Can't close BufferedReader of command result
[DEBUG]:Closing stream
[WARN]:Credential Provider URI is invalid. <*>
[ERROR]:<*> exceptions occurred loading INodeDirectories
[DEBUG]:Checking access for the acl + toFullPropertyName(queueName, qACL.getAclName()) + for user + ugi.getShortUserName()
[DEBUG]:Using kerberos user: <*>
[INFO]:<*>: number of containers changed from <*> to <*>
[INFO]:Removing state for reservation
[DEBUG]:Adding saslServer wrapped token of size + token.length + as call response.
[DEBUG]:Retrieval of results initiated
[INFO]:Service <*> version <*> upgrade initialized
[DEBUG]:Scheduler shutdown
[ERROR]:The conf property DFS_NAMENODE_SHARED_EDITS_DIR_KEY is not properly set with correct journal node hostnames
[INFO]:Cancel request by <*>
[DEBUG]:No credentials from <*>: <*>
[INFO]:Container update process started.
[WARN]:<*> Current health <*>% has been below health threshold of <*>% for <*> secs (threshold window = <*> secs)
[DEBUG]:Allocated resource updated
[DEBUG]:Cache pool added
[WARN]:Failed to register MBean "<*>": Instance already exists.
[INFO]:Stopping NamenodeHeartbeat service for, NS <*> NN <*> , this.nameserviceId, this.namenodeId
[ERROR]:Error monitoring job :
[INFO]:Collector status updated
[WARN]:Failed to perform reverse lookup: <*>
[WARN]:Unable to create app directory
[DEBUG]:add to mapName map: nameId<*> id: nameId<*>
[INFO]:Starting plan for Node : <*>:<*>, node.getDataNodeName(), node.getDataNodePort()
[DEBUG]:Saving MD5 file
[DEBUG]:Attempting to reacquire classId for container: <*>
[INFO]:File <*> no longer exists, removing it from log list
[DEBUG]:logUtilizationCollection("above-average", aboveAvgUtilized)
[DEBUG]:nodeUpdate: <*> cluster capacity: <*><*>
[DEBUG]:logAuditEvent(false, operationName, src) (from catch block)
[WARN]:Couldn't get container for allocation!
[ERROR]:Call cos sdk failed, retryIndex: <*>, call method: uploadPart, exception: ...
[INFO]:Authorization successful
[WARN]:Request remote address could not be resolved, <*>
[ERROR]:ACLs not supported on at least one file system: , <*>
[INFO]:Strict memory control enabled: <*>
[ERROR]:Error in updating persisted RMDelegationToken with sequence number: sequence_number_value
[INFO]:connection aborted from <*>
[DEBUG]:startupShutdownMessage
[TRACE]:can't get an mmap for <*> of <*> since SKIP_CHECKSUMS was not given, we aren't skipping checksums, and the block is not mlocked.
[INFO]:DynamicInputFormat: Getting splits for job: + jobContext.getJobID()
[DEBUG]:Path <*> for <*> didn't exist. Created a new znode to update the application attempt state., path, appAttemptId
[INFO]:Completed loading all INodeDirectory sub-sections
[WARN]:Unable to add token <*> for cancellation. Will retry..
[DEBUG]:logEdit executed
[DEBUG]:Exception happened during obtaining NM web address from RM.
[DEBUG]:Starting the block retrieval process
[WARN]:Unable to parse the JWT token
[INFO]:<*> is overcommitted (<*>), preempt/kill containers
[ERROR]:Could not auto-create leaf queue due to :
[ERROR]:State store operation failed
[INFO]:End step for saving cache pools
[INFO]:Updating lastWriterEpoch from ...
[DEBUG]:Parent queue = ..., nodeLabel = ..., absCapacity = ..., leafQueueAbsoluteCapacity = ..., deactivatedCapacity = ..., absChildActivatedCapacity = ..., availableCapacity = ...
[ERROR]:At least one commit file could not be read: failing
[INFO]:Initialized root queue + root
[ERROR]:Unknown event type on UpdateContainer: <*>
[INFO]:Local node is already active. No need to failover. Returning success.
[INFO]:Got application report from ASM for, appId=..., appAttemptId=..., clientToAMToken=..., appDiagnostics=..., appMasterHost=..., appQueue=..., appMasterRpcPort=..., appStartTime=..., yarnAppState=..., distributedFinalState=..., appTrackingUrl=..., appUser=...
[DEBUG]:Original tracking url is '<*>'. Redirecting to AHS app page
[DEBUG]:BLOCK* <*> recovery started, primary=<*>
[ERROR]:Missing options: must have host, port and api
[DEBUG]:Failed to decode token identifier
[WARN]:Configuration MB is overriding the configured value
[WARN]:short-circuit read access for the file <*> is disabled for DataNode <*>. reason: <*>
[DEBUG]:Retrieve reduce output field separator
[DEBUG]:AzureBlobFileSystem.append path: <*> bufferSize: <*>
[DEBUG]:*DIR* NameNode.rename: src to dst
[INFO]:Attempting to create address for host without nnServiceName
[INFO]:Killing container
[ERROR]:Unable to save image for + sd.getRoot(), t\n
[DEBUG]:Writing with FileSystemTimelineWriterImpl
[ERROR]:image loading failed at offset <*>
[DEBUG]:DistCpMapper::map(): Received path
[DEBUG]:Container <*> is the first container get launched for application <*>
[INFO]:Component is stable after upgrade or cancel upgrade ]]>
[DEBUG]:Invocation successful on <*>
[WARN]:Unexpected meta-file version for + name + : version in file is + header.getVersion() + but expected version is + VERSION
[INFO]:<*>: received UDP query <*>
[DEBUG]:nthValidToReturn is <*>
[INFO]:Encryption zone created
[WARN]:Block: + blockId + found in invalid directory. Expected directory: + expectedBlockDir + . Actual directory: + actualBlockDir
[ERROR]:Failed to unregister application
[WARN]:The default cluster security is insecure
[ERROR]:<*>: failure to <*> <*> to <*> with source status <*> and destination status <*>
[DEBUG]:printChildQueues - queue: <*> child-queues: <*>
[INFO]:offering IBR service
[INFO]:Adding a new node: + NodeBase.getPath(node)
[INFO]:ViewFs listStatus call invoked
[DEBUG]:Node path detail
[WARN]:Unexpected initial state
[DEBUG]:Failed to load OpenSSL. Falling back to the JSSE default.
[DEBUG]:Mount tree initialization failed with the reason => <*>. Falling back to regular DFS initialization. Please re-initialize the fs after updating mount point.
[INFO]:Storing state for reservation + reservationIdName + from + plan + planName + at path + reservationPath
[INFO]:New instance created for InputFormat
[WARN]:Re-encryption updater thread interrupted. Exiting.
[INFO]:Flushing subClusters from cache and rehydrating from store, most likely on account of RM failover.
[WARN]:Exception, e
[DEBUG]:nodeLookupPolicy used for <*> is <*>
[WARN]:An un-configured port is being requested <*> using default
[INFO]:The supplied Docker client config is + dockerClientConfig
[DEBUG]:responding to call Wrote numBytes bytes.
[DEBUG]:Illegal progress value found, progress is Float.NaN. Progress will be changed to 0
[DEBUG]:New listing status: <*>
[ERROR]:Cannot build PowerShell script
[INFO]:Removing queue: + queueName
[DEBUG]:aggregate statistics\n<*>
[INFO]:Successfully executed refreshAdminAcls
[INFO]:Error while loading service definition from FS: <*>
[ERROR]:File does not exist
[INFO]:Rolling new DB instance for + getName()
[DEBUG]:Number of timeline entities being sent in batch: <*>
[INFO]:State store deleted
[ERROR]:Error stopping proxy web server
[INFO]:Retrying connect to server: + server + . Already tried + curRetries + time(s); maxRetries= + maxRetries
[ERROR]:Unable to make <*> active (<*>). Failing back.
[WARN]:NET_TOPOLOGY_TABLE_MAPPING_FILE_KEY not configured.
[ERROR]:Invalid Node Label(s) from Provider : + errorMsg
[DEBUG]:Thread interrupted
[WARN]:Failed to parse `%s` in `%s`. Ignoring in the %s list.
[WARN]:Got exception when getting Hadoop user name. Set the user name to 'hadoop'.
[INFO]:Starting the schema creation
[INFO]:Nothing to flush
[ERROR]:Error closing store.
[INFO]:Opportunistic container containerId will be queued at the NM.
[WARN]:Could not wait for the thread to join
[ERROR]:Task final state is not FAILED or KILLED: + finalState
[INFO]:log=/log_path
[WARN]:-f is a deprecated option. Ignoring.
[DEBUG]:Application <*> starts to launch a stream (<*>)
[ERROR]:Webapps failed to start. Ignoring for now: <*>
[DEBUG]:IOUtils stream closed
[DEBUG]:selected by alias=<*> token=<*>, service, token
[INFO]:Completed downloading of Hadoop tarball
[INFO]:DistCp job log path: + logPath
[DEBUG]:Performing getDatanodeListForReport
[WARN]:Current bytesPerCRC=<*> doesnâ€™t match next bpc=<*>
[DEBUG]:this + : + caller + : closing fd + fd + at the request of the handler.
[DEBUG]:this: selecting input streams starting at fromTxId (inProgress ok) from among elfs.size() candidate file(s)
[TRACE]:No buffer eligible for eviction
[DEBUG]:writeSpillFileCB.. path:<*>; pos:<*>
[DEBUG]:Removed <*> from exclude protocol list
[DEBUG]:Checking EC block group
[INFO]:Applying default permissions
[INFO]:Service <*> is stopped.
[ERROR]:Cannot find namenode id for local <*>
[INFO]:Sending event + toSend + to + job.getID()
[WARN]:Unable to fetch completion status of workload job. Will proceed to attempt to kill it.
[ERROR]:Failed to reEstablish connection with ZooKeeper
[DEBUG]:Getting NameNode ID
[ERROR]:FSImage.formatEditLogReplayError
[WARN]:Exception when unlocking storage
[ERROR]:Audit event failed due to AccessControlException
[ERROR]:Cannot find znode
[INFO]:Fix Quota src=<*> dst=<*> oldQuota=<*>/<*> newQuota=<*>/<*>, location.getSrc(), location, remoteQuota.getQuota(), remoteQuota.getSpaceQuota(), gQuota.getQuota(), gQuota.getSpaceQuota()
[WARN]:Invalid reservationId: <*> specified for the app: <*>
[WARN]:Exception occurred while compiling report
[INFO]:placing the following ReservationRequest: + contract
[INFO]:Node <*> has <*> blocks yet to process
[ERROR]:Failed to reload allocations file
[INFO]:Cluster Status
[WARN]:<*> is set to <*>. It must be greater than zero. Setting to default of <*>, DFSConfigKeys.DFS_IMAGE_PARALLEL_INODE_THRESHOLD_KEY, inodeThreshold, DFSConfigKeys.DFS_IMAGE_PARALLEL_INODE_THRESHOLD_DEFAULT
[INFO]:Obtained number of VCores used from Linux
[DEBUG]:UNSTABLE write request, send response for offset: OFFSET_PLACEHOLDER
[DEBUG]:User <*> in queue <*> will exceed limit - consumed: <*> limit: <*>
[WARN]:IPC_FCQ_DECAYSCHEDULER_THRESHOLDS_KEY is deprecated. Please use IPC_DECAYSCHEDULER_THRESHOLDS_KEY
[DEBUG]:skipping check for bucket existence
[INFO]:Using <*> samples
[WARN]:rollingMonitorInterval should be more than or equal to <*> seconds. Using <*> seconds instead.
[WARN]:Failed to find pathStr at dir
[DEBUG]:BLOCK* addStoredBlock: <*> on <*> size <*> but it does not belong to any file
[DEBUG]:Scanner skips for unknown file <*>
[DEBUG]:Hadoop logout
[INFO]:Running Distributed Shell with arguments: ...
[WARN]:Failed to report bad + block + from datanode + srcDataNode + to namenode
[DEBUG]:BLOCK* addStoredBlock: <*> is added to <*> (size=<*>)
[INFO]:Removing RMDTMasterKey.
[ERROR]:Jersey retry failed! Message: IOException
[INFO]:Using store: + timelineReaderClassName
[WARN]:Failed to move block:<*> from src:<*> to destin:<*> to satisfy storageType:<*>
[INFO]:rollingUpgrade PREPARE
[ERROR]:Disk Balancer - Unable to find dest volume: <*>
[INFO]:Attempting to clean up remaining running applications.
[DEBUG]:There is a temporary file <*> in <*>
[INFO]:Recovering task for upgrading scenario, moving files from ... to ...
[INFO]:NMClientAsync initialized
[DEBUG]:Thread <*>
[DEBUG]:Startup failed
[WARN]:<*> no longer exists. Skip for scanning.
[WARN]:Treating <*> as an archive even though it was specified as PATTERN
[INFO]:Scan for users on <*>
[INFO]:Recovering persistent memory cache for block <*>, path = <*>, length = <*>
[ERROR]:Cannot get active NN for <*>, State Store unavailable
[WARN]:Not setting collector info as it is null.
[DEBUG]:, org.apache.hadoop.hdfs.util.ByteArrayManager$FixedLengthManager instance
[ERROR]:Error running Client, t
[DEBUG]:Creating Connection
[WARN]:Could not find timestamp portion from path: + serialDirPath.toString() + . Continuing with next
[WARN]:Unable to create the user directory : <*>
[INFO]:starting solve
[ERROR]:<*> Error while submitting the job
[WARN]:Render default scheduler page as scheduler page configured doesn't exist
[INFO]:get valid queue mapping from app name config: <*>, override: <*>
[INFO]:preempting Y running task: Z
[WARN]:Invocation returned exception: ... on <*>
[INFO]:Mount point updated successfully
[INFO]:Null channel should only happen in tests. Do nothing.
[ERROR]:Unable to store token <*>
[INFO]:requested <*> Intel FPGA(s)
[INFO]:Converting the leaf queue
[DEBUG]:AzureNativeFileSystemStore init. Settings=<*>,<*>,<*>,<*>,<*>,<*>,<*>},<*>,<*>,<*>}
[DEBUG]:PUT <*>: <*> bytes
[INFO]:Scheduling block for deletion
[INFO]:Container + containerId + not running, nothing to signal.
[INFO]:Action set for property: MAX_CAPACITY_PERCENTAGE
[ERROR]:Unable to fetch namespace information from any remote NN. Possible NameNodes: <*>
[WARN]:Caching disabled because of slow operation (...)
[ERROR]:FileNotFoundException occurred
[INFO]:<*> received stopped but cancellation pending, event.getContainerId()
[INFO]:Finished write mirror at: $<*>
[DEBUG]:MemoryMappableBlockLoader used for block loading
[INFO]:Job failed as tasks failed. failedMaps:<*> failedReduces:<*> killedMaps:<*> killedReduces: <*>
[DEBUG]:Duplicate: deleting
[DEBUG]:List status for path: <*>
[ERROR]:Unable to disable Nameservice <*>, nsId
[INFO]:<*>: Flex deferred because dependencies not satisfied.
[DEBUG]:Decrease parentLimits <*> for <*> by <*> as childQueue=<*> is blocked
[DEBUG]:Setting max error to <*>
[DEBUG]:rename(<*>, <*>) failure <*>; retry=<*> etag <*>
[WARN]:Ignore the log aggregation status update request for the application: + appId + . The cached log aggregation status is + tracker.getLogAggregationStatus() + .
[DEBUG]:User <*> is not associated with any Secondary Group. Hence it may use the 'default' queue
[INFO]:writeCurrentBufferToService started
[INFO]:Too many applications (...)
[INFO]:Job summary saved to <*>
[ERROR]:Container resource is being increased or undergoing ExecutionType promotion
[INFO]:done
[INFO]:drop FINISH_APPS event to + appID + because container + container.getContainerId() + is recovering
[DEBUG]:<*>: appAttempt:<*> container:<*>, SchedulerEventType.MARK_CONTAINER_FOR_PREEMPTION, aid, cont
[DEBUG]:syncBlock for block <*>, all datanodes don't have the block or their replicas have 0 length. The block can be deleted.
[INFO]:Key creation with KeyProviderExtension successful
[WARN]:Found PlacementProcessor= + p.getClass().getCanonicalName() + defined in + YarnConfiguration.RM_APPLICATION_MASTER_SERVICE_PROCESSORS + , however PlacementProcessor handler should be configured + by using + YarnConfiguration.RM_PLACEMENT_CONSTRAINTS_HANDLER + , this processor will be ignored.
[ERROR]:Error starting ResourceManager
[DEBUG]:Forward seek by reading <*> bytes
[INFO]:Perms after creating + fsStatus.getPermission().toShort() + , Expected: + fsp.toShort()
[ERROR]:Error in updating persisted RMDelegationToken with sequence number: (actual sequence number retrieved from id.getSequenceNumber())
[WARN]:this + ": error shutting down shm: got IOException calling " + "shutdown(SHUT_RDWR)"
[INFO]:CGroupElasticMemoryController currently is supported only on Linux.
[DEBUG]:Updating ClusterNode <*> with queue wait time <*> and wait queue length <*>
[DEBUG]:Creating request URL
[ERROR]:Error running child ...
[DEBUG]:<*>: "<*>" - <*>
[ERROR]:Registry list key " + key + " failed
[DEBUG]:Handling deprecation for (String)item
[DEBUG]:found <*>
[ERROR]:Enable to fetch json representation of namenodes <*>
[INFO]:Compressor initialized
[INFO]:managedParentQueue.getQueuePath() + " : Removed partition " + partition + " from leaf queue state"
[DEBUG]:Could not flush Keystore.. + attempting to reset to previous state !!
[ERROR]:No configuration file + CONFIG_FILE + found in classpath.
[DEBUG]:Inode <*> EZ key version unchanged, skipping re-encryption.
[DEBUG]:DataTransferProtocol using SaslPropertiesResolver, configured QOP <*> = <*>, configured class <*> = <*>
[ERROR]:<*> is at <*> state, upgrade can only be invoked when service is running.
[INFO]:Storage policy satisfier is already in mode:<*>, so ignoring change mode event.
[INFO]:Copied ... to ...
[INFO]:Found resource entry <*>
[INFO]:Spilling map output
[ERROR]:Error when writing start information of container + containerStart.getContainerId(), e
[DEBUG]:Copying markers from <*>
[INFO]:Submit reservation request failed, ue
[DEBUG]:Unable to wrap exception of type <*>, it has no (String) constructor.
[INFO]:Explicitly setting permissions to : ...
[INFO]:Killing applications in queue: <*>
[DEBUG]:Token max lifetime obtained
[WARN]:Fail to save the lease for inode id + id + as the file is not under construction
[WARN]:Failed to execute refreshLogRetentionSettings : Aggregated Log Deletion Service is not started
[DEBUG]:Checking operation (inside try block)
[ERROR]:Application Master is trying to unregister before registering for: appId
[DEBUG]:Access token was invalid when connecting to <*>: <*>
[WARN]:The remote file + remotePath + has changed since it's localized; will not consider it for upload
[ERROR]:Container complete event for unknown container <*>
[INFO]:changing property <*> to <*>
[INFO]:Failover from <*> to <*> successful
[DEBUG]:About to load edits
[INFO]:Application report fetched from RM
[WARN]:Cannot put the domain + domainId + because the timeline service is not enabled
[WARN]:Unable to parse prior job history, aborting recovery
[INFO]:<*> directory already exists
[DEBUG]:Adding jobId to job list cache with fileInfo.getJobIndexInfo()
[ERROR]:<*> Failed to get localization statuses for <*> <*>
[WARN]:Setting password to null since IOException is caught when getting password
[INFO]:Application added - appId: application.getApplicationId() user: application.getUser() leaf-queue: getQueuePath() #user-pending-applications: user.getPendingApplications() #user-active-applications: user.getActiveApplications() #queue-pending-applications: getNumPendingApplications() #queue-active-applications: getNumActiveApplications() #queue-nonrunnable-applications: getNumNonRunnableApps()
[ERROR]:Error storing UAM token as AMRMProxy context entry in NMSS for + attemptId, e
[DEBUG]:Initializing AzureBlobFileSystem for <*>
[ERROR]:Group placement rule failed: No groups returned for user <*>
[INFO]:ContainerManager bound to <*>
[INFO]:Using Replanner: <*> for queue: <*>
[INFO]:Update the SubCluster to <*> for application <*> in the StateStore
[INFO]:Slow ReadProcessor read fields for block XXX took YYYms
[INFO]:Updated timeline service address to + timelineServiceAddress
[INFO]:SLSRunner is waiting for all nodes RUNNING. <*> of <*> NMs initialized.
[INFO]:Using remote NameNode with RPC address: %s
[ERROR]:Read operation failed
[INFO]:Deactivating volumes (clear failure=%b): %s
[ERROR]:Error in removing RMDelegationToken with sequence number: <*>
[ERROR]:Failed to create file:
[INFO]:Set storage policy <*> on <*>
[ERROR]:AM is not holding on a keytab in a secure deployment: service will fail when tokens expire
[INFO]:Containers Allocated: countHere
[INFO]:Resource manager allocation request completed
[TRACE]:StreamMonitor can still have a sleep:...
[DEBUG]:Creating new cgroups blkio handler
[DEBUG]:Failed to upload <*>, try again., <*>
[WARN]:Ignoring attempt to recover existing resource + rsrc
[WARN]:<*>, Token=<*>
[INFO]:Cannot find entity <*>. Will send HTTP 404 in response.
[DEBUG]:DIR* Namesystem.delete: <*> is removed
[DEBUG]:doEditTx() op=<*> txid=<*>
[INFO]:Container is localizing
[INFO]:RMAuditLogger logSuccess
[WARN]:Couldn't setup connection for <*> to <*>
[INFO]:listAllowedUsers=<*>
[DEBUG]:Calling with Connection
[WARN]:checkDiskError got <*> failed volumes - <*>
[DEBUG]:State transition <*> -> <*>
[INFO]:Transactions count is : + checkpointConf.getTxnCount() + , to trigger checkpoint
[INFO]:Registered the SubCluster into the StateStore
[DEBUG]:Unable to create a temporary directory. Fall back to the default system temp directory <*>
[INFO]:Progress updated
[DEBUG]:SecondaryGroupExisting rule: parent rule result: <*>
[INFO]:CGroupElasticMemoryController requires enabling memory CGroups with YarnConfiguration.NM_MEMORY_RESOURCE_ENABLED
[INFO]:Kerberos authentication attempted
[WARN]:couldn't fulfill an immediate putMetrics request in time. Abandoning.
[INFO]:PUT: updateService for app = <*> with data = <*> user = <*>, appName, updateServiceData, ugi
[TRACE]:<*>: can't fethchOrCreate <*> because the cache is closed.
[DEBUG]:<*>: Saving _SUCCESS file to <*>
[DEBUG]:running sort pass
[WARN]:Unable to initialize HBase root as an atomic rename directory.
[DEBUG]:Re-encryption handler throttling because queue size <*> is larger than number of cores <*>
[INFO]:Failed to get response.
[INFO]:Rolling upgrade started
[DEBUG]:While closing stream
[INFO]:Received URL + url + from user + TimelineReaderWebServicesUtils.getUserName(callerUGI)
[INFO]:Failed to find a pending move for + noMoveInterval + ms. Skipping + this
[INFO]:Authorized user
[ERROR]:Intel aocl program <*> to <*> failed!, <*>
[WARN]:notifyOfResponse for policy failed for sub-cluster + subClusterId, e
[INFO]:Container : some_container_id is waiting for free GPU devices.
[DEBUG]:Getting groups for user <*>
[INFO]:RouterRpcServer refresh invoked
[DEBUG]:<*> is a File, qualifiedPath
[INFO]:Application <*> transitioned from <*> to <*>
[INFO]:Service state changed from <*> -> <*>
[DEBUG]:logSync
[INFO]:Entering loadToken method
[ERROR]:Can't handle this event at current state for + this.taskId
[INFO]:HTTP server started on address
[ERROR]:getting attribute + prs + of + oname + threw an exception
[ERROR]:Unable to record log deleter state
[INFO]:Checking invocation result
[INFO]:ClientRMService: <*>
[INFO]:Number of suppressed write-lock reports: ... <*>
[INFO]:Read data interrupted.
[DEBUG]:OOM handler timed out
[DEBUG]:After Scheduling:
[WARN]:Unexpected meta-file version for <*>: version in file is <*> but expected version is <*>
[INFO]:Initializing Plan Follower Policy: org.apache.hadoop.yarn.server.resourcemanager.reservation.CapacitySchedulerPlanFollower
[DEBUG]:Credential provider class is: + className
[DEBUG]:Parsing URL for <*>
[ERROR]:Staging dir does not exist ...
[DEBUG]:LeaseManager is interrupted
[WARN]:Failed to get tc stats
[INFO]:Error while creating Router ClientRM Service for user:, user: + user
[INFO]:Image file <*> of size <*> bytes saved in <*> seconds <*>
[WARN]:Interrupted while trying for connection
[INFO]:Received block X size Y from address
[DEBUG]:Wait to get the mapping for the first time
[DEBUG]:To-release container=<*>, for to a new allocated container, is in final state
[INFO]:Invariant checker enabled. Monitoring every <*> ms, throwOnViolation=<*>
[INFO]:Publication of num splits completed
[INFO]:Updating AMRMToken
[DEBUG]:Requesting session token of duration <*>
[DEBUG]:AzureBlobFileSystem.removeAclEntries path: <*>
[DEBUG]:Beginning of the phase: <*>
[INFO]:truncateBlock: blockFile=<*>, metaFile=<*>, oldlen=<*>, newlen=<*>
[INFO]:Local mount <*> no longer exist, skipping cleaning up the volume
[ERROR]:Duplicate files in input path: , <*>
[WARN]:Invalid blacklist request by application + appAttemptId
[INFO]:Marking <*> for removal
[INFO]:No file for job-history with + jobId + found in cache!
[INFO]:Container <*> was marked as inactive. Returning terminated error
[INFO]:Local service <*> entered state: <*>
[ERROR]:this + : error writing to notificationSockets<*>, e
[ERROR]:Failed to query the status of Container
[ERROR]:Failed to move some block's after <*> retries.
[WARN]:<*>: component count goes to negative (<*><*> = <*>), ignore and reset it to 0.
[DEBUG]:Could not compare file-systems. Unknown host:
[INFO]:Finished cleaning up previous job temporary files
[DEBUG]:write to <*>: <*>, block=<*>, datanode, Op.BLOCK_CHECKSUM, block
[INFO]:stats.toString()
[INFO]:Token verified
[DEBUG]:CIDRNMatcher low = + subnetInfo.getLowAddress() + , high = + subnetInfo.getHighAddress() + , denying client ' + address + ', ' + hostname + '
[DEBUG]:Ignoring client socket close, cause
[INFO]:PortmapHandler unknown rpc procedure= + portmapProc
[DEBUG]:Using failoverProxy to service <*>
[INFO]:EVENTS field filter added
[ERROR]:The conf property DFS_NAMENODE_SHARED_EDITS_DIR_KEY is not set properly with correct journal node uri
[DEBUG]:Some debug message
[WARN]:Failed to parse \" + s + \", which is the index \" + i + \" element in \" + originalString + \"
[DEBUG]:Adding thread capacity: <*>
[DEBUG]:SecondaryGroupExisting rule: parent rule failed
[ERROR]:Cannot add application home subcluster for appId
[INFO]:failure to clean up + tmpOutputPath, ie
[INFO]:Request URL appended
[INFO]:Added volume - location, StorageType: storageType
[ERROR]:Unexpected number: + assignedResources.size() + of assigned numa resources for + containerId + while recovering.
[WARN]:Generating splits for a floating-point index column. Due to the
[INFO]:Loading service definition from + appDefPath
[INFO]:Uploaded + target
[DEBUG]:Checking user <*> for: <*>: <*>
[DEBUG]:Log4j property file exists
[INFO]:Creating temp file: <*>
[WARN]:Application already registered
[WARN]:User '<*>' is not allowed to do placement based on application tag
[INFO]:OutputCommitter set in config ...
[DEBUG]:Creating new mount table entry
[DEBUG]:Cannot schedule check on null volume
[DEBUG]:Replacing service <*> implementation <*>
[DEBUG]:Moving to next queue from queue index <*> to index <*>, number of requests left for current queue: <*>.
[DEBUG]:NFS READDIR fileHandle: <*> cookie: <*> count: <*> client: <*>
[WARN]:releasing 'ready' block: releaseTarget
[INFO]:servlet path: + req.getServletPath()
[DEBUG]:write to <*>: <*>, block=<*>
[WARN]:hostsFilePath + is empty. + REFER_TO_DOC_MSG
[INFO]:Interrupted: aborting upload
[INFO]:Physical memory check enabled: <*>
[ERROR]:Unable to remove resource <*> from state store
[DEBUG]:*BLOCK* NameNode.blockReceivedAndDeleted: from <*> <*> blocks.
[INFO]:File not found, creating parent directories
[INFO]:Loading lib tar from + dependencyLibTarGzip
[DEBUG]:<*> sending #<*> <*>
[DEBUG]:Sending heartbeat with <*> storage reports from service actor: <*>
[WARN]:Not able to initialize queue
[INFO]:Calling getInstance with CipherSuite
[INFO]:Rolling edit logs
[DEBUG]:Exception
[DEBUG]:Committer Statistics
[DEBUG]:Saved MD5 $<*> to $<*>
[DEBUG]:default FileSystem: + jtFs.getUri()
[DEBUG]:Shutting down metrics publisher
[ERROR]:Error: status failed for required journal (journal_and_stream)
[INFO]:PUT: upgrade component <*> for service <*> user = <*>
[ERROR]:Failed to create file:<*> at fallback : <*>
[DEBUG]:Recursive list of all entries under <*>
[INFO]:Scheduling request: <*>
[INFO]:Removing CPU constraints for YARN containers.
[WARN]:Executor did not terminate
[INFO]:Scheduled health check for volume <*>
[ERROR]:Exception when trying to get usable GPU device
[TRACE]:stopMaintenance: Node <*> in <*>, nothing to do.
[WARN]:Placement rule specified a parent queue <*>, but it does not exist.
[INFO]:ApplicationMaster is out of sync with ResourceManager, hence resync and send outstanding requests.
[TRACE]:this + ": freed"
[DEBUG]:Changed current proxy from <*> to <*>
[INFO]:FSAppend operation executed
[DEBUG]:Namespace for <*> (<*>) is <*>
[INFO]:No version file in
[TRACE]:Evicting buffer idx <*>; was used for file <*> offset <*> length <*>
[INFO]:Deactivating volumes (clear failure=true/false): <*>
[INFO]:Checking superuser privilege
[INFO]:At datanode display name, Recovering rbw
[ERROR]:Exception while loading allocation file:
[INFO]:Upgrade container <*>
[ERROR]:Failed to get local host name
[DEBUG]:Cache cleanup handled
[WARN]:Exception when scheduling the event of starting Container + container.getId()
[DEBUG]:Added <*> entries; ignored <*>; hasNext=<*>; hasMoreObjects=<*>
[INFO]:Output directory for <*> and <*> is: <*>
[WARN]:Error registering FSDatasetState MBean
[INFO]:Container was marked as inactive. Returning terminated error
[INFO]:Completing previous rollback for storage directory <*>
[WARN]:Exit code from container executor initialization is : <*>
[WARN]:Skip the timeline entity: <*>, e
[INFO]:Generating block reports
[ERROR]:<*> is at <*> state, flex can not be invoked when service is upgrading.
[INFO]:Nvidia Docker v2 assigned GPU: <*>
[DEBUG]:Fetching application details
[INFO]:Proxy users configuration refreshed
[WARN]:Failed to move block
[INFO]:reduceResourceRequest: <*>
[INFO]:Service initialized
[TRACE]:Validating resource request: <*>
[INFO]:Failed to connect to <*>: <*>
[DEBUG]:Token service set
[INFO]:Authoritative path list is "..."
[INFO]:Path access checked successfully
[INFO]:NodeManager started on
[ERROR]:Interrupted; exiting from thread.
[DEBUG]:Deleting <*>
[INFO]:User <*> does not have access to any queue.
[DEBUG]:Display entity per user filter enabled
[INFO]:Interrupted. Stopping the WebImageViewer.
[ERROR]:Error starting Registry DNS Server, t
[DEBUG]:Buffer dir: <*> does not exists. create it first.
[DEBUG]:No pending container in this cycle
[DEBUG]:Buffered pread option processed
[ERROR]:Unable to create proxy to the ResourceManager
[DEBUG]:RMAppManager processing event for applicationId of type APP_COMPLETED
[INFO]:Storage directory with location <*> is not formatted for namespace <*>. Formatting...
[INFO]:Very low remaining capacity on <*> event queue: <*>
[TRACE]:Fetching token provider
[INFO]:Stopping service <*>, with appId = <*>
[INFO]:Skipping download of remote edit log + log + since it already is stored locally at + f
[WARN]:Failed to reset renewer
[INFO]:formatMessage(extraSleepTime, gcTimesAfterSleep, gcTimesBeforeSleep)
[INFO]:Updating info for attempt: <*> at: <*>
[WARN]:destroy ticket failed
[INFO]:Ignoring completed status of <*>; unknown container(probably launched by previous attempt)
[WARN]:"<*>: Got exception while serving <*> to <*>: ", dnR, block, remoteAddress, ioe
[DEBUG]:<*>, Requesting next <*> objects under <*>
[INFO]:key ===> value
[WARN]:Unable to initialize MapOutputCollector + clazz.getName()
[WARN]:Interrupted while waiting for CacheReplicationMonitor rescan
[DEBUG]:error prefetching block <*>
[WARN]:<*> active upload(s) in progress under <*>
[DEBUG]:Initializing Generic Keys
[DEBUG]:Directory markers will be deleted
[WARN]:Unable to execute ...
[DEBUG]:Federation Enabled: true/false // conditional depending on isEnabled
[INFO]:token validation failed - sending redirect to: + loginURL
[DEBUG]:Could not locate file <*>
[INFO]:onIncreaseContainerResourceError: <*>, <*>
[WARN]:Finish information is missing for application + appId
[DEBUG]:Completed block movement. <*>
[INFO]:Start request for containerIdStr by user remoteUser with resource containerResource
[WARN]:Failed to get groups for user <*> (attempt=<*>/<*>) using <*>. Exception:
[ERROR]:Interrupted while canceling token for + fs.getUri() + filesystem
[INFO]:Slept for $<*>
[INFO]:Compiling report for volume: ProvidedVolumeImpl; bpid: someBpid
[TRACE]:<*>: returning new remote block reader using UNIX domain socket on <*>
[WARN]:Request key should not be null at level level.
[INFO]:Fallback to the old authorization provider API because the expected method is not found.
[DEBUG]:completeMultipartUploadResult.getETag()
[TRACE]:Exiting createKey Method.
[DEBUG]:Configuring entity info
[DEBUG]:Reservation Exceeds Allowed number of nodes: app_id= + getApplicationId() + existingReservations= + existingReservations + totalAvailableNodes= + totalAvailNodes + reservableNodesRatio= + df.format(scheduler.getReservableNodesRatio()) + numAllowedReservations= + numAllowedReservations
[INFO]:Max virtual cores capabililty of resources in this cluster <*>
[INFO]:Got response from RM for container ask, allocatedCnt= + allocatedContainers.size()
[INFO]:Skipping blockpool <*>
[DEBUG]:Setting heartbeatinterval to: <*> node: <*> nodeUtil: <*> clusterUtil: <*>
[DEBUG]:Cannot find to-be-moved container's application=<*>
[INFO]:Completed deletion of files from <*>
[ERROR]:Returning, interrupted : <*>
[DEBUG]:<*>: Scheduling suspect block <*> for rescanning.
[INFO]:Probe for isCommitJobRepeatable(<*>): returning false
[INFO]:Expanded source <*>
[WARN]:Unknown Container. Container might have completed, please go back to the previous page and retry
[DEBUG]:Block with id <*>, pool <*> already exists in the FsDatasetCache with state <*>
[ERROR]:Task final state is not FAILED or KILLED:
[INFO]:RMAuditLogger: User <*> successfully executed removeFromClusterNodeLabels
[DEBUG]:Committing single commit <*>
[ERROR]:Forcing CleanerThreadPool to shutdown!
[WARN]:Could not lower thread count to <*> from <*>. Too busy.
[INFO]:Sorry, <*> not found.
[INFO]:Real User = <*>
[INFO]:Failed to submit application to parent-queue: + parent.getQueuePath(), ace
[INFO]:TaskInfo loaded
[INFO]:Retrieving block access token.
[DEBUG]:<*>: Job Summary <*>
[ERROR]:Error getting logs for <*>
[INFO]:At root level only " queue " tags are allowed
[INFO]:bpos.toString() + ": scheduling a full block report " + "to namenode: " + nnAddr + "."
[ERROR]:Parent directory <*> of <*> tarball location <*> does not have world read/execute permission
[DEBUG]:Added priority=
[INFO]:Initializing cache loader: org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.PmemMappableBlockLoader
[INFO]:Finished create editlog file at: $<*>
[DEBUG]:Creating compression for FS image
[WARN]:No KEY found for persisted identifier + identifier.toString()
[WARN]:Can not set up custom log4j properties. +
[DEBUG]:Try allocating <*> <*>, requestedDeviceCount, resourceName
[INFO]:Executing 'hadoop archives'
[WARN]:Error cleaning up <*>: <*>
[DEBUG]:*BLOCK* NameNode.blockReport: from <*>, reports.length=<*>
[WARN]:Block + blockId + + NONEXISTENT_STATUS
[DEBUG]:STRING_TABLE writing header: <*>
[DEBUG]:BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block <*> from priority queue <*>
[INFO]:Starting SyncJournal daemon for journal + jid
[DEBUG]:Start datablock<*> upload, index
[ERROR]:KeyProvider URI string is invalid <*>!!
[DEBUG]:getQueuePath() + used= + queueUsage.getUsed() + numContainers= + numContainers + user= + userName + user-resources= + user.getUsed()
[ERROR]:Event <*> not handled, because previousFailedAttempt is null
[INFO]:Adding cache directive info
[INFO]:Formatting journal <*> with nsid: <*>
[WARN]:Heartbeat scaling factors must be â‰¥ 0 SpeedupFactor: <*> SlowdownFactor: <*>. Using Defaults
[ERROR]:S3Guard is no longer needed/supported, yet <*> is configured to use DynamoDB as the S3Guard metadata store. This is no longer needed or supported. Origin of setting is <*>
[WARN]:Edits tailer failed to find any streams. Will try again later.
[DEBUG]:Removing reservationallocation <*> for plan <*>
[ERROR]:Got RuntimeException at position + inputStream.getPosition()
[INFO]:found resource name at url
[DEBUG]:Cancelling futures
[DEBUG]:Setting Container ID: <*>
[INFO]:Allow All Origins: + allowAllOrigins
[DEBUG]:Sending client SASL negotiation
[ERROR]:Invalid eventtype . Ignoring!
[DEBUG]:Reading cluster info
[WARN]:Invocation returned exception on <*>; <*> failure(s) so far
[DEBUG]:MSIToken: token renewing. Time elapsed since last token fetch: <*> milli seconds
[INFO]:<*> received started but cancellation pending
[DEBUG]:Datanode <*> is using BR lease id 0x0 to bypass rate-limiting.
[INFO]:Requesting Container update : container=<*>, updateType=<*>, targetCapability=<*>, targetExecType=<*>
[INFO]:Total input files to process : ...
[INFO]:Queue activity recorded
[ERROR]:Error closing connection
[INFO]:Connects to Namenode <*>
[TRACE]:Checking file <*>, modification time is <*>, last reload time is <*>
[DEBUG]:Loading section STRING_TABLE length: <*>
[ERROR]:Failed to fetch user credentials from application:
[DEBUG]:<*>: saving block iterator <*> after <*> ms., this, curBlockIter, saveDelta
[INFO]:org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache: closing
[DEBUG]:In processSummationMajorCompaction, will drop cells older than <*> CurrentColumnCells size=<*>
[WARN]:When aborting <*> stream after failing to close it for <*>
[ERROR]:Lost job
[INFO]:Queue + q.getName() + not equal to + newq.getName()
[WARN]:Unexpected item in trash: + dir + . Ignoring.
[DEBUG]:Querying Collection : <*> , with query <*>
[DEBUG]:Upstream service is down, skipping the sps work.
[ERROR]:Unable to remove the global cleaner pid file! The file may need to be removed manually.
[DEBUG]:Resetting scheduling opportunities
[ERROR]:Failed to abort file: ... with inode: ...
[INFO]:Application <*> from user: <*> activated in queue: <*>
[ERROR]:Exception while checking heartbeat
[ERROR]:Cannot create data directory <*>
[WARN]:Manifest file + manifest + is not a file
[DEBUG]:BLOCK* invalidateBlocks: postponing invalidation of <*> on <*> because <*> replica(s) are located on nodes with potentially out-of-date block reports
[DEBUG]:Got the information about the specified SubCluster <*>
[INFO]:token.toString()
[WARN]:Failed to read cgroup tasks file.
[INFO]:newState + has added children in refresh
[WARN]:Key key is already mapped to file initialMappedEntry; file fileName will not be added
[DEBUG]:Probe datanode: <*> result: <*>, type: <*>
[ERROR]:App: <*> can't handle this event at current state
[INFO]:Setting job diagnostics to <*>
[WARN]:Could not rename <*> to <*>
[ERROR]:Failed to parse device major number from stat output
[INFO]:Key creation with KMSClientProvider successful
[ERROR]:Error rebuilding local cache for zkDelegationTokens
[INFO]:<*> is missing. Not setting ip and hostname
[WARN]:Missing ApplicationHomeSubCluster Info. Please try again by specifying an ApplicationHomeSubCluster information.
[DEBUG]:Partitioning the keys to delete as it is more than page size. Number of keys: <*>, Page size: <*>
[DEBUG]:Failed to get the number of live decommissioned datanodes
[ERROR]:Unable to enable Nameservice <*>
[DEBUG]:The updated demand for + getName() + is + demand + ; the max is + getMaxShare()
[INFO]:Web app + name + started at + httpServer.getConnectorAddress(0).getPort()
[INFO]:info
[INFO]:Unable to find ' + resourceFile + '.
[DEBUG]:Using connector : <*>
[ERROR]:Invalid Port - int required
[INFO]:Completed reading history information of all containers of application attempt <*>
[DEBUG]:Watchdog interrupted
[INFO]:Closing all peers.
[DEBUG]:After dump, nonSequentialWriteInMemory == <*>
[ERROR]:NameNode process will exit now... The saved FsImage <*> is potentially corrupted.
[DEBUG]:Failed to create raw erasure decoder , fallback to next codec if possible
[INFO]:Reservation creation failed
[WARN]:Max job attempts set to 1 since encrypted intermediate data spill is enabled
[INFO]:Missing command line arguments
[ERROR]:Cannot get apps: <*>
[INFO]:Action set for property: MAPPED_DYNAMIC_QUEUE
[WARN]:Unable to drop cache on file close
[INFO]:Starting up re-encrypt thread with interval=<*> millisecond.
[WARN]:Could not resolve record for component <*>: <*>
[INFO]:Processing the event JOB_COMMIT
[INFO]:"Stopping " + Thread.currentThread().getName()
[INFO]:Loaded + numKeys + master keys and + numTokens + tokens from leveldb, and latest sequence number is + state.getLatestSequenceNumber()
[ERROR]:Registry write key <*> failed
[ERROR]:Failed to start journalnode.
[INFO]:Unchecked exception is thrown from onStopContainerError for Container event.getContainerId()
[INFO]:authorizerClass.getName() + " is instantiated."
[DEBUG]:Exception closing executor service
[INFO]:Adding <*>
[INFO]:Status reporter thread started.
[INFO]:Submission completed of zone <*> for re-encryption.
[TRACE]:ReadBufferWorker completed read file <*> for offset <*> outcome <*> bytes <*>
[DEBUG]:BLOCK* findAndMarkBlockAsCorrupt: <*> not found on <*>
[WARN]:Invalid argument: + arg
[ERROR]:Statistics Error while waiting for other threads to get ready
[ERROR]:Cannot add more than <*> connections at the same time
[INFO]:Added profile 'profileName' with resources: resource
[WARN]:Environment variable <*> is deprecated and overriding property <*>, please set the property in <*> instead.
[INFO]:NMAuditLogger: Success
[DEBUG]:DFSClient flush(): bytesCurBlock=<*>, lastFlushOffset=<*>, createNewBlock=<*>
[DEBUG]:Initializing DelegationTokenManager for <*>
[INFO]:All async disk service threads have been shut down
[DEBUG]:Map task identified
[INFO]:Reset exclude protocol list: <*>
[DEBUG]:Becoming active for <*>
[DEBUG]:Thread interrupted while performing token counter increment
[DEBUG]:File deleted in BlockUploadData close: <*>
[DEBUG]:Groups:
[INFO]:Temporary redirect with URI
[INFO]:<*> version <*> : Creating dir on hdfs: <*>
[INFO]:Bad conf file: top-level element not <*>
[INFO]:movedContainer container=<*> containerState=<*> resource=<*> queueMoveIn=<*> usedCapacity=<*> absoluteUsedCapacity=<*> used=<*> cluster=<*>
[INFO]:Transition initiated
[INFO]:Creating new traffic control bandwidth handler.
[TRACE]:Incrementing counter <*> by <*> with final value <*>
[DEBUG]:Missing ip list file : + fileName
[INFO]:<*>: Starting merge with <*> segments, while ignoring <*> segments
[ERROR]:There is no reducer, no need to use native output collector
[INFO]:sigma=...
[INFO]:ACLs checked
[TRACE]:<*>: Call -> <*>: <*>: <*>
[INFO]:Completing previous checkpoint for storage directory <*>
[INFO]:File length retrieved
[ERROR]:An error occurred while attempting to read from
[INFO]:Limit parameter added
[INFO]:ConnectionException caught by TimelineClientConnectionRetry, will keep retrying. Message: <*>
[TRACE]:<*>: disabling scanning on block pool <*>, this, bpid
[DEBUG]:Checked files in directory
[ERROR]:Unable to deserialize list results
[ERROR]:Kerberos.getDefaultRealm() failed
[WARN]:Unexpected: procfs stat file is not in the expected format for process with pid
[INFO]:No eligible applications to process
[DEBUG]:Size of protoMap for <*> = <*>
[INFO]:systemPropsToLog
[WARN]:<*> nodes are decommissioning but only <*> nodes will be tracked at a time. <*> nodes are currently queued waiting to be decommissioned.
[DEBUG]:<*> info for attempt: <*> at: <*>, operation, appAttemptId, path
[DEBUG]:Added LocalResource for localization:
[WARN]:Failed to call blockReceivedAndDeleted: <*>, nnId: <*> + , duration(ms): <*>, Arrays.toString(reports), nnRpcLatencySuffix, monotonicNow() - startTime
[ERROR]:Failed to gracefully shutdown gRPC communication channel in 5 seconds
[WARN]:NameNode safe mode check failed: Failed to finalize rolling upgrade
[ERROR]:BUG: Found lastValidNode <*> but not nth valid node. parentNode=<*>, excludedScopeNode=<*>, excludedNodes=<*>, totalInScopeNodes=<*>, availableNodes=<*>, nthValidToReturn=<*>.
[INFO]:Loaded <*> inode references
[DEBUG]:close <*> , key
[ERROR]:Delete key: <*> occurs an exception: <*>.
[DEBUG]:Adding zone <*> for re-encryption status
[DEBUG]:count=count, return byte<*>
[TRACE]:storageTypes=<*>, storageTypes
[INFO]:<*>: Reset container failure count from <*> to 0.
[INFO]:Placed application with ID <*> in queue: <*>, original submission queue was: <*>
[ERROR]:Unable to remove token <*>, <*>
[DEBUG]:Reading input file
[DEBUG]:Emitting metric <*>, type <*>, value <*>, slope <*>, from hostname <*>
[INFO]:Processed URL (Took x ms.)
[WARN]:Invalid deSelects string + literals.trim()
[DEBUG]:logUtilizationCollection("over-utilized", overUtilized)
[DEBUG]:Checking TFile Data Index
[INFO]:Java runtime version : <*>
[DEBUG]:Localizing <*> for container <*>
[ERROR]:Error launching job , Invalid job conf :
[DEBUG]:Reducer output key fields set
[DEBUG]:Proxy user Authentication successful
[WARN]:Failed to use snapshot diff for distcp
[WARN]:There are no sufficient resources to start guaranteed <*> at the moment. Opportunistic containers are in the process of being killed to make room.
[DEBUG]:Empty rule set defined, ignoring update
[INFO]:Decided to move X bytes from sourceName to targetName
[INFO]:yarn docker env var has been set <*>
[DEBUG]:scan logs for <*> in <*>
[ERROR]:Ignoring invalid eventtype
[WARN]:Caught exception when adding...
[INFO]:Application stop event received for stopping AppId: + event.getApplicationID().toString()
[WARN]:Credentials requested when closed
[INFO]:Native Bzip2 library not loaded; using default library name
[DEBUG]:Proxy allocation request sent
[DEBUG]:The first job has a submit time of <*>
[WARN]:Random directory component did not match. Deleting localized path only
[WARN]:The identifier for the State Store connection is not set
[INFO]:Parsed new queues
[INFO]:Ignored <*> because it is a directory
[DEBUG]:Before setting ACLs\n
[ERROR]:Not all labels being added contained by known label...
[DEBUG]:Executing operation with no result
[DEBUG]:Counting resource from childQueueName Resource; Total resource demand for FSParentQueueName now UpdatedDemand
[WARN]:Linux Container Executor is not configured for the NodeManager. To fully enable GPU feature on the node also set YarnConfiguration.NM_CONTAINER_EXECUTOR properly.
[DEBUG]:Unable to perform a zero-copy read from offset <*> of <*>; <*> bytes left in block. blockPos=<*>; curPos=<*>; curEnd=<*>
[DEBUG]:Use <*> authentication for protocol <*>
[DEBUG]:saveNameSystemSection completed
[DEBUG]:Operation retried debug log
[WARN]:Took <*> ms to process <*> commands from NN, processCommandsMs, cmds.length
[WARN]:Environment variable <*> is deprecated and overriding property <*>', please set the property in <*> instead.
[DEBUG]:Log an audit event
[WARN]:Failed to delete meta file
[WARN]:Unable to finish rolling edits in %d ms
[DEBUG]:DatanodeAdminMonitorV2 is running.
[WARN]:The target has been modified since snapshot ...
[DEBUG]:Found 'userid' '<*>' in application tag
[ERROR]:<*> must be greater than zero. Defaulting to <*>
[INFO]:MRAppMaster uberizing job ...
[ERROR]:Task: taskAttemptID - failed due to FSError: message
[DEBUG]:DistCpMapper::map(): Received <*>, <*>
[WARN]:Interrupted partUpload
[DEBUG]:Constructing ProcessTree for: PID = pId ContainerId = containerId
[DEBUG]:Got access token error in response to OP_BLOCK_CHECKSUM for file <*> for block <*> from datanode <*>. Will retry the block once.
[INFO]:MRConfig.LOCAL_DIR for uber task
[INFO]:createNameNode <*>
[DEBUG]:Succesfully shutdown executor service
[INFO]:A policy with same schema and cell size already exists
[DEBUG]:tokens aren't supported for this protocol or user doesn't have one
[INFO]:Successfully saved namespace for preparing rolling upgrade.
[ERROR]:Unable to kill the paused container <*>
[INFO]:File doesn't exist. Skip deleting the file + dstPath
[DEBUG]:Total # of splits generated by getSplits: <*>, TimeTaken: <*>
[INFO]:Container <*> is already stopped or failed
[DEBUG]:This node <*> doesn't have sufficient available or preemptible resource for minimum allocation
[INFO]:App: + appId + successfully moved from + sourceQueueName + to: + destQueueName
[WARN]:Setting default time zone: GMT
[INFO]:<*>: remove <*> outstanding container requests for allocateId <*>
[INFO]:session.getRemoteAddress().getHostString() + " closed, status: " + status
[ERROR]:Could not find uri with key <*> to create a keyProvider !!
[INFO]:Nonpositive count in invalid READDIR request: <*>
[DEBUG]:Uncaching of <*> completed. usedBytes = <*>
[WARN]:Failed to fetch application report from ATS v2, ex
[INFO]:Group Ids:
[ERROR]:Cannot access method <*> with types <*> from <*>
[INFO]:NodeHealthyStatus
[INFO]:Successfully created HBase schema.
[ERROR]:error looking up the name of group ... : ...
[DEBUG]:logAuditEvent
[DEBUG]:Getting Mapper class
[ERROR]:DFSZKFailOverController exiting due to earlier exception: t
[INFO]:Collection by MapOutputBuffer started
[INFO]:aggregated log deletion finished.
[DEBUG]:addResourceRequest: applicationId= priority= priority.getPriority() resourceName= resourceName numContainers= resourceRequestInfo.remoteRequest.getNumContainers() #asks= ask.size()
[DEBUG]:pMemCheck <*>, this.containersAllocation.getPhysicalMemory(), (pMemBytes >> 20), (getContainersMonitor().getPmemAllocatedForContainers() >> 20)
[WARN]:Skipping file; it is a symlink with a nonexistent target: <*>
[ERROR]:Failed to setup application log directory for <*>
[DEBUG]:Finished reading range <*> from path <*>
[INFO]:Exception thrown in thread join: ...
[INFO]:Removing zone <*> from re-encryption.
[WARN]:DEPRECATED: Please use 'replacementCommand' instead.
[INFO]:# applications = <*>, # total tasks = <*>, average # tasks per application = <*>
[DEBUG]:Using local interface <*>
[DEBUG]:Exception in getKey.
[WARN]:Invalid hostname + hostStr + in hosts file
[ERROR]:Failed to resolve sub-cluster for node <*>, skipping this node
[INFO]:Remove the node out from dead node list: <*>.
[TRACE]:<*> exiting because of InterruptedException.
[ERROR]:No more jobs to process in the trace with 'starts-after' set to <*> ms.
[INFO]:Dispatcher started
[DEBUG]:Could not reset Keystore to previous state
[DEBUG]:Storing RMDelegationKey_<*>
[INFO]:Scheduling $<*> eviction for $<*>
[DEBUG]:Opening proxy : <*>
[DEBUG]:requested offset=<*> and current filesize=<*>
[WARN]:Error flushing metrics to Graphite
[DEBUG]:null prefix was specified; returning all columns
[DEBUG]:Block with id <*>, pool <*> does not need to be uncached, because it is not currently in the mappableBlockMap.
[INFO]:Recover failed close b
[WARN]:The SchedulingRequest has requested more than 1 allocation, but only 1 will be attempted !!
[ERROR]:getTaskLogFileDetail threw an exception <*>
[ERROR]:Failed writing AMRMToken to registry for subcluster subClusterId, e
[DEBUG]:selected by service=<*> token=<*>
[DEBUG]:Creating app attempt entity
[TRACE]:Exception interrupting DataXceiverServer
[INFO]:Delaying safemode exit for <*> milliseconds...
[WARN]:NN safe mode check
[INFO]:Got allocated containers ...
[DEBUG]:Retrying connect to Remote service:<*> Already tried <*> time(s); retry policy is <*>, delay <*>ms.
[DEBUG]:closeAllForUGI UGI: <*>
[INFO]:Asking remote to cede its active state for timeout ms
[INFO]:Forwarding request to web application
[DEBUG]:Recording source-path: <*> for copy.
[DEBUG]:Activated leaf queues : <*>
[DEBUG]:Parsing <*> at offset <*>
[DEBUG]:default FileSystem: <*>
[INFO]:No valid ADL SDK timeout configured: using SDK default.
[TRACE]:Removed block <*> from PENDING_CACHED list.
[DEBUG]:Rejecting appliance of allocation due to existing pending allocation request for schedulerContainer
[INFO]:Loading service definition from <*>
[ERROR]:Retrieving key <*> with byteRangeStart <*> occurs an CosServiceException: <*>.
[WARN]:Log dir <*> is in an unsupported file system
[INFO]:logAuditEvent(true, operationName, src, null, auditStat)
[INFO]:Updated timeline delegation token
[ERROR]:Re-throwing API exception, no more retries
[ERROR]:failover: incorrect arguments
[INFO]:ResourceCalculatorPlugin is unavailable on this system. <*> is disabled.
[INFO]:Failed to submit application to parent-queue: + getParent().getQueuePath(), ace
[DEBUG]:DataNode$DataTransfer: close-ack=<*>
[INFO]:Fetched new range of seq num, from <*> to <*>
[INFO]:Moved <*> to <*>, appDirPath, doneAppPath
[WARN]:Following requests of <*> exhausted all retry attempts trying to schedule on placed node: <*>
[DEBUG]:Drop the response. Current retryCount == <*>
[INFO]:<*> TaskAttempt Transitioned from <*> to <*>
[WARN]:WARN_INCORRECT_RANGE.warn("Expected range to contain 0 or 2 elements." + " Got <*> elements. Ignoring.", rangeValue.length)
[WARN]:encountered an exception
[DEBUG]:YarnClient created
[DEBUG]:GETATTR for fileHandle: <*> client: <*>
[DEBUG]:<*>: failed to get ShortCircuitReplica. Cannot construct BlockReaderLocal via <*>, this, pathInfo.getPath()
[ERROR]:Fail to stop service: <*>
[DEBUG]:KeyStore initialized anew successfully !!
[WARN]:elapsed time:<*> is greater than threshold:<*>, mtime:<*> in file:<*>, will proceed with Du for space computation calculation
[INFO]:couldn't find application + appID + while processing + FINISH_APPS event. The ResourceManager allocated resources for this application to the NodeManager but no active containers were found to process.
[DEBUG]:Block locations retrieved
[DEBUG]:Aborting multipart upload <*> to <*> initiated by <*> on <*>
[WARN]:Error while decoding <*>, <*>
[WARN]:Encountered exception setting Rollback Image
[DEBUG]:Given mode: <*> is invalid
[DEBUG]:Setting <*> to <*>
[DEBUG]:Skipping scheduling since node <*> is reserved by application <*>
[DEBUG]:Using match all for 'host' and READ_ONLY
[INFO]:Source file + src.toString() + not found, but target + file + target.toString() + already exists. Move already + happened.
[INFO]:Accepted application <*> from user: <*>, currently num of applications: <*>
[WARN]:Ignoring blacklisted job: + id
[DEBUG]:SASL server GSSAPI callback: setting canonicalized client ID: <*>
[DEBUG]:Schedule probe datanode for probe type: <*>.
[TRACE]:DFSClient readNextPacket got header <*>
[INFO]:Done recovering task ...
[DEBUG]:Auditor class is <*>
[WARN]:Shutdown has been called, but periodic scanner not started
[DEBUG]:No leaf znode exists. Removing parent node <*>, parentZnode
[WARN]:Task attempt $<*> is done from TaskUmbilicalProtocol's point of view. However, it stays in finishing state for too long
[INFO]:Stopping AMRMProxyService
[DEBUG]:RenameSnapshotOp created
[DEBUG]:Task attempt registered to finishing monitor
[INFO]:Creating symlink
[WARN]:Inconsistent number of corrupt replicas for <*> + blockMap has <*> but corrupt replicas map has <*>
[ERROR]:ReplicaCachingGetSpaceUsed refresh error
[DEBUG]:NFS READDIRPLUS fileHandle: <*> cookie: <*> dirCount: <*> + maxCount: <*> client: <*>
[INFO]:Heartbeat from attemptId with responseId request.getResponseId() when we are expecting lastAllocateResponse.getResponseId()
[INFO]:Following commands registered for host<*> : <*>
[TRACE]:submit readahead: + req
[INFO]:Setting keystore location to
[WARN]:Unable to submit the application <*> to SubCluster <*>
[INFO]:Not enough replicas was chosen. Reason: <*>, reasonMap
[DEBUG]:Region for endpoint <*>, URI <*> is determined as <*>
[INFO]:Preemption monitor:org.apache.hadoop.yarn.server.resourcemanager.monitor.capacity.ProportionalCapacityPreemptionPolicy
[WARN]:fetchBlockByteRange(). Got a checksum exception for <*> at <*>:<*> from <*>
[WARN]:this + : mmap error, e
[INFO]:Retrieved job using jobID
[INFO]:Number of warnings: <*>
[INFO]:Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
[WARN]:Script <*> does not exist, falling back to /sbin/DevicePluginScript/
[INFO]:Diagnostics report from taskAttempt.attemptId: diagEvent.getDiagnosticInfo()
[INFO]:VM type = <*>-bit
[DEBUG]:Adding resource type - name = VCORES, units = ResourceInformation.VCORES.getUnits(), type = ResourceTypes.COUNTABLE
[WARN]:Can not load log meta from the log file:
[INFO]:Relaying an out of band ack of type
[INFO]:Ignoring failure to deleteOnExit for path <*>
[DEBUG]:block=<*>, getBytesPerCRC=<*>, crcPerBlock=<*>, compositeCrc=<*>
[INFO]:Already in election. Not re-connecting.
[INFO]:Sync log completed
[DEBUG]:Scheduler started
[INFO]:publishing volumes
[INFO]:Submission policy is ...
[WARN]:Ignore the log aggregation status update request for the application: + appId + . The request log aggregation status update is older than the cached log aggregation status.
[INFO]:Unknown child node with name: <*>
[DEBUG]:failed to find <*> on the classpath
[DEBUG]:Configuring job jar
[INFO]:Web server is in development mode. Resources will be read from the source tree.
[INFO]:rmId + " relinquish leadership"
[INFO]:Create new dump directory <*>
[DEBUG]:Trying to schedule on node: <*>, available: <*>
[INFO]:Recovering previously launched container
[DEBUG]:Cannot find active collector while publishing entity
[DEBUG]:Aborting stream <*>
[INFO]:Could not find a node matching given resourceName RESOURCE_NAME
[ERROR]:Input error:, e
[INFO]:<*> printed
[DEBUG]:Token not set, looking for delegation token. Creds:<*>, size:<*>
[INFO]:Node <*> isn't healthy. It needs to replicate <*> more blocks. <*> is still in progress.
[INFO]:prefix + metrics system stopped (again)
[ERROR]:Unexpected event for REDUCE task + event.getType()
[ERROR]:Error opening job jar
[INFO]:Successfully transitioned <*> to standby state
[INFO]:Token added
[WARN]:Queue <*> cannot handle resource request because it has zero available amount of resource for a requested resource type, so the resource request is ignored! Requested resources: <*>, maximum queue resources: <*>
[DEBUG]:Received new AMRMToken
[DEBUG]:DIR* NameSystem.createSymlink: target= + target + link= + link
[INFO]:Syncing Journal...
[DEBUG]:Skip downloading resource: <*> since it is locked by other threads
[WARN]:Couldn't read <*>; can't determine disk scheduler type
[INFO]:Sent total: ...
[INFO]:Expecting ... records each with a length of ... bytes in the split with an effective size of ... bytes
[INFO]:Application for Container with id doesn't exist in RM or Timeline Server.
[ERROR]:Error while processing REST request, e
[DEBUG]:classId -> bytes sent <*>
[INFO]:Not allocating more containers as we have reached max allocations per AM heartbeat
[INFO]:Successfully transitioned localTarget to active state
[DEBUG]:Assigned container + container.getId() + of capacity + container.getResource() + on host + getRMNode().getNodeAddress(), which has + getNumContainers() containers, + getAllocatedResource() used and + getUnallocatedResource() available after allocation
[DEBUG]:Queue Name:queueName, partition:partition
[ERROR]:Invalid data in ZK: + StringUtils.byteToHexString(data)
[INFO]:Reading NUMA topology using 'numactl --hardware' command.
[ERROR]:Callback handler does not implement container re-initialize callback methods
[TRACE]:Initializing AbfsClient for <*>
[DEBUG]:Before Scheduling:
[ERROR]:...
[WARN]:Interrupted while joining on: <*>
[DEBUG]:Filesystem <*> created while awaiting semaphore
[INFO]:Can perform rollback for shared edit log.
[INFO]:Renamed root path + FSDirectory.DOT_RESERVED_STRING + to + renameString
[INFO]:Parent Cgroups directory <*> does not exist. Skipping deletion
[INFO]:<*>: Deleting job directory <*>, getName(), baseDir
[DEBUG]:needsContainers: app.#re-reserve= + application.getReReservations(schedulerKey) + reserved= + reservedContainers + nodeFactor= + nodeFactor + minAllocFactor= + application.getCSLeafQueue().getMinimumAllocationFactor() + starvation= + starvation
[DEBUG]:logEdit operation
[WARN]:Caught exception:
[DEBUG]:AM launch command: <*>
[DEBUG]:BLOCK* Removing <*> from neededReconstruction as it has enough replicas
[INFO]:Removed ProcessTree with root PID
[WARN]:Could not update resources on continer update of <*>, <*>
[INFO]:Connected to InMemoryAliasMap at <*>
[INFO]:STATE* Safe mode is already OFF
[DEBUG]:*DIR* NameNode.truncate: src to newLength
[DEBUG]:Outputted <*> INodes.
[WARN]:Failed to delete tc rule for classId: + classId
[INFO]:usercache path : <*>
[DEBUG]:Mapped HA service delegation token for logical URI + haUri + to namenode + singleNNAddr
[ERROR]:Error starting PerNodeTimelineCollectorServer
[DEBUG]:Assigning container <*> to reduce
[INFO]:Registry System ACLs:, RegistrySecurity.aclsToString(registrySecurity.getSystemACLs())
[DEBUG]:gc window of metric: <*> userName: <*>
[WARN]:Unexpected EOF reading index at entry #count. Ignoring.
[DEBUG]:from environment variable: <*>
[DEBUG]:Task AttemptID: <*> task timeout set: <*>s, taskTimedOut: <*>; task stuck timeout set: <*>s, taskStuck: <*>
[INFO]:Web server started
[DEBUG]:NFS FSSTAT fileHandle: <*> client: <*>
[INFO]:Recovered <*> running containers from UAM in <*>
[ERROR]:ERROR: + e.getMessage() + \n
[ERROR]:The connection is not in the closed state
[DEBUG]:recycle: array.length=, freeQueueSize=
[INFO]:Splitting using IntegerSplitter
[INFO]:Cannot send OOB response + ackStatus + . Responder not running.
[DEBUG]:The file system initialized uri scheme is matching with the given target uri scheme. So, the target file system instances will not be cached. To cache fs instances, please set fs.viewfs.enable.inner.cache to true. The target uri is: uri
[DEBUG]:Adding runnable application: application.getApplicationAttemptId()
[DEBUG]:Copied <*> meta to <*> and calculated checksum
[INFO]:User does not have privilege to see this application
[DEBUG]:Repeated write request which hasnâ€™t been served: xid=<*>, drop it.
[DEBUG]:Add env entry: + name + = + value
[DEBUG]:Updating min resource for Queue: <*> as <*>, Actual resource: <*>, ratio: <*>
[DEBUG]:SDK_REGION_CHAIN_IN_USE
[WARN]:RuntimeException of NvidiaDockerV1CommandPlugin init:, e
[WARN]:Datanode <*> is not a valid cache location for block <*> because that node does not have a backing replica!
[INFO]:FSImageSaver clean checkpoint: txid=<*> when meet + Throwable., context.getTxId()
[ERROR]:Unable to update next master key in state store
[INFO]:Token= ( + dttr + ) is expiring, request new token.
[WARN]:DIR* FSDirectory.unprotectedRenameTo: rename source cannot be the root
[ERROR]:Unsupported protocol found when creating the proxy connection to NameNode
[DEBUG]:Running job setup task
[INFO]:Cannot find block info for block <*>
[ERROR]:App attempt: + appAttemptID + can't handle this event at current state, e
[DEBUG]:Already aborted: <*>
[WARN]:'Authorization' does not start with 'Basic' : <*>
[WARN]:Resource is missing:<*>
[INFO]:Total Nodes: countHere
[INFO]:Dispatcher setup and services added
[TRACE]:<*>: trying to create ShortCircuitReplicaInfo.
[INFO]:Sending fileName: <*>, fileSize: <*>.
[INFO]:Loading allocation file
[DEBUG]:addSymlink: <*> is added
[WARN]:<*>: Failed to delete directory
[ERROR]:Unexpected IOException by closing FsVolumeReference
[DEBUG]:Adding new framework-token for <*> for localization: <*>
[DEBUG]:Sending Heartbeat to RM. AskList:<*> <*> LOG.DEBUG: Sending Heartbeat to RM. AskList:<*>,
[DEBUG]:Config has been overridden during init
[INFO]:SUBMITTING ApplicationSubmissionContext app:<*> to queue:<*> with reservationId:<*>
[DEBUG]:Block added
[INFO]:Ignoring exception
[WARN]:Failed to parse resource-request
[DEBUG]:Volume <*> is <*>., reference.getVolume(), result
[INFO]:Updating edits cache to use layout version <*> starting from txn ID <*>; previous version was <*>; old entries will be cleared.
[INFO]:Action set for property: QUEUE_AUTO_CREATE
[ERROR]:Unknown resource profile
[INFO]:found local record? false
[INFO]:Done loading applications from FS state store
[DEBUG]:Assigned to queue: <*> stats: <*> --> <*>, <*>
[WARN]:All opened streams are busy, can't remove any from cache.
[INFO]:EventFetcher: Thread started
[INFO]:Failed to free the buffer
[INFO]:session.getRemoteAddress().getHostString() + " closed!"
[WARN]:Recovery for replica " + block + " on data-node " + id + " is already in progress. Recovery id = " + rBlock.getNewGenerationStamp() + " is aborted.
[INFO]:Catching up to latest edits from old active before taking over writer role in edits logs
[INFO]:updating the following ReservationRequest: + contract
[DEBUG]:addResourceRequest: applicationId= + applicationId.getId() + priority= + priority.getPriority() + resourceName= + resourceName + numContainers= + remoteRequest.getNumContainers() + #asks= + ask.size()
[DEBUG]:Loading file: <*>
[INFO]:Exception caught by TimelineClientConnectionRetry, will try <*> more time(s). Message: <*>
[DEBUG]:Attempting active election for + this
[ERROR]:Not able to initialize target file system. ResultKind:%s, resolvedPathStr:%s, targetOfResolvedPathStr:%s, remainingPath:%s, will return null.
[INFO]:Rolled edit log using RouterClientProtocol
[INFO]:Attempting to delete blob
[DEBUG]:Connecting to Azure storage in Secure Mode
[INFO]:Launch container failed:
[WARN]:Failed to connect with namenode
[WARN]:I/O error constructing remote block reader.
[WARN]:DIR* FSDirectory.unprotectedAddFile: exception when add existing.getPath() to the file system
[DEBUG]:Unexpected error.
[DEBUG]:pMemCheck <*>
[DEBUG]:Ignoring bucket option <*>
[DEBUG]:Trim write request by delta: " + delta + " " + toString()
[DEBUG]:showRequests: application=... headRoom=... currentConsumption=...
[DEBUG]:DataNode failed volumes: <*>
[INFO]:Setting up application submission context for ASM
[DEBUG]:Removing pending reconstruction for <*>
[INFO]:Recovering storage directory <*> from previous upgrade
[WARN]:User <*> request <*> <*> caused exception.
[ERROR]:Interrupted while waiting for CleanerThreadPool to terminate
[INFO]:logEdit invoked
[INFO]:Found + timestampedDirList.size() + directories to load
[DEBUG]:NameNode safe mode check completed
[DEBUG]:closing ipc connection to server: closeException.getMessage()
[INFO]:Delayed removal requested and allowed, skipping removal - <*>
[DEBUG]:Filesystem glob <*>
[INFO]:Incrementing containers ready
[ERROR]:comment, t
[INFO]:Successfully addHistory new resource skylines for <*>.
[INFO]:Service <*> does not have an application ID
[DEBUG]:Decrypted EDEK for file: <*>, output stream: 0x<*>
[DEBUG]:Renamed <*> to <*> successfully.
[TRACE]:Entering getCurrentVersion method.
[INFO]:Reading entity types
[INFO]:removeAcl operation completed
[INFO]:dn + <*> has utilization= + utilization + >= average= + average + but it is not specified as a source; skipping it.
[INFO]:onNodesUpdated: <*>
[INFO]:User ACL Info for Queue
[INFO]:Completed reading history information of application attempt
[INFO]:Path already exists, no action taken
[TRACE]:this: NotificationHandler: doing a read on sock.fd
[DEBUG]:Retrieved file system
[DEBUG]:Succeeded to start DataNode Container + containerId
[DEBUG]:Server using encryption algorithm + dnConf.getEncryptionAlgorithm()
[DEBUG]:Node + node.getNodeName() + offered to parent queue: + getName() + visiting + childQueues.size() + children
[WARN]:Unable to determine if the filesystem supports append operation
[TRACE]:Got token: <*>.
[DEBUG]:lease path: <*>
[DEBUG]:JWT token expiration date has been successfully validated
[TRACE]:<*>: loading <*>
[INFO]:Operation addToClusterNodeLabels succeeded
[DEBUG]:updateAverageResponseTime queue: <*> Average: <*> Count: <*>
[ERROR]:Attempted to cache data of length %d with newStartTxn %d and newEndTxn %d
[ERROR]:Could not put workRequest into inputQueue. Retrying...
[DEBUG]:Thread.currentThread().getName(): disconnecting client + connection +. Number of active connections: + size()
[WARN]:Interrupted Exception while stopping
[DEBUG]:readAggregatedLogs
[DEBUG]:VMEM Comparison: <*> <*>
[DEBUG]:Map tasks to process: <*>}
[INFO]:Given mode: <*> is invalid
[INFO]:File not found, creating node without parents
[WARN]:Failed to place enough replicas: expected size is <*> but only <*> storage types can be selected (replication=<*>, selected=<*>, unavailable=<*>, removed=<*>, policy=<*>)
[INFO]:Failed to change storage policy satisfier as DFS_STORAGE_POLICY_ENABLED_KEY set to <*>
[WARN]:Unable to get groups for user <*> via <*> because: <*>
[DEBUG]:Closing streams upon failure.
[INFO]:Creating paxos dir: <*>
[INFO]:FSImageSaver clean checkpoint: txid=<*> when meet + Throwable., context.getTxId()\n
[DEBUG]:there are no corrupt file blocks.
[TRACE]:AbfsClient init complete
[ERROR]:Invalid LOOKUP request
[DEBUG]:Token decoded
[INFO]:Disk Volume set <*> - Type : <*> plan completed.
[ERROR]:Resource update get failed on all nodes due to change resource on an unrecognized node: <*>
[ERROR]:Error on destroy ' + serviceName + ': not found.
[WARN]:Log4j configuration file '<*>' not found
[DEBUG]:Try to allocate from a non-existed reserved container
[ERROR]:Unable to get quota usage for + src, ioe
[INFO]:Reading amrmToken for subcluster <*> for <*>
[TRACE]:No need to dump with status(replied,dataState):(replied,dataState)
[DEBUG]:Getting groups for user + user
[WARN]:$<*>, $<*>
[WARN]:"Unable to gracefully make <*> standby (unable to connect)"
[WARN]:Duplicate containerID: <*> found in the allocated containers from same sub-cluster: <*>, so ignoring.
[ERROR]:Caught exception
[INFO]:Recovered <*> replicas from <*>
[INFO]:Node update recording started
[DEBUG]:<*>=<*>
[INFO]:getContainerLogsInfo
[ERROR]:Subcluster <*> failed to return Cluster Metrics.
[INFO]:Unchecked exception is thrown in handler for event <*> for Container + containerId
[ERROR]:Failed to download resource
[INFO]:Handling decommission event
[ERROR]:Error storing appAttempt:
[ERROR]:Could not set service <*> programmatically -server shutting down-, <*>
[INFO]:jsp requested
[DEBUG]:assignContainers: node=... #applications=...
[DEBUG]:Bonded to filesystem with resilient commits under path <*>
[DEBUG]:In safemode, not computing reconstruction work
[DEBUG]:Creating <*> requires creating parent <*>, src, parent
[DEBUG]:invalidateCorruptReplicas error in deleting bad block <*> on <*>
[WARN]:Unexpected exception in block pool this
[WARN]:RuntimeException during Trash.Emptier.run(): <*>
[INFO]:Creation of AutoCreatedLeafQueue succeeded
[DEBUG]:First line in cgroup tasks file: <*> <*>
[INFO]:Reported NameNode version '<*>' does not match DataNode version '<*>' but is within acceptable limits. Note: This is normal during a rolling upgrade.
[WARN]:<*> is unknown for disk error.
[WARN]:logBuilder.toString()
[INFO]:Thread.currentThread().getName() + ": starting"
[ERROR]:Interrupted on sleep while exiting.
[ERROR]:Error in storing master key with KeyID:
[INFO]:Handling NodeAttributesStoreEvent
[INFO]:Got exception while pausing container: + StringUtils.stringifyException(e)
[WARN]:The value of DFS_NAMENODE_AVAILABLE_SPACE_RACK_FAULT_TOLERANT_BLOCK_PLACEMENT_POLICY_BALANCED_SPACE_PREFERENCE_FRACTION_KEY is less than 0.5 so datanodes with more used percent will receive more block allocations.
[ERROR]:Manifest file and parents must not be writable by group or others. The current Permission of <*> is <*>
[ERROR]:Failed to squash cgroup operations!
[DEBUG]:Change concurrent thread count to <*> from <*>
[INFO]:Safe mode exception encountered
[INFO]:NMCollectorService started at
[INFO]:Router is running now
[INFO]:AMRMClientAsync initialized
[INFO]:Deactivating Node + rmNode.nodeId + as it is now + finalState
[INFO]:Deleted <*>/<*> start time entities earlier than <*>
[INFO]:VolumeImpl VOLUME_ID transitioned from OLD_STATE to NEW_STATE
[WARN]:Exception in getting reader from provided alias map
[WARN]:Got a command from standby NN <*> - ignoring command: <*>
[INFO]:Zone <*>(<*>) is submitted for re-encryption., zoneName, inode.getId()
[DEBUG]:Scanned <*> directories.
[DEBUG]:Preempting .. container(s)
[DEBUG]:read requested b.length = <*>, offset = <*>, len = <*>
[DEBUG]:Creating heart beat request for subClusters
[INFO]:Error getting users for netgroup
[ERROR]:Error during executing external binary
[INFO]:Successfully started new epoch <*>
[DEBUG]:mode.toString() + " Loaded TrustStore: " + truststoreLocation
[INFO]:task.commitAttempt already given a go for committing the task output, so killing attemptID
[INFO]:Spec output bytes w/o records. Using input record count
[ERROR]:Read request interrupted
[DEBUG]:key: attr
[INFO]:Operation executed with action and path
[INFO]:GridMix is configured to use a compression ratio of ... for the job output data.
[WARN]:Arrays.toString(nodes) + " are unavailable and all striping blocks on them are lost. IgnoredNodes = " + ignoredNodes
[INFO]:Starting $<*>; track at: http://$<*>/node/containerlogs/$<*>/$<*>/
[INFO]:Sampling (samples) splits of (splits.size())
[INFO]:ParsedTask details: ... (detailed data) ...
[DEBUG]:Trim request [offset-(offset + count)), current offset currentOffset, drop the overlapped section [offset-currentOffset) and write new data [currentOffset-(offset + count))
[DEBUG]:*DIR* NameNode.unsetStoragePolicy for path: <*>
[DEBUG]:Returning current token
[INFO]:adminAclList=<*>
[INFO]:op=LISTXATTRS target=path
[WARN]:<*> is set to <*>. It must be greater than zero. Setting to default of <*>, DFSConfigKeys.DFS_IMAGE_PARALLEL_TARGET_SECTIONS_KEY, targetSections, DFSConfigKeys.DFS_IMAGE_PARALLEL_TARGET_SECTIONS_DEFAULT
[INFO]:TaskInfo object initialized
[WARN]:null file argument.
[ERROR]:HadoopLogsAnalyzer.processReduceAttemptLine: bad numerical format, at line...
[DEBUG]:Running DeletionTask : <*>
[DEBUG]:Adding source dir for traverse: <*>
[DEBUG]:Delete \"<*>\" completed; deleted <*> objects
[ERROR]:Giving up on <*> after <*> retries.
[WARN]:Unexpected exception
[INFO]:Registered sink <*>
[DEBUG]:beforeExecute in thread: + Thread.currentThread().getName() + ", runnable type: " + r.getClass().getName()
[DEBUG]:<*>: attempt path is <*>
[DEBUG]:Token renewal interval obtained
[ERROR]:Error cleaning files, e
[DEBUG]:Probing NN at service address: <*>
[INFO]:Scanning destination directory <*> with thread count: <*>
[INFO]:Successfully sent block report 0x...
[DEBUG]:With principals: Arrays.asList(principals)
[DEBUG]:No pending resource for: nodeType=, node=, requestKey=, application=
[DEBUG]:Closing page blob output stream.
[INFO]:The number of failed attempts in previous <*> milliseconds is <*>. The max attempts is <*>
[DEBUG]:<*> got value #<*>
[INFO]:Loading node into resolver: nodeName --> subClusterId
[DEBUG]:Init the lastScheduledContainer time, priority: <*>, time: <*>
[INFO]:Added <*> to list of failed maps
[DEBUG]:Added to active capacity from queues
[DEBUG]:Print human-readable requests to LOG debug.
[INFO]:Kill task attempt TASK_ID received from USER at SERVER_ADDRESS
[INFO]:Forwarding finish application request to the real YARN Resource Manager
[INFO]:Created the global cleaner pid file at pidPath.toString()
[TRACE]:Entering generateEncryptedKeys method.
[INFO]:User to Groups mapping refreshed
[WARN]:Failed to submit <*> as <*>
[DEBUG]:No such Execution Type=<*>
[WARN]:Quorum journal URI ' + uri + ' has an even number of Journal Nodes specified. This is not recommended!
[INFO]:Application <*> is registered for timeout monitor, type=<*> value=<*> seconds
[INFO]:Using Committer <*> for <*>, outputCommitter, outputPath
[DEBUG]:Skipping sending lifeline for + BPServiceActor.this + , because it is not due.
[INFO]:Could not obtain job info after ... attempt(s). Sleeping for ... seconds and retrying.
[ERROR]:Unable to fence service by any configured method.
[DEBUG]:for url=msgToEncode sent hash and received reply
[WARN]:Log file + file + has no valid header, e
[ERROR]:Cannot get main namespace for path <*> with order <*>, path, order
[DEBUG]:Logging user info
[WARN]:Failed to get major-minor number from reading /dev/<*>
[DEBUG]:Processing previouly queued message
[DEBUG]:BLOCK markBlockAsCorrupt: <*> cannot be marked as corrupt as it does not belong to any file
[ERROR]:"Couldn't close write selector in " + Thread.currentThread().getName(), ioe
[WARN]:Configuration key <*> is deprecated! Ignoring... Instead please specify a value for <*>
[INFO]:context.service.toString()
[WARN]:Unable to determine the max transaction ID seen by
[INFO]:Recovering app attempt <*>
[DEBUG]:Falling back to authHandler.getClass() (req=request)
[INFO]:All async data service threads have been shut down
[DEBUG]:RPC operation check executed
[DEBUG]:Child starting
[INFO]:<*> version <*> : Creating Public Resource dir on hdfs: <*>
[INFO]:parameters = <*>
[WARN]:Job init failed, e
[TRACE]:New Excluded nodes: <*>
[DEBUG]:canSatisfyOrConstraint check
[WARN]:Failed to send success response back to the client. Shutting down socket for <*>
[WARN]:Unexpected error trying to delete/move block
[DEBUG]:Using SSE-C with <*>
[WARN]:Got exception from TagManager !
[INFO]:Percentage of invalid ops: ...
[DEBUG]:Creating unknown node ID
[DEBUG]:Added RM HA URLs
[DEBUG]:Cycle #<*> of log aggregator
[WARN]:Metrics cache overflow at <*> for <*>
[INFO]:No files to upload
[ERROR]:<*>: Invalid event <*> at <*> <*>
[INFO]:All datanode containers completed; marking application as done
[ERROR]:Failed to load/recover state
[DEBUG]:Chosen node <*> from first random
[ERROR]:Failed to create service <*> :
[INFO]:prefix + metrics system started in standby mode
[DEBUG]:Stacktrace:
[INFO]:App completely done transition executed.
[INFO]:Cannot set capacity beyond end time: <*> was (<*>)
[WARN]:FsDatasetImpl.shutdown ignoring InterruptedException from LazyWriter.join
[TRACE]:MsiTokenProvider initialized
[WARN]:Unable to clean resources
[DEBUG]:Path:<*> doesn't exist!
[DEBUG]:Filesystem based provider excluded from provider path due to recursive dependency: <*>
[DEBUG]:Creating new rule: <*>
[WARN]:<*>:DataXceiverServer.kill()
[INFO]:Shutdown request received. Ignoring since keep_containers_across_application_attempts is enabled
[INFO]:Read aborted due to zero length
[ERROR]:Cannot retrieve numNamenodes for JMX: <*>
[DEBUG]:Unregistering metrics for <*>
[INFO]:Removing state store at + recoveryRoot + due to decommission
[INFO]:Time taken to scan block pool <*> on <*>: <*>ms
[ERROR]:LOGGER.error(msg)
[DEBUG]:After writing <*> at offset <*>, updated the memory count, new value: <*>, handle.dumpFileHandle(), offset, nonSequentialWriteInMemory.get()
[INFO]:Started listening to UDP requests at port + boundPort + for + rpcProgram + with workerCount + workerCount
[DEBUG]:Token identifier fields read
[WARN]:application ID <*> is reported as null
[WARN]:Exiting Datanode
[ERROR]:caught iae during conversion to long
[DEBUG]:isNamespaceEnabled is UNKNOWN; fall back and determine through getAcl server call
[ERROR]:Error in getting GPU topology info. Skip topology aware scheduling
[WARN]:Exception running local (uberized) 'child'
[INFO]:Unhealthy Nodes: countHere
[WARN]:After resync, position is ...
[INFO]:Initialized federation membership service.
[DEBUG]:Found <*>, adding to configuration
[INFO]:capacity = 2^<*> = <*> entries
[INFO]:Service starting up. Logging start...
[INFO]:Starting Local Zookeeper service
[DEBUG]:Filesystem <*> defined in configuration option
[INFO]:InMemoryReservationAllocation initialized
[DEBUG]:blocks = <*>
[INFO]:Failing over to the ResourceManager for SubClusterId: ...
[WARN]:Unmanaged AM still not successfully launched/registered yet. Stopping the UAM heartbeat thread anyways.
[WARN]:Volume <*> has less than 0 available space
[WARN]:%s change detected on %s %s%s. Expected %s got %s
[INFO]:Formatting using clusterid: <*>
[INFO]:storage.getJournalManager().doRollback called
[WARN]:Exception in committer.isCommitJobRepeatable()
[ERROR]:User <*> does not have permission to submit <*> to queue <*>.
[INFO]:Job started: startTime
[INFO]:Stopped JobHistoryEventHandler. super.stop()
[INFO]:Found container + container + on node + node.getNodeName() + without app, skipping preemption
[ERROR]:Unable to update token + tokenId.getSequenceNumber(), e
[ERROR]:Can't make a speculation runtime estimator
[INFO]:closing the flowActivityTable table
[DEBUG]:Load plugin <*> with classpath: <*>
[TRACE]:demoteOldEvictable: demoting <*>: <*>: <*>
[DEBUG]:Inode <*> EZ key changed, skipping re-encryption.
[INFO]:KnownNode Count at 0. Not computing ignoreBlacklisting
[WARN]:Invalid number of args: + args.size()
[ERROR]:Invalid URI for path: throws URISyntaxException
[INFO]:Capacity Scheduler configuration changed, updated preemption properties to:...
[ERROR]:Can't update the maps. Will use the old ones, which can potentially cause problem.
[DEBUG]:Set memory to <*>
[INFO]:The storage policy of <*>: <*>
[ERROR]:Invalid URI:
[DEBUG]:Token renewed, expiration time updated
[DEBUG]:iterating in reported metrics, size=<*> values=<*>
[INFO]:Node transitioned to RUNNING
[ERROR]:No namenode available to invoke...
[ERROR]:Application failed to complete successfully
[ERROR]:Can't get path for fileId: <*>
[TRACE]:Returned false due to null rempteIp
[INFO]:Authentication method: %s
[TRACE]:this + blocksToReceive= + blocksToReceive + , scheduledSize= + getScheduledSize() + , srcBlocks#= + srcBlocks.size()
[TRACE]:shuffle for jobId reducer reduce length contentLength mappers: mapIds
[ERROR]:In-progress stale edits file + f + has improperly formatted transaction ID
[INFO]:this + : datanode does not support short-circuit + shared memory access: + error
[INFO]:Shutdown request received. Processing since keep_containers_across_application_attempts is disabled
[DEBUG]:<*>: Created <*> directories
[INFO]:logAuditEvent(true, "createSymlink", link, target, auditStat)
[DEBUG]:openFileForRead filesystem: <*> path: <*>
[INFO]:Web app <*> started at <*>
[INFO]:Skip killing <*>
[INFO]:Ramping up
[INFO]:Successfully updated reservation: <*> in plan.
[INFO]:Failed to allocate container for application on node because this allocation violates the placement constraint.
[INFO]:<*> does not exist. Creating ...
[WARN]:<*>: error creating legacy BlockReaderLocal. Disabling legacy local reads.
[DEBUG]:name
[DEBUG]:Lease free update blob <*> encountered Storage Exception: <*> Error Code : <*>, key, ex, ex.getErrorCode()
[INFO]:Attempt failed for application: appId
[INFO]:addJerseyResourcePackage: packageName=<*>, pathSpec=<*>
[DEBUG]:Will connect to NameNode at + address
[INFO]:Reinitialized queue management policy for parent queue <*> with leaf queue template capacities : <*>
[INFO]:Initializing the GreedyReservationAgent to favor "early" (left) allocations (controlled by parameter: FAVOR_EARLY_ALLOCATION)
[DEBUG]:Predict resource requests for pipelineId: <*>.
[DEBUG]:CSConf - getQueues called for: queuePrefix=<*>
[INFO]:Rolling master-key for nm-tokens
[INFO]:Send configurations that match regex expression: + regex + , total number of configs: + count + , total size : + dob.getLength() + bytes.
[DEBUG]:Statistics of the operation evaluated
[INFO]:Tar-gzipping folders <*> to <*>
[INFO]:No node available for <*>
[INFO]:Ignore blacklisting set to false. Known: <*>, Blacklisted: <*>, <*>%
[INFO]:Finished iteration of plan follower edit policy for plan: <*>
[DEBUG]:getAclStatus filesystem: <*> path: <*>
[TRACE]:load(<*>, <*>): loaded iterator <*>: <*>
[ERROR]:msg
[DEBUG]:Remove write <*> from the list
[WARN]:Cannot set replication to ... for path: ... on a non-distributed filesystem ...
[WARN]:<*>: using deprecated cleanupJob call for <*>, r, id
[INFO]:PingSocketCleaner started...
[INFO]:Loading the existing database at th path: <*>
[DEBUG]:Closer check completed
[DEBUG]:Closing FileSystem: Key: someKey; URI: someUri; Object Identity Hash: someHash
[DEBUG]:handleVolumeFailures done with empty unhealthyVolumes
[WARN]:Failed to get + AppPlacementAllocator.class.getName() + for application= + getApplicationId() + schedulerRequestKey= + schedulerKey
[INFO]:Rolling back Container reInitialization for <*> !!
[WARN]:Request #getBlocks to Standby NameNode but meet exception, will fallback to normal way.
[ERROR]:transitionToObserver: incorrect number of arguments
[INFO]:Kill the application using: ...
[INFO]:Usage printed
[INFO]:Using Scheduler: schedulerClassName
[DEBUG]:BLOCK* ExcessRedundancyMap.add(<*>, <*>)
[INFO]:Job instance created
[INFO]:Using a keytab from localhost: keytabURI
[DEBUG]:Found the path: <*> as a file.
[INFO]:Concurrent invocation executed
[DEBUG]:Server connection from + connection + ; # active connections: + size() + ; # queued calls: + callQueue.size()
[DEBUG]:Cancel delegation token
[ERROR]:Response from the timeline server is not successful, HTTP error code: ...
[INFO]:Cancelling <*> re-encryption tasks
[INFO]:Deleting staging directory + FileSystem.getDefaultUri(getConfig()) + jobTempDir
[INFO]:Heartbeated the StateStore for the specified SubCluster
[INFO]:mapResourceRequest: + mapResourceRequest
[WARN]:Yarn Registry record <*> does not contain <*> attribute
[TRACE]:<*>: loadManifest('<*>'), getName(), status
[WARN]:Failed to place enough replicas...
[INFO]:The filesystem under path 'dir' has no CORRUPT files
[INFO]:Balancing took ...
[DEBUG]:allocate: post-update applicationAttemptId= ...
[INFO]:forceKillApplication applicationId on SubCluster subClusterId
[INFO]:Downloading public resource: <*>
[DEBUG]:Error while connecting to namenode
[WARN]:DataNode is shutting down due to failed volumes: <*>
[TRACE]:Entering reencryptEncryptedKeys method.
[WARN]:Some logs may not have been aggregated for <*>
[DEBUG]:Detailed exit debug info
[WARN]:<*> failure getting localization statuses
[ERROR]:Error storing AMRMProxy application context entry for + context.getApplicationAttemptId(), e
[TRACE]:Excluding datanode <*>: outOfService=<*>, excluded=<*>, notIncluded=<*>
[WARN]:Failed to query node cardinality: <*>
[WARN]:Could not parse %s in %s
[DEBUG]:removing cookie <*> on <*>
[INFO]:currCacheSize * 100.0 / maxCacheSize + % of cache is loaded.
[WARN]:StorageLocation <*> appears to be degraded.
[INFO]:Error when reading history information of some application attempts of application appId
[INFO]:Rolling master-key for container-tokens, got key with id + masterKeyRecord.getKeyId()
[INFO]:Force-killing UAM id <*> for application <*>
[INFO]:Cannot add application <*>: <*>
[INFO]:ApplicationHistory Init
[DEBUG]:error
[DEBUG]:Initializing SSL Context to channel mode Default
[DEBUG]:Writing with NoOpTimelineWriterImpl
[ERROR]:An exception occurred while returning the buffer to the buffer pool.
[INFO]:ImageServlet allowing checkpointer: + remoteUser
[INFO]:No policy configured for default queue <*> in StateStore, fallback to local config
[INFO]:Processed URL + url + but flowrun not found (Took + (Time.monotonicNow() - startTime) + ms.)
[WARN]:commitBeforeRead didnâ€™t succeed with ret=<*>
[DEBUG]:Entering map method
[DEBUG]:result.getETag()
[INFO]:Acquiring pre-assigned chunk: + acquiredFilePath
[DEBUG]:Cannot get locations for <*>, <*>.
[INFO]:Update IP hash to + newHash
[DEBUG]:FS for <*> is <*>
[DEBUG]:sample log statement for debug
[DEBUG]:Ignoring unknown CryptoProtocolVersion provided by client: <*>
[INFO]:Localizer CWD set to <*> = <*>
[DEBUG]:Delete <*> due to unsuccessful mapping.
[ERROR]:Application doesn't exist in cache
[TRACE]:<*>: pulled the last slot <*> out of <*>, this, slot.getSlotIdx(), shm
[DEBUG]:Application <*> is not registered in the Placement Constraint Manager., appId
[WARN]:principal short name: result still contains @ or /
[WARN]:Container not found
[INFO]:FSPlacementRule applied
[WARN]:<*>: can't remove block pool <*>, because it was never added., this, bpid
[ERROR]:Error while trying to clean up previous job's temporary files
[DEBUG]:Expiry based on expires_on: <*>
[DEBUG]:putEntitiesAsync(entities=<*>, callerUgi=<*>)
[DEBUG]:Starting mapper thread pool executor.
[WARN]:List inconsistency is no longer emulated; only throttling and read errors
[DEBUG]:Queue: <*>, node label : <*>, queue partition resource : <*>, queue current limit : <*>, queue partition usable resource : <*>, amResourceLimit : <*>
[INFO]:Attempting to recover.
[DEBUG]:The property '+ locationProperty +' has not been set, no TrustStore will be loaded
[WARN]:INTERNAL_SERVER_ERROR, e
[WARN]:Quorum journal URI ' + uri + ' has an even number + of Journal Nodes specified. This is not recommended!
[WARN]:FinishApplicationMaster already called by attemptId, skip heartbeat processing and return dummy response
[INFO]:Scheduler host freed
[ERROR]:Failed to fetch user credentials from application
[DEBUG]:Thread sleep in monitoring loop interrupted
[DEBUG]:Stopping expired delegation token remover thread
[ERROR]:Exception in listStatus. Will send for retry.
[INFO]:Added erasure coding policy
[DEBUG]:First execution of REST operation - <*>
[DEBUG]:Generating RelativePath SAS Key for relativePath <*> inside Container <*> inside Storage Account <*>
[DEBUG]:Unable to restrict HEAD request to etag; will check later
[TRACE]:got a relevant read buffer for file <*> offset <*> buffer idx <*>
[TRACE]:Found no rules for user
[DEBUG]:Registered source + name
[DEBUG]:<*> files to commit under <*>
[INFO]:Parsing allocation file
[INFO]:Send <*> to <*> to free up <*>
[DEBUG]:Recovering <*>
[ERROR]:Unable to free lease on
[DEBUG]:Crypto codec <*> not found.
[DEBUG]:Processing + event.getTaskID() + of type + event.getType()
[INFO]:NextBlock call returned null. No valid block to copy. <*>
[INFO]:ImageServlet rejecting: + remoteUser
[DEBUG]:Invalid containerId CONFIGURED
[INFO]:Publishing component instance status <*> <*>
[INFO]:Running as user
[WARN]:Getting exception while trying to determine if nameservice can use logical URI
[INFO]:Total number of input data files : + fileCount
[ERROR]:Application not found
[WARN]:Ticket is already destroyed, remove it.
[WARN]:Exception while reading checksum
[DEBUG]:Dispatcher registered
[DEBUG]:<*> not created
[DEBUG]:Using existing delegation token
[TRACE]:Reading receipt verification byte for slotId
[DEBUG]:Placement rule order check
[INFO]:Considering container + logContext.getContainerId() + for log-aggregation
[INFO]:Skip env entry: <*>
[DEBUG]:Configuring metrics output directory
[WARN]:Missing SetSubClusterPolicyConfiguration Request. Please try again by specifying an policy insertion information.
[ERROR]:IOException: errorMessage
[WARN]:Got failure attempting to read from storage, assuming Storage is down
[DEBUG]:Updating token <*>
[INFO]:Stopping + prefix + metrics system...
[TRACE]:Name lookup for + hostname + took + elapsedMs + ms.
[INFO]:Removing attempt + attemptId + from app: + appId
[DEBUG]:No cleanup needed for System.out
[INFO]:Ignoring killed event for successful reduce task attempt + taskAttempt.getID().toString()
[DEBUG]:Connecting to MRHistoryServer at: + hsAddress
[DEBUG]:Adding container <*>
[WARN]:Failed to upgrade storage directory <*> for block pool <*>
[WARN]:Could not find a target for file <*> with favored node <*>
[ERROR]:Unable to remove application + appAttemptRemovedEvent.getApplicationAttemptID() + ie
[INFO]:writeAuditLog
[DEBUG]:: stopped, remaining connections
[DEBUG]:Get InputStream by cache address.
[ERROR]:Cannot fetch records for <*>
[ERROR]:Invalid format for CustomSigner: <*>
[INFO]:Invalidated <*> extra redundancy blocks on <*> after it is in service, numExtraRedundancy, srcNode
[WARN]:Cannot launch privileged container. Submitting user (<*>) fails ACL check.
[DEBUG]:creating thread pool of size <*>, numThreads
[DEBUG]:concat + targetFile + allChunkSize+ + allChunkPaths.size()
[DEBUG]:deleteCgroup: <*>
[DEBUG]:Ignoring exception raised in task completion:
[INFO]:<*> Transitioned from <*> to <*> on <*> event.
[TRACE]:Entering getKeyNames method.
[INFO]:Adding service.getName()'s keytab for localization, uri = keytabOnhdfs
[DEBUG]:Cleanup with Logger initiated
[WARN]:Metrics logging will not be async since the logger is not log4j
[WARN]:Invalid namespaceID in journal request - expected <*> actual <*>
[DEBUG]:RM has confirmed changed resource allocation for container ...
[INFO]:Creating application directory
[WARN]:Cannot load customized ssl related configuration. Fallback to system-generic settings.
[INFO]:Fenced by <*> with epoch <*>
[ERROR]:An error occurred while reflecting the event in top service, event: (cmd=<*>,userName=<*>)
[INFO]:Processing Event <*> for Container <*>
[DEBUG]:Submitted Class Name: <*> + logName + <*><*>
[ERROR]:Error when writing finish information of application + appFinish.getApplicationId(), e
[INFO]:Instance <*> already decommissioned
[INFO]:rename <*> to <*> failed, checking etag of destination
[INFO]:Initializing configured GPU resources for the NodeManager.
[TRACE]:getNextSubDir(<*>, <*>): no subdirectories found in <*>
[DEBUG]:Recovering block " + block + ", length=" + block.getNumBytes() + ", safeLength=" + safeLength + ", syncList=" + syncBlocks
[DEBUG]:Context initialized with ResourceManager and Yarn Configuration
[DEBUG]:PrimaryGroup rule: parent rule failed
[DEBUG]:Completed setting up container command <*>
[TRACE]:<*>: checked shared memory segment. isStale=<*>
[WARN]:Failed to delete <*>, e
[DEBUG]:+token: <*>
[INFO]:Write locked
[ERROR]:No ack received, took <*>ms (threshold=<*>ms). File being written: <*>, block: <*>, Write pipeline datanodes: <*>.
[ERROR]:ListAsUser for <*> returned with exit code: <*>
[ERROR]:Failed to stop Container <*> when stopping NMClientImpl
[INFO]:Upgrade of <*> is complete
[WARN]:Couldn't remove BPOS BPOfferService from bpByNameserviceId map
[INFO]:Deleting file with retries
[INFO]:Received URL $<*> from user $<*>
[DEBUG]:parts=<*>, params=<*>
[WARN]:<*>: nextBlock error on <*>
[ERROR]:Connection timed out: couldn't connect to ZooKeeper in <*> milliseconds
[DEBUG]:Done. # tags & metrics= + numMetrics
[ERROR]:Mount table cache refresher was interrupted.
[INFO]:Image file <*> of size <*> bytes saved in <*> seconds.
[INFO]:Already in standby state
[WARN]:Unknown file for recovering RMDelegationTokenSecretManager
[DEBUG]:Re-encryption handler throttling expect: <*>, actual: <*>, throttleTimerAll:<*>
[WARN]:Unable to stop service <*>
[ERROR]:Unable to cleanup meta folder: <*>
[ERROR]:Error parsing se query parameter (<*>) from SAS.
[INFO]:Using FAIR_SCHEDULER_XML defined in YARN_SITE_XML by key: FairSchedulerConfiguration.ALLOCATION_FILE
[INFO]:Computing input splits took (t2 - t1) ms
[WARN]:Multi Node scheduling is enabled, however invalid class is configured. Valid sorting policy has to be configured in yarn.scheduler.capacity.<*>.multi-node-sorting.policy
[INFO]:OUTCOME: FAILURE, Reservation ID: + reservationId.toString() + , Contract: + contract.toString()
[DEBUG]:Not generating HistoryFinish event since start event not generated for task: + task.getID()
[ERROR]:We got a closed connection from <*>
[DEBUG]:platform <*> support key class <*>
[WARN]:Can not load log meta from the log file
[ERROR]:Error getting entity
[INFO]:Ignoring FS object ...
[ERROR]:Unresolved dependency mapping for host + node.getHostName() + . Continuing with an empty dependency list
[INFO]:Render counters for task
[ERROR]:NM node labels <*> were not accepted by RM and message from RM : + response.getDiagnosticsMessage()
[DEBUG]:starting downlink
[WARN]:A cleaner task is already running. This scheduled cleaner task will do nothing.
[INFO]:... (l.getLayers() + ";" + l.toString()) ...
[WARN]:Slow manageWriterOsCache took <*>ms (threshold=<*>ms), volume=<*>, blockId=<*>
[INFO]:Creating a Wrapped Input Stream since feInfo is not null
[INFO]:Access check complete
[DEBUG]:History proxy cancelled
[INFO]:Restoring <*> to <*>
[DEBUG]:storeContainerLaunched: containerId=<*>
[ERROR]:Exception encountered while processing heart beat for attemptId, ex
[INFO]:Purging no-longer needed file <*>
[DEBUG]:scanning file: ...
[DEBUG]:Setting finish time
[TRACE]:Reference trace incremented
[DEBUG]:Sanity checks completed
[INFO]:Application appId has already finished
[INFO]:NodeStatusUpdater thread is reRegistered and restarted
[DEBUG]:Initiating logout for <*>
[DEBUG]:Path: <*> is a dir. COS key: <*>
[INFO]:Ignoring killed event for successful map only task attempt + taskAttempt.getID().toString()
[INFO]:DN <*> joining cluster has expanded a formerly single-rack cluster to be multi-rack. Re-checking all blocks for replication, since they should now be replicated cross-rack
[WARN]:Host has no default realm
[INFO]:BLOCK* + err + (numNodes= + numNodes + (numNodes <*>= ) + minimum = + min + ) in file + src
[INFO]:Loaded state version info
[TRACE]:MAJOR COMPACTION loop sum= discarding now: qualifier= value= timestamp=
[INFO]:<*>: scaling down from <*> to <*>
[INFO]:DatanodeCommand action: DNA_ERASURE_CODING_RECOVERY
[INFO]:EDEKCacheLoader interrupted during retry.
[INFO]:opCopyBlock ... received exception ...
[DEBUG]:Set owner operation created
[INFO]:CompositeInputFormat split executed
[WARN]:Cannot create directory marker at <*>: <*>
[INFO]:<*> does not exist to report, containerId
[ERROR]:Shuffle error: , cause
[INFO]:App failed with unknown state
[INFO]:Job jar is not present. Not adding any jar to the list of resources.
[DEBUG]:Accessing pid from pid file <*>
[DEBUG]:stack trace
[TRACE]:Directive <*>: can't cache block <*> because it is in state <*>, not COMPLETE.
[WARN]:Exception when scheduling the event Commit re-initialization of Container containerId
[WARN]:Could not access memory resource for %s
[INFO]:Adding auxiliary service <*> version <*>
[INFO]:Start checkpoint for address
[WARN]:Gave up waiting for scheduler to shutdown
[ERROR]:Error when reading history file of application + appId, e
[INFO]:msg.toString()
[ERROR]:Unable to obtain user name, user not authenticated
[DEBUG]:Unable to perform a zero-copy read from offset <*> of <*>; BlockReader#getClientMmap returned null.
[INFO]:Recovery message with NONE state
[INFO]:Setting the excludes file to <*>
[INFO]:Created trash checkpoint: <*>
[INFO]:NameNode information: %s
[TRACE]:Writing string table entry: <*>
[ERROR]:Unknown NMTimelineEvent type: + event.getType()
[INFO]:Container <*> of finished application <*> completed with event <*>
[WARN]:Failed to parse cgroups + memswStat
[WARN]:Audience validation failed.
[INFO]:CachedRecordStore cache loaded
[WARN]:Exception when scheduling the event of querying the status of Container <*>
[INFO]:Initiate a multipart upload. bucket: <*>, COS key: <*>.
[INFO]:Starting IBR Task Handler.
[ERROR]:FifoPolicy policy is only for leaf queues. Please choose DominantResourceFairnessPolicy or FairSharePolicy for parent queues.
[DEBUG]:Unreserving: <*Changing block file offset of b>. Available: <*>
[ERROR]:Invalid node attribute(s) from Provider: + e.getMessage()
[TRACE]:Chosen nodes: <*>
[INFO]:ParsedJob details: <*>
[DEBUG]:Validating AWS credential provider classes
[DEBUG]:*DIR* NameNode.setStoragePolicy for path: <*>, policyName: <*>
[INFO]:Removing containerID from application app.toString()
[INFO]:cliID: ..., src: 127.0.0.1, dest: 127.0.0.1, op: REQUEST_SHORT_CIRCUIT_SHM, shmId: n/a, srvID: ..., success: false
[WARN]:DIR* FSDirectory.unprotectedRenameTo: rename destination cannot be the root
[INFO]:Start information of container + containerStart.getContainerId() + is written
[DEBUG]:AzureBlobFileSystem.removeDefaultAcl path: <*>
[DEBUG]:checked to see if could unreserve for app but nothing reserved that matches for this app
[INFO]:Refreshing Reservation system
[INFO]:Exception while running the status reporter thread!
[WARN]:Cannot get one of the children's( + path + ) target path( + link.getTargetFileSystem().getUri() + ) file status.
[DEBUG]:Upload block list took <*> ms for blob <*>
[WARN]:Failed to fetch container report from ATS v2
[DEBUG]:NodeManager <*> releases a container (<*>)
[INFO]:current name + name + not equal to + newState.getName()
[INFO]:Exception while creating remote block reader, datanode <*>
[INFO]:Unable to use java.security.SecureRandom. Falling back to Java SecureRandom.
[DEBUG]:\tat <*>
[WARN]:Slow waitForAckedSeqno took <*>ms (threshold=<*>ms). File being written: <*>, block: <*>, Write pipeline datanodes: <*>.
[ERROR]:Unable to create new app from RM web service
[INFO]:Sent total: <*> bytes. Size of last segment intended to send: <*> bytes.
[INFO]:Application attempt + application.getApplicationAttemptId() + released container + container.getId() + on node: + node + with event: + event
[INFO]:Audit event for operation: setErasureCodingPolicy on srcArg
[INFO]:Loaded image for txid + txId + from + curFile
[ERROR]:Got exception creating tarball and uploading to HDFS
[INFO]:Loaded token cache in <*> milliseconds
[INFO]:Error updating info for attempt: <*>, <*>
[ERROR]:Could not get item from childQueue. Retrying...
[WARN]:Unable to trigger a roll of the active NN
[ERROR]:Unable to remove token <*>, e
[INFO]:Using delegation token <*>
[INFO]:'<*> Blacklist '<*>'
[ERROR]:Interrupted while waiting for application <*> to be killed.
[DEBUG]:Creating split : ..., bytes in split: ...
[TRACE]:Updating <*> for re-encryption.
[WARN]:logWarningWhenAuxServiceThrowExceptions during APPLICATION_STOP
[ERROR]:Failed to create an AM: <*>
[ERROR]:Failover failed: <*>
[WARN]:SystemMetricsPublisher.class.getName() + " is interrupted. Exiting."
[INFO]:SuperUserGroups configuration refreshed
[INFO]:Standalone MiniKdc Running
[DEBUG]:<*> + " "]
[DEBUG]:Error parsing <*> as an ApplicationAttemptId
[INFO]:Audit event success for computeSnapshotDiff
[DEBUG]:Incoming requestAttribute:<*> matches with node:<*>
[ERROR]:Failed to upgrade application: , e
[INFO]:Now rescanning bpid <*> on volume <*>, after more than <*> hour(s)
[WARN]:Encountered exception when handling exception ($<*>):, $<*>
[DEBUG]:Removing existing BR lease 0x<*> for DN <*> in order to issue a new one.
[ERROR]:TimelineClient has reached to max retry times : <*>, but failed to fetch timeline service address. Please verify Timeline Auxiliary Service is configured in all the NMs
[INFO]:Read X bytes from map-output for Y
[DEBUG]:Waiting for <*> active copies to complete: <*>
[INFO]:App succeeded with state: KILLED
[DEBUG]:<*>: <*>
[DEBUG]:adding the following namenodes' delegation tokens: null
[INFO]:Registry User ACLs ...
[INFO]:Cleaning up resources
[INFO]:Unchecked exception is thrown from onContainerResourceUpdated for Container
[INFO]:Sleeping in the re-encrypt handler for unit test.
[INFO]:Scheduler container completed
[INFO]:Node request: nodeRequest, Rack request: rackRequest, Any request: anyRequest
[WARN]:Event of type <*> not expected here..
[WARN]:Thread interrupted while trying to acquire READ lock
[DEBUG]:Adding directory: <*>
[DEBUG]:Audit manager initialized with audit service <*>
[INFO]:Calling handler for JobFinishedEvent
[INFO]:Updated reservation using GreedyReservationAgent
[WARN]:Output Path is null in abortTask()
[DEBUG]:LazyWriter: Start persisting RamDisk block: block pool Id: <*> block id: <*> on target volume <*>
[INFO]:Job setup failed with diagnostic message
[INFO]:Adding <*> to application <*>
[INFO]:Setting up container launch context for containerid=$<*> isNameNode=$<*>
[INFO]:Task <*> committed <*> files
[INFO]:completedMapPercent
[WARN]:Failed to get default policy for + fullPath + e
[ERROR]:<*> is not supported for filesystem <*> on path <*>
[DEBUG]:Launching container with cmd: <*>
[INFO]:Successfully loaded file fileName
[DEBUG]:IndexCache HIT: MapId mapId found
[DEBUG]:Successfully authorized
[INFO]:refreshNodes excludesFile + excludesFile
[DEBUG]:Executing shell command
[DEBUG]:timed poll(): timed out
[INFO]:Attempting to kill infrastructure app: <*>
[DEBUG]:JSON Parsing exception: <*> while parsing <*>
[DEBUG]:Proxying operation: <*>
[WARN]:Failed to create file <*>: <*>
[DEBUG]:Node + node.getNodeName() + offered to queue: + getName() + fairShare: + getFairShare(),
[INFO]:Phase initialized for map (67%) and sort (33%)
[INFO]:Recovering unfinalized segments in currentDir
[DEBUG]:Read fully completed
[INFO]:Received new application ID <*> from RM
[INFO]:Reprocessing replication and invalidation queues
[INFO]:Timeout expired in FAIL_WAIT waiting for tasks to get killed. Going to fail job anyway
[INFO]:Applying UMask
[DEBUG]:Node not in list!
[INFO]:The active NameNode is in Upgrade. Prepare the upgrade for the standby NameNode as well.
[WARN]:InterruptedException while stopping
[ERROR]:containerLogNotFound
[WARN]:Edits URI Ignoring duplicates.
[INFO]:Handler responds to 'identifier', says: 'message', returns returnCode
[DEBUG]:Invalidating cache with key name <*>.
[ERROR]:Error when writing command to temp file
[DEBUG]:AADToken: refreshing user-password based token
[DEBUG]:The openFileCtx is not active anymore, fileId: <*>
[WARN]:Found image file at but storage directory is not configured to contain images.
[DEBUG]:Exception raised
[DEBUG]:isValidRequestor is allowing: ...
[ERROR]:Unable to update reservation: <*>
[DEBUG]:Reservation <*> is within threshold so attempting to create synchronously., reservationId
[DEBUG]:The scanning start dir/sub dir + childPath + does not have childrens.
[DEBUG]:Reporting non-HA namenode as operational: <*>
[INFO]:Calling RouterClientProtocol mkdirs
[DEBUG]:Generating block token for + identifier
[WARN]:<*> is at <*> state, do not localize resources.
[INFO]:Retrieved job using jobID from jid
[WARN]:Finished time + finished + is ahead of started time + started
[INFO]:Status: OK
[INFO]:Skipping activateApplications for application.getApplicationAttemptId() since cluster resource is none
[DEBUG]:NameNode is on an older version, request file info with additional RPC call for file: <*>
[DEBUG]:Removing info for app: <*> at: <*> and its attempts.
[DEBUG]:Creating new cgroups cpu handler
[DEBUG]:OP_ADD: ... numblocks: ....
[DEBUG]:Monitoring active leader for (object_instance)
[DEBUG]:Starting to compare Incoming requestAttribute :<*> with requestAttribute value= <*>, stored nodeAttribute value= <*>
[DEBUG]:commit already applied for <*>
[INFO]:Starting maintenance of <*> <*> with <*> blocks
[ERROR]:Invalid READDIR request, with negative cookie: <*>
[INFO]:No existing UAM for application <*> found in Yarn Registry
[DEBUG]:Command: LIST, age %d msec, path %s (prefix \"%s\")
[WARN]:Namespace quota violation in image for...
[ERROR]:Audit event: create, src
[INFO]:Unchecked exception is thrown from onUpdateContainerResourceError for Container
[ERROR]:Unable to remove master key X, e
[INFO]:Loading directories
[INFO]:TrackID: <*> becomes timed out and moved to needed retries queue for next iteration.
[INFO]:Adding snapshot
[INFO]:Starting SchedulingMonitor= + getName()
[INFO]:Upload successful
[WARN]:Flow activity document encountered a warning
[ERROR]:logAuditEvent(false, getAclStatus, src)
[DEBUG]:SSL Configuration read
[ERROR]:Incompatible version for timeline store
[TRACE]:Block <*> numExpected=<*>, numLive=<*>
[DEBUG]:Node attributes <*>} were Accepted by RM
[INFO]:Found binary: pathOfGpuBinary
[INFO]:removing RMDelegation token with sequence number: <*>
[INFO]:Setting timestamp for event
[INFO]:Handling log event in LogAggregationService
[DEBUG]:fs.s3a.endpoint.region="<*>", region
[ERROR]:Error storing info for AMRMTokenSecretManager: <*>
[ERROR]:Could not fetch RM start time
[INFO]:Quitting master election for ... and marking that fencing is necessary
[DEBUG]:Retrieved credentials form RM for <*>: <*>
[DEBUG]:Received data from read ahead, not doing remote read
[INFO]:getName thread interrupted
[INFO]:Scheduling Log Deletion for application: + appId + , with delay of + this.deleteDelaySeconds + seconds
[INFO]:Time taken to replay the logs in ms: ...
[DEBUG]:Core-site XML loaded and processed
[INFO]:Pausing re-encrypt updater for testing.
[INFO]:Removing reservation allocation. + reservationEvent.getReservationIdName()
[INFO]:Writing to HBaseTimelineWriter
[TRACE]:<*>: successfully loaded <*>
[DEBUG]:Cannot rename the root directory of a filesystem.
[WARN]:Error occurred when removing unhealthy storage dirs, e
[INFO]:name + not found
[ERROR]:Couldnt change the file permissions
[ERROR]:Error message
[WARN]:Failed to locate GPU device discovery binary, tried paths: + triedBinaryPaths + ! Please double check the value of config + YarnConfiguration.NM_GPU_PATH_TO_EXEC + . Using default binary: + DEFAULT_BINARY_NAME
[WARN]:A packet was last sent <*>ms ago. Maximum idle time: <*>ms.
[DEBUG]:NULL Credentials specified for Store connection, so ignoring
[INFO]:Node allocation skipped
[DEBUG]:CIDRNMatcher low = + subnetInfo.getLowAddress() + , high = + subnetInfo.getHighAddress() + , allowing client ' + address + ', ' + hostname + '
[INFO]:queueName, capacity=this.queueCapacities.getCapacity(), absoluteCapacity=this.queueCapacities.getAbsoluteCapacity(), maxCapacity=this.queueCapacities.getMaximumCapacity(), absoluteMaxCapacity=this.queueCapacities.getAbsoluteMaximumCapacity(), state=getState(), acls=aclsString, labels=labelStrBuilder, reservationsContinueLooking=reservationsContinueLooking, orderingPolicy=getQueueOrderingPolicyConfigName(), priority=priority
[INFO]:Upload the last part..., blockId: <*>, written bytes: <*>
[INFO]:KMS Hadoop Version:
[DEBUG]:Writing entity list of size <*>
[ERROR]:Queue Management Change event cannot be applied for parent queue
[DEBUG]:Returning JSON response
[INFO]:starts-after time is specified. Initial job submit time : ...<*>
[DEBUG]:<*>: entering state <*>, this, next
[DEBUG]:Selected to preempt <*> resource from partition:<*>
[WARN]:this + : error requesting short-circuit shared memory + access: + error
[WARN]:The same path is included more than once with different links or wildcards
[ERROR]:Namenode is not operational: <*>
[INFO]:Successfully recovered + count + out of + appStates.size() + applications
[INFO]:EagerKeyGeneratorKeyProviderCryptoExtension Decryption successful
[DEBUG]:Redundant shutdown
[TRACE]:Acquiring write lock to replay edit log
[DEBUG]:Cleaned up container resources
[WARN]:Not able to start
[INFO]:MagicS3GuardCommitter staging dirs cleaned
[DEBUG]:Skipping container: <*> with resource:<*> as UserLimit for user:<*> with resource usage: <*> is going under UL
[DEBUG]:Configuration loaded
[INFO]:Success: user action refreshJobRetentionSettings on HISTORY_ADMIN_SERVER
[WARN]:Potential performance problem: getGroups(user= + user + ) + took + deltaMs + milliseconds.
[ERROR]:No component instance exists for + containerId
[ERROR]:Error message with object array
[DEBUG]:Initialization of RemoteSASKeyGenerator instance successful
[DEBUG]:Calling FileSystemNodeLabelsStore recover
[ERROR]:Unexpected health check result null for volume <*>, reference.getVolume()
[DEBUG]:Allocate from reserved container <*> is in final state
[DEBUG]:Get file length. COS key: <*>
[DEBUG]:Rolling key with name <*>., name
[DEBUG]:Refreshing <*> for path <*>
[ERROR]:DeleteAsUser for <*> returned with exit code: <*>
[WARN]:Exit code from container <*> startLocalizer is : <*>
[INFO]:available bytes: <*>
[INFO]:Default file system <*>
[WARN]:Rejecting recoverTask(<*>) call
[WARN]:'userid' was not found in application tags
[ERROR]:Error aggregating timeline metrics
[ERROR]:Null DeviceRuntimeSpec value got from <*> for container: <*>, please check plugin logic
[INFO]:Processed URL $<*> (Took $<*> ms.)
[INFO]:Opened streaming server at <*>
[DEBUG]:Ignoring directory: <*>
[ERROR]:-r, --rack arguments are not supported anymore. RackID resolution is handled by the NameNode.
[DEBUG]:Event <*> handled by <*>
[DEBUG]:Added TEMP container with tags=<*>
[INFO]:Application <*> with appId <*> submitted on <*>
[INFO]:Cancel upgrade in progress. Please wait..
[INFO]:<*> is released by application
[DEBUG]:Preflight Load of pending files
[DEBUG]:Failed to get number of files
[DEBUG]:Deleted batch of <*>. Total start times deleted so far this cycle: <*>
[INFO]:Initializing CSI volume processor
[INFO]:UserGroupMappingPlacementRule applied
[WARN]:Failed to save task commit data to <*>
[INFO]:OP_COUNT_LABEL=opCount
[INFO]:Non-AM container preempted, current appAttemptId=%s, containerId=%s, resource=%s
[INFO]:Unchecked exception is thrown from onContainerStarted for Container containerId
[INFO]:An exception occurred while processing URL <*> from user <*>
[INFO]:MinReplicationToBeInMaintenance is set to zero. <*> is put in maintenance state immediately.
[DEBUG]:AzureBlobFileSystem.setXAttr path: <*>
[ERROR]:errMsg
[DEBUG]:Adding block reconstruction task <*> to <*>, current queue size is <*>
[INFO]:NameNode safe mode checked
[DEBUG]:proxy address is: <*>
[TRACE]:SPNEGO initiated with server principal <*>
[INFO]:Got response from RM for container ask, allocatedCnt=x
[ERROR]:Error storing resource state for + rsrc
[WARN]:Failed to create archives for + appId
[ERROR]:<*> updating resolved params
[INFO]:Shutting down all async data service threads...
[DEBUG]:YARN_NODEMANAGER_DURATION_TO_TRACK_STOPPED_CONTAINERS:600000
[DEBUG]:Starting removeAclEntries
[TRACE]:Retrieval of slow peer report for all nodes is disabled. To enable it, please enable config <*>.
[DEBUG]:Prefix count = <*>; object count=<*>
[INFO]:Workload job completed successfully!
[INFO]:Loading image file curFile using compression
[INFO]:Initializing ApplicationMaster
[INFO]:could not get ... due to InvalidToken exception.
[ERROR]:Resource profiles is not enabled
[INFO]:Can not find any valid fileControllers.
[WARN]:JobConf.deprecatedString(JobConf.MAPRED_TASK_MAXVMEM_PROPERTY) + Instead use + JobConf.MAPREDUCE_JOB_MAP_MEMORY_MB_PROPERTY + and + JobConf.MAPREDUCE_JOB_REDUCE_MEMORY_MB_PROPERTY
[INFO]:Outputted <*> INodes.
[INFO]:Read completed tasks from history
[ERROR]:prompt
[INFO]:Got APPLICATION_INIT for service <*>
[INFO]:valueName = value; threshold action; done waiting after time ms.
[DEBUG]:Removing application attempts NMToken keys for application <*>
[INFO]:Recovering previously paused container
[DEBUG]:Log start rolling upgrade
[INFO]:Submitting application to ASM
[DEBUG]:Retrieved file status: null
[DEBUG]:RegisterUAM returned existing NM token for node <*>
[DEBUG]:Writing output to file
[INFO]:Error in processing cluster status at ...
[INFO]:Checking device file: <*>
[DEBUG]:Initializing SSL Context to channel mode <*>
[INFO]:Renewed <*>}:<*>} until <*>}
[INFO]:Acknowledging ACTIVE Namenode actor
[INFO]:Stopping RedundancyMonitor.
[INFO]:Registering + eventType + for + handler.getClass()
[ERROR]:Cannot find BPOfferService for reporting block deleted for bpid= + block.getBlockPoolId()
[ERROR]:msg.toString()
[INFO]:Application not found: <*>
[INFO]:Got exception while trying to read from stream <*>, client: <*> object: <*>, trying to recover: <*>
[INFO]:Exiting, since retries are exhausted !!
[DEBUG]:Started Audit Manager <*>
[ERROR]:Detected errors while saving FsImage
[ERROR]:Error in deleting application: <*>
[INFO]:Using shared cache
[INFO]:Uberizing job + jobId + ": " + numMapTasks + "m+" + numReduceTasks + "r tasks (" + dataInputLength + " input bytes) will run sequentially on single node.
[DEBUG]:Key written and counter incremented
[TRACE]:<*>: loaded block iterator for <*>.
[INFO]:Killed application <*>
[WARN]:Failed to connect to <*> with <*> map outputs
[DEBUG]:Resetting capacity with ignoreGuar set to true
[INFO]:Detected a loopback TCP socket, disconnecting it
[WARN]:Failed to connect to: <*>
[WARN]:Host list file <*> does not exist or is not a file !!
[DEBUG]:computePacketChunkSize: src=<*>, chunkSize=<*>, chunksPerPacket=<*>, packetSize=<*>
[DEBUG]:Setting default node label expression : <*>
[INFO]:Timeline Server Overview
[WARN]:Log warning as the lock was held for too long
[INFO]:FAIL: value, StringUtils.stringifyException(e)
[INFO]:Successfully add estimated resource allocation for <*>.
[INFO]:The configurated fileControllers:
[INFO]:Image Transfer timeout configured to + timeout + milliseconds
[INFO]:Relaunching Container <*>. remaining retry attempts(after relaunch) <*>, retry interval <*> ms
[ERROR]:Unable to set exit code for container
[DEBUG]:Sync a new collector address: <*> for application: <*> from RM
[WARN]:s3a: <*> capped to ~2.14GB (maximum allowed size with current output mechanism)
[DEBUG]:StatusUpdater thread exiting since it got interrupted
[INFO]:SmapBasedCumulativeRssmem (bytes) : total
[WARN]:nMaps == 1. Why use DynamicInputFormat?
[INFO]:IS_RELATED_TO field filter added
[DEBUG]:shuffle for jobId reducer reduce length contentLength
[INFO]:fetcher# + id + - MergeManager returned Status.WAIT ...
[ERROR]:Trying to get queue of an absent application
[ERROR]:Exception during DirectoryScanner execution - will continue next cycle
[ERROR]:Unable to locate user for + appId
[INFO]:Allocated <*> as opportunistic at location <*>
[INFO]:Num retry attempts <*>
[INFO]:Accepted application <*> from user <*>.
[INFO]:Persisted service <*> at <*>
[DEBUG]:Loading service definition from FS: <*>
[INFO]:Rebooted Nodes: countHere
[WARN]:Error unregistering <*>
[WARN]:Could not locate <*> - skipping
[DEBUG]:Started Registry operations in realm <*>
[ERROR]:got IOException while trying to validate header of + elf + . Skipping., e
[DEBUG]:Process perfectOverWrite
[INFO]:BLOCK* registerDatanode: from ...
[WARN]:Unable to cleanup temp files
[WARN]:Unable to determine input streams from + jas.getManager() + . Skipping.
[INFO]:<*> is now runnable in <*>
[DEBUG]:Auxiliary service already loaded: <*>
[INFO]:rmId + failed to transition to active, giving up leadership, e
[INFO]:Did not cancel + t
[INFO]:Created symlink: linkFile -> rsrcEvent.getLocation()
[INFO]:The requested number of containers have been allocated. Releasing the extra container allocation from the RM.
[TRACE]:Receipt verification is not enabled on the DataNode. Not verifying slotId
[INFO]:onContainersUpdated: ...
[INFO]:START REPLAY @ <*>
[INFO]:Namenode actor relinquishing ACTIVE state with txid= nnHaState.getTxId()
[DEBUG]:Decaying costs for the user: ..., its decayedCost: ..., rawCost: ...;
[INFO]:f + ": Failed to open at " + rNode.getFs().getUri()
[DEBUG]:scheduleLogDeletionTask
[TRACE]:closed <*><*> this suffix
[DEBUG]:allocate: post-update applicationId=applicationAttemptId application=application
[WARN]:<*> is corrupt but has no associated node.
[INFO]:DistCp job-id: + jobID
[WARN]:Map ID + mapId + not found in queue!!
[WARN]:Cannot retrieve S3_ENCRYPTION_KEY for bucket <*>
[INFO]:Whitelisted non-jar /path/to/jar
[INFO]:Retry cache on namenode is enabled
[WARN]:ApplicationMaster is out of sync with ResourceManager, hence resyncing.
[DEBUG]:Updating token #
[DEBUG]:Volumes are imbalanced. Selecting volume from low available space volumes for write of block size replicaSize
[INFO]:logRpcIds executed
[ERROR]:Failing over to edit log...
[WARN]:Could not set last modified time for <*> file(s)
[TRACE]:<*>: isFile('<*>'), getName(), path
[DEBUG]:ACL not found for application <*> owned by <*>. Using default <*>
[DEBUG]:Block <*>: cannot be found in block manager and hence skipped from calculation for node <*>.
[DEBUG]:Loading <*>.
[DEBUG]:FsPathBooleanRunner is running
[INFO]:<*> (<*>) failure
[TRACE]:Entering createKey Method.
[INFO]:Application should be expired, max number of completed apps kept in memory met: maxCompletedAppsInMemory = <*>, removing app <*> from memory.
[ERROR]:<*> has not been deleted.
[INFO]:Queue metrics initialized
[WARN]:Received unknown event-type <*>. Ignoring.
[DEBUG]:Page blob directories: <*>
[INFO]:<*>: Job Commit statistics <*>, committerConfig.getName(), ioStatisticsToPrettyString(iostatistics)
[WARN]:Caught exception while adding replicas from + volume + in subtask. Will throw later.
[WARN]:IOException in LifelineSender for + BPServiceActor.this
[ERROR]:Cannot open write stream for record <*>, <*>
[INFO]:The machine list file path is not specified in the configuration
[INFO]:Splitting using FloatSplitter
[WARN]:<*>: failed to load block iterator.
[INFO]:Requesting Amazon STS Session credentials
[ERROR]:ShutdownHookManager shutdown forcefully after <*> seconds.
[WARN]:Node is out of sync with ResourceManager, hence resyncing.
[WARN]:Problem getting block size
[INFO]:Down to the last merge-pass, with segments left
[ERROR]:: Invalid event <*> at <*>, <*>
[INFO]:All containers in DONE state
[DEBUG]:SASL encryption trust check: localHostTrusted = <*>, remoteHostTrusted = <*>
[INFO]:addCachePool of <*> failed: <*>
[INFO]:<*> filter <*>
[ERROR]:Error when executing command.
[DEBUG]:Deleting entity type:<*> id:<*> primary filter entry <*> <*>
[DEBUG]:Write to <*> failed
[INFO]:Could not get container creation time, using current time
[WARN]:Unknown DatanodeCommand action: ...
[ERROR]:Cannot get method <*> with types <*> from <*>
[WARN]:Expected split length of sysInfo to be 11. Got ...
[ERROR]:Unexpected event for REDUCE task <*>
[INFO]:Job ended: end_time
[DEBUG]:Exception in removeRenewAction: <*>
[ERROR]:Received event
[DEBUG]:ResourceRequest: resource = <*>, locality = <*>
[DEBUG]:Adding source dir for traverse: sourceStatus.getPath()
[INFO]:Thread.currentThread().getName() caught an exception
[DEBUG]:Disk file: File Length is L
[INFO]:Cleaning up history files
[ERROR]:Bootstrap + resourceName + failed. Null value got from plugin's getDevices method
[INFO]:Parsing entry: str
[DEBUG]:Using Regex match for 'host' and READ_ONLY
[INFO]:Starting full compaction cycle
[DEBUG]:Failure to retrieve storage account key for accountName, e
[INFO]:Processing batched re-encryption for zone <*>, batch size <*>, start:<*>, zoneNodeId, batch.size(), batch.getFirstFilePath()
[ERROR]:Audit Constant $<*> is not recognized.
[DEBUG]:NetworkTopology became:\n<*>
[INFO]:Container <*> not launched. No cleanup needed to be done
[ERROR]:Allocated empty container + rmContainer.getContainerId()
[INFO]:Initializing NodeSortingService= <*>
[WARN]:Invalid key name '<*>'
[INFO]:Snapshot diff report generated
[ERROR]:Cannot initialize the ZK connection, e
[DEBUG]:pre-assignContainers for application + getApplicationId()
[WARN]:Finish information is missing for application attempt
[WARN]:User + remoteUser + is unauthorized to access the page + request.getRequestURI() + .
[INFO]:Node label store recover is completed
[ERROR]:Unsupported protocol found when creating the proxy connection to ResourceManager: ...
[DEBUG]:Task complete
[TRACE]:Retrieval of slow peer report is disabled. To enable it, please enable config <*>.
[WARN]:WARNING: cannot delete file + f.getAbsolutePath()
[DEBUG]:Couldn't create proxy provider null
[DEBUG]:User rule: parent rule found: <*>
[INFO]:Pmem enforcement enabled
[DEBUG]:Received nodePublishVolume call, request: <*>
[INFO]:Processing volume event, type=EVENT_TYPE, volumeId=VOLUME_ID
[WARN]:Failed to cache the block <*>!
[ERROR]:Exception occurred while fetching applications
[INFO]:Task failed <*>
[WARN]:Request to start an already existing appId was received. This can happen if an application failed and a new attempt was created on this machine. ApplicationId: applicationAttemptId.toString()
[INFO]:UserGroupInformation set with configuration
[INFO]:Add token with service alias
[DEBUG]:Returning '<*>' for key: <*>
[DEBUG]:Error reading the contents of <*>
[WARN]:Unexpectedly low genstamp on <*>.
[WARN]:-principal and -keytab not both specified! Kerberos login not attempted.
[DEBUG]:NFS SETATTR fileHandle: <*> client: <*>
[WARN]:Workload job failed.
[INFO]:CostProvider not specified, defaulting to DefaultCostProvider
[WARN]:The created archive " + harName + " is missing or empty.
[INFO]:Processed URL + url + but encountered exception (Took + (endTime - startTime) + ms.)
[DEBUG]:Event received with stale zk
[INFO]:Created reservation <*> synchronously., reservationId
[TRACE]:org.apache.hadoop.io.retry.RetryInvocationHandler$Call@instance
[DEBUG]:Rolling secret
[INFO]:Queues refreshed
[INFO]:Type-specific cleanup of application <*> of type <*> succeeded
[ERROR]:This is a rare failure scenario!!!
[INFO]:Elastic memory control enabled: <*>
[DEBUG]:Container Status: id= + containerId + , status= + containerStatus
[DEBUG]:setZooKeeperRef called
[INFO]:Node Managers started
[WARN]:Failed to wipe tc state. This could happen if the interface is already in its default state. Ignoring.
[DEBUG]:<*>: removing partition path to be replaced:
[WARN]:this sd not available:
[WARN]:Lock held time above threshold(%d ms): lock identifier: %s lockHeldTimeMs=%d ms. Suppressed %d lock warnings. Longest suppressed LockHeldTimeMs=%d. The stack trace is: %s
[INFO]:Deactivation request received for active volume: <*>
[INFO]:Received URL <*> from user <*>
[ERROR]:Cannot get remote user: <*>
[INFO]:Fetching task diagnostics
[WARN]:IOException caught when re-encrypting zone <*>
[INFO]:Scheduling a check for <*>, target
[DEBUG]:NFS PATHCONF fileHandle: <*> client: <*>
[INFO]:Dispatching event for app attempt
[DEBUG]:Interrupted waiting for peers to close
[DEBUG]:Queueing Datanode <*> for block report; numBlocks = numBlocks
[ERROR]:Unable to create default file context <*>, e
[INFO]:Timeline services health check: timeline reader reported connection failure
[DEBUG]:AADToken: fetched token with expiry <*>, expiresOn passed: <*>
[DEBUG]:Returning; either check access is not enabled or the account used is not namespace enabled
[INFO]:Adding ShuffleProvider Service: <*> to serviceData
[DEBUG]:Retrieved '<*>' as owner for path - <*>
[INFO]:<*>: directory <*> contained <*> file(s); data size <*>, getName(), taskAttemptDir, fileCount, fileDataSize
[INFO]:Recovering storage directory <*> from previous rollback
[DEBUG]:REQ HEADER: <*> : <*>
[INFO]:The application <*> was not inserted in the StateStore because it was already present in SubCluster <*>
[ERROR]:Unable to remove token tokenId.getSequenceNumber(), e
[DEBUG]:Creating splits at submitJobDir
[INFO]:"Client <*> did not send a valid status code after reading. Will close connection.", peer.getRemoteAddressString()
[DEBUG]:Failure to load login credentials
[TRACE]:getSubdirEntries(<*>, <*>): listed <*> entries in <*>
[ERROR]:Error While Removing RMDTMasterKey., e
[INFO]:Service def state changed from <*> -> <*>
[INFO]:Stopping BPOfferServices for nameservices: ...
[INFO]:Deleting application + removeAppId + from state store
[INFO]:Directory markers will be kept
[DEBUG]:NameNode <*> threw StandbyException when fetching HAState
[DEBUG]:Response temporary redirect configured
[DEBUG]:Summary directory set to <*>
[WARN]:<*> limit has been reached, re-queueing <*> nodes which are dead while in Decommission In Progress., DFSConfigKeys.DFS_NAMENODE_DECOMMISSION_MAX_CONCURRENT_TRACKED_NODES, numUnhealthyNodesToRequeue
[DEBUG]:Active scan complete
[WARN]:resourceName + plugin failed to discover resource ( null value got).
[DEBUG]:BLOCK* prepareFileForTruncate: <*> Scheduling in-place block truncate to new size <*>
[DEBUG]:CSConf - getCapacityOfLabel: prefix= + getNodeLabelPrefix(queue, label) + , capacity= + capacity
[INFO]:Service added
[WARN]:"Could not carry out resource dir checks for " + localDir + ", which was marked as good"
[INFO]:Job received Kill in INITED state.
[DEBUG]:Listing beans for + qry
[DEBUG]:LazyWriter schedule async task to persist RamDisk block pool id: + bpId + block id: + blockId
[INFO]:Available Nodes: countHere
[INFO]:<*> Transitioned from <*> to <*> on <*> event., componentSpec.getName(), oldState, getState(), event.getType()
[INFO]:Configuration script appended
[ERROR]:XAttrs not supported on at least one file system: , <*>
[DEBUG]:saveCacheManagerSection completed
[TRACE]:this: NotificationHandler: read succeeded on sock.fd
[DEBUG]:instanceIOStatistics=<*>
[DEBUG]:Copied srcReplica.getBlockURI() to dstFile
[DEBUG]:addSpillIndexFileCB... Path: <*>
[DEBUG]:openFileForWrite filesystem:<*> path:<*> overwrite:<*>, client.getFileSystem(), path, overwrite
[WARN]:Skipping inaccessible cgroup mount point <*>
[INFO]:Context Path = <*>
[WARN]:service.getName()'s keytab (principalName = principalName) doesn't exist at: keytabOnhdfs
[DEBUG]:Fetched token <*> for <*> into <*>
[INFO]:The job-jar file on the remote FS is ...
[DEBUG]:Path: <*> is a directory. COS key: <*>
[ERROR]:Error adding replica to map
[DEBUG]:Error
[DEBUG]:setPermission filesystem: <*> path: <*> permission: <*>
[ERROR]:Node Labels <*> reported from NM with ID <*> was rejected from RM with exception message as: <*>
[DEBUG]:Processed cache report from <*>, blocks: <*>, processing time: <*> msecs
[INFO]:Unchecked exception is thrown from onContainerStatusReceived for Container <*>
[DEBUG]:Application attempt + getApplicationAttemptId() + reserved container + rmContainer + on node + node + . This attempt currently has + reservedContainers.size() + reserved containers at priority + schedulerKey.getPriority() + ; currentReservation + reservedResource
[DEBUG]:No configuration: skipping check for fs.<*>.impl
[ERROR]:Unable to store master key for application + attempt
[DEBUG]:Using default scheduler. Allowed: + allowed + ,Used: + used + , containerId: + containerId
[WARN]:interrupted when wait copies to finish
[ERROR]:Couldn't transition <*> to standby state
[WARN]:Invalid tagName: <*>
[WARN]:Failed to get snapshottable directories. Ignore and continue.
[ERROR]:e.getMessage(), e
[DEBUG]:Resubmitting application
[WARN]:No rule was found for user '<*>'
[WARN]:Fail to find inode + id + when saving the leases.
[INFO]:AMRMTokenKeyRollingInterval: this.rollingInterval ms and AMRMTokenKeyActivationDelay: this.activationDelay ms
[DEBUG]:Initializing RemoteSASKeyGeneratorImpl instance
[INFO]:Stopping rpcProxy in InMemoryAliasMapProtocolClientSideTranslatorPB
[INFO]:Unset storage policy <*>
[DEBUG]:Updating SPS service status, current mode:<*>, new mode:<*>
[DEBUG]:Sending signal to pid <*> as user <*> for container <*>
[DEBUG]:Acquired locations for path
[DEBUG]:DRConf - setMemoryPerNode: nodePrefix=<*>, memory=<*>
[DEBUG]:Normalizing source path
[DEBUG]:xResponse.getResponseInfo().toString()
[DEBUG]:Path <*> is a folder.
[INFO]:Starting recovery of GpuDevice for <*>.
[INFO]:key = v (default=defaultValue)
[INFO]:sumPageview= <*>
[WARN]:I/O error attempting to unlock storage directory <*>.
[DEBUG]:Try refresh logs for <*>
[DEBUG]:String.format(STATE_CHANGE_MESSAGE, appAttemptID, oldState, getAppAttemptState(), event.getType())
[DEBUG]:listFiles(<*>, <*>)
[DEBUG]:Allocated to <*>: <*>
[INFO]:modifyDirective of <*> successfully applied <*>.
[DEBUG]:Resource handler chain enabled = <*>
[INFO]:Succeed in finding FPGA discoverer executable: executable
[INFO]:Application report retrieved and AppInfo created
[DEBUG]:removeAcl filesystem: <*> path: <*>
[WARN]:Removing non-existent lease! holder=<*> src=<*>
[DEBUG]:BLOCK* getAdditionalBlock: <*> inodeId <*> for <*>
[DEBUG]:Getting key with version name <*>.
[INFO]:Disabling StoragePolicySatisfier, mode:<*>
[INFO]:Save namespace ...
[INFO]:Checksum JSON location response
[DEBUG]:Native call failed
[DEBUG]:Completed upload of <*> to part <*>
[DEBUG]:AzureBlobFileSystem.rename src: <*> dst: <*>
[ERROR]:Shuffle error :
[INFO]:Skip searching, the nvidia gpu binary is already set: pathOfGpuBinary
[INFO]:Processing the event JOB_SETUP
[DEBUG]:delete: <*> <*>, (isFile ? "file" : "dir marker"), key
[DEBUG]:Using match all for 'host' and READ_WRITE
[INFO]:DatanodeCommand action from standby NN <*>: DNA_ACCESSKEYUPDATE
[DEBUG]:InterruptedException in block key updater thread
[WARN]:Currently creating proxy using LossyRetryInvocationHandler requires NN HA setup
[DEBUG]:writing more data than block has capacity -triggering upload
[ERROR]:Failed to get the response from the timeline server.
[ERROR]:Registration failure with <*>:<*>, portmap entry: <*>
[ERROR]:Index file for the log of taskid doesn't exist.
[DEBUG]:RPC ids logged with op
[DEBUG]:Resolved hostName to rackName
[INFO]:Generated new cluster id: <*>
[INFO]:Epoch set for Federation: + epoch
[DEBUG]:Registering Custom Signer - <*>
[INFO]:Successfully synced BackupNode with NameNode at txnid ...
[INFO]:Replacing block
[ERROR]:YarnException(msg)
[INFO]:Ignoring same directory link %s to %s
[DEBUG]:Created instance for key <*>: <*> overwritten by <*>, key, strongRef, resolvedStrongRef
[INFO]:Failed to createOutputCommitter
[WARN]:Move Application has failed: errorMessage
[DEBUG]:Trying to allocate from reserved container in async scheduling mode
[DEBUG]:Submitted a shutdown request to datanode
[ERROR]:Error getting entity timelines
[DEBUG]:Updated last update time
[DEBUG]:Queue: <*> responseTime: <*> backoffThreshold: <*>
[DEBUG]:End of the phase: <*>
[DEBUG]:Shutting down Router metrics
[INFO]:Enabled protocols: <*>
[ERROR]:Exception while selecting input streams
[WARN]:Failed to launch container.
[INFO]:Resolving file system path
[WARN]:Failed to upgrade storage directory <*>
[DEBUG]:Connecting to datanode <*>
[INFO]:Error when parsing local resource URI for upgrade of Container <*>
[DEBUG]:App-level real-time aggregating
[DEBUG]:<*> corruption detected! Child nodes are missing.
[WARN]:Waiting to remove IN_INTERMEDIATE state histories (e.g. firstInIntermediateKey) from JobListCache because it is not in done yet. Total count is inIntermediateCount.
[INFO]:received TCP query <*>
[INFO]:Finished spill 0
[DEBUG]:ExactMatcher ' + ipOrHost + ', allowing client ' + address + ', ' + hostname
[WARN]:Configuration ... is overriding the ... configuration
[DEBUG]:protocol doesn't use kerberos
[ERROR]:Error starting NodeManager
[INFO]:Instantiating AHSWebApp at <*>
[INFO]:Storing RMDTMasterKey.
[WARN]:Failed to connect to <*>: <*>
[DEBUG]:Checksum loaded and data length set
[INFO]:Stored the start data of application attempt <*>
[WARN]:AsyncDiskService awaitTermination timeout.
[INFO]:Set the environment for the application master
[ERROR]:Fail to flex application: , e
[INFO]:Loaded + numKeys + master keys and + numTokens + tokens from + tokenStatePath
[ERROR]:Error when writing finish information of application attempt + appAttemptFinish.getApplicationAttemptId(), e
[WARN]:I/O error finding interface <*>: <*>
[WARN]:forceExit used when normal exist would suffice. Treating force exit as normal safe mode exit.
[DEBUG]:<*> does not allow retrying a failed subcluster
[DEBUG]:Replica is finalized!
[DEBUG]:Prepared token for write: <*>
[ERROR]:Query plan failed. ex: <*>, ex
[INFO]:Recovery started
[ERROR]:Unable to load DataNode plugins. Specified list of plugins: <*>
[INFO]:queueName, capacity=..., absoluteCapacity=..., maxCapacity=..., absoluteMaxCapacity=..., state=..., acls=..., labels=..., reservationsContinueLooking=..., orderingPolicy=..., priority=...
[ERROR]:Error while removing reservation allocation. e
[INFO]:Connecting to ZooKeeper with SASL/Kerberos and using 'sasl' ACLs
[WARN]:Exception while notifying listeners of <*>
[INFO]:Compressing tarball
[INFO]:Creating secret znode
[WARN]:this + ": failed to munmap", e
[INFO]:Filter initializers set for timeline service: + actualInitializers
[DEBUG]:Queueing upload of <*> for upload <*>
[TRACE]:To delete unnecessary fake directory <*> for <*>
[DEBUG]:Creating DataFactory of type : <*>
[DEBUG]:task statistics\n<*>
[INFO]:Temporary redirect for checksum
[ERROR]:Failed to parse file fileName
[INFO]:Loaded FSImage in <*> seconds.
[INFO]:Removing RMDelegationToken_<*>
[WARN]:Failed to resolve address: $<*>. Continuing to use the same.
[INFO]:Delegation token not available for renewal for app + appCollector.getTimelineEntityContext().getAppId()
[INFO]:Trying to initialize the next record reader
[INFO]:Using leveldb path <*>
[INFO]:DELETE: deleteService for appName = <*> user = <*>
[INFO]:Partial read. Asked offset: <*> count: <*> and read back: <*> file size: <*>
[INFO]:Not attempting to recover. Intermediate spill encryption is enabled.
[DEBUG]:Class <*> is not a CryptoCodec.
[ERROR]:Error in handling event type <*> for applicationAttempt <*>
[INFO]:createSuccessLog(user, operation, target, null, null)
[WARN]:Ignoring unexpected file in active directory <*>
[DEBUG]:Try to update docker run command for
[DEBUG]:Interrupted while sleeping in exponential backoff.
[WARN]:Failed to get Operating System name. + Exception
[ERROR]:Connecting to namenode via <*>
[DEBUG]:<*> <*>
[WARN]:No Output found for <*>
[INFO]:Replica Cache file: path cannot be deleted
[WARN]:Ignoring Blacklists, blacklist size currentBlacklistSize is more than failure threshold ratio blacklistDisableFailureThreshold out of total usable nodes numberOfNodeManagerHosts
[DEBUG]:Exception while invoking call #callId proxyDescriptor.getProxyInfo().getString(method.getName()). Not retrying because retryInfo.action.reason
[ERROR]:createBlobClient is an invalid operation in SAS Key Mode
[DEBUG]:Will collect peer metrics for downstream node <*>
[DEBUG]:scheme : <*>
[INFO]:Set <*> to false since <*> is passed.
[WARN]:Failed to pass FPGA devices diagnose
[INFO]:Total time to scan all replicas for block pool <*>: <*>ms
[DEBUG]:Retrieved etag of source for rename recovery: <*>; isDir=<*>
[INFO]:Initialized readable endpoints
[ERROR]:Error creating user intermediate history done directory
[TRACE]:Reference count: + op + this +: + this.reference.getReferenceCount()
[INFO]:deleted public resource dir <*>, publicResourceDir
[INFO]:Packet queued
[INFO]:ContainerId=..., docker exec output for ...: ...
[DEBUG]:Cleaning up with logger
[INFO]:<*>: starting
[INFO]:Finalize service <*> upgrade
[INFO]:Roll Edit Log from <*>
[DEBUG]:AFTER decResourceRequest: applicationId= applicationId.getId() priority= priority.getPriority() resourceName= resourceName numContainers= remoteRequest.getNumContainers() #asks= ask.size()
[DEBUG]:current user violates sticky bit check
[INFO]:But old node has our own data, so don't need to fence it.
[DEBUG]:Using default data node port : <*>
[INFO]:Removing reservationallocation + reservationIdName + for plan + planName
[ERROR]:It appears that another node <*> has already locked the storage directory: <*>
[WARN]:Commit failure for job <*>
[DEBUG]:Trying to delete + context.fullPath
[DEBUG]:pull docker image done with <*>ms specnt. image name: <*>, container: <*>
[DEBUG]:Scanned <*> inodes.
[WARN]:Failed to commit upload against unknown destination, described in <*>: <*>
[WARN]:message
[WARN]:Block group <*> failed to write <*> blocks. It's at high risk of losing data.
[WARN]:Exception occurs when retrieve the block range start: <*> end: <*>
[INFO]:Enabled trash for bpid <*>
[DEBUG]:Error when checking for application status
[WARN]:error stopping existing instance: <*>
[DEBUG]:Skipping existence/overwrite checks
[INFO]:totalPageview= <*>
[WARN]:Periodic block scanner is not running
[INFO]:Closing log reader
[INFO]:Wrote VERSION in the new storage, <*>
[DEBUG]:Setting property <*> with value <*>, property, value
[INFO]:removed attempt + attemptID + from the futures to keep track of
[ERROR]:The subnet or mask is invalid: Subnet: <*> Mask: <*>
[INFO]:Re-encryption completed on zone <*>. Re-encrypted <*> files, failures encountered: <*>.
[DEBUG]:Adding trackID:<*> for the file id:<*> back to retry queue as none of the blocks found its eligible targets.
[DEBUG]:Distributed Node Attributes is enabled with provider class as : ScriptBasedNodeAttributesProvider
[WARN]:Got a repeated request, same range, with a different xid: <*> xid in old request: <*>
[INFO]:loadDataStorage: <*> upgrade tasks
[DEBUG]:Validating component name format
[INFO]:Retrieved locations for path
[ERROR]:Unsupported protocol found when creating the proxy connection to ResourceManager:
[DEBUG]:Setting value for resource type <*> to <*> with units <*>
[DEBUG]:Loaded <*> tokens from <*>
[DEBUG]:ignoring seek to current position.
[TRACE]:<*> invoked by user <*>
[WARN]:<*> must be at least 100 KB; configured value is <*>
[WARN]:Error executing shell command $<*>
[WARN]:Unresolved link encountered
[INFO]:Finalizing upgrade for journal + storage.getRoot() + . + (storage.getLayoutVersion() == 0 ? : \n cur LV = + storage.getLayoutVersion() + ; cur CTime = + storage.getCTime())
[ERROR]:Cannot create base directories:
[INFO]:Invalid table name provided.
[WARN]:Failed to add storage directory <*> for block pool <*>
[DEBUG]:Unexpected node state
[DEBUG]:Request execution in progress
[WARN]:All active and enabled subclusters have expired last heartbeat time. Ignore the expiry check for this request
[INFO]:<*> nothing to cancel
[ERROR]:All of your job<*> have the same submit time. Please just use your input file.
[INFO]:the collector for + appId + was added
[INFO]:Dominate component <*> finished, exiting Service Master... , final status= <*>
[WARN]:Error while reading
[DEBUG]:DELETED <*>
[ERROR]:BUG: Found lastValidNode <*> but not nth valid node. parentNode=<*>, excludedScopeNode=<*>, excludedNodes=<*>, totalInScopeNodes=<*>, availableNodes=<*>, nthValidToReturn=<*>
[DEBUG]:deleteFilesystem for filesystem: <*>
[INFO]:Registering <*>
[WARN]:NameNode low on available disk space. Entering safe mode.
[DEBUG]:*DIR* NameNode.create: file <*> for <*> at <*>
[DEBUG]:<*>: CACHE MISS: <*>
[WARN]:Can't create trash directory: ...
[ERROR]:Error:
[WARN]:The process vanished in the interim!
[INFO]:Attempting to get socket address for target.
[INFO]:Finish information of application + appFinish.getApplicationId() + is written
[INFO]:Recovering task + taskId + from prior app attempt, status was + taskInfo.getTaskStatus()
[DEBUG]:Rename operation failed.
[ERROR]:<*>: Stage <*> failed: after <*>: <*>, getName(), stageName, OperationDuration.humanTime(stageExecutionTracker.asDuration().toMillis()), e.toString()
[INFO]:Scanning service definitions for user <*>.
[INFO]:Stopping services started for <*> state
[DEBUG]:Swap cgroups monitoring is not compiled into the kernel <*>
[INFO]:Will not renew token <*>
[INFO]:Success log for user-induced failure
[INFO]:Phase initialized for map (100%)
[DEBUG]:Setup Job %s
[INFO]:found resource + name + at + url
[DEBUG]:NS_INFO writing header: <*>
[INFO]:Loaded profiles: profiles.keySet()
[DEBUG]:here setUserLimit: queuePrefix=<*>, userLimit=<*>
[INFO]:Requested node-label-expression is invalid.
[INFO]:Refresh user to groups mapping successful for address
[DEBUG]:UGI: <*>
[INFO]:Delayed Deletion Thread Interrupted. Shutting it down
[ERROR]:Failed to close provider., e
[ERROR]:The property MR_HISTORY_LOADED_TASKS_CACHE_SIZE is not an integer value. Please set it to a positive integer value.
[DEBUG]:Creating RMProxy instance
[DEBUG]:Initialized application resources
[DEBUG]:Failing attempt with id: attId
[ERROR]:FATAL: Queue named queueName missing during application recovery. Queue removal during recovery is not presently supported by the capacity scheduler, please restart with all queues configured which were present before shutdown/restart.
[WARN]:Property <*> has a value <*>, but is not a valid file
[INFO]:Storing timeline store version info
[ERROR]:Unable to remove application + appAttemptRemovedEvent.getApplicationAttemptID(), ie
[DEBUG]:Resolving SASL properties for <*> <*>
[INFO]:Killing container ...
[DEBUG]:Returning success response from append blob idempotency code
[DEBUG]:Loading using Protobuf Loader
[INFO]:Killed infrastructure app
[INFO]:Updating Configuration
[INFO]:Invoking getTaskAttemptCompletionEvents
[INFO]:Added file for localization: symlink -> localResource.getResource().getFile(), dest mount path: destFile
[DEBUG]:using ' + file + ' for output stream.
[WARN]:Graceful stop failed. Exiting..
[DEBUG]:Skipping volume. Volume : %s Type : %s Target Number of bytes : %f lowVolume dfsUsed : %d. Skipping this volume from all future balancing calls.
[WARN]:(warning message placeholder)
[INFO]:Recovering persistent memory cache for block <*>, path = <*>, address = <*>, length = <*>
[ERROR]:Container end event could not be published for ...
[ERROR]:System.err.println(AdminHelper.prettifyException(e))
[INFO]:Stopping Router ClientRMService
[INFO]:Rollback aborted.
[WARN]:Removing lazyPersist file <*> with no replicas.
[ERROR]:Cannot initialize record store for simpleName
[ERROR]:NM node attributes <*> were not accepted by RM and message from RM :
[DEBUG]:Storage policy is not enabled, ignoring
[WARN]:checkAllVolumesAsync - no volumes can be referenced
[DEBUG]:Successfully cached <*>. We are now caching <*> bytes in total.
[TRACE]:Rename source queryparam added <*>
[WARN]:Periodic Directory Tree Verification scan is disabled because verification is turned off by configuration
[INFO]:Container <*> not paused as resume already called
[WARN]:modifyDirective of <*> failed: <*>
[DEBUG]:Exception caught, ignoring node:<*>.
[INFO]:clearing userToGroupsMap cache
[INFO]:Initialized queues with configuration
[WARN]:Interrupted while trying to fence via ssh
[WARN]:failed to stop the flusher task in time. will still proceed to close the writer.
[DEBUG]:logEdit <*>
[INFO]:specToString()
[INFO]:ZK Election indicated that <*> should become standby
[DEBUG]:Server accepts auth methods:<*>
[INFO]:GET
[ERROR]:Received + event
[WARN]:NameNode low on available disk space. Already in safe mode.
[INFO]:Application report fetched from AHS
[INFO]:Starting to load key cache.
[INFO]:Waiting for containers to be killed
[ERROR]:Error closing KeyProviderCryptoExtension, ioe
[DEBUG]:Block recovery: DataNode: <*> does not have replica for block: <*>
[DEBUG]:Did not load hdfs image to hash file, file doesn't exist
[DEBUG]:Try to schedule ... using ...
[TRACE]:read(arr.length=<*>, off=<*>, len=<*>, filename=<*>, block=<*>, canSkipChecksum=<*>): returning <*>
[WARN]:Node Labels script timed out, Caught exception : + e.getMessage(), e
[DEBUG]:Write failure
[DEBUG]:Ping from + taskAttemptID.toString()
[DEBUG]:Generating runtime spec for allocated devices: <*>, <*>
[INFO]:Aborting commit ID <*> to object <*><*>, uploadId, destKey, origin
[INFO]:All component finished, exiting Service Master... , final status=Succeeded
[DEBUG]:DataNode <*> was requested to be excluded, but it was not found.
[DEBUG]:Creating NameNode connector
[DEBUG]:Converting from proto format
[DEBUG]:getSpillFileCB... access incorrect position.. Path <*>; Pos: <*>
[INFO]:Successfully got block locations
[INFO]:Priority ' + appPriority.getPriority() + ' is acceptable in queue : + queuePath + for application: + applicationId
[TRACE]:Connected to ApplicationMaster at: + serviceAddr
[INFO]:keyName has not been created.
[DEBUG]:Checking if component is stable ]]>
[DEBUG]:To-release container=<*> is in final state
[INFO]:Existing Working Dir detected: - FORCE_OPTION not specified -> exiting
[INFO]:Removing info for app: + appId + at: + nodeRemovePath
[INFO]:Default Metrics System initialized
[DEBUG]:User <*> NN <*> is using connection <*>
[DEBUG]:Handshake secret is null, sending without handshake secret.
[DEBUG]:Cleaning up work path <*>
[DEBUG]:Filesystem <*> is using delegation tokens of kind <*>, getCanonicalUri(), tokenBindingName
[DEBUG]:Fetcher ID going to fetch from host for: maps
[DEBUG]:Scan complete: shutting down
[INFO]:Added global filter ' + name + ' (class= + classname + )
[INFO]:Stopping Router RMAdminService
[ERROR]:interrupted while waiting for masterThread to terminate, e
[TRACE]:Removed BR lease 0x<*> for DN <*>. numPending = <*>
[INFO]:Successfully query resource skylines for <*>.
[ERROR]:Error communicating with RM: + e.getMessage(), e
[DEBUG]:Cannot get remote user: <*>
[INFO]:Adding <*> to recently stopped containers
[INFO]:Got finalize command for block pool ...
[WARN]:cleanup keys with prefix + FINISHED_APPS_KEY_PREFIX + from leveldb failed
[WARN]:Failed to discover GPU information from system, exception message: ... continue...
[INFO]:Roll back resource for container + containerId
[DEBUG]:Commit done: x
[DEBUG]:Initialising new rule set
[INFO]:Preempting <*>
[ERROR]:Received a container with following resources suited for a DataNode but no NameNode container exists: containerMem= + rsrc.getMemorySize() + , containerVcores= + rsrc.getVirtualCores()
[INFO]:Checked <*> blocks this tick. <*> nodes are now in maintenance or transitioning state. <*> nodes pending. <*> nodes waiting to be cancelled.
[ERROR]:Failed to parse XML output of GPU_SCRIPT_REFERENCE!
[ERROR]:Fatal error caught by connection creator
[WARN]:Error creating sink '%s'
[INFO]:Starting decommission of <*> <*> with <*> blocks
[DEBUG]:Skipping compute move. lowVolume: <*>, highVolume: <*>
[INFO]:Initializing request processing pipeline for user: <*>
[DEBUG]:Found existing $<*> servlet at path $<*>; will replace mapping with $<*> servlet
[INFO]:Rolling key version from KeyProvider: provider
[INFO]:Possible loss of precision converting <*><*> to <*> for <*>
[INFO]:Refreshing SuperUser proxy group mapping list
[DEBUG]:Overwriting file <*>
[ERROR]:Exception logged from logContainerLogs: (ex.getMessage())
[DEBUG]:BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for <*> to add as corrupt on <*> by <*> <*>
[ERROR]:GPU is enabled on the NodeManager, but couldn't find any usable GPU devices, please double check configuration!
[DEBUG]:newEpoch(<*>) responses:\n<*>
[INFO]:Scheduled Metric snapshot period at <*> second(s).
[DEBUG]:logEdit called
[ERROR]:No cost table initialized!
[INFO]:Infra app was killed; exiting from client.
[WARN]:e.getCause().getMessage()
[INFO]:File closed: <*>
[WARN]:Failed to rename the local file under <*>/<*>
[DEBUG]:attribute + : + a
[DEBUG]:DIR* NameSystem.appendFile: src=<*>, holder=<*>, clientMachine=<*>
[ERROR]:Disk Balancer - Internal Error.
[INFO]:transitionToActive: Node is already active
[DEBUG]:Generating block token for +
[DEBUG]:get commit while still writing to the requested offset, + with empty queue
[INFO]:Found numEntries files: processing for one resource per key
[DEBUG]:checkDiskErrorAsync: no volume failures detected
[WARN]:If other tasks/jobs are writing to <*>, this action may cause them to fail
[INFO]:Using explicitly defined FAIR_SCHEDULER_XML
[DEBUG]:allocate: applicationAttemptId=... container=... host=... type=...
[INFO]:Cannot get delegation token from <*>
[DEBUG]:Deprecation logged for oldName with provider
[DEBUG]:Found <*> as an explicit blob. Checking if it's a file or folder.
[INFO]:RM proxy-user privilege is not enabled. Skip requesting hdfs tokens.
[INFO]:Application Masters started
[DEBUG]:Application state data size for <*> is <*>
[INFO]:Task assigned to chunk
[INFO]:Decommissioning complete for node <*>
[INFO]:Parsing Placement Specs: <*>
[INFO]:NNTop conf: + DFSConfigKeys.NNTOP_NUM_USERS_KEY + = +
[INFO]:Processing the event UNKNOWN
[INFO]:Opportunistic container <*> will not be queued at the NM since max queue length <*> has been reached
[INFO]:Deleted from target: files: <*> directories: <*>; skipped deletions <*>; deletions already missing <*>; failed deletes <*>
[DEBUG]:Auth method <*>
[INFO]:Total VCores allocated for Containers
[DEBUG]:Sequential invocation initiated
[INFO]:FSContentSummary operation executed
[WARN]:DIR* FSDirectory.unprotectedRenameTo: rename destination directory is not empty: <*>
[ERROR]:RM could not transition to Standby
[TRACE]:In collect cells FlowSannerOperation=...
[WARN]:HistoryCleanerService/move to done shutdown may not have succeeded, Forcing a shutdown
[ERROR]:Got sink exception, retry in X ms
[TRACE]:getBlock for file <*> position <*> thread <*>, stream.getPath(), position, Thread.currentThread().getName()
[INFO]:Initializing Document Store Reader for : <*>
[DEBUG]:Swap monitoring is turned off in the kernel
[DEBUG]:Incremented write operations count
[INFO]:Priority 'appPriority' is updated in queue :<*> for application: <*> for the user: <*>
[INFO]:removing master key with keyID
[ERROR]:Unable to create new reservation from RM web service
[TRACE]:GOT EXCEPITION
[DEBUG]:application <*> AMResource <*> maxAMResourcePerQueuePercent <*> amLimit <*> lastClusterResource <*> amIfStarted <*> AM node-partition name <*>
[DEBUG]:using name node URI : <*>
[DEBUG]:<*> = <*>
[INFO]:Container <*> not paused. No resume necessary
[INFO]:Logging exit info
[ERROR]:Failed to start DataNode Container <*>
[DEBUG]:Initializing service <*>
[WARN]:Now FSCK to DFSRouter is unstable feature. There may be incompatible changes between releases.
[DEBUG]:<*> Expired after expiryIntervalMs / 1000 secs
[DEBUG]:Initiating Multipart upload to destKey
[DEBUG]:Datanode:<*> storage type:<*> doesnâ€™t have sufficient space:<*> to move the target block size:<*>
[DEBUG]:Creating FSImage
[ERROR]:Could not deallocate container for task attemptId + aId
[DEBUG]:Waiting for active copies to complete
[INFO]:Application <*> already submitted on SubCluster <*>
[INFO]:<*>: no suitable block pools found to scan. Waiting <*> ms.
[WARN]:Thread sleep in monitoring loop interrupted
[INFO]:(EQUATOR) <*> kvi <*> (<*>)
[DEBUG]:Scheduling write back task for fileId: ...
[DEBUG]:Deleting blob with key: $<*>
[WARN]:Caught ExecutionException while waiting all streamer flush,
[WARN]:Unable to delete + recoveryRoot
[DEBUG]:*DIR* NameNode.append: file <*> for <*> at <*>
[ERROR]:Unexpected error rebooting NodeStatusUpdater, e
[DEBUG]:Found blob as a directory-using this file under it to infer its properties <*>
[ERROR]:Invalid eventtype UNKNOWN. Ignoring!
[INFO]:Recovering data for FederationInterceptor for <*>
[INFO]:Container failed with state: <*>
[DEBUG]:SecondaryNameNode principal could not be added
[WARN]:HeartBeat interval: <*> must be greater than 0, using default.
[INFO]:Log segment started
[ERROR]:Cannot fetch safemode state for <*>
[INFO]:RMAuditLogger.logSuccess
[DEBUG]:<*>: seqno=<*> waiting for local datanode to finish write.
[ERROR]:Error starting ApplicationHistoryServer
[INFO]:Using PlanFollowerPolicy: planFollowerPolicyClassName
[DEBUG]:Failed to delete <*>, path, e
[DEBUG]:preFlush store = <*>
[DEBUG]:Found mapping for key: + key + port: + res
[INFO]:Setting the resources allocated to containers to <*>
[DEBUG]:Updated reserved container + container.getContainer().getId() + on node + this + for application attempt + application.getApplicationAttemptId()
[INFO]:createSuccessLog(user, operation, target)
[INFO]:Action set for property: MIN_RESOURCES
[INFO]:Assigned from earlierFailedMaps
[WARN]:Uncaught exception in ContainersMonitorImpl while monitoring resource of containerId
[WARN]:failed to update application state in state store
[DEBUG]:multipleLinearRandomRetry = <*>
[DEBUG]:Start decrypting EDEK for file: <*>, output stream: 0x<*>
[DEBUG]:Failed to get access time of block <*>
[INFO]:Container containerId no longer exists
[WARN]:Log aggregation did not complete for application
[DEBUG]:Stopping delegation tokens
[WARN]:Skipping unexpected file in history server token state: <*>
[INFO]:Mount point added successfully
[INFO]:DIR* completeFile: request from ... to complete inode ... which is already closed.
[DEBUG]:BLOCK* block DELETED_BLOCK: block <*> is received from <*>
[INFO]:Can't get path for fromHandle fileId: <*>
[DEBUG]:Container status is <*>, skipping kill - <*>
[WARN]:No ContainerStatus in containerFinishedEvent
[WARN]:Name <*> is converted to <*> when it is used as a queue name.
[ERROR]:Exception in getting local edit log manifest
[INFO]:Portmap mapping registration succeeded
[DEBUG]:Updating non existent Key path <*>.. Adding new !!
[INFO]:Source listing completed in <*>
[DEBUG]:logUtilizationCollection("underutilized", underUtilized)
[INFO]:RECOVERY FAILED: caught exception
[INFO]:In all <*> UAMs <*> running containers including AM recovered for <*>
[WARN]:Cannot get RMApp by appId= + appId + , just added it to finishedApplications list for cleanup
[WARN]:Total Nodes in scope : <*> are less than Available Nodes : <*>, totalInScopeNodes, availableNodes
[DEBUG]:No delegation tokens present: using direct authentication
[INFO]:Time to add replicas to map for block pool on volume : ms
[DEBUG]:Storing state for attempt <*> at <*>
[INFO]:No policy configured for queue <*> in StateStore, fallback to default queue
[INFO]:Loaded properties from <*>
[TRACE]:save(<*>, <*>): saved <*>
[ERROR]:Exception encountered during storage policy setting.
[WARN]:<*> is shutting down, this, re
[ERROR]:Invalid node attribute(s) from Provider : + e.getMessage()
[ERROR]:Init RMAdminRequestInterceptor error for user: <*>
[INFO]:Successfully created + znodeWorkingDir + in ZK.
[DEBUG]:DIR* NameSystem.appendFile: file <*> for <*> at <*> block <*> block size <*>
[INFO]:YARN Configuration: Processor RM Placement Constraints Handler will be used. Scheduling requests will be handled by the placement constraint processor
[WARN]:No bytes sent metric found for container: + containerId + with classId: + classId
[DEBUG]:Loaded indexed logs meta
[ERROR]:Cannot create PowerShell script
[ERROR]:Fencing method + method + failed with an unexpected error.
[INFO]:Operation check started
[DEBUG]:getName(): operation: 'source' to 'dest'
[DEBUG]:After dump, new dumpFileOffset: dumpFileOffset
[INFO]:Storing timeline state store version info <*>
[INFO]:Write lock metrics added: ... <*>
[ERROR]:Couldnâ€™t complete DistCp operation: , e
[WARN]:LazyWriter failed to async persist RamDisk block pool id: <*> block Id: <*>
[WARN]:Exception encountered while saving legacy OIV image; continuing with other checkpointing steps
[DEBUG]:Failed to Get total capacity
[WARN]:Failed to instantiate default resource calculator. <*>
[ERROR]:Cannot finish application from non-leaf queue: + queue.getQueuePath()
[DEBUG]:Released container <*> of capacity <*> on host <*>, which currently has <*> containers, <*> used and <*> available, release resources=<*>
[DEBUG]:Closing old block <*>
[INFO]:Executing <*>
[WARN]:Interrupted while joining workload job thread; continuing to cleanup.
[WARN]:timestamp is not set for event eventId! Using the current timestamp
[DEBUG]:ACL not found for access-type <*> for application <*> owned by <*>. Using default <*>
[DEBUG]:Created instance <*>, instance
[INFO]:Log synchronized
[DEBUG]:Work path is <*>
[DEBUG]:Node after allocation + nm.getNodeID() + resource = + node.getUnallocatedResource()
[INFO]:Could not get pid for <*>. Waited for <*> ms.
[DEBUG]:Unable to push to znode; another server already did it
[INFO]:Decommissioned node <*> is put in maintenance state immediately.
[WARN]:Unable to download file ...
