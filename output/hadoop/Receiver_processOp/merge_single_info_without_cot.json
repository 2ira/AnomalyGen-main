{
  "org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opReadBlock()": "```xml\n<merge_result>\n  <valid_paths>\n    <path>\n      <id>P1-C1</id>\n      <eval>true</eval>\n      <exec_flow>ENTRY -> TRY -> CALL: readBlock -> IF_TRUE: traceScope != null -> CALL: traceScope.close -> IF_TRUE: span != null -> CALL: close -> EXIT -> EXIT</exec_flow>\n      <log_sequence>ENTRY -> TRY -> CALL: readBlock -> IF_TRUE: traceScope != null -> CALL: traceScope.close -> IF_TRUE: span != null -> CALL: close -> EXIT -> EXIT</log_sequence>\n    </path>\n    <path>\n      <id>P1-C2</id>\n      <eval>false</eval>\n      <exec_flow>ENTRY -> TRY -> CALL: readBlock -> IF_FALSE: traceScope != null -> EXIT</exec_flow>\n      <log_sequence>ENTRY -> TRY -> CALL: readBlock -> IF_FALSE: traceScope != null -> EXIT</log_sequence>\n    </path>\n    <path>\n      <id>C1</id>\n      <eval>true</eval>\n      <exec_flow>ENTRY -> CALL: continueTraceSpan -> CALL: getSpanContext -> CALL: getTraceInfo -> CALL: getSpanContext -> CALL: getTraceInfo -> RETURN -> EXIT</exec_flow>\n      <log_sequence>ENTRY -> CALL: continueTraceSpan -> CALL: getSpanContext -> CALL: getTraceInfo -> CALL: getSpanContext -> CALL: getTraceInfo -> RETURN -> EXIT</log_sequence>\n    </path>\n  </valid_paths>\n  <pruned_paths>\n    <path id=\"P1-C1-C2\" reason=\"Conflict in conditional evaluation: 'traceScope != null' true vs false\"/>\n  </pruned_paths>\n</merge_result>\n```",
  "org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:processOp(org.apache.hadoop.hdfs.protocol.datatransfer.Op)": "```xml\n<merge_result>\n  <valid_paths>\n    <path>\n      <id>P1-C1</id>\n      <eval>true</eval>\n      <exec_flow>ENTRY -> SWITCH: op -> CASE: [RELEASE_SHORT_CIRCUIT_FDS] -> CALL: opReleaseShortCircuitFds -> TRY -> CALL: releaseShortCircuitFds -> IF_TRUE: traceScope != null -> ENTRY -> IF_TRUE: span != null -> CALL: close -> EXIT -> EXIT</exec_flow>\n      <log_sequence>ENTRY -> SWITCH: op -> CASE: [RELEASE_SHORT_CIRCUIT_FDS] -> CALL: opReleaseShortCircuitFds -> TRY -> CALL: releaseShortCircuitFds -> IF_TRUE: traceScope != null -> ENTRY -> IF_TRUE: span != null -> CALL: close -> EXIT -> EXIT</log_sequence>\n    </path>\n    <path>\n      <id>P1-C2</id>\n      <eval>true</eval>\n      <exec_flow>ENTRY -> SWITCH: op -> CASE: [RELEASE_SHORT_CIRCUIT_FDS] -> CALL: opReleaseShortCircuitFds -> TRY -> CALL: releaseShortCircuitFds -> IF_FALSE: traceScope != null -> EXIT</exec_flow>\n      <log_sequence>ENTRY -> SWITCH: op -> CASE: [RELEASE_SHORT_CIRCUIT_FDS] -> CALL: opReleaseShortCircuitFds -> TRY -> CALL: releaseShortCircuitFds -> IF_FALSE: traceScope != null -> EXIT</log_sequence>\n    </path>\n  </valid_paths>\n  <pruned_paths>\n    <path id=\"C1\" reason=\"No valid logs in child node to merge with parent paths\"/>\n    <path id=\"C2\" reason=\"Child node logs ('ENTRY -> RETURN -> EXIT') do not align with parent execution flow or conditions\"/>\n    <path id=\"P1-C1-C1\" reason=\"No direct log or conditional conflict resolution between parent and child paths.\"/>\n    <path id=\"P1-C2-C1\" reason=\"No direct log or conditional conflict resolution between parent and child paths.\"/>\n  </pruned_paths>\n</merge_result>\n```",
  "org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:continueTraceSpan(org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ClientOperationHeaderProto,java.lang.String)": "['ENTRY -> CALL: continueTraceSpan -> CALL: getSpanContext -> CALL: getTraceInfo -> CALL: getSpanContext -> CALL: getTraceInfo -> RETURN -> EXIT']",
  "org.apache.hadoop.tracing.TraceScope:close()": "['ENTRY -> IF_TRUE: span != null -> CALL: close -> EXIT', 'ENTRY -> IF_FALSE: span != null -> EXIT']",
  "org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opReplaceBlock(java.io.DataInputStream)": "```xml\n<merge_result>\n  <valid_paths>\n    <path>\n      <id>P1-C1</id>\n      <eval>true</eval>\n      <exec_flow>ENTRY -> TRY -> CALL: replaceBlock -> IF_TRUE: traceScope != null -> ENTRY -> IF_TRUE: span != null -> CALL: close -> EXIT -> EXIT</exec_flow>\n      <log_sequence>ENTRY -> TRY -> CALL: replaceBlock -> IF_TRUE: traceScope != null -> ENTRY -> IF_TRUE: span != null -> CALL: close -> EXIT -> EXIT</log_sequence>\n    </path>\n    <path>\n      <id>P1-C2</id>\n      <eval>true</eval>\n      <exec_flow>ENTRY -> TRY -> CALL: replaceBlock -> IF_FALSE: traceScope != null -> EXIT</exec_flow>\n      <log_sequence>ENTRY -> TRY -> CALL: replaceBlock -> IF_FALSE: traceScope != null -> EXIT</log_sequence>\n    </path>\n    <path>\n      <id>P2-C1</id>\n      <eval>true</eval>\n      <exec_flow>ENTRY -> CALL: continueTraceSpan -> CALL: getSpanContext -> CALL: getTraceInfo -> CALL: getSpanContext -> CALL: getTraceInfo -> RETURN -> EXIT</exec_flow>\n      <log_sequence>ENTRY -> CALL: continueTraceSpan -> CALL: getSpanContext -> CALL: getTraceInfo -> CALL: getSpanContext -> CALL: getTraceInfo -> RETURN -> EXIT</log_sequence>\n    </path>\n  </valid_paths>\n  <pruned_paths>\n  </pruned_paths>\n</merge_result>\n```",
  "org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opWriteBlock(java.io.DataInputStream)": "```xml\n<merge_result>\n  <valid_paths>\n    <path>\n      <id>P1-C1</id>\n      <eval>true</eval>\n      <exec_flow>ENTRY -> TRY -> CALL: writeBlock -> IF_TRUE: traceScope != null -> CALL: continueTraceSpan -> CALL: getSpanContext -> CALL: getTraceInfo -> CALL: getSpanContext -> CALL: getTraceInfo -> RETURN -> CALL: traceScope.close -> IF_TRUE: span != null -> CALL: close -> EXIT</exec_flow>\n      <log_sequence>ENTRY -> TRY -> CALL: writeBlock -> IF_TRUE: traceScope != null -> CALL: traceScope.close -> IF_TRUE: span != null -> CALL: close -> EXIT</log_sequence>\n    </path>\n    <path>\n      <id>P1-C2</id>\n      <eval>true</eval>\n      <exec_flow>ENTRY -> TRY -> CALL: writeBlock -> IF_FALSE: traceScope != null -> EXIT</exec_flow>\n      <log_sequence>ENTRY -> TRY -> CALL: writeBlock -> IF_FALSE: traceScope != null -> EXIT</log_sequence>\n    </path>\n  </valid_paths>\n  <pruned_paths>\n    <path id=\"C1\" reason=\"No valid parent path to merge with\"/>\n    <path id=\"C2\" reason=\"No valid parent path to merge with\"/>\n  </pruned_paths>\n</merge_result>\n```",
  "org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:continueTraceSpan(org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$BaseHeaderProto,java.lang.String)": "['ENTRY -> CALL: continueTraceSpan -> CALL: getSpanContext -> CALL: getTraceInfo -> CALL: getSpanContext -> CALL: getTraceInfo -> RETURN -> EXIT']",
  "org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opCopyBlock(java.io.DataInputStream)": "```xml\n<merge_result>\n  <valid_paths>\n    <path>\n      <id>P1-C1</id>\n      <eval>true</eval>\n      <exec_flow>ENTRY -> TRY -> CALL: copyBlock -> IF_TRUE: traceScope != null -> ENTRY -> IF_TRUE: span != null -> CALL: close -> EXIT -> EXIT -> CALL: continueTraceSpan -> CALL: getSpanContext -> CALL: getTraceInfo -> RETURN -> EXIT</exec_flow>\n      <log_sequence>[ENTRY, TRY, CALL: copyBlock, IF_TRUE: traceScope != null, ENTRY, IF_TRUE: span != null, CALL: close, EXIT, EXIT, CALL: continueTraceSpan, CALL: getSpanContext, CALL: getTraceInfo, RETURN, EXIT]</log_sequence>\n    </path>\n    <path>\n      <id>P1-C2</id>\n      <eval>true</eval>\n      <exec_flow>ENTRY -> TRY -> CALL: copyBlock -> IF_FALSE: traceScope != null -> EXIT -> CALL: continueTraceSpan -> CALL: getSpanContext -> CALL: getTraceInfo -> RETURN -> EXIT</exec_flow>\n      <log_sequence>[ENTRY, TRY, CALL: copyBlock, IF_FALSE: traceScope != null, EXIT, CALL: continueTraceSpan, CALL: getSpanContext, CALL: getTraceInfo, RETURN, EXIT]</log_sequence>\n    </path>\n    <path>\n      <id>P1-C1-C1</id>\n      <eval>true</eval>\n      <exec_flow>ENTRY -> TRY -> CALL: copyBlock -> IF_TRUE: traceScope != null -> ENTRY -> IF_FALSE: span != null -> EXIT -> EXIT -> CALL: continueTraceSpan -> CALL: getSpanContext -> CALL: getTraceInfo -> RETURN -> EXIT</exec_flow>\n      <log_sequence>[ENTRY, TRY, CALL: copyBlock, IF_TRUE: traceScope != null, ENTRY, IF_FALSE: span != null, EXIT, EXIT, CALL: continueTraceSpan, CALL: getSpanContext, CALL: getTraceInfo, RETURN, EXIT]</log_sequence>\n    </path>\n  </valid_paths>\n  <pruned_paths>\n  </pruned_paths>\n</merge_result>\n```",
  "org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opBlockChecksum(java.io.DataInputStream)": "```xml\n<merge_result>\n  <valid_paths>\n    <path>\n      <id>P1-C1</id>\n      <eval>true</eval>\n      <exec_flow>ENTRY -> TRY -> CALL: blockChecksum -> IF_TRUE: traceScope != null -> ENTRY -> IF_TRUE: span != null -> CALL: close -> EXIT -> EXIT -> CALL: continueTraceSpan -> CALL: getSpanContext -> CALL: getTraceInfo -> RETURN -> EXIT</exec_flow>\n      <log_sequence>ENTRY, TRY, CALL: blockChecksum, IF_TRUE: traceScope != null, ENTRY, IF_TRUE: span != null, CALL: close, EXIT, EXIT, CALL: continueTraceSpan, CALL: getSpanContext, CALL: getTraceInfo, RETURN, EXIT</log_sequence>\n    </path>\n    <path>\n      <id>P1-C2</id>\n      <eval>true</eval>\n      <exec_flow>ENTRY -> TRY -> CALL: blockChecksum -> IF_TRUE: traceScope != null -> ENTRY -> IF_FALSE: span != null -> EXIT -> EXIT -> CALL: continueTraceSpan -> CALL: getSpanContext -> CALL: getTraceInfo -> RETURN -> EXIT</exec_flow>\n      <log_sequence>ENTRY, TRY, CALL: blockChecksum, IF_TRUE: traceScope != null, ENTRY, IF_FALSE: span != null, EXIT, EXIT, CALL: continueTraceSpan, CALL: getSpanContext, CALL: getTraceInfo, RETURN, EXIT</log_sequence>\n    </path>\n    <path>\n      <id>P1-C3</id>\n      <eval>true</eval>\n      <exec_flow>ENTRY -> TRY -> CALL: blockChecksum -> IF_FALSE: traceScope != null -> EXIT -> CALL: continueTraceSpan -> CALL: getSpanContext -> CALL: getTraceInfo -> RETURN -> EXIT</exec_flow>\n      <log_sequence>ENTRY, TRY, CALL: blockChecksum, IF_FALSE: traceScope != null, EXIT, CALL: continueTraceSpan, CALL: getSpanContext, CALL: getTraceInfo, RETURN, EXIT</log_sequence>\n    </path>\n  </valid_paths>\n  <pruned_paths>\n  </pruned_paths>\n</merge_result>\n```",
  "org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opStripedBlockChecksum(java.io.DataInputStream)": "```xml\n<merge_result>\n  <valid_paths>\n    <path>\n      <id>P1-C1</id>\n      <eval>true</eval>\n      <exec_flow>ENTRY -> TRY -> CALL: blockGroupChecksum -> IF_TRUE: traceScope != null -> ENTRY -> IF_TRUE: span != null -> CALL: close -> EXIT -> EXIT -> CALL: continueTraceSpan -> CALL: getSpanContext -> CALL: getTraceInfo -> CALL: getSpanContext -> CALL: getTraceInfo -> RETURN -> EXIT</exec_flow>\n      <log_sequence>ENTRY, TRY, CALL: blockGroupChecksum, IF_TRUE: traceScope != null, ENTRY, IF_TRUE: span != null, CALL: close, EXIT, EXIT, CALL: continueTraceSpan, CALL: getSpanContext, CALL: getTraceInfo, RETURN</log_sequence>\n    </path>\n    <path>\n      <id>P1-C2</id>\n      <eval>true</eval>\n      <exec_flow>ENTRY -> TRY -> CALL: blockGroupChecksum -> IF_FALSE: traceScope != null -> EXIT -> CALL: continueTraceSpan -> CALL: getSpanContext -> CALL: getTraceInfo -> CALL: getSpanContext -> CALL: getTraceInfo -> RETURN -> EXIT</exec_flow>\n      <log_sequence>ENTRY, TRY, CALL: blockGroupChecksum, IF_FALSE: traceScope != null, EXIT, CALL: continueTraceSpan, CALL: getSpanContext, CALL: getTraceInfo, RETURN</log_sequence>\n    </path>\n    <path>\n      <id>P1-C1-Alt</id>\n      <eval>true</eval>\n      <exec_flow>ENTRY -> TRY -> CALL: blockGroupChecksum -> IF_TRUE: traceScope != null -> ENTRY -> IF_FALSE: span != null -> EXIT -> EXIT -> CALL: continueTraceSpan -> CALL: getSpanContext -> CALL: getTraceInfo -> CALL: getSpanContext -> CALL: getTraceInfo -> RETURN -> EXIT</exec_flow>\n      <log_sequence>ENTRY, TRY, CALL: blockGroupChecksum, IF_TRUE: traceScope != null, ENTRY, IF_FALSE: span != null, EXIT, EXIT, CALL: continueTraceSpan, CALL: getSpanContext, CALL: getTraceInfo, RETURN</log_sequence>\n    </path>\n  </valid_paths>\n  <pruned_paths>\n  </pruned_paths>\n</merge_result>\n```",
  "org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opTransferBlock(java.io.DataInputStream)": "```xml\n<merge_result>\n  <valid_paths>\n    <path>\n      <id>P1-C1</id>\n      <eval>true</eval>\n      <exec_flow>ENTRY -> TRY -> CALL: transferBlock -> IF_TRUE: traceScope != null -> ENTRY -> IF_TRUE: span != null -> CALL: close -> EXIT -> EXIT</exec_flow>\n      <log_sequence>ENTRY -> TRY -> CALL: transferBlock -> IF_TRUE: traceScope != null -> ENTRY -> IF_TRUE: span != null -> CALL: close -> EXIT -> EXIT</log_sequence>\n    </path>\n    <path>\n      <id>P1-C2</id>\n      <eval>true</eval>\n      <exec_flow>ENTRY -> TRY -> CALL: transferBlock -> IF_TRUE: traceScope != null -> ENTRY -> IF_FALSE: span != null -> EXIT -> EXIT</exec_flow>\n      <log_sequence>ENTRY -> TRY -> CALL: transferBlock -> IF_TRUE: traceScope != null -> ENTRY -> IF_FALSE: span != null -> EXIT -> EXIT</log_sequence>\n    </path>\n    <path>\n      <id>P1-C3</id>\n      <eval>true</eval>\n      <exec_flow>ENTRY -> TRY -> CALL: transferBlock -> IF_FALSE: traceScope != null -> EXIT</exec_flow>\n      <log_sequence>ENTRY -> TRY -> CALL: transferBlock -> IF_FALSE: traceScope != null -> EXIT</log_sequence>\n    </path>\n  </valid_paths>\n  <pruned_paths>\n    <path id=\"C1\" reason=\"No valid log sequence in child node\"/>\n    <path id=\"C2\" reason=\"No valid log sequence in child node\"/>\n  </pruned_paths>\n</merge_result>\n```",
  "org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opRequestShortCircuitFds(java.io.DataInputStream)": "```xml\n<merge_result>\n  <valid_paths>\n    <path>\n      <id>P1-C1</id>\n      <eval>true</eval>\n      <exec_flow>ENTRY -> TRY -> CALL: requestShortCircuitFds -> IF_TRUE: traceScope != null -> CALL: continueTraceSpan -> CALL: getSpanContext -> CALL: getTraceInfo -> CALL: getSpanContext -> CALL: getTraceInfo -> RETURN -> CALL: traceScope.close -> ENTRY -> IF_TRUE: span != null -> CALL: close -> EXIT -> EXIT</exec_flow>\n      <log_sequence>[ENTRY, TRY, CALL: requestShortCircuitFds, IF_TRUE: traceScope != null, CALL: continueTraceSpan, CALL: getSpanContext, CALL: getTraceInfo, CALL: getSpanContext, CALL: getTraceInfo, RETURN, CALL: traceScope.close, ENTRY, IF_TRUE: span != null, CALL: close, EXIT, EXIT]</log_sequence>\n    </path>\n    <path>\n      <id>P1-C2</id>\n      <eval>true</eval>\n      <exec_flow>ENTRY -> TRY -> CALL: requestShortCircuitFds -> IF_TRUE: traceScope != null -> CALL: continueTraceSpan -> CALL: getSpanContext -> CALL: getTraceInfo -> CALL: getSpanContext -> CALL: getTraceInfo -> RETURN -> CALL: traceScope.close -> ENTRY -> IF_FALSE: span != null -> EXIT -> EXIT</exec_flow>\n      <log_sequence>[ENTRY, TRY, CALL: requestShortCircuitFds, IF_TRUE: traceScope != null, CALL: continueTraceSpan, CALL: getSpanContext, CALL: getTraceInfo, CALL: getSpanContext, CALL: getTraceInfo, RETURN, CALL: traceScope.close, ENTRY, IF_FALSE: span != null, EXIT, EXIT]</log_sequence>\n    </path>\n    <path>\n      <id>P1-C3</id>\n      <eval>true</eval>\n      <exec_flow>ENTRY -> TRY -> CALL: requestShortCircuitFds -> IF_FALSE: traceScope != null -> EXIT</exec_flow>\n      <log_sequence>[ENTRY, TRY, CALL: requestShortCircuitFds, IF_FALSE: traceScope != null, EXIT]</log_sequence>\n    </path>\n  </valid_paths>\n  <pruned_paths>\n    <path id=\"C1\" reason=\"No valid parent path to merge with\"/>\n    <path id=\"C2\" reason=\"No valid parent path to merge with\"/>\n  </pruned_paths>\n</merge_result>\n```",
  "org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opReleaseShortCircuitFds(java.io.DataInputStream)": "```xml\n<merge_result>\n  <valid_paths>\n    <path>\n      <id>P1-C1</id>\n      <eval>true</eval>\n      <exec_flow>ENTRY -> TRY -> CALL: releaseShortCircuitFds -> IF_TRUE: traceScope != null -> ENTRY -> IF_TRUE: span != null -> CALL: close -> EXIT -> EXIT</exec_flow>\n      <log_sequence>ENTRY -> TRY -> CALL: releaseShortCircuitFds -> IF_TRUE: traceScope != null -> ENTRY -> IF_TRUE: span != null -> CALL: close -> EXIT -> EXIT</log_sequence>\n    </path>\n    <path>\n      <id>P1-C2</id>\n      <eval>true</eval>\n      <exec_flow>ENTRY -> TRY -> CALL: releaseShortCircuitFds -> IF_FALSE: traceScope != null -> EXIT</exec_flow>\n      <log_sequence>ENTRY -> TRY -> CALL: releaseShortCircuitFds -> IF_FALSE: traceScope != null -> EXIT</log_sequence>\n    </path>\n  </valid_paths>\n  <pruned_paths>\n    <path id=\"C1\" reason=\"No valid logs in child node to merge with parent paths\"/>\n    <path id=\"C2\" reason=\"Child node logs ('ENTRY -> RETURN -> EXIT') do not align with parent execution flow or conditions\"/>\n  </pruned_paths>\n</merge_result>\n```",
  "org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$DataTransferTraceInfoProto:getSpanContext()": "['ENTRY -> RETURN -> EXIT']",
  "org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ReleaseShortCircuitAccessRequestProto:getTraceInfo()": "['ENTRY -> CALL: getDefaultInstance -> RETURN -> EXIT']",
  "org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:continueTraceSpan(org.apache.hadoop.thirdparty.protobuf.ByteString,java.lang.String)": "['ENTRY -> CALL: continueTraceSpan -> CALL: getSpanContext -> CALL: getTraceInfo -> CALL: getSpanContext -> CALL: getTraceInfo -> RETURN -> EXIT']",
  "org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opRequestShortCircuitShm(java.io.DataInputStream)": "```xml\n<merge_result>\n  <valid_paths>\n    <path>\n      <id>P1-C1</id>\n      <eval>true</eval>\n      <exec_flow>ENTRY -> TRY -> CALL: requestShortCircuitShm -> IF_TRUE: traceScope != null -> CALL: traceScope.close -> IF_TRUE: span != null -> CALL: close -> EXIT</exec_flow>\n      <log_sequence>ENTRY -> TRY -> CALL: requestShortCircuitShm -> IF_TRUE: traceScope != null -> CALL: traceScope.close -> IF_TRUE: span != null -> CALL: close -> EXIT</log_sequence>\n    </path>\n    <path>\n      <id>P1-C2</id>\n      <eval>true</eval>\n      <exec_flow>ENTRY -> TRY -> CALL: requestShortCircuitShm -> IF_FALSE: traceScope != null -> EXIT</exec_flow>\n      <log_sequence>ENTRY -> TRY -> CALL: requestShortCircuitShm -> IF_FALSE: traceScope != null -> EXIT</log_sequence>\n    </path>\n  </valid_paths>\n  <pruned_paths>\n    <path id=\"P1-C1-C1\" reason=\"No direct log or conditional conflict resolution between parent and child paths.\"/>\n    <path id=\"P1-C2-C1\" reason=\"No direct log or conditional conflict resolution between parent and child paths.\"/>\n  </pruned_paths>\n</merge_result>\n```",
  "org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitShmRequestProto:getTraceInfo()": "['ENTRY -> CALL: getDefaultInstance -> RETURN -> EXIT']"
}