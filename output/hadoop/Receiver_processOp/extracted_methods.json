{
    "org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ReleaseShortCircuitAccessRequestProto:getTraceInfo()": {
        "source_code": "/**\n * <code>optional .hadoop.hdfs.DataTransferTraceInfoProto traceInfo = 2;</code>\n */\npublic org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos.DataTransferTraceInfoProto getTraceInfo() {\n    return traceInfo_ == null ? org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos.DataTransferTraceInfoProto.getDefaultInstance() : traceInfo_;\n}",
        "file_path": "hadoop/hadoop-hdfs-project/hadoop-hdfs-client/target/generated-sources/java/org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java"
    },
    "org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:processOp(org.apache.hadoop.hdfs.protocol.datatransfer.Op)": {
        "source_code": "/**\n * Process op by the corresponding method.\n */\nprotected final void processOp(Op op) throws IOException {\n    switch(op) {\n        case READ_BLOCK:\n            opReadBlock();\n            break;\n        case WRITE_BLOCK:\n            opWriteBlock(in);\n            break;\n        case REPLACE_BLOCK:\n            opReplaceBlock(in);\n            break;\n        case COPY_BLOCK:\n            opCopyBlock(in);\n            break;\n        case BLOCK_CHECKSUM:\n            opBlockChecksum(in);\n            break;\n        case BLOCK_GROUP_CHECKSUM:\n            opStripedBlockChecksum(in);\n            break;\n        case TRANSFER_BLOCK:\n            opTransferBlock(in);\n            break;\n        case REQUEST_SHORT_CIRCUIT_FDS:\n            opRequestShortCircuitFds(in);\n            break;\n        case RELEASE_SHORT_CIRCUIT_FDS:\n            opReleaseShortCircuitFds(in);\n            break;\n        case REQUEST_SHORT_CIRCUIT_SHM:\n            opRequestShortCircuitShm(in);\n            break;\n        default:\n            throw new IOException(\"Unknown op \" + op + \" in data stream\");\n    }\n}",
        "file_path": "hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/datatransfer/Receiver.java"
    },
    "org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opReleaseShortCircuitFds(java.io.DataInputStream)": {
        "source_code": "/**\n * Receive {@link Op#RELEASE_SHORT_CIRCUIT_FDS}\n */\nprivate void opReleaseShortCircuitFds(DataInputStream in) throws IOException {\n    final ReleaseShortCircuitAccessRequestProto proto = ReleaseShortCircuitAccessRequestProto.parseFrom(vintPrefixed(in));\n    TraceScope traceScope = continueTraceSpan(proto.getTraceInfo().getSpanContext(), proto.getClass().getSimpleName());\n    try {\n        releaseShortCircuitFds(PBHelperClient.convert(proto.getSlotId()));\n    } finally {\n        if (traceScope != null)\n            traceScope.close();\n    }\n}",
        "file_path": "hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/datatransfer/Receiver.java"
    },
    "org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:continueTraceSpan(org.apache.hadoop.thirdparty.protobuf.ByteString,java.lang.String)": {
        "source_code": "private TraceScope continueTraceSpan(BaseHeaderProto header, String description) {\n    return continueTraceSpan(header.getTraceInfo().getSpanContext(), description);\n}",
        "file_path": "hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/datatransfer/Receiver.java"
    },
    "org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opReplaceBlock(java.io.DataInputStream)": {
        "source_code": "/**\n * Receive OP_REPLACE_BLOCK\n */\nprivate void opReplaceBlock(DataInputStream in) throws IOException {\n    OpReplaceBlockProto proto = OpReplaceBlockProto.parseFrom(vintPrefixed(in));\n    TraceScope traceScope = continueTraceSpan(proto.getHeader(), proto.getClass().getSimpleName());\n    try {\n        replaceBlock(PBHelperClient.convert(proto.getHeader().getBlock()), PBHelperClient.convertStorageType(proto.getStorageType()), PBHelperClient.convert(proto.getHeader().getToken()), proto.getDelHint(), PBHelperClient.convert(proto.getSource()), proto.getStorageId());\n    } finally {\n        if (traceScope != null)\n            traceScope.close();\n    }\n}",
        "file_path": "hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/datatransfer/Receiver.java"
    },
    "org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opBlockChecksum(java.io.DataInputStream)": {
        "source_code": "/**\n * Receive OP_BLOCK_CHECKSUM\n */\nprivate void opBlockChecksum(DataInputStream in) throws IOException {\n    OpBlockChecksumProto proto = OpBlockChecksumProto.parseFrom(vintPrefixed(in));\n    TraceScope traceScope = continueTraceSpan(proto.getHeader(), proto.getClass().getSimpleName());\n    try {\n        blockChecksum(PBHelperClient.convert(proto.getHeader().getBlock()), PBHelperClient.convert(proto.getHeader().getToken()), PBHelperClient.convert(proto.getBlockChecksumOptions()));\n    } finally {\n        if (traceScope != null)\n            traceScope.close();\n    }\n}",
        "file_path": "hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/datatransfer/Receiver.java"
    },
    "org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opReadBlock()": {
        "source_code": "/**\n * Receive OP_READ_BLOCK\n */\nprivate void opReadBlock() throws IOException {\n    OpReadBlockProto proto = OpReadBlockProto.parseFrom(vintPrefixed(in));\n    TraceScope traceScope = continueTraceSpan(proto.getHeader(), proto.getClass().getSimpleName());\n    try {\n        readBlock(PBHelperClient.convert(proto.getHeader().getBaseHeader().getBlock()), PBHelperClient.convert(proto.getHeader().getBaseHeader().getToken()), proto.getHeader().getClientName(), proto.getOffset(), proto.getLen(), proto.getSendChecksums(), (proto.hasCachingStrategy() ? getCachingStrategy(proto.getCachingStrategy()) : CachingStrategy.newDefaultStrategy()));\n    } finally {\n        if (traceScope != null)\n            traceScope.close();\n    }\n}",
        "file_path": "hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/datatransfer/Receiver.java"
    },
    "org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:continueTraceSpan(org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ClientOperationHeaderProto,java.lang.String)": {
        "source_code": "private TraceScope continueTraceSpan(BaseHeaderProto header, String description) {\n    return continueTraceSpan(header.getTraceInfo().getSpanContext(), description);\n}",
        "file_path": "hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/datatransfer/Receiver.java"
    },
    "org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:continueTraceSpan(org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$BaseHeaderProto,java.lang.String)": {
        "source_code": "private TraceScope continueTraceSpan(BaseHeaderProto header, String description) {\n    return continueTraceSpan(header.getTraceInfo().getSpanContext(), description);\n}",
        "file_path": "hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/datatransfer/Receiver.java"
    },
    "org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opRequestShortCircuitFds(java.io.DataInputStream)": {
        "source_code": "/**\n * Receive {@link Op#REQUEST_SHORT_CIRCUIT_FDS}\n */\nprivate void opRequestShortCircuitFds(DataInputStream in) throws IOException {\n    final OpRequestShortCircuitAccessProto proto = OpRequestShortCircuitAccessProto.parseFrom(vintPrefixed(in));\n    SlotId slotId = (proto.hasSlotId()) ? PBHelperClient.convert(proto.getSlotId()) : null;\n    TraceScope traceScope = continueTraceSpan(proto.getHeader(), proto.getClass().getSimpleName());\n    try {\n        requestShortCircuitFds(PBHelperClient.convert(proto.getHeader().getBlock()), PBHelperClient.convert(proto.getHeader().getToken()), slotId, proto.getMaxVersion(), proto.getSupportsReceiptVerification());\n    } finally {\n        if (traceScope != null)\n            traceScope.close();\n    }\n}",
        "file_path": "hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/datatransfer/Receiver.java"
    },
    "org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitShmRequestProto:getTraceInfo()": {
        "source_code": "/**\n * <code>optional .hadoop.hdfs.DataTransferTraceInfoProto traceInfo = 2;</code>\n */\npublic org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos.DataTransferTraceInfoProto getTraceInfo() {\n    return traceInfo_ == null ? org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos.DataTransferTraceInfoProto.getDefaultInstance() : traceInfo_;\n}",
        "file_path": "hadoop/hadoop-hdfs-project/hadoop-hdfs-client/target/generated-sources/java/org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java"
    },
    "org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opCopyBlock(java.io.DataInputStream)": {
        "source_code": "/**\n * Receive OP_COPY_BLOCK\n */\nprivate void opCopyBlock(DataInputStream in) throws IOException {\n    OpCopyBlockProto proto = OpCopyBlockProto.parseFrom(vintPrefixed(in));\n    TraceScope traceScope = continueTraceSpan(proto.getHeader(), proto.getClass().getSimpleName());\n    try {\n        copyBlock(PBHelperClient.convert(proto.getHeader().getBlock()), PBHelperClient.convert(proto.getHeader().getToken()));\n    } finally {\n        if (traceScope != null)\n            traceScope.close();\n    }\n}",
        "file_path": "hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/datatransfer/Receiver.java"
    },
    "org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opStripedBlockChecksum(java.io.DataInputStream)": {
        "source_code": "/**\n * Receive OP_STRIPED_BLOCK_CHECKSUM.\n */\nprivate void opStripedBlockChecksum(DataInputStream dis) throws IOException {\n    OpBlockGroupChecksumProto proto = OpBlockGroupChecksumProto.parseFrom(vintPrefixed(dis));\n    TraceScope traceScope = continueTraceSpan(proto.getHeader(), proto.getClass().getSimpleName());\n    StripedBlockInfo stripedBlockInfo = new StripedBlockInfo(PBHelperClient.convert(proto.getHeader().getBlock()), PBHelperClient.convert(proto.getDatanodes()), PBHelperClient.convertTokens(proto.getBlockTokensList()), PBHelperClient.convertBlockIndices(proto.getBlockIndicesList()), PBHelperClient.convertErasureCodingPolicy(proto.getEcPolicy()));\n    try {\n        blockGroupChecksum(stripedBlockInfo, PBHelperClient.convert(proto.getHeader().getToken()), proto.getRequestedNumBytes(), PBHelperClient.convert(proto.getBlockChecksumOptions()));\n    } finally {\n        if (traceScope != null) {\n            traceScope.close();\n        }\n    }\n}",
        "file_path": "hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/datatransfer/Receiver.java"
    },
    "org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opWriteBlock(java.io.DataInputStream)": {
        "source_code": "/**\n * Receive OP_WRITE_BLOCK\n */\nprivate void opWriteBlock(DataInputStream in) throws IOException {\n    final OpWriteBlockProto proto = OpWriteBlockProto.parseFrom(vintPrefixed(in));\n    final DatanodeInfo[] targets = PBHelperClient.convert(proto.getTargetsList());\n    TraceScope traceScope = continueTraceSpan(proto.getHeader(), proto.getClass().getSimpleName());\n    try {\n        writeBlock(PBHelperClient.convert(proto.getHeader().getBaseHeader().getBlock()), PBHelperClient.convertStorageType(proto.getStorageType()), PBHelperClient.convert(proto.getHeader().getBaseHeader().getToken()), proto.getHeader().getClientName(), targets, PBHelperClient.convertStorageTypes(proto.getTargetStorageTypesList(), targets.length), PBHelperClient.convert(proto.getSource()), fromProto(proto.getStage()), proto.getPipelineSize(), proto.getMinBytesRcvd(), proto.getMaxBytesRcvd(), proto.getLatestGenerationStamp(), fromProto(proto.getRequestedChecksum()), (proto.hasCachingStrategy() ? getCachingStrategy(proto.getCachingStrategy()) : CachingStrategy.newDefaultStrategy()), (proto.hasAllowLazyPersist() ? proto.getAllowLazyPersist() : false), (proto.hasPinning() ? proto.getPinning() : false), (PBHelperClient.convertBooleanList(proto.getTargetPinningsList())), proto.getStorageId(), proto.getTargetStorageIdsList().toArray(new String[0]));\n    } finally {\n        if (traceScope != null)\n            traceScope.close();\n    }\n}",
        "file_path": "hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/datatransfer/Receiver.java"
    },
    "org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opRequestShortCircuitShm(java.io.DataInputStream)": {
        "source_code": "/**\n * Receive {@link Op#REQUEST_SHORT_CIRCUIT_SHM}\n */\nprivate void opRequestShortCircuitShm(DataInputStream in) throws IOException {\n    final ShortCircuitShmRequestProto proto = ShortCircuitShmRequestProto.parseFrom(vintPrefixed(in));\n    TraceScope traceScope = continueTraceSpan(proto.getTraceInfo().getSpanContext(), proto.getClass().getSimpleName());\n    try {\n        requestShortCircuitShm(proto.getClientName());\n    } finally {\n        if (traceScope != null)\n            traceScope.close();\n    }\n}",
        "file_path": "hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/datatransfer/Receiver.java"
    },
    "org.apache.hadoop.tracing.TraceScope:close()": {
        "source_code": "public void close() {\n    if (span != null) {\n        span.close();\n    }\n}",
        "file_path": "hadoop/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/tracing/TraceScope.java"
    },
    "org.apache.hadoop.hdfs.protocol.datatransfer.Receiver:opTransferBlock(java.io.DataInputStream)": {
        "source_code": "/**\n * Receive {@link Op#TRANSFER_BLOCK}\n */\nprivate void opTransferBlock(DataInputStream in) throws IOException {\n    final OpTransferBlockProto proto = OpTransferBlockProto.parseFrom(vintPrefixed(in));\n    final DatanodeInfo[] targets = PBHelperClient.convert(proto.getTargetsList());\n    TraceScope traceScope = continueTraceSpan(proto.getHeader(), proto.getClass().getSimpleName());\n    try {\n        final ExtendedBlock block = PBHelperClient.convert(proto.getHeader().getBaseHeader().getBlock());\n        final StorageType[] targetStorageTypes = PBHelperClient.convertStorageTypes(proto.getTargetStorageTypesList(), targets.length);\n        transferBlock(block, PBHelperClient.convert(proto.getHeader().getBaseHeader().getToken()), proto.getHeader().getClientName(), targets, targetStorageTypes, proto.getTargetStorageIdsList().toArray(new String[0]));\n    } finally {\n        if (traceScope != null)\n            traceScope.close();\n    }\n}",
        "file_path": "hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/datatransfer/Receiver.java"
    },
    "org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$DataTransferTraceInfoProto:getSpanContext()": {
        "source_code": "/**\n * <code>optional bytes spanContext = 3;</code>\n */\npublic org.apache.hadoop.thirdparty.protobuf.ByteString getSpanContext() {\n    return spanContext_;\n}",
        "file_path": "hadoop/hadoop-hdfs-project/hadoop-hdfs-client/target/generated-sources/java/org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java"
    }
}