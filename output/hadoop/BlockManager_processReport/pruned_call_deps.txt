org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:processReport(org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo,org.apache.hadoop.hdfs.protocol.BlockListAsLongs)->org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:reportDiff(org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo,org.apache.hadoop.hdfs.protocol.BlockListAsLongs,java.util.Collection,java.util.Collection,java.util.Collection,java.util.Collection,java.util.Collection), depth 1
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:processReport(org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo,org.apache.hadoop.hdfs.protocol.BlockListAsLongs)->org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo:getDatanodeDescriptor(), depth 1
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:processReport(org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo,org.apache.hadoop.hdfs.protocol.BlockListAsLongs)->org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:addStoredBlockUnderConstruction(org.apache.hadoop.hdfs.server.blockmanagement.BlockManager$StatefulBlockInfo,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo), depth 1
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:processReport(org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo,org.apache.hadoop.hdfs.protocol.BlockListAsLongs)->org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:removeStoredBlock(org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor), depth 1
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:processReport(org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo,org.apache.hadoop.hdfs.protocol.BlockListAsLongs)->org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:addStoredBlock(org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo,org.apache.hadoop.hdfs.protocol.Block,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor,boolean), depth 1
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:processReport(org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo,org.apache.hadoop.hdfs.protocol.BlockListAsLongs)->org.slf4j.Logger:info(java.lang.String,java.lang.Object,java.lang.Object), depth 1
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:processReport(org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo,org.apache.hadoop.hdfs.protocol.BlockListAsLongs)->org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:addToInvalidates(org.apache.hadoop.hdfs.protocol.Block,org.apache.hadoop.hdfs.protocol.DatanodeInfo), depth 1
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:processReport(org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo,org.apache.hadoop.hdfs.protocol.BlockListAsLongs)->org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:markBlockAsCorrupt(org.apache.hadoop.hdfs.server.blockmanagement.BlockToMarkCorrupt,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor), depth 1
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:markBlockAsCorrupt(org.apache.hadoop.hdfs.server.blockmanagement.BlockToMarkCorrupt,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor)->org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo:isDeleted(), depth 2
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:markBlockAsCorrupt(org.apache.hadoop.hdfs.server.blockmanagement.BlockToMarkCorrupt,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor)->org.slf4j.Logger:debug(java.lang.String,java.lang.Object), depth 2
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:markBlockAsCorrupt(org.apache.hadoop.hdfs.server.blockmanagement.BlockToMarkCorrupt,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor)->org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:addToInvalidates(org.apache.hadoop.hdfs.protocol.Block,org.apache.hadoop.hdfs.protocol.DatanodeInfo), depth 2
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:markBlockAsCorrupt(org.apache.hadoop.hdfs.server.blockmanagement.BlockToMarkCorrupt,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor)->org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo:addBlock(org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo,org.apache.hadoop.hdfs.protocol.Block), depth 2
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:markBlockAsCorrupt(org.apache.hadoop.hdfs.server.blockmanagement.BlockToMarkCorrupt,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor)->org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo:isStriped(), depth 2
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:markBlockAsCorrupt(org.apache.hadoop.hdfs.server.blockmanagement.BlockToMarkCorrupt,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor)->org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo:getBlockId(), depth 2
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:markBlockAsCorrupt(org.apache.hadoop.hdfs.server.blockmanagement.BlockToMarkCorrupt,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor)->org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo:isStriped(), depth 2
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:markBlockAsCorrupt(org.apache.hadoop.hdfs.server.blockmanagement.BlockToMarkCorrupt,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor)->org.apache.hadoop.hdfs.server.blockmanagement.CorruptReplicasMap:addToCorruptReplicasMap(org.apache.hadoop.hdfs.protocol.Block,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor,java.lang.String,org.apache.hadoop.hdfs.server.blockmanagement.CorruptReplicasMap$Reason,boolean), depth 2
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:markBlockAsCorrupt(org.apache.hadoop.hdfs.server.blockmanagement.BlockToMarkCorrupt,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor)->org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo:isStriped(), depth 2
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:markBlockAsCorrupt(org.apache.hadoop.hdfs.server.blockmanagement.BlockToMarkCorrupt,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor)->org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo:removeBlock(org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo), depth 2
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:markBlockAsCorrupt(org.apache.hadoop.hdfs.server.blockmanagement.BlockToMarkCorrupt,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor)->org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:invalidateBlock(org.apache.hadoop.hdfs.server.blockmanagement.BlockToMarkCorrupt,org.apache.hadoop.hdfs.protocol.DatanodeInfo,org.apache.hadoop.hdfs.server.blockmanagement.NumberReplicas), depth 2
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:markBlockAsCorrupt(org.apache.hadoop.hdfs.server.blockmanagement.BlockToMarkCorrupt,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor)->org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:updateNeededReconstructions(org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo,int,int), depth 2
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:updateNeededReconstructions(org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo,int,int)->org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo:isComplete(), depth 3
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:updateNeededReconstructions(org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo,int,int)->org.apache.hadoop.hdfs.server.blockmanagement.LowRedundancyBlocks:remove(org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo,int,int,int,int), depth 3
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:invalidateBlock(org.apache.hadoop.hdfs.server.blockmanagement.BlockToMarkCorrupt,org.apache.hadoop.hdfs.protocol.DatanodeInfo,org.apache.hadoop.hdfs.server.blockmanagement.NumberReplicas)->org.slf4j.Logger:debug(java.lang.String,java.lang.Object,java.lang.Object), depth 3
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:invalidateBlock(org.apache.hadoop.hdfs.server.blockmanagement.BlockToMarkCorrupt,org.apache.hadoop.hdfs.protocol.DatanodeInfo,org.apache.hadoop.hdfs.server.blockmanagement.NumberReplicas)->org.slf4j.Logger:debug(java.lang.String,java.lang.Object[]), depth 3
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:invalidateBlock(org.apache.hadoop.hdfs.server.blockmanagement.BlockToMarkCorrupt,org.apache.hadoop.hdfs.protocol.DatanodeInfo,org.apache.hadoop.hdfs.server.blockmanagement.NumberReplicas)->org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:addToInvalidates(org.apache.hadoop.hdfs.protocol.Block,org.apache.hadoop.hdfs.protocol.DatanodeInfo), depth 3
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:invalidateBlock(org.apache.hadoop.hdfs.server.blockmanagement.BlockToMarkCorrupt,org.apache.hadoop.hdfs.protocol.DatanodeInfo,org.apache.hadoop.hdfs.server.blockmanagement.NumberReplicas)->org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:removeStoredBlock(org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor), depth 3
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:invalidateBlock(org.apache.hadoop.hdfs.server.blockmanagement.BlockToMarkCorrupt,org.apache.hadoop.hdfs.protocol.DatanodeInfo,org.apache.hadoop.hdfs.server.blockmanagement.NumberReplicas)->org.slf4j.Logger:debug(java.lang.String,java.lang.Object,java.lang.Object), depth 3
org.apache.hadoop.hdfs.server.blockmanagement.CorruptReplicasMap:addToCorruptReplicasMap(org.apache.hadoop.hdfs.protocol.Block,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor,java.lang.String,org.apache.hadoop.hdfs.server.blockmanagement.CorruptReplicasMap$Reason,boolean)->org.slf4j.Logger:debug(java.lang.String,java.lang.Object[]), depth 3
org.apache.hadoop.hdfs.server.blockmanagement.CorruptReplicasMap:addToCorruptReplicasMap(org.apache.hadoop.hdfs.protocol.Block,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor,java.lang.String,org.apache.hadoop.hdfs.server.blockmanagement.CorruptReplicasMap$Reason,boolean)->org.slf4j.Logger:debug(java.lang.String,java.lang.Object[]), depth 3
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:addToInvalidates(org.apache.hadoop.hdfs.protocol.Block,org.apache.hadoop.hdfs.protocol.DatanodeInfo)->org.apache.hadoop.hdfs.server.blockmanagement.InvalidateBlocks:add(org.apache.hadoop.hdfs.protocol.Block,org.apache.hadoop.hdfs.protocol.DatanodeInfo,boolean), depth 3
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:addToInvalidates(org.apache.hadoop.hdfs.protocol.Block,org.apache.hadoop.hdfs.protocol.DatanodeInfo)->org.apache.hadoop.hdfs.server.blockmanagement.InvalidateBlocks:add(org.apache.hadoop.hdfs.protocol.Block,org.apache.hadoop.hdfs.protocol.DatanodeInfo,boolean), depth 2
org.apache.hadoop.hdfs.server.blockmanagement.InvalidateBlocks:add(org.apache.hadoop.hdfs.protocol.Block,org.apache.hadoop.hdfs.protocol.DatanodeInfo,boolean)->org.slf4j.Logger:debug(java.lang.String,java.lang.Object[]), depth 3
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:addStoredBlock(org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo,org.apache.hadoop.hdfs.protocol.Block,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor,boolean)->java.lang.AssertionError:<init>(), depth 2
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:addStoredBlock(org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo,org.apache.hadoop.hdfs.protocol.Block,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor,boolean)->org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo:getDatanodeDescriptor(), depth 2
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:addStoredBlock(org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo,org.apache.hadoop.hdfs.protocol.Block,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor,boolean)->org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo:isComplete(), depth 2
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:addStoredBlock(org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo,org.apache.hadoop.hdfs.protocol.Block,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor,boolean)->org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo:isDeleted(), depth 2
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:addStoredBlock(org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo,org.apache.hadoop.hdfs.protocol.Block,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor,boolean)->org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo:getNumBytes(), depth 2
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:addStoredBlock(org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo,org.apache.hadoop.hdfs.protocol.Block,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor,boolean)->org.slf4j.Logger:debug(java.lang.String,java.lang.Object[]), depth 2
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:addStoredBlock(org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo,org.apache.hadoop.hdfs.protocol.Block,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor,boolean)->org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo:addBlock(org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo,org.apache.hadoop.hdfs.protocol.Block), depth 2
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:addStoredBlock(org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo,org.apache.hadoop.hdfs.protocol.Block,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor,boolean)->org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo:getNumBytes(), depth 2
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:addStoredBlock(org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo,org.apache.hadoop.hdfs.protocol.Block,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor,boolean)->org.slf4j.Logger:debug(java.lang.String,java.lang.Object[]), depth 2
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:addStoredBlock(org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo,org.apache.hadoop.hdfs.protocol.Block,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor,boolean)->org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo:getStorageType(), depth 2
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:addStoredBlock(org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo,org.apache.hadoop.hdfs.protocol.Block,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor,boolean)->org.slf4j.Logger:warn(java.lang.String,java.lang.Object[]), depth 2
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:addStoredBlock(org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo,org.apache.hadoop.hdfs.protocol.Block,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor,boolean)->org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo:getNumBytes(), depth 2
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:addStoredBlock(org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo,org.apache.hadoop.hdfs.protocol.Block,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor,boolean)->org.slf4j.Logger:debug(java.lang.String,java.lang.Object[]), depth 2
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:addStoredBlock(org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo,org.apache.hadoop.hdfs.protocol.Block,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor,boolean)->org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo:getBlockUCState(), depth 2
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:addStoredBlock(org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo,org.apache.hadoop.hdfs.protocol.Block,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor,boolean)->org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:completeBlock(org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo,org.apache.hadoop.hdfs.server.namenode.INodesInPath,boolean), depth 2
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:addStoredBlock(org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo,org.apache.hadoop.hdfs.protocol.Block,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor,boolean)->org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo:isComplete(), depth 2
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:addStoredBlock(org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo,org.apache.hadoop.hdfs.protocol.Block,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor,boolean)->org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode:incrementSafeBlockCount(int,org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo), depth 2
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:addStoredBlock(org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo,org.apache.hadoop.hdfs.protocol.Block,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor,boolean)->org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo:isCompleteOrCommitted(), depth 2
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:addStoredBlock(org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo,org.apache.hadoop.hdfs.protocol.Block,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor,boolean)->org.apache.hadoop.hdfs.server.blockmanagement.LowRedundancyBlocks:remove(org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo,int,int,int,int), depth 2
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:addStoredBlock(org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo,org.apache.hadoop.hdfs.protocol.Block,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor,boolean)->org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:updateNeededReconstructions(org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo,int,int), depth 2
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:addStoredBlock(org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo,org.apache.hadoop.hdfs.protocol.Block,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor,boolean)->org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:processExtraRedundancyBlock(org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo,short,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor), depth 2
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:addStoredBlock(org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo,org.apache.hadoop.hdfs.protocol.Block,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor,boolean)->org.slf4j.Logger:warn(java.lang.String,java.lang.Object[]), depth 2
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:addStoredBlock(org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo,org.apache.hadoop.hdfs.protocol.Block,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor,boolean)->org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:invalidateCorruptReplicas(org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo,org.apache.hadoop.hdfs.protocol.Block,org.apache.hadoop.hdfs.server.blockmanagement.NumberReplicas), depth 2
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:invalidateCorruptReplicas(org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo,org.apache.hadoop.hdfs.protocol.Block,org.apache.hadoop.hdfs.server.blockmanagement.NumberReplicas)->org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo:isStriped(), depth 3
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:invalidateCorruptReplicas(org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo,org.apache.hadoop.hdfs.protocol.Block,org.apache.hadoop.hdfs.server.blockmanagement.NumberReplicas)->org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo:isStriped(), depth 3
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:invalidateCorruptReplicas(org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo,org.apache.hadoop.hdfs.protocol.Block,org.apache.hadoop.hdfs.server.blockmanagement.NumberReplicas)->org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo:getDatanodeDescriptor(), depth 3
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:invalidateCorruptReplicas(org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo,org.apache.hadoop.hdfs.protocol.Block,org.apache.hadoop.hdfs.server.blockmanagement.NumberReplicas)->org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:invalidateBlock(org.apache.hadoop.hdfs.server.blockmanagement.BlockToMarkCorrupt,org.apache.hadoop.hdfs.protocol.DatanodeInfo,org.apache.hadoop.hdfs.server.blockmanagement.NumberReplicas), depth 3
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:invalidateCorruptReplicas(org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo,org.apache.hadoop.hdfs.protocol.Block,org.apache.hadoop.hdfs.server.blockmanagement.NumberReplicas)->org.slf4j.Logger:debug(java.lang.String,java.lang.Object[]), depth 3
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:processExtraRedundancyBlock(org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo,short,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor)->java.lang.AssertionError:<init>(), depth 3
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:processExtraRedundancyBlock(org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo,short,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor)->org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo:getState(), depth 3
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:processExtraRedundancyBlock(org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo,short,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor)->org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo:getDatanodeDescriptor(), depth 3
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:processExtraRedundancyBlock(org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo,short,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor)->org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo:areBlockContentsStale(), depth 3
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:processExtraRedundancyBlock(org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo,short,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor)->org.slf4j.Logger:trace(java.lang.String,java.lang.Object,java.lang.Object), depth 3
org.apache.hadoop.hdfs.server.blockmanagement.LowRedundancyBlocks:remove(org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo,int,int,int,int)->java.lang.AssertionError:<init>(java.lang.Object), depth 3
org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode:incrementSafeBlockCount(int,org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo)->java.lang.AssertionError:<init>(), depth 3
org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode:incrementSafeBlockCount(int,org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo)->org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo:isStriped(), depth 3
org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode:incrementSafeBlockCount(int,org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo)->org.apache.hadoop.hdfs.server.blockmanagement.BlockInfoStriped:getRealDataBlockNum(), depth 3
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:completeBlock(org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo,org.apache.hadoop.hdfs.server.namenode.INodesInPath,boolean)->org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo:isComplete(), depth 3
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:completeBlock(org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo,org.apache.hadoop.hdfs.server.namenode.INodesInPath,boolean)->org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo:numNodes(), depth 3
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:completeBlock(org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo,org.apache.hadoop.hdfs.server.namenode.INodesInPath,boolean)->org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo:getBlockUCState(), depth 3
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:completeBlock(org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo,org.apache.hadoop.hdfs.server.namenode.INodesInPath,boolean)->org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo:isStriped(), depth 3
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:completeBlock(org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo,org.apache.hadoop.hdfs.server.namenode.INodesInPath,boolean)->org.apache.hadoop.hdfs.server.blockmanagement.BlockInfoStriped:getRealDataBlockNum(), depth 3
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:completeBlock(org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo,org.apache.hadoop.hdfs.server.namenode.INodesInPath,boolean)->org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode:incrementSafeBlockCount(int,org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo), depth 3
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:removeStoredBlock(org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor)->org.slf4j.Logger:debug(java.lang.String,java.lang.Object,java.lang.Object), depth 2
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:removeStoredBlock(org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor)->java.lang.AssertionError:<init>(), depth 2
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:removeStoredBlock(org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor)->org.slf4j.Logger:debug(java.lang.String,java.lang.Object,java.lang.Object), depth 2
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:removeStoredBlock(org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor)->org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo:getBlockId(), depth 2
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:removeStoredBlock(org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor)->org.slf4j.Logger:debug(java.lang.String,java.lang.Object,java.lang.Object), depth 2
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:removeStoredBlock(org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor)->org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo:isDeleted(), depth 2
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:removeStoredBlock(org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor)->org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode:decrementSafeBlockCount(org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo), depth 2
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:removeStoredBlock(org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor)->org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:updateNeededReconstructions(org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo,int,int), depth 2
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:removeStoredBlock(org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor)->org.apache.hadoop.hdfs.server.blockmanagement.ExcessRedundancyMap:remove(org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor,org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo), depth 2
org.apache.hadoop.hdfs.server.blockmanagement.ExcessRedundancyMap:remove(org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor,org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo)->org.slf4j.Logger:debug(java.lang.String,java.lang.Object,java.lang.Object), depth 3
org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode:decrementSafeBlockCount(org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo)->java.lang.AssertionError:<init>(), depth 3
org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode:decrementSafeBlockCount(org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo)->org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo:isStriped(), depth 3
org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode:decrementSafeBlockCount(org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo)->org.apache.hadoop.hdfs.server.blockmanagement.BlockInfoStriped:getRealDataBlockNum(), depth 3
org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode:decrementSafeBlockCount(org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo)->org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo:isComplete(), depth 3
org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode:decrementSafeBlockCount(org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo)->java.lang.AssertionError:<init>(), depth 3
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:addStoredBlockUnderConstruction(org.apache.hadoop.hdfs.server.blockmanagement.BlockManager$StatefulBlockInfo,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo)->org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo:getUnderConstructionFeature(), depth 2
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:addStoredBlockUnderConstruction(org.apache.hadoop.hdfs.server.blockmanagement.BlockManager$StatefulBlockInfo,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo)->org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo:findStorageInfo(org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo), depth 2
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:addStoredBlockUnderConstruction(org.apache.hadoop.hdfs.server.blockmanagement.BlockManager$StatefulBlockInfo,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo)->org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo:getDatanodeDescriptor(), depth 2
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:addStoredBlockUnderConstruction(org.apache.hadoop.hdfs.server.blockmanagement.BlockManager$StatefulBlockInfo,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo)->org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:addStoredBlock(org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo,org.apache.hadoop.hdfs.protocol.Block,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor,boolean), depth 2
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:reportDiff(org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo,org.apache.hadoop.hdfs.protocol.BlockListAsLongs,java.util.Collection,java.util.Collection,java.util.Collection,java.util.Collection,java.util.Collection)->org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo:getDatanodeDescriptor(), depth 2
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:reportDiff(org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo,org.apache.hadoop.hdfs.protocol.BlockListAsLongs,java.util.Collection,java.util.Collection,java.util.Collection,java.util.Collection,java.util.Collection)->org.apache.hadoop.hdfs.server.blockmanagement.BlockInfoContiguous:<init>(org.apache.hadoop.hdfs.protocol.Block,short), depth 2
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:reportDiff(org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo,org.apache.hadoop.hdfs.protocol.BlockListAsLongs,java.util.Collection,java.util.Collection,java.util.Collection,java.util.Collection,java.util.Collection)->org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo:addBlock(org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo,org.apache.hadoop.hdfs.protocol.Block), depth 2
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:reportDiff(org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo,org.apache.hadoop.hdfs.protocol.BlockListAsLongs,java.util.Collection,java.util.Collection,java.util.Collection,java.util.Collection,java.util.Collection)->java.lang.AssertionError:<init>(java.lang.Object), depth 2
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:reportDiff(org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo,org.apache.hadoop.hdfs.protocol.BlockListAsLongs,java.util.Collection,java.util.Collection,java.util.Collection,java.util.Collection,java.util.Collection)->org.slf4j.Logger:debug(java.lang.String,java.lang.Object[]), depth 2
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:reportDiff(org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo,org.apache.hadoop.hdfs.protocol.BlockListAsLongs,java.util.Collection,java.util.Collection,java.util.Collection,java.util.Collection,java.util.Collection)->org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:processReportedBlock(org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo,org.apache.hadoop.hdfs.protocol.Block,org.apache.hadoop.hdfs.server.common.HdfsServerConstants$ReplicaState,java.util.Collection,java.util.Collection,java.util.Collection,java.util.Collection), depth 2
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:reportDiff(org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo,org.apache.hadoop.hdfs.protocol.BlockListAsLongs,java.util.Collection,java.util.Collection,java.util.Collection,java.util.Collection,java.util.Collection)->org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo:findStorageInfo(org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo), depth 2
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:reportDiff(org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo,org.apache.hadoop.hdfs.protocol.BlockListAsLongs,java.util.Collection,java.util.Collection,java.util.Collection,java.util.Collection,java.util.Collection)->org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo:moveBlockToHead(org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo,int,int), depth 2
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:reportDiff(org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo,org.apache.hadoop.hdfs.protocol.BlockListAsLongs,java.util.Collection,java.util.Collection,java.util.Collection,java.util.Collection,java.util.Collection)->org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo:getClass(), depth 2
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:reportDiff(org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo,org.apache.hadoop.hdfs.protocol.BlockListAsLongs,java.util.Collection,java.util.Collection,java.util.Collection,java.util.Collection,java.util.Collection)->org.apache.hadoop.hdfs.server.blockmanagement.BlockInfoContiguous:getNext(int), depth 2
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:reportDiff(org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo,org.apache.hadoop.hdfs.protocol.BlockListAsLongs,java.util.Collection,java.util.Collection,java.util.Collection,java.util.Collection,java.util.Collection)->org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo$BlockIterator:<init>(org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo,org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo), depth 2
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:reportDiff(org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo,org.apache.hadoop.hdfs.protocol.BlockListAsLongs,java.util.Collection,java.util.Collection,java.util.Collection,java.util.Collection,java.util.Collection)->org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo$BlockIterator:hasNext(), depth 2
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:reportDiff(org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo,org.apache.hadoop.hdfs.protocol.BlockListAsLongs,java.util.Collection,java.util.Collection,java.util.Collection,java.util.Collection,java.util.Collection)->org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo$BlockIterator:next(), depth 2
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:reportDiff(org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo,org.apache.hadoop.hdfs.protocol.BlockListAsLongs,java.util.Collection,java.util.Collection,java.util.Collection,java.util.Collection,java.util.Collection)->org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo:removeBlock(org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo), depth 2
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:processReportedBlock(org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo,org.apache.hadoop.hdfs.protocol.Block,org.apache.hadoop.hdfs.server.common.HdfsServerConstants$ReplicaState,java.util.Collection,java.util.Collection,java.util.Collection,java.util.Collection)->org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo:getDatanodeDescriptor(), depth 3
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:processReportedBlock(org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo,org.apache.hadoop.hdfs.protocol.Block,org.apache.hadoop.hdfs.server.common.HdfsServerConstants$ReplicaState,java.util.Collection,java.util.Collection,java.util.Collection,java.util.Collection)->org.slf4j.Logger:debug(java.lang.String,java.lang.Object[]), depth 3
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:processReportedBlock(org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo,org.apache.hadoop.hdfs.protocol.Block,org.apache.hadoop.hdfs.server.common.HdfsServerConstants$ReplicaState,java.util.Collection,java.util.Collection,java.util.Collection,java.util.Collection)->org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo:getBlockUCState(), depth 3
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:processReportedBlock(org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo,org.apache.hadoop.hdfs.protocol.Block,org.apache.hadoop.hdfs.server.common.HdfsServerConstants$ReplicaState,java.util.Collection,java.util.Collection,java.util.Collection,java.util.Collection)->org.slf4j.Logger:debug(java.lang.String,java.lang.Object), depth 3
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:processReportedBlock(org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo,org.apache.hadoop.hdfs.protocol.Block,org.apache.hadoop.hdfs.server.common.HdfsServerConstants$ReplicaState,java.util.Collection,java.util.Collection,java.util.Collection,java.util.Collection)->org.apache.hadoop.hdfs.server.blockmanagement.BlockManager$StatefulBlockInfo:<init>(org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo,org.apache.hadoop.hdfs.protocol.Block,org.apache.hadoop.hdfs.server.common.HdfsServerConstants$ReplicaState), depth 3
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:processReportedBlock(org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo,org.apache.hadoop.hdfs.protocol.Block,org.apache.hadoop.hdfs.server.common.HdfsServerConstants$ReplicaState,java.util.Collection,java.util.Collection,java.util.Collection,java.util.Collection)->org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo:findStorageInfo(org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo), depth 3
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:processReportedBlock(org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo,org.apache.hadoop.hdfs.protocol.Block,org.apache.hadoop.hdfs.server.common.HdfsServerConstants$ReplicaState,java.util.Collection,java.util.Collection,java.util.Collection,java.util.Collection)->org.apache.hadoop.hdfs.server.blockmanagement.BlockManager$BlockInfoToAdd:<init>(org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo,org.apache.hadoop.hdfs.protocol.Block), depth 3
