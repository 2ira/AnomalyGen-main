{
  "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:processReport(org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo,org.apache.hadoop.hdfs.protocol.BlockListAsLongs)": "```xml\n<merge_result>\n  <valid_paths>\n    <path>\n      <id>P1-C1</id>\n      <eval>true</eval>\n      <exec_flow>ENTRY -> CALL: reportDiff -> FOREACH: toUC -> CALL: block.getUnderConstructionFeature().addReplicaIfNotPresent -> IF_TRUE: ucBlock.reportedState == ReplicaState.FINALIZED && (block.findStorageInfo(storageInfo) < 0) || corruptReplicas.isReplicaCorrupt(block, storageInfo.getDatanodeDescriptor()) -> CALL: addStoredBlock -> ENTRY -> IF_TRUE: !block.isComplete() -> CALL: getStoredBlock -> IF_TRUE: storedBlock == null || storedBlock.isDeleted() -> CALL: blockLog.debug -> FOREACH_EXIT -> FOREACH: toRemove -> CALL: removeStoredBlock -> ENTRY -> CALL: blockLog.debug -> IF_TRUE: storedBlock == null || !blocksMap.removeNode(storedBlock, node) -> CALL: blockLog.debug -> RETURN -> EXIT -> FOREACH_EXIT -> FOREACH: toAdd -> FOREACH_EXIT -> IF_TRUE: numBlocksLogged > maxNumBlocksToLog -> CALL: blockLog.info -> FOREACH: toInvalidate -> ENTRY -> IF_FALSE: !isPopulatingReplQueues() -> FOREACH: blocksMap.getStorages(storedBlock) -> IF_TRUE: storage.getState() != State.NORMAL -> CONTINUE -> EXIT -> FOREACH_EXIT -> FOREACH: toCorrupt -> CALL: markBlockAsCorrupt -> ENTRY -> IF_TRUE: b.getStored().isDeleted() -> CALL: blockLog.debug -> CALL: addToInvalidates -> EXIT -> FOREACH_EXIT -> RETURN -> EXIT</exec_flow>\n      <log_sequence>[ENTRY, CALL: reportDiff, FOREACH: toUC, CALL: block.getUnderConstructionFeature().addReplicaIfNotPresent, IF_TRUE: ucBlock.reportedState == ReplicaState.FINALIZED && (block.findStorageInfo(storageInfo) < 0) || corruptReplicas.isReplicaCorrupt(block, storageInfo.getDatanodeDescriptor()), CALL: addStoredBlock, ENTRY, IF_TRUE: !block.isComplete(), CALL: getStoredBlock, IF_TRUE: storedBlock == null || storedBlock.isDeleted(), CALL: blockLog.debug, FOREACH_EXIT, FOREACH: toRemove, CALL: removeStoredBlock, ENTRY, CALL: blockLog.debug, IF_TRUE: storedBlock == null || !blocksMap.removeNode(storedBlock, node), CALL: blockLog.debug, RETURN, EXIT, FOREACH_EXIT, FOREACH: toAdd, FOREACH_EXIT, IF_TRUE: numBlocksLogged > maxNumBlocksToLog, CALL: blockLog.info, FOREACH: toInvalidate, ENTRY, IF_FALSE: !isPopulatingReplQueues(), FOREACH: blocksMap.getStorages(storedBlock), IF_TRUE: storage.getState() != State.NORMAL, CONTINUE, EXIT, FOREACH_EXIT, FOREACH: toCorrupt, CALL: markBlockAsCorrupt, ENTRY, IF_TRUE: b.getStored().isDeleted(), CALL: blockLog.debug, CALL: addToInvalidates, EXIT, FOREACH_EXIT, RETURN, EXIT]</log_sequence>\n    </path>\n    <path>\n      <id>P1-C2</id>\n      <eval>false</eval>\n      <exec_flow>ENTRY -> CALL: reportDiff -> FOREACH: toUC -> CALL: block.getUnderConstructionFeature().addReplicaIfNotPresent -> IF_FALSE: ucBlock.reportedState == ReplicaState.FINALIZED && (block.findStorageInfo(storageInfo) < 0) || corruptReplicas.isReplicaCorrupt(block, storageInfo.getDatanodeDescriptor()) -> ENTRY -> IF_FALSE: !block.isComplete() -> IF_TRUE: storedBlock == null || storedBlock.isDeleted() -> CALL: blockLog.debug -> FOREACH_EXIT -> FOREACH: toRemove -> CALL: removeStoredBlock -> ENTRY -> CALL: blockLog.debug -> IF_TRUE: storedBlock == null || !blocksMap.removeNode(storedBlock, node) -> CALL: blockLog.debug -> RETURN -> EXIT -> FOREACH_EXIT -> FOREACH: toAdd -> FOREACH_EXIT -> IF_FALSE: numBlocksLogged > maxNumBlocksToLog -> FOREACH: toInvalidate -> ENTRY -> IF_FALSE: !isPopulatingReplQueues() -> FOREACH: blocksMap.getStorages(storedBlock) -> FOREACH_EXIT -> IF_TRUE: datanodes != null && datanodes.length() != 0 -> CALL: blockLog.debug -> EXIT -> FOREACH_EXIT -> FOREACH: toCorrupt -> CALL: markBlockAsCorrupt -> ENTRY -> IF_FALSE: b.getStored().isDeleted() -> CALL: corruptReplicas.addToCorruptReplicasMap -> ENTRY -> IF_TRUE: nodes == null -> NEW: HashMap<DatanodeDescriptor, Reason> -> CALL: corruptReplicasMap.put -> CALL: incrementBlockStat -> IF_TRUE: reason != null -> IF_TRUE: !nodes.keySet().contains(dn) -> CALL: NameNode.blockStateChangeLog.debug -> CALL: put -> EXIT -> FOREACH_EXIT -> RETURN -> EXIT</exec_flow>\n      <log_sequence>[ENTRY, CALL: reportDiff, FOREACH: toUC, CALL: block.getUnderConstructionFeature().addReplicaIfNotPresent, IF_FALSE: ucBlock.reportedState == ReplicaState.FINALIZED && (block.findStorageInfo(storageInfo) < 0) || corruptReplicas.isReplicaCorrupt(block, storageInfo.getDatanodeDescriptor()), ENTRY, IF_FALSE: !block.isComplete(), IF_TRUE: storedBlock == null || storedBlock.isDeleted(), CALL: blockLog.debug, FOREACH_EXIT, FOREACH: toRemove, CALL: removeStoredBlock, ENTRY, CALL: blockLog.debug, IF_TRUE: storedBlock == null || !blocksMap.removeNode(storedBlock, node), CALL: blockLog.debug, RETURN, EXIT, FOREACH_EXIT, FOREACH: toAdd, FOREACH_EXIT, IF_FALSE: numBlocksLogged > maxNumBlocksToLog, FOREACH: toInvalidate, ENTRY, IF_FALSE: !isPopulatingReplQueues(), FOREACH: blocksMap.getStorages(storedBlock), FOREACH_EXIT, IF_TRUE: datanodes != null && datanodes.length() != 0, CALL: blockLog.debug, EXIT, FOREACH_EXIT, FOREACH: toCorrupt, CALL: markBlockAsCorrupt, ENTRY, IF_FALSE: b.getStored().isDeleted(), CALL: corruptReplicas.addToCorruptReplicasMap, ENTRY, IF_TRUE: nodes == null, NEW: HashMap<DatanodeDescriptor, Reason>, CALL: corruptReplicasMap.put, CALL: incrementBlockStat, IF_TRUE: reason != null, IF_TRUE: !nodes.keySet().contains(dn), CALL: NameNode.blockStateChangeLog.debug, CALL: put, EXIT, FOREACH_EXIT, RETURN, EXIT]</log_sequence>\n    </path>\n  </valid_paths>\n  <pruned_paths>\n    <path id=\"P1-C3\" reason=\"Conflicting conditions in child paths\"/>\n    <path id=\"P1-C4\" reason=\"Conflicting conditions in child paths\"/>\n    <path id=\"P1-C5\" reason=\"Conflicting conditions in child paths\"/>\n    <path id=\"P1-C6\" reason=\"Conflicting conditions in child paths\"/>\n    <path id=\"P1-C7\" reason=\"Conflicting conditions in child paths\"/>\n    <path id=\"P1-C8\" reason=\"Conflicting conditions in child paths\"/>\n    <path id=\"P1-C3\" reason=\"Conflicting conditions between parent and child paths\"/>\n  </pruned_paths>\n</merge_result>\n```",
  "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:reportDiff(org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo,org.apache.hadoop.hdfs.protocol.BlockListAsLongs,java.util.Collection,java.util.Collection,java.util.Collection,java.util.Collection,java.util.Collection)": "```xml\n<merge_result>\n  <valid_paths>\n    <path>\n      <id>P1-C1</id>\n      <eval>true</eval>\n      <exec_flow>ENTRY -> IF_TRUE: newReport == null -> FOREACH: newReport -> FOREACH_EXIT -> LOG: LOG.DEBUG: Reported block {} on {} size {} replicaState = {}, block, dn, block.getNumBytes(), reportedState -> IF_TRUE: shouldPostponeBlocksFromFuture && isGenStampInFuture(block) -> CALL: queueReportedBlock -> RETURN -> WHILE: it.hasNext() -> WHILE_COND: it.hasNext() -> WHILE_EXIT -> CALL: storageInfo.removeBlock -> ENTRY -> CALL: listRemove -> IF_TRUE: b.removeStorage(this) -> RETURN -> EXIT -> ENTRY -> CALL: addBlock -> RETURN -> EXIT -> RETURN -> EXIT -> EXIT</exec_flow>\n      <log_sequence>[ENTRY, IF_TRUE: newReport == null, FOREACH: newReport, FOREACH_EXIT, LOG.DEBUG: Reported block {} on {} size {} replicaState = {}, block, dn, block.getNumBytes(), reportedState, IF_TRUE: shouldPostponeBlocksFromFuture && isGenStampInFuture(block), CALL: queueReportedBlock, RETURN, WHILE: it.hasNext(), WHILE_COND: it.hasNext(), WHILE_EXIT, CALL: storageInfo.removeBlock, ENTRY, CALL: listRemove, IF_TRUE: b.removeStorage(this), RETURN, EXIT, ENTRY, CALL: addBlock, RETURN, EXIT, RETURN, EXIT, EXIT]</log_sequence>\n    </path>\n    <path>\n      <id>P1-C2</id>\n      <eval>true</eval>\n      <exec_flow>ENTRY -> IF_TRUE: newReport == null -> FOREACH: newReport -> FOREACH_EXIT -> LOG: LOG.DEBUG: Reported block {} on {} size {} replicaState = {}, block, dn, block.getNumBytes(), reportedState -> IF_FALSE: shouldPostponeBlocksFromFuture && isGenStampInFuture(block) -> IF_TRUE: storedBlock == null -> CALL: toInvalidate.add -> RETURN -> WHILE: it.hasNext() -> WHILE_COND: it.hasNext() -> WHILE_EXIT -> CALL: storageInfo.removeBlock -> ENTRY -> CALL: listRemove -> IF_TRUE: b.removeStorage(this) -> RETURN -> EXIT -> ENTRY -> CALL: addBlock -> RETURN -> EXIT -> RETURN -> EXIT -> EXIT</exec_flow>\n      <log_sequence>[ENTRY, IF_TRUE: newReport == null, FOREACH: newReport, FOREACH_EXIT, LOG.DEBUG: Reported block {} on {} size {} replicaState = {}, block, dn, block.getNumBytes(), reportedState, IF_FALSE: shouldPostponeBlocksFromFuture && isGenStampInFuture(block), IF_TRUE: storedBlock == null, CALL: toInvalidate.add, RETURN, WHILE: it.hasNext(), WHILE_COND: it.hasNext(), WHILE_EXIT, CALL: storageInfo.removeBlock, ENTRY, CALL: listRemove, IF_TRUE: b.removeStorage(this), RETURN, EXIT, ENTRY, CALL: addBlock, RETURN, EXIT, RETURN, EXIT, EXIT]</log_sequence>\n    </path>\n    <path>\n      <id>P1-C3</id>\n      <eval>true</eval>\n      <exec_flow>ENTRY -> IF_TRUE: newReport == null -> FOREACH: newReport -> FOREACH_EXIT -> LOG: LOG.DEBUG: Reported block {} on {} size {} replicaState = {}, block, dn, block.getNumBytes(), reportedState -> IF_FALSE: shouldPostponeBlocksFromFuture && isGenStampInFuture(block) -> IF_FALSE: storedBlock == null -> LOG: LOG.DEBUG: In memory blockUCState = {}, ucState -> IF_TRUE: invalidateBlocks.contains(dn, block) -> RETURN -> WHILE: it.hasNext() -> WHILE_COND: it.hasNext() -> WHILE_EXIT -> CALL: storageInfo.removeBlock -> ENTRY -> CALL: listRemove -> IF_TRUE: b.removeStorage(this) -> RETURN -> EXIT -> ENTRY -> CALL: addBlock -> RETURN -> EXIT -> RETURN -> EXIT -> EXIT</exec_flow>\n      <log_sequence>[ENTRY, IF_TRUE: newReport == null, FOREACH: newReport, FOREACH_EXIT, LOG.DEBUG: Reported block {} on {} size {} replicaState = {}, block, dn, block.getNumBytes(), reportedState, IF_FALSE: shouldPostponeBlocksFromFuture && isGenStampInFuture(block), IF_FALSE: storedBlock == null, LOG.DEBUG: In memory blockUCState = {}, ucState, IF_TRUE: invalidateBlocks.contains(dn, block), RETURN, WHILE: it.hasNext(), WHILE_COND: it.hasNext(), WHILE_EXIT, CALL: storageInfo.removeBlock, ENTRY, CALL: listRemove, IF_TRUE: b.removeStorage(this), RETURN, EXIT, ENTRY, CALL: addBlock, RETURN, EXIT, RETURN, EXIT, EXIT]</log_sequence>\n    </path>\n    <path>\n      <id>P1-C1-B1</id>\n      <eval>true</eval>\n      <exec_flow>ENTRY -> FOR_INIT -> FOR_COND: idx < len -> IF_TRUE: cur == storageInfo -> RETURN -> EXIT</exec_flow>\n      <log_sequence>[ENTRY, FOR_INIT, FOR_COND: idx < len, IF_TRUE: cur == storageInfo, RETURN, EXIT]</log_sequence>\n    </path>\n    <path>\n      <id>P1-C1-B2</id>\n      <eval>true</eval>\n      <exec_flow>ENTRY -> FOR_INIT -> FOR_COND: idx < len -> FOR_EXIT -> RETURN -> EXIT</exec_flow>\n      <log_sequence>[ENTRY, FOR_INIT, FOR_COND: idx < len, FOR_EXIT, RETURN, EXIT]</log_sequence>\n    </path>\n    <path>\n      <id>P1-C1-B3</id>\n      <eval>true</eval>\n      <exec_flow>ENTRY -> CALL: getNext -> CALL: findStorageInfo -> CALL: findStorageInfo -> RETURN -> EXIT</exec_flow>\n      <log_sequence>[ENTRY, CALL: getNext, CALL: findStorageInfo, CALL: findStorageInfo, RETURN, EXIT]</log_sequence>\n    </path>\n  </valid_paths>\n  <pruned_paths>\n    <path id=\"P1-C4\" reason=\"Conflicting conditions in child paths\"/>\n    <path id=\"P1-C5\" reason=\"Conflicting conditions in child paths\"/>\n    <path id=\"P1-C6\" reason=\"Conflicting conditions in child paths\"/>\n    <path id=\"P1-C7\" reason=\"Conflicting conditions in child paths\"/>\n    <path id=\"P1-C8\" reason=\"Conflicting conditions in child paths\"/>\n  </pruned_paths>\n</merge_result>\n```",
  "org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo:addBlock(org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo,org.apache.hadoop.hdfs.protocol.Block)": "['ENTRY -> CALL: addBlock -> RETURN -> EXIT']",
  "org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo:getDatanodeDescriptor()": "['ENTRY -> RETURN -> EXIT']",
  "org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo:getBlockUCState()": "['ENTRY -> CALL: getBlockUCState -> RETURN -> EXIT']",
  "org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo:findStorageInfo(org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo)": "['ENTRY -> FOR_INIT -> FOR_COND: idx < len -> IF_TRUE: cur == storageInfo -> RETURN -> EXIT', 'ENTRY -> FOR_INIT -> FOR_COND: idx < len -> FOR_EXIT -> RETURN -> EXIT']",
  "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:processReportedBlock(org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo,org.apache.hadoop.hdfs.protocol.Block,org.apache.hadoop.hdfs.server.common.HdfsServerConstants$ReplicaState,java.util.Collection,java.util.Collection,java.util.Collection,java.util.Collection)": "```xml\n<merge_result>\n  <valid_paths>\n    <path>\n      <id>P1-C1</id>\n      <eval>true</eval>\n      <exec_flow>ENTRY -> LOG: LOG.DEBUG: Reported block {} on {} size {} replicaState = {}, block, dn, block.getNumBytes(), reportedState -> IF_TRUE: shouldPostponeBlocksFromFuture && isGenStampInFuture(block) -> CALL: queueReportedBlock -> RETURN -> EXIT</exec_flow>\n      <log_sequence>LOG.DEBUG: Reported block {} on {} size {} replicaState = {}, block, dn, block.getNumBytes(), reportedState</log_sequence>\n    </path>\n    <path>\n      <id>P1-C2</id>\n      <eval>true</eval>\n      <exec_flow>ENTRY -> LOG: LOG.DEBUG: Reported block {} on {} size {} replicaState = {}, block, dn, block.getNumBytes(), reportedState -> IF_FALSE: shouldPostponeBlocksFromFuture && isGenStampInFuture(block) -> IF_TRUE: storedBlock == null -> CALL: toInvalidate.add -> RETURN -> EXIT</exec_flow>\n      <log_sequence>LOG.DEBUG: Reported block {} on {} size {} replicaState = {}, block, dn, block.getNumBytes(), reportedState</log_sequence>\n    </path>\n    <path>\n      <id>P1-C3</id>\n      <eval>true</eval>\n      <exec_flow>ENTRY -> LOG: LOG.DEBUG: Reported block {} on {} size {} replicaState = {}, block, dn, block.getNumBytes(), reportedState -> IF_FALSE: shouldPostponeBlocksFromFuture && isGenStampInFuture(block) -> IF_FALSE: storedBlock == null -> LOG: LOG.DEBUG: In memory blockUCState = {}, ucState -> IF_TRUE: invalidateBlocks.contains(dn, block) -> RETURN -> EXIT</exec_flow>\n      <log_sequence>LOG.DEBUG: Reported block {} on {} size {} replicaState = {}, block, dn, block.getNumBytes(), reportedState -> LOG.DEBUG: In memory blockUCState = {}, ucState</log_sequence>\n    </path>\n    <path>\n      <id>P1-C4</id>\n      <eval>true</eval>\n      <exec_flow>ENTRY -> LOG: LOG.DEBUG: Reported block {} on {} size {} replicaState = {}, block, dn, block.getNumBytes(), reportedState -> IF_FALSE: shouldPostponeBlocksFromFuture && isGenStampInFuture(block) -> IF_FALSE: storedBlock == null -> LOG: LOG.DEBUG: In memory blockUCState = {}, ucState -> IF_FALSE: invalidateBlocks.contains(dn, block) -> IF_TRUE: c != null -> IF_TRUE: shouldPostponeBlocksFromFuture -> CALL: queueReportedBlock -> RETURN -> EXIT</exec_flow>\n      <log_sequence>LOG.DEBUG: Reported block {} on {} size {} replicaState = {}, block, dn, block.getNumBytes(), reportedState -> LOG.DEBUG: In memory blockUCState = {}, ucState</log_sequence>\n    </path>\n    <path>\n      <id>P1-C5</id>\n      <eval>true</eval>\n      <exec_flow>ENTRY -> LOG: LOG.DEBUG: Reported block {} on {} size {} replicaState = {}, block, dn, block.getNumBytes(), reportedState -> IF_FALSE: shouldPostponeBlocksFromFuture && isGenStampInFuture(block) -> IF_FALSE: storedBlock == null -> LOG: LOG.DEBUG: In memory blockUCState = {}, ucState -> IF_FALSE: invalidateBlocks.contains(dn, block) -> IF_TRUE: c != null -> IF_FALSE: shouldPostponeBlocksFromFuture -> CALL: toCorrupt.add -> RETURN -> EXIT</exec_flow>\n      <log_sequence>LOG.DEBUG: Reported block {} on {} size {} replicaState = {}, block, dn, block.getNumBytes(), reportedState -> LOG.DEBUG: In memory blockUCState = {}, ucState</log_sequence>\n    </path>\n    <path>\n      <id>P1-C6</id>\n      <eval>true</eval>\n      <exec_flow>ENTRY -> LOG: LOG.DEBUG: Reported block {} on {} size {} replicaState = {}, block, dn, block.getNumBytes(), reportedState -> IF_FALSE: shouldPostponeBlocksFromFuture && isGenStampInFuture(block) -> IF_FALSE: storedBlock == null -> LOG: LOG.DEBUG: In memory blockUCState = {}, ucState -> IF_FALSE: invalidateBlocks.contains(dn, block) -> IF_FALSE: c != null -> IF_TRUE: isBlockUnderConstruction(storedBlock, ucState, reportedState) -> CALL: toUC.add -> RETURN -> EXIT</exec_flow>\n      <log_sequence>LOG.DEBUG: Reported block {} on {} size {} replicaState = {}, block, dn, block.getNumBytes(), reportedState -> LOG.DEBUG: In memory blockUCState = {}, ucState</log_sequence>\n    </path>\n    <path>\n      <id>P1-C7</id>\n      <eval>true</eval>\n      <exec_flow>ENTRY -> LOG: LOG.DEBUG: Reported block {} on {} size {} replicaState = {}, block, dn, block.getNumBytes(), reportedState -> IF_FALSE: shouldPostponeBlocksFromFuture && isGenStampInFuture(block) -> IF_FALSE: storedBlock == null -> LOG: LOG.DEBUG: In memory blockUCState = {}, ucState -> IF_FALSE: invalidateBlocks.contains(dn, block) -> IF_FALSE: c != null -> IF_FALSE: isBlockUnderConstruction(storedBlock, ucState, reportedState) -> IF_TRUE: reportedState == ReplicaState.FINALIZED && (storedBlock.findStorageInfo(storageInfo) == -1 || corruptReplicas.isReplicaCorrupt(storedBlock, dn)) -> CALL: toAdd.add -> RETURN -> EXIT</exec_flow>\n      <log_sequence>LOG.DEBUG: Reported block {} on {} size {} replicaState = {}, block, dn, block.getNumBytes(), reportedState -> LOG.DEBUG: In memory blockUCState = {}, ucState</log_sequence>\n    </path>\n    <path>\n      <id>P1-C8</id>\n      <eval>true</eval>\n      <exec_flow>ENTRY -> LOG: LOG.DEBUG: Reported block {} on {} size {} replicaState = {}, block, dn, block.getNumBytes(), reportedState -> IF_FALSE: shouldPostponeBlocksFromFuture && isGenStampInFuture(block) -> IF_FALSE: storedBlock == null -> LOG: LOG.DEBUG: In memory blockUCState = {}, ucState -> IF_FALSE: invalidateBlocks.contains(dn, block) -> IF_FALSE: c != null -> IF_FALSE: isBlockUnderConstruction(storedBlock, ucState, reportedState) -> IF_FALSE: reportedState == ReplicaState.FINALIZED && (storedBlock.findStorageInfo(storageInfo) == -1 || corruptReplicas.isReplicaCorrupt(storedBlock, dn)) -> RETURN -> EXIT</exec_flow>\n      <log_sequence>LOG.DEBUG: Reported block {} on {} size {} replicaState = {}, block, dn, block.getNumBytes(), reportedState -> LOG.DEBUG: In memory blockUCState = {}, ucState</log_sequence>\n    </path>\n  </valid_paths>\n  <pruned_paths>\n    <path id=\"P1-C9\" reason=\"No valid logs or conflicting conditions detected\"/>\n  </pruned_paths>\n</merge_result>\n```",
  "org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo:moveBlockToHead(org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo,int,int)": "['ENTRY -> CALL: moveBlockToHead -> RETURN -> EXIT']",
  "org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo$BlockIterator:hasNext()": "['ENTRY -> RETURN -> EXIT']",
  "org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo$BlockIterator:next()": "['ENTRY -> CALL: getNext -> CALL: findStorageInfo -> CALL: findStorageInfo -> RETURN -> EXIT']",
  "org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo:removeBlock(org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo)": "['ENTRY -> CALL: listRemove -> IF_TRUE: b.removeStorage(this) -> RETURN -> EXIT', 'ENTRY -> CALL: listRemove -> IF_FALSE: b.removeStorage(this) -> RETURN -> EXIT']",
  "org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo:getUnderConstructionFeature()": "['ENTRY -> RETURN -> EXIT']",
  "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:addStoredBlockUnderConstruction(org.apache.hadoop.hdfs.server.blockmanagement.BlockManager$StatefulBlockInfo,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo)": "```xml\n<merge_result>\n  <valid_paths>\n    <path>\n      <id>P1-C1</id>\n      <eval>true</eval>\n      <exec_flow>ENTRY -> CALL: block.getUnderConstructionFeature().addReplicaIfNotPresent -> IF_TRUE: ucBlock.reportedState == ReplicaState.FINALIZED && (block.findStorageInfo(storageInfo) < 0) || corruptReplicas.isReplicaCorrupt(block, storageInfo.getDatanodeDescriptor()) -> CALL: addStoredBlock -> ENTRY -> IF_TRUE: !block.isComplete() -> CALL: getStoredBlock -> IF_TRUE: storedBlock == null || storedBlock.isDeleted() -> CALL: blockLog.debug -> RETURN -> EXIT</exec_flow>\n      <log_sequence>ENTRY -> CALL: block.getUnderConstructionFeature().addReplicaIfNotPresent -> IF_TRUE: ucBlock.reportedState == ReplicaState.FINALIZED && (block.findStorageInfo(storageInfo) < 0) || corruptReplicas.isReplicaCorrupt(block, storageInfo.getDatanodeDescriptor()) -> CALL: addStoredBlock -> ENTRY -> IF_TRUE: !block.isComplete() -> CALL: getStoredBlock -> IF_TRUE: storedBlock == null || storedBlock.isDeleted() -> CALL: blockLog.debug -> RETURN -> EXIT</log_sequence>\n    </path>\n    <path>\n      <id>P1-C2</id>\n      <eval>false</eval>\n      <exec_flow>ENTRY -> CALL: block.getUnderConstructionFeature().addReplicaIfNotPresent -> IF_FALSE: ucBlock.reportedState == ReplicaState.FINALIZED && (block.findStorageInfo(storageInfo) < 0) || corruptReplicas.isReplicaCorrupt(block, storageInfo.getDatanodeDescriptor()) -> ENTRY -> IF_FALSE: !block.isComplete() -> IF_TRUE: storedBlock == null || storedBlock.isDeleted() -> CALL: blockLog.debug -> RETURN -> EXIT</exec_flow>\n      <log_sequence>ENTRY -> CALL: block.getUnderConstructionFeature().addReplicaIfNotPresent -> IF_FALSE: ucBlock.reportedState == ReplicaState.FINALIZED && (block.findStorageInfo(storageInfo) < 0) || corruptReplicas.isReplicaCorrupt(block, storageInfo.getDatanodeDescriptor()) -> ENTRY -> IF_FALSE: !block.isComplete() -> IF_TRUE: storedBlock == null || storedBlock.isDeleted() -> CALL: blockLog.debug -> RETURN -> EXIT</log_sequence>\n    </path>\n  </valid_paths>\n  <pruned_paths>\n    <path id=\"P1-C3\" reason=\"Conflicting conditions between parent and child paths\"/>\n  </pruned_paths>\n</merge_result>\n``````xml\n<merge_result>\n  <valid_paths>\n    <path>\n      <id>P1-C1</id>\n      <eval>true</eval>\n      <exec_flow>ENTRY -> CALL: block.getUnderConstructionFeature().addReplicaIfNotPresent -> IF_TRUE: ucBlock.reportedState == ReplicaState.FINALIZED && (block.findStorageInfo(storageInfo) < 0) || corruptReplicas.isReplicaCorrupt(block, storageInfo.getDatanodeDescriptor()) -> CALL: addStoredBlock -> ENTRY -> IF_TRUE: !block.isComplete() -> CALL: getStoredBlock -> IF_TRUE: storedBlock == null || storedBlock.isDeleted() -> CALL: blockLog.debug -> RETURN -> EXIT</exec_flow>\n      <log_sequence>ENTRY -> CALL: block.getUnderConstructionFeature().addReplicaIfNotPresent -> IF_TRUE: ucBlock.reportedState == ReplicaState.FINALIZED && (block.findStorageInfo(storageInfo) < 0) || corruptReplicas.isReplicaCorrupt(block, storageInfo.getDatanodeDescriptor()) -> CALL: addStoredBlock -> ENTRY -> IF_TRUE: !block.isComplete() -> CALL: getStoredBlock -> IF_TRUE: storedBlock == null || storedBlock.isDeleted() -> CALL: blockLog.debug -> RETURN -> EXIT</log_sequence>\n    </path>\n    <path>\n      <id>P1-C2</id>\n      <eval>false</eval>\n      <exec_flow>ENTRY -> CALL: block.getUnderConstructionFeature().addReplicaIfNotPresent -> IF_FALSE: ucBlock.reportedState == ReplicaState.FINALIZED && (block.findStorageInfo(storageInfo) < 0) || corruptReplicas.isReplicaCorrupt(block, storageInfo.getDatanodeDescriptor()) -> ENTRY -> IF_FALSE: !block.isComplete() -> IF_TRUE: storedBlock == null || storedBlock.isDeleted() -> CALL: blockLog.debug -> RETURN -> EXIT</exec_flow>\n      <log_sequence>ENTRY -> CALL: block.getUnderConstructionFeature().addReplicaIfNotPresent -> IF_FALSE: ucBlock.reportedState == ReplicaState.FINALIZED && (block.findStorageInfo(storageInfo) < 0) || corruptReplicas.isReplicaCorrupt(block, storageInfo.getDatanodeDescriptor()) -> ENTRY -> IF_FALSE: !block.isComplete() -> IF_TRUE: storedBlock == null || storedBlock.isDeleted() -> CALL: blockLog.debug -> RETURN -> EXIT</log_sequence>\n    </path>\n  </valid_paths>\n  <pruned_paths>\n    <path id=\"P1-C3\" reason=\"Conflicting conditions between parent and child paths\"/>\n  </pruned_paths>\n</merge_result>\n```",
  "org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo:isComplete()": "['ENTRY -> CALL: equals -> CALL: getBlockUCState -> RETURN -> EXIT']",
  "org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo:isDeleted()": "['ENTRY -> RETURN -> EXIT']",
  "org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo:getStorageType()": "['ENTRY -> RETURN -> EXIT']",
  "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:completeBlock(org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo,org.apache.hadoop.hdfs.server.namenode.INodesInPath,boolean)": "```xml\n<merge_result>\n  <valid_paths>\n    <path>\n      <id>P1-C1</id>\n      <eval>true</eval>\n      <exec_flow>ENTRY -> IF_TRUE: curBlock.isComplete() -> RETURN -> EXIT</exec_flow>\n      <log_sequence>ENTRY, IF_TRUE: curBlock.isComplete(), RETURN, EXIT</log_sequence>\n    </path>\n    <path>\n      <id>P2-C1</id>\n      <eval>false</eval>\n      <exec_flow>ENTRY -> IF_FALSE: curBlock.isComplete() -> IF_TRUE: !force && !hasMinStorage(curBlock, numNodes) -> THROW: new IOException(\"Cannot complete block: block does not satisfy minimal replication requirement.\") -> EXIT</exec_flow>\n      <log_sequence>ENTRY, IF_FALSE: curBlock.isComplete(), IF_TRUE: !force && !hasMinStorage(curBlock, numNodes), THROW: new IOException(\"Cannot complete block: block does not satisfy minimal replication requirement.\"), EXIT</log_sequence>\n    </path>\n    <path>\n      <id>P3-C1</id>\n      <eval>false</eval>\n      <exec_flow>ENTRY -> IF_FALSE: curBlock.isComplete() -> IF_FALSE: !force && !hasMinStorage(curBlock, numNodes) -> IF_TRUE: !force && curBlock.getBlockUCState() != BlockUCState.COMMITTED -> CALL: getBlockUCState -> RETURN -> THROW: new IOException(\"Cannot complete block: block has not been COMMITTED by the client\") -> EXIT</exec_flow>\n      <log_sequence>ENTRY, IF_FALSE: curBlock.isComplete(), IF_FALSE: !force && !hasMinStorage(curBlock, numNodes), IF_TRUE: !force && curBlock.getBlockUCState() != BlockUCState.COMMITTED, CALL: getBlockUCState, RETURN, THROW: new IOException(\"Cannot complete block: block has not been COMMITTED by the client\"), EXIT</log_sequence>\n    </path>\n    <path>\n      <id>P4-C1</id>\n      <eval>true</eval>\n      <exec_flow>ENTRY -> IF_FALSE: curBlock.isComplete() -> IF_FALSE: !force && !hasMinStorage(curBlock, numNodes) -> IF_FALSE: !force && curBlock.getBlockUCState() != BlockUCState.COMMITTED -> CALL: convertToCompleteBlock -> CALL: bmSafeMode.adjustBlockTotals -> CALL: bmSafeMode.incrementSafeBlockCount -> ENTRY -> IF_TRUE: status == BMSafeModeStatus.OFF -> RETURN -> EXIT</exec_flow>\n      <log_sequence>ENTRY, IF_FALSE: curBlock.isComplete(), IF_FALSE: !force && !hasMinStorage(curBlock, numNodes), IF_FALSE: !force && curBlock.getBlockUCState() != BlockUCState.COMMITTED, CALL: convertToCompleteBlock, CALL: bmSafeMode.adjustBlockTotals, CALL: bmSafeMode.incrementSafeBlockCount, ENTRY, IF_TRUE: status == BMSafeModeStatus.OFF, RETURN, EXIT</log_sequence>\n    </path>\n  </valid_paths>\n  <pruned_paths>\n    <path id=\"P4-C1\" reason=\"Conflict in conditional evaluation between parent and child paths\"/>\n  </pruned_paths>\n</merge_result>\n```",
  "org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo:numNodes()": "/**\n * Count the number of data-nodes the block currently belongs to (i.e., NN\n * has received block reports from the DN).\n */\npublic abstract int numNodes();",
  "org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo:isStriped()": "public abstract boolean isStriped();",
  "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:addStoredBlock(org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo,org.apache.hadoop.hdfs.protocol.Block,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor,boolean)": "```xml\n<merge_result>\n  <valid_paths>\n    <path>\n      <id>P1-C1</id>\n      <eval>true</eval>\n      <exec_flow>ENTRY -> IF_TRUE: !block.isComplete() -> CALL: getStoredBlock -> IF_TRUE: storedBlock == null || storedBlock.isDeleted() -> CALL: blockLog.debug -> RETURN -> EXIT</exec_flow>\n      <log_sequence>[ENTRY, IF_TRUE: !block.isComplete(), CALL: getStoredBlock, IF_TRUE: storedBlock == null || storedBlock.isDeleted(), CALL: blockLog.debug, RETURN, EXIT]</log_sequence>\n    </path>\n    <path>\n      <id>P1-C2</id>\n      <eval>true</eval>\n      <exec_flow>ENTRY -> IF_TRUE: !block.isComplete() -> CALL: getStoredBlock -> IF_FALSE: storedBlock == null || storedBlock.isDeleted() -> IF_TRUE: result == AddBlockResult.ADDED -> CALL: isDecommissioned -> CALL: isDecommissionInProgress -> IF_TRUE: logEveryBlock -> CALL: blockLog.debug -> IF_FALSE: storedBlock.getBlockUCState() == BlockUCState.COMMITTED && hasMinStorage(storedBlock, numUsableReplicas) -> IF_TRUE: storedBlock.isComplete() && result == AddBlockResult.ADDED -> CALL: bmSafeMode.incrementSafeBlockCount -> IF_TRUE: !storedBlock.isCompleteOrCommitted() -> RETURN -> EXIT</exec_flow>\n      <log_sequence>[ENTRY, IF_TRUE: !block.isComplete(), CALL: getStoredBlock, IF_FALSE: storedBlock == null || storedBlock.isDeleted(), IF_TRUE: result == AddBlockResult.ADDED, CALL: isDecommissioned, CALL: isDecommissionInProgress, IF_TRUE: logEveryBlock, CALL: blockLog.debug, IF_FALSE: storedBlock.getBlockUCState() == BlockUCState.COMMITTED && hasMinStorage(storedBlock, numUsableReplicas), IF_TRUE: storedBlock.isComplete() && result == AddBlockResult.ADDED, CALL: bmSafeMode.incrementSafeBlockCount, IF_TRUE: !storedBlock.isCompleteOrCommitted(), RETURN, EXIT]</log_sequence>\n    </path>\n    <path>\n      <id>P1-C3</id>\n      <eval>true</eval>\n      <exec_flow>ENTRY -> IF_TRUE: !block.isComplete() -> CALL: getStoredBlock -> IF_FALSE: storedBlock == null || storedBlock.isDeleted() -> IF_TRUE: result == AddBlockResult.ADDED -> CALL: isDecommissioned -> CALL: isDecommissionInProgress -> IF_TRUE: logEveryBlock -> CALL: blockLog.debug -> IF_FALSE: storedBlock.getBlockUCState() == BlockUCState.COMMITTED && hasMinStorage(storedBlock, numUsableReplicas) -> IF_FALSE: storedBlock.isComplete() && result == AddBlockResult.ADDED -> IF_TRUE: !storedBlock.isCompleteOrCommitted() -> RETURN -> EXIT</exec_flow>\n      <log_sequence>[ENTRY, IF_TRUE: !block.isComplete(), CALL: getStoredBlock, IF_FALSE: storedBlock == null || storedBlock.isDeleted(), IF_TRUE: result == AddBlockResult.ADDED, CALL: isDecommissioned, CALL: isDecommissionInProgress, IF_TRUE: logEveryBlock, CALL: blockLog.debug, IF_FALSE: storedBlock.getBlockUCState() == BlockUCState.COMMITTED && hasMinStorage(storedBlock, numUsableReplicas), IF_FALSE: storedBlock.isComplete() && result == AddBlockResult.ADDED, IF_TRUE: !storedBlock.isCompleteOrCommitted(), RETURN, EXIT]</log_sequence>\n    </path>\n    <path>\n      <id>P1-C4</id>\n      <eval>true</eval>\n      <exec_flow>ENTRY -> IF_TRUE: !block.isComplete() -> CALL: getStoredBlock -> IF_FALSE: storedBlock == null || storedBlock.isDeleted() -> IF_TRUE: result == AddBlockResult.ADDED -> CALL: isDecommissioned -> CALL: isDecommissionInProgress -> IF_TRUE: logEveryBlock -> CALL: blockLog.debug -> IF_FALSE: storedBlock.getBlockUCState() == BlockUCState.COMMITTED && hasMinStorage(storedBlock, numUsableReplicas) -> IF_FALSE: storedBlock.isComplete() && result == AddBlockResult.ADDED -> IF_FALSE: !storedBlock.isCompleteOrCommitted() -> IF_TRUE: !isPopulatingReplQueues() -> RETURN -> EXIT</exec_flow>\n      <log_sequence>[ENTRY, IF_TRUE: !block.isComplete(), CALL: getStoredBlock, IF_FALSE: storedBlock == null || storedBlock.isDeleted(), IF_TRUE: result == AddBlockResult.ADDED, CALL: isDecommissioned, CALL: isDecommissionInProgress, IF_TRUE: logEveryBlock, CALL: blockLog.debug, IF_FALSE: storedBlock.getBlockUCState() == BlockUCState.COMMITTED && hasMinStorage(storedBlock, numUsableReplicas), IF_FALSE: storedBlock.isComplete() && result == AddBlockResult.ADDED, IF_FALSE: !storedBlock.isCompleteOrCommitted(), IF_TRUE: !isPopulatingReplQueues(), RETURN, EXIT]</log_sequence>\n    </path>\n    <path>\n      <id>P1-C5</id>\n      <eval>true</eval>\n      <exec_flow>ENTRY -> IF_TRUE: curBlock.isComplete() -> RETURN -> EXIT</exec_flow>\n      <log_sequence>[ENTRY, IF_TRUE: curBlock.isComplete(), RETURN, EXIT]</log_sequence>\n    </path>\n    <path>\n      <id>P2-C1</id>\n      <eval>true</eval>\n      <exec_flow>ENTRY -> CALL: writeLock -> TRY -> IF_FALSE: !isPopulatingReplQueues() || !block.isComplete() -> IF_TRUE: !hasEnoughEffectiveReplicas(block, repl, pendingNum) -> CALL: neededReconstruction.update -> CALL: writeUnlock -> EXIT</exec_flow>\n      <log_sequence>[ENTRY, CALL: writeLock, TRY, IF_FALSE: !isPopulatingReplQueues() || !block.isComplete(), IF_TRUE: !hasEnoughEffectiveReplicas(block, repl, pendingNum), CALL: neededReconstruction.update, CALL: writeUnlock, EXIT]</log_sequence>\n    </path>\n    <path>\n      <id>P3-C1</id>\n      <eval>true</eval>\n      <exec_flow>ENTRY -> CALL: writeLock -> TRY -> IF_FALSE: !isPopulatingReplQueues() || !block.isComplete() -> IF_FALSE: !hasEnoughEffectiveReplicas(block, repl, pendingNum) -> CALL: neededReconstruction.remove -> CALL: writeUnlock -> EXIT</exec_flow>\n      <log_sequence>[ENTRY, CALL: writeLock, TRY, IF_FALSE: !isPopulatingReplQueues() || !block.isComplete(), IF_FALSE: !hasEnoughEffectiveReplicas(block, repl, pendingNum), CALL: neededReconstruction.remove, CALL: writeUnlock, EXIT]</log_sequence>\n    </path>\n    <path>\n      <id>P3-C2</id>\n      <eval>true</eval>\n      <exec_flow>ENTRY -> CALL: writeLock -> TRY -> IF_FALSE: !isPopulatingReplQueues() || !block.isComplete() -> IF_FALSE: !hasEnoughEffectiveReplicas(block, repl, pendingNum) -> CALL: neededReconstruction.remove -> CALL: NameNode.blockStateChangeLog.debug -> CALL: decrementBlockStat -> CALL: writeUnlock -> EXIT</exec_flow>\n      <log_sequence>[ENTRY, CALL: writeLock, TRY, IF_FALSE: !isPopulatingReplQueues() || !block.isComplete(), IF_FALSE: !hasEnoughEffectiveReplicas(block, repl, pendingNum), CALL: neededReconstruction.remove, CALL: NameNode.blockStateChangeLog.debug, CALL: decrementBlockStat, CALL: writeUnlock, EXIT]</log_sequence>\n    </path>\n  </valid_paths>\n  <pruned_paths>\n    <path id=\"P2-C2\" reason=\"Conflict: Data flow inconsistency in !hasEnoughEffectiveReplicas(block, repl, pendingNum) evaluation.\"/>\n    <path id=\"P1-C6\" reason=\"Conflict: Data flow inconsistency detected\"/>\n    <path id=\"P4-C1\" reason=\"Conflict in conditional evaluation between parent and child paths\"/>\n    <path id=\"P1-C2\" reason=\"Conflict: Conditional mismatch in !isPopulatingReplQueues() || !block.isComplete() and isComplete() evaluation.\"/>\n    <path id=\"P1-C2\" reason=\"Conflicting conditions or data flow issues\"/>\n  </pruned_paths>\n</merge_result>\n```",
  "org.apache.hadoop.hdfs.server.blockmanagement.BlockInfoStriped:getRealDataBlockNum()": "['ENTRY -> IF_TRUE: isComplete() || getBlockUCState() == BlockUCState.COMMITTED -> CALL: min -> CALL: getDataBlockNum -> CALL: getNumBytes -> CALL: getCellSize -> CALL: getDataBlockNum -> CALL: getNumBytes -> CALL: getCellSize -> RETURN -> EXIT', 'ENTRY -> IF_FALSE: isComplete() || getBlockUCState() == BlockUCState.COMMITTED -> CALL: getDataBlockNum -> RETURN -> EXIT']",
  "org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode:incrementSafeBlockCount(int,org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo)": "```xml\n<merge_result>\n  <valid_paths>\n    <path>\n      <id>P1-C1</id>\n      <eval>true</eval>\n      <exec_flow>ENTRY -> IF_TRUE: status == BMSafeModeStatus.OFF -> RETURN -> EXIT</exec_flow>\n      <log_sequence>ENTRY, IF_TRUE: status == BMSafeModeStatus.OFF, RETURN, EXIT</log_sequence>\n    </path>\n    <path>\n      <id>P1-C2</id>\n      <eval>true</eval>\n      <exec_flow>ENTRY -> IF_FALSE: status == BMSafeModeStatus.OFF -> IF_TRUE: storageNum == safeNumberOfNodes -> IF_TRUE: prog.getStatus(Phase.SAFEMODE) != Status.COMPLETE -> IF_TRUE: this.awaitingReportedBlocksCounter == null -> CALL: getCounter -> CALL: this.awaitingReportedBlocksCounter.increment -> CALL: checkSafeMode -> EXIT</exec_flow>\n      <log_sequence>ENTRY, IF_FALSE: status == BMSafeModeStatus.OFF, IF_TRUE: storageNum == safeNumberOfNodes, IF_TRUE: prog.getStatus(Phase.SAFEMODE) != Status.COMPLETE, IF_TRUE: this.awaitingReportedBlocksCounter == null, CALL: getCounter, CALL: this.awaitingReportedBlocksCounter.increment, CALL: checkSafeMode, EXIT</log_sequence>\n    </path>\n    <path>\n      <id>P1-C3</id>\n      <eval>true</eval>\n      <exec_flow>ENTRY -> IF_FALSE: status == BMSafeModeStatus.OFF -> IF_TRUE: storageNum == safeNumberOfNodes -> IF_TRUE: prog.getStatus(Phase.SAFEMODE) != Status.COMPLETE -> IF_FALSE: this.awaitingReportedBlocksCounter == null -> CALL: this.awaitingReportedBlocksCounter.increment -> CALL: checkSafeMode -> EXIT</exec_flow>\n      <log_sequence>ENTRY, IF_FALSE: status == BMSafeModeStatus.OFF, IF_TRUE: storageNum == safeNumberOfNodes, IF_TRUE: prog.getStatus(Phase.SAFEMODE) != Status.COMPLETE, IF_FALSE: this.awaitingReportedBlocksCounter == null, CALL: this.awaitingReportedBlocksCounter.increment, CALL: checkSafeMode, EXIT</log_sequence>\n    </path>\n    <path>\n      <id>P1-C4</id>\n      <eval>true</eval>\n      <exec_flow>ENTRY -> IF_FALSE: status == BMSafeModeStatus.OFF -> IF_TRUE: storageNum == safeNumberOfNodes -> IF_FALSE: prog.getStatus(Phase.SAFEMODE) != Status.COMPLETE -> CALL: checkSafeMode -> EXIT</exec_flow>\n      <log_sequence>ENTRY, IF_FALSE: status == BMSafeModeStatus.OFF, IF_TRUE: storageNum == safeNumberOfNodes, IF_FALSE: prog.getStatus(Phase.SAFEMODE) != Status.COMPLETE, CALL: checkSafeMode, EXIT</log_sequence>\n    </path>\n    <path>\n      <id>P1-C5</id>\n      <eval>true</eval>\n      <exec_flow>ENTRY -> IF_FALSE: status == BMSafeModeStatus.OFF -> IF_FALSE: storageNum == safeNumberOfNodes -> EXIT</exec_flow>\n      <log_sequence>ENTRY, IF_FALSE: status == BMSafeModeStatus.OFF, IF_FALSE: storageNum == safeNumberOfNodes, EXIT</log_sequence>\n    </path>\n  </valid_paths>\n  <pruned_paths>\n    <path id=\"C1\" reason=\"No logs in child node source code\"/>\n    <path id=\"C2\" reason=\"No logs in child node source code\"/>\n  </pruned_paths>\n</merge_result>\n```",
  "org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo:isCompleteOrCommitted()": "['ENTRY -> CALL: equals -> CALL: equals -> RETURN -> EXIT']",
  "org.apache.hadoop.hdfs.server.blockmanagement.LowRedundancyBlocks:remove(org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo,int,int,int,int)": "['ENTRY -> IF_TRUE: priLevel >= 0 && priLevel < LEVEL && priorityQueues.get(priLevel).remove(block) -> CALL: NameNode.blockStateChangeLog.debug -> CALL: decrementBlockStat -> RETURN -> EXIT', 'ENTRY -> IF_FALSE: priLevel >= 0 && priLevel < LEVEL && priorityQueues.get(priLevel).remove(block) -> FOR_INIT -> FOR_COND: i < LEVEL -> FOR_EXIT -> RETURN -> EXIT']",
  "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:updateNeededReconstructions(org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo,int,int)": "```xml\n<merge_result>\n  <valid_paths>\n    <path>\n      <id>P1-C1</id>\n      <eval>true</eval>\n      <exec_flow>ENTRY -> CALL: writeLock -> TRY -> IF_TRUE: !isPopulatingReplQueues() || !block.isComplete() -> CALL: equals -> CALL: getBlockUCState -> RETURN -> EXIT</exec_flow>\n      <log_sequence>ENTRY, CALL: writeLock, TRY, IF_TRUE: !isPopulatingReplQueues() || !block.isComplete(), CALL: equals, CALL: getBlockUCState, RETURN, EXIT</log_sequence>\n    </path>\n    <path>\n      <id>P2-C1</id>\n      <eval>true</eval>\n      <exec_flow>ENTRY -> CALL: writeLock -> TRY -> IF_FALSE: !isPopulatingReplQueues() || !block.isComplete() -> IF_TRUE: !hasEnoughEffectiveReplicas(block, repl, pendingNum) -> CALL: neededReconstruction.update -> CALL: writeUnlock -> EXIT</exec_flow>\n      <log_sequence>ENTRY, CALL: writeLock, TRY, IF_FALSE: !isPopulatingReplQueues() || !block.isComplete(), IF_TRUE: !hasEnoughEffectiveReplicas(block, repl, pendingNum), CALL: neededReconstruction.update, CALL: writeUnlock, EXIT</log_sequence>\n    </path>\n    <path>\n      <id>P3-C1</id>\n      <eval>true</eval>\n      <exec_flow>ENTRY -> CALL: writeLock -> TRY -> IF_FALSE: !isPopulatingReplQueues() || !block.isComplete() -> IF_FALSE: !hasEnoughEffectiveReplicas(block, repl, pendingNum) -> CALL: neededReconstruction.remove -> CALL: writeUnlock -> EXIT</exec_flow>\n      <log_sequence>ENTRY, CALL: writeLock, TRY, IF_FALSE: !isPopulatingReplQueues() || !block.isComplete(), IF_FALSE: !hasEnoughEffectiveReplicas(block, repl, pendingNum), CALL: neededReconstruction.remove, CALL: writeUnlock, EXIT</log_sequence>\n    </path>\n    <path>\n      <id>P3-C2</id>\n      <eval>true</eval>\n      <exec_flow>ENTRY -> CALL: writeLock -> TRY -> IF_FALSE: !isPopulatingReplQueues() || !block.isComplete() -> IF_FALSE: !hasEnoughEffectiveReplicas(block, repl, pendingNum) -> CALL: neededReconstruction.remove -> CALL: NameNode.blockStateChangeLog.debug -> CALL: decrementBlockStat -> CALL: writeUnlock -> EXIT</exec_flow>\n      <log_sequence>ENTRY, CALL: writeLock, TRY, IF_FALSE: !isPopulatingReplQueues() || !block.isComplete(), IF_FALSE: !hasEnoughEffectiveReplicas(block, repl, pendingNum), CALL: neededReconstruction.remove, CALL: NameNode.blockStateChangeLog.debug, CALL: decrementBlockStat, CALL: writeUnlock, EXIT</log_sequence>\n    </path>\n  </valid_paths>\n  <pruned_paths>\n    <path id=\"P1-C2\" reason=\"Conflict: Conditional mismatch in !isPopulatingReplQueues() || !block.isComplete() and isComplete() evaluation.\"/>\n    <path id=\"P2-C2\" reason=\"Conflict: Data flow inconsistency in !hasEnoughEffectiveReplicas(block, repl, pendingNum) evaluation.\"/>\n  </pruned_paths>\n</merge_result>\n```",
  "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:processExtraRedundancyBlock(org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo,short,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor)": "```xml\n<merge_result>\n  <valid_paths>\n    <path>\n      <id>P1-C1</id>\n      <eval>true</eval>\n      <exec_flow>\n        processExtraRedundancyBlock -> areBlockContentsStale -> getDatanodeDescriptor\n        [conditions: storage.getState() == State.NORMAL, !storage.areBlockContentsStale(), !isExcess(cur, block), cur.isInService(), corruptNodes == null || !corruptNodes.contains(cur]\n      </exec_flow>\n      <log_sequence>\n        LOG.trace(\"BLOCK* processExtraRedundancyBlock: Postponing {} since storage {} does not yet have up-to-date information.\", block, storage)\n        ENTRY -> RETURN -> EXIT\n      </log_sequence>\n    </path>\n  </valid_paths>\n  <pruned_paths>\n    <path id=\"P1-C2\" reason=\"Conflicting conditions or data flow issues\"/>\n  </pruned_paths>\n</merge_result>\n```",
  "org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo:getState()": "['ENTRY -> RETURN -> EXIT']",
  "org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo:areBlockContentsStale()": "['ENTRY -> RETURN -> EXIT']",
  "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:invalidateBlock(org.apache.hadoop.hdfs.server.blockmanagement.BlockToMarkCorrupt,org.apache.hadoop.hdfs.protocol.DatanodeInfo,org.apache.hadoop.hdfs.server.blockmanagement.NumberReplicas)": "```xml\n<merge_result>\n  <valid_paths>\n    <path>\n      <id>P1-C1</id>\n      <eval>true</eval>\n      <exec_flow>ENTRY -> CALL: blockLog.debug -> IF_TRUE: node == null -> THROW: new IOException(\"Cannot invalidate \" + b + \" because datanode \" + dn + \" does not exist.\") -> EXIT</exec_flow>\n      <log_sequence>ENTRY -> CALL: blockLog.debug -> IF_TRUE: node == null -> THROW: new IOException(\"Cannot invalidate \" + b + \" because datanode \" + dn + \" does not exist.\") -> EXIT</log_sequence>\n    </path>\n    <path>\n      <id>P1-C2</id>\n      <eval>false</eval>\n      <exec_flow>ENTRY -> CALL: blockLog.debug -> IF_FALSE: node == null -> IF_TRUE: nr.replicasOnStaleNodes() > 0 && !deleteCorruptReplicaImmediately -> CALL: blockLog.debug -> CALL: postponeBlock -> RETURN -> EXIT</exec_flow>\n      <log_sequence>ENTRY -> CALL: blockLog.debug -> IF_FALSE: node == null -> IF_TRUE: nr.replicasOnStaleNodes() > 0 && !deleteCorruptReplicaImmediately -> CALL: blockLog.debug -> CALL: postponeBlock -> RETURN -> EXIT</log_sequence>\n    </path>\n    <path>\n      <id>P1-C3</id>\n      <eval>true</eval>\n      <exec_flow>ENTRY -> CALL: blockLog.debug -> IF_FALSE: node == null -> IF_FALSE: nr.replicasOnStaleNodes() > 0 && !deleteCorruptReplicaImmediately -> CALL: addToInvalidates -> FOREACH: blocksMap.getStorages(storedBlock) -> FOREACH_EXIT -> IF_TRUE: datanodes != null && datanodes.length() != 0 -> CALL: blockLog.debug -> EXIT -> CALL: removeStoredBlock -> CALL: blockLog.debug -> RETURN -> EXIT</exec_flow>\n      <log_sequence>ENTRY -> CALL: blockLog.debug -> IF_FALSE: node == null -> IF_FALSE: nr.replicasOnStaleNodes() > 0 && !deleteCorruptReplicaImmediately -> CALL: addToInvalidates -> FOREACH: blocksMap.getStorages(storedBlock) -> FOREACH_EXIT -> IF_TRUE: datanodes != null && datanodes.length() != 0 -> CALL: blockLog.debug -> EXIT -> CALL: removeStoredBlock -> CALL: blockLog.debug -> RETURN -> EXIT</log_sequence>\n    </path>\n  </valid_paths>\n  <pruned_paths>\n    <path id=\"P1-C4\" reason=\"Conflict: Conditional mismatch in child node execution flow\"/>\n    <path id=\"P1-C5\" reason=\"Conflict: Data flow inconsistency detected\"/>\n  </pruned_paths>\n</merge_result>\n```",
  "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:invalidateCorruptReplicas(org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo,org.apache.hadoop.hdfs.protocol.Block,org.apache.hadoop.hdfs.server.blockmanagement.NumberReplicas)": "```xml\n<merge_result>\n  <valid_paths>\n    <path>\n      <id>P1-C1</id>\n      <eval>true</eval>\n      <exec_flow>ENTRY -> IF_TRUE: nodes == null -> RETURN -> EXIT</exec_flow>\n      <log_sequence>ENTRY -> IF_TRUE: nodes == null -> RETURN -> EXIT</log_sequence>\n    </path>\n    <path>\n      <id>P3-C1</id>\n      <eval>true</eval>\n      <exec_flow>ENTRY -> IF_FALSE: nodes == null -> IF_TRUE: blk.isStriped() -> CALL: getStorages -> FOREACH: nodesCopy -> FOREACH_EXIT -> IF_TRUE: removedFromBlocksMap -> CALL: corruptReplicas.removeFromCorruptReplicasMap -> EXIT</exec_flow>\n      <log_sequence>ENTRY -> IF_FALSE: nodes == null -> IF_TRUE: blk.isStriped() -> CALL: getStorages -> FOREACH: nodesCopy -> FOREACH_EXIT -> IF_TRUE: removedFromBlocksMap -> CALL: corruptReplicas.removeFromCorruptReplicasMap -> EXIT</log_sequence>\n    </path>\n    <path>\n      <id>P4-C1</id>\n      <eval>true</eval>\n      <exec_flow>ENTRY -> IF_FALSE: nodes == null -> IF_TRUE: blk.isStriped() -> CALL: getStorages -> FOREACH: nodesCopy -> FOREACH_EXIT -> IF_FALSE: removedFromBlocksMap -> EXIT</exec_flow>\n      <log_sequence>ENTRY -> IF_FALSE: nodes == null -> IF_TRUE: blk.isStriped() -> CALL: getStorages -> FOREACH: nodesCopy -> FOREACH_EXIT -> IF_FALSE: removedFromBlocksMap -> EXIT</log_sequence>\n    </path>\n    <path>\n      <id>P6-C1</id>\n      <eval>true</eval>\n      <exec_flow>ENTRY -> IF_FALSE: nodes == null -> IF_FALSE: blk.isStriped() -> FOREACH: nodesCopy -> FOREACH_EXIT -> IF_TRUE: removedFromBlocksMap -> CALL: corruptReplicas.removeFromCorruptReplicasMap -> EXIT</exec_flow>\n      <log_sequence>ENTRY -> IF_FALSE: nodes == null -> IF_FALSE: blk.isStriped() -> FOREACH: nodesCopy -> FOREACH_EXIT -> IF_TRUE: removedFromBlocksMap -> CALL: corruptReplicas.removeFromCorruptReplicasMap -> EXIT</log_sequence>\n    </path>\n    <path>\n      <id>P7-C1</id>\n      <eval>true</eval>\n      <exec_flow>ENTRY -> IF_FALSE: nodes == null -> IF_FALSE: blk.isStriped() -> FOREACH: nodesCopy -> FOREACH_EXIT -> IF_FALSE: removedFromBlocksMap -> EXIT</exec_flow>\n      <log_sequence>ENTRY -> IF_FALSE: nodes == null -> IF_FALSE: blk.isStriped() -> FOREACH: nodesCopy -> FOREACH_EXIT -> IF_FALSE: removedFromBlocksMap -> EXIT</log_sequence>\n    </path>\n  </valid_paths>\n  <pruned_paths>\n    <path id=\"P2-C1\" reason=\"Conflict in conditional evaluation: blk.isStriped() vs blk.isStriped()\"/>\n    <path id=\"P5-C1\" reason=\"Data flow conflict: storages != null && blk.isStriped()\"/>\n  </pruned_paths>\n</merge_result>\n```",
  "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:addToInvalidates(org.apache.hadoop.hdfs.protocol.Block,org.apache.hadoop.hdfs.protocol.DatanodeInfo)": "```xml\n<merge_result>\n  <valid_paths>\n    <path>\n      <id>P1-C1</id>\n      <eval>true</eval>\n      <exec_flow>ENTRY -> IF_FALSE: !isPopulatingReplQueues() -> FOREACH: blocksMap.getStorages(storedBlock) -> IF_TRUE: storage.getState() != State.NORMAL -> CONTINUE -> EXIT</exec_flow>\n      <log_sequence>ENTRY -> IF_FALSE: !isPopulatingReplQueues() -> FOREACH: blocksMap.getStorages(storedBlock) -> IF_TRUE: storage.getState() != State.NORMAL -> CONTINUE -> EXIT</log_sequence>\n    </path>\n    <path>\n      <id>P1-C2</id>\n      <eval>true</eval>\n      <exec_flow>ENTRY -> IF_FALSE: !isPopulatingReplQueues() -> FOREACH: blocksMap.getStorages(storedBlock) -> FOREACH_EXIT -> IF_TRUE: datanodes != null && datanodes.length() != 0 -> CALL: blockLog.debug -> EXIT</exec_flow>\n      <log_sequence>ENTRY -> IF_FALSE: !isPopulatingReplQueues() -> FOREACH: blocksMap.getStorages(storedBlock) -> FOREACH_EXIT -> IF_TRUE: datanodes != null && datanodes.length() != 0 -> CALL: blockLog.debug -> EXIT</log_sequence>\n    </path>\n    <path>\n      <id>P2-C1</id>\n      <eval>true</eval>\n      <exec_flow>ENTRY -> IF_TRUE: set == null -> NEW: LightWeightHashSet<> -> CALL: putBlocksSet -> IF_TRUE: set.add(block) -> IF_TRUE: blockIdManager.isStripedBlock(block) -> CALL: numECBlocks.increment -> IF_TRUE: log -> CALL: NameNode.blockStateChangeLog.debug -> EXIT</exec_flow>\n      <log_sequence>ENTRY -> IF_TRUE: set == null -> NEW: LightWeightHashSet<> -> CALL: putBlocksSet -> IF_TRUE: set.add(block) -> IF_TRUE: blockIdManager.isStripedBlock(block) -> CALL: numECBlocks.increment -> IF_TRUE: log -> CALL: NameNode.blockStateChangeLog.debug -> EXIT</log_sequence>\n    </path>\n    <path>\n      <id>P2-C2</id>\n      <eval>true</eval>\n      <exec_flow>ENTRY -> IF_TRUE: set == null -> NEW: LightWeightHashSet<> -> CALL: putBlocksSet -> IF_TRUE: set.add(block) -> IF_FALSE: blockIdManager.isStripedBlock(block) -> CALL: numBlocks.increment -> IF_TRUE: log -> CALL: NameNode.blockStateChangeLog.debug -> EXIT</exec_flow>\n      <log_sequence>ENTRY -> IF_TRUE: set == null -> NEW: LightWeightHashSet<> -> CALL: putBlocksSet -> IF_TRUE: set.add(block) -> IF_FALSE: blockIdManager.isStripedBlock(block) -> CALL: numBlocks.increment -> IF_TRUE: log -> CALL: NameNode.blockStateChangeLog.debug -> EXIT</log_sequence>\n    </path>\n  </valid_paths>\n  <pruned_paths>\n    <path id=\"P1-C3\" reason=\"Conditional conflict: datanodes != null && datanodes.length() != 0 vs datanodes == null || datanodes.length() == 0\"/>\n    <path id=\"P2-C3\" reason=\"Data flow conflict: set.add(block) failed\"/>\n  </pruned_paths>\n</merge_result>\n```",
  "org.apache.hadoop.hdfs.server.blockmanagement.InvalidateBlocks:add(org.apache.hadoop.hdfs.protocol.Block,org.apache.hadoop.hdfs.protocol.DatanodeInfo,boolean)": "['ENTRY -> IF_TRUE: set == null -> NEW: LightWeightHashSet<> -> CALL: putBlocksSet -> IF_TRUE: set.add(block) -> IF_TRUE: blockIdManager.isStripedBlock(block) -> CALL: numECBlocks.increment -> IF_TRUE: log -> CALL: NameNode.blockStateChangeLog.debug -> EXIT', 'ENTRY -> IF_TRUE: set == null -> NEW: LightWeightHashSet<> -> CALL: putBlocksSet -> IF_TRUE: set.add(block) -> IF_TRUE: blockIdManager.isStripedBlock(block) -> CALL: numECBlocks.increment -> IF_FALSE: log -> EXIT', 'ENTRY -> IF_TRUE: set == null -> NEW: LightWeightHashSet<> -> CALL: putBlocksSet -> IF_TRUE: set.add(block) -> IF_FALSE: blockIdManager.isStripedBlock(block) -> CALL: numBlocks.increment -> IF_TRUE: log -> CALL: NameNode.blockStateChangeLog.debug -> EXIT', 'ENTRY -> IF_TRUE: set == null -> NEW: LightWeightHashSet<> -> CALL: putBlocksSet -> IF_TRUE: set.add(block) -> IF_FALSE: blockIdManager.isStripedBlock(block) -> CALL: numBlocks.increment -> IF_FALSE: log -> EXIT', 'ENTRY -> IF_TRUE: set == null -> NEW: LightWeightHashSet<> -> CALL: putBlocksSet -> IF_FALSE: set.add(block) -> EXIT', 'ENTRY -> IF_FALSE: set == null -> IF_TRUE: set.add(block) -> IF_TRUE: blockIdManager.isStripedBlock(block) -> CALL: numECBlocks.increment -> IF_TRUE: log -> CALL: NameNode.blockStateChangeLog.debug -> EXIT', 'ENTRY -> IF_FALSE: set == null -> IF_TRUE: set.add(block) -> IF_TRUE: blockIdManager.isStripedBlock(block) -> CALL: numECBlocks.increment -> IF_FALSE: log -> EXIT', 'ENTRY -> IF_FALSE: set == null -> IF_TRUE: set.add(block) -> IF_FALSE: blockIdManager.isStripedBlock(block) -> CALL: numBlocks.increment -> IF_TRUE: log -> CALL: NameNode.blockStateChangeLog.debug -> EXIT', 'ENTRY -> IF_FALSE: set == null -> IF_TRUE: set.add(block) -> IF_FALSE: blockIdManager.isStripedBlock(block) -> CALL: numBlocks.increment -> IF_FALSE: log -> EXIT', 'ENTRY -> IF_FALSE: set == null -> IF_FALSE: set.add(block) -> EXIT']",
  "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:removeStoredBlock(org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor)": "```xml\n<merge_result>\n  <valid_paths>\n    <path>\n      <id>P1-C1</id>\n      <eval>true</eval>\n      <exec_flow>ENTRY -> CALL: blockLog.debug -> IF_TRUE: storedBlock == null || !blocksMap.removeNode(storedBlock, node) -> CALL: blockLog.debug -> RETURN -> EXIT</exec_flow>\n      <log_sequence>ENTRY, CALL: blockLog.debug, IF_TRUE: storedBlock == null || !blocksMap.removeNode(storedBlock, node), CALL: blockLog.debug, RETURN, EXIT</log_sequence>\n    </path>\n    <path>\n      <id>P2-C1</id>\n      <eval>true</eval>\n      <exec_flow>ENTRY -> CALL: blockLog.debug -> IF_FALSE: storedBlock == null || !blocksMap.removeNode(storedBlock, node) -> IF_FALSE: cblock != null -> IF_TRUE: !storedBlock.isDeleted() -> CALL: bmSafeMode.decrementSafeBlockCount -> IF_FALSE: status == BMSafeModeStatus.OFF -> IF_TRUE: storedBlock.isComplete() && blockManager.countNodes(b).liveReplicas() == safeNumberOfNodes - 1 -> CALL: checkSafeMode -> CALL: updateNeededReconstructions -> CALL: excessRedundancyMap.remove -> CALL: corruptReplicas.removeFromCorruptReplicasMap -> EXIT</exec_flow>\n      <log_sequence>ENTRY, CALL: blockLog.debug, IF_FALSE: storedBlock == null || !blocksMap.removeNode(storedBlock, node), IF_FALSE: cblock != null, IF_TRUE: !storedBlock.isDeleted(), CALL: bmSafeMode.decrementSafeBlockCount, IF_FALSE: status == BMSafeModeStatus.OFF, IF_TRUE: storedBlock.isComplete() && blockManager.countNodes(b).liveReplicas() == safeNumberOfNodes - 1, CALL: checkSafeMode, CALL: updateNeededReconstructions, CALL: excessRedundancyMap.remove, CALL: corruptReplicas.removeFromCorruptReplicasMap, EXIT</log_sequence>\n    </path>\n    <path>\n      <id>P2-C2</id>\n      <eval>true</eval>\n      <exec_flow>ENTRY -> CALL: blockLog.debug -> IF_FALSE: storedBlock == null || !blocksMap.removeNode(storedBlock, node) -> IF_FALSE: cblock != null -> IF_TRUE: !storedBlock.isDeleted() -> CALL: bmSafeMode.decrementSafeBlockCount -> IF_FALSE: status == BMSafeModeStatus.OFF -> IF_TRUE: storedBlock.isComplete() && blockManager.countNodes(b).liveReplicas() == safeNumberOfNodes - 1 -> CALL: getRealDataBlockNum -> CALL: min -> CALL: getDataBlockNum -> CALL: getNumBytes -> CALL: getCellSize -> RETURN -> CALL: updateNeededReconstructions -> CALL: excessRedundancyMap.remove -> CALL: corruptReplicas.removeFromCorruptReplicasMap -> EXIT</exec_flow>\n      <log_sequence>ENTRY, CALL: blockLog.debug, IF_FALSE: storedBlock == null || !blocksMap.removeNode(storedBlock, node), IF_FALSE: cblock != null, IF_TRUE: !storedBlock.isDeleted(), CALL: bmSafeMode.decrementSafeBlockCount, IF_FALSE: status == BMSafeModeStatus.OFF, IF_TRUE: storedBlock.isComplete() && blockManager.countNodes(b).liveReplicas() == safeNumberOfNodes - 1, CALL: getRealDataBlockNum, CALL: min, CALL: getDataBlockNum, CALL: getNumBytes, CALL: getCellSize, RETURN, CALL: updateNeededReconstructions, CALL: excessRedundancyMap.remove, CALL: corruptReplicas.removeFromCorruptReplicasMap, EXIT</log_sequence>\n    </path>\n    <path>\n      <id>P3-C1</id>\n      <eval>true</eval>\n      <exec_flow>ENTRY -> CALL: blockLog.debug -> IF_FALSE: storedBlock == null || !blocksMap.removeNode(storedBlock, node) -> IF_FALSE: cblock != null -> IF_FALSE: !storedBlock.isDeleted() -> CALL: excessRedundancyMap.remove -> CALL: corruptReplicas.removeFromCorruptReplicasMap -> EXIT</exec_flow>\n      <log_sequence>ENTRY, CALL: blockLog.debug, IF_FALSE: storedBlock == null || !blocksMap.removeNode(storedBlock, node), IF_FALSE: cblock != null, IF_FALSE: !storedBlock.isDeleted(), CALL: excessRedundancyMap.remove, CALL: corruptReplicas.removeFromCorruptReplicasMap, EXIT</log_sequence>\n    </path>\n  </valid_paths>\n  <pruned_paths>\n    <path id=\"P3-C2\" reason=\"Conflicting conditions: isComplete() || getBlockUCState() == BlockUCState.COMMITTED is false\"/>\n    <path id=\"P1-C2\" reason=\"Conflict: Conditional mismatch in !isPopulatingReplQueues() || !block.isComplete() and isComplete() evaluation.\"/>\n    <path id=\"P2-C2\" reason=\"Conflict: Data flow inconsistency in !hasEnoughEffectiveReplicas(block, repl, pendingNum) evaluation.\"/>\n  </pruned_paths>\n</merge_result>\n```",
  "org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode:decrementSafeBlockCount(org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo)": "```xml\n<merge_result>\n  <valid_paths>\n    <path>\n      <id>P1-C1</id>\n      <eval>false</eval>\n      <exec_flow>ENTRY -> IF_TRUE: status == BMSafeModeStatus.OFF -> RETURN -> EXIT</exec_flow>\n      <log_sequence>ENTRY -> IF_TRUE: status == BMSafeModeStatus.OFF -> RETURN -> EXIT</log_sequence>\n    </path>\n    <path>\n      <id>P2-C1</id>\n      <eval>true</eval>\n      <exec_flow>ENTRY -> IF_FALSE: status == BMSafeModeStatus.OFF -> IF_TRUE: storedBlock.isComplete() && blockManager.countNodes(b).liveReplicas() == safeNumberOfNodes - 1 -> CALL: checkSafeMode -> EXIT</exec_flow>\n      <log_sequence>ENTRY -> IF_FALSE: status == BMSafeModeStatus.OFF -> IF_TRUE: storedBlock.isComplete() && blockManager.countNodes(b).liveReplicas() == safeNumberOfNodes - 1 -> CALL: checkSafeMode -> EXIT</log_sequence>\n    </path>\n    <path>\n      <id>P2-C2</id>\n      <eval>true</eval>\n      <exec_flow>ENTRY -> IF_FALSE: status == BMSafeModeStatus.OFF -> IF_TRUE: storedBlock.isComplete() && blockManager.countNodes(b).liveReplicas() == safeNumberOfNodes - 1 -> CALL: getRealDataBlockNum -> CALL: min -> CALL: getDataBlockNum -> CALL: getNumBytes -> CALL: getCellSize -> RETURN -> EXIT</exec_flow>\n      <log_sequence>ENTRY -> IF_FALSE: status == BMSafeModeStatus.OFF -> IF_TRUE: storedBlock.isComplete() && blockManager.countNodes(b).liveReplicas() == safeNumberOfNodes - 1 -> CALL: getRealDataBlockNum -> CALL: min -> CALL: getDataBlockNum -> CALL: getNumBytes -> CALL: getCellSize -> RETURN -> EXIT</log_sequence>\n    </path>\n  </valid_paths>\n  <pruned_paths>\n    <path id=\"P3-C1\" reason=\"Conflicting conditions: status == BMSafeModeStatus.OFF is false and storedBlock.isComplete() && blockManager.countNodes(b).liveReplicas() == safeNumberOfNodes - 1 is false\"/>\n    <path id=\"P3-C2\" reason=\"Conflicting conditions: isComplete() || getBlockUCState() == BlockUCState.COMMITTED is false\"/>\n  </pruned_paths>\n</merge_result>\n```",
  "org.apache.hadoop.hdfs.server.blockmanagement.ExcessRedundancyMap:remove(org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor,org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo)": "['ENTRY -> IF_TRUE: set == null -> RETURN -> EXIT', 'ENTRY -> IF_FALSE: set == null -> IF_TRUE: removed -> CALL: decrementAndGet -> CALL: blockLog.debug -> IF_TRUE: set.isEmpty() -> CALL: remove -> RETURN -> EXIT', 'ENTRY -> IF_FALSE: set == null -> IF_TRUE: removed -> CALL: decrementAndGet -> CALL: blockLog.debug -> IF_FALSE: set.isEmpty() -> RETURN -> EXIT', 'ENTRY -> IF_FALSE: set == null -> IF_FALSE: removed -> RETURN -> EXIT']",
  "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:markBlockAsCorrupt(org.apache.hadoop.hdfs.server.blockmanagement.BlockToMarkCorrupt,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor)": "```xml\n<merge_result>\n  <valid_paths>\n    <path>\n      <id>P1-C1</id>\n      <eval>true</eval>\n      <exec_flow>ENTRY -> IF_TRUE: b.getStored().isDeleted() -> CALL: blockLog.debug -> CALL: addToInvalidates -> EXIT</exec_flow>\n      <log_sequence>[BLOCK markBlockAsCorrupt: {} cannot be marked as corrupt as it does not belong to any file]</log_sequence>\n    </path>\n    <path>\n      <id>P1-C2</id>\n      <eval>true</eval>\n      <exec_flow>ENTRY -> IF_FALSE: b.getStored().isDeleted() -> CALL: corruptReplicas.addToCorruptReplicasMap -> ENTRY -> IF_TRUE: nodes == null -> NEW: HashMap<DatanodeDescriptor, Reason> -> CALL: corruptReplicasMap.put -> CALL: incrementBlockStat -> IF_TRUE: reason != null -> IF_TRUE: !nodes.keySet().contains(dn) -> CALL: NameNode.blockStateChangeLog.debug -> CALL: put -> EXIT</exec_flow>\n      <log_sequence>[BLOCK NameSystem.addToCorruptReplicasMap: {} added as corrupt on {} by {} {}]</log_sequence>\n    </path>\n    <path>\n      <id>P1-C3</id>\n      <eval>true</eval>\n      <exec_flow>ENTRY -> IF_FALSE: b.getStored().isDeleted() -> CALL: corruptReplicas.addToCorruptReplicasMap -> ENTRY -> IF_TRUE: nodes == null -> NEW: HashMap<DatanodeDescriptor, Reason> -> CALL: corruptReplicasMap.put -> CALL: incrementBlockStat -> IF_TRUE: reason != null -> IF_FALSE: !nodes.keySet().contains(dn) -> CALL: NameNode.blockStateChangeLog.debug -> CALL: put -> EXIT</exec_flow>\n      <log_sequence>[BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for {} to add as corrupt on {} by {} {}]</log_sequence>\n    </path>\n    <path>\n      <id>P2-C1</id>\n      <eval>true</eval>\n      <exec_flow>ENTRY -> CALL: listRemove -> IF_TRUE: b.removeStorage(this) -> RETURN -> EXIT</exec_flow>\n      <log_sequence>[BLOCK NameSystem.removeBlock: {} successfully removed from storage]</log_sequence>\n    </path>\n    <path>\n      <id>P2-C2</id>\n      <eval>true</eval>\n      <exec_flow>ENTRY -> CALL: listRemove -> IF_FALSE: b.removeStorage(this) -> RETURN -> EXIT</exec_flow>\n      <log_sequence>[BLOCK NameSystem.removeBlock: {} removal from storage failed]</log_sequence>\n    </path>\n    <path>\n      <id>P3-C1</id>\n      <eval>true</eval>\n      <exec_flow>ENTRY -> CALL: writeLock -> TRY -> IF_FALSE: !isPopulatingReplQueues() || !block.isComplete() -> IF_FALSE: !hasEnoughEffectiveReplicas(block, repl, pendingNum) -> CALL: neededReconstruction.remove -> CALL: writeUnlock -> EXIT</exec_flow>\n      <log_sequence>ENTRY, CALL: writeLock, TRY, IF_FALSE: !isPopulatingReplQueues() || !block.isComplete(), IF_FALSE: !hasEnoughEffectiveReplicas(block, repl, pendingNum), CALL: neededReconstruction.remove, CALL: writeUnlock, EXIT</log_sequence>\n    </path>\n    <path>\n      <id>P3-C2</id>\n      <eval>true</eval>\n      <exec_flow>ENTRY -> CALL: writeLock -> TRY -> IF_FALSE: !isPopulatingReplQueues() || !block.isComplete() -> IF_FALSE: !hasEnoughEffectiveReplicas(block, repl, pendingNum) -> CALL: neededReconstruction.remove -> CALL: NameNode.blockStateChangeLog.debug -> CALL: decrementBlockStat -> CALL: writeUnlock -> EXIT</exec_flow>\n      <log_sequence>ENTRY, CALL: writeLock, TRY, IF_FALSE: !isPopulatingReplQueues() || !block.isComplete(), IF_FALSE: !hasEnoughEffectiveReplicas(block, repl, pendingNum), CALL: neededReconstruction.remove, CALL: NameNode.blockStateChangeLog.debug, CALL: decrementBlockStat, CALL: writeUnlock, EXIT</log_sequence>\n    </path>\n  </valid_paths>\n  <pruned_paths>\n    <path id=\"P1-C4\" reason=\"Conflict: Conditional mismatch between parent and child paths\"/>\n    <path id=\"P1-C5\" reason=\"Conflict: Data flow inconsistency detected\"/>\n    <path id=\"P1-C2\" reason=\"Conflict: Conditional mismatch in !isPopulatingReplQueues() || !block.isComplete() and isComplete() evaluation.\"/>\n    <path id=\"P2-C2\" reason=\"Conflict: Data flow inconsistency in !hasEnoughEffectiveReplicas(block, repl, pendingNum) evaluation.\"/>\n  </pruned_paths>\n</merge_result>\n```",
  "org.apache.hadoop.hdfs.server.blockmanagement.CorruptReplicasMap:addToCorruptReplicasMap(org.apache.hadoop.hdfs.protocol.Block,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor,java.lang.String,org.apache.hadoop.hdfs.server.blockmanagement.CorruptReplicasMap$Reason,boolean)": "['ENTRY -> IF_TRUE: nodes == null -> NEW: HashMap<DatanodeDescriptor, Reason> -> CALL: corruptReplicasMap.put -> CALL: incrementBlockStat -> IF_TRUE: reason != null -> IF_TRUE: !nodes.keySet().contains(dn) -> CALL: NameNode.blockStateChangeLog.debug -> CALL: put -> EXIT', 'ENTRY -> IF_TRUE: nodes == null -> NEW: HashMap<DatanodeDescriptor, Reason> -> CALL: corruptReplicasMap.put -> CALL: incrementBlockStat -> IF_TRUE: reason != null -> IF_FALSE: !nodes.keySet().contains(dn) -> CALL: NameNode.blockStateChangeLog.debug -> CALL: put -> EXIT', 'ENTRY -> IF_TRUE: nodes == null -> NEW: HashMap<DatanodeDescriptor, Reason> -> CALL: corruptReplicasMap.put -> CALL: incrementBlockStat -> IF_FALSE: reason != null -> IF_TRUE: !nodes.keySet().contains(dn) -> CALL: NameNode.blockStateChangeLog.debug -> CALL: put -> EXIT', 'ENTRY -> IF_TRUE: nodes == null -> NEW: HashMap<DatanodeDescriptor, Reason> -> CALL: corruptReplicasMap.put -> CALL: incrementBlockStat -> IF_FALSE: reason != null -> IF_FALSE: !nodes.keySet().contains(dn) -> CALL: NameNode.blockStateChangeLog.debug -> CALL: put -> EXIT', 'ENTRY -> IF_FALSE: nodes == null -> IF_TRUE: reason != null -> IF_TRUE: !nodes.keySet().contains(dn) -> CALL: NameNode.blockStateChangeLog.debug -> CALL: put -> EXIT', 'ENTRY -> IF_FALSE: nodes == null -> IF_TRUE: reason != null -> IF_FALSE: !nodes.keySet().contains(dn) -> CALL: NameNode.blockStateChangeLog.debug -> CALL: put -> EXIT', 'ENTRY -> IF_FALSE: nodes == null -> IF_FALSE: reason != null -> IF_TRUE: !nodes.keySet().contains(dn) -> CALL: NameNode.blockStateChangeLog.debug -> CALL: put -> EXIT', 'ENTRY -> IF_FALSE: nodes == null -> IF_FALSE: reason != null -> IF_FALSE: !nodes.keySet().contains(dn) -> CALL: NameNode.blockStateChangeLog.debug -> CALL: put -> EXIT']"
}