org.apache.hadoop.security.authentication.examples.RequestLoggerFilter$XHttpServletResponse:setStatus(int,java.lang.String)	java.lang.Deprecated
org.apache.hadoop.security.authentication.client.KerberosAuthenticator:wrapExceptionWithMessage(java.lang.Exception,java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.security.authentication.server.LdapAuthenticationHandler:setEnableStartTls(java.lang.Boolean)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.security.authentication.server.LdapAuthenticationHandler:setDisableHostNameVerification(java.lang.Boolean)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.security.authentication.server.JWTRedirectAuthenticationHandler:constructLoginURL(javax.servlet.http.HttpServletRequest)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.security.authentication.util.KerberosUtil:getOidInstance(java.lang.String)	java.lang.Deprecated
org.apache.hadoop.security.authentication.util.KerberosName:resetDefaultRealm()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.security.authentication.util.ZKSignerSecretProvider:<init>(long)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.security.authentication.util.ZKSignerSecretProvider:generateRandomSecret()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.security.authentication.util.RandomSignerSecretProvider:<init>(long)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.conf.ConfServlet:parseAcceptHeader(javax.servlet.http.HttpServletRequest)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.conf.ReconfigurableBase:setReconfigurationUtil(org.apache.hadoop.conf.ReconfigurationUtil)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.conf.ReconfigurableBase:getChangedProperties(org.apache.hadoop.conf.Configuration,org.apache.hadoop.conf.Configuration)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.conf.Configuration:addDeprecation(java.lang.String,java.lang.String[],java.lang.String)	java.lang.Deprecated
org.apache.hadoop.conf.Configuration:addDeprecation(java.lang.String,java.lang.String[])	java.lang.Deprecated
org.apache.hadoop.conf.Configuration:setAllowNullValueProperties(boolean)	org.apache.hadoop.classification.VisibleForTesting
org.apache.hadoop.conf.Configuration:onlyKeyExists(java.lang.String)	org.apache.hadoop.classification.VisibleForTesting
org.apache.hadoop.conf.Configuration:logDeprecation(java.lang.String)	org.apache.hadoop.classification.VisibleForTesting
org.apache.hadoop.conf.Configuration:getPropertySources(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.tools.GetUserMappingsProtocol:getGroupsForUser(java.lang.String)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.ipc.CallerContext:isContextValid()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.ipc.ProtobufRpcEngine2$Server:registerForDeferredResponse2()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.ipc.metrics.RpcMetrics:numOpenConnections()	org.apache.hadoop.metrics2.annotation.Metric	value	{Number of open connections}
org.apache.hadoop.ipc.metrics.RpcMetrics:numOpenConnectionsPerUser()	org.apache.hadoop.metrics2.annotation.Metric	value	{Number of open connections per user}
org.apache.hadoop.ipc.metrics.RpcMetrics:callQueueLength()	org.apache.hadoop.metrics2.annotation.Metric	value	{Length of the call queue}
org.apache.hadoop.ipc.metrics.RpcMetrics:numDroppedConnections()	org.apache.hadoop.metrics2.annotation.Metric	value	{Number of dropped connections}
org.apache.hadoop.ipc.metrics.RpcMetrics:getTotalRequests()	org.apache.hadoop.metrics2.annotation.Metric	value	{Number of total requests}
org.apache.hadoop.ipc.metrics.RpcMetrics:getTotalRequestsPerSecond()	org.apache.hadoop.metrics2.annotation.Metric	value	{Number of total requests per second}
org.apache.hadoop.ipc.metrics.RpcMetrics:getTag(java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.ipc.metrics.DecayRpcSchedulerDetailedMetrics:getRpcQueueRates()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.ipc.metrics.DecayRpcSchedulerDetailedMetrics:getRpcProcessingRates()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.ipc.ProtocolSignature:resetCache()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.ipc.DecayRpcScheduler:getPriorityLevel(org.apache.hadoop.security.UserGroupInformation)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.ipc.DecayRpcScheduler:setPriorityLevel(org.apache.hadoop.security.UserGroupInformation,int)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.ipc.DecayRpcScheduler:getDecayFactor()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.ipc.DecayRpcScheduler:getDecayPeriodMillis()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.ipc.DecayRpcScheduler:getThresholds()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.ipc.DecayRpcScheduler:forceDecay()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.ipc.DecayRpcScheduler:getCallCostSnapshot()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.ipc.DecayRpcScheduler:getTotalCallSnapshot()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.ipc.DecayRpcScheduler:getDecayRpcSchedulerDetailedMetrics()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RpcSaslProto$SaslState:valueOf(int)	java.lang.Deprecated
org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RpcRequestHeaderProto$OperationProto:valueOf(int)	java.lang.Deprecated
org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RpcResponseHeaderProto$RpcStatusProto:valueOf(int)	java.lang.Deprecated
org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RpcKindProto:valueOf(int)	java.lang.Deprecated
org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RpcResponseHeaderProto$RpcErrorCodeProto:valueOf(int)	java.lang.Deprecated
org.apache.hadoop.ipc.ClientCache:clearCache()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.ipc.FairCallQueue:putQueue(int,org.apache.hadoop.ipc.Schedulable)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.ipc.FairCallQueue:offerQueue(int,org.apache.hadoop.ipc.Schedulable)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.ipc.FairCallQueue:setMultiplexer(org.apache.hadoop.ipc.RpcMultiplexer)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.ipc.WritableRpcEngine$Server:<init>(java.lang.Object,org.apache.hadoop.conf.Configuration,java.lang.String,int)	java.lang.Deprecated
org.apache.hadoop.ipc.WritableRpcEngine$Server:<init>(java.lang.Object,org.apache.hadoop.conf.Configuration,java.lang.String,int,int,int,int,boolean,org.apache.hadoop.security.token.SecretManager)	java.lang.Deprecated
org.apache.hadoop.ipc.WritableRpcEngine$Server:<init>(java.lang.Class,java.lang.Object,org.apache.hadoop.conf.Configuration,java.lang.String,int,int,int,int,boolean,org.apache.hadoop.security.token.SecretManager,java.lang.String)	java.lang.Deprecated
org.apache.hadoop.ipc.RetryCache:getCacheSet()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.ipc.RetryCache:getMetricsForTests()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.ipc.ProtobufRpcEngine$Server:registerForDeferredResponse()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.ipc.ProtobufRpcEngine2:getAsyncReturnMessage()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.ipc.ProtobufRpcEngine2:getClient(org.apache.hadoop.conf.Configuration)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.ipc.ProtobufRpcEngine2:getClient(org.apache.hadoop.conf.Configuration)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.ipc.ProtobufRpcEngine2:getClient(org.apache.hadoop.conf.Configuration)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.ipc.ProtobufRpcEngine2:clearClientCache()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.ipc.GenericRefreshProtocol:refresh(java.lang.String,java.lang.String[])	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.ipc.Client$ConnectionId:getSaslQop()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.ipc.Server:getCurCall()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.ipc.Server:setLogSlowRPC(boolean)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.ipc.Server:getPurgeIntervalNanos()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.ipc.Server:getPriorityLevel(org.apache.hadoop.ipc.Schedulable)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.ipc.Server:getPriorityLevel(org.apache.hadoop.security.UserGroupInformation)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.ipc.Server:setPriorityLevel(org.apache.hadoop.security.UserGroupInformation,int)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.ipc.Server:getRpcMetrics()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.ipc.Server:getRpcDetailedMetrics()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.ipc.Server:getHandlers()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.ipc.Server:getConnections()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.ipc.Server:refreshServiceAclWithLoadedConfiguration(org.apache.hadoop.conf.Configuration,org.apache.hadoop.security.authorize.PolicyProvider)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.ipc.Server:getServiceAuthorizationManager()	org.apache.hadoop.classification.InterfaceAudience$LimitedPrivate	value	{HDFS,MapReduce}
org.apache.hadoop.ipc.Server:logException(org.slf4j.Logger,java.lang.Throwable,org.apache.hadoop.ipc.Server$Call)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.ipc.Server:call(org.apache.hadoop.io.Writable,long)	java.lang.Deprecated
org.apache.hadoop.ipc.WritableRpcEngine:getClient(org.apache.hadoop.conf.Configuration)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.ipc.WritableRpcEngine:getClient(org.apache.hadoop.conf.Configuration)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.ipc.ProtobufHelper:getRemoteException(com.google.protobuf.ServiceException)	java.lang.Deprecated
org.apache.hadoop.ipc.RefreshCallQueueProtocol:refreshCallQueue()	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.ipc.RPC$Builder:setnumReaders(int)	java.lang.Deprecated
org.apache.hadoop.ipc.CallQueueManager:<init>(java.util.concurrent.BlockingQueue,org.apache.hadoop.ipc.RpcScheduler,boolean,boolean)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.ipc.CallQueueManager:addInternal(org.apache.hadoop.ipc.Schedulable,boolean)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.ipc.Client:getAsyncRpcResponse()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.ipc.Client:getTimeout(org.apache.hadoop.conf.Configuration)	java.lang.Deprecated
org.apache.hadoop.ipc.Client:isAsynchronousMode()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.ipc.Client:setAsynchronousMode(boolean)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.ipc.Client:getAsyncCallCount()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.ipc.Client:getConnectionIds()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.ipc.Client:getConnectionIds()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.ipc.Client:close()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.ipc.RpcScheduler:addResponseTime(java.lang.String,int,int,int)	java.lang.Deprecated
org.apache.hadoop.ipc.ProtobufRpcEngine:getAsyncReturnMessage()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.ipc.ProtobufRpcEngine:getClient(org.apache.hadoop.conf.Configuration)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.ipc.ProtobufRpcEngine:getClient(org.apache.hadoop.conf.Configuration)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.ipc.ProtobufRpcEngine:getClient(org.apache.hadoop.conf.Configuration)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.ipc.Server$Call:<init>(int,int,java.lang.Void,java.lang.Void,org.apache.hadoop.ipc.RPC$RpcKind,byte[])	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.ipc.Server$Call:postponeResponse()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.ipc.Server$Call:postponeResponse()	org.apache.hadoop.classification.InterfaceAudience$LimitedPrivate	value	{HDFS}
org.apache.hadoop.ipc.Server$Call:sendResponse()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.ipc.Server$Call:sendResponse()	org.apache.hadoop.classification.InterfaceAudience$LimitedPrivate	value	{HDFS}
org.apache.hadoop.ipc.Server$Call:abortResponse(java.lang.Throwable)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.ipc.Server$Call:abortResponse(java.lang.Throwable)	org.apache.hadoop.classification.InterfaceAudience$LimitedPrivate	value	{HDFS}
org.apache.hadoop.ipc.Server$Call:deferResponse()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.ipc.Server$Call:isResponseDeferred()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.http.HttpServer2:getPort()	java.lang.Deprecated
org.apache.hadoop.log.metrics.EventCounter:getFatal()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.log.metrics.EventCounter:getError()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.log.metrics.EventCounter:getWarn()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.log.metrics.EventCounter:getInfo()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.log.LogThrottlingHelper:<init>(long,java.lang.String,org.apache.hadoop.util.Timer)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.log.LogThrottlingHelper:reset()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.metrics2.source.JvmMetrics:registerIfNeeded()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.metrics2.source.JvmMetrics:<init>(java.lang.String,java.lang.String,boolean)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.metrics2.MetricsSystem:init(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.metrics2.MetricsSystem:getSource(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.metrics2.lib.MutableQuantiles:getEstimator()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.metrics2.lib.MutableRollingAverages:replaceScheduledTask(int,long,java.util.concurrent.TimeUnit)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.metrics2.lib.MutableRollingAverages:setRecordValidityMs(long)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.metrics2.lib.DefaultMetricsSystem:setInstance(org.apache.hadoop.metrics2.MetricsSystem)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.metrics2.lib.DefaultMetricsSystem:setMiniClusterMode(boolean)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.metrics2.lib.DefaultMetricsSystem:inMiniClusterMode()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.metrics2.lib.DefaultMetricsSystem:newMBeanName(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.metrics2.lib.DefaultMetricsSystem:removeMBeanName(javax.management.ObjectName)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.metrics2.lib.DefaultMetricsSystem:removeSourceName(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.metrics2.lib.DefaultMetricsSystem:sourceName(java.lang.String,boolean)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.metrics2.lib.MetricsRegistry:newRate(java.lang.String,java.lang.String,boolean,boolean)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.metrics2.util.MetricsCache$Record:metrics()	java.lang.Deprecated
org.apache.hadoop.metrics2.util.SampleQuantiles:getSampleCount()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.metrics2.util.MBeans:getMBeanName(java.lang.String,java.lang.String,java.util.Map)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.metrics2.impl.MetricsSourceAdapter:getMBeanName()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.metrics2.impl.MetricsSourceAdapter:getJmxCacheTTL()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.metrics2.impl.MetricsSystemImpl:sampleMetrics()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.metrics2.impl.MetricsSystemImpl:getSourceAdapter(java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.metrics2.impl.MetricsSystemImpl:getSinkAdapter(java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.metrics2.impl.MetricsCollectorImpl:clear()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.metrics2.sink.RollingFileSystemSink:<init>(long,long)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.metrics2.sink.RollingFileSystemSink:getRollInterval()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.metrics2.sink.RollingFileSystemSink:updateFlushTime(java.util.Date)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.metrics2.sink.RollingFileSystemSink:setInitialFlushTime(java.util.Date)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.metrics2.sink.ganglia.GangliaSink30:appendPrefix(org.apache.hadoop.metrics2.MetricsRecord,java.lang.StringBuilder)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.net.NetworkTopology:setRandomSeed(long)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.net.NetworkTopology:countNumOfAvailableNodes(java.lang.String,java.util.Collection)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.net.NetworkTopology:getWeight(org.apache.hadoop.net.Node,org.apache.hadoop.net.Node)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.net.NetworkTopology:getWeightUsingNetworkLocation(org.apache.hadoop.net.Node,org.apache.hadoop.net.Node)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.net.unix.DomainSocketWatcher:isClosed()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.net.unix.DomainSocket:validateSocketPathSecurity0(java.lang.String,int)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.net.unix.DomainSocket:disableBindPathValidation()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.FSProtos$FileStatusProto$Flags:valueOf(int)	java.lang.Deprecated
org.apache.hadoop.fs.FilterFs:getServerDefaults()	java.lang.Deprecated
org.apache.hadoop.fs.shell.Ls:isPathOnly()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.shell.Ls:isDirRecurse()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.shell.Ls:isHumanReadable()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.shell.Ls:isHideNonPrintable()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.shell.Ls:isOrderReverse()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.shell.Ls:isOrderTime()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.shell.Ls:isOrderSize()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.shell.Ls:isUseAtime()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.shell.Ls:isDisplayECPolicy()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.shell.CommandFormat:<init>(java.lang.String,int,int,java.lang.String[])	java.lang.Deprecated
org.apache.hadoop.fs.shell.CopyCommandWithMultiThread:getThreadCount()	org.apache.hadoop.classification.VisibleForTesting
org.apache.hadoop.fs.shell.CopyCommandWithMultiThread:getThreadPoolQueueSize()	org.apache.hadoop.classification.VisibleForTesting
org.apache.hadoop.fs.shell.CopyCommandWithMultiThread:getExecutor()	org.apache.hadoop.classification.VisibleForTesting
org.apache.hadoop.fs.shell.CopyCommandWithMultiThread:isMultiThreadNecessary(java.util.LinkedList)	org.apache.hadoop.classification.VisibleForTesting
org.apache.hadoop.fs.shell.Concat:setTestFs(org.apache.hadoop.fs.FileSystem)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.shell.find.Find:setRootExpression(org.apache.hadoop.fs.shell.find.Expression)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.fs.shell.find.Find:getRootExpression()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.fs.shell.find.Find:getOptions()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.fs.shell.FsCommand:runAll()	java.lang.Deprecated
org.apache.hadoop.fs.shell.TouchCommands$Touch:getDateFormat()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.fs.shell.TouchCommands$Touch:getDateFormat()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.shell.Count:<init>(java.lang.String[],int,org.apache.hadoop.conf.Configuration)	java.lang.Deprecated
org.apache.hadoop.fs.shell.Count:isShowQuotas()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.fs.shell.Count:isHumanReadable()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.fs.shell.Count:isShowQuotabyType()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.fs.shell.Count:getStorageTypes()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.fs.shell.Tail:getFollowDelay()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.CachingGetSpaceUsed:getRefreshInterval()	org.apache.hadoop.classification.VisibleForTesting
org.apache.hadoop.fs.CachingGetSpaceUsed:getJitter()	org.apache.hadoop.classification.VisibleForTesting
org.apache.hadoop.fs.FSDataInputStream:getWrappedStream()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.fs.FSDataInputStream:getWrappedStream()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.fs.sftp.SFTPFileSystem:getConnectionPool()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.TrashPolicyDefault:initialize(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.FileSystem,org.apache.hadoop.fs.Path)	java.lang.Deprecated
org.apache.hadoop.fs.Path:makeQualified(org.apache.hadoop.fs.FileSystem)	java.lang.Deprecated
org.apache.hadoop.fs.Path:makeQualified(java.net.URI,org.apache.hadoop.fs.Path)	org.apache.hadoop.classification.InterfaceAudience$LimitedPrivate	value	{HDFS,MapReduce}
org.apache.hadoop.fs.FSBuilder:opt(java.lang.String,float)	java.lang.Deprecated
org.apache.hadoop.fs.FSBuilder:opt(java.lang.String,double)	java.lang.Deprecated
org.apache.hadoop.fs.FSBuilder:must(java.lang.String,float)	java.lang.Deprecated
org.apache.hadoop.fs.FSBuilder:must(java.lang.String,long)	java.lang.Deprecated
org.apache.hadoop.fs.FSBuilder:must(java.lang.String,double)	java.lang.Deprecated
org.apache.hadoop.fs.AbstractFileSystem:getServerDefaults()	java.lang.Deprecated
org.apache.hadoop.fs.AbstractFileSystem:access(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.permission.FsAction)	org.apache.hadoop.classification.InterfaceAudience$LimitedPrivate	value	{HDFS,Hive}
org.apache.hadoop.fs.AbstractFileSystem:getDelegationTokens(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$LimitedPrivate	value	{HDFS,MapReduce}
org.apache.hadoop.fs.AbstractFileSystem:createMultipartUploader(org.apache.hadoop.fs.Path)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.fs.LocalDirAllocator:removeContext(java.lang.String)	java.lang.Deprecated
org.apache.hadoop.fs.LocalDirAllocator:removeContext(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$LimitedPrivate	value	{MapReduce}
org.apache.hadoop.fs.Seekable:seekToNewSource(long)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.fs.DU:<init>(java.io.File,long,long,long)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.FileSystem:addFileSystemForTesting(java.net.URI,org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.FileSystem)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.FileSystem:removeFileSystemForTesting(java.net.URI,org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.FileSystem)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.FileSystem:cacheSize()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.FileSystem:getCanonicalServiceName()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.fs.FileSystem:getCanonicalServiceName()	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.fs.FileSystem:getName()	java.lang.Deprecated
org.apache.hadoop.fs.FileSystem:getNamed(java.lang.String,org.apache.hadoop.conf.Configuration)	java.lang.Deprecated
org.apache.hadoop.fs.FileSystem:getDelegationToken(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.fs.FileSystem:getChildFileSystems()	org.apache.hadoop.classification.InterfaceAudience$LimitedPrivate	value	{HDFS}
org.apache.hadoop.fs.FileSystem:getChildFileSystems()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.FileSystem:getAdditionalTokenIssuers()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.fs.FileSystem:getServerDefaults()	java.lang.Deprecated
org.apache.hadoop.fs.FileSystem:primitiveCreate(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.permission.FsPermission,java.util.EnumSet,int,short,long,org.apache.hadoop.util.Progressable,org.apache.hadoop.fs.Options$ChecksumOpt)	java.lang.Deprecated
org.apache.hadoop.fs.FileSystem:primitiveMkdir(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.permission.FsPermission)	java.lang.Deprecated
org.apache.hadoop.fs.FileSystem:primitiveMkdir(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.permission.FsPermission,boolean)	java.lang.Deprecated
org.apache.hadoop.fs.FileSystem:getReplication(org.apache.hadoop.fs.Path)	java.lang.Deprecated
org.apache.hadoop.fs.FileSystem:rename(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Options$Rename[])	java.lang.Deprecated
org.apache.hadoop.fs.FileSystem:delete(org.apache.hadoop.fs.Path)	java.lang.Deprecated
org.apache.hadoop.fs.FileSystem:isDirectory(org.apache.hadoop.fs.Path)	java.lang.Deprecated
org.apache.hadoop.fs.FileSystem:isFile(org.apache.hadoop.fs.Path)	java.lang.Deprecated
org.apache.hadoop.fs.FileSystem:getLength(org.apache.hadoop.fs.Path)	java.lang.Deprecated
org.apache.hadoop.fs.FileSystem:listStatusBatch(org.apache.hadoop.fs.Path,byte[])	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.fs.FileSystem:getBlockSize(org.apache.hadoop.fs.Path)	java.lang.Deprecated
org.apache.hadoop.fs.FileSystem:getDefaultBlockSize()	java.lang.Deprecated
org.apache.hadoop.fs.FileSystem:getDefaultReplication()	java.lang.Deprecated
org.apache.hadoop.fs.FileSystem:access(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.permission.FsAction)	org.apache.hadoop.classification.InterfaceAudience$LimitedPrivate	value	{HDFS,Hive}
org.apache.hadoop.fs.FileSystem:checkAccessPermissions(org.apache.hadoop.fs.FileStatus,org.apache.hadoop.fs.permission.FsAction)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.fs.FileSystem:getStatistics()	java.lang.Deprecated
org.apache.hadoop.fs.FileSystem:getAllStatistics()	java.lang.Deprecated
org.apache.hadoop.fs.FileSystem:getStatistics(java.lang.String,java.lang.Class)	java.lang.Deprecated
org.apache.hadoop.fs.FileSystem:areSymlinksEnabled()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.FileSystem:enableSymlinks()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.FileSystem:createDataOutputStreamBuilder(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.fs.Path)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.fs.FileSystem:openFile(org.apache.hadoop.fs.Path)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.fs.FileSystem:openFile(org.apache.hadoop.fs.PathHandle)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.fs.FileSystem:createDataInputStreamBuilder(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.fs.Path)	org.apache.hadoop.classification.InterfaceAudience$LimitedPrivate	value	{Filesystems}
org.apache.hadoop.fs.FileSystem:createDataInputStreamBuilder(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.fs.Path)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.fs.FileSystem:createDataInputStreamBuilder(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.fs.PathHandle)	org.apache.hadoop.classification.InterfaceAudience$LimitedPrivate	value	{Filesystems}
org.apache.hadoop.fs.FileSystem:createDataInputStreamBuilder(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.fs.PathHandle)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.fs.FileSystem:createMultipartUploader(org.apache.hadoop.fs.Path)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.fs.DelegationTokenRenewer:getRenewQueueLength()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.DelegationTokenRenewer:reset()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.permission.AclEntryType:toString()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.fs.permission.FsPermission:write(java.io.DataOutput)	java.lang.Deprecated
org.apache.hadoop.fs.permission.FsPermission:readFields(java.io.DataInput)	java.lang.Deprecated
org.apache.hadoop.fs.permission.FsPermission:toExtendedShort()	java.lang.Deprecated
org.apache.hadoop.fs.permission.FsPermission:getAclBit()	java.lang.Deprecated
org.apache.hadoop.fs.permission.FsPermission:getEncryptedBit()	java.lang.Deprecated
org.apache.hadoop.fs.permission.FsPermission:getErasureCodedBit()	java.lang.Deprecated
org.apache.hadoop.fs.permission.AclEntry:toString()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.fs.FileUtil:fullyDelete(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.fs.Path)	java.lang.Deprecated
org.apache.hadoop.fs.FileUtil:rename(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Options$Rename[])	org.apache.hadoop.classification.InterfaceAudience$LimitedPrivate	value	{ViewDistributedFileSystem}
org.apache.hadoop.fs.FileUtil:rename(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Options$Rename[])	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.fs.local.RawLocalFs:getServerDefaults()	java.lang.Deprecated
org.apache.hadoop.fs.FileStatus:isDir()	java.lang.Deprecated
org.apache.hadoop.fs.FileStatus:readFields(java.io.DataInput)	java.lang.Deprecated
org.apache.hadoop.fs.FileStatus:write(java.io.DataOutput)	java.lang.Deprecated
org.apache.hadoop.fs.FsServerDefaults:write(java.io.DataOutput)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.fs.FsServerDefaults:readFields(java.io.DataInput)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.fs.FSInputChecker:checksum2long(byte[])	java.lang.Deprecated
org.apache.hadoop.fs.FSDataOutputStream:getWrappedStream()	org.apache.hadoop.classification.InterfaceAudience$LimitedPrivate	value	{HDFS}
org.apache.hadoop.fs.DF:parseOutput()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.ftp.FtpFs:getServerDefaults()	java.lang.Deprecated
org.apache.hadoop.fs.ftp.FTPFileSystem:setTimeout(org.apache.commons.net.ftp.FTPClient,org.apache.hadoop.conf.Configuration)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.ftp.FTPFileSystem:getTransferMode(org.apache.hadoop.conf.Configuration)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.ftp.FTPFileSystem:setDataConnectionMode(org.apache.commons.net.ftp.FTPClient,org.apache.hadoop.conf.Configuration)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.ftp.FTPFileSystem:getFsAction(int,org.apache.commons.net.ftp.FTPFile)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.viewfs.ViewFs$InternalDirOfViewFs:getServerDefaults()	java.lang.Deprecated
org.apache.hadoop.fs.viewfs.ChRootedFs:getServerDefaults()	java.lang.Deprecated
org.apache.hadoop.fs.viewfs.ViewFs:getServerDefaults()	java.lang.Deprecated
org.apache.hadoop.fs.statistics.MeanStatistic:isEmpty()	com.fasterxml.jackson.annotation.JsonIgnore
org.apache.hadoop.fs.statistics.impl.IOStatisticsContextIntegration:getThreadSpecificIOStatisticsContext(long)	org.apache.hadoop.classification.VisibleForTesting
org.apache.hadoop.fs.statistics.impl.IOStatisticsContextIntegration:enableIOStatisticsContext()	org.apache.hadoop.classification.VisibleForTesting
org.apache.hadoop.fs.FSProtos$FileStatusProto$FileType:valueOf(int)	java.lang.Deprecated
org.apache.hadoop.fs.ContentSummary:<init>()	java.lang.Deprecated
org.apache.hadoop.fs.ContentSummary:<init>(long,long,long)	java.lang.Deprecated
org.apache.hadoop.fs.ContentSummary:<init>(long,long,long,long,long,long)	java.lang.Deprecated
org.apache.hadoop.fs.ContentSummary:write(java.io.DataOutput)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.fs.ContentSummary:readFields(java.io.DataInput)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.fs.FileSystem$Statistics:getAllThreadLocalDataSize()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.TrashPolicy:initialize(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.FileSystem,org.apache.hadoop.fs.Path)	java.lang.Deprecated
org.apache.hadoop.fs.TrashPolicy:getInstance(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.FileSystem,org.apache.hadoop.fs.Path)	java.lang.Deprecated
org.apache.hadoop.fs.RawLocalFileSystem:useStatIfAvailable()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.RawLocalFileSystem:handleEmptyDstDirectoryOnWindows(org.apache.hadoop.fs.Path,java.io.File,org.apache.hadoop.fs.Path,java.io.File)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.RawLocalFileSystem:deprecatedGetFileStatus(org.apache.hadoop.fs.Path)	java.lang.Deprecated
org.apache.hadoop.fs.RawLocalFileSystem:deprecatedGetFileLinkStatusInternal(org.apache.hadoop.fs.Path)	java.lang.Deprecated
org.apache.hadoop.fs.Stat:getFileStatusForTesting()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.impl.FutureIOSupport:awaitFuture(java.util.concurrent.Future)	java.lang.Deprecated
org.apache.hadoop.fs.impl.FutureIOSupport:awaitFuture(java.util.concurrent.Future,long,java.util.concurrent.TimeUnit)	java.lang.Deprecated
org.apache.hadoop.fs.impl.FutureIOSupport:raiseInnerCause(java.util.concurrent.ExecutionException)	java.lang.Deprecated
org.apache.hadoop.fs.impl.FutureIOSupport:raiseInnerCause(java.util.concurrent.CompletionException)	java.lang.Deprecated
org.apache.hadoop.fs.impl.FutureIOSupport:propagateOptions(org.apache.hadoop.fs.FSBuilder,org.apache.hadoop.conf.Configuration,java.lang.String,java.lang.String)	java.lang.Deprecated
org.apache.hadoop.fs.impl.FutureIOSupport:propagateOptions(org.apache.hadoop.fs.FSBuilder,org.apache.hadoop.conf.Configuration,java.lang.String,boolean)	java.lang.Deprecated
org.apache.hadoop.fs.TrashPolicyDefault$Emptier:getEmptierInterval()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.DelegateToFileSystem:getServerDefaults()	java.lang.Deprecated
org.apache.hadoop.fs.RawLocalFileSystem$DeprecatedRawLocalFileStatus:loadPermissionInfoByNonNativeIO()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.RawLocalFileSystem$DeprecatedRawLocalFileStatus:loadPermissionInfoByNativeIO()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.FileContext:getDefaultFileSystem()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.fs.FileContext:getDefaultFileSystem()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.fs.FileContext:getDefaultFileSystem()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.FileContext:access(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.permission.FsAction)	org.apache.hadoop.classification.InterfaceAudience$LimitedPrivate	value	{HDFS,Hive}
org.apache.hadoop.fs.FileContext:getFileBlockLocations(org.apache.hadoop.fs.Path,long,long)	org.apache.hadoop.classification.InterfaceAudience$LimitedPrivate	value	{HDFS,MapReduce}
org.apache.hadoop.fs.FileContext:getFileBlockLocations(org.apache.hadoop.fs.Path,long,long)	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.fs.FileContext:getDelegationTokens(org.apache.hadoop.fs.Path,java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$LimitedPrivate	value	{HDFS,MapReduce}
org.apache.hadoop.fs.FileContext:openFile(org.apache.hadoop.fs.Path)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.fs.FileContext:createMultipartUploader(org.apache.hadoop.fs.Path)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.fs.LocatedFileStatus:<init>(long,boolean,int,long,long,long,org.apache.hadoop.fs.permission.FsPermission,java.lang.String,java.lang.String,org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path,org.apache.hadoop.fs.BlockLocation[])	java.lang.Deprecated
org.apache.hadoop.fs.FileSystem$Cache:getDiscardedInstances()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.crypto.key.KeyProviderDelegationTokenExtension$DelegationTokenExtension:selectDelegationToken(org.apache.hadoop.security.Credentials)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.crypto.key.KeyProviderDelegationTokenExtension$DelegationTokenExtension:selectDelegationToken(org.apache.hadoop.security.Credentials)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.crypto.key.KeyProviderDelegationTokenExtension$DelegationTokenExtension:selectDelegationToken(org.apache.hadoop.security.Credentials)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider:<init>(org.apache.hadoop.crypto.key.kms.KMSClientProvider[],long,org.apache.hadoop.conf.Configuration)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider:getProviders()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.crypto.key.kms.KMSClientProvider:getEncKeyQueueSize(java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.crypto.key.kms.KMSClientProvider:createAuthenticatedURL()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.crypto.key.kms.KMSClientProvider:selectDelegationToken(org.apache.hadoop.security.Credentials)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.crypto.key.kms.KMSClientProvider:getActualUgi()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.crypto.key.kms.KMSClientProvider:getKMSUrl()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.crypto.key.JavaKeyStoreProvider:<init>(org.apache.hadoop.crypto.key.JavaKeyStoreProvider)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.io.file.tfile.TFile$Reader:createScanner(byte[],byte[])	java.lang.Deprecated
org.apache.hadoop.io.file.tfile.TFile$Reader:createScanner(org.apache.hadoop.io.file.tfile.RawComparable,org.apache.hadoop.io.file.tfile.RawComparable)	java.lang.Deprecated
org.apache.hadoop.io.MapFile$Reader:<init>(org.apache.hadoop.fs.FileSystem,java.lang.String,org.apache.hadoop.conf.Configuration)	java.lang.Deprecated
org.apache.hadoop.io.MapFile$Reader:<init>(org.apache.hadoop.fs.FileSystem,java.lang.String,org.apache.hadoop.io.WritableComparator,org.apache.hadoop.conf.Configuration)	java.lang.Deprecated
org.apache.hadoop.io.WeakReferencedElasticByteBufferPool:getCurrentBuffersCount(boolean)	org.apache.hadoop.classification.VisibleForTesting
org.apache.hadoop.io.SequenceFile:createWriter(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path,java.lang.Class,java.lang.Class)	java.lang.Deprecated
org.apache.hadoop.io.SequenceFile:createWriter(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path,java.lang.Class,java.lang.Class,org.apache.hadoop.io.SequenceFile$CompressionType)	java.lang.Deprecated
org.apache.hadoop.io.SequenceFile:createWriter(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path,java.lang.Class,java.lang.Class,org.apache.hadoop.io.SequenceFile$CompressionType,org.apache.hadoop.util.Progressable)	java.lang.Deprecated
org.apache.hadoop.io.SequenceFile:createWriter(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path,java.lang.Class,java.lang.Class,org.apache.hadoop.io.SequenceFile$CompressionType,org.apache.hadoop.io.compress.CompressionCodec)	java.lang.Deprecated
org.apache.hadoop.io.SequenceFile:createWriter(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path,java.lang.Class,java.lang.Class,org.apache.hadoop.io.SequenceFile$CompressionType,org.apache.hadoop.io.compress.CompressionCodec,org.apache.hadoop.util.Progressable,org.apache.hadoop.io.SequenceFile$Metadata)	java.lang.Deprecated
org.apache.hadoop.io.SequenceFile:createWriter(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path,java.lang.Class,java.lang.Class,int,short,long,org.apache.hadoop.io.SequenceFile$CompressionType,org.apache.hadoop.io.compress.CompressionCodec,org.apache.hadoop.util.Progressable,org.apache.hadoop.io.SequenceFile$Metadata)	java.lang.Deprecated
org.apache.hadoop.io.SequenceFile:createWriter(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path,java.lang.Class,java.lang.Class,int,short,long,boolean,org.apache.hadoop.io.SequenceFile$CompressionType,org.apache.hadoop.io.compress.CompressionCodec,org.apache.hadoop.io.SequenceFile$Metadata)	java.lang.Deprecated
org.apache.hadoop.io.SequenceFile:createWriter(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path,java.lang.Class,java.lang.Class,org.apache.hadoop.io.SequenceFile$CompressionType,org.apache.hadoop.io.compress.CompressionCodec,org.apache.hadoop.util.Progressable)	java.lang.Deprecated
org.apache.hadoop.io.SequenceFile:createWriter(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.FSDataOutputStream,java.lang.Class,java.lang.Class,org.apache.hadoop.io.SequenceFile$CompressionType,org.apache.hadoop.io.compress.CompressionCodec,org.apache.hadoop.io.SequenceFile$Metadata)	java.lang.Deprecated
org.apache.hadoop.io.SequenceFile:createWriter(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.FSDataOutputStream,java.lang.Class,java.lang.Class,org.apache.hadoop.io.SequenceFile$CompressionType,org.apache.hadoop.io.compress.CompressionCodec)	java.lang.Deprecated
org.apache.hadoop.io.BloomMapFile$Writer:<init>(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.FileSystem,java.lang.String,java.lang.Class,java.lang.Class,org.apache.hadoop.io.SequenceFile$CompressionType,org.apache.hadoop.io.compress.CompressionCodec,org.apache.hadoop.util.Progressable)	java.lang.Deprecated
org.apache.hadoop.io.BloomMapFile$Writer:<init>(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.FileSystem,java.lang.String,java.lang.Class,java.lang.Class,org.apache.hadoop.io.SequenceFile$CompressionType,org.apache.hadoop.util.Progressable)	java.lang.Deprecated
org.apache.hadoop.io.BloomMapFile$Writer:<init>(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.FileSystem,java.lang.String,java.lang.Class,java.lang.Class,org.apache.hadoop.io.SequenceFile$CompressionType)	java.lang.Deprecated
org.apache.hadoop.io.BloomMapFile$Writer:<init>(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.FileSystem,java.lang.String,org.apache.hadoop.io.WritableComparator,java.lang.Class,org.apache.hadoop.io.SequenceFile$CompressionType,org.apache.hadoop.io.compress.CompressionCodec,org.apache.hadoop.util.Progressable)	java.lang.Deprecated
org.apache.hadoop.io.BloomMapFile$Writer:<init>(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.FileSystem,java.lang.String,org.apache.hadoop.io.WritableComparator,java.lang.Class,org.apache.hadoop.io.SequenceFile$CompressionType,org.apache.hadoop.util.Progressable)	java.lang.Deprecated
org.apache.hadoop.io.BloomMapFile$Writer:<init>(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.FileSystem,java.lang.String,org.apache.hadoop.io.WritableComparator,java.lang.Class,org.apache.hadoop.io.SequenceFile$CompressionType)	java.lang.Deprecated
org.apache.hadoop.io.BloomMapFile$Writer:<init>(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.FileSystem,java.lang.String,org.apache.hadoop.io.WritableComparator,java.lang.Class)	java.lang.Deprecated
org.apache.hadoop.io.BloomMapFile$Writer:<init>(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.FileSystem,java.lang.String,java.lang.Class,java.lang.Class)	java.lang.Deprecated
org.apache.hadoop.io.MapFile$Writer:<init>(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.FileSystem,java.lang.String,java.lang.Class,java.lang.Class)	java.lang.Deprecated
org.apache.hadoop.io.MapFile$Writer:<init>(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.FileSystem,java.lang.String,java.lang.Class,java.lang.Class,org.apache.hadoop.io.SequenceFile$CompressionType,org.apache.hadoop.util.Progressable)	java.lang.Deprecated
org.apache.hadoop.io.MapFile$Writer:<init>(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.FileSystem,java.lang.String,java.lang.Class,java.lang.Class,org.apache.hadoop.io.SequenceFile$CompressionType,org.apache.hadoop.io.compress.CompressionCodec,org.apache.hadoop.util.Progressable)	java.lang.Deprecated
org.apache.hadoop.io.MapFile$Writer:<init>(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.FileSystem,java.lang.String,java.lang.Class,java.lang.Class,org.apache.hadoop.io.SequenceFile$CompressionType)	java.lang.Deprecated
org.apache.hadoop.io.MapFile$Writer:<init>(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.FileSystem,java.lang.String,org.apache.hadoop.io.WritableComparator,java.lang.Class)	java.lang.Deprecated
org.apache.hadoop.io.MapFile$Writer:<init>(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.FileSystem,java.lang.String,org.apache.hadoop.io.WritableComparator,java.lang.Class,org.apache.hadoop.io.SequenceFile$CompressionType)	java.lang.Deprecated
org.apache.hadoop.io.MapFile$Writer:<init>(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.FileSystem,java.lang.String,org.apache.hadoop.io.WritableComparator,java.lang.Class,org.apache.hadoop.io.SequenceFile$CompressionType,org.apache.hadoop.util.Progressable)	java.lang.Deprecated
org.apache.hadoop.io.MapFile$Writer:<init>(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.FileSystem,java.lang.String,org.apache.hadoop.io.WritableComparator,java.lang.Class,org.apache.hadoop.io.SequenceFile$CompressionType,org.apache.hadoop.io.compress.CompressionCodec,org.apache.hadoop.util.Progressable)	java.lang.Deprecated
org.apache.hadoop.io.SequenceFile$Writer:filesystem(org.apache.hadoop.fs.FileSystem)	java.lang.Deprecated
org.apache.hadoop.io.SequenceFile$Writer:<init>(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path,java.lang.Class,java.lang.Class)	java.lang.Deprecated
org.apache.hadoop.io.SequenceFile$Writer:<init>(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path,java.lang.Class,java.lang.Class,org.apache.hadoop.util.Progressable,org.apache.hadoop.io.SequenceFile$Metadata)	java.lang.Deprecated
org.apache.hadoop.io.SequenceFile$Writer:<init>(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path,java.lang.Class,java.lang.Class,int,short,long,org.apache.hadoop.util.Progressable,org.apache.hadoop.io.SequenceFile$Metadata)	java.lang.Deprecated
org.apache.hadoop.io.SequenceFile$Writer:syncFs()	java.lang.Deprecated
org.apache.hadoop.io.BloomMapFile$Reader:<init>(org.apache.hadoop.fs.FileSystem,java.lang.String,org.apache.hadoop.conf.Configuration)	java.lang.Deprecated
org.apache.hadoop.io.BloomMapFile$Reader:<init>(org.apache.hadoop.fs.FileSystem,java.lang.String,org.apache.hadoop.io.WritableComparator,org.apache.hadoop.conf.Configuration,boolean)	java.lang.Deprecated
org.apache.hadoop.io.BloomMapFile$Reader:<init>(org.apache.hadoop.fs.FileSystem,java.lang.String,org.apache.hadoop.io.WritableComparator,org.apache.hadoop.conf.Configuration)	java.lang.Deprecated
org.apache.hadoop.io.ReadaheadPool:resetInstance()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.io.WritableUtils:cloneInto(org.apache.hadoop.io.Writable,org.apache.hadoop.io.Writable)	java.lang.Deprecated
org.apache.hadoop.io.SecureIOUtils:forceSecureOpenForRandomRead(java.io.File,java.lang.String,java.lang.String,java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.io.SecureIOUtils:forceSecureOpenFSDataInputStream(java.io.File,java.lang.String,java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.io.SecureIOUtils:forceSecureOpenForRead(java.io.File,java.lang.String,java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.io.ElasticByteBufferPool:size(boolean)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.io.ElasticByteBufferPool:size(boolean)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.io.retry.RetryPolicies$RetryUpToMaximumTimeWithFixedSleep:constructReasonString(long,java.util.concurrent.TimeUnit)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.io.retry.RetryPolicies$RetryLimited:constructReasonString(int)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.io.retry.RetryInvocationHandler:isRpcInvocation(java.lang.Object)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.io.retry.RetryInvocationHandler:getProxyProvider()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.io.retry.AsyncCallHandler:getAsyncReturn()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.io.retry.AsyncCallHandler:setLowerLayerAsyncReturn(org.apache.hadoop.util.concurrent.AsyncGet)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.io.retry.AsyncCallHandler:getGracePeriod()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.io.BytesWritable:get()	java.lang.Deprecated
org.apache.hadoop.io.BytesWritable:getSize()	java.lang.Deprecated
org.apache.hadoop.io.serializer.avro.AvroReflectSerialization:accept(java.lang.Class)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.io.serializer.avro.AvroReflectSerialization:getReader(java.lang.Class)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.io.serializer.avro.AvroReflectSerialization:getSchema(java.lang.Object)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.io.serializer.avro.AvroReflectSerialization:getWriter(java.lang.Class)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.io.serializer.avro.AvroSpecificSerialization:accept(java.lang.Class)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.io.serializer.avro.AvroSpecificSerialization:getReader(java.lang.Class)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.io.serializer.avro.AvroSpecificSerialization:getSchema(org.apache.avro.specific.SpecificRecord)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.io.serializer.avro.AvroSpecificSerialization:getWriter(java.lang.Class)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.io.serializer.avro.AvroSpecificSerialization:getSchema(java.lang.Object)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.io.serializer.avro.AvroSerialization:getDeserializer(java.lang.Class)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.io.serializer.avro.AvroSerialization:getSerializer(java.lang.Class)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.io.serializer.avro.AvroSerialization:getSchema(java.lang.Object)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.io.serializer.avro.AvroSerialization:getWriter(java.lang.Class)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.io.serializer.avro.AvroSerialization:getReader(java.lang.Class)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.io.serializer.WritableSerialization:accept(java.lang.Class)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.io.serializer.WritableSerialization:getSerializer(java.lang.Class)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.io.serializer.WritableSerialization:getDeserializer(java.lang.Class)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.io.serializer.JavaSerialization:accept(java.lang.Class)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.io.serializer.JavaSerialization:getDeserializer(java.lang.Class)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.io.serializer.JavaSerialization:getSerializer(java.lang.Class)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.io.serializer.JavaSerializationComparator:<init>()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.io.serializer.JavaSerializationComparator:compare(java.io.Serializable,java.io.Serializable)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.io.serializer.JavaSerializationComparator:compare(java.lang.Object,java.lang.Object)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.io.nativeio.NativeIO:link(java.io.File,java.io.File)	java.lang.Deprecated
org.apache.hadoop.io.SequenceFile$Reader:<init>(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.fs.Path,org.apache.hadoop.conf.Configuration)	java.lang.Deprecated
org.apache.hadoop.io.SequenceFile$Reader:<init>(org.apache.hadoop.fs.FSDataInputStream,int,long,long,org.apache.hadoop.conf.Configuration)	java.lang.Deprecated
org.apache.hadoop.io.SequenceFile$Reader:next(org.apache.hadoop.io.DataOutputBuffer)	java.lang.Deprecated
org.apache.hadoop.io.compress.BZip2Codec:writeHeader(java.io.OutputStream)	org.apache.hadoop.classification.VisibleForTesting
org.apache.hadoop.io.compress.bzip2.CBZip2OutputStream:getAllowableBlockSize(int)	org.apache.hadoop.classification.VisibleForTesting
org.apache.hadoop.io.compress.bzip2.CBZip2InputStream:skipToNextBlockMarker()	org.apache.hadoop.classification.VisibleForTesting
org.apache.hadoop.io.compress.DecompressorStream:<init>(java.io.InputStream,org.apache.hadoop.io.compress.Decompressor,int,int)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.io.compress.zlib.ZlibFactory:loadNativeZLib()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.io.compress.zlib.ZlibFactory:setNativeZlibLoaded(boolean)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.io.compress.zstd.ZStandardCompressor:<init>()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.io.compress.zstd.ZStandardCompressor:<init>(int,int,int)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.io.IOUtils:cleanup(org.apache.commons.logging.Log,java.io.Closeable[])	java.lang.Deprecated
org.apache.hadoop.io.erasurecode.rawcoder.DecodingValidator:getNewValidIndexes()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.io.erasurecode.rawcoder.DecodingValidator:getNewErasedIndex()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.io.erasurecode.CodecRegistry:updateCoders(java.lang.Iterable)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.service.launcher.ServiceLauncher:loadConfigurationClasses()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.service.AbstractService:resetGlobalListeners()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.security.SaslRpcServer:<init>(org.apache.hadoop.security.SaslRpcServer$AuthMethod)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.security.SaslRpcServer:<init>(org.apache.hadoop.security.SaslRpcServer$AuthMethod)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.security.SaslRpcServer:create(org.apache.hadoop.ipc.Server$Connection,java.util.Map,org.apache.hadoop.security.token.SecretManager)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.security.SaslRpcServer:create(org.apache.hadoop.ipc.Server$Connection,java.util.Map,org.apache.hadoop.security.token.SecretManager)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.security.Groups:getNegativeCache()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.security.Groups:getUserToGroupsMappingServiceWithLoadedConfiguration(org.apache.hadoop.conf.Configuration)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.security.UserGroupInformation:setShouldRenewImmediatelyForTests(boolean)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.security.UserGroupInformation:setConfiguration(org.apache.hadoop.conf.Configuration)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.security.UserGroupInformation:setConfiguration(org.apache.hadoop.conf.Configuration)	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.security.UserGroupInformation:reset()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.security.UserGroupInformation:reset()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.security.UserGroupInformation:isAuthenticationMethodEnabled(org.apache.hadoop.security.UserGroupInformation$AuthenticationMethod)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.security.UserGroupInformation:isAuthenticationMethodEnabled(org.apache.hadoop.security.UserGroupInformation$AuthenticationMethod)	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.security.UserGroupInformation:isKerberosKeyTabLoginRenewalEnabled()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.security.UserGroupInformation:isKerberosKeyTabLoginRenewalEnabled()	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.security.UserGroupInformation:isKerberosKeyTabLoginRenewalEnabled()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.security.UserGroupInformation:getKerberosLoginRenewalExecutor()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.security.UserGroupInformation:getKerberosLoginRenewalExecutor()	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.security.UserGroupInformation:getKerberosLoginRenewalExecutor()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.security.UserGroupInformation:getCurrentUser()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.security.UserGroupInformation:getCurrentUser()	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.security.UserGroupInformation:getUGIFromTicketCache(java.lang.String,java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.security.UserGroupInformation:getUGIFromTicketCache(java.lang.String,java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.security.UserGroupInformation:getLoginUser()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.security.UserGroupInformation:getLoginUser()	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.security.UserGroupInformation:loginUserFromSubject(javax.security.auth.Subject)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.security.UserGroupInformation:loginUserFromSubject(javax.security.auth.Subject)	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.security.UserGroupInformation:setLoginUser(org.apache.hadoop.security.UserGroupInformation)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.security.UserGroupInformation:setLoginUser(org.apache.hadoop.security.UserGroupInformation)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.security.UserGroupInformation:setLoginUser(org.apache.hadoop.security.UserGroupInformation)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.security.UserGroupInformation:shouldRelogin()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.security.UserGroupInformation:shouldRelogin()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.security.UserGroupInformation:spawnAutoRenewalThreadForUserCreds(boolean)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.security.UserGroupInformation:spawnAutoRenewalThreadForUserCreds(boolean)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.security.UserGroupInformation:spawnAutoRenewalThreadForUserCreds(boolean)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.security.UserGroupInformation:getNextTgtRenewalTime(long,long,org.apache.hadoop.io.retry.RetryPolicy)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.security.UserGroupInformation:loginUserFromKeytab(java.lang.String,java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.security.UserGroupInformation:loginUserFromKeytab(java.lang.String,java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.security.UserGroupInformation:logoutUserFromKeytab()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.security.UserGroupInformation:logoutUserFromKeytab()	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.security.UserGroupInformation:fixKerberosTicketOrder()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.security.UserGroupInformation:reloginFromKeytab()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.security.UserGroupInformation:reloginFromKeytab()	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.security.UserGroupInformation:forceReloginFromKeytab()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.security.UserGroupInformation:forceReloginFromKeytab()	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.security.UserGroupInformation:reloginFromTicketCache()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.security.UserGroupInformation:reloginFromTicketCache()	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.security.UserGroupInformation:isLoginKeytabBased()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.security.UserGroupInformation:isLoginKeytabBased()	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.security.UserGroupInformation:createRemoteUser(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.security.UserGroupInformation:createRemoteUser(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.security.UserGroupInformation:createRemoteUser(java.lang.String,org.apache.hadoop.security.SaslRpcServer$AuthMethod)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.security.UserGroupInformation:createRemoteUser(java.lang.String,org.apache.hadoop.security.SaslRpcServer$AuthMethod)	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.security.UserGroupInformation:createProxyUser(java.lang.String,org.apache.hadoop.security.UserGroupInformation)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.security.UserGroupInformation:createProxyUser(java.lang.String,org.apache.hadoop.security.UserGroupInformation)	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.security.UserGroupInformation:getRealUser()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.security.UserGroupInformation:getRealUser()	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.security.UserGroupInformation:createUserForTesting(java.lang.String,java.lang.String[])	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.security.UserGroupInformation:createUserForTesting(java.lang.String,java.lang.String[])	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.security.UserGroupInformation:getUserName()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.security.UserGroupInformation:getUserName()	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.security.UserGroupInformation:doAs(java.security.PrivilegedAction)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.security.UserGroupInformation:doAs(java.security.PrivilegedAction)	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.security.UserGroupInformation:doAs(java.security.PrivilegedExceptionAction)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.security.UserGroupInformation:doAs(java.security.PrivilegedExceptionAction)	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.security.UserGroupInformation:logUserInfo(org.slf4j.Logger,java.lang.String,org.apache.hadoop.security.UserGroupInformation)	org.apache.hadoop.classification.InterfaceAudience$LimitedPrivate	value	{HDFS,KMS}
org.apache.hadoop.security.UserGroupInformation:logUserInfo(org.slf4j.Logger,java.lang.String,org.apache.hadoop.security.UserGroupInformation)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.security.UserGroupInformation:logAllUserInfo(org.slf4j.Logger,org.apache.hadoop.security.UserGroupInformation)	org.apache.hadoop.classification.InterfaceAudience$LimitedPrivate	value	{HDFS,KMS}
org.apache.hadoop.security.UserGroupInformation:logAllUserInfo(org.slf4j.Logger,org.apache.hadoop.security.UserGroupInformation)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.security.ShellBasedUnixGroupsMapping:resolveFullGroupNames(java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.security.ShellBasedIdMapping:<init>(org.apache.hadoop.conf.Configuration,boolean)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.security.ShellBasedIdMapping:getTimeout()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.security.ShellBasedIdMapping:getUidNameMap()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.security.ShellBasedIdMapping:getGidNameMap()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.security.ShellBasedIdMapping:clearNameMaps()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.security.ShellBasedIdMapping:updateMapInternal(org.apache.hadoop.thirdparty.com.google.common.collect.BiMap,java.lang.String,java.lang.String,java.lang.String,java.util.Map)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.security.http.CrossOriginFilter:getAllowedHeadersHeader()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.security.http.CrossOriginFilter:getAllowedMethodsHeader()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.security.http.CrossOriginFilter:areOriginsAllowed(java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.security.token.Token:setKind(org.apache.hadoop.io.Text)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.security.token.DelegationTokenIssuer:collectDelegationTokens(org.apache.hadoop.security.token.DelegationTokenIssuer,java.lang.String,org.apache.hadoop.security.Credentials,java.util.List)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticationHandler:getTokenManager()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticationHandler:initTokenManager(java.util.Properties)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticationHandler:initJsonFactory(java.util.Properties)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.security.token.delegation.web.DelegationTokenManager:getDelegationTokenSecretManager()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticatedURL:setUseQueryStringForDelegationToken(boolean)	java.lang.Deprecated
org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticatedURL:selectDelegationToken(java.net.URL,org.apache.hadoop.security.Credentials)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticationFilter:getDoAs(javax.servlet.http.HttpServletRequest)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.security.token.delegation.ZKDelegationTokenSecretManager:getCurator()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.security.token.delegation.ZKDelegationTokenSecretManager:getNodePath(java.lang.String,java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.security.token.delegation.ZKDelegationTokenSecretManager:getNodePath(java.lang.String,java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.security.token.delegation.ZKDelegationTokenSecretManager:getNodePath(java.lang.String,java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.security.token.delegation.ZKDelegationTokenSecretManager:getTokenInfoFromMemory(org.apache.hadoop.security.token.delegation.AbstractDelegationTokenIdentifier)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.security.token.delegation.AbstractDelegationTokenIdentifier:writeImpl(java.io.DataOutput)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.security.IngressPortBasedResolver:getServerProperties(java.net.InetAddress,int)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.security.ssl.DelegatingSSLSocketFactory:resetDefaultFactory()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.security.ssl.FileBasedKeyStoresFactory:resolvePropertyName(org.apache.hadoop.security.ssl.SSLFactory$Mode,java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.security.SecurityUtil:setConfiguration(org.apache.hadoop.conf.Configuration)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.security.SecurityUtil:setConfiguration(org.apache.hadoop.conf.Configuration)	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.security.SecurityUtil:setTokenServiceUseIp(boolean)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.security.SecurityUtil:setTokenServiceUseIp(boolean)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.security.SecurityUtil:getServerPrincipal(java.lang.String,java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.security.SecurityUtil:getServerPrincipal(java.lang.String,java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.security.SecurityUtil:getServerPrincipal(java.lang.String,java.net.InetAddress)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.security.SecurityUtil:getServerPrincipal(java.lang.String,java.net.InetAddress)	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.security.SecurityUtil:login(org.apache.hadoop.conf.Configuration,java.lang.String,java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.security.SecurityUtil:login(org.apache.hadoop.conf.Configuration,java.lang.String,java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.security.SecurityUtil:login(org.apache.hadoop.conf.Configuration,java.lang.String,java.lang.String,java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.security.SecurityUtil:login(org.apache.hadoop.conf.Configuration,java.lang.String,java.lang.String,java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.security.SecurityUtil:setSecurityInfoProviders(org.apache.hadoop.security.SecurityInfo[])	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.security.SecurityUtil:getByName(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.security.RefreshUserMappingsProtocol:refreshUserToGroupsMappings()	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.security.RefreshUserMappingsProtocol:refreshSuperUserGroupsConfiguration()	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.security.LdapGroupsMapping:lookupGroup(javax.naming.directory.SearchResult,javax.naming.directory.DirContext,int)	org.apache.hadoop.classification.VisibleForTesting
org.apache.hadoop.security.LdapGroupsMapping:getPassword(org.apache.hadoop.conf.Configuration,java.lang.String,java.lang.String)	java.lang.Deprecated
org.apache.hadoop.security.SaslRpcClient:getNegotiatedProperty(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.security.SaslRpcClient:getNegotiatedProperty(java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.security.SaslRpcClient:getAuthMethod()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.security.SaslRpcClient:getServerPrincipal(org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RpcSaslProto$SaslAuth)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.security.authorize.ServiceAuthorizationManager:refreshWithLoadedConfiguration(org.apache.hadoop.conf.Configuration,org.apache.hadoop.security.authorize.PolicyProvider)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.security.authorize.ServiceAuthorizationManager:getProtocolsWithAcls()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.security.authorize.ServiceAuthorizationManager:getProtocolsAcls(java.lang.Class)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.security.authorize.ServiceAuthorizationManager:getProtocolsBlockedAcls(java.lang.Class)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.security.authorize.ServiceAuthorizationManager:getProtocolsWithMachineLists()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.security.authorize.ServiceAuthorizationManager:getProtocolsMachineList(java.lang.Class)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.security.authorize.ServiceAuthorizationManager:getProtocolsBlockedMachineList(java.lang.Class)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.security.authorize.RefreshAuthorizationPolicyProtocol:refreshServiceAcl()	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.security.authorize.ProxyUsers:authorize(org.apache.hadoop.security.UserGroupInformation,java.lang.String,org.apache.hadoop.conf.Configuration)	java.lang.Deprecated
org.apache.hadoop.security.authorize.ProxyUsers:getDefaultImpersonationProvider()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.security.authorize.DefaultImpersonationProvider:getProxyGroups()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.security.authorize.DefaultImpersonationProvider:getProxyHosts()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.util.InstrumentedReadLock:<init>(java.lang.String,org.slf4j.Logger,java.util.concurrent.locks.ReentrantReadWriteLock,long,long,org.apache.hadoop.util.Timer)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.util.DiskChecker:getFileNameForDiskIoCheck(java.io.File,int)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.util.DiskChecker:replaceFileOutputStreamProvider(org.apache.hadoop.util.DiskChecker$FileIoProvider)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.util.DiskChecker:getFileOutputStreamProvider()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.util.LogAdapter:create(org.apache.commons.logging.Log)	java.lang.Deprecated
org.apache.hadoop.util.Shell$ShellCommandExecutor:getTimeoutInterval()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.util.DirectBufferPool:countBuffersOfSize(int)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.util.NativeCrc32:nativeVerifyChunkedSums(int,int,java.nio.ByteBuffer,int,java.nio.ByteBuffer,int,int,java.lang.String,long)	java.lang.Deprecated
org.apache.hadoop.util.NativeCrc32:nativeVerifyChunkedSums(int,int,java.nio.ByteBuffer,int,java.nio.ByteBuffer,int,int,java.lang.String,long)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.util.ReadWriteDiskValidatorMetrics:getFileReadQuantiles()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.util.ReadWriteDiskValidatorMetrics:getFileWriteQuantiles()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.util.ReflectionUtils:cloneWritableInto(org.apache.hadoop.io.Writable,org.apache.hadoop.io.Writable)	java.lang.Deprecated
org.apache.hadoop.util.LightWeightGSet:computeCapacity(long,double,java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.util.MachineList:getCollection()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.util.SysInfoWindows:now()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.util.RunJar:unJarAndSave(java.io.InputStream,java.io.File,java.lang.String,java.util.regex.Pattern)	java.lang.Deprecated
org.apache.hadoop.util.Lists:newArrayList(java.lang.Object[])	java.lang.SafeVarargs
org.apache.hadoop.util.ShutdownHookManager:executeShutdown()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.util.ShutdownHookManager:executeShutdown()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.util.ShutdownHookManager:get()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.util.ShutdownHookManager:getShutdownTimeout(org.apache.hadoop.conf.Configuration)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.util.ShutdownHookManager:getShutdownTimeout(org.apache.hadoop.conf.Configuration)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.util.ShutdownHookManager:<init>()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.util.ShutdownHookManager:<init>()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.util.ShutdownHookManager:getShutdownHooksInOrder()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.util.ShutdownHookManager:getShutdownHooksInOrder()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.util.ShutdownHookManager:addShutdownHook(java.lang.Runnable,int)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.util.ShutdownHookManager:addShutdownHook(java.lang.Runnable,int)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.util.ShutdownHookManager:addShutdownHook(java.lang.Runnable,int,long,java.util.concurrent.TimeUnit)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.util.ShutdownHookManager:addShutdownHook(java.lang.Runnable,int,long,java.util.concurrent.TimeUnit)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.util.ShutdownHookManager:removeShutdownHook(java.lang.Runnable)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.util.ShutdownHookManager:removeShutdownHook(java.lang.Runnable)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.util.ShutdownHookManager:hasShutdownHook(java.lang.Runnable)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.util.ShutdownHookManager:hasShutdownHook(java.lang.Runnable)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.util.ShutdownHookManager:isShutdownInProgress()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.util.ShutdownHookManager:isShutdownInProgress()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.util.ShutdownHookManager:clearShutdownHooks()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.util.ShutdownHookManager:clearShutdownHooks()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.util.StringUtils:humanReadableInt(long)	java.lang.Deprecated
org.apache.hadoop.util.StringUtils:limitDecimalTo2(double)	java.lang.Deprecated
org.apache.hadoop.util.FindClass:setOutputStreams(java.io.PrintStream,java.io.PrintStream)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.util.Shell:isJava7OrAbove()	java.lang.Deprecated
org.apache.hadoop.util.Shell:bashQuote(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.util.Shell:checkHadoopHomeInner(java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.util.HostsFileReader:<init>(java.lang.String,java.io.InputStream,java.lang.String,java.io.InputStream)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.util.HostsFileReader:readFileToSetWithFileInputStream(java.lang.String,java.lang.String,java.io.InputStream,java.util.Set)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.util.HostsFileReader:refresh(java.io.InputStream,java.io.InputStream)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.util.HostsFileReader:getHostDetails(java.util.Set,java.util.Set)	java.lang.Deprecated
org.apache.hadoop.util.HostsFileReader:getHostDetails(java.util.Set,java.util.Map)	java.lang.Deprecated
org.apache.hadoop.util.SysInfoLinux:<init>(java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,long)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.util.SysInfoLinux:setReadCpuInfoFile(boolean)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.util.InstrumentedWriteLock:<init>(java.lang.String,org.slf4j.Logger,java.util.concurrent.locks.ReentrantReadWriteLock,long,long,org.apache.hadoop.util.Timer)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.util.ChunkedArrayList:getNumChunks()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.util.ChunkedArrayList:getMaxChunkSize()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.util.AutoCloseableLock:isLocked()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.util.InstrumentedLock:<init>(java.lang.String,org.slf4j.Logger,java.util.concurrent.locks.Lock,long,long,org.apache.hadoop.util.Timer)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.util.InstrumentedLock:logWarning(long,org.apache.hadoop.util.InstrumentedLock$SuppressedSnapshot)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.util.InstrumentedLock:logWaitWarning(long,org.apache.hadoop.util.InstrumentedLock$SuppressedSnapshot)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.util.LightWeightCache:<init>(int,int,long,long,org.apache.hadoop.util.Timer)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.ha.proto.HAServiceProtocolProtos$HAServiceStateProto:valueOf(int)	java.lang.Deprecated
org.apache.hadoop.ha.proto.HAServiceProtocolProtos$HARequestSource:valueOf(int)	java.lang.Deprecated
org.apache.hadoop.ha.ZKFailoverController:getServiceState()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.ha.ZKFailoverController:getElectorForTests()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.ha.ZKFailoverController:getRpcServerForTests()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.ha.ActiveStandbyElector:getWantToBeInElection()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.ha.ActiveStandbyElector:sleepFor(int)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.ha.ActiveStandbyElector:preventSessionReestablishmentForTests()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.ha.ActiveStandbyElector:allowSessionReestablishmentForTests()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.ha.ActiveStandbyElector:getZKSessionIdForTests()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.ha.ActiveStandbyElector:getStateForTests()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.ha.ActiveStandbyElector:isMonitorLockNodePending()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.ha.ActiveStandbyElector:terminateConnection()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.ha.HAServiceProtocol:monitorHealth()	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.ha.HAServiceProtocol:transitionToActive(org.apache.hadoop.ha.HAServiceProtocol$StateChangeRequestInfo)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.ha.HAServiceProtocol:transitionToStandby(org.apache.hadoop.ha.HAServiceProtocol$StateChangeRequestInfo)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.ha.HAServiceProtocol:transitionToObserver(org.apache.hadoop.ha.HAServiceProtocol$StateChangeRequestInfo)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.ha.HAServiceProtocol:getServiceStatus()	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.ha.ZKFCProtocol:cedeActive(int)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.ha.ZKFCProtocol:gracefulFailover()	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.crypto.key.kms.server.KMSAuthenticationFilter:getKMSConfiguration(org.apache.hadoop.conf.Configuration)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.crypto.key.kms.server.KMSMDCFilter:setContext(org.apache.hadoop.security.UserGroupInformation,java.lang.String,java.lang.String,java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.crypto.key.kms.server.KMSAudit:evictCacheForTesting()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.crypto.key.kms.server.KMS:createKey(java.util.Map)	javax.ws.rs.POST
org.apache.hadoop.crypto.key.kms.server.KMS:createKey(java.util.Map)	javax.ws.rs.Path	value	keys
org.apache.hadoop.crypto.key.kms.server.KMS:createKey(java.util.Map)	javax.ws.rs.Consumes	value	{application/json}
org.apache.hadoop.crypto.key.kms.server.KMS:createKey(java.util.Map)	javax.ws.rs.Produces	value	{application/json; charset=utf-8}
org.apache.hadoop.crypto.key.kms.server.KMS:deleteKey(java.lang.String)	javax.ws.rs.DELETE
org.apache.hadoop.crypto.key.kms.server.KMS:deleteKey(java.lang.String)	javax.ws.rs.Path	value	key/{name:.*}
org.apache.hadoop.crypto.key.kms.server.KMS:rolloverKey(java.lang.String,java.util.Map)	javax.ws.rs.POST
org.apache.hadoop.crypto.key.kms.server.KMS:rolloverKey(java.lang.String,java.util.Map)	javax.ws.rs.Path	value	key/{name:.*}
org.apache.hadoop.crypto.key.kms.server.KMS:rolloverKey(java.lang.String,java.util.Map)	javax.ws.rs.Consumes	value	{application/json}
org.apache.hadoop.crypto.key.kms.server.KMS:rolloverKey(java.lang.String,java.util.Map)	javax.ws.rs.Produces	value	{application/json; charset=utf-8}
org.apache.hadoop.crypto.key.kms.server.KMS:invalidateCache(java.lang.String)	javax.ws.rs.POST
org.apache.hadoop.crypto.key.kms.server.KMS:invalidateCache(java.lang.String)	javax.ws.rs.Path	value	key/{name:.*}/_invalidatecache
org.apache.hadoop.crypto.key.kms.server.KMS:getKeysMetadata(java.util.List)	javax.ws.rs.GET
org.apache.hadoop.crypto.key.kms.server.KMS:getKeysMetadata(java.util.List)	javax.ws.rs.Path	value	keys/metadata
org.apache.hadoop.crypto.key.kms.server.KMS:getKeysMetadata(java.util.List)	javax.ws.rs.Produces	value	{application/json; charset=utf-8}
org.apache.hadoop.crypto.key.kms.server.KMS:getKeyNames()	javax.ws.rs.GET
org.apache.hadoop.crypto.key.kms.server.KMS:getKeyNames()	javax.ws.rs.Path	value	keys/names
org.apache.hadoop.crypto.key.kms.server.KMS:getKeyNames()	javax.ws.rs.Produces	value	{application/json; charset=utf-8}
org.apache.hadoop.crypto.key.kms.server.KMS:getKey(java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.crypto.key.kms.server.KMS:getKey(java.lang.String)	javax.ws.rs.Path	value	key/{name:.*}
org.apache.hadoop.crypto.key.kms.server.KMS:getMetadata(java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.crypto.key.kms.server.KMS:getMetadata(java.lang.String)	javax.ws.rs.Path	value	key/{name:.*}/_metadata
org.apache.hadoop.crypto.key.kms.server.KMS:getMetadata(java.lang.String)	javax.ws.rs.Produces	value	{application/json; charset=utf-8}
org.apache.hadoop.crypto.key.kms.server.KMS:getCurrentVersion(java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.crypto.key.kms.server.KMS:getCurrentVersion(java.lang.String)	javax.ws.rs.Path	value	key/{name:.*}/_currentversion
org.apache.hadoop.crypto.key.kms.server.KMS:getCurrentVersion(java.lang.String)	javax.ws.rs.Produces	value	{application/json; charset=utf-8}
org.apache.hadoop.crypto.key.kms.server.KMS:getKeyVersion(java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.crypto.key.kms.server.KMS:getKeyVersion(java.lang.String)	javax.ws.rs.Path	value	keyversion/{versionName:.*}
org.apache.hadoop.crypto.key.kms.server.KMS:getKeyVersion(java.lang.String)	javax.ws.rs.Produces	value	{application/json; charset=utf-8}
org.apache.hadoop.crypto.key.kms.server.KMS:generateEncryptedKeys(java.lang.String,java.lang.String,int)	javax.ws.rs.GET
org.apache.hadoop.crypto.key.kms.server.KMS:generateEncryptedKeys(java.lang.String,java.lang.String,int)	javax.ws.rs.Path	value	key/{name:.*}/_eek
org.apache.hadoop.crypto.key.kms.server.KMS:generateEncryptedKeys(java.lang.String,java.lang.String,int)	javax.ws.rs.Produces	value	{application/json; charset=utf-8}
org.apache.hadoop.crypto.key.kms.server.KMS:reencryptEncryptedKeys(java.lang.String,java.util.List)	javax.ws.rs.POST
org.apache.hadoop.crypto.key.kms.server.KMS:reencryptEncryptedKeys(java.lang.String,java.util.List)	javax.ws.rs.Path	value	key/{name:.*}/_reencryptbatch
org.apache.hadoop.crypto.key.kms.server.KMS:reencryptEncryptedKeys(java.lang.String,java.util.List)	javax.ws.rs.Consumes	value	{application/json}
org.apache.hadoop.crypto.key.kms.server.KMS:reencryptEncryptedKeys(java.lang.String,java.util.List)	javax.ws.rs.Produces	value	{application/json; charset=utf-8}
org.apache.hadoop.crypto.key.kms.server.KMS:handleEncryptedKeyOp(java.lang.String,java.lang.String,java.util.Map)	javax.ws.rs.POST
org.apache.hadoop.crypto.key.kms.server.KMS:handleEncryptedKeyOp(java.lang.String,java.lang.String,java.util.Map)	javax.ws.rs.Path	value	keyversion/{versionName:.*}/_eek
org.apache.hadoop.crypto.key.kms.server.KMS:handleEncryptedKeyOp(java.lang.String,java.lang.String,java.util.Map)	javax.ws.rs.Produces	value	{application/json; charset=utf-8}
org.apache.hadoop.crypto.key.kms.server.KMS:getKeyVersions(java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.crypto.key.kms.server.KMS:getKeyVersions(java.lang.String)	javax.ws.rs.Path	value	key/{name:.*}/_versions
org.apache.hadoop.crypto.key.kms.server.KMS:getKeyVersions(java.lang.String)	javax.ws.rs.Produces	value	{application/json; charset=utf-8}
org.apache.hadoop.crypto.key.kms.server.KMSAuthenticationFilter$KMSResponse:setStatus(int,java.lang.String)	java.lang.Deprecated
org.apache.hadoop.crypto.key.kms.server.KMSACLs:setKeyACLs(org.apache.hadoop.conf.Configuration)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.crypto.key.kms.server.KMSACLs:forceNextReloadForTesting()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.minikdc.KerberosSecurityTestcase:startMiniKdc()	org.junit.Before
org.apache.hadoop.minikdc.KerberosSecurityTestcase:stopMiniKdc()	org.junit.After
org.apache.hadoop.nfs.nfs3.response.READDIRPLUS3Response$EntryPlus3:getName()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.nfs.nfs3.response.READDIRPLUS3Response:getDirListPlus()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.nfs.nfs3.response.READDIR3Response$DirList3:getEntries()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.nfs.nfs3.response.READDIR3Response$Entry3:getName()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.nfs.nfs3.response.READDIRPLUS3Response$DirListPlus3:getEntries()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.nfs.nfs3.request.LOOKUP3Request:serialize(org.apache.hadoop.oncrpc.XDR)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.nfs.nfs3.request.READ3Request:<init>(org.apache.hadoop.nfs.nfs3.FileHandle,long,int)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.oncrpc.SimpleTcpClient:run()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.oncrpc.RpcProgram:getPortmapUdpTimeoutMillis()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.oncrpc.XDR:getBytes()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.oncrpc.security.Credentials:getCredentialLength()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.oncrpc.security.CredentialsSys:getStamp()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.oncrpc.security.CredentialsSys:setHostName(java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.oncrpc.RpcUtil$RpcFrameDecoder:isLast()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.oncrpc.RpcCallCache:iterator()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.portmap.Portmap:getTcpServerLocalAddress()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.portmap.Portmap:getUdpServerLoAddress()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.portmap.Portmap:getHandler()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.registry.client.binding.RegistryUtils:getCurrentUsernameUnencoded(java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.registry.client.impl.zk.CuratorService:maybeCreate(java.lang.String,org.apache.zookeeper.CreateMode,java.util.List,boolean)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.registry.client.impl.FSRegistryOperationsService:getFs()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.registry.client.types.ServiceRecord:set(java.lang.String,java.lang.Object)	com.fasterxml.jackson.annotation.JsonAnySetter
org.apache.hadoop.registry.client.types.ServiceRecord:attributes()	com.fasterxml.jackson.annotation.JsonAnyGetter
org.apache.hadoop.registry.server.dns.RegistryDNS:getZoneCount()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.registry.server.dns.RegistryDNS:addSplitReverseZones(org.apache.hadoop.conf.Configuration,long)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.registry.server.dns.RegistryDNS:setDNSSECEnabled(org.apache.hadoop.conf.Configuration)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.registry.server.dns.ReverseZoneUtils:splitIp(java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.registry.server.services.RegistryAdminService:createRootRegistryPaths()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.registry.server.services.RegistryAdminService:purge(java.lang.String,org.apache.hadoop.registry.server.services.RegistryAdminService$NodeSelector,org.apache.hadoop.registry.server.services.RegistryAdminService$PurgePolicy,org.apache.curator.framework.api.BackgroundCallback)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.Hdfs:getServerDefaults()	java.lang.Deprecated
org.apache.hadoop.hdfs.DFSClient:setDisabledStopDeadNodeDetectorThreadForTest(boolean)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.DFSClient:<init>(org.apache.hadoop.conf.Configuration)	java.lang.Deprecated
org.apache.hadoop.hdfs.DFSClient:<init>(java.net.URI,org.apache.hadoop.hdfs.protocol.ClientProtocol,org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.FileSystem$Statistics)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.DFSClient:getClientName()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.DFSClient:getCanonicalServiceName()	org.apache.hadoop.classification.InterfaceAudience$LimitedPrivate	value	{HDFS}
org.apache.hadoop.hdfs.DFSClient:renewDelegationToken(org.apache.hadoop.security.token.Token)	java.lang.Deprecated
org.apache.hadoop.hdfs.DFSClient:cancelDelegationToken(org.apache.hadoop.security.token.Token)	java.lang.Deprecated
org.apache.hadoop.hdfs.DFSClient:getLocatedBlocks(java.lang.String,long,long)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.DFSClient:open(java.lang.String,int,boolean,org.apache.hadoop.fs.FileSystem$Statistics)	java.lang.Deprecated
org.apache.hadoop.hdfs.DFSClient:rename(java.lang.String,java.lang.String)	java.lang.Deprecated
org.apache.hadoop.hdfs.DFSClient:delete(java.lang.String)	java.lang.Deprecated
org.apache.hadoop.hdfs.DFSClient:clearDataEncryptionKey()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.hdfs.DFSClient:getEncryptionKey()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.DFSClient:getPreviousBlock(long)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.DFSClient:mkdirs(java.lang.String)	java.lang.Deprecated
org.apache.hadoop.hdfs.DFSClient:setKeyProvider(org.apache.hadoop.crypto.key.KeyProvider)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.DFSClient:listOpenFiles()	java.lang.Deprecated
org.apache.hadoop.hdfs.DFSClient:getHAServiceState()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.DistributedFileSystem$HdfsDataOutputStreamBuilder:getStoragePolicyName()	org.apache.hadoop.classification.VisibleForTesting
org.apache.hadoop.hdfs.DistributedFileSystem$HdfsDataOutputStreamBuilder:getEcPolicyName()	org.apache.hadoop.classification.VisibleForTesting
org.apache.hadoop.hdfs.DistributedFileSystem$HdfsDataOutputStreamBuilder:shouldReplicate()	org.apache.hadoop.classification.VisibleForTesting
org.apache.hadoop.hdfs.DistributedFileSystem$HdfsDataOutputStreamBuilder:getFlags()	org.apache.hadoop.classification.VisibleForTesting
org.apache.hadoop.hdfs.ViewDistributedFileSystem:getStoragePolicies()	java.lang.Deprecated
org.apache.hadoop.hdfs.ViewDistributedFileSystem:getClient()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.hdfs.ViewDistributedFileSystem:listOpenFiles()	java.lang.Deprecated
org.apache.hadoop.hdfs.ViewDistributedFileSystem:listOpenFiles(java.util.EnumSet)	java.lang.Deprecated
org.apache.hadoop.hdfs.DeadNodeDetector:isThreadsShutdown()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.DeadNodeDetector:setDisabledProbeThreadForTest(boolean)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.DeadNodeDetector:startProbeScheduler()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.DeadNodeDetector:setSuspectQueue(org.apache.hadoop.hdfs.DeadNodeDetector$UniqueQueue)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.DeadNodeDetector:setDeadQueue(org.apache.hadoop.hdfs.DeadNodeDetector$UniqueQueue)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.web.resources.UserParam:getUserPatternDomain()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.web.resources.UserParam:setUserPatternDomain(org.apache.hadoop.hdfs.web.resources.StringParam$Domain)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.web.resources.AclPermissionParam:getAclPermissionPattern()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.web.resources.AclPermissionParam:setAclPermissionPattern(org.apache.hadoop.hdfs.web.resources.StringParam$Domain)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.web.URLConnectionFactory:<init>(org.apache.hadoop.security.authentication.client.ConnectionConfigurator)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.web.ByteRangeInputStream:getInputStream()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.web.ByteRangeInputStream:openInputStream(long)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.web.WebHdfsFileSystem$WebHdfsInputStream:getReadRunner()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.web.WebHdfsFileSystem$WebHdfsInputStream:setReadRunner(org.apache.hadoop.hdfs.web.WebHdfsFileSystem$ReadRunner)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.web.WebHdfsFileSystem$ReadRunner:initializeInputStream(java.net.HttpURLConnection)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.web.WebHdfsFileSystem$ReadRunner:closeInputStream(org.apache.hadoop.hdfs.web.WebHdfsFileSystem$RunnerState)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.web.WebHdfsFileSystem$ReadRunner:getInputStream()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.web.WebHdfsFileSystem$ReadRunner:setInputStream(java.io.InputStream)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.web.WebHdfsFileSystem:replaceExpiredDelegationToken()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.web.WebHdfsFileSystem:getHomeDirectoryString(org.apache.hadoop.security.UserGroupInformation)	java.lang.Deprecated
org.apache.hadoop.hdfs.web.WebHdfsFileSystem:getResolvedNNAddr()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.web.WebHdfsFileSystem:setRetryPolicy(org.apache.hadoop.io.retry.RetryPolicy)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.web.WebHdfsFileSystem:setTestProvider(org.apache.hadoop.crypto.key.KeyProvider)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.web.TokenAspect:selectDelegationToken(org.apache.hadoop.security.UserGroupInformation)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.BlockMetadataHeader:<init>(short,org.apache.hadoop.util.DataChecksum)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.BlockMetadataHeader:writeHeader(java.io.DataOutputStream,org.apache.hadoop.hdfs.server.datanode.BlockMetadataHeader)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.ha.ObserverReadProxyProvider:setObserverReadEnabled(boolean)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.ha.ObserverReadProxyProvider:getLastProxy()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.ClientContext:getFromConf(org.apache.hadoop.conf.Configuration)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB:listOpenFiles(long)	java.lang.Deprecated
org.apache.hadoop.hdfs.DistributedFileSystem:getStoragePolicies()	java.lang.Deprecated
org.apache.hadoop.hdfs.DistributedFileSystem:getClient()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.hdfs.DistributedFileSystem:getClient()	org.apache.hadoop.classification.VisibleForTesting
org.apache.hadoop.hdfs.DistributedFileSystem:setSafeMode(org.apache.hadoop.hdfs.protocol.HdfsConstants$SafeModeAction)	java.lang.Deprecated
org.apache.hadoop.hdfs.DistributedFileSystem:setSafeMode(org.apache.hadoop.hdfs.protocol.HdfsConstants$SafeModeAction,boolean)	java.lang.Deprecated
org.apache.hadoop.hdfs.DistributedFileSystem:listOpenFiles()	java.lang.Deprecated
org.apache.hadoop.hdfs.DistributedFileSystem:listOpenFiles(java.util.EnumSet)	java.lang.Deprecated
org.apache.hadoop.hdfs.PeerCache:clear()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.PeerCache:close()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.NameNodeProxiesClient:createFailoverProxyProvider(org.apache.hadoop.conf.Configuration,java.net.URI,java.lang.Class,boolean,java.util.concurrent.atomic.AtomicBoolean)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.NameNodeProxiesClient:getFailoverProxyProviderClass(org.apache.hadoop.conf.Configuration,java.net.URI)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory:clearPathMap()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache:setMaxTotalSize(int)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache:fetch(org.apache.hadoop.hdfs.ExtendedBlockId,org.apache.hadoop.util.Waitable)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache:accept(org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache$CacheVisitor)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache:getDfsClientShmManager()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache:getReplicaInfoMapSize()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.shortcircuit.ShortCircuitReplica:hasMmap()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.shortcircuit.ShortCircuitReplica:getSlot()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.shortcircuit.DfsClientShmManager:visit(org.apache.hadoop.hdfs.shortcircuit.DfsClientShmManager$Visitor)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.shortcircuit.DfsClientShmManager:getDomainSocketWatcher()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.shortcircuit.DfsClientShmManager:getShmNum()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.DFSInputStream:getlastBlockBeingWrittenLengthForTesting()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.DFSInputStream:deadNodesContain(org.apache.hadoop.hdfs.protocol.DatanodeInfo)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.DFSInputStream:chooseDataNode(org.apache.hadoop.hdfs.protocol.LocatedBlock,java.util.Collection,boolean)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.DFSInputStream:getHedgedReadOpsLoopNumForTesting()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.DFSInputStream:setLastRefreshedBlocksAtForTesting(long)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.DFSInputStream:getLastRefreshedBlocksAtForTesting()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.KeyProviderCache:invalidateCache()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.KeyProviderCache:setKeyProvider(org.apache.hadoop.conf.Configuration,org.apache.hadoop.crypto.key.KeyProvider)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.security.token.block.BlockTokenIdentifier:readFieldsLegacy(java.io.DataInput)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.security.token.block.BlockTokenIdentifier:readFieldsProtobuf(java.io.DataInput)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.security.token.block.BlockTokenIdentifier:writeLegacy(java.io.DataOutput)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.security.token.block.BlockTokenIdentifier:writeProtobuf(java.io.DataOutput)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.security.token.delegation.DelegationTokenIdentifier:clearCache()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.DataStreamer:updatePipeline(long)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.DataStreamer:getPipelineRecoveryCount()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.StripedDataStreamer:peekFollowingBlock()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.StripedDataStreamer:updatePipeline(long)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.util.StripedBlockUtil:getStripingCellsOfByteRange(org.apache.hadoop.hdfs.protocol.ErasureCodingPolicy,int,org.apache.hadoop.hdfs.protocol.LocatedStripedBlock,long,long)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.util.StripedBlockUtil:getRangesForInternalBlocks(org.apache.hadoop.hdfs.protocol.ErasureCodingPolicy,int,org.apache.hadoop.hdfs.util.StripedBlockUtil$StripingCell[])	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.inotify.Event$MetadataUpdateEvent:toString()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.hdfs.inotify.Event$UnlinkEvent:toString()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.hdfs.inotify.Event$CloseEvent:toString()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.hdfs.inotify.Event$CreateEvent:toString()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.hdfs.inotify.Event$AppendEvent:toString()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.hdfs.inotify.Event$TruncateEvent:toString()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.hdfs.inotify.Event$RenameEvent:toString()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.hdfs.DFSStripedOutputStream:enqueueAllCurrentPackets()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.DFSOutputStream:getPipeline()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.DFSOutputStream:setAppendChunk(boolean)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.DFSOutputStream:setBytesCurBlock(long)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.DFSOutputStream:getNumCurrentReplicas()	java.lang.Deprecated
org.apache.hadoop.hdfs.DFSOutputStream:setArtificialSlowdown(long)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.DFSOutputStream:setChunksPerPacket(int)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.DFSOutputStream:getBlock()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.DFSOutputStream:getFileId()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheFlagProto:valueOf(int)	java.lang.Deprecated
org.apache.hadoop.hdfs.protocol.proto.AclProtos$AclEntryProto$AclEntryTypeProto:valueOf(int)	java.lang.Deprecated
org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$XAttrProto$XAttrNamespaceProto:valueOf(int)	java.lang.Deprecated
org.apache.hadoop.hdfs.protocol.proto.AclProtos$AclEntryProto$FsActionProto:valueOf(int)	java.lang.Deprecated
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageTypeProto:valueOf(int)	java.lang.Deprecated
org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ReencryptActionProto:valueOf(int)	java.lang.Deprecated
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$OpenFilesTypeProto:valueOf(int)	java.lang.Deprecated
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockChecksumTypeProto:valueOf(int)	java.lang.Deprecated
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddBlockFlagProto:valueOf(int)	java.lang.Deprecated
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ErasureCodingPolicyState:valueOf(int)	java.lang.Deprecated
org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$DataTransferEncryptorMessageProto$DataTransferEncryptorStatus:valueOf(int)	java.lang.Deprecated
org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$INodeType:valueOf(int)	java.lang.Deprecated
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$CipherSuiteProto:valueOf(int)	java.lang.Deprecated
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsFileStatusProto$Flags:valueOf(int)	java.lang.Deprecated
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockTypeProto:valueOf(int)	java.lang.Deprecated
org.apache.hadoop.hdfs.protocol.proto.AclProtos$AclEntryProto$AclEntryScopeProto:valueOf(int)	java.lang.Deprecated
org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpWriteBlockProto$BlockConstructionStage:valueOf(int)	java.lang.Deprecated
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollingUpgradeActionProto:valueOf(int)	java.lang.Deprecated
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SafeModeActionProto:valueOf(int)	java.lang.Deprecated
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$AccessModeProto:valueOf(int)	java.lang.Deprecated
org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$XAttrSetFlagProto:valueOf(int)	java.lang.Deprecated
org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitFdResponse:valueOf(int)	java.lang.Deprecated
org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$Status:valueOf(int)	java.lang.Deprecated
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsFileStatusProto$FileType:valueOf(int)	java.lang.Deprecated
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageReportProto$Builder:hasStorageUuid()	java.lang.Deprecated
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageReportProto$Builder:getStorageUuid()	java.lang.Deprecated
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageReportProto$Builder:getStorageUuidBytes()	java.lang.Deprecated
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageReportProto$Builder:setStorageUuid(java.lang.String)	java.lang.Deprecated
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageReportProto$Builder:clearStorageUuid()	java.lang.Deprecated
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageReportProto$Builder:setStorageUuidBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)	java.lang.Deprecated
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageReportProto:hasStorageUuid()	java.lang.Deprecated
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageReportProto:getStorageUuid()	java.lang.Deprecated
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageReportProto:getStorageUuidBytes()	java.lang.Deprecated
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DatanodeReportTypeProto:valueOf(int)	java.lang.Deprecated
org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$MetadataUpdateType:valueOf(int)	java.lang.Deprecated
org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ReencryptionStateProto:valueOf(int)	java.lang.Deprecated
org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$EventType:valueOf(int)	java.lang.Deprecated
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ChecksumTypeProto:valueOf(int)	java.lang.Deprecated
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateFlagProto:valueOf(int)	java.lang.Deprecated
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageReportProtoOrBuilder:hasStorageUuid()	java.lang.Deprecated
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageReportProtoOrBuilder:getStorageUuid()	java.lang.Deprecated
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageReportProtoOrBuilder:getStorageUuidBytes()	java.lang.Deprecated
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeStorageProto$StorageState:valueOf(int)	java.lang.Deprecated
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$CryptoProtocolVersionProto:valueOf(int)	java.lang.Deprecated
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeInfoProto$AdminState:valueOf(int)	java.lang.Deprecated
org.apache.hadoop.hdfs.protocol.ReencryptionStatus:<init>(org.apache.hadoop.hdfs.protocol.ReencryptionStatus)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.protocol.ReencryptionStatus:resetMetrics()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.protocol.ReencryptionStatus:zonesQueued()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.protocol.ReencryptionStatus:zonesTotal()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.protocol.ReencryptionStatus:getNumZonesReencrypted()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.protocol.ReconfigurationProtocol:startReconfiguration()	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.protocol.ReconfigurationProtocol:getReconfigurationStatus()	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.protocol.ReconfigurationProtocol:listReconfigurableProperties()	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferClient:getTargetQOP()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.protocol.ProvidedStorageLocation:getPath()	javax.annotation.Nonnull
org.apache.hadoop.hdfs.protocol.ProvidedStorageLocation:getNonce()	javax.annotation.Nonnull
org.apache.hadoop.hdfs.protocol.BlockStoragePolicy:<init>(byte,java.lang.String,org.apache.hadoop.fs.StorageType[],org.apache.hadoop.fs.StorageType[],org.apache.hadoop.fs.StorageType[])	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.protocol.BlockStoragePolicy:<init>(byte,java.lang.String,org.apache.hadoop.fs.StorageType[],org.apache.hadoop.fs.StorageType[],org.apache.hadoop.fs.StorageType[],boolean)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.protocol.ClientProtocol:getBlockLocations(java.lang.String,long,long)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.protocol.ClientProtocol:getBlockLocations(java.lang.String,long,long)	org.apache.hadoop.hdfs.server.namenode.ha.ReadOnly	atimeAffected	true
org.apache.hadoop.hdfs.protocol.ClientProtocol:getBlockLocations(java.lang.String,long,long)	org.apache.hadoop.hdfs.server.namenode.ha.ReadOnly	isCoordinated	true
org.apache.hadoop.hdfs.protocol.ClientProtocol:getServerDefaults()	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.protocol.ClientProtocol:getServerDefaults()	org.apache.hadoop.hdfs.server.namenode.ha.ReadOnly	isCoordinated	true
org.apache.hadoop.hdfs.protocol.ClientProtocol:create(java.lang.String,org.apache.hadoop.fs.permission.FsPermission,java.lang.String,org.apache.hadoop.io.EnumSetWritable,boolean,short,long,org.apache.hadoop.crypto.CryptoProtocolVersion[],java.lang.String,java.lang.String)	org.apache.hadoop.io.retry.AtMostOnce
org.apache.hadoop.hdfs.protocol.ClientProtocol:append(java.lang.String,java.lang.String,org.apache.hadoop.io.EnumSetWritable)	org.apache.hadoop.io.retry.AtMostOnce
org.apache.hadoop.hdfs.protocol.ClientProtocol:setReplication(java.lang.String,short)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.protocol.ClientProtocol:getStoragePolicies()	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.protocol.ClientProtocol:getStoragePolicies()	org.apache.hadoop.hdfs.server.namenode.ha.ReadOnly	isCoordinated	true
org.apache.hadoop.hdfs.protocol.ClientProtocol:setStoragePolicy(java.lang.String,java.lang.String)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.protocol.ClientProtocol:unsetStoragePolicy(java.lang.String)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.protocol.ClientProtocol:getStoragePolicy(java.lang.String)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.protocol.ClientProtocol:getStoragePolicy(java.lang.String)	org.apache.hadoop.hdfs.server.namenode.ha.ReadOnly	isCoordinated	true
org.apache.hadoop.hdfs.protocol.ClientProtocol:setPermission(java.lang.String,org.apache.hadoop.fs.permission.FsPermission)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.protocol.ClientProtocol:setOwner(java.lang.String,java.lang.String,java.lang.String)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.protocol.ClientProtocol:abandonBlock(org.apache.hadoop.hdfs.protocol.ExtendedBlock,long,java.lang.String,java.lang.String)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.protocol.ClientProtocol:addBlock(java.lang.String,java.lang.String,org.apache.hadoop.hdfs.protocol.ExtendedBlock,org.apache.hadoop.hdfs.protocol.DatanodeInfo[],long,java.lang.String[],java.util.EnumSet)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.protocol.ClientProtocol:getAdditionalDatanode(java.lang.String,long,org.apache.hadoop.hdfs.protocol.ExtendedBlock,org.apache.hadoop.hdfs.protocol.DatanodeInfo[],java.lang.String[],org.apache.hadoop.hdfs.protocol.DatanodeInfo[],int,java.lang.String)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.protocol.ClientProtocol:complete(java.lang.String,java.lang.String,org.apache.hadoop.hdfs.protocol.ExtendedBlock,long)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.protocol.ClientProtocol:reportBadBlocks(org.apache.hadoop.hdfs.protocol.LocatedBlock[])	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.protocol.ClientProtocol:rename(java.lang.String,java.lang.String)	org.apache.hadoop.io.retry.AtMostOnce
org.apache.hadoop.hdfs.protocol.ClientProtocol:concat(java.lang.String,java.lang.String[])	org.apache.hadoop.io.retry.AtMostOnce
org.apache.hadoop.hdfs.protocol.ClientProtocol:rename2(java.lang.String,java.lang.String,org.apache.hadoop.fs.Options$Rename[])	org.apache.hadoop.io.retry.AtMostOnce
org.apache.hadoop.hdfs.protocol.ClientProtocol:truncate(java.lang.String,long,java.lang.String)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.protocol.ClientProtocol:delete(java.lang.String,boolean)	org.apache.hadoop.io.retry.AtMostOnce
org.apache.hadoop.hdfs.protocol.ClientProtocol:mkdirs(java.lang.String,org.apache.hadoop.fs.permission.FsPermission,boolean)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.protocol.ClientProtocol:getListing(java.lang.String,byte[],boolean)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.protocol.ClientProtocol:getListing(java.lang.String,byte[],boolean)	org.apache.hadoop.hdfs.server.namenode.ha.ReadOnly	isCoordinated	true
org.apache.hadoop.hdfs.protocol.ClientProtocol:getBatchedListing(java.lang.String[],byte[],boolean)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.protocol.ClientProtocol:getBatchedListing(java.lang.String[],byte[],boolean)	org.apache.hadoop.hdfs.server.namenode.ha.ReadOnly	isCoordinated	true
org.apache.hadoop.hdfs.protocol.ClientProtocol:getSnapshottableDirListing()	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.protocol.ClientProtocol:getSnapshottableDirListing()	org.apache.hadoop.hdfs.server.namenode.ha.ReadOnly	isCoordinated	true
org.apache.hadoop.hdfs.protocol.ClientProtocol:renewLease(java.lang.String)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.protocol.ClientProtocol:recoverLease(java.lang.String,java.lang.String)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.protocol.ClientProtocol:getStats()	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.protocol.ClientProtocol:getStats()	org.apache.hadoop.hdfs.server.namenode.ha.ReadOnly
org.apache.hadoop.hdfs.protocol.ClientProtocol:getReplicatedBlockStats()	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.protocol.ClientProtocol:getReplicatedBlockStats()	org.apache.hadoop.hdfs.server.namenode.ha.ReadOnly
org.apache.hadoop.hdfs.protocol.ClientProtocol:getECBlockGroupStats()	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.protocol.ClientProtocol:getECBlockGroupStats()	org.apache.hadoop.hdfs.server.namenode.ha.ReadOnly
org.apache.hadoop.hdfs.protocol.ClientProtocol:getDatanodeReport(org.apache.hadoop.hdfs.protocol.HdfsConstants$DatanodeReportType)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.protocol.ClientProtocol:getDatanodeReport(org.apache.hadoop.hdfs.protocol.HdfsConstants$DatanodeReportType)	org.apache.hadoop.hdfs.server.namenode.ha.ReadOnly
org.apache.hadoop.hdfs.protocol.ClientProtocol:getDatanodeStorageReport(org.apache.hadoop.hdfs.protocol.HdfsConstants$DatanodeReportType)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.protocol.ClientProtocol:getDatanodeStorageReport(org.apache.hadoop.hdfs.protocol.HdfsConstants$DatanodeReportType)	org.apache.hadoop.hdfs.server.namenode.ha.ReadOnly
org.apache.hadoop.hdfs.protocol.ClientProtocol:getPreferredBlockSize(java.lang.String)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.protocol.ClientProtocol:getPreferredBlockSize(java.lang.String)	org.apache.hadoop.hdfs.server.namenode.ha.ReadOnly	isCoordinated	true
org.apache.hadoop.hdfs.protocol.ClientProtocol:setSafeMode(org.apache.hadoop.hdfs.protocol.HdfsConstants$SafeModeAction,boolean)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.protocol.ClientProtocol:saveNamespace(long,long)	org.apache.hadoop.io.retry.AtMostOnce
org.apache.hadoop.hdfs.protocol.ClientProtocol:rollEdits()	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.protocol.ClientProtocol:restoreFailedStorage(java.lang.String)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.protocol.ClientProtocol:refreshNodes()	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.protocol.ClientProtocol:finalizeUpgrade()	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.protocol.ClientProtocol:upgradeStatus()	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.protocol.ClientProtocol:rollingUpgrade(org.apache.hadoop.hdfs.protocol.HdfsConstants$RollingUpgradeAction)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.protocol.ClientProtocol:listCorruptFileBlocks(java.lang.String,java.lang.String)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.protocol.ClientProtocol:listCorruptFileBlocks(java.lang.String,java.lang.String)	org.apache.hadoop.hdfs.server.namenode.ha.ReadOnly	isCoordinated	true
org.apache.hadoop.hdfs.protocol.ClientProtocol:metaSave(java.lang.String)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.protocol.ClientProtocol:setBalancerBandwidth(long)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.protocol.ClientProtocol:getFileInfo(java.lang.String)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.protocol.ClientProtocol:getFileInfo(java.lang.String)	org.apache.hadoop.hdfs.server.namenode.ha.ReadOnly	isCoordinated	true
org.apache.hadoop.hdfs.protocol.ClientProtocol:isFileClosed(java.lang.String)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.protocol.ClientProtocol:isFileClosed(java.lang.String)	org.apache.hadoop.hdfs.server.namenode.ha.ReadOnly	isCoordinated	true
org.apache.hadoop.hdfs.protocol.ClientProtocol:getFileLinkInfo(java.lang.String)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.protocol.ClientProtocol:getFileLinkInfo(java.lang.String)	org.apache.hadoop.hdfs.server.namenode.ha.ReadOnly	isCoordinated	true
org.apache.hadoop.hdfs.protocol.ClientProtocol:getLocatedFileInfo(java.lang.String,boolean)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.protocol.ClientProtocol:getLocatedFileInfo(java.lang.String,boolean)	org.apache.hadoop.hdfs.server.namenode.ha.ReadOnly	isCoordinated	true
org.apache.hadoop.hdfs.protocol.ClientProtocol:getContentSummary(java.lang.String)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.protocol.ClientProtocol:getContentSummary(java.lang.String)	org.apache.hadoop.hdfs.server.namenode.ha.ReadOnly	isCoordinated	true
org.apache.hadoop.hdfs.protocol.ClientProtocol:setQuota(java.lang.String,long,long,org.apache.hadoop.fs.StorageType)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.protocol.ClientProtocol:fsync(java.lang.String,long,java.lang.String,long)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.protocol.ClientProtocol:setTimes(java.lang.String,long,long)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.protocol.ClientProtocol:createSymlink(java.lang.String,java.lang.String,org.apache.hadoop.fs.permission.FsPermission,boolean)	org.apache.hadoop.io.retry.AtMostOnce
org.apache.hadoop.hdfs.protocol.ClientProtocol:getLinkTarget(java.lang.String)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.protocol.ClientProtocol:getLinkTarget(java.lang.String)	org.apache.hadoop.hdfs.server.namenode.ha.ReadOnly	isCoordinated	true
org.apache.hadoop.hdfs.protocol.ClientProtocol:updateBlockForPipeline(org.apache.hadoop.hdfs.protocol.ExtendedBlock,java.lang.String)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.protocol.ClientProtocol:updatePipeline(java.lang.String,org.apache.hadoop.hdfs.protocol.ExtendedBlock,org.apache.hadoop.hdfs.protocol.ExtendedBlock,org.apache.hadoop.hdfs.protocol.DatanodeID[],java.lang.String[])	org.apache.hadoop.io.retry.AtMostOnce
org.apache.hadoop.hdfs.protocol.ClientProtocol:getDelegationToken(org.apache.hadoop.io.Text)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.protocol.ClientProtocol:renewDelegationToken(org.apache.hadoop.security.token.Token)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.protocol.ClientProtocol:cancelDelegationToken(org.apache.hadoop.security.token.Token)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.protocol.ClientProtocol:getDataEncryptionKey()	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.protocol.ClientProtocol:getDataEncryptionKey()	org.apache.hadoop.hdfs.server.namenode.ha.ReadOnly	isCoordinated	true
org.apache.hadoop.hdfs.protocol.ClientProtocol:createSnapshot(java.lang.String,java.lang.String)	org.apache.hadoop.io.retry.AtMostOnce
org.apache.hadoop.hdfs.protocol.ClientProtocol:deleteSnapshot(java.lang.String,java.lang.String)	org.apache.hadoop.io.retry.AtMostOnce
org.apache.hadoop.hdfs.protocol.ClientProtocol:renameSnapshot(java.lang.String,java.lang.String,java.lang.String)	org.apache.hadoop.io.retry.AtMostOnce
org.apache.hadoop.hdfs.protocol.ClientProtocol:allowSnapshot(java.lang.String)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.protocol.ClientProtocol:disallowSnapshot(java.lang.String)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.protocol.ClientProtocol:getSnapshotDiffReport(java.lang.String,java.lang.String,java.lang.String)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.protocol.ClientProtocol:getSnapshotDiffReport(java.lang.String,java.lang.String,java.lang.String)	org.apache.hadoop.hdfs.server.namenode.ha.ReadOnly	isCoordinated	true
org.apache.hadoop.hdfs.protocol.ClientProtocol:getSnapshotDiffReportListing(java.lang.String,java.lang.String,java.lang.String,byte[],int)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.protocol.ClientProtocol:getSnapshotDiffReportListing(java.lang.String,java.lang.String,java.lang.String,byte[],int)	org.apache.hadoop.hdfs.server.namenode.ha.ReadOnly	isCoordinated	true
org.apache.hadoop.hdfs.protocol.ClientProtocol:addCacheDirective(org.apache.hadoop.hdfs.protocol.CacheDirectiveInfo,java.util.EnumSet)	org.apache.hadoop.io.retry.AtMostOnce
org.apache.hadoop.hdfs.protocol.ClientProtocol:modifyCacheDirective(org.apache.hadoop.hdfs.protocol.CacheDirectiveInfo,java.util.EnumSet)	org.apache.hadoop.io.retry.AtMostOnce
org.apache.hadoop.hdfs.protocol.ClientProtocol:removeCacheDirective(long)	org.apache.hadoop.io.retry.AtMostOnce
org.apache.hadoop.hdfs.protocol.ClientProtocol:listCacheDirectives(long,org.apache.hadoop.hdfs.protocol.CacheDirectiveInfo)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.protocol.ClientProtocol:listCacheDirectives(long,org.apache.hadoop.hdfs.protocol.CacheDirectiveInfo)	org.apache.hadoop.hdfs.server.namenode.ha.ReadOnly	isCoordinated	true
org.apache.hadoop.hdfs.protocol.ClientProtocol:addCachePool(org.apache.hadoop.hdfs.protocol.CachePoolInfo)	org.apache.hadoop.io.retry.AtMostOnce
org.apache.hadoop.hdfs.protocol.ClientProtocol:modifyCachePool(org.apache.hadoop.hdfs.protocol.CachePoolInfo)	org.apache.hadoop.io.retry.AtMostOnce
org.apache.hadoop.hdfs.protocol.ClientProtocol:removeCachePool(java.lang.String)	org.apache.hadoop.io.retry.AtMostOnce
org.apache.hadoop.hdfs.protocol.ClientProtocol:listCachePools(java.lang.String)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.protocol.ClientProtocol:listCachePools(java.lang.String)	org.apache.hadoop.hdfs.server.namenode.ha.ReadOnly	isCoordinated	true
org.apache.hadoop.hdfs.protocol.ClientProtocol:modifyAclEntries(java.lang.String,java.util.List)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.protocol.ClientProtocol:removeAclEntries(java.lang.String,java.util.List)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.protocol.ClientProtocol:removeDefaultAcl(java.lang.String)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.protocol.ClientProtocol:removeAcl(java.lang.String)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.protocol.ClientProtocol:setAcl(java.lang.String,java.util.List)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.protocol.ClientProtocol:getAclStatus(java.lang.String)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.protocol.ClientProtocol:getAclStatus(java.lang.String)	org.apache.hadoop.hdfs.server.namenode.ha.ReadOnly	isCoordinated	true
org.apache.hadoop.hdfs.protocol.ClientProtocol:createEncryptionZone(java.lang.String,java.lang.String)	org.apache.hadoop.io.retry.AtMostOnce
org.apache.hadoop.hdfs.protocol.ClientProtocol:getEZForPath(java.lang.String)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.protocol.ClientProtocol:getEZForPath(java.lang.String)	org.apache.hadoop.hdfs.server.namenode.ha.ReadOnly	isCoordinated	true
org.apache.hadoop.hdfs.protocol.ClientProtocol:listEncryptionZones(long)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.protocol.ClientProtocol:listEncryptionZones(long)	org.apache.hadoop.hdfs.server.namenode.ha.ReadOnly	isCoordinated	true
org.apache.hadoop.hdfs.protocol.ClientProtocol:reencryptEncryptionZone(java.lang.String,org.apache.hadoop.hdfs.protocol.HdfsConstants$ReencryptAction)	org.apache.hadoop.io.retry.AtMostOnce
org.apache.hadoop.hdfs.protocol.ClientProtocol:listReencryptionStatus(long)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.protocol.ClientProtocol:listReencryptionStatus(long)	org.apache.hadoop.hdfs.server.namenode.ha.ReadOnly	isCoordinated	true
org.apache.hadoop.hdfs.protocol.ClientProtocol:setXAttr(java.lang.String,org.apache.hadoop.fs.XAttr,java.util.EnumSet)	org.apache.hadoop.io.retry.AtMostOnce
org.apache.hadoop.hdfs.protocol.ClientProtocol:getXAttrs(java.lang.String,java.util.List)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.protocol.ClientProtocol:getXAttrs(java.lang.String,java.util.List)	org.apache.hadoop.hdfs.server.namenode.ha.ReadOnly	isCoordinated	true
org.apache.hadoop.hdfs.protocol.ClientProtocol:listXAttrs(java.lang.String)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.protocol.ClientProtocol:listXAttrs(java.lang.String)	org.apache.hadoop.hdfs.server.namenode.ha.ReadOnly	isCoordinated	true
org.apache.hadoop.hdfs.protocol.ClientProtocol:removeXAttr(java.lang.String,org.apache.hadoop.fs.XAttr)	org.apache.hadoop.io.retry.AtMostOnce
org.apache.hadoop.hdfs.protocol.ClientProtocol:checkAccess(java.lang.String,org.apache.hadoop.fs.permission.FsAction)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.protocol.ClientProtocol:checkAccess(java.lang.String,org.apache.hadoop.fs.permission.FsAction)	org.apache.hadoop.hdfs.server.namenode.ha.ReadOnly	isCoordinated	true
org.apache.hadoop.hdfs.protocol.ClientProtocol:getCurrentEditLogTxid()	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.protocol.ClientProtocol:getCurrentEditLogTxid()	org.apache.hadoop.hdfs.server.namenode.ha.ReadOnly	isCoordinated	true
org.apache.hadoop.hdfs.protocol.ClientProtocol:getEditsFromTxid(long)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.protocol.ClientProtocol:getEditsFromTxid(long)	org.apache.hadoop.hdfs.server.namenode.ha.ReadOnly	isCoordinated	true
org.apache.hadoop.hdfs.protocol.ClientProtocol:setErasureCodingPolicy(java.lang.String,java.lang.String)	org.apache.hadoop.io.retry.AtMostOnce
org.apache.hadoop.hdfs.protocol.ClientProtocol:addErasureCodingPolicies(org.apache.hadoop.hdfs.protocol.ErasureCodingPolicy[])	org.apache.hadoop.io.retry.AtMostOnce
org.apache.hadoop.hdfs.protocol.ClientProtocol:removeErasureCodingPolicy(java.lang.String)	org.apache.hadoop.io.retry.AtMostOnce
org.apache.hadoop.hdfs.protocol.ClientProtocol:enableErasureCodingPolicy(java.lang.String)	org.apache.hadoop.io.retry.AtMostOnce
org.apache.hadoop.hdfs.protocol.ClientProtocol:disableErasureCodingPolicy(java.lang.String)	org.apache.hadoop.io.retry.AtMostOnce
org.apache.hadoop.hdfs.protocol.ClientProtocol:getErasureCodingPolicies()	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.protocol.ClientProtocol:getErasureCodingPolicies()	org.apache.hadoop.hdfs.server.namenode.ha.ReadOnly	isCoordinated	true
org.apache.hadoop.hdfs.protocol.ClientProtocol:getErasureCodingCodecs()	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.protocol.ClientProtocol:getErasureCodingCodecs()	org.apache.hadoop.hdfs.server.namenode.ha.ReadOnly	isCoordinated	true
org.apache.hadoop.hdfs.protocol.ClientProtocol:getErasureCodingPolicy(java.lang.String)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.protocol.ClientProtocol:getErasureCodingPolicy(java.lang.String)	org.apache.hadoop.hdfs.server.namenode.ha.ReadOnly	isCoordinated	true
org.apache.hadoop.hdfs.protocol.ClientProtocol:unsetErasureCodingPolicy(java.lang.String)	org.apache.hadoop.io.retry.AtMostOnce
org.apache.hadoop.hdfs.protocol.ClientProtocol:getECTopologyResultForPolicies(java.lang.String[])	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.protocol.ClientProtocol:getECTopologyResultForPolicies(java.lang.String[])	org.apache.hadoop.hdfs.server.namenode.ha.ReadOnly
org.apache.hadoop.hdfs.protocol.ClientProtocol:getQuotaUsage(java.lang.String)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.protocol.ClientProtocol:getQuotaUsage(java.lang.String)	org.apache.hadoop.hdfs.server.namenode.ha.ReadOnly	activeOnly	true
org.apache.hadoop.hdfs.protocol.ClientProtocol:listOpenFiles(long)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.protocol.ClientProtocol:listOpenFiles(long)	java.lang.Deprecated
org.apache.hadoop.hdfs.protocol.ClientProtocol:listOpenFiles(long)	org.apache.hadoop.hdfs.server.namenode.ha.ReadOnly	isCoordinated	true
org.apache.hadoop.hdfs.protocol.ClientProtocol:listOpenFiles(long,java.util.EnumSet,java.lang.String)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.protocol.ClientProtocol:listOpenFiles(long,java.util.EnumSet,java.lang.String)	org.apache.hadoop.hdfs.server.namenode.ha.ReadOnly	isCoordinated	true
org.apache.hadoop.hdfs.protocol.ClientProtocol:getHAServiceState()	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.protocol.ClientProtocol:getHAServiceState()	org.apache.hadoop.hdfs.server.namenode.ha.ReadOnly
org.apache.hadoop.hdfs.protocol.ClientProtocol:msync()	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.protocol.ClientProtocol:msync()	org.apache.hadoop.hdfs.server.namenode.ha.ReadOnly	activeOnly	true
org.apache.hadoop.hdfs.protocol.ClientProtocol:satisfyStoragePolicy(java.lang.String)	org.apache.hadoop.io.retry.AtMostOnce
org.apache.hadoop.hdfs.protocol.ClientProtocol:getSlowDatanodeReport()	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.protocol.ClientProtocol:getSlowDatanodeReport()	org.apache.hadoop.hdfs.server.namenode.ha.ReadOnly
org.apache.hadoop.hdfs.protocol.DatanodeID:<init>(java.lang.String,org.apache.hadoop.hdfs.protocol.DatanodeID)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.DFSStripedInputStream:blockSeekTo(long)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.client.HdfsAdmin:createEncryptionZone(org.apache.hadoop.fs.Path,java.lang.String)	java.lang.Deprecated
org.apache.hadoop.hdfs.client.HdfsAdmin:listOpenFiles()	java.lang.Deprecated
org.apache.hadoop.hdfs.client.HdfsAdmin:listOpenFiles(java.util.EnumSet)	java.lang.Deprecated
org.apache.hadoop.hdfs.client.impl.metrics.BlockReaderLocalMetrics:getShortCircuitReadRollingAverages()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.client.impl.BlockReaderRemote:getPeer()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.client.impl.BlockReaderLocal:getVerifyChecksum()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.client.impl.BlockReaderLocal:getMaxReadaheadLength()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.client.impl.BlockReaderLocal:forceAnchorable()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.client.impl.BlockReaderLocal:forceUnanchorable()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.client.impl.BlockReaderFactory:setFailureInjectorForTesting(org.apache.hadoop.hdfs.client.impl.BlockReaderFactory$FailureInjector)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.client.impl.LeaseRenewer:setRenewalTime(long)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.client.impl.LeaseRenewer:isRunning()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.client.impl.LeaseRenewer:setEmptyTime(long)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.client.impl.LeaseRenewer:setLeaseRenewerGraceDefault(long)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.client.impl.DfsClientConf:getBlockWriteLocateFollowingInitialDelayMs()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.http.client.HttpFSFileSystem:delete(org.apache.hadoop.fs.Path)	java.lang.Deprecated
org.apache.hadoop.fs.http.server.HttpFSServer:getRoot(javax.ws.rs.core.UriInfo,org.apache.hadoop.fs.http.server.HttpFSParametersProvider$OperationParam,org.apache.hadoop.lib.wsrs.Parameters,javax.servlet.http.HttpServletRequest)	javax.ws.rs.GET
org.apache.hadoop.fs.http.server.HttpFSServer:getRoot(javax.ws.rs.core.UriInfo,org.apache.hadoop.fs.http.server.HttpFSParametersProvider$OperationParam,org.apache.hadoop.lib.wsrs.Parameters,javax.servlet.http.HttpServletRequest)	javax.ws.rs.Produces	value	{application/json; charset=utf-8}
org.apache.hadoop.fs.http.server.HttpFSServer:get(java.lang.String,javax.ws.rs.core.UriInfo,org.apache.hadoop.fs.http.server.HttpFSParametersProvider$OperationParam,org.apache.hadoop.lib.wsrs.Parameters,javax.servlet.http.HttpServletRequest)	javax.ws.rs.GET
org.apache.hadoop.fs.http.server.HttpFSServer:get(java.lang.String,javax.ws.rs.core.UriInfo,org.apache.hadoop.fs.http.server.HttpFSParametersProvider$OperationParam,org.apache.hadoop.lib.wsrs.Parameters,javax.servlet.http.HttpServletRequest)	javax.ws.rs.Path	value	{path:.*}
org.apache.hadoop.fs.http.server.HttpFSServer:get(java.lang.String,javax.ws.rs.core.UriInfo,org.apache.hadoop.fs.http.server.HttpFSParametersProvider$OperationParam,org.apache.hadoop.lib.wsrs.Parameters,javax.servlet.http.HttpServletRequest)	javax.ws.rs.Produces	value	{application/octet-stream; charset=utf-8,application/json; charset=utf-8}
org.apache.hadoop.fs.http.server.HttpFSServer:delete(java.lang.String,org.apache.hadoop.fs.http.server.HttpFSParametersProvider$OperationParam,org.apache.hadoop.lib.wsrs.Parameters,javax.servlet.http.HttpServletRequest)	javax.ws.rs.DELETE
org.apache.hadoop.fs.http.server.HttpFSServer:delete(java.lang.String,org.apache.hadoop.fs.http.server.HttpFSParametersProvider$OperationParam,org.apache.hadoop.lib.wsrs.Parameters,javax.servlet.http.HttpServletRequest)	javax.ws.rs.Path	value	{path:.*}
org.apache.hadoop.fs.http.server.HttpFSServer:delete(java.lang.String,org.apache.hadoop.fs.http.server.HttpFSParametersProvider$OperationParam,org.apache.hadoop.lib.wsrs.Parameters,javax.servlet.http.HttpServletRequest)	javax.ws.rs.Produces	value	{application/json; charset=utf-8}
org.apache.hadoop.fs.http.server.HttpFSServer:postRoot(java.io.InputStream,javax.ws.rs.core.UriInfo,org.apache.hadoop.fs.http.server.HttpFSParametersProvider$OperationParam,org.apache.hadoop.lib.wsrs.Parameters,javax.servlet.http.HttpServletRequest)	javax.ws.rs.POST
org.apache.hadoop.fs.http.server.HttpFSServer:postRoot(java.io.InputStream,javax.ws.rs.core.UriInfo,org.apache.hadoop.fs.http.server.HttpFSParametersProvider$OperationParam,org.apache.hadoop.lib.wsrs.Parameters,javax.servlet.http.HttpServletRequest)	javax.ws.rs.Produces	value	{application/json; charset=utf-8}
org.apache.hadoop.fs.http.server.HttpFSServer:post(java.io.InputStream,javax.ws.rs.core.UriInfo,java.lang.String,org.apache.hadoop.fs.http.server.HttpFSParametersProvider$OperationParam,org.apache.hadoop.lib.wsrs.Parameters,javax.servlet.http.HttpServletRequest)	javax.ws.rs.POST
org.apache.hadoop.fs.http.server.HttpFSServer:post(java.io.InputStream,javax.ws.rs.core.UriInfo,java.lang.String,org.apache.hadoop.fs.http.server.HttpFSParametersProvider$OperationParam,org.apache.hadoop.lib.wsrs.Parameters,javax.servlet.http.HttpServletRequest)	javax.ws.rs.Path	value	{path:.*}
org.apache.hadoop.fs.http.server.HttpFSServer:post(java.io.InputStream,javax.ws.rs.core.UriInfo,java.lang.String,org.apache.hadoop.fs.http.server.HttpFSParametersProvider$OperationParam,org.apache.hadoop.lib.wsrs.Parameters,javax.servlet.http.HttpServletRequest)	javax.ws.rs.Consumes	value	{*/*}
org.apache.hadoop.fs.http.server.HttpFSServer:post(java.io.InputStream,javax.ws.rs.core.UriInfo,java.lang.String,org.apache.hadoop.fs.http.server.HttpFSParametersProvider$OperationParam,org.apache.hadoop.lib.wsrs.Parameters,javax.servlet.http.HttpServletRequest)	javax.ws.rs.Produces	value	{application/json; charset=utf-8}
org.apache.hadoop.fs.http.server.HttpFSServer:putRoot(java.io.InputStream,javax.ws.rs.core.UriInfo,org.apache.hadoop.fs.http.server.HttpFSParametersProvider$OperationParam,org.apache.hadoop.lib.wsrs.Parameters,javax.servlet.http.HttpServletRequest)	javax.ws.rs.PUT
org.apache.hadoop.fs.http.server.HttpFSServer:putRoot(java.io.InputStream,javax.ws.rs.core.UriInfo,org.apache.hadoop.fs.http.server.HttpFSParametersProvider$OperationParam,org.apache.hadoop.lib.wsrs.Parameters,javax.servlet.http.HttpServletRequest)	javax.ws.rs.Produces	value	{application/json; charset=utf-8}
org.apache.hadoop.fs.http.server.HttpFSServer:put(java.io.InputStream,javax.ws.rs.core.UriInfo,java.lang.String,org.apache.hadoop.fs.http.server.HttpFSParametersProvider$OperationParam,org.apache.hadoop.lib.wsrs.Parameters,javax.servlet.http.HttpServletRequest)	javax.ws.rs.PUT
org.apache.hadoop.fs.http.server.HttpFSServer:put(java.io.InputStream,javax.ws.rs.core.UriInfo,java.lang.String,org.apache.hadoop.fs.http.server.HttpFSParametersProvider$OperationParam,org.apache.hadoop.lib.wsrs.Parameters,javax.servlet.http.HttpServletRequest)	javax.ws.rs.Path	value	{path:.*}
org.apache.hadoop.fs.http.server.HttpFSServer:put(java.io.InputStream,javax.ws.rs.core.UriInfo,java.lang.String,org.apache.hadoop.fs.http.server.HttpFSParametersProvider$OperationParam,org.apache.hadoop.lib.wsrs.Parameters,javax.servlet.http.HttpServletRequest)	javax.ws.rs.Consumes	value	{*/*}
org.apache.hadoop.fs.http.server.HttpFSServer:put(java.io.InputStream,javax.ws.rs.core.UriInfo,java.lang.String,org.apache.hadoop.fs.http.server.HttpFSParametersProvider$OperationParam,org.apache.hadoop.lib.wsrs.Parameters,javax.servlet.http.HttpServletRequest)	javax.ws.rs.Produces	value	{application/json; charset=utf-8}
org.apache.hadoop.lib.servlet.ServerWebApp:setAuthority(java.net.InetSocketAddress)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.nfs.mount.RpcProgramMountd:getExports()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.nfs.nfs3.WriteManager:getOpenFileCtxCache()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.nfs.nfs3.Nfs3:startServiceInternal(boolean)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.nfs.nfs3.DFSClientCache:getClientCache()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.nfs.nfs3.WriteCtx:getData()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.nfs.nfs3.RpcProgramNfs3:getInfoServer()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.nfs.nfs3.RpcProgramNfs3:getattr(org.apache.hadoop.oncrpc.XDR,org.apache.hadoop.oncrpc.security.SecurityHandler,java.net.SocketAddress)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.nfs.nfs3.RpcProgramNfs3:setattr(org.apache.hadoop.oncrpc.XDR,org.apache.hadoop.oncrpc.security.SecurityHandler,java.net.SocketAddress)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.nfs.nfs3.RpcProgramNfs3:lookup(org.apache.hadoop.oncrpc.XDR,org.apache.hadoop.oncrpc.security.SecurityHandler,java.net.SocketAddress)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.nfs.nfs3.RpcProgramNfs3:access(org.apache.hadoop.oncrpc.XDR,org.apache.hadoop.oncrpc.security.SecurityHandler,java.net.SocketAddress)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.nfs.nfs3.RpcProgramNfs3:readlink(org.apache.hadoop.oncrpc.XDR,org.apache.hadoop.oncrpc.security.SecurityHandler,java.net.SocketAddress)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.nfs.nfs3.RpcProgramNfs3:read(org.apache.hadoop.oncrpc.XDR,org.apache.hadoop.oncrpc.security.SecurityHandler,java.net.SocketAddress)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.nfs.nfs3.RpcProgramNfs3:write(org.apache.hadoop.oncrpc.XDR,io.netty.channel.Channel,int,org.apache.hadoop.oncrpc.security.SecurityHandler,java.net.SocketAddress)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.nfs.nfs3.RpcProgramNfs3:create(org.apache.hadoop.oncrpc.XDR,org.apache.hadoop.oncrpc.security.SecurityHandler,java.net.SocketAddress)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.nfs.nfs3.RpcProgramNfs3:mkdir(org.apache.hadoop.oncrpc.XDR,org.apache.hadoop.oncrpc.security.SecurityHandler,java.net.SocketAddress)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.nfs.nfs3.RpcProgramNfs3:remove(org.apache.hadoop.oncrpc.XDR,org.apache.hadoop.oncrpc.security.SecurityHandler,java.net.SocketAddress)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.nfs.nfs3.RpcProgramNfs3:rmdir(org.apache.hadoop.oncrpc.XDR,org.apache.hadoop.oncrpc.security.SecurityHandler,java.net.SocketAddress)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.nfs.nfs3.RpcProgramNfs3:rename(org.apache.hadoop.oncrpc.XDR,org.apache.hadoop.oncrpc.security.SecurityHandler,java.net.SocketAddress)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.nfs.nfs3.RpcProgramNfs3:symlink(org.apache.hadoop.oncrpc.XDR,org.apache.hadoop.oncrpc.security.SecurityHandler,java.net.SocketAddress)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.nfs.nfs3.RpcProgramNfs3:readdirplus(org.apache.hadoop.oncrpc.XDR,org.apache.hadoop.oncrpc.security.SecurityHandler,java.net.SocketAddress)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.nfs.nfs3.RpcProgramNfs3:fsstat(org.apache.hadoop.oncrpc.XDR,org.apache.hadoop.oncrpc.security.SecurityHandler,java.net.SocketAddress)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.nfs.nfs3.RpcProgramNfs3:fsinfo(org.apache.hadoop.oncrpc.XDR,org.apache.hadoop.oncrpc.security.SecurityHandler,java.net.SocketAddress)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.nfs.nfs3.RpcProgramNfs3:pathconf(org.apache.hadoop.oncrpc.XDR,org.apache.hadoop.oncrpc.security.SecurityHandler,java.net.SocketAddress)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.nfs.nfs3.RpcProgramNfs3:commit(org.apache.hadoop.oncrpc.XDR,io.netty.channel.Channel,int,org.apache.hadoop.oncrpc.security.SecurityHandler,java.net.SocketAddress)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.nfs.nfs3.RpcProgramNfs3:getWriteManager()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.nfs.nfs3.OpenFileCtxCache:getEntryToEvict()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.nfs.nfs3.OpenFileCtxCache:scan(long)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.nfs.nfs3.OpenFileCtx:alterWriteRequest(org.apache.hadoop.nfs.nfs3.request.WRITE3Request,long)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.nfs.nfs3.OpenFileCtx:trimWriteRequest(org.apache.hadoop.hdfs.nfs.nfs3.WriteCtx,long)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.nfs.nfs3.OpenFileCtx:checkSequential(long,long)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.nfs.nfs3.OpenFileCtx:checkCommitInternal(long,io.netty.channel.Channel,int,org.apache.hadoop.nfs.nfs3.Nfs3FileAttributes,boolean)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.nfs.nfs3.OpenFileCtx:getPendingWritesForTest()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.nfs.nfs3.OpenFileCtx:getPendingCommitsForTest()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.nfs.nfs3.OpenFileCtx:getNextOffsetForTest()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.nfs.nfs3.OpenFileCtx:setNextOffsetForTest(long)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.nfs.nfs3.OpenFileCtx:setActiveStatusForTest(boolean)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$RouterFederatedStateProtoOrBuilder:getNamespaceStateIds()	java.lang.Deprecated
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$MountTableRecordProto$DestOrder:valueOf(int)	java.lang.Deprecated
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$RouterFederatedStateProto:getNamespaceStateIds()	java.lang.Deprecated
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$RouterFederatedStateProto$Builder:getNamespaceStateIds()	java.lang.Deprecated
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$RouterFederatedStateProto$Builder:getMutableNamespaceStateIds()	java.lang.Deprecated
org.apache.hadoop.hdfs.server.federation.metrics.RBFMetrics:getDateString(long)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.federation.metrics.FederationMBean:getRouterStarted()	java.lang.Deprecated
org.apache.hadoop.hdfs.server.federation.metrics.FederationMBean:getVersion()	java.lang.Deprecated
org.apache.hadoop.hdfs.server.federation.metrics.FederationMBean:getCompiledDate()	java.lang.Deprecated
org.apache.hadoop.hdfs.server.federation.metrics.FederationMBean:getCompileInfo()	java.lang.Deprecated
org.apache.hadoop.hdfs.server.federation.metrics.FederationMBean:getHostAndPort()	java.lang.Deprecated
org.apache.hadoop.hdfs.server.federation.metrics.FederationMBean:getRouterId()	java.lang.Deprecated
org.apache.hadoop.hdfs.server.federation.metrics.FederationMBean:getBlockPoolId()	java.lang.Deprecated
org.apache.hadoop.hdfs.server.federation.metrics.FederationMBean:getRouterStatus()	java.lang.Deprecated
org.apache.hadoop.hdfs.server.federation.metrics.FederationMBean:getCurrentTokensCount()	java.lang.Deprecated
org.apache.hadoop.hdfs.server.federation.metrics.FederationMBean:isSecurityEnabled()	java.lang.Deprecated
org.apache.hadoop.hdfs.server.federation.metrics.NamenodeBeanMetrics:getPendingReplicationBlocks()	java.lang.Deprecated
org.apache.hadoop.hdfs.server.federation.metrics.NamenodeBeanMetrics:getUnderReplicatedBlocks()	java.lang.Deprecated
org.apache.hadoop.hdfs.server.federation.metrics.StateStoreMetrics:reset()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.federation.resolver.MultipleDestinationMountTableResolver:addResolver(org.apache.hadoop.hdfs.server.federation.resolver.order.DestinationOrder,org.apache.hadoop.hdfs.server.federation.resolver.order.OrderedResolver)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.federation.resolver.order.LocalResolver:getClientAddr()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.federation.resolver.order.HashResolver:extractTempFileName(java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.federation.resolver.MountTableResolver:<init>(org.apache.hadoop.conf.Configuration)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.federation.resolver.MountTableResolver:refreshEntries(java.util.Collection)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.federation.resolver.MountTableResolver:isTrashPath(java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.federation.resolver.MountTableResolver:getTrashRoot()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.federation.resolver.MountTableResolver:subtractTrashCurrentPath(java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.federation.resolver.MountTableResolver:getDefaultNameService()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.federation.resolver.MountTableResolver:setDefaultNameService(java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.federation.resolver.MountTableResolver:isDefaultNSEnable()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.federation.resolver.MountTableResolver:setDefaultNSEnable(boolean)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.federation.resolver.MountTableResolver:setDisabled(boolean)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.federation.router.ConnectionPool:getClientIndex()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.federation.router.RouterAdminServer:getAdminServer()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.federation.router.RouterRpcClient:processExceptionMsg(java.lang.String,java.lang.String,java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.federation.router.Router:getQuotaCacheUpdateService()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.federation.router.Router:getNamenodeHeartbeatServices()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.federation.router.Router:getRouterHeartbeatService()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.federation.router.RouterClientProtocol:rename(java.lang.String,java.lang.String)	java.lang.Deprecated
org.apache.hadoop.hdfs.server.federation.router.RouterClientProtocol:listOpenFiles(long)	java.lang.Deprecated
org.apache.hadoop.hdfs.server.federation.router.RouterClientProtocol:getMountPointStatus(java.lang.String,int,long)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.federation.router.RouterClientProtocol:isMultiDestDirectory(java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.federation.router.RouterHeartbeatService:updateStateStore()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.federation.router.RouterRpcServer:getServer()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.federation.router.RouterRpcServer:rename(java.lang.String,java.lang.String)	java.lang.Deprecated
org.apache.hadoop.hdfs.server.federation.router.RouterRpcServer:listOpenFiles(long)	java.lang.Deprecated
org.apache.hadoop.hdfs.server.federation.router.RouterRpcServer:getClientProtocolModule()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.federation.router.ConnectionPoolId:getUgi()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.federation.router.ConnectionManager:getPools()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.federation.router.ConnectionManager:cleanup(org.apache.hadoop.hdfs.server.federation.router.ConnectionPool)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.federation.router.security.RouterSecurityManager:<init>(org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.federation.router.security.token.HikariDataSourceConnectionFactory:getDataSource()	org.apache.hadoop.classification.VisibleForTesting
org.apache.hadoop.hdfs.server.federation.router.security.token.SQLDelegationTokenSecretManagerImpl:getConnectionFactory()	org.apache.hadoop.classification.VisibleForTesting
org.apache.hadoop.hdfs.server.federation.router.MountTableRefresherService:closeRouterClient(org.apache.hadoop.hdfs.server.federation.router.RouterClient)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.federation.router.MountTableRefresherService:createRouterClient(java.net.InetSocketAddress,org.apache.hadoop.conf.Configuration)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.federation.router.MountTableRefresherService:getLocalRefresher(java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.federation.store.driver.StateStoreRecordOperations:get(java.lang.Class)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.server.federation.store.driver.StateStoreRecordOperations:get(java.lang.Class,org.apache.hadoop.hdfs.server.federation.store.records.Query)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.server.federation.store.driver.StateStoreRecordOperations:getMultiple(java.lang.Class,org.apache.hadoop.hdfs.server.federation.store.records.Query)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.server.federation.store.driver.StateStoreRecordOperations:put(org.apache.hadoop.hdfs.server.federation.store.records.BaseRecord,boolean,boolean)	org.apache.hadoop.io.retry.AtMostOnce
org.apache.hadoop.hdfs.server.federation.store.driver.StateStoreRecordOperations:putAll(java.util.List,boolean,boolean)	org.apache.hadoop.io.retry.AtMostOnce
org.apache.hadoop.hdfs.server.federation.store.driver.StateStoreRecordOperations:remove(org.apache.hadoop.hdfs.server.federation.store.records.BaseRecord)	org.apache.hadoop.io.retry.AtMostOnce
org.apache.hadoop.hdfs.server.federation.store.driver.StateStoreRecordOperations:removeAll(java.lang.Class)	org.apache.hadoop.io.retry.AtMostOnce
org.apache.hadoop.hdfs.server.federation.store.driver.StateStoreRecordOperations:remove(java.lang.Class,org.apache.hadoop.hdfs.server.federation.store.records.Query)	org.apache.hadoop.io.retry.AtMostOnce
org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreFileImpl:getWriter(java.lang.String)	org.apache.hadoop.classification.VisibleForTesting
org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreFileSystemImpl:getWriter(java.lang.String)	org.apache.hadoop.classification.VisibleForTesting
org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreFileBaseImpl:getWriter(java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreFileBaseImpl:isOldTempRecord(java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.federation.store.StateStoreService:closeDriver()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.federation.store.StateStoreService:stopCacheUpdateService()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.federation.store.records.BaseRecord:hasOtherFields()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.federation.store.protocol.GetSafeModeResponse:isInSafeMode()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.hdfs.server.federation.store.protocol.GetSafeModeResponse:isInSafeMode()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.hdfs.server.federation.store.protocol.GetSafeModeResponse:setSafeMode(boolean)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.hdfs.server.federation.store.protocol.GetSafeModeResponse:setSafeMode(boolean)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.hdfs.server.federation.store.protocol.DisableNameserviceResponse:getStatus()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.hdfs.server.federation.store.protocol.DisableNameserviceResponse:getStatus()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.hdfs.server.federation.store.protocol.DisableNameserviceResponse:setStatus(boolean)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.hdfs.server.federation.store.protocol.DisableNameserviceResponse:setStatus(boolean)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.hdfs.server.federation.store.protocol.GetRouterRegistrationsResponse:getRouters()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.hdfs.server.federation.store.protocol.GetRouterRegistrationsResponse:getRouters()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.hdfs.server.federation.store.protocol.GetRouterRegistrationsResponse:setRouters(java.util.List)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.hdfs.server.federation.store.protocol.GetRouterRegistrationsResponse:setRouters(java.util.List)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.hdfs.server.federation.store.protocol.GetRouterRegistrationsResponse:getTimestamp()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.hdfs.server.federation.store.protocol.GetRouterRegistrationsResponse:getTimestamp()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.hdfs.server.federation.store.protocol.GetRouterRegistrationsResponse:setTimestamp(long)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.hdfs.server.federation.store.protocol.GetRouterRegistrationsResponse:setTimestamp(long)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.hdfs.server.federation.store.protocol.GetMountTableEntriesResponse:getEntries()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.hdfs.server.federation.store.protocol.GetMountTableEntriesResponse:getEntries()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.hdfs.server.federation.store.protocol.GetMountTableEntriesResponse:setEntries(java.util.List)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.hdfs.server.federation.store.protocol.GetMountTableEntriesResponse:setEntries(java.util.List)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.hdfs.server.federation.store.protocol.GetMountTableEntriesResponse:getTimestamp()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.hdfs.server.federation.store.protocol.GetMountTableEntriesResponse:getTimestamp()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.hdfs.server.federation.store.protocol.GetMountTableEntriesResponse:setTimestamp(long)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.hdfs.server.federation.store.protocol.GetMountTableEntriesResponse:setTimestamp(long)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.hdfs.server.federation.store.protocol.GetMountTableEntriesRequest:getSrcPath()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.hdfs.server.federation.store.protocol.GetMountTableEntriesRequest:getSrcPath()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.hdfs.server.federation.store.protocol.GetMountTableEntriesRequest:setSrcPath(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.hdfs.server.federation.store.protocol.GetMountTableEntriesRequest:setSrcPath(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.hdfs.server.federation.store.protocol.GetDisabledNameservicesResponse:getNameservices()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.hdfs.server.federation.store.protocol.GetDisabledNameservicesResponse:getNameservices()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.hdfs.server.federation.store.protocol.GetDisabledNameservicesResponse:setNameservices(java.util.Set)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.hdfs.server.federation.store.protocol.GetDisabledNameservicesResponse:setNameservices(java.util.Set)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.hdfs.server.federation.store.protocol.EnableNameserviceRequest:getNameServiceId()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.hdfs.server.federation.store.protocol.EnableNameserviceRequest:getNameServiceId()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.hdfs.server.federation.store.protocol.EnableNameserviceRequest:setNameServiceId(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.hdfs.server.federation.store.protocol.EnableNameserviceRequest:setNameServiceId(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.hdfs.server.federation.store.protocol.GetRouterRegistrationResponse:getRouter()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.hdfs.server.federation.store.protocol.GetRouterRegistrationResponse:getRouter()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.hdfs.server.federation.store.protocol.GetRouterRegistrationResponse:setRouter(org.apache.hadoop.hdfs.server.federation.store.records.RouterState)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.hdfs.server.federation.store.protocol.GetRouterRegistrationResponse:setRouter(org.apache.hadoop.hdfs.server.federation.store.records.RouterState)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.hdfs.server.federation.store.protocol.RefreshSuperUserGroupsConfigurationResponse:getStatus()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.hdfs.server.federation.store.protocol.RefreshSuperUserGroupsConfigurationResponse:getStatus()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.hdfs.server.federation.store.protocol.RefreshSuperUserGroupsConfigurationResponse:setStatus(boolean)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.hdfs.server.federation.store.protocol.RefreshSuperUserGroupsConfigurationResponse:setStatus(boolean)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.hdfs.server.federation.store.protocol.UpdateMountTableEntryRequest:getEntry()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.hdfs.server.federation.store.protocol.UpdateMountTableEntryRequest:getEntry()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.hdfs.server.federation.store.protocol.UpdateMountTableEntryRequest:setEntry(org.apache.hadoop.hdfs.server.federation.store.records.MountTable)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.hdfs.server.federation.store.protocol.UpdateMountTableEntryRequest:setEntry(org.apache.hadoop.hdfs.server.federation.store.records.MountTable)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.hdfs.server.federation.store.protocol.RefreshMountTableEntriesResponse:getResult()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.hdfs.server.federation.store.protocol.RefreshMountTableEntriesResponse:getResult()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.hdfs.server.federation.store.protocol.RefreshMountTableEntriesResponse:setResult(boolean)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.hdfs.server.federation.store.protocol.RefreshMountTableEntriesResponse:setResult(boolean)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.hdfs.server.federation.store.protocol.EnableNameserviceResponse:getStatus()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.hdfs.server.federation.store.protocol.EnableNameserviceResponse:getStatus()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.hdfs.server.federation.store.protocol.EnableNameserviceResponse:setStatus(boolean)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.hdfs.server.federation.store.protocol.EnableNameserviceResponse:setStatus(boolean)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.hdfs.server.federation.store.protocol.UpdateNamenodeRegistrationRequest:getNameserviceId()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.hdfs.server.federation.store.protocol.UpdateNamenodeRegistrationRequest:getNameserviceId()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.hdfs.server.federation.store.protocol.UpdateNamenodeRegistrationRequest:getNamenodeId()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.hdfs.server.federation.store.protocol.UpdateNamenodeRegistrationRequest:getNamenodeId()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.hdfs.server.federation.store.protocol.UpdateNamenodeRegistrationRequest:getState()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.hdfs.server.federation.store.protocol.UpdateNamenodeRegistrationRequest:getState()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.hdfs.server.federation.store.protocol.UpdateNamenodeRegistrationRequest:setNameserviceId(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.hdfs.server.federation.store.protocol.UpdateNamenodeRegistrationRequest:setNameserviceId(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.hdfs.server.federation.store.protocol.UpdateNamenodeRegistrationRequest:setNamenodeId(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.hdfs.server.federation.store.protocol.UpdateNamenodeRegistrationRequest:setNamenodeId(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.hdfs.server.federation.store.protocol.UpdateNamenodeRegistrationRequest:setState(org.apache.hadoop.hdfs.server.federation.resolver.FederationNamenodeServiceState)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.hdfs.server.federation.store.protocol.UpdateNamenodeRegistrationRequest:setState(org.apache.hadoop.hdfs.server.federation.resolver.FederationNamenodeServiceState)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.hdfs.server.federation.store.protocol.AddMountTableEntryResponse:getStatus()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.hdfs.server.federation.store.protocol.AddMountTableEntryResponse:getStatus()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.hdfs.server.federation.store.protocol.AddMountTableEntryResponse:setStatus(boolean)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.hdfs.server.federation.store.protocol.AddMountTableEntryResponse:setStatus(boolean)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.hdfs.server.federation.store.protocol.GetDestinationResponse:getDestinations()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.hdfs.server.federation.store.protocol.GetDestinationResponse:getDestinations()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.hdfs.server.federation.store.protocol.GetDestinationResponse:setDestination(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.hdfs.server.federation.store.protocol.GetDestinationResponse:setDestination(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.hdfs.server.federation.store.protocol.GetDestinationResponse:setDestinations(java.util.Collection)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.hdfs.server.federation.store.protocol.GetDestinationResponse:setDestinations(java.util.Collection)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.hdfs.server.federation.store.protocol.GetDestinationRequest:getSrcPath()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.hdfs.server.federation.store.protocol.GetDestinationRequest:getSrcPath()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.hdfs.server.federation.store.protocol.GetDestinationRequest:setSrcPath(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.hdfs.server.federation.store.protocol.GetDestinationRequest:setSrcPath(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.hdfs.server.federation.store.protocol.DisableNameserviceRequest:getNameServiceId()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.hdfs.server.federation.store.protocol.DisableNameserviceRequest:getNameServiceId()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.hdfs.server.federation.store.protocol.DisableNameserviceRequest:setNameServiceId(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.hdfs.server.federation.store.protocol.DisableNameserviceRequest:setNameServiceId(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.hdfs.server.federation.store.protocol.LeaveSafeModeResponse:getStatus()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.hdfs.server.federation.store.protocol.LeaveSafeModeResponse:getStatus()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.hdfs.server.federation.store.protocol.LeaveSafeModeResponse:setStatus(boolean)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.hdfs.server.federation.store.protocol.LeaveSafeModeResponse:setStatus(boolean)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.hdfs.server.federation.store.protocol.NamenodeHeartbeatResponse:getResult()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.hdfs.server.federation.store.protocol.NamenodeHeartbeatResponse:getResult()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.hdfs.server.federation.store.protocol.NamenodeHeartbeatResponse:setResult(boolean)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.hdfs.server.federation.store.protocol.NamenodeHeartbeatResponse:setResult(boolean)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.hdfs.server.federation.store.protocol.AddMountTableEntryRequest:getEntry()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.hdfs.server.federation.store.protocol.AddMountTableEntryRequest:getEntry()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.hdfs.server.federation.store.protocol.AddMountTableEntryRequest:setEntry(org.apache.hadoop.hdfs.server.federation.store.records.MountTable)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.hdfs.server.federation.store.protocol.AddMountTableEntryRequest:setEntry(org.apache.hadoop.hdfs.server.federation.store.records.MountTable)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.hdfs.server.federation.store.protocol.UpdateMountTableEntryResponse:getStatus()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.hdfs.server.federation.store.protocol.UpdateMountTableEntryResponse:getStatus()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.hdfs.server.federation.store.protocol.UpdateMountTableEntryResponse:setStatus(boolean)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.hdfs.server.federation.store.protocol.UpdateMountTableEntryResponse:setStatus(boolean)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.hdfs.server.federation.store.protocol.RemoveMountTableEntryResponse:getStatus()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.hdfs.server.federation.store.protocol.RemoveMountTableEntryResponse:getStatus()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.hdfs.server.federation.store.protocol.RemoveMountTableEntryResponse:setStatus(boolean)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.hdfs.server.federation.store.protocol.RemoveMountTableEntryResponse:setStatus(boolean)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.hdfs.server.federation.store.protocol.GetRouterRegistrationRequest:getRouterId()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.hdfs.server.federation.store.protocol.GetRouterRegistrationRequest:getRouterId()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.hdfs.server.federation.store.protocol.GetRouterRegistrationRequest:setRouterId(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.hdfs.server.federation.store.protocol.GetRouterRegistrationRequest:setRouterId(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.hdfs.server.federation.store.protocol.GetNamespaceInfoResponse:getNamespaceInfo()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.hdfs.server.federation.store.protocol.GetNamespaceInfoResponse:getNamespaceInfo()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.hdfs.server.federation.store.protocol.GetNamespaceInfoResponse:setNamespaceInfo(java.util.Set)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.hdfs.server.federation.store.protocol.GetNamespaceInfoResponse:setNamespaceInfo(java.util.Set)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.hdfs.server.federation.store.protocol.RouterHeartbeatRequest:getRouter()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.hdfs.server.federation.store.protocol.RouterHeartbeatRequest:getRouter()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.hdfs.server.federation.store.protocol.RouterHeartbeatRequest:setRouter(org.apache.hadoop.hdfs.server.federation.store.records.RouterState)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.hdfs.server.federation.store.protocol.RouterHeartbeatRequest:setRouter(org.apache.hadoop.hdfs.server.federation.store.records.RouterState)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.hdfs.server.federation.store.protocol.RemoveMountTableEntryRequest:getSrcPath()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.hdfs.server.federation.store.protocol.RemoveMountTableEntryRequest:getSrcPath()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.hdfs.server.federation.store.protocol.RemoveMountTableEntryRequest:setSrcPath(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.hdfs.server.federation.store.protocol.RemoveMountTableEntryRequest:setSrcPath(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.hdfs.server.federation.store.protocol.EnterSafeModeResponse:getStatus()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.hdfs.server.federation.store.protocol.EnterSafeModeResponse:getStatus()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.hdfs.server.federation.store.protocol.EnterSafeModeResponse:setStatus(boolean)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.hdfs.server.federation.store.protocol.EnterSafeModeResponse:setStatus(boolean)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.hdfs.server.federation.store.protocol.NamenodeHeartbeatRequest:getNamenodeMembership()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.hdfs.server.federation.store.protocol.NamenodeHeartbeatRequest:getNamenodeMembership()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.hdfs.server.federation.store.protocol.NamenodeHeartbeatRequest:setNamenodeMembership(org.apache.hadoop.hdfs.server.federation.store.records.MembershipState)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.hdfs.server.federation.store.protocol.NamenodeHeartbeatRequest:setNamenodeMembership(org.apache.hadoop.hdfs.server.federation.store.records.MembershipState)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.hdfs.server.federation.store.protocol.GetNamenodeRegistrationsResponse:getNamenodeMemberships()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.hdfs.server.federation.store.protocol.GetNamenodeRegistrationsResponse:getNamenodeMemberships()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.hdfs.server.federation.store.protocol.GetNamenodeRegistrationsResponse:setNamenodeMemberships(java.util.List)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.hdfs.server.federation.store.protocol.GetNamenodeRegistrationsResponse:setNamenodeMemberships(java.util.List)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.hdfs.server.federation.store.protocol.RouterHeartbeatResponse:getStatus()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.hdfs.server.federation.store.protocol.RouterHeartbeatResponse:getStatus()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.hdfs.server.federation.store.protocol.RouterHeartbeatResponse:setStatus(boolean)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.hdfs.server.federation.store.protocol.RouterHeartbeatResponse:setStatus(boolean)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.hdfs.server.federation.store.protocol.GetNamenodeRegistrationsRequest:getPartialMembership()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.hdfs.server.federation.store.protocol.GetNamenodeRegistrationsRequest:getPartialMembership()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.hdfs.server.federation.store.protocol.GetNamenodeRegistrationsRequest:setPartialMembership(org.apache.hadoop.hdfs.server.federation.store.records.MembershipState)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.hdfs.server.federation.store.protocol.GetNamenodeRegistrationsRequest:setPartialMembership(org.apache.hadoop.hdfs.server.federation.store.records.MembershipState)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.hdfs.server.federation.store.protocol.UpdateNamenodeRegistrationResponse:getResult()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.hdfs.server.federation.store.protocol.UpdateNamenodeRegistrationResponse:getResult()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.hdfs.server.federation.store.protocol.UpdateNamenodeRegistrationResponse:setResult(boolean)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.hdfs.server.federation.store.protocol.UpdateNamenodeRegistrationResponse:setResult(boolean)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.hdfs.qjournal.server.JournalNodeRpcServer:getRpcServer()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.qjournal.server.JournalNodeSyncer:getJournalAddrList(java.lang.String)	org.apache.hadoop.classification.VisibleForTesting
org.apache.hadoop.hdfs.qjournal.server.JournalNode:getJournalSyncer(java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.qjournal.server.JournalNode:getJournalSyncerStatus(java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.qjournal.server.JournalNode:getOrCreateJournal(java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.qjournal.server.JournalNode:getJournal(java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.qjournal.server.JournalNode:getRpcServer()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.qjournal.server.Journal:getSegmentInfo(long)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.qjournal.server.Journal:getJournaledEditsCache()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.qjournal.server.JournaledEditsCache:getRawDataForTests(long)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.qjournal.server.JournalMetrics:getLastWriterEpoch()	org.apache.hadoop.metrics2.annotation.Metric	value	{Current writer's epoch}
org.apache.hadoop.hdfs.qjournal.server.JournalMetrics:getLastPromisedEpoch()	org.apache.hadoop.metrics2.annotation.Metric	value	{Last accepted epoch}
org.apache.hadoop.hdfs.qjournal.server.JournalMetrics:getLastWrittenTxId()	org.apache.hadoop.metrics2.annotation.Metric	value	{The highest txid stored on this JN}
org.apache.hadoop.hdfs.qjournal.server.JournalMetrics:getCurrentLagTxns()	org.apache.hadoop.metrics2.annotation.Metric	value	{Number of transactions that this JN is lagging}
org.apache.hadoop.hdfs.qjournal.server.JournalMetrics:getLastJournalTimestamp()	org.apache.hadoop.metrics2.annotation.Metric	value	{The timestamp of last successfully written transaction}
org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocol:discardSegments(java.lang.String,java.lang.String,long)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager:<init>(org.apache.hadoop.conf.Configuration,java.net.URI,org.apache.hadoop.hdfs.server.protocol.NamespaceInfo)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager:<init>(org.apache.hadoop.conf.Configuration,java.net.URI,org.apache.hadoop.hdfs.server.protocol.NamespaceInfo,org.apache.hadoop.hdfs.qjournal.client.AsyncLogger$Factory)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager:getLoggerSetForTests()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.qjournal.client.IPCLoggerChannelMetrics:isOutOfSync()	org.apache.hadoop.metrics2.annotation.Metric	value	{Is the remote logger out of sync with the quorum}
org.apache.hadoop.hdfs.qjournal.client.IPCLoggerChannelMetrics:getCurrentLagTxns()	org.apache.hadoop.metrics2.annotation.Metric	value	{The number of transactions the remote log is lagging behind the quorum}
org.apache.hadoop.hdfs.qjournal.client.IPCLoggerChannelMetrics:getLagTimeMillis()	org.apache.hadoop.metrics2.annotation.Metric	value	{The number of milliseconds the remote log is lagging behind the quorum}
org.apache.hadoop.hdfs.qjournal.client.IPCLoggerChannelMetrics:getQueuedEditsSize()	org.apache.hadoop.metrics2.annotation.Metric	value	{The number of bytes of pending data to be sent to the remote node}
org.apache.hadoop.hdfs.qjournal.client.IPCLoggerChannel:createSingleThreadExecutor()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.qjournal.client.IPCLoggerChannel:createParallelExecutor()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.qjournal.client.IPCLoggerChannel:getNextIpcSerial()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.qjournal.client.IPCLoggerChannel:waitForAllPendingCalls()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.qjournal.client.AsyncLoggerSet:getLoggersForTests()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.tools.DFSZKFailoverController:isThreadDumpCaptured()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.tools.offlineImageViewer.WebImageViewer:initServer(java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.tools.offlineImageViewer.WebImageViewer:getPort()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.tools.DelegationTokenFetcher:main(org.apache.hadoop.conf.Configuration,java.lang.String[])	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.tools.DelegationTokenFetcher:cancelTokens(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.tools.DelegationTokenFetcher:renewTokens(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.tools.DelegationTokenFetcher:saveDelegationToken(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.FileSystem,java.lang.String,org.apache.hadoop.fs.Path)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.tools.DelegationTokenFetcher:printTokensToString(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path,boolean)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.web.resources.ExceptionHandler:initResponse(javax.servlet.http.HttpServletResponse)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.diskbalancer.command.Command:getCluster()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.diskbalancer.command.Command:setCluster(org.apache.hadoop.hdfs.server.diskbalancer.datamodel.DiskBalancerCluster)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.diskbalancer.datamodel.DiskBalancerVolumeSet:isTransient()	com.fasterxml.jackson.annotation.JsonProperty	value	transient
org.apache.hadoop.hdfs.server.diskbalancer.datamodel.DiskBalancerVolumeSet:setTransient(boolean)	com.fasterxml.jackson.annotation.JsonProperty	value	transient
org.apache.hadoop.hdfs.server.diskbalancer.datamodel.DiskBalancerVolumeSet:getVolumeCount()	com.fasterxml.jackson.annotation.JsonIgnore
org.apache.hadoop.hdfs.server.diskbalancer.datamodel.DiskBalancerVolumeSet:getSortedQueue()	com.fasterxml.jackson.annotation.JsonIgnore
org.apache.hadoop.hdfs.server.diskbalancer.datamodel.DiskBalancerVolumeSet:getIdealUsed()	com.fasterxml.jackson.annotation.JsonIgnore
org.apache.hadoop.hdfs.server.diskbalancer.datamodel.DiskBalancerVolume:getFreeSpace()	com.fasterxml.jackson.annotation.JsonIgnore
org.apache.hadoop.hdfs.server.diskbalancer.datamodel.DiskBalancerVolume:getUsedRatio()	com.fasterxml.jackson.annotation.JsonIgnore
org.apache.hadoop.hdfs.server.diskbalancer.datamodel.DiskBalancerVolume:getFreeRatio()	com.fasterxml.jackson.annotation.JsonIgnore
org.apache.hadoop.hdfs.server.diskbalancer.datamodel.DiskBalancerVolume:computeEffectiveCapacity()	com.fasterxml.jackson.annotation.JsonIgnore
org.apache.hadoop.hdfs.server.diskbalancer.datamodel.DiskBalancerCluster:getNodesToProcess()	com.fasterxml.jackson.annotation.JsonIgnore
org.apache.hadoop.hdfs.server.diskbalancer.datamodel.DiskBalancerCluster:setNodesToProcess(java.util.List)	com.fasterxml.jackson.annotation.JsonIgnore
org.apache.hadoop.hdfs.server.common.blockaliasmap.impl.TextFileRegionAliasMap:createReader(org.apache.hadoop.fs.Path,java.lang.String,org.apache.hadoop.conf.Configuration,java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.common.blockaliasmap.impl.TextFileRegionAliasMap:createWriter(org.apache.hadoop.fs.Path,org.apache.hadoop.io.compress.CompressionCodec,java.lang.String,org.apache.hadoop.conf.Configuration)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.common.blockaliasmap.impl.TextFileRegionAliasMap:blockPoolIDFromFileName(org.apache.hadoop.fs.Path)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.common.blockaliasmap.impl.TextFileRegionAliasMap:fileNameFromBlockPoolID(java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.mover.Mover$Cli:getNameNodePathsToMove(org.apache.hadoop.conf.Configuration,java.lang.String[])	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.mover.Mover$Processor:scheduleMoveReplica(org.apache.hadoop.hdfs.server.balancer.Dispatcher$DBlock,org.apache.hadoop.hdfs.server.mover.Mover$MLocation,java.util.List)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.blockmanagement.InvalidateBlocks:getInvalidationDelay()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo:setBlockContentsStale(boolean)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo:setUtilizationForTesting(long,long,long,long)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo:getStorageID()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo:getBlockListHeadForTesting()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo:setRemainingForTests(int)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerFaultInjector:getInstance()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerFaultInjector:incomingBlockReportRpc(org.apache.hadoop.hdfs.protocol.DatanodeID,org.apache.hadoop.hdfs.server.protocol.BlockReportContext)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerFaultInjector:requestBlockReportLease(org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor,long)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerFaultInjector:removeBlockReportLease(org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor,long)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.blockmanagement.SlowPeerTracker:getReportValidityMs()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.blockmanagement.PendingReconstructionBlocks:getTimerThread()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.blockmanagement.DatanodeAdminManager:startDecommission(org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.blockmanagement.DatanodeAdminManager:stopDecommission(org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.blockmanagement.DatanodeAdminManager:startMaintenance(org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor,long)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.blockmanagement.DatanodeAdminManager:stopMaintenance(org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.blockmanagement.DatanodeAdminManager:getNumPendingNodes()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.blockmanagement.DatanodeAdminManager:getNumTrackedNodes()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.blockmanagement.DatanodeAdminManager:getNumNodesChecked()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.blockmanagement.DatanodeAdminManager:getPendingNodes()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.blockmanagement.DatanodeAdminManager:runMonitorForTest()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.blockmanagement.DatanodeAdminManager:getPendingRepLimit()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.blockmanagement.DatanodeAdminManager:getBlocksPerLock()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.blockmanagement.ProvidedStorageMap:getProvidedStorageInfo()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.blockmanagement.ProvidedStorageMap:getAliasMap()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.blockmanagement.CombinedHostFileManager:parseEntry(java.lang.String,java.lang.String,int)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.blockmanagement.CombinedHostFileManager:refresh(org.apache.hadoop.hdfs.server.blockmanagement.CombinedHostFileManager$HostProperties)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor:isHeartbeatedSinceRegistration()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor:getStorageInfo(java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor:getStorageInfos()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor:incrementPendingReplicationWithoutTargets()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor:decrementPendingReplicationWithoutTargets()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor:addBlockToBeReplicated(org.apache.hadoop.hdfs.protocol.Block,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo[])	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor:getNumberOfBlocksToBeErasureCoded()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor:getNumberOfReplicateBlocks()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor:containsInvalidateBlock(org.apache.hadoop.hdfs.protocol.Block)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.blockmanagement.BlockStoragePolicySuite:createDefaultSuite()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.blockmanagement.DatanodeAdminBackoffMonitor:getPendingRepLimit()	org.apache.hadoop.classification.VisibleForTesting
org.apache.hadoop.hdfs.server.blockmanagement.DatanodeAdminBackoffMonitor:getBlocksPerLock()	org.apache.hadoop.classification.VisibleForTesting
org.apache.hadoop.hdfs.server.blockmanagement.ExcessRedundancyMap:getSize4Testing(java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:getBlockTokenSecretManager()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:enableRMTerminationForTesting()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:getBlockPlacementPolicy()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:getStriptedBlockPlacementPolicy()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:setMaxReplicationStreams(int,boolean)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:postponeBlock(org.apache.hadoop.hdfs.protocol.Block)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:computeReconstructionWorkForBlocks(java.util.List)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:scheduleReconstruction(org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo,int)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:chooseSourceDatanodes(org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo,java.util.List,java.util.List,org.apache.hadoop.hdfs.server.blockmanagement.NumberReplicas,java.util.List,java.util.List,java.util.List,int)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:addBlock(org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo,org.apache.hadoop.hdfs.protocol.Block,java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:getExcessSize4Testing(java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:containsInvalidateBlock(org.apache.hadoop.hdfs.protocol.DatanodeInfo,org.apache.hadoop.hdfs.protocol.Block)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:getLastRedundancyMonitorTS()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:flushBlockOps()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:getRedundancyThread()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:getMarkedDeleteQueue()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:setBlockRecoveryTimeout(long)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:getProvidedStorageMap()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:getExcludeSlowNodesEnabled(org.apache.hadoop.hdfs.protocol.BlockType)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault:chooseReplicaToDelete(java.util.Collection,java.util.Collection,java.util.List,java.util.Map)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault:useDelHint(org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo,org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo,java.util.List,java.util.Collection,java.util.List)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault:setPreferLocalNode(boolean)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.blockmanagement.PendingRecoveryBlocks:setRecoveryTimeoutInterval(long)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.blockmanagement.HostFileManager:parseEntry(java.lang.String,java.lang.String,java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.blockmanagement.HostFileManager:refresh(org.apache.hadoop.hdfs.server.blockmanagement.HostSet,org.apache.hadoop.hdfs.server.blockmanagement.HostSet)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.blockmanagement.DatanodeAdminDefaultMonitor:getPendingRepLimit()	org.apache.hadoop.classification.VisibleForTesting
org.apache.hadoop.hdfs.server.blockmanagement.DatanodeAdminDefaultMonitor:getBlocksPerLock()	org.apache.hadoop.classification.VisibleForTesting
org.apache.hadoop.hdfs.server.blockmanagement.HeartbeatManager:restartHeartbeatStopWatch()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.blockmanagement.HeartbeatManager:shouldAbortHeartbeatCheck(long)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.blockmanagement.HeartbeatManager:heartbeatCheck()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.blockmanagement.BlockInfoStriped:getStorageBlockIndex(org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.blockmanagement.SlowDiskTracker:getSlowDiskIDForReport(java.lang.String,java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.blockmanagement.SlowDiskTracker:updateSlowDiskReportAsync(long)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.blockmanagement.SlowDiskTracker:getSlowDisksReport()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.blockmanagement.SlowDiskTracker:getReportValidityMs()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.blockmanagement.SlowDiskTracker:setReportValidityMs(long)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager:getDatanodeAdminManager()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager:setHeartbeatExpireInterval(long)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager:getFSClusterStats()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager:getBlockInvalidateLimit()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager:getEnableAvoidSlowDataNodesForRead()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager:getMaxSlowpeerCollectNodes()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager:checkIfClusterIsNowMultiRack(org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager:getSlowPeerTracker()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager:getSlowDiskTracker()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager:addSlowPeers(java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.blockmanagement.StorageTypeStats:setDataNodesInServiceXceiverCount(int,int)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.blockmanagement.StorageTypeStats:<init>(long,long,long,long,long,int)	java.beans.ConstructorProperties	value	{capacityTotal,capacityUsed,capacityNonDfsUsed,capacityRemaining,blockPoolUsed,nodesInService}
org.apache.hadoop.hdfs.server.blockmanagement.CorruptReplicasMap:getCorruptBlockIdsForTesting(org.apache.hadoop.hdfs.server.blockmanagement.BlockIdManager,org.apache.hadoop.hdfs.protocol.BlockType,int,java.lang.Long)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.blockmanagement.BlockIdManager:getBlockIdGenerator()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.blockmanagement.BlockIdManager:getImpendingGenerationStamp()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.blockmanagement.BlockIdManager:getNextLegacyGenerationStamp()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.blockmanagement.BlockIdManager:getNextGenerationStamp()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.metrics.DataNodePeerMetrics:getSlowNodeDetector()	org.apache.hadoop.classification.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.metrics.DataNodeDiskMetrics:addSlowDiskForTesting(java.lang.String,java.util.Map)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.metrics.DataNodeDiskMetrics:getSlowDiskDetector()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.LocalReplica:getBlockFile()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.LocalReplica:getMetaFile()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.LocalReplica:parseBaseDir(java.io.File,long)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.BlockRecoveryWorker$RecoveryTaskStriped:getSafeLength(java.util.Map)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.ProvidedReplica:getPathSuffix()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.ProvidedReplica:getPathPrefix()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.ProvidedReplica:setPathHandle(org.apache.hadoop.fs.PathHandle)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.SecureDataNodeStarter:getSecureResources(org.apache.hadoop.conf.Configuration)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.ProfilingFileIoEvents:getDiskStatsEnabled()	org.apache.hadoop.classification.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.ProfilingFileIoEvents:getSampleRangeMax()	org.apache.hadoop.classification.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.DataStorage:addStorageLocations(org.apache.hadoop.hdfs.server.datanode.DataNode,org.apache.hadoop.hdfs.server.protocol.NamespaceInfo,java.util.Collection,org.apache.hadoop.hdfs.server.common.HdfsServerConstants$StartupOption)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.DataStorage:fullyDelete(java.io.File)	java.lang.Deprecated
org.apache.hadoop.hdfs.server.datanode.DataNode:createSocketAddr(java.lang.String)	java.lang.Deprecated
org.apache.hadoop.hdfs.server.datanode.DataNode:<init>(org.apache.hadoop.conf.Configuration)	org.apache.hadoop.classification.InterfaceAudience$LimitedPrivate	value	{HDFS}
org.apache.hadoop.hdfs.server.datanode.DataNode:<init>(org.apache.hadoop.conf.Configuration)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.DataNode:parseChangedVolumes(java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.DataNode:setHeartbeatsDisabledForTests(boolean)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.DataNode:areHeartbeatsDisabledForTests()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.DataNode:setIBRDisabledForTest(boolean)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.DataNode:areIBRDisabledForTests()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.DataNode:areCacheReportsDisabledForTests()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.DataNode:getXferServer()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.DataNode:getXferPort()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.DataNode:getSaslServer()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.DataNode:getDNRegistrationForBP(java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.DataNode:transferBlock(org.apache.hadoop.hdfs.protocol.ExtendedBlock,org.apache.hadoop.hdfs.protocol.DatanodeInfo[],org.apache.hadoop.fs.StorageType[],java.lang.String[])	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.DataNode:createDataNode(java.lang.String[],org.apache.hadoop.conf.Configuration)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.DataNode:createDataNode(java.lang.String[],org.apache.hadoop.conf.Configuration,org.apache.hadoop.hdfs.server.datanode.SecureDataNodeStarter$SecureResources)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.hdfs.server.datanode.DataNode:createDataNode(java.lang.String[],org.apache.hadoop.conf.Configuration,org.apache.hadoop.hdfs.server.datanode.SecureDataNodeStarter$SecureResources)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.DataNode:parseArguments(java.lang.String[],org.apache.hadoop.conf.Configuration)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.DataNode:getFSDataset()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.DataNode:getBlockScanner()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.DataNode:getDirectoryScanner()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.DataNode:getBlockPoolTokenSecretManager()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.DataNode:getBPServiceActorInfoMap()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.DataNode:getDatanodeId()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.DataNode:clearAllBlockSecretKeys()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.DataNode:getStorage()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.DataNode:checkDiskError()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.DataNode:getLastDiskErrorCheck()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.DataNode:getMetricsLoggerTimer()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.DataNode:setBlockScanner(org.apache.hadoop.hdfs.server.datanode.BlockScanner)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.DataNode:getBlockPoolManager()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.DataXceiverServer:getNumPeersXceiver()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.DataXceiverServer:getPeerServer()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.DataXceiverServer:setMaxReconfigureWaitTime(int)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.DataXceiverServer:getMaxXceiverCount()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.ShortCircuitRegistry:visit(org.apache.hadoop.hdfs.server.datanode.ShortCircuitRegistry$Visitor)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.ShortCircuitRegistry:getShmNum()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.web.webhdfs.DataNodeUGIProvider:clearCache()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage:isTrashAllowed(java.io.File)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage:getRestoreDirectory(java.io.File)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage:trashEnabled()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.DirectoryScanner:setRetainDiffs(boolean)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.DirectoryScanner:getRunStatus()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.DirectoryScanner:reconcile()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.DirectoryScanner:getVolumeReports()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.DataXceiver:getBlockReceiver(org.apache.hadoop.hdfs.protocol.ExtendedBlock,org.apache.hadoop.fs.StorageType,java.io.DataInputStream,java.lang.String,java.lang.String,org.apache.hadoop.hdfs.protocol.datatransfer.BlockConstructionStage,long,long,long,java.lang.String,org.apache.hadoop.hdfs.protocol.DatanodeInfo,org.apache.hadoop.hdfs.server.datanode.DataNode,org.apache.hadoop.util.DataChecksum,org.apache.hadoop.hdfs.server.datanode.CachingStrategy,boolean,boolean,java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.DataXceiver:getBufferedOutputStream()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.VolumeScanner:setConf(org.apache.hadoop.hdfs.server.datanode.BlockScanner$Conf)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.VolumeScanner:calculateShouldScan(java.lang.String,long,long,long,long)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.VolumeScanner:getStatistics()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.BlockScanner:setConf(org.apache.hadoop.hdfs.server.datanode.BlockScanner$Conf)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.BlockScanner:getVolumeStats(java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.checker.AbstractFuture:setFuture(org.apache.hadoop.thirdparty.com.google.common.util.concurrent.ListenableFuture)	org.apache.hadoop.thirdparty.com.google.common.annotations.Beta
org.apache.hadoop.hdfs.server.datanode.checker.AbstractFuture:afterDone()	org.apache.hadoop.thirdparty.com.google.common.annotations.Beta
org.apache.hadoop.hdfs.server.datanode.checker.DatasetVolumeChecker:setDelegateChecker(org.apache.hadoop.hdfs.server.datanode.checker.AsyncChecker)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.DataStorage$VolumeBuilder:<init>(org.apache.hadoop.hdfs.server.datanode.DataStorage,org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.fsdataset.FsDatasetSpi:getReplica(java.lang.String,long)	java.lang.Deprecated
org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsVolumeImplBuilder:setUsage(org.apache.hadoop.fs.DF)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.PmemVolumeManager:reset()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.PmemVolumeManager:setMaxBytes(long)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.PmemVolumeManager:verifyIfValidPmemVolume(java.io.File)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.PmemVolumeManager:getVolumeByIndex(java.lang.Byte)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.PmemVolumeManager:getBlockKeyToVolume()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl:createFsVolume(java.lang.String,org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory,org.apache.hadoop.hdfs.server.datanode.StorageLocation)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl:getReplicaInfo(java.lang.String,long)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl:moveBlock(org.apache.hadoop.hdfs.protocol.ExtendedBlock,org.apache.hadoop.hdfs.server.datanode.ReplicaInfo,org.apache.hadoop.hdfs.server.datanode.fsdataset.FsVolumeReference)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl:copyReplicaToVolume(org.apache.hadoop.hdfs.protocol.ExtendedBlock,org.apache.hadoop.hdfs.server.datanode.ReplicaInfo,org.apache.hadoop.hdfs.server.datanode.fsdataset.FsVolumeReference)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl:finalizeNewReplica(org.apache.hadoop.hdfs.server.datanode.ReplicaInfo,org.apache.hadoop.hdfs.protocol.ExtendedBlock)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl:getReplica(java.lang.String,long)	java.lang.Deprecated
org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl:setBlockPoolId(java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl:evictLazyPersistBlocks(long)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl:getNonPersistentReplicas()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl:setTimer(org.apache.hadoop.util.Timer)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl:getReplica(java.lang.String,long)	java.lang.Deprecated
org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.ProvidedVolumeImpl$ProvidedBlockPoolSlice:setFileRegionProvider(org.apache.hadoop.hdfs.server.common.blockaliasmap.BlockAliasMap)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.ProvidedVolumeImpl:getSuffix(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.ProvidedVolumeImpl:getBlockFormat(java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.ProvidedVolumeImpl:containsBlock(java.net.URI,java.net.URI)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.ProvidedVolumeImpl:getFileRegionProvider(java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.ProvidedVolumeImpl:setFileRegionProvider(java.lang.String,org.apache.hadoop.hdfs.server.common.blockaliasmap.BlockAliasMap)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsVolumeImpl:getReferenceCount()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsVolumeImpl:getCurrentDir()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsVolumeImpl:getDfsUsed()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsVolumeImpl:getCapacity()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsVolumeImpl:setCapacityForTesting(long)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsVolumeImpl:getDfAvailable()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsVolumeImpl:getReservedForReplicas()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsVolumeImpl:getRecentReserved()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsVolumeImpl:getBlockPoolSlice(java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsVolumeImpl:getFinalizedDir(java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsVolumeImpl:nextSorted(java.util.List,java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice:getDfsUsage()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice:selectReplicaToDelete(org.apache.hadoop.hdfs.server.datanode.ReplicaInfo,org.apache.hadoop.hdfs.server.datanode.ReplicaInfo)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice:getAddReplicaForkPoolSize()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice:getAddReplicaThreadPool()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice:reInitializeAddReplicaThreadPool()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.BPServiceActor:setNameNode(org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.BPServiceActor:getNameNodeProxy()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.BPServiceActor:setLifelineNameNode(org.apache.hadoop.hdfs.protocolPB.DatanodeLifelineProtocolClientSideTranslatorPB)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.BPServiceActor:getLifelineNameNodeProxy()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.BPServiceActor:retrieveNamespaceInfo()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.BPServiceActor:triggerBlockReportForTests()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.BPServiceActor:triggerHeartbeatForTests()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.BPServiceActor:sendLifelineForTests()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.BPServiceActor:stopCommandProcessingThread()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.BPServiceActor$Scheduler:getNextBlockReportTime()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.BPServiceActor$Scheduler:setNextBlockReportTime(long)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.BPServiceActor$Scheduler:getOutliersReportIntervalMs()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.BPServiceActor$Scheduler:monotonicNow()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.erasurecode.StripedReconstructor:getBufferPool()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.DiskBalancer$DiskBalancerMover:computeDelay(long,long,org.apache.hadoop.hdfs.server.datanode.DiskBalancerWorkItem)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.BPOfferService:setNamespaceInfo(org.apache.hadoop.hdfs.server.protocol.NamespaceInfo)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.BPOfferService:getBPServiceActors()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.BPOfferService:countNameNodes()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.BPOfferService:triggerBlockReportForTests()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.BPOfferService:triggerDeletionReportForTests()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.BPOfferService:triggerHeartbeatForTests()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.DataXceiverServer$BlockBalanceThrottler:getMaxConcurrentMovers()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.IncrementalBlockReportManager:addRDBI(org.apache.hadoop.hdfs.server.protocol.ReceivedDeletedBlockInfo,org.apache.hadoop.hdfs.server.protocol.DatanodeStorage)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.IncrementalBlockReportManager:triggerDeletionReportForTests()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.datanode.IncrementalBlockReportManager:getPendingIBRSize()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.CacheManager:getCachedBlocks()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.CacheManager:setCachedLocations(org.apache.hadoop.hdfs.protocol.LocatedBlock)	edu.umd.cs.findbugs.annotations.SuppressFBWarnings	value	{EC_UNRELATED_TYPES}
org.apache.hadoop.hdfs.server.namenode.CacheManager:setCachedLocations(org.apache.hadoop.hdfs.protocol.LocatedBlock)	edu.umd.cs.findbugs.annotations.SuppressFBWarnings	justification	HDFS-15255 Asked Wei-Chiu and Pifta to review this warning and we all agree the code is OK and the warning is not needed
org.apache.hadoop.hdfs.server.namenode.CacheManager:getCacheReplicationMonitor()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.metrics.NameNodeMetrics:totalFileOps()	org.apache.hadoop.metrics2.annotation.Metric	value	{Number of file system operations}
org.apache.hadoop.hdfs.server.namenode.metrics.FSNamesystemMBean:getPendingReplicationBlocks()	java.lang.Deprecated
org.apache.hadoop.hdfs.server.namenode.metrics.FSNamesystemMBean:getUnderReplicatedBlocks()	java.lang.Deprecated
org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader:<init>(org.apache.hadoop.hdfs.server.namenode.FSNamesystem,long,org.apache.hadoop.util.Timer)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.NamenodeFsck:check(java.lang.String,org.apache.hadoop.hdfs.protocol.HdfsFileStatus,org.apache.hadoop.hdfs.server.namenode.NamenodeFsck$Result,org.apache.hadoop.hdfs.server.namenode.NamenodeFsck$Result)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.LeaseManager:getINodeWithLeases()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.LeaseManager:countLease()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.LeaseManager:checkLeases()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.LeaseManager:triggerMonitorCheckNow()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.LeaseManager:runLeaseChecks()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.FsImageProto$SnapshotDiffSection$DiffEntry$Type:valueOf(int)	java.lang.Deprecated
org.apache.hadoop.hdfs.server.namenode.ReencryptionUpdater:pauseForTesting()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.ReencryptionUpdater:resumeForTesting()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.ReencryptionUpdater:pauseForTestingAfterNthCheckpoint(long,int)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.ReencryptionUpdater:isRunning()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.FSDirXAttrOp:filterINodeXAttrs(java.util.List,java.util.List,java.util.List)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.EncryptionZoneManager:pauseReencryptForTesting()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.EncryptionZoneManager:resumeReencryptForTesting()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.EncryptionZoneManager:pauseForTestingAfterNthSubmission(int)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.EncryptionZoneManager:pauseReencryptUpdaterForTesting()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.EncryptionZoneManager:resumeReencryptUpdaterForTesting()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.EncryptionZoneManager:pauseForTestingAfterNthCheckpoint(java.lang.String,int)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.EncryptionZoneManager:resetMetricsForTesting()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.EncryptionZoneManager:getReencryptionStatus()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.EncryptionZoneManager:getZoneStatus(java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.INodeDirectory:dumpTreeRecursively(java.io.PrintWriter,java.lang.StringBuilder,int)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.INodeDirectory:dumpTreeRecursively(java.io.PrintWriter,java.lang.StringBuilder,java.lang.Iterable)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.snapshot.DirectorySnapshottableFeature:dumpTreeRecursively(org.apache.hadoop.hdfs.server.namenode.INodeDirectory,java.io.PrintWriter,java.lang.StringBuilder,int)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager:setCaptureOpenFiles(boolean)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.NameNodeUtils:getClientNamenodeAddress(org.apache.hadoop.conf.Configuration,java.lang.String)	javax.annotation.Nullable
org.apache.hadoop.hdfs.server.namenode.NameNodeUtils:getClientNamenodeAddress(org.apache.hadoop.conf.Configuration,java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.INodeAttributeProvider:getPathElements(java.lang.String)	java.lang.Deprecated
org.apache.hadoop.hdfs.server.namenode.INodeAttributeProvider:getAttributes(java.lang.String,org.apache.hadoop.hdfs.server.namenode.INodeAttributes)	java.lang.Deprecated
org.apache.hadoop.hdfs.server.namenode.NameNode:getHttpServer()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.NameNode:getAliasMapServer()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.NameNode:getFSImage()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.NameNode:getNNAuxiliaryRpcAddress()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.NameNode:joinHttpServer()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.NameNode:initializeSharedEdits(org.apache.hadoop.conf.Configuration)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.NameNode:initializeSharedEdits(org.apache.hadoop.conf.Configuration,boolean)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.NameNode:doRollback(org.apache.hadoop.conf.Configuration,boolean)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.NameNode:parseArguments(java.lang.String[])	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.JournalSet$JournalAndStream:setJournalForTests(org.apache.hadoop.hdfs.server.namenode.JournalManager)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.ErasureCodingPolicyManager:getRemovedPolicies()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods:chooseDatanode(org.apache.hadoop.hdfs.server.namenode.NameNode,java.lang.String,org.apache.hadoop.hdfs.web.resources.HttpOpParam$Op,long,long,java.lang.String,java.lang.String,org.apache.hadoop.hdfs.protocol.HdfsFileStatus)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods:putRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.PutOpParam,org.apache.hadoop.hdfs.web.resources.DestinationParam,org.apache.hadoop.hdfs.web.resources.OwnerParam,org.apache.hadoop.hdfs.web.resources.GroupParam,org.apache.hadoop.hdfs.web.resources.PermissionParam,org.apache.hadoop.hdfs.web.resources.UnmaskedPermissionParam,org.apache.hadoop.hdfs.web.resources.OverwriteParam,org.apache.hadoop.hdfs.web.resources.BufferSizeParam,org.apache.hadoop.hdfs.web.resources.ReplicationParam,org.apache.hadoop.hdfs.web.resources.BlockSizeParam,org.apache.hadoop.hdfs.web.resources.ModificationTimeParam,org.apache.hadoop.hdfs.web.resources.AccessTimeParam,org.apache.hadoop.hdfs.web.resources.RenameOptionSetParam,org.apache.hadoop.hdfs.web.resources.CreateParentParam,org.apache.hadoop.hdfs.web.resources.TokenArgumentParam,org.apache.hadoop.hdfs.web.resources.AclPermissionParam,org.apache.hadoop.hdfs.web.resources.XAttrNameParam,org.apache.hadoop.hdfs.web.resources.XAttrValueParam,org.apache.hadoop.hdfs.web.resources.XAttrSetFlagParam,org.apache.hadoop.hdfs.web.resources.SnapshotNameParam,org.apache.hadoop.hdfs.web.resources.OldSnapshotNameParam,org.apache.hadoop.hdfs.web.resources.ExcludeDatanodesParam,org.apache.hadoop.hdfs.web.resources.CreateFlagParam,org.apache.hadoop.hdfs.web.resources.NoRedirectParam,org.apache.hadoop.hdfs.web.resources.StoragePolicyParam,org.apache.hadoop.hdfs.web.resources.ECPolicyParam,org.apache.hadoop.hdfs.web.resources.NameSpaceQuotaParam,org.apache.hadoop.hdfs.web.resources.StorageSpaceQuotaParam,org.apache.hadoop.hdfs.web.resources.StorageTypeParam)	javax.ws.rs.PUT
org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods:putRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.PutOpParam,org.apache.hadoop.hdfs.web.resources.DestinationParam,org.apache.hadoop.hdfs.web.resources.OwnerParam,org.apache.hadoop.hdfs.web.resources.GroupParam,org.apache.hadoop.hdfs.web.resources.PermissionParam,org.apache.hadoop.hdfs.web.resources.UnmaskedPermissionParam,org.apache.hadoop.hdfs.web.resources.OverwriteParam,org.apache.hadoop.hdfs.web.resources.BufferSizeParam,org.apache.hadoop.hdfs.web.resources.ReplicationParam,org.apache.hadoop.hdfs.web.resources.BlockSizeParam,org.apache.hadoop.hdfs.web.resources.ModificationTimeParam,org.apache.hadoop.hdfs.web.resources.AccessTimeParam,org.apache.hadoop.hdfs.web.resources.RenameOptionSetParam,org.apache.hadoop.hdfs.web.resources.CreateParentParam,org.apache.hadoop.hdfs.web.resources.TokenArgumentParam,org.apache.hadoop.hdfs.web.resources.AclPermissionParam,org.apache.hadoop.hdfs.web.resources.XAttrNameParam,org.apache.hadoop.hdfs.web.resources.XAttrValueParam,org.apache.hadoop.hdfs.web.resources.XAttrSetFlagParam,org.apache.hadoop.hdfs.web.resources.SnapshotNameParam,org.apache.hadoop.hdfs.web.resources.OldSnapshotNameParam,org.apache.hadoop.hdfs.web.resources.ExcludeDatanodesParam,org.apache.hadoop.hdfs.web.resources.CreateFlagParam,org.apache.hadoop.hdfs.web.resources.NoRedirectParam,org.apache.hadoop.hdfs.web.resources.StoragePolicyParam,org.apache.hadoop.hdfs.web.resources.ECPolicyParam,org.apache.hadoop.hdfs.web.resources.NameSpaceQuotaParam,org.apache.hadoop.hdfs.web.resources.StorageSpaceQuotaParam,org.apache.hadoop.hdfs.web.resources.StorageTypeParam)	javax.ws.rs.Path	value	/
org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods:putRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.PutOpParam,org.apache.hadoop.hdfs.web.resources.DestinationParam,org.apache.hadoop.hdfs.web.resources.OwnerParam,org.apache.hadoop.hdfs.web.resources.GroupParam,org.apache.hadoop.hdfs.web.resources.PermissionParam,org.apache.hadoop.hdfs.web.resources.UnmaskedPermissionParam,org.apache.hadoop.hdfs.web.resources.OverwriteParam,org.apache.hadoop.hdfs.web.resources.BufferSizeParam,org.apache.hadoop.hdfs.web.resources.ReplicationParam,org.apache.hadoop.hdfs.web.resources.BlockSizeParam,org.apache.hadoop.hdfs.web.resources.ModificationTimeParam,org.apache.hadoop.hdfs.web.resources.AccessTimeParam,org.apache.hadoop.hdfs.web.resources.RenameOptionSetParam,org.apache.hadoop.hdfs.web.resources.CreateParentParam,org.apache.hadoop.hdfs.web.resources.TokenArgumentParam,org.apache.hadoop.hdfs.web.resources.AclPermissionParam,org.apache.hadoop.hdfs.web.resources.XAttrNameParam,org.apache.hadoop.hdfs.web.resources.XAttrValueParam,org.apache.hadoop.hdfs.web.resources.XAttrSetFlagParam,org.apache.hadoop.hdfs.web.resources.SnapshotNameParam,org.apache.hadoop.hdfs.web.resources.OldSnapshotNameParam,org.apache.hadoop.hdfs.web.resources.ExcludeDatanodesParam,org.apache.hadoop.hdfs.web.resources.CreateFlagParam,org.apache.hadoop.hdfs.web.resources.NoRedirectParam,org.apache.hadoop.hdfs.web.resources.StoragePolicyParam,org.apache.hadoop.hdfs.web.resources.ECPolicyParam,org.apache.hadoop.hdfs.web.resources.NameSpaceQuotaParam,org.apache.hadoop.hdfs.web.resources.StorageSpaceQuotaParam,org.apache.hadoop.hdfs.web.resources.StorageTypeParam)	javax.ws.rs.Consumes	value	{*/*}
org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods:putRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.PutOpParam,org.apache.hadoop.hdfs.web.resources.DestinationParam,org.apache.hadoop.hdfs.web.resources.OwnerParam,org.apache.hadoop.hdfs.web.resources.GroupParam,org.apache.hadoop.hdfs.web.resources.PermissionParam,org.apache.hadoop.hdfs.web.resources.UnmaskedPermissionParam,org.apache.hadoop.hdfs.web.resources.OverwriteParam,org.apache.hadoop.hdfs.web.resources.BufferSizeParam,org.apache.hadoop.hdfs.web.resources.ReplicationParam,org.apache.hadoop.hdfs.web.resources.BlockSizeParam,org.apache.hadoop.hdfs.web.resources.ModificationTimeParam,org.apache.hadoop.hdfs.web.resources.AccessTimeParam,org.apache.hadoop.hdfs.web.resources.RenameOptionSetParam,org.apache.hadoop.hdfs.web.resources.CreateParentParam,org.apache.hadoop.hdfs.web.resources.TokenArgumentParam,org.apache.hadoop.hdfs.web.resources.AclPermissionParam,org.apache.hadoop.hdfs.web.resources.XAttrNameParam,org.apache.hadoop.hdfs.web.resources.XAttrValueParam,org.apache.hadoop.hdfs.web.resources.XAttrSetFlagParam,org.apache.hadoop.hdfs.web.resources.SnapshotNameParam,org.apache.hadoop.hdfs.web.resources.OldSnapshotNameParam,org.apache.hadoop.hdfs.web.resources.ExcludeDatanodesParam,org.apache.hadoop.hdfs.web.resources.CreateFlagParam,org.apache.hadoop.hdfs.web.resources.NoRedirectParam,org.apache.hadoop.hdfs.web.resources.StoragePolicyParam,org.apache.hadoop.hdfs.web.resources.ECPolicyParam,org.apache.hadoop.hdfs.web.resources.NameSpaceQuotaParam,org.apache.hadoop.hdfs.web.resources.StorageSpaceQuotaParam,org.apache.hadoop.hdfs.web.resources.StorageTypeParam)	javax.ws.rs.Produces	value	{application/octet-stream; charset=utf-8,application/json; charset=utf-8}
org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods:put(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.UriFsPathParam,org.apache.hadoop.hdfs.web.resources.PutOpParam,org.apache.hadoop.hdfs.web.resources.DestinationParam,org.apache.hadoop.hdfs.web.resources.OwnerParam,org.apache.hadoop.hdfs.web.resources.GroupParam,org.apache.hadoop.hdfs.web.resources.PermissionParam,org.apache.hadoop.hdfs.web.resources.UnmaskedPermissionParam,org.apache.hadoop.hdfs.web.resources.OverwriteParam,org.apache.hadoop.hdfs.web.resources.BufferSizeParam,org.apache.hadoop.hdfs.web.resources.ReplicationParam,org.apache.hadoop.hdfs.web.resources.BlockSizeParam,org.apache.hadoop.hdfs.web.resources.ModificationTimeParam,org.apache.hadoop.hdfs.web.resources.AccessTimeParam,org.apache.hadoop.hdfs.web.resources.RenameOptionSetParam,org.apache.hadoop.hdfs.web.resources.CreateParentParam,org.apache.hadoop.hdfs.web.resources.TokenArgumentParam,org.apache.hadoop.hdfs.web.resources.AclPermissionParam,org.apache.hadoop.hdfs.web.resources.XAttrNameParam,org.apache.hadoop.hdfs.web.resources.XAttrValueParam,org.apache.hadoop.hdfs.web.resources.XAttrSetFlagParam,org.apache.hadoop.hdfs.web.resources.SnapshotNameParam,org.apache.hadoop.hdfs.web.resources.OldSnapshotNameParam,org.apache.hadoop.hdfs.web.resources.ExcludeDatanodesParam,org.apache.hadoop.hdfs.web.resources.CreateFlagParam,org.apache.hadoop.hdfs.web.resources.NoRedirectParam,org.apache.hadoop.hdfs.web.resources.StoragePolicyParam,org.apache.hadoop.hdfs.web.resources.ECPolicyParam,org.apache.hadoop.hdfs.web.resources.NameSpaceQuotaParam,org.apache.hadoop.hdfs.web.resources.StorageSpaceQuotaParam,org.apache.hadoop.hdfs.web.resources.StorageTypeParam)	javax.ws.rs.PUT
org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods:put(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.UriFsPathParam,org.apache.hadoop.hdfs.web.resources.PutOpParam,org.apache.hadoop.hdfs.web.resources.DestinationParam,org.apache.hadoop.hdfs.web.resources.OwnerParam,org.apache.hadoop.hdfs.web.resources.GroupParam,org.apache.hadoop.hdfs.web.resources.PermissionParam,org.apache.hadoop.hdfs.web.resources.UnmaskedPermissionParam,org.apache.hadoop.hdfs.web.resources.OverwriteParam,org.apache.hadoop.hdfs.web.resources.BufferSizeParam,org.apache.hadoop.hdfs.web.resources.ReplicationParam,org.apache.hadoop.hdfs.web.resources.BlockSizeParam,org.apache.hadoop.hdfs.web.resources.ModificationTimeParam,org.apache.hadoop.hdfs.web.resources.AccessTimeParam,org.apache.hadoop.hdfs.web.resources.RenameOptionSetParam,org.apache.hadoop.hdfs.web.resources.CreateParentParam,org.apache.hadoop.hdfs.web.resources.TokenArgumentParam,org.apache.hadoop.hdfs.web.resources.AclPermissionParam,org.apache.hadoop.hdfs.web.resources.XAttrNameParam,org.apache.hadoop.hdfs.web.resources.XAttrValueParam,org.apache.hadoop.hdfs.web.resources.XAttrSetFlagParam,org.apache.hadoop.hdfs.web.resources.SnapshotNameParam,org.apache.hadoop.hdfs.web.resources.OldSnapshotNameParam,org.apache.hadoop.hdfs.web.resources.ExcludeDatanodesParam,org.apache.hadoop.hdfs.web.resources.CreateFlagParam,org.apache.hadoop.hdfs.web.resources.NoRedirectParam,org.apache.hadoop.hdfs.web.resources.StoragePolicyParam,org.apache.hadoop.hdfs.web.resources.ECPolicyParam,org.apache.hadoop.hdfs.web.resources.NameSpaceQuotaParam,org.apache.hadoop.hdfs.web.resources.StorageSpaceQuotaParam,org.apache.hadoop.hdfs.web.resources.StorageTypeParam)	javax.ws.rs.Path	value	{path:.*}
org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods:put(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.UriFsPathParam,org.apache.hadoop.hdfs.web.resources.PutOpParam,org.apache.hadoop.hdfs.web.resources.DestinationParam,org.apache.hadoop.hdfs.web.resources.OwnerParam,org.apache.hadoop.hdfs.web.resources.GroupParam,org.apache.hadoop.hdfs.web.resources.PermissionParam,org.apache.hadoop.hdfs.web.resources.UnmaskedPermissionParam,org.apache.hadoop.hdfs.web.resources.OverwriteParam,org.apache.hadoop.hdfs.web.resources.BufferSizeParam,org.apache.hadoop.hdfs.web.resources.ReplicationParam,org.apache.hadoop.hdfs.web.resources.BlockSizeParam,org.apache.hadoop.hdfs.web.resources.ModificationTimeParam,org.apache.hadoop.hdfs.web.resources.AccessTimeParam,org.apache.hadoop.hdfs.web.resources.RenameOptionSetParam,org.apache.hadoop.hdfs.web.resources.CreateParentParam,org.apache.hadoop.hdfs.web.resources.TokenArgumentParam,org.apache.hadoop.hdfs.web.resources.AclPermissionParam,org.apache.hadoop.hdfs.web.resources.XAttrNameParam,org.apache.hadoop.hdfs.web.resources.XAttrValueParam,org.apache.hadoop.hdfs.web.resources.XAttrSetFlagParam,org.apache.hadoop.hdfs.web.resources.SnapshotNameParam,org.apache.hadoop.hdfs.web.resources.OldSnapshotNameParam,org.apache.hadoop.hdfs.web.resources.ExcludeDatanodesParam,org.apache.hadoop.hdfs.web.resources.CreateFlagParam,org.apache.hadoop.hdfs.web.resources.NoRedirectParam,org.apache.hadoop.hdfs.web.resources.StoragePolicyParam,org.apache.hadoop.hdfs.web.resources.ECPolicyParam,org.apache.hadoop.hdfs.web.resources.NameSpaceQuotaParam,org.apache.hadoop.hdfs.web.resources.StorageSpaceQuotaParam,org.apache.hadoop.hdfs.web.resources.StorageTypeParam)	javax.ws.rs.Consumes	value	{*/*}
org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods:put(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.UriFsPathParam,org.apache.hadoop.hdfs.web.resources.PutOpParam,org.apache.hadoop.hdfs.web.resources.DestinationParam,org.apache.hadoop.hdfs.web.resources.OwnerParam,org.apache.hadoop.hdfs.web.resources.GroupParam,org.apache.hadoop.hdfs.web.resources.PermissionParam,org.apache.hadoop.hdfs.web.resources.UnmaskedPermissionParam,org.apache.hadoop.hdfs.web.resources.OverwriteParam,org.apache.hadoop.hdfs.web.resources.BufferSizeParam,org.apache.hadoop.hdfs.web.resources.ReplicationParam,org.apache.hadoop.hdfs.web.resources.BlockSizeParam,org.apache.hadoop.hdfs.web.resources.ModificationTimeParam,org.apache.hadoop.hdfs.web.resources.AccessTimeParam,org.apache.hadoop.hdfs.web.resources.RenameOptionSetParam,org.apache.hadoop.hdfs.web.resources.CreateParentParam,org.apache.hadoop.hdfs.web.resources.TokenArgumentParam,org.apache.hadoop.hdfs.web.resources.AclPermissionParam,org.apache.hadoop.hdfs.web.resources.XAttrNameParam,org.apache.hadoop.hdfs.web.resources.XAttrValueParam,org.apache.hadoop.hdfs.web.resources.XAttrSetFlagParam,org.apache.hadoop.hdfs.web.resources.SnapshotNameParam,org.apache.hadoop.hdfs.web.resources.OldSnapshotNameParam,org.apache.hadoop.hdfs.web.resources.ExcludeDatanodesParam,org.apache.hadoop.hdfs.web.resources.CreateFlagParam,org.apache.hadoop.hdfs.web.resources.NoRedirectParam,org.apache.hadoop.hdfs.web.resources.StoragePolicyParam,org.apache.hadoop.hdfs.web.resources.ECPolicyParam,org.apache.hadoop.hdfs.web.resources.NameSpaceQuotaParam,org.apache.hadoop.hdfs.web.resources.StorageSpaceQuotaParam,org.apache.hadoop.hdfs.web.resources.StorageTypeParam)	javax.ws.rs.Produces	value	{application/octet-stream; charset=utf-8,application/json; charset=utf-8}
org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods:postRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.PostOpParam,org.apache.hadoop.hdfs.web.resources.ConcatSourcesParam,org.apache.hadoop.hdfs.web.resources.BufferSizeParam,org.apache.hadoop.hdfs.web.resources.ExcludeDatanodesParam,org.apache.hadoop.hdfs.web.resources.NewLengthParam,org.apache.hadoop.hdfs.web.resources.NoRedirectParam)	javax.ws.rs.POST
org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods:postRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.PostOpParam,org.apache.hadoop.hdfs.web.resources.ConcatSourcesParam,org.apache.hadoop.hdfs.web.resources.BufferSizeParam,org.apache.hadoop.hdfs.web.resources.ExcludeDatanodesParam,org.apache.hadoop.hdfs.web.resources.NewLengthParam,org.apache.hadoop.hdfs.web.resources.NoRedirectParam)	javax.ws.rs.Path	value	/
org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods:postRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.PostOpParam,org.apache.hadoop.hdfs.web.resources.ConcatSourcesParam,org.apache.hadoop.hdfs.web.resources.BufferSizeParam,org.apache.hadoop.hdfs.web.resources.ExcludeDatanodesParam,org.apache.hadoop.hdfs.web.resources.NewLengthParam,org.apache.hadoop.hdfs.web.resources.NoRedirectParam)	javax.ws.rs.Consumes	value	{*/*}
org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods:postRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.PostOpParam,org.apache.hadoop.hdfs.web.resources.ConcatSourcesParam,org.apache.hadoop.hdfs.web.resources.BufferSizeParam,org.apache.hadoop.hdfs.web.resources.ExcludeDatanodesParam,org.apache.hadoop.hdfs.web.resources.NewLengthParam,org.apache.hadoop.hdfs.web.resources.NoRedirectParam)	javax.ws.rs.Produces	value	{application/octet-stream; charset=utf-8,application/json; charset=utf-8}
org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods:post(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.UriFsPathParam,org.apache.hadoop.hdfs.web.resources.PostOpParam,org.apache.hadoop.hdfs.web.resources.ConcatSourcesParam,org.apache.hadoop.hdfs.web.resources.BufferSizeParam,org.apache.hadoop.hdfs.web.resources.ExcludeDatanodesParam,org.apache.hadoop.hdfs.web.resources.NewLengthParam,org.apache.hadoop.hdfs.web.resources.NoRedirectParam)	javax.ws.rs.POST
org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods:post(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.UriFsPathParam,org.apache.hadoop.hdfs.web.resources.PostOpParam,org.apache.hadoop.hdfs.web.resources.ConcatSourcesParam,org.apache.hadoop.hdfs.web.resources.BufferSizeParam,org.apache.hadoop.hdfs.web.resources.ExcludeDatanodesParam,org.apache.hadoop.hdfs.web.resources.NewLengthParam,org.apache.hadoop.hdfs.web.resources.NoRedirectParam)	javax.ws.rs.Path	value	{path:.*}
org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods:post(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.UriFsPathParam,org.apache.hadoop.hdfs.web.resources.PostOpParam,org.apache.hadoop.hdfs.web.resources.ConcatSourcesParam,org.apache.hadoop.hdfs.web.resources.BufferSizeParam,org.apache.hadoop.hdfs.web.resources.ExcludeDatanodesParam,org.apache.hadoop.hdfs.web.resources.NewLengthParam,org.apache.hadoop.hdfs.web.resources.NoRedirectParam)	javax.ws.rs.Consumes	value	{*/*}
org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods:post(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.UriFsPathParam,org.apache.hadoop.hdfs.web.resources.PostOpParam,org.apache.hadoop.hdfs.web.resources.ConcatSourcesParam,org.apache.hadoop.hdfs.web.resources.BufferSizeParam,org.apache.hadoop.hdfs.web.resources.ExcludeDatanodesParam,org.apache.hadoop.hdfs.web.resources.NewLengthParam,org.apache.hadoop.hdfs.web.resources.NoRedirectParam)	javax.ws.rs.Produces	value	{application/octet-stream; charset=utf-8,application/json; charset=utf-8}
org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods:getRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.GetOpParam,org.apache.hadoop.hdfs.web.resources.OffsetParam,org.apache.hadoop.hdfs.web.resources.LengthParam,org.apache.hadoop.hdfs.web.resources.RenewerParam,org.apache.hadoop.hdfs.web.resources.BufferSizeParam,java.util.List,org.apache.hadoop.hdfs.web.resources.XAttrEncodingParam,org.apache.hadoop.hdfs.web.resources.ExcludeDatanodesParam,org.apache.hadoop.hdfs.web.resources.FsActionParam,org.apache.hadoop.hdfs.web.resources.SnapshotNameParam,org.apache.hadoop.hdfs.web.resources.OldSnapshotNameParam,org.apache.hadoop.hdfs.web.resources.TokenKindParam,org.apache.hadoop.hdfs.web.resources.TokenServiceParam,org.apache.hadoop.hdfs.web.resources.NoRedirectParam,org.apache.hadoop.hdfs.web.resources.StartAfterParam)	javax.ws.rs.GET
org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods:getRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.GetOpParam,org.apache.hadoop.hdfs.web.resources.OffsetParam,org.apache.hadoop.hdfs.web.resources.LengthParam,org.apache.hadoop.hdfs.web.resources.RenewerParam,org.apache.hadoop.hdfs.web.resources.BufferSizeParam,java.util.List,org.apache.hadoop.hdfs.web.resources.XAttrEncodingParam,org.apache.hadoop.hdfs.web.resources.ExcludeDatanodesParam,org.apache.hadoop.hdfs.web.resources.FsActionParam,org.apache.hadoop.hdfs.web.resources.SnapshotNameParam,org.apache.hadoop.hdfs.web.resources.OldSnapshotNameParam,org.apache.hadoop.hdfs.web.resources.TokenKindParam,org.apache.hadoop.hdfs.web.resources.TokenServiceParam,org.apache.hadoop.hdfs.web.resources.NoRedirectParam,org.apache.hadoop.hdfs.web.resources.StartAfterParam)	javax.ws.rs.Path	value	/
org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods:getRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.GetOpParam,org.apache.hadoop.hdfs.web.resources.OffsetParam,org.apache.hadoop.hdfs.web.resources.LengthParam,org.apache.hadoop.hdfs.web.resources.RenewerParam,org.apache.hadoop.hdfs.web.resources.BufferSizeParam,java.util.List,org.apache.hadoop.hdfs.web.resources.XAttrEncodingParam,org.apache.hadoop.hdfs.web.resources.ExcludeDatanodesParam,org.apache.hadoop.hdfs.web.resources.FsActionParam,org.apache.hadoop.hdfs.web.resources.SnapshotNameParam,org.apache.hadoop.hdfs.web.resources.OldSnapshotNameParam,org.apache.hadoop.hdfs.web.resources.TokenKindParam,org.apache.hadoop.hdfs.web.resources.TokenServiceParam,org.apache.hadoop.hdfs.web.resources.NoRedirectParam,org.apache.hadoop.hdfs.web.resources.StartAfterParam)	javax.ws.rs.Produces	value	{application/octet-stream; charset=utf-8,application/json; charset=utf-8}
org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods:get(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.UriFsPathParam,org.apache.hadoop.hdfs.web.resources.GetOpParam,org.apache.hadoop.hdfs.web.resources.OffsetParam,org.apache.hadoop.hdfs.web.resources.LengthParam,org.apache.hadoop.hdfs.web.resources.RenewerParam,org.apache.hadoop.hdfs.web.resources.BufferSizeParam,java.util.List,org.apache.hadoop.hdfs.web.resources.XAttrEncodingParam,org.apache.hadoop.hdfs.web.resources.ExcludeDatanodesParam,org.apache.hadoop.hdfs.web.resources.FsActionParam,org.apache.hadoop.hdfs.web.resources.SnapshotNameParam,org.apache.hadoop.hdfs.web.resources.OldSnapshotNameParam,org.apache.hadoop.hdfs.web.resources.TokenKindParam,org.apache.hadoop.hdfs.web.resources.TokenServiceParam,org.apache.hadoop.hdfs.web.resources.NoRedirectParam,org.apache.hadoop.hdfs.web.resources.StartAfterParam)	javax.ws.rs.GET
org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods:get(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.UriFsPathParam,org.apache.hadoop.hdfs.web.resources.GetOpParam,org.apache.hadoop.hdfs.web.resources.OffsetParam,org.apache.hadoop.hdfs.web.resources.LengthParam,org.apache.hadoop.hdfs.web.resources.RenewerParam,org.apache.hadoop.hdfs.web.resources.BufferSizeParam,java.util.List,org.apache.hadoop.hdfs.web.resources.XAttrEncodingParam,org.apache.hadoop.hdfs.web.resources.ExcludeDatanodesParam,org.apache.hadoop.hdfs.web.resources.FsActionParam,org.apache.hadoop.hdfs.web.resources.SnapshotNameParam,org.apache.hadoop.hdfs.web.resources.OldSnapshotNameParam,org.apache.hadoop.hdfs.web.resources.TokenKindParam,org.apache.hadoop.hdfs.web.resources.TokenServiceParam,org.apache.hadoop.hdfs.web.resources.NoRedirectParam,org.apache.hadoop.hdfs.web.resources.StartAfterParam)	javax.ws.rs.Path	value	{path:.*}
org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods:get(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.UriFsPathParam,org.apache.hadoop.hdfs.web.resources.GetOpParam,org.apache.hadoop.hdfs.web.resources.OffsetParam,org.apache.hadoop.hdfs.web.resources.LengthParam,org.apache.hadoop.hdfs.web.resources.RenewerParam,org.apache.hadoop.hdfs.web.resources.BufferSizeParam,java.util.List,org.apache.hadoop.hdfs.web.resources.XAttrEncodingParam,org.apache.hadoop.hdfs.web.resources.ExcludeDatanodesParam,org.apache.hadoop.hdfs.web.resources.FsActionParam,org.apache.hadoop.hdfs.web.resources.SnapshotNameParam,org.apache.hadoop.hdfs.web.resources.OldSnapshotNameParam,org.apache.hadoop.hdfs.web.resources.TokenKindParam,org.apache.hadoop.hdfs.web.resources.TokenServiceParam,org.apache.hadoop.hdfs.web.resources.NoRedirectParam,org.apache.hadoop.hdfs.web.resources.StartAfterParam)	javax.ws.rs.Produces	value	{application/octet-stream; charset=utf-8,application/json; charset=utf-8}
org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods:deleteRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.DeleteOpParam,org.apache.hadoop.hdfs.web.resources.RecursiveParam,org.apache.hadoop.hdfs.web.resources.SnapshotNameParam)	javax.ws.rs.DELETE
org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods:deleteRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.DeleteOpParam,org.apache.hadoop.hdfs.web.resources.RecursiveParam,org.apache.hadoop.hdfs.web.resources.SnapshotNameParam)	javax.ws.rs.Path	value	/
org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods:deleteRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.DeleteOpParam,org.apache.hadoop.hdfs.web.resources.RecursiveParam,org.apache.hadoop.hdfs.web.resources.SnapshotNameParam)	javax.ws.rs.Produces	value	{application/json; charset=utf-8}
org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods:delete(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.UriFsPathParam,org.apache.hadoop.hdfs.web.resources.DeleteOpParam,org.apache.hadoop.hdfs.web.resources.RecursiveParam,org.apache.hadoop.hdfs.web.resources.SnapshotNameParam)	javax.ws.rs.DELETE
org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods:delete(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.UriFsPathParam,org.apache.hadoop.hdfs.web.resources.DeleteOpParam,org.apache.hadoop.hdfs.web.resources.RecursiveParam,org.apache.hadoop.hdfs.web.resources.SnapshotNameParam)	javax.ws.rs.Path	value	{path:.*}
org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods:delete(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.UriFsPathParam,org.apache.hadoop.hdfs.web.resources.DeleteOpParam,org.apache.hadoop.hdfs.web.resources.RecursiveParam,org.apache.hadoop.hdfs.web.resources.SnapshotNameParam)	javax.ws.rs.Produces	value	{application/json; charset=utf-8}
org.apache.hadoop.hdfs.server.namenode.NNStorage:setStorageDirectories(java.util.Collection,java.util.Collection)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.NNStorage:setStorageDirectories(java.util.Collection,java.util.Collection,java.util.Collection)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.NNStorage:getCheckpointImageFileName(long)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.NNStorage:getImageFileName(long)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.NNStorage:getRollbackImageFileName(long)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.NNStorage:getInProgressEditsFileName(long)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.NNStorage:getFinalizedEditsFileName(long,long)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.AclStorage:getEntriesFromAclFeature(org.apache.hadoop.hdfs.server.namenode.AclFeature)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.AclStorage:getUniqueAclFeatures()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.FSEditLog:getCurSegmentTxId()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.FSEditLog:getJournalSet()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.FSEditLog:setJournalSetForTesting(org.apache.hadoop.hdfs.server.namenode.JournalSet)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.FSEditLog:setMetricsForTests(org.apache.hadoop.hdfs.server.namenode.metrics.NameNodeMetrics)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.FSEditLog:createJournal(java.net.URI)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.FSEditLog:restart()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.INodeAttributeProvider$AuthorizationContext:equals(java.lang.Object)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.EditLogFileOutputStream:writeHeader(int,java.io.DataOutputStream)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.EditLogFileOutputStream:setFileChannelForTesting(java.nio.channels.FileChannel)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.EditLogFileOutputStream:getFileChannelForTesting()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.EditLogFileOutputStream:setShouldSkipFsyncForTesting(boolean)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.LeaseManager$Lease:getLastUpdate()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.ImageServlet:setRecentImageCheckTimePrecision(double)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.ImageServlet:isValidRequestor(javax.servlet.ServletContext,java.lang.String,org.apache.hadoop.conf.Configuration)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.FSDirRenameOp:renameToInt(org.apache.hadoop.hdfs.server.namenode.FSDirectory,org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker,java.lang.String,java.lang.String,boolean)	java.lang.Deprecated
org.apache.hadoop.hdfs.server.namenode.FSDirRenameOp:renameForEditLog(org.apache.hadoop.hdfs.server.namenode.FSDirectory,java.lang.String,java.lang.String,long)	java.lang.Deprecated
org.apache.hadoop.hdfs.server.namenode.FSDirRenameOp:unprotectedRenameTo(org.apache.hadoop.hdfs.server.namenode.FSDirectory,org.apache.hadoop.hdfs.server.namenode.INodesInPath,org.apache.hadoop.hdfs.server.namenode.INodesInPath,long)	java.lang.Deprecated
org.apache.hadoop.hdfs.server.namenode.FSDirRenameOp:renameTo(org.apache.hadoop.hdfs.server.namenode.FSDirectory,org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker,org.apache.hadoop.hdfs.server.namenode.INodesInPath,org.apache.hadoop.hdfs.server.namenode.INodesInPath,boolean)	java.lang.Deprecated
org.apache.hadoop.hdfs.server.namenode.FileJournalManager:getStorageDirectory()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.NameNodeHttpServer:getHttpServer()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.INode:getObjectString()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.INode:getParentString()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.INode:toDetailString()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.INode:getPathComponents(java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.INode:dumpTreeRecursively()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.INode:dumpTreeRecursively(java.io.PrintStream)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.INode:dumpTreeRecursively(java.io.PrintWriter,java.lang.StringBuilder,int)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.FSNamesystemLock:<init>(org.apache.hadoop.conf.Configuration,org.apache.hadoop.metrics2.lib.MutableRatesWithAggregation,org.apache.hadoop.util.Timer)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp:<init>(org.apache.hadoop.hdfs.server.namenode.FSEditLogOpCodes)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.BackupNode:stop(boolean)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.FSEditLogAsync:restart()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.FSNamesystem:isImageLoaded()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.FSNamesystem:getLeaseManager()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.FSNamesystem:getLazyPersistFileScrubberTS()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.FSNamesystem:getAuditLoggers()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.FSNamesystem:getRetryCache()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.FSNamesystem:getLeaseRecheckIntervalMs()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.FSNamesystem:getMaxLockHoldToReleaseLeaseMs()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.FSNamesystem:getProvider()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.FSNamesystem:initRetryCache(org.apache.hadoop.conf.Configuration)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.FSNamesystem:getCTime()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.FSNamesystem:getServerDefaults()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.FSNamesystem:renameTo(java.lang.String,java.lang.String,boolean)	java.lang.Deprecated
org.apache.hadoop.hdfs.server.namenode.FSNamesystem:getStoredBlock(org.apache.hadoop.hdfs.protocol.Block)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.FSNamesystem:closeFileCommitBlocks(java.lang.String,org.apache.hadoop.hdfs.server.namenode.INodeFile,org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.FSNamesystem:getMissingBlocksCount()	org.apache.hadoop.metrics2.annotation.Metric	value	{MissingBlocks,Number of missing blocks}
org.apache.hadoop.hdfs.server.namenode.FSNamesystem:getMissingReplOneBlocksCount()	org.apache.hadoop.metrics2.annotation.Metric	value	{MissingReplOneBlocks,Number of missing blocks with replication factor 1}
org.apache.hadoop.hdfs.server.namenode.FSNamesystem:getExpiredHeartbeats()	org.apache.hadoop.metrics2.annotation.Metric	value	{ExpiredHeartbeats,Number of expired heartbeats}
org.apache.hadoop.hdfs.server.namenode.FSNamesystem:getExpiredHeartbeats()	org.apache.hadoop.metrics2.annotation.Metric	type	COUNTER
org.apache.hadoop.hdfs.server.namenode.FSNamesystem:getTransactionsSinceLastCheckpoint()	org.apache.hadoop.metrics2.annotation.Metric	value	{TransactionsSinceLastCheckpoint,Number of transactions since last checkpoint}
org.apache.hadoop.hdfs.server.namenode.FSNamesystem:getTransactionsSinceLastLogRoll()	org.apache.hadoop.metrics2.annotation.Metric	value	{TransactionsSinceLastLogRoll,Number of transactions since last edit log roll}
org.apache.hadoop.hdfs.server.namenode.FSNamesystem:getLastWrittenTransactionId()	org.apache.hadoop.metrics2.annotation.Metric	value	{LastWrittenTransactionId,Transaction ID written to the edit log}
org.apache.hadoop.hdfs.server.namenode.FSNamesystem:getLastCheckpointTime()	org.apache.hadoop.metrics2.annotation.Metric	value	{LastCheckpointTime,Time in milliseconds since the epoch of the last checkpoint}
org.apache.hadoop.hdfs.server.namenode.FSNamesystem:getCapacityTotal()	org.apache.hadoop.metrics2.annotation.Metric	value	{CapacityTotal,Total raw capacity of data nodes in bytes}
org.apache.hadoop.hdfs.server.namenode.FSNamesystem:getCapacityTotalGB()	org.apache.hadoop.metrics2.annotation.Metric	value	{CapacityTotalGB,Total raw capacity of data nodes in GB}
org.apache.hadoop.hdfs.server.namenode.FSNamesystem:getCapacityUsed()	org.apache.hadoop.metrics2.annotation.Metric	value	{CapacityUsed,Total used capacity across all data nodes in bytes}
org.apache.hadoop.hdfs.server.namenode.FSNamesystem:getCapacityUsedGB()	org.apache.hadoop.metrics2.annotation.Metric	value	{CapacityUsedGB,Total used capacity across all data nodes in GB}
org.apache.hadoop.hdfs.server.namenode.FSNamesystem:getCapacityRemaining()	org.apache.hadoop.metrics2.annotation.Metric	value	{CapacityRemaining,Remaining capacity in bytes}
org.apache.hadoop.hdfs.server.namenode.FSNamesystem:getProvidedCapacityTotal()	org.apache.hadoop.metrics2.annotation.Metric	value	{ProvidedCapacityTotal,Total space used in PROVIDED storage in bytes}
org.apache.hadoop.hdfs.server.namenode.FSNamesystem:getCapacityRemainingGB()	org.apache.hadoop.metrics2.annotation.Metric	value	{CapacityRemainingGB,Remaining capacity in GB}
org.apache.hadoop.hdfs.server.namenode.FSNamesystem:getCapacityUsedNonDFS()	org.apache.hadoop.metrics2.annotation.Metric	value	{CapacityUsedNonDFS,Total space used by data nodes for non DFS purposes in bytes}
org.apache.hadoop.hdfs.server.namenode.FSNamesystem:getTotalLoad()	org.apache.hadoop.metrics2.annotation.Metric
org.apache.hadoop.hdfs.server.namenode.FSNamesystem:getNumSnapshottableDirs()	org.apache.hadoop.metrics2.annotation.Metric	value	{SnapshottableDirectories,Number of snapshottable directories}
org.apache.hadoop.hdfs.server.namenode.FSNamesystem:getNumSnapshots()	org.apache.hadoop.metrics2.annotation.Metric	value	{Snapshots,The number of snapshots}
org.apache.hadoop.hdfs.server.namenode.FSNamesystem:getNumEncryptionZones()	org.apache.hadoop.metrics2.annotation.Metric	value	{NumEncryptionZones,The number of encryption zones}
org.apache.hadoop.hdfs.server.namenode.FSNamesystem:getCurrentTokensCount()	org.apache.hadoop.metrics2.annotation.Metric	value	{CurrentTokensCount,The number of delegation tokens}
org.apache.hadoop.hdfs.server.namenode.FSNamesystem:getFsLockQueueLength()	org.apache.hadoop.metrics2.annotation.Metric	value	{LockQueueLength,Number of threads waiting to acquire FSNameSystemLock}
org.apache.hadoop.hdfs.server.namenode.FSNamesystem:getNumOfReadLockLongHold()	org.apache.hadoop.metrics2.annotation.Metric	value	{ReadLockLongHoldCount,The number of time the read lock has been held for longer than the threshold}
org.apache.hadoop.hdfs.server.namenode.FSNamesystem:getNumOfReadLockLongHold()	org.apache.hadoop.metrics2.annotation.Metric	type	COUNTER
org.apache.hadoop.hdfs.server.namenode.FSNamesystem:getNumOfWriteLockLongHold()	org.apache.hadoop.metrics2.annotation.Metric	value	{WriteLockLongHoldCount,The number of time the write lock has been held for longer than the threshold}
org.apache.hadoop.hdfs.server.namenode.FSNamesystem:getNumOfWriteLockLongHold()	org.apache.hadoop.metrics2.annotation.Metric	type	COUNTER
org.apache.hadoop.hdfs.server.namenode.FSNamesystem:getBlocksTotal()	org.apache.hadoop.metrics2.annotation.Metric
org.apache.hadoop.hdfs.server.namenode.FSNamesystem:getNumFilesUnderConstruction()	org.apache.hadoop.metrics2.annotation.Metric	value	{NumFilesUnderConstruction,Number of files under construction}
org.apache.hadoop.hdfs.server.namenode.FSNamesystem:getNumActiveClients()	org.apache.hadoop.metrics2.annotation.Metric	value	{NumActiveClients,Number of active clients holding lease}
org.apache.hadoop.hdfs.server.namenode.FSNamesystem:getFilesTotal()	org.apache.hadoop.metrics2.annotation.Metric
org.apache.hadoop.hdfs.server.namenode.FSNamesystem:getPendingReplicationBlocks()	org.apache.hadoop.metrics2.annotation.Metric
org.apache.hadoop.hdfs.server.namenode.FSNamesystem:getPendingReplicationBlocks()	java.lang.Deprecated
org.apache.hadoop.hdfs.server.namenode.FSNamesystem:getPendingReconstructionBlocks()	org.apache.hadoop.metrics2.annotation.Metric
org.apache.hadoop.hdfs.server.namenode.FSNamesystem:getUnderReplicatedBlocks()	org.apache.hadoop.metrics2.annotation.Metric
org.apache.hadoop.hdfs.server.namenode.FSNamesystem:getUnderReplicatedBlocks()	java.lang.Deprecated
org.apache.hadoop.hdfs.server.namenode.FSNamesystem:getLowRedundancyBlocks()	org.apache.hadoop.metrics2.annotation.Metric
org.apache.hadoop.hdfs.server.namenode.FSNamesystem:getCorruptReplicaBlocks()	org.apache.hadoop.metrics2.annotation.Metric	value	{CorruptBlocks,Number of blocks with corrupt replicas}
org.apache.hadoop.hdfs.server.namenode.FSNamesystem:getScheduledReplicationBlocks()	org.apache.hadoop.metrics2.annotation.Metric
org.apache.hadoop.hdfs.server.namenode.FSNamesystem:getPendingDeletionBlocks()	org.apache.hadoop.metrics2.annotation.Metric
org.apache.hadoop.hdfs.server.namenode.FSNamesystem:getLowRedundancyReplicatedBlocks()	org.apache.hadoop.metrics2.annotation.Metric	value	{LowRedundancyReplicatedBlocks,Number of low redundancy replicated blocks}
org.apache.hadoop.hdfs.server.namenode.FSNamesystem:getCorruptReplicatedBlocks()	org.apache.hadoop.metrics2.annotation.Metric	value	{CorruptReplicatedBlocks,Number of corrupted replicated blocks}
org.apache.hadoop.hdfs.server.namenode.FSNamesystem:getMissingReplicatedBlocks()	org.apache.hadoop.metrics2.annotation.Metric	value	{MissingReplicatedBlocks,Number of missing replicated blocks}
org.apache.hadoop.hdfs.server.namenode.FSNamesystem:getMissingReplicationOneBlocks()	org.apache.hadoop.metrics2.annotation.Metric	value	{MissingReplicationOneBlocks,Number of missing replicated blocks with replication factor 1}
org.apache.hadoop.hdfs.server.namenode.FSNamesystem:getHighestPriorityLowRedundancyReplicatedBlocks()	org.apache.hadoop.metrics2.annotation.Metric	value	{HighestPriorityLowRedundancyReplicatedBlocks,Number of replicated blocks which have the highest risk of loss.}
org.apache.hadoop.hdfs.server.namenode.FSNamesystem:getHighestPriorityLowRedundancyECBlocks()	org.apache.hadoop.metrics2.annotation.Metric	value	{HighestPriorityLowRedundancyECBlocks,Number of erasure coded blocks which have the highest risk of loss.}
org.apache.hadoop.hdfs.server.namenode.FSNamesystem:getBytesInFutureReplicatedBlocks()	org.apache.hadoop.metrics2.annotation.Metric	value	{BytesInFutureReplicatedBlocks,Total bytes in replicated blocks with future generation stamp}
org.apache.hadoop.hdfs.server.namenode.FSNamesystem:getPendingDeletionReplicatedBlocks()	org.apache.hadoop.metrics2.annotation.Metric	value	{PendingDeletionReplicatedBlocks,Number of replicated blocks that are pending deletion}
org.apache.hadoop.hdfs.server.namenode.FSNamesystem:getTotalReplicatedBlocks()	org.apache.hadoop.metrics2.annotation.Metric	value	{TotalReplicatedBlocks,Total number of replicated blocks}
org.apache.hadoop.hdfs.server.namenode.FSNamesystem:getLowRedundancyECBlockGroups()	org.apache.hadoop.metrics2.annotation.Metric	value	{LowRedundancyECBlockGroups,Number of erasure coded block groups with low redundancy}
org.apache.hadoop.hdfs.server.namenode.FSNamesystem:getCorruptECBlockGroups()	org.apache.hadoop.metrics2.annotation.Metric	value	{CorruptECBlockGroups,Number of erasure coded block groups that are corrupt}
org.apache.hadoop.hdfs.server.namenode.FSNamesystem:getMissingECBlockGroups()	org.apache.hadoop.metrics2.annotation.Metric	value	{MissingECBlockGroups,Number of erasure coded block groups that are missing}
org.apache.hadoop.hdfs.server.namenode.FSNamesystem:getBytesInFutureECBlockGroups()	org.apache.hadoop.metrics2.annotation.Metric	value	{BytesInFutureECBlockGroups,Total bytes in erasure coded block groups with future generation stamp}
org.apache.hadoop.hdfs.server.namenode.FSNamesystem:getPendingDeletionECBlocks()	org.apache.hadoop.metrics2.annotation.Metric	value	{PendingDeletionECBlocks,Number of erasure coded blocks that are pending deletion}
org.apache.hadoop.hdfs.server.namenode.FSNamesystem:getTotalECBlockGroups()	org.apache.hadoop.metrics2.annotation.Metric	value	{TotalECBlockGroups,Total number of erasure coded block groups}
org.apache.hadoop.hdfs.server.namenode.FSNamesystem:getEnabledEcPolicies()	org.apache.hadoop.metrics2.annotation.Metric	value	{EnabledEcPolicies,Enabled erasure coding policies}
org.apache.hadoop.hdfs.server.namenode.FSNamesystem:getExcessBlocks()	org.apache.hadoop.metrics2.annotation.Metric
org.apache.hadoop.hdfs.server.namenode.FSNamesystem:getNumTimedOutPendingReconstructions()	org.apache.hadoop.metrics2.annotation.Metric
org.apache.hadoop.hdfs.server.namenode.FSNamesystem:getPostponedMisreplicatedBlocks()	org.apache.hadoop.metrics2.annotation.Metric
org.apache.hadoop.hdfs.server.namenode.FSNamesystem:getPendingDataNodeMessageCount()	org.apache.hadoop.metrics2.annotation.Metric
org.apache.hadoop.hdfs.server.namenode.FSNamesystem:getHAState()	org.apache.hadoop.metrics2.annotation.Metric
org.apache.hadoop.hdfs.server.namenode.FSNamesystem:getMillisSinceLastLoadedEdits()	org.apache.hadoop.metrics2.annotation.Metric
org.apache.hadoop.hdfs.server.namenode.FSNamesystem:getBlockCapacity()	org.apache.hadoop.metrics2.annotation.Metric
org.apache.hadoop.hdfs.server.namenode.FSNamesystem:getNumLiveDataNodes()	org.apache.hadoop.metrics2.annotation.Metric	value	{NumLiveDataNodes,Number of datanodes which are currently live}
org.apache.hadoop.hdfs.server.namenode.FSNamesystem:getNumDeadDataNodes()	org.apache.hadoop.metrics2.annotation.Metric	value	{NumDeadDataNodes,Number of datanodes which are currently dead}
org.apache.hadoop.hdfs.server.namenode.FSNamesystem:getNumDecomLiveDataNodes()	org.apache.hadoop.metrics2.annotation.Metric	value	{NumDecomLiveDataNodes,Number of datanodes which have been decommissioned and are now live}
org.apache.hadoop.hdfs.server.namenode.FSNamesystem:getNumDecomDeadDataNodes()	org.apache.hadoop.metrics2.annotation.Metric	value	{NumDecomDeadDataNodes,Number of datanodes which have been decommissioned and are now dead}
org.apache.hadoop.hdfs.server.namenode.FSNamesystem:getNumInServiceLiveDataNodes()	org.apache.hadoop.metrics2.annotation.Metric	value	{NumInServiceLiveDataNodes,Number of live datanodes which are currently in service}
org.apache.hadoop.hdfs.server.namenode.FSNamesystem:getVolumeFailuresTotal()	org.apache.hadoop.metrics2.annotation.Metric	value	{VolumeFailuresTotal,Total number of volume failures across all Datanodes}
org.apache.hadoop.hdfs.server.namenode.FSNamesystem:getEstimatedCapacityLostTotal()	org.apache.hadoop.metrics2.annotation.Metric	value	{EstimatedCapacityLostTotal,An estimate of the total capacity lost due to volume failures}
org.apache.hadoop.hdfs.server.namenode.FSNamesystem:getNumDecommissioningDataNodes()	org.apache.hadoop.metrics2.annotation.Metric	value	{NumDecommissioningDataNodes,Number of datanodes in decommissioning state}
org.apache.hadoop.hdfs.server.namenode.FSNamesystem:getNumStaleDataNodes()	org.apache.hadoop.metrics2.annotation.Metric	value	{StaleDataNodes,Number of datanodes marked stale due to delayed heartbeat}
org.apache.hadoop.hdfs.server.namenode.FSNamesystem:getNumStaleStorages()	org.apache.hadoop.metrics2.annotation.Metric	value	{NumStaleStorages,Number of storages marked as content stale}
org.apache.hadoop.hdfs.server.namenode.FSNamesystem:setBlockManagerForTesting(org.apache.hadoop.hdfs.server.blockmanagement.BlockManager)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.FSNamesystem:setFSDirectory(org.apache.hadoop.hdfs.server.namenode.FSDirectory)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.FSNamesystem:getEditLogTailer()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.FSNamesystem:setEditLogTailerForTests(org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.FSNamesystem:setFsLockForTests(java.util.concurrent.locks.ReentrantReadWriteLock)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.FSNamesystem:getFsLockForTests()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.FSNamesystem:getCpLockForTests()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.FSNamesystem:setNNResourceChecker(org.apache.hadoop.hdfs.server.namenode.NameNodeResourceChecker)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.FSNamesystem:getEffectiveLayoutVersion(boolean,int,int,int)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.FSNamesystem:getTotalSyncCount()	org.apache.hadoop.metrics2.annotation.Metric	value	{TotalSyncCount,Total number of sync operations performed on edit logs}
org.apache.hadoop.hdfs.server.namenode.FSNamesystem:getTotalSyncTimes()	org.apache.hadoop.metrics2.annotation.Metric	value	{TotalSyncTimes,Total time spend in sync operation on various edit logs}
org.apache.hadoop.hdfs.server.namenode.FSNamesystem:getNumInMaintenanceLiveDataNodes()	org.apache.hadoop.metrics2.annotation.Metric	value	{NumInMaintenanceLiveDataNodes,Number of live Datanodes which are in maintenance state}
org.apache.hadoop.hdfs.server.namenode.FSNamesystem:getNumInMaintenanceDeadDataNodes()	org.apache.hadoop.metrics2.annotation.Metric	value	{NumInMaintenanceDeadDataNodes,Number of dead Datanodes which are in maintenance state}
org.apache.hadoop.hdfs.server.namenode.FSNamesystem:getNumEnteringMaintenanceDataNodes()	org.apache.hadoop.metrics2.annotation.Metric	value	{NumEnteringMaintenanceDataNodes,Number of Datanodes that are entering the maintenance state}
org.apache.hadoop.hdfs.server.namenode.NetworkTopologyServlet:parseAcceptHeader(javax.servlet.http.HttpServletRequest)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.ReencryptionHandler:pauseForTesting()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.ReencryptionHandler:resumeForTesting()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.ReencryptionHandler:pauseForTestingAfterNthSubmission(int)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.ReencryptionHandler:pauseUpdaterForTesting()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.ReencryptionHandler:resumeUpdaterForTesting()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.ReencryptionHandler:pauseForTestingAfterNthCheckpoint(long,int)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode:getFSImage()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode:getMergeErrorCount()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode:getFSNamesystem()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode:setFSImage(org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode:getNameNode()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode:setNameNode(org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode:startInfoServer()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode:doCheckpoint()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer:getLifelineRpcServer()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer:getClientRpcServer()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer:getServiceRpcServer()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer:getRpcAddress()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer:getAuxiliaryRpcAddresses()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer:rename(java.lang.String,java.lang.String)	java.lang.Deprecated
org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer:listOpenFiles(long)	java.lang.Deprecated
org.apache.hadoop.hdfs.server.namenode.NNStorage$NameNodeFile:getName()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.EditLogFileInputStream:readLogVersion(java.io.DataInputStream,boolean)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.EncryptionFaultInjector:getInstance()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.EncryptionFaultInjector:startFileNoKey()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.EncryptionFaultInjector:startFileBeforeGenerateKey()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.EncryptionFaultInjector:startFileAfterGenerateKey()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.EncryptionFaultInjector:reencryptEncryptedKeys()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.EncryptionFaultInjector:reencryptUpdaterProcessOneTask()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.EncryptionFaultInjector:reencryptUpdaterProcessCheckpoint()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.EncryptionFaultInjector:ensureKeyIsInitialized()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.FsImageProto$INodeSection$INode$Type:valueOf(int)	java.lang.Deprecated
org.apache.hadoop.hdfs.server.namenode.INodeFile:getErasureCodingPolicyID()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.INodeFile:isStriped()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.INodeFile:getBlockType()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.INodeFile:dumpTreeRecursively(java.io.PrintWriter,java.lang.StringBuilder,int)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.FSDirTruncateOp:prepareFileForTruncate(org.apache.hadoop.hdfs.server.namenode.FSNamesystem,org.apache.hadoop.hdfs.server.namenode.INodesInPath,java.lang.String,java.lang.String,long,org.apache.hadoop.hdfs.protocol.Block)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.FSDirectory:getReadHoldCount()	java.lang.Deprecated
org.apache.hadoop.hdfs.server.namenode.FSDirectory:getWriteHoldCount()	java.lang.Deprecated
org.apache.hadoop.hdfs.server.namenode.FSDirectory:parseProtectedDirectories(org.apache.hadoop.conf.Configuration)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.FSDirectory:parseProtectedDirectories(java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.FSDirectory:isPosixAclInheritanceEnabled()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.FSDirectory:setPosixAclInheritanceEnabled(boolean)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.FSDirectory:resolvePath(org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker,java.lang.String,org.apache.hadoop.hdfs.server.namenode.FSDirectory$DirOp)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.FSDirectory:addLastINode(org.apache.hadoop.hdfs.server.namenode.INodesInPath,org.apache.hadoop.hdfs.server.namenode.INode,org.apache.hadoop.fs.permission.FsPermission,boolean)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.FSDirectory:removeLastINode(org.apache.hadoop.hdfs.server.namenode.INodesInPath)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.FSDirectory:getYieldCount()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.FSDirectory:getInodeMapSize()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.FSDirectory:getINode(java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.FSDirectory:getINode4Write(java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.FSDirectory:getPermissionChecker(java.lang.String,java.lang.String,org.apache.hadoop.security.UserGroupInformation)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.FSImageFormat:useDefaultRenameReservedPairs()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.FSImageFormat:setRenameReservedPairs(java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.ReencryptionHandler$ReencryptionPendingInodeIdCollector:throttle()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.NameNodeResourceChecker:getVolumesLowOnSpace()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.NameNodeResourceChecker:setVolumes(java.util.Map)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.NameNodeResourceChecker:setMinimumReduntdantVolumes(int)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer:getEditLog()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer:setEditLog(org.apache.hadoop.hdfs.server.namenode.FSEditLog)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer:doTailEdits()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer:getNameNodeProxy()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer:triggerActiveLogRoll()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer:sleep(long)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.ha.StandbyCheckpointer:getCanceledCount()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.ha.StandbyCheckpointer:getActiveNNAddresses()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.sps.BlockStorageMovementAttemptedItems:blocksStorageMovementUnReportedItemsCheck()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.sps.BlockStorageMovementAttemptedItems:blockStorageMovementReportedItemsCheck()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.sps.BlockStorageMovementAttemptedItems:getMovementFinishedBlocksCount()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.sps.BlockStorageMovementAttemptedItems:getAttemptedItemsCount()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.sps.StoragePolicySatisfyManager:isSatisfierRunning()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.sps.StoragePolicySatisfier:getAttemptedItemsMonitor()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.sps.StoragePolicySatisfier:getStorageMovementQueue()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.sps.BlockStorageMovementNeeded:addAll(long,java.util.List,boolean)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.sps.BlockStorageMovementNeeded:add(org.apache.hadoop.hdfs.server.namenode.sps.ItemInfo,boolean)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.sps.BlockStorageMovementNeeded:setStatusClearanceElapsedTimeMs(long)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.sps.BlockStorageMovementNeeded:getStatusClearanceElapsedTimeMs()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.balancer.Dispatcher:isGoodBlockCandidate(org.apache.hadoop.hdfs.server.balancer.Dispatcher$DDatanode$StorageGroup,org.apache.hadoop.hdfs.server.balancer.Dispatcher$DDatanode$StorageGroup,org.apache.hadoop.fs.StorageType,org.apache.hadoop.hdfs.server.balancer.Dispatcher$DBlock)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.balancer.Dispatcher:setDelayAfterErrors(long)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.balancer.Dispatcher$PendingMove:<init>(org.apache.hadoop.hdfs.server.balancer.Dispatcher,org.apache.hadoop.hdfs.server.balancer.Dispatcher$Source,org.apache.hadoop.hdfs.server.balancer.Dispatcher$DDatanode$StorageGroup)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.balancer.Dispatcher$PendingMove:markMovedIfGoodBlock(org.apache.hadoop.hdfs.server.balancer.Dispatcher$DBlock,org.apache.hadoop.fs.StorageType)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.balancer.NameNodeConnector:setWrite2IdFile(boolean)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.balancer.NameNodeConnector:checkOtherInstanceRunning(boolean)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.protocol.DatanodeProtocol:registerDatanode(org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.server.protocol.DatanodeProtocol:sendHeartbeat(org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration,org.apache.hadoop.hdfs.server.protocol.StorageReport[],long,long,int,int,int,org.apache.hadoop.hdfs.server.protocol.VolumeFailureSummary,boolean,org.apache.hadoop.hdfs.server.protocol.SlowPeerReports,org.apache.hadoop.hdfs.server.protocol.SlowDiskReports)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.server.protocol.DatanodeProtocol:blockReport(org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration,java.lang.String,org.apache.hadoop.hdfs.server.protocol.StorageBlockReport[],org.apache.hadoop.hdfs.server.protocol.BlockReportContext)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.server.protocol.DatanodeProtocol:cacheReport(org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration,java.lang.String,java.util.List)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.server.protocol.DatanodeProtocol:blockReceivedAndDeleted(org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration,java.lang.String,org.apache.hadoop.hdfs.server.protocol.StorageReceivedDeletedBlocks[])	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.server.protocol.DatanodeProtocol:errorReport(org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration,int,java.lang.String)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.server.protocol.DatanodeProtocol:versionRequest()	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.server.protocol.DatanodeProtocol:reportBadBlocks(org.apache.hadoop.hdfs.protocol.LocatedBlock[])	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.server.protocol.DatanodeProtocol:commitBlockSynchronization(org.apache.hadoop.hdfs.protocol.ExtendedBlock,long,long,boolean,boolean,org.apache.hadoop.hdfs.protocol.DatanodeID[],java.lang.String[])	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.server.protocol.StorageReceivedDeletedBlocks:getStorageID()	java.lang.Deprecated
org.apache.hadoop.hdfs.server.protocol.StorageReceivedDeletedBlocks:<init>(java.lang.String,org.apache.hadoop.hdfs.server.protocol.ReceivedDeletedBlockInfo[])	java.lang.Deprecated
org.apache.hadoop.hdfs.server.protocol.DatanodeLifelineProtocol:sendLifeline(org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration,org.apache.hadoop.hdfs.server.protocol.StorageReport[],long,long,int,int,int,org.apache.hadoop.hdfs.server.protocol.VolumeFailureSummary)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration:<init>(java.lang.String,org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.protocol.NamespaceInfo:setCapabilities(long)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.protocol.NamespaceInfo:setState(org.apache.hadoop.ha.HAServiceProtocol$HAServiceState)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol:getBlocks(org.apache.hadoop.hdfs.protocol.DatanodeInfo,long,long)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol:getBlocks(org.apache.hadoop.hdfs.protocol.DatanodeInfo,long,long)	org.apache.hadoop.hdfs.server.namenode.ha.ReadOnly
org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol:getBlockKeys()	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol:getTransactionID()	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol:getMostRecentCheckpointTxId()	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol:rollEditLog()	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol:versionRequest()	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol:errorReport(org.apache.hadoop.hdfs.server.protocol.NamenodeRegistration,int,java.lang.String)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol:registerSubordinateNamenode(org.apache.hadoop.hdfs.server.protocol.NamenodeRegistration)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol:startCheckpoint(org.apache.hadoop.hdfs.server.protocol.NamenodeRegistration)	org.apache.hadoop.io.retry.AtMostOnce
org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol:endCheckpoint(org.apache.hadoop.hdfs.server.protocol.NamenodeRegistration,org.apache.hadoop.hdfs.server.namenode.CheckpointSignature)	org.apache.hadoop.io.retry.AtMostOnce
org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol:getEditLogManifest(long)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol:isUpgradeFinalized()	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol:isRollingUpgrade()	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol:getNextSPSPath()	org.apache.hadoop.io.retry.AtMostOnce
org.apache.hadoop.hdfs.server.aliasmap.InMemoryAliasMapProtocol:list(java.util.Optional)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.server.aliasmap.InMemoryAliasMapProtocol:read(org.apache.hadoop.hdfs.protocol.Block)	javax.annotation.Nonnull
org.apache.hadoop.hdfs.server.aliasmap.InMemoryAliasMapProtocol:read(org.apache.hadoop.hdfs.protocol.Block)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.server.aliasmap.InMemoryAliasMapProtocol:write(org.apache.hadoop.hdfs.protocol.Block,org.apache.hadoop.hdfs.protocol.ProvidedStorageLocation)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.server.aliasmap.InMemoryAliasMapProtocol:getBlockPoolId()	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.hdfs.server.aliasmap.InMemoryAliasMap:init(org.apache.hadoop.conf.Configuration,java.lang.String)	javax.annotation.Nonnull
org.apache.hadoop.hdfs.server.aliasmap.InMemoryAliasMap:<init>(java.net.URI,org.iq80.leveldb.DB,java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.aliasmap.InMemoryAliasMap:read(org.apache.hadoop.hdfs.protocol.Block)	javax.annotation.Nonnull
org.apache.hadoop.hdfs.server.aliasmap.InMemoryAliasMap:fromProvidedStorageLocationBytes(byte[])	javax.annotation.Nonnull
org.apache.hadoop.hdfs.server.aliasmap.InMemoryAliasMap:fromBlockBytes(byte[])	javax.annotation.Nonnull
org.apache.hadoop.hdfs.server.aliasmap.InMemoryLevelDBAliasMapServer:read(org.apache.hadoop.hdfs.protocol.Block)	javax.annotation.Nonnull
org.apache.hadoop.hdfs.net.DFSTopologyNodeImpl:getChildrenStorageInfo()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.net.DFSNetworkTopology:chooseRandomWithStorageType(java.lang.String,java.lang.String,java.util.Collection,org.apache.hadoop.fs.StorageType)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.protocolPB.InMemoryAliasMapProtocolClientSideTranslatorPB:read(org.apache.hadoop.hdfs.protocol.Block)	javax.annotation.Nonnull
org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB:<init>(org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolPB)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.DFSUtil:substituteForWildcardAddress(java.lang.String,java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.DFSUtil:addPBProtocol(org.apache.hadoop.conf.Configuration,java.lang.Class,com.google.protobuf.BlockingService,org.apache.hadoop.ipc.RPC$Server)	java.lang.Deprecated
org.apache.hadoop.hdfs.security.token.block.BlockPoolTokenSecretManager:get(java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.security.token.block.BlockPoolTokenSecretManager:clearAllKeysForTesting()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.security.token.block.BlockTokenSecretManager:setSerialNo(int)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.security.token.block.BlockTokenSecretManager:setKeyUpdateIntervalForTesting(long)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.security.token.block.BlockTokenSecretManager:clearAllKeysForTesting()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.security.token.block.BlockTokenSecretManager:hasKey(int)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.security.token.block.BlockTokenSecretManager:getSerialNoForTesting()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.util.ReferenceCountMap:getEntries()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.util.ReferenceCountMap:clear()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos$NamenodeCommandProto$Type:valueOf(int)	java.lang.Deprecated
org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos$NamenodeRegistrationProto$NamenodeRoleProto:valueOf(int)	java.lang.Deprecated
org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$DatanodeCommandProto$Type:valueOf(int)	java.lang.Deprecated
org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos$ReplicaStateProto:valueOf(int)	java.lang.Deprecated
org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$StorageReceivedDeletedBlocksProto$Builder:hasStorageUuid()	java.lang.Deprecated
org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$StorageReceivedDeletedBlocksProto$Builder:getStorageUuid()	java.lang.Deprecated
org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$StorageReceivedDeletedBlocksProto$Builder:getStorageUuidBytes()	java.lang.Deprecated
org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$StorageReceivedDeletedBlocksProto$Builder:setStorageUuid(java.lang.String)	java.lang.Deprecated
org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$StorageReceivedDeletedBlocksProto$Builder:clearStorageUuid()	java.lang.Deprecated
org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$StorageReceivedDeletedBlocksProto$Builder:setStorageUuidBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)	java.lang.Deprecated
org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$BlockIdCommandProto$Action:valueOf(int)	java.lang.Deprecated
org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$StorageReceivedDeletedBlocksProto:hasStorageUuid()	java.lang.Deprecated
org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$StorageReceivedDeletedBlocksProto:getStorageUuid()	java.lang.Deprecated
org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$StorageReceivedDeletedBlocksProto:getStorageUuidBytes()	java.lang.Deprecated
org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos$NNHAStatusHeartbeatProto$State:valueOf(int)	java.lang.Deprecated
org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$BlockCommandProto$Action:valueOf(int)	java.lang.Deprecated
org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$StorageReceivedDeletedBlocksProtoOrBuilder:hasStorageUuid()	java.lang.Deprecated
org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$StorageReceivedDeletedBlocksProtoOrBuilder:getStorageUuid()	java.lang.Deprecated
org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$StorageReceivedDeletedBlocksProtoOrBuilder:getStorageUuidBytes()	java.lang.Deprecated
org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$ErrorReportRequestProto$ErrorCode:valueOf(int)	java.lang.Deprecated
org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$ReceivedDeletedBlockInfoProto$BlockStatus:valueOf(int)	java.lang.Deprecated
org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferServer:getNegotiatedQOP()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.protocol.BlockListAsLongs:decodeBuffers(int,java.util.List)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.protocol.BlockListAsLongs:encode(java.util.Collection)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.protocol.BlockListAsLongs:builder()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.mapred.YarnChild:reportError(java.lang.Exception,org.apache.hadoop.mapred.Task,org.apache.hadoop.mapred.TaskUmbilicalProtocol)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.mapred.TaskAttemptListenerImpl:getAttemptIdToStatus()	org.apache.hadoop.classification.VisibleForTesting
org.apache.hadoop.mapred.LocalContainerLauncher:renameMapOutputForReduce(org.apache.hadoop.mapred.JobConf,org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId,org.apache.hadoop.mapred.MapOutputFile)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.mapreduce.v2.app.MRAppMaster:shutDownJob()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.mapreduce.v2.app.speculate.DefaultSpeculator:getSoonestRetryAfterNoSpeculate()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.mapreduce.v2.app.speculate.DefaultSpeculator:getSoonestRetryAfterSpeculate()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.mapreduce.v2.app.speculate.DefaultSpeculator:getProportionRunningTasksSpeculatable()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.mapreduce.v2.app.speculate.DefaultSpeculator:getProportionTotalTasksSpeculatable()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.mapreduce.v2.app.speculate.DefaultSpeculator:getMinimumAllowedSpeculativeTasks()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator:getAssignedRequests()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator:getAssignedRequests()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator:getScheduledRequests()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator:getScheduledRequests()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator:getNumOfPendingReduces()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator:getNumOfPendingReduces()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator:setReduceResourceRequest(org.apache.hadoop.yarn.api.records.Resource)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator:setReduceResourceRequest(org.apache.hadoop.yarn.api.records.Resource)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator:setMapResourceRequest(org.apache.hadoop.yarn.api.records.Resource)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator:setMapResourceRequest(org.apache.hadoop.yarn.api.records.Resource)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator:preemptReducesIfNeeded()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator:preemptReducesIfNeeded()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator:scheduleReduces(int,int,int,int,int,int,org.apache.hadoop.yarn.api.records.Resource,org.apache.hadoop.yarn.api.records.Resource,int,float,float)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator:scheduleAllReduces()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator:rampUpReduces(int)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator:rampDownReduces(int)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator:processFinishedContainer(org.apache.hadoop.yarn.api.records.ContainerStatus)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator:createContainerFinishedEvent(org.apache.hadoop.yarn.api.records.ContainerStatus,org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator:getResourceLimit()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor:getAsk()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor:getAsk()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator:doUnregistration()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator:isApplicationMasterRegistered()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl:getInternalState()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl:getInternalState()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl:getInternalState()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl:cleanupSharedCacheUploadPolicies(org.apache.hadoop.conf.Configuration)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl:constructFinalFullcounters()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl:decrementSucceededMapperCount()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.mapreduce.v2.app.webapp.ConfBlock:<init>(org.apache.hadoop.mapreduce.v2.app.AppContext)	com.google.inject.Inject
org.apache.hadoop.mapreduce.v2.app.webapp.AppController:<init>(org.apache.hadoop.mapreduce.v2.app.webapp.App,org.apache.hadoop.conf.Configuration,org.apache.hadoop.yarn.webapp.Controller$RequestContext)	com.google.inject.Inject
org.apache.hadoop.mapreduce.v2.app.webapp.App:<init>(org.apache.hadoop.mapreduce.v2.app.AppContext)	com.google.inject.Inject
org.apache.hadoop.mapreduce.v2.app.webapp.JobBlock:<init>(org.apache.hadoop.mapreduce.v2.app.AppContext)	com.google.inject.Inject
org.apache.hadoop.mapreduce.v2.app.webapp.TaskPage$AttemptsBlock:<init>(org.apache.hadoop.mapreduce.v2.app.webapp.App,org.apache.hadoop.conf.Configuration)	com.google.inject.Inject
org.apache.hadoop.mapreduce.v2.app.webapp.NavBlock:<init>(org.apache.hadoop.mapreduce.v2.app.webapp.App)	com.google.inject.Inject
org.apache.hadoop.mapreduce.v2.app.webapp.SingleCounterBlock:<init>(org.apache.hadoop.mapreduce.v2.app.AppContext,org.apache.hadoop.yarn.webapp.View$ViewContext)	com.google.inject.Inject
org.apache.hadoop.mapreduce.v2.app.webapp.dao.TaskAttemptsInfo:getTaskAttempts()	javax.xml.bind.annotation.XmlElementRef
org.apache.hadoop.mapreduce.v2.app.webapp.CountersBlock:<init>(org.apache.hadoop.mapreduce.v2.app.AppContext,org.apache.hadoop.yarn.webapp.View$ViewContext)	com.google.inject.Inject
org.apache.hadoop.mapreduce.v2.app.webapp.AttemptsPage$FewAttemptsBlock:<init>(org.apache.hadoop.mapreduce.v2.app.webapp.App,org.apache.hadoop.conf.Configuration)	com.google.inject.Inject
org.apache.hadoop.mapreduce.v2.app.webapp.TasksBlock:<init>(org.apache.hadoop.mapreduce.v2.app.webapp.App)	com.google.inject.Inject
org.apache.hadoop.mapreduce.v2.app.webapp.JobsBlock:<init>(org.apache.hadoop.mapreduce.v2.app.AppContext)	com.google.inject.Inject
org.apache.hadoop.mapreduce.v2.app.webapp.AMWebServices:<init>(org.apache.hadoop.mapreduce.v2.app.webapp.App,org.apache.hadoop.mapreduce.v2.app.AppContext)	com.google.inject.Inject
org.apache.hadoop.mapreduce.v2.app.webapp.AMWebServices:get()	javax.ws.rs.GET
org.apache.hadoop.mapreduce.v2.app.webapp.AMWebServices:get()	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.mapreduce.v2.app.webapp.AMWebServices:getAppInfo()	javax.ws.rs.GET
org.apache.hadoop.mapreduce.v2.app.webapp.AMWebServices:getAppInfo()	javax.ws.rs.Path	value	/info
org.apache.hadoop.mapreduce.v2.app.webapp.AMWebServices:getAppInfo()	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.mapreduce.v2.app.webapp.AMWebServices:getBlacklistedNodes()	javax.ws.rs.GET
org.apache.hadoop.mapreduce.v2.app.webapp.AMWebServices:getBlacklistedNodes()	javax.ws.rs.Path	value	/blacklistednodes
org.apache.hadoop.mapreduce.v2.app.webapp.AMWebServices:getBlacklistedNodes()	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.mapreduce.v2.app.webapp.AMWebServices:getJobs(javax.servlet.http.HttpServletRequest)	javax.ws.rs.GET
org.apache.hadoop.mapreduce.v2.app.webapp.AMWebServices:getJobs(javax.servlet.http.HttpServletRequest)	javax.ws.rs.Path	value	/jobs
org.apache.hadoop.mapreduce.v2.app.webapp.AMWebServices:getJobs(javax.servlet.http.HttpServletRequest)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.mapreduce.v2.app.webapp.AMWebServices:getJob(javax.servlet.http.HttpServletRequest,java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.mapreduce.v2.app.webapp.AMWebServices:getJob(javax.servlet.http.HttpServletRequest,java.lang.String)	javax.ws.rs.Path	value	/jobs/{jobid}
org.apache.hadoop.mapreduce.v2.app.webapp.AMWebServices:getJob(javax.servlet.http.HttpServletRequest,java.lang.String)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.mapreduce.v2.app.webapp.AMWebServices:getJobAttempts(java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.mapreduce.v2.app.webapp.AMWebServices:getJobAttempts(java.lang.String)	javax.ws.rs.Path	value	/jobs/{jobid}/jobattempts
org.apache.hadoop.mapreduce.v2.app.webapp.AMWebServices:getJobAttempts(java.lang.String)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.mapreduce.v2.app.webapp.AMWebServices:getJobCounters(javax.servlet.http.HttpServletRequest,java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.mapreduce.v2.app.webapp.AMWebServices:getJobCounters(javax.servlet.http.HttpServletRequest,java.lang.String)	javax.ws.rs.Path	value	/jobs/{jobid}/counters
org.apache.hadoop.mapreduce.v2.app.webapp.AMWebServices:getJobCounters(javax.servlet.http.HttpServletRequest,java.lang.String)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.mapreduce.v2.app.webapp.AMWebServices:getJobConf(javax.servlet.http.HttpServletRequest,java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.mapreduce.v2.app.webapp.AMWebServices:getJobConf(javax.servlet.http.HttpServletRequest,java.lang.String)	javax.ws.rs.Path	value	/jobs/{jobid}/conf
org.apache.hadoop.mapreduce.v2.app.webapp.AMWebServices:getJobConf(javax.servlet.http.HttpServletRequest,java.lang.String)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.mapreduce.v2.app.webapp.AMWebServices:getJobTasks(javax.servlet.http.HttpServletRequest,java.lang.String,java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.mapreduce.v2.app.webapp.AMWebServices:getJobTasks(javax.servlet.http.HttpServletRequest,java.lang.String,java.lang.String)	javax.ws.rs.Path	value	/jobs/{jobid}/tasks
org.apache.hadoop.mapreduce.v2.app.webapp.AMWebServices:getJobTasks(javax.servlet.http.HttpServletRequest,java.lang.String,java.lang.String)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.mapreduce.v2.app.webapp.AMWebServices:getJobTask(javax.servlet.http.HttpServletRequest,java.lang.String,java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.mapreduce.v2.app.webapp.AMWebServices:getJobTask(javax.servlet.http.HttpServletRequest,java.lang.String,java.lang.String)	javax.ws.rs.Path	value	/jobs/{jobid}/tasks/{taskid}
org.apache.hadoop.mapreduce.v2.app.webapp.AMWebServices:getJobTask(javax.servlet.http.HttpServletRequest,java.lang.String,java.lang.String)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.mapreduce.v2.app.webapp.AMWebServices:getSingleTaskCounters(javax.servlet.http.HttpServletRequest,java.lang.String,java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.mapreduce.v2.app.webapp.AMWebServices:getSingleTaskCounters(javax.servlet.http.HttpServletRequest,java.lang.String,java.lang.String)	javax.ws.rs.Path	value	/jobs/{jobid}/tasks/{taskid}/counters
org.apache.hadoop.mapreduce.v2.app.webapp.AMWebServices:getSingleTaskCounters(javax.servlet.http.HttpServletRequest,java.lang.String,java.lang.String)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.mapreduce.v2.app.webapp.AMWebServices:getJobTaskAttempts(javax.servlet.http.HttpServletRequest,java.lang.String,java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.mapreduce.v2.app.webapp.AMWebServices:getJobTaskAttempts(javax.servlet.http.HttpServletRequest,java.lang.String,java.lang.String)	javax.ws.rs.Path	value	/jobs/{jobid}/tasks/{taskid}/attempts
org.apache.hadoop.mapreduce.v2.app.webapp.AMWebServices:getJobTaskAttempts(javax.servlet.http.HttpServletRequest,java.lang.String,java.lang.String)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.mapreduce.v2.app.webapp.AMWebServices:getJobTaskAttemptId(javax.servlet.http.HttpServletRequest,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.mapreduce.v2.app.webapp.AMWebServices:getJobTaskAttemptId(javax.servlet.http.HttpServletRequest,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.Path	value	/jobs/{jobid}/tasks/{taskid}/attempts/{attemptid}
org.apache.hadoop.mapreduce.v2.app.webapp.AMWebServices:getJobTaskAttemptId(javax.servlet.http.HttpServletRequest,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.mapreduce.v2.app.webapp.AMWebServices:getJobTaskAttemptState(javax.servlet.http.HttpServletRequest,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.mapreduce.v2.app.webapp.AMWebServices:getJobTaskAttemptState(javax.servlet.http.HttpServletRequest,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.Path	value	/jobs/{jobid}/tasks/{taskid}/attempts/{attemptid}/state
org.apache.hadoop.mapreduce.v2.app.webapp.AMWebServices:getJobTaskAttemptState(javax.servlet.http.HttpServletRequest,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.mapreduce.v2.app.webapp.AMWebServices:updateJobTaskAttemptState(org.apache.hadoop.mapreduce.v2.app.webapp.dao.JobTaskAttemptState,javax.servlet.http.HttpServletRequest,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.PUT
org.apache.hadoop.mapreduce.v2.app.webapp.AMWebServices:updateJobTaskAttemptState(org.apache.hadoop.mapreduce.v2.app.webapp.dao.JobTaskAttemptState,javax.servlet.http.HttpServletRequest,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.Path	value	/jobs/{jobid}/tasks/{taskid}/attempts/{attemptid}/state
org.apache.hadoop.mapreduce.v2.app.webapp.AMWebServices:updateJobTaskAttemptState(org.apache.hadoop.mapreduce.v2.app.webapp.dao.JobTaskAttemptState,javax.servlet.http.HttpServletRequest,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.mapreduce.v2.app.webapp.AMWebServices:updateJobTaskAttemptState(org.apache.hadoop.mapreduce.v2.app.webapp.dao.JobTaskAttemptState,javax.servlet.http.HttpServletRequest,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.Consumes	value	{application/json,application/xml}
org.apache.hadoop.mapreduce.v2.app.webapp.AMWebServices:getJobTaskAttemptIdCounters(javax.servlet.http.HttpServletRequest,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.mapreduce.v2.app.webapp.AMWebServices:getJobTaskAttemptIdCounters(javax.servlet.http.HttpServletRequest,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.Path	value	/jobs/{jobid}/tasks/{taskid}/attempts/{attemptid}/counters
org.apache.hadoop.mapreduce.v2.app.webapp.AMWebServices:getJobTaskAttemptIdCounters(javax.servlet.http.HttpServletRequest,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.mapreduce.v2.app.TaskHeartbeatHandler:getRunningAttempts()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.mapreduce.v2.app.TaskHeartbeatHandler:getTaskTimeOut()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler:handleEvent(org.apache.hadoop.mapreduce.jobhistory.JobHistoryEvent)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler:getFlushTimerStatus()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.mapred.LocalJobRunner:<init>(org.apache.hadoop.mapred.JobConf)	java.lang.Deprecated
org.apache.hadoop.mapreduce.v2.proto.MRProtos$TaskStateProto:valueOf(int)	java.lang.Deprecated
org.apache.hadoop.mapreduce.v2.proto.MRProtos$JobStateProto:valueOf(int)	java.lang.Deprecated
org.apache.hadoop.mapreduce.v2.proto.MRProtos$TaskTypeProto:valueOf(int)	java.lang.Deprecated
org.apache.hadoop.mapreduce.v2.proto.MRProtos$TaskAttemptCompletionEventStatusProto:valueOf(int)	java.lang.Deprecated
org.apache.hadoop.mapreduce.v2.proto.MRProtos$PhaseProto:valueOf(int)	java.lang.Deprecated
org.apache.hadoop.mapreduce.v2.proto.MRProtos$TaskAttemptStateProto:valueOf(int)	java.lang.Deprecated
org.apache.hadoop.mapreduce.v2.util.MRApps:getSystemClasses(org.apache.hadoop.conf.Configuration)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.mapreduce.v2.util.MRApps:addToEnvironment(java.util.Map,java.lang.String,java.lang.String,org.apache.hadoop.conf.Configuration)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.mapreduce.v2.util.MRApps:addToEnvironment(java.util.Map,java.lang.String,java.lang.String,org.apache.hadoop.conf.Configuration)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.filecache.DistributedCache:addLocalArchives(org.apache.hadoop.conf.Configuration,java.lang.String)	java.lang.Deprecated
org.apache.hadoop.filecache.DistributedCache:addLocalFiles(org.apache.hadoop.conf.Configuration,java.lang.String)	java.lang.Deprecated
org.apache.hadoop.filecache.DistributedCache:createAllSymlink(org.apache.hadoop.conf.Configuration,java.io.File,java.io.File)	java.lang.Deprecated
org.apache.hadoop.filecache.DistributedCache:getFileStatus(org.apache.hadoop.conf.Configuration,java.net.URI)	java.lang.Deprecated
org.apache.hadoop.filecache.DistributedCache:getTimestamp(org.apache.hadoop.conf.Configuration,java.net.URI)	java.lang.Deprecated
org.apache.hadoop.filecache.DistributedCache:setArchiveTimestamps(org.apache.hadoop.conf.Configuration,java.lang.String)	java.lang.Deprecated
org.apache.hadoop.filecache.DistributedCache:setFileTimestamps(org.apache.hadoop.conf.Configuration,java.lang.String)	java.lang.Deprecated
org.apache.hadoop.filecache.DistributedCache:setLocalArchives(org.apache.hadoop.conf.Configuration,java.lang.String)	java.lang.Deprecated
org.apache.hadoop.filecache.DistributedCache:setLocalFiles(org.apache.hadoop.conf.Configuration,java.lang.String)	java.lang.Deprecated
org.apache.hadoop.mapred.jobcontrol.Job:setAssignedJobID(org.apache.hadoop.mapred.JobID)	java.lang.Deprecated
org.apache.hadoop.mapred.jobcontrol.Job:setState(int)	java.lang.Deprecated
org.apache.hadoop.mapred.jobcontrol.Job:setMapredJobID(java.lang.String)	java.lang.Deprecated
org.apache.hadoop.mapred.OutputCommitter:cleanupJob(org.apache.hadoop.mapred.JobContext)	java.lang.Deprecated
org.apache.hadoop.mapred.OutputCommitter:isRecoverySupported()	java.lang.Deprecated
org.apache.hadoop.mapred.OutputCommitter:cleanupJob(org.apache.hadoop.mapreduce.JobContext)	java.lang.Deprecated
org.apache.hadoop.mapred.LocatedFileStatusFetcher:getListeningExecutorService()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.mapred.JobID:read(java.io.DataInput)	java.lang.Deprecated
org.apache.hadoop.mapred.JobID:getJobIDsPattern(java.lang.String,java.lang.Integer)	java.lang.Deprecated
org.apache.hadoop.mapred.JobID:getJobIDsPatternWOPrefix(java.lang.String,java.lang.Integer)	java.lang.Deprecated
org.apache.hadoop.mapred.FileOutputCommitter:getJobAttemptPath(org.apache.hadoop.mapred.JobContext)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.mapred.FileOutputCommitter:getTaskAttemptPath(org.apache.hadoop.mapred.TaskAttemptContext)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.mapred.FileOutputCommitter:getCommittedTaskPath(org.apache.hadoop.mapred.TaskAttemptContext)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.mapred.FileOutputCommitter:cleanupJob(org.apache.hadoop.mapred.JobContext)	java.lang.Deprecated
org.apache.hadoop.mapred.FileOutputCommitter:isRecoverySupported()	java.lang.Deprecated
org.apache.hadoop.mapred.TaskCompletionEvent:downgrade(org.apache.hadoop.mapreduce.TaskCompletionEvent)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.mapred.TaskCompletionEvent:getTaskId()	java.lang.Deprecated
org.apache.hadoop.mapred.TaskCompletionEvent:setTaskId(java.lang.String)	java.lang.Deprecated
org.apache.hadoop.mapred.TaskCompletionEvent:setTaskID(org.apache.hadoop.mapred.TaskAttemptID)	java.lang.Deprecated
org.apache.hadoop.mapred.TaskCompletionEvent:setTaskStatus(org.apache.hadoop.mapred.TaskCompletionEvent$Status)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.mapred.TaskCompletionEvent:setTaskRunTime(int)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.mapred.TaskCompletionEvent:setEventId(int)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.mapred.TaskCompletionEvent:setTaskTrackerHttp(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.mapred.Task:setTaskDone()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.mapred.TaskID:<init>(org.apache.hadoop.mapreduce.JobID,boolean,int)	java.lang.Deprecated
org.apache.hadoop.mapred.TaskID:<init>(java.lang.String,int,boolean,int)	java.lang.Deprecated
org.apache.hadoop.mapred.TaskID:read(java.io.DataInput)	java.lang.Deprecated
org.apache.hadoop.mapred.TaskID:getTaskIDsPattern(java.lang.String,java.lang.Integer,java.lang.Boolean,java.lang.Integer)	java.lang.Deprecated
org.apache.hadoop.mapred.TaskID:getTaskIDsPattern(java.lang.String,java.lang.Integer,org.apache.hadoop.mapreduce.TaskType,java.lang.Integer)	java.lang.Deprecated
org.apache.hadoop.mapred.TaskID:getTaskIDsPatternWOPrefix(java.lang.String,java.lang.Integer,org.apache.hadoop.mapreduce.TaskType,java.lang.Integer)	java.lang.Deprecated
org.apache.hadoop.mapred.JobQueueInfo:setQueueName(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.mapred.JobQueueInfo:setSchedulingInfo(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.mapred.JobQueueInfo:setQueueState(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.mapred.JobQueueInfo:getQueueState()	java.lang.Deprecated
org.apache.hadoop.mapred.JobQueueInfo:setChildren(java.util.List)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.mapred.JobQueueInfo:setProperties(java.util.Properties)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.mapred.JobQueueInfo:setJobStatuses(org.apache.hadoop.mapreduce.JobStatus[])	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.mapred.JobClient:submitJobInternal(org.apache.hadoop.mapred.JobConf)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.mapred.JobClient:getJob(java.lang.String)	java.lang.Deprecated
org.apache.hadoop.mapred.JobClient:getMapTaskReports(java.lang.String)	java.lang.Deprecated
org.apache.hadoop.mapred.JobClient:getReduceTaskReports(java.lang.String)	java.lang.Deprecated
org.apache.hadoop.mapred.JobClient:setTaskOutputFilter(org.apache.hadoop.mapred.JobClient$TaskStatusFilter)	java.lang.Deprecated
org.apache.hadoop.mapred.JobClient:getTaskOutputFilter()	java.lang.Deprecated
org.apache.hadoop.mapred.Task$TaskReporter:<init>(org.apache.hadoop.mapred.Task,org.apache.hadoop.util.Progress,org.apache.hadoop.mapred.TaskUmbilicalProtocol)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.mapred.FileSplit:<init>(org.apache.hadoop.fs.Path,long,long,org.apache.hadoop.mapred.JobConf)	java.lang.Deprecated
org.apache.hadoop.mapred.FileSplit:getLocationInfo()	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.mapred.TaskReport:<init>(org.apache.hadoop.mapred.TaskID,float,java.lang.String,java.lang.String[],long,long,org.apache.hadoop.mapred.Counters)	java.lang.Deprecated
org.apache.hadoop.mapred.pipes.Application$PingSocketCleaner:closeSocketInternal(java.net.Socket)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.mapred.pipes.Submitter:submitJob(org.apache.hadoop.mapred.JobConf)	java.lang.Deprecated
org.apache.hadoop.mapred.FileOutputFormat:setWorkOutputPath(org.apache.hadoop.mapred.JobConf,org.apache.hadoop.fs.Path)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.mapred.JobStatus:<init>(org.apache.hadoop.mapred.JobID,float,float,float,int)	java.lang.Deprecated
org.apache.hadoop.mapred.JobStatus:<init>(org.apache.hadoop.mapred.JobID,float,float,int)	java.lang.Deprecated
org.apache.hadoop.mapred.JobStatus:<init>(org.apache.hadoop.mapred.JobID,float,float,float,int,org.apache.hadoop.mapred.JobPriority)	java.lang.Deprecated
org.apache.hadoop.mapred.JobStatus:<init>(org.apache.hadoop.mapred.JobID,float,float,float,float,int,org.apache.hadoop.mapred.JobPriority)	java.lang.Deprecated
org.apache.hadoop.mapred.JobStatus:getJobId()	java.lang.Deprecated
org.apache.hadoop.mapred.JobStatus:setRunState(int)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.mapred.JobStatus:setSchedulingInfo(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.mapred.JobClient$NetworkedJob:getJobID()	java.lang.Deprecated
org.apache.hadoop.mapred.JobClient$NetworkedJob:killTask(java.lang.String,boolean)	java.lang.Deprecated
org.apache.hadoop.mapred.Counters$Counter:contentEquals(org.apache.hadoop.mapred.Counters$Counter)	java.lang.Deprecated
org.apache.hadoop.mapred.RunningJob:getJobID()	java.lang.Deprecated
org.apache.hadoop.mapred.RunningJob:killTask(java.lang.String,boolean)	java.lang.Deprecated
org.apache.hadoop.mapred.JobConf:setCredentials(org.apache.hadoop.security.Credentials)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.mapred.JobConf:deleteLocalFiles()	java.lang.Deprecated
org.apache.hadoop.mapred.JobConf:getSessionId()	java.lang.Deprecated
org.apache.hadoop.mapred.JobConf:setSessionId(java.lang.String)	java.lang.Deprecated
org.apache.hadoop.mapred.JobConf:getMaxVirtualMemoryForTask()	java.lang.Deprecated
org.apache.hadoop.mapred.JobConf:setMaxVirtualMemoryForTask(long)	java.lang.Deprecated
org.apache.hadoop.mapred.JobConf:getMaxPhysicalMemoryForTask()	java.lang.Deprecated
org.apache.hadoop.mapred.JobConf:setMaxPhysicalMemoryForTask(long)	java.lang.Deprecated
org.apache.hadoop.mapred.JobConf:getTaskJavaOpts(org.apache.hadoop.mapreduce.TaskType)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.mapred.JobConf:parseMaximumHeapSizeMB(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.mapred.JobConf:parseMaximumHeapSizeMB(java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.mapred.JobConf:getMemoryRequired(org.apache.hadoop.mapreduce.TaskType)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.mapred.lib.TotalOrderPartitioner:setPartitionFile(org.apache.hadoop.mapred.JobConf,org.apache.hadoop.fs.Path)	java.lang.Deprecated
org.apache.hadoop.mapred.lib.TotalOrderPartitioner:getPartitionFile(org.apache.hadoop.mapred.JobConf)	java.lang.Deprecated
org.apache.hadoop.mapred.lib.CombineFileInputFormat:createPool(org.apache.hadoop.mapred.JobConf,java.util.List)	java.lang.Deprecated
org.apache.hadoop.mapred.lib.CombineFileInputFormat:createPool(org.apache.hadoop.mapred.JobConf,org.apache.hadoop.fs.PathFilter[])	java.lang.Deprecated
org.apache.hadoop.mapred.lib.CombineFileInputFormat:isSplitable(org.apache.hadoop.mapreduce.JobContext,org.apache.hadoop.fs.Path)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.mapred.lib.MultipleOutputs:setRecordWriters(java.util.Map)	org.apache.hadoop.classification.VisibleForTesting
org.apache.hadoop.mapred.JobProfile:<init>(java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	java.lang.Deprecated
org.apache.hadoop.mapred.JobProfile:getJobId()	java.lang.Deprecated
org.apache.hadoop.mapred.Counters:findCounter(java.lang.String,int,java.lang.String)	java.lang.Deprecated
org.apache.hadoop.mapred.Counters$Group:getCounter(int,java.lang.String)	java.lang.Deprecated
org.apache.hadoop.mapred.ClusterStatus:getGraylistedTrackerNames()	java.lang.Deprecated
org.apache.hadoop.mapred.ClusterStatus:getGraylistedTrackers()	java.lang.Deprecated
org.apache.hadoop.mapred.ClusterStatus:getMaxMemory()	java.lang.Deprecated
org.apache.hadoop.mapred.ClusterStatus:getUsedMemory()	java.lang.Deprecated
org.apache.hadoop.mapred.ClusterStatus:getJobTrackerState()	java.lang.Deprecated
org.apache.hadoop.mapred.TaskAttemptID:<init>(java.lang.String,int,boolean,int,int)	java.lang.Deprecated
org.apache.hadoop.mapred.TaskAttemptID:read(java.io.DataInput)	java.lang.Deprecated
org.apache.hadoop.mapred.TaskAttemptID:getTaskAttemptIDsPattern(java.lang.String,java.lang.Integer,java.lang.Boolean,java.lang.Integer,java.lang.Integer)	java.lang.Deprecated
org.apache.hadoop.mapred.TaskAttemptID:getTaskAttemptIDsPattern(java.lang.String,java.lang.Integer,org.apache.hadoop.mapreduce.TaskType,java.lang.Integer,java.lang.Integer)	java.lang.Deprecated
org.apache.hadoop.mapred.TaskAttemptID:getTaskAttemptIDsPatternWOPrefix(java.lang.String,java.lang.Integer,org.apache.hadoop.mapreduce.TaskType,java.lang.Integer,java.lang.Integer)	java.lang.Deprecated
org.apache.hadoop.mapreduce.OutputCommitter:cleanupJob(org.apache.hadoop.mapreduce.JobContext)	java.lang.Deprecated
org.apache.hadoop.mapreduce.OutputCommitter:isRecoverySupported()	java.lang.Deprecated
org.apache.hadoop.mapreduce.counters.FrameworkCounterGroup$FrameworkCounter:getKey()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.mapreduce.counters.FrameworkCounterGroup$FrameworkCounter:getGroupName()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.mapreduce.counters.AbstractCounters:<init>(org.apache.hadoop.mapreduce.counters.CounterGroupFactory)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.mapreduce.counters.AbstractCounters:<init>(org.apache.hadoop.mapreduce.counters.AbstractCounters,org.apache.hadoop.mapreduce.counters.CounterGroupFactory)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.mapreduce.counters.AbstractCounters:addGroup(org.apache.hadoop.mapreduce.counters.CounterGroupBase)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.mapreduce.counters.AbstractCounters:addGroup(java.lang.String,java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.mapreduce.counters.AbstractCounters:findCounter(java.lang.String,org.apache.hadoop.mapreduce.FileSystemCounter)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.mapreduce.counters.AbstractCounters:setWriteAllCounters(boolean)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.mapreduce.counters.AbstractCounters:getWriteAllCounters()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.mapreduce.counters.AbstractCounters:limits()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.mapreduce.counters.FileSystemCounterGroup$FSCounter:getScheme()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.mapreduce.counters.FileSystemCounterGroup$FSCounter:getFileSystemCounter()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.mapreduce.counters.GenericCounter:setDisplayName(java.lang.String)	java.lang.Deprecated
org.apache.hadoop.mapreduce.counters.CounterGroupBase:getUnderlyingGroup()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.mapreduce.counters.AbstractCounter:setDisplayName(java.lang.String)	java.lang.Deprecated
org.apache.hadoop.mapreduce.TaskID:<init>(org.apache.hadoop.mapreduce.JobID,boolean,int)	java.lang.Deprecated
org.apache.hadoop.mapreduce.TaskID:<init>(java.lang.String,int,boolean,int)	java.lang.Deprecated
org.apache.hadoop.mapreduce.TaskID:isMap()	java.lang.Deprecated
org.apache.hadoop.mapreduce.tools.CLI:getJob(org.apache.hadoop.mapreduce.JobID)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.mapreduce.tools.CLI:displayJobList(org.apache.hadoop.mapreduce.JobStatus[],java.io.PrintWriter)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.mapreduce.InputSplit:getLocationInfo()	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.mapreduce.JobSubmissionFiles:getStagingDir(org.apache.hadoop.mapreduce.Cluster,org.apache.hadoop.conf.Configuration,org.apache.hadoop.security.UserGroupInformation)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.mapreduce.Cluster:getAllJobs()	java.lang.Deprecated
org.apache.hadoop.mapreduce.task.reduce.ShuffleClientMetrics:getMetricsRegistry()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl:hostFailureCount(java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl:fetchFailureCount(org.apache.hadoop.mapreduce.TaskAttemptID)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl:getExceptionReporter()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl:getMaxInMemReduceLimit()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.mapreduce.task.reduce.Fetcher:<init>(org.apache.hadoop.mapred.JobConf,org.apache.hadoop.mapreduce.TaskAttemptID,org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl,org.apache.hadoop.mapreduce.task.reduce.MergeManager,org.apache.hadoop.mapred.Reporter,org.apache.hadoop.mapreduce.task.reduce.ShuffleClientMetrics,org.apache.hadoop.mapreduce.task.reduce.ExceptionReporter,javax.crypto.SecretKey,int)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.mapreduce.task.reduce.Fetcher:openConnection(java.net.URL)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.mapreduce.task.reduce.Fetcher:copyFromHost(org.apache.hadoop.mapreduce.task.reduce.MapHost)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.mapreduce.task.reduce.OnDiskMapOutput:<init>(org.apache.hadoop.mapreduce.TaskAttemptID,org.apache.hadoop.mapreduce.TaskAttemptID,org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl,long,org.apache.hadoop.mapred.JobConf,org.apache.hadoop.mapred.MapOutputFile,int,boolean)	java.lang.Deprecated
org.apache.hadoop.mapreduce.task.reduce.OnDiskMapOutput:<init>(org.apache.hadoop.mapreduce.TaskAttemptID,org.apache.hadoop.mapreduce.TaskAttemptID,org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl,long,org.apache.hadoop.mapred.JobConf,org.apache.hadoop.mapred.MapOutputFile,int,boolean,org.apache.hadoop.fs.FileSystem,org.apache.hadoop.fs.Path)	java.lang.Deprecated
org.apache.hadoop.mapreduce.task.reduce.OnDiskMapOutput:getTempPath(org.apache.hadoop.fs.Path,int)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.mapreduce.Counter:setDisplayName(java.lang.String)	java.lang.Deprecated
org.apache.hadoop.mapreduce.Counter:getUnderlyingCounter()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.mapreduce.JobContext:getSymlink()	java.lang.Deprecated
org.apache.hadoop.mapreduce.JobContext:getLocalCacheArchives()	java.lang.Deprecated
org.apache.hadoop.mapreduce.JobContext:getLocalCacheFiles()	java.lang.Deprecated
org.apache.hadoop.mapreduce.security.TokenCache:loadTokens(java.lang.String,org.apache.hadoop.mapred.JobConf)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.mapreduce.security.TokenCache:loadTokens(java.lang.String,org.apache.hadoop.mapred.JobConf)	java.lang.Deprecated
org.apache.hadoop.mapreduce.security.TokenCache:loadTokens(java.lang.String,org.apache.hadoop.conf.Configuration)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.mapreduce.security.TokenCache:loadTokens(java.lang.String,org.apache.hadoop.conf.Configuration)	java.lang.Deprecated
org.apache.hadoop.mapreduce.security.TokenCache:setJobToken(org.apache.hadoop.security.token.Token,org.apache.hadoop.security.Credentials)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.mapreduce.security.TokenCache:getJobToken(org.apache.hadoop.security.Credentials)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.mapreduce.security.TokenCache:setShuffleSecretKey(byte[],org.apache.hadoop.security.Credentials)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.mapreduce.security.TokenCache:getShuffleSecretKey(org.apache.hadoop.security.Credentials)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.mapreduce.security.TokenCache:setEncryptedSpillKey(byte[],org.apache.hadoop.security.Credentials)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.mapreduce.security.TokenCache:getEncryptedSpillKey(org.apache.hadoop.security.Credentials)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.mapreduce.security.TokenCache:getDelegationToken(org.apache.hadoop.security.Credentials,java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.mapreduce.security.TokenCache:getDelegationToken(org.apache.hadoop.security.Credentials,java.lang.String)	java.lang.Deprecated
org.apache.hadoop.mapreduce.Job:<init>()	java.lang.Deprecated
org.apache.hadoop.mapreduce.Job:<init>(org.apache.hadoop.conf.Configuration)	java.lang.Deprecated
org.apache.hadoop.mapreduce.Job:<init>(org.apache.hadoop.conf.Configuration,java.lang.String)	java.lang.Deprecated
org.apache.hadoop.mapreduce.Job:getInstance(org.apache.hadoop.mapreduce.Cluster)	java.lang.Deprecated
org.apache.hadoop.mapreduce.Job:getInstance(org.apache.hadoop.mapreduce.Cluster,org.apache.hadoop.conf.Configuration)	java.lang.Deprecated
org.apache.hadoop.mapreduce.Job:getInstance(org.apache.hadoop.mapreduce.Cluster,org.apache.hadoop.mapreduce.JobStatus,org.apache.hadoop.conf.Configuration)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.mapreduce.Job:getCluster()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.mapreduce.Job:setCluster(org.apache.hadoop.mapreduce.Cluster)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.mapreduce.Job:killTask(org.apache.hadoop.mapreduce.TaskAttemptID,boolean)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.mapreduce.Job:createSymlink()	java.lang.Deprecated
org.apache.hadoop.mapreduce.Job:addFileToSharedCache(java.net.URI,org.apache.hadoop.conf.Configuration)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.mapreduce.Job:addFileToSharedCacheAndClasspath(java.net.URI,org.apache.hadoop.conf.Configuration)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.mapreduce.Job:addArchiveToSharedCache(java.net.URI,org.apache.hadoop.conf.Configuration)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.mapreduce.Job:setFileSharedCacheUploadPolicies(org.apache.hadoop.conf.Configuration,java.util.Map)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.mapreduce.Job:setArchiveSharedCacheUploadPolicies(org.apache.hadoop.conf.Configuration,java.util.Map)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.mapreduce.Job:getFileSharedCacheUploadPolicies(org.apache.hadoop.conf.Configuration)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.mapreduce.Job:getArchiveSharedCacheUploadPolicies(org.apache.hadoop.conf.Configuration)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.mapreduce.Job:connect()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.mapreduce.Job:connect()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.mapreduce.Job:getJobSubmitter(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapreduce.protocol.ClientProtocol)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.mapreduce.Job:getJobSubmitter(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapreduce.protocol.ClientProtocol)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.mapreduce.lib.db.DBRecordReader:createValue()	java.lang.Deprecated
org.apache.hadoop.mapreduce.lib.db.DBRecordReader:getPos()	java.lang.Deprecated
org.apache.hadoop.mapreduce.lib.db.DBRecordReader:next(org.apache.hadoop.io.LongWritable,org.apache.hadoop.mapreduce.lib.db.DBWritable)	java.lang.Deprecated
org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter:<init>(org.apache.hadoop.fs.Path,org.apache.hadoop.mapreduce.JobContext)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter:commitJobInternal(org.apache.hadoop.mapreduce.JobContext)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter:cleanupJob(org.apache.hadoop.mapreduce.JobContext)	java.lang.Deprecated
org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter:commitTask(org.apache.hadoop.mapreduce.TaskAttemptContext,org.apache.hadoop.fs.Path)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter:abortTask(org.apache.hadoop.mapreduce.TaskAttemptContext,org.apache.hadoop.fs.Path)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter:needsTaskCommit(org.apache.hadoop.mapreduce.TaskAttemptContext,org.apache.hadoop.fs.Path)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter:isRecoverySupported()	java.lang.Deprecated
org.apache.hadoop.mapreduce.lib.output.PartialFileOutputCommitter:fsFor(org.apache.hadoop.fs.Path,org.apache.hadoop.conf.Configuration)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.mapreduce.lib.output.committer.manifest.stages.LoadManifestsStage:coalesceDirectories(org.apache.hadoop.mapreduce.lib.output.committer.manifest.files.TaskManifest)	org.apache.hadoop.classification.VisibleForTesting
org.apache.hadoop.mapreduce.lib.output.committer.manifest.ManifestCommitter:getTaskAttemptCommittedManifest()	org.apache.hadoop.classification.VisibleForTesting
org.apache.hadoop.mapreduce.lib.output.committer.manifest.ManifestCommitter:getTaskAttemptPath(org.apache.hadoop.mapreduce.TaskAttemptContext)	org.apache.hadoop.classification.VisibleForTesting
org.apache.hadoop.mapreduce.lib.output.committer.manifest.ManifestCommitter:getTaskManifestPath(org.apache.hadoop.mapreduce.TaskAttemptContext)	org.apache.hadoop.classification.VisibleForTesting
org.apache.hadoop.mapreduce.lib.output.committer.manifest.ManifestCommitter:getJobAttemptPath(org.apache.hadoop.mapreduce.JobContext)	org.apache.hadoop.classification.VisibleForTesting
org.apache.hadoop.mapreduce.lib.output.committer.manifest.files.TaskManifest:getTotalFileSize()	com.fasterxml.jackson.annotation.JsonIgnore
org.apache.hadoop.mapreduce.lib.output.committer.manifest.files.FileEntry:getSourcePath()	com.fasterxml.jackson.annotation.JsonIgnore
org.apache.hadoop.mapreduce.lib.output.committer.manifest.files.FileEntry:getDestPath()	com.fasterxml.jackson.annotation.JsonIgnore
org.apache.hadoop.mapreduce.lib.output.committer.manifest.files.DirEntry:getDestPath()	com.fasterxml.jackson.annotation.JsonIgnore
org.apache.hadoop.mapreduce.lib.output.committer.manifest.files.DirEntry:getStatus()	com.fasterxml.jackson.annotation.JsonIgnore
org.apache.hadoop.mapreduce.lib.output.committer.manifest.files.DirEntry:setStatus(org.apache.hadoop.mapreduce.lib.output.committer.manifest.files.EntryStatus)	com.fasterxml.jackson.annotation.JsonIgnore
org.apache.hadoop.mapreduce.lib.output.committer.manifest.files.ManifestSuccessData:getFilenamePaths()	com.fasterxml.jackson.annotation.JsonIgnore
org.apache.hadoop.mapreduce.lib.output.committer.manifest.files.ManifestSuccessData:setFilenamePaths(java.util.List)	com.fasterxml.jackson.annotation.JsonIgnore
org.apache.hadoop.mapreduce.lib.output.committer.manifest.impl.ManifestStoreOperations$CommitFileResult:getWaitTime()	javax.annotation.Nullable
org.apache.hadoop.mapreduce.lib.output.NullOutputFormat$2:isRecoverySupported()	java.lang.Deprecated
org.apache.hadoop.mapreduce.lib.output.MultipleOutputs:setRecordWriters(java.util.Map)	org.apache.hadoop.classification.VisibleForTesting
org.apache.hadoop.mapreduce.lib.input.FileSplit:getLocationInfo()	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.mapreduce.lib.input.CombineFileInputFormat$OneFileInfo:populateBlockInfo(org.apache.hadoop.mapreduce.lib.input.CombineFileInputFormat$OneBlockInfo[],java.util.Map,java.util.Map,java.util.Map,java.util.Map)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.mapreduce.lib.input.CombineFileInputFormat:createSplits(java.util.Map,java.util.Map,java.util.Map,long,long,long,long,java.util.List)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.mapreduce.JobResourceUploader:createSharedCacheClient(org.apache.hadoop.conf.Configuration)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.mapreduce.JobResourceUploader:uploadFiles(org.apache.hadoop.mapreduce.Job,java.util.Collection,org.apache.hadoop.fs.Path,org.apache.hadoop.fs.permission.FsPermission,short,java.util.Map,java.util.Map)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.mapreduce.JobResourceUploader:uploadLibJars(org.apache.hadoop.mapreduce.Job,java.util.Collection,org.apache.hadoop.fs.Path,org.apache.hadoop.fs.permission.FsPermission,short,java.util.Map,java.util.Map)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.mapreduce.JobResourceUploader:uploadArchives(org.apache.hadoop.mapreduce.Job,java.util.Collection,org.apache.hadoop.fs.Path,org.apache.hadoop.fs.permission.FsPermission,short,java.util.Map,java.util.Map)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.mapreduce.JobResourceUploader:uploadJobJar(org.apache.hadoop.mapreduce.Job,java.lang.String,org.apache.hadoop.fs.Path,short,java.util.Map)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.mapreduce.JobResourceUploader:checkLocalizationLimits(org.apache.hadoop.conf.Configuration,java.util.Collection,java.util.Collection,java.util.Collection,java.lang.String,java.util.Map)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.mapreduce.JobResourceUploader:stringToPath(java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.mapreduce.JobResourceUploader:getFileStatus(java.util.Map,org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.mapreduce.JobResourceUploader:mkdirs(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.fs.Path,org.apache.hadoop.fs.permission.FsPermission)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.mapreduce.JobResourceUploader:copyRemoteFiles(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path,org.apache.hadoop.conf.Configuration,short)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.mapreduce.JobResourceUploader:copyJar(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path,short)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.mapreduce.util.HostUtil:getTaskLogUrl(java.lang.String,java.lang.String,java.lang.String)	java.lang.Deprecated
org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser:parse(org.apache.hadoop.mapreduce.jobhistory.EventReader,org.apache.hadoop.mapreduce.jobhistory.HistoryEventHandler)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser:parse(org.apache.hadoop.mapreduce.jobhistory.EventReader)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.mapreduce.jobhistory.EventWriter:<init>(org.apache.hadoop.fs.FSDataOutputStream,org.apache.hadoop.mapreduce.jobhistory.EventWriter$WriteMode)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.mapreduce.jobhistory.EventWriter:close()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent:<init>(org.apache.hadoop.mapreduce.TaskAttemptID,org.apache.hadoop.mapreduce.TaskType,java.lang.String,long,long,java.lang.String,java.lang.String,org.apache.hadoop.mapreduce.Counters)	java.lang.Deprecated
org.apache.hadoop.mapreduce.TaskAttemptID:<init>(java.lang.String,int,boolean,int,int)	java.lang.Deprecated
org.apache.hadoop.mapreduce.TaskAttemptID:isMap()	java.lang.Deprecated
org.apache.hadoop.mapreduce.filecache.DistributedCache:setCacheArchives(java.net.URI[],org.apache.hadoop.conf.Configuration)	java.lang.Deprecated
org.apache.hadoop.mapreduce.filecache.DistributedCache:setCacheFiles(java.net.URI[],org.apache.hadoop.conf.Configuration)	java.lang.Deprecated
org.apache.hadoop.mapreduce.filecache.DistributedCache:getCacheArchives(org.apache.hadoop.conf.Configuration)	java.lang.Deprecated
org.apache.hadoop.mapreduce.filecache.DistributedCache:getCacheFiles(org.apache.hadoop.conf.Configuration)	java.lang.Deprecated
org.apache.hadoop.mapreduce.filecache.DistributedCache:getLocalCacheArchives(org.apache.hadoop.conf.Configuration)	java.lang.Deprecated
org.apache.hadoop.mapreduce.filecache.DistributedCache:getLocalCacheFiles(org.apache.hadoop.conf.Configuration)	java.lang.Deprecated
org.apache.hadoop.mapreduce.filecache.DistributedCache:getArchiveTimestamps(org.apache.hadoop.conf.Configuration)	java.lang.Deprecated
org.apache.hadoop.mapreduce.filecache.DistributedCache:getFileTimestamps(org.apache.hadoop.conf.Configuration)	java.lang.Deprecated
org.apache.hadoop.mapreduce.filecache.DistributedCache:addCacheArchive(java.net.URI,org.apache.hadoop.conf.Configuration)	java.lang.Deprecated
org.apache.hadoop.mapreduce.filecache.DistributedCache:addCacheFile(java.net.URI,org.apache.hadoop.conf.Configuration)	java.lang.Deprecated
org.apache.hadoop.mapreduce.filecache.DistributedCache:addFileToClassPath(org.apache.hadoop.fs.Path,org.apache.hadoop.conf.Configuration)	java.lang.Deprecated
org.apache.hadoop.mapreduce.filecache.DistributedCache:getFileClassPaths(org.apache.hadoop.conf.Configuration)	java.lang.Deprecated
org.apache.hadoop.mapreduce.filecache.DistributedCache:addArchiveToClassPath(org.apache.hadoop.fs.Path,org.apache.hadoop.conf.Configuration)	java.lang.Deprecated
org.apache.hadoop.mapreduce.filecache.DistributedCache:getArchiveClassPaths(org.apache.hadoop.conf.Configuration)	java.lang.Deprecated
org.apache.hadoop.mapreduce.filecache.DistributedCache:createSymlink(org.apache.hadoop.conf.Configuration)	java.lang.Deprecated
org.apache.hadoop.mapreduce.filecache.DistributedCache:getSymlink(org.apache.hadoop.conf.Configuration)	java.lang.Deprecated
org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager:createHistoryDirs(org.apache.hadoop.yarn.util.Clock,long,long)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager:tryCreatingHistoryDirs(boolean)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager:scanDirectory(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.FileContext,org.apache.hadoop.fs.PathFilter)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager:setMaxHistoryAge(long)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.mapreduce.v2.hs.JobHistory:getHistoryStorage()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.mapreduce.v2.hs.HistoryClientService:initializeWebApp(org.apache.hadoop.conf.Configuration)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.mapreduce.v2.hs.HistoryClientService:getClientHandler()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.mapreduce.v2.hs.HistoryClientService:getBindAddress()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.mapreduce.v2.hs.server.HSAdminServer:getLoginUGI()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.mapreduce.v2.hs.server.HSAdminServer:setLoginUGI(org.apache.hadoop.security.UserGroupInformation)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager$HistoryFileInfo:<init>(org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager,org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path,org.apache.hadoop.mapreduce.v2.jobhistory.JobIndexInfo,boolean)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager$HistoryFileInfo:isMovePending()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager$HistoryFileInfo:didMoveFail()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager$HistoryFileInfo:moveToDone()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.mapreduce.v2.hs.JobHistoryServer:createHistoryClientService()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.mapreduce.v2.hs.JobHistoryServer:getClientService()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.mapreduce.v2.hs.webapp.HsAttemptsPage$FewAttemptsBlock:<init>(org.apache.hadoop.mapreduce.v2.app.webapp.App,org.apache.hadoop.conf.Configuration)	com.google.inject.Inject
org.apache.hadoop.mapreduce.v2.hs.webapp.HsWebServices:<init>(org.apache.hadoop.mapreduce.v2.hs.HistoryContext,org.apache.hadoop.conf.Configuration,org.apache.hadoop.yarn.webapp.WebApp,org.apache.hadoop.yarn.api.ApplicationClientProtocol)	com.google.inject.Inject
org.apache.hadoop.mapreduce.v2.hs.webapp.HsWebServices:setResponse(javax.servlet.http.HttpServletResponse)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.mapreduce.v2.hs.webapp.HsWebServices:get()	javax.ws.rs.GET
org.apache.hadoop.mapreduce.v2.hs.webapp.HsWebServices:get()	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.mapreduce.v2.hs.webapp.HsWebServices:getHistoryInfo()	javax.ws.rs.GET
org.apache.hadoop.mapreduce.v2.hs.webapp.HsWebServices:getHistoryInfo()	javax.ws.rs.Path	value	/info
org.apache.hadoop.mapreduce.v2.hs.webapp.HsWebServices:getHistoryInfo()	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.mapreduce.v2.hs.webapp.HsWebServices:getJobs(java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.mapreduce.v2.hs.webapp.HsWebServices:getJobs(java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.Path	value	/mapreduce/jobs
org.apache.hadoop.mapreduce.v2.hs.webapp.HsWebServices:getJobs(java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.mapreduce.v2.hs.webapp.HsWebServices:getJob(javax.servlet.http.HttpServletRequest,java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.mapreduce.v2.hs.webapp.HsWebServices:getJob(javax.servlet.http.HttpServletRequest,java.lang.String)	javax.ws.rs.Path	value	/mapreduce/jobs/{jobid}
org.apache.hadoop.mapreduce.v2.hs.webapp.HsWebServices:getJob(javax.servlet.http.HttpServletRequest,java.lang.String)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.mapreduce.v2.hs.webapp.HsWebServices:getJobAttempts(java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.mapreduce.v2.hs.webapp.HsWebServices:getJobAttempts(java.lang.String)	javax.ws.rs.Path	value	/mapreduce/jobs/{jobid}/jobattempts
org.apache.hadoop.mapreduce.v2.hs.webapp.HsWebServices:getJobAttempts(java.lang.String)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.mapreduce.v2.hs.webapp.HsWebServices:getJobCounters(javax.servlet.http.HttpServletRequest,java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.mapreduce.v2.hs.webapp.HsWebServices:getJobCounters(javax.servlet.http.HttpServletRequest,java.lang.String)	javax.ws.rs.Path	value	/mapreduce/jobs/{jobid}/counters
org.apache.hadoop.mapreduce.v2.hs.webapp.HsWebServices:getJobCounters(javax.servlet.http.HttpServletRequest,java.lang.String)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.mapreduce.v2.hs.webapp.HsWebServices:getJobConf(javax.servlet.http.HttpServletRequest,java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.mapreduce.v2.hs.webapp.HsWebServices:getJobConf(javax.servlet.http.HttpServletRequest,java.lang.String)	javax.ws.rs.Path	value	/mapreduce/jobs/{jobid}/conf
org.apache.hadoop.mapreduce.v2.hs.webapp.HsWebServices:getJobConf(javax.servlet.http.HttpServletRequest,java.lang.String)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.mapreduce.v2.hs.webapp.HsWebServices:getJobTasks(javax.servlet.http.HttpServletRequest,java.lang.String,java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.mapreduce.v2.hs.webapp.HsWebServices:getJobTasks(javax.servlet.http.HttpServletRequest,java.lang.String,java.lang.String)	javax.ws.rs.Path	value	/mapreduce/jobs/{jobid}/tasks
org.apache.hadoop.mapreduce.v2.hs.webapp.HsWebServices:getJobTasks(javax.servlet.http.HttpServletRequest,java.lang.String,java.lang.String)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.mapreduce.v2.hs.webapp.HsWebServices:getJobTask(javax.servlet.http.HttpServletRequest,java.lang.String,java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.mapreduce.v2.hs.webapp.HsWebServices:getJobTask(javax.servlet.http.HttpServletRequest,java.lang.String,java.lang.String)	javax.ws.rs.Path	value	/mapreduce/jobs/{jobid}/tasks/{taskid}
org.apache.hadoop.mapreduce.v2.hs.webapp.HsWebServices:getJobTask(javax.servlet.http.HttpServletRequest,java.lang.String,java.lang.String)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.mapreduce.v2.hs.webapp.HsWebServices:getSingleTaskCounters(javax.servlet.http.HttpServletRequest,java.lang.String,java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.mapreduce.v2.hs.webapp.HsWebServices:getSingleTaskCounters(javax.servlet.http.HttpServletRequest,java.lang.String,java.lang.String)	javax.ws.rs.Path	value	/mapreduce/jobs/{jobid}/tasks/{taskid}/counters
org.apache.hadoop.mapreduce.v2.hs.webapp.HsWebServices:getSingleTaskCounters(javax.servlet.http.HttpServletRequest,java.lang.String,java.lang.String)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.mapreduce.v2.hs.webapp.HsWebServices:getJobTaskAttempts(javax.servlet.http.HttpServletRequest,java.lang.String,java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.mapreduce.v2.hs.webapp.HsWebServices:getJobTaskAttempts(javax.servlet.http.HttpServletRequest,java.lang.String,java.lang.String)	javax.ws.rs.Path	value	/mapreduce/jobs/{jobid}/tasks/{taskid}/attempts
org.apache.hadoop.mapreduce.v2.hs.webapp.HsWebServices:getJobTaskAttempts(javax.servlet.http.HttpServletRequest,java.lang.String,java.lang.String)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.mapreduce.v2.hs.webapp.HsWebServices:getJobTaskAttemptId(javax.servlet.http.HttpServletRequest,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.mapreduce.v2.hs.webapp.HsWebServices:getJobTaskAttemptId(javax.servlet.http.HttpServletRequest,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.Path	value	/mapreduce/jobs/{jobid}/tasks/{taskid}/attempts/{attemptid}
org.apache.hadoop.mapreduce.v2.hs.webapp.HsWebServices:getJobTaskAttemptId(javax.servlet.http.HttpServletRequest,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.mapreduce.v2.hs.webapp.HsWebServices:getJobTaskAttemptIdCounters(javax.servlet.http.HttpServletRequest,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.mapreduce.v2.hs.webapp.HsWebServices:getJobTaskAttemptIdCounters(javax.servlet.http.HttpServletRequest,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.Path	value	/mapreduce/jobs/{jobid}/tasks/{taskid}/attempts/{attemptid}/counters
org.apache.hadoop.mapreduce.v2.hs.webapp.HsWebServices:getJobTaskAttemptIdCounters(javax.servlet.http.HttpServletRequest,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.mapreduce.v2.hs.webapp.HsWebServices:getAggregatedLogsMeta(javax.servlet.http.HttpServletRequest,java.lang.String,java.lang.String,java.lang.String,java.lang.String,boolean,boolean)	javax.ws.rs.GET
org.apache.hadoop.mapreduce.v2.hs.webapp.HsWebServices:getAggregatedLogsMeta(javax.servlet.http.HttpServletRequest,java.lang.String,java.lang.String,java.lang.String,java.lang.String,boolean,boolean)	javax.ws.rs.Path	value	/aggregatedlogs
org.apache.hadoop.mapreduce.v2.hs.webapp.HsWebServices:getAggregatedLogsMeta(javax.servlet.http.HttpServletRequest,java.lang.String,java.lang.String,java.lang.String,java.lang.String,boolean,boolean)	javax.ws.rs.Produces	value	{application/json,application/xml}
org.apache.hadoop.mapreduce.v2.hs.webapp.HsWebServices:getAggregatedLogsMeta(javax.servlet.http.HttpServletRequest,java.lang.String,java.lang.String,java.lang.String,java.lang.String,boolean,boolean)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.mapreduce.v2.hs.webapp.HsWebServices:getAggregatedLogsMeta(javax.servlet.http.HttpServletRequest,java.lang.String,java.lang.String,java.lang.String,java.lang.String,boolean,boolean)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.mapreduce.v2.hs.webapp.HsWebServices:getContainerLogs(javax.servlet.http.HttpServletRequest,java.lang.String,java.lang.String,boolean,boolean)	javax.ws.rs.GET
org.apache.hadoop.mapreduce.v2.hs.webapp.HsWebServices:getContainerLogs(javax.servlet.http.HttpServletRequest,java.lang.String,java.lang.String,boolean,boolean)	javax.ws.rs.Path	value	/containers/{containerid}/logs
org.apache.hadoop.mapreduce.v2.hs.webapp.HsWebServices:getContainerLogs(javax.servlet.http.HttpServletRequest,java.lang.String,java.lang.String,boolean,boolean)	javax.ws.rs.Produces	value	{application/json,application/xml}
org.apache.hadoop.mapreduce.v2.hs.webapp.HsWebServices:getContainerLogs(javax.servlet.http.HttpServletRequest,java.lang.String,java.lang.String,boolean,boolean)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.mapreduce.v2.hs.webapp.HsWebServices:getContainerLogs(javax.servlet.http.HttpServletRequest,java.lang.String,java.lang.String,boolean,boolean)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.mapreduce.v2.hs.webapp.HsWebServices:getContainerLogFile(javax.servlet.http.HttpServletRequest,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,boolean,boolean)	javax.ws.rs.GET
org.apache.hadoop.mapreduce.v2.hs.webapp.HsWebServices:getContainerLogFile(javax.servlet.http.HttpServletRequest,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,boolean,boolean)	javax.ws.rs.Path	value	/containerlogs/{containerid}/{filename}
org.apache.hadoop.mapreduce.v2.hs.webapp.HsWebServices:getContainerLogFile(javax.servlet.http.HttpServletRequest,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,boolean,boolean)	javax.ws.rs.Produces	value	{text/plain; charset=utf-8}
org.apache.hadoop.mapreduce.v2.hs.webapp.HsWebServices:getContainerLogFile(javax.servlet.http.HttpServletRequest,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,boolean,boolean)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.mapreduce.v2.hs.webapp.HsWebServices:getContainerLogFile(javax.servlet.http.HttpServletRequest,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,boolean,boolean)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.mapreduce.v2.hs.webapp.HsWebServices:getLogServlet()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.mapreduce.v2.hs.webapp.HsWebServices:setLogServlet(org.apache.hadoop.yarn.server.webapp.LogServlet)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.mapreduce.v2.hs.webapp.HsJobBlock:<init>(org.apache.hadoop.mapreduce.v2.app.AppContext)	com.google.inject.Inject
org.apache.hadoop.mapreduce.v2.hs.webapp.HsController:<init>(org.apache.hadoop.mapreduce.v2.app.webapp.App,org.apache.hadoop.conf.Configuration,org.apache.hadoop.yarn.webapp.Controller$RequestContext)	com.google.inject.Inject
org.apache.hadoop.mapreduce.v2.hs.webapp.HsNavBlock:<init>(org.apache.hadoop.mapreduce.v2.app.webapp.App)	com.google.inject.Inject
org.apache.hadoop.mapreduce.v2.hs.webapp.HsJobsBlock:<init>(org.apache.hadoop.conf.Configuration,org.apache.hadoop.mapreduce.v2.app.AppContext,org.apache.hadoop.yarn.webapp.View$ViewContext)	com.google.inject.Inject
org.apache.hadoop.mapreduce.v2.hs.webapp.HsTaskPage$AttemptsBlock:<init>(org.apache.hadoop.mapreduce.v2.app.webapp.App,org.apache.hadoop.conf.Configuration)	com.google.inject.Inject
org.apache.hadoop.mapreduce.v2.hs.webapp.HsTasksBlock:<init>(org.apache.hadoop.mapreduce.v2.app.webapp.App)	com.google.inject.Inject
org.apache.hadoop.mapreduce.v2.hs.CachedHistoryStorage:createConf()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.mapreduce.v2.hs.CachedHistoryStorage:getLoadedJobCache()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.mapreduce.v2.hs.CachedHistoryStorage:getUseLoadedTasksCache()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.mapreduce.v2.hs.CachedHistoryStorage:getLoadedTasksCacheSize()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.mapred.YARNRunner:setResourceMgrDelegate(org.apache.hadoop.mapred.ResourceMgrDelegate)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.mapred.YARNRunner:addHistoryToken(org.apache.hadoop.security.Credentials)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.mapred.YARNRunner:getDelegationTokenFromHS(org.apache.hadoop.mapreduce.v2.api.MRClientProtocol)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.mapred.ClientServiceDelegate:getMaxClientRetry()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.mapred.nativetask.NativeRuntime:JNICreateDefaultNativeObject(byte[])	java.lang.Deprecated
org.apache.hadoop.mapred.FadvisedFileRegion:customShuffleTransfer(java.nio.channels.WritableByteChannel,long)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.mapred.ShuffleHandler:loadVersion()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.mapred.ShuffleHandler:storeVersion(org.apache.hadoop.yarn.server.records.Version)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.mapred.FadvisedChunkedFile:getFd()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.mapred.uploader.FrameworkUploader:setConf(org.apache.hadoop.conf.Configuration)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.mapred.uploader.FrameworkUploader:collectPackages()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.mapred.uploader.FrameworkUploader:beginUpload()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.mapred.uploader.FrameworkUploader:buildPackage()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.mapred.uploader.FrameworkUploader:expandEnvironmentVariables(java.lang.String,java.util.Map)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.mapred.uploader.FrameworkUploader:checkSymlink(java.io.File)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.mapred.uploader.FrameworkUploader:parseArguments(java.lang.String[])	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.aliyun.oss.AliyunOSSFileSystem:getDefaultBlockSize()	java.lang.Deprecated
org.apache.hadoop.tools.HadoopArchiveLogs:prepareWorkingDir(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.fs.Path)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.tools.HadoopArchiveLogs:filterAppsByAggregatedStatus()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.tools.HadoopArchiveLogs:checkFilesAndSeedApps(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.fs.Path,java.lang.String,org.apache.hadoop.fs.Path)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.tools.HadoopArchiveLogs:checkMaxEligible()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.tools.HadoopArchiveLogs:generateScript(java.io.File)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.s3a.ArnResource:accessPointFromArn(java.lang.String)	javax.annotation.Nonnull
org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider:<init>(org.apache.hadoop.fs.s3native.S3xLoginHelper$Login)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.s3a.S3AFileStatus:getETag()	java.lang.Deprecated
org.apache.hadoop.fs.s3a.s3guard.S3Guard:getAuthoritativePaths(java.net.URI,org.apache.hadoop.conf.Configuration,java.util.function.Function)	org.apache.hadoop.classification.VisibleForTesting
org.apache.hadoop.fs.s3a.tools.MarkerTool:execute(org.apache.hadoop.fs.s3a.tools.MarkerTool$ScanArgs)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.s3a.S3ALocatedFileStatus:getETag()	java.lang.Deprecated
org.apache.hadoop.fs.s3a.prefetch.S3ARemoteInputStream:getS3AStreamStatistics()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.fs.s3a.prefetch.S3ARemoteInputStream:getS3AStreamStatistics()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.fs.s3a.prefetch.S3APrefetchingInputStream:getS3AStreamStatistics()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.fs.s3a.prefetch.S3APrefetchingInputStream:getS3AStreamStatistics()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.fs.s3a.prefetch.S3APrefetchingInputStream:getS3AStreamStatistics()	org.apache.hadoop.classification.VisibleForTesting
org.apache.hadoop.fs.s3a.Listing:toProvidedFileStatusIterator(org.apache.hadoop.fs.s3a.S3AFileStatus[])	org.apache.hadoop.classification.VisibleForTesting
org.apache.hadoop.fs.s3a.Listing:createLocatedFileStatusIterator(org.apache.hadoop.fs.RemoteIterator)	org.apache.hadoop.classification.VisibleForTesting
org.apache.hadoop.fs.s3a.select.SelectInputStream:getS3AStreamStatistics()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.fs.s3a.select.SelectInputStream:getS3AStreamStatistics()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.fs.s3a.select.SelectInputStream:toString()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.fs.s3a.S3AUtils:lookupPassword(java.lang.String,org.apache.hadoop.conf.Configuration,java.lang.String,java.lang.String)	java.lang.Deprecated
org.apache.hadoop.fs.s3a.S3AUtils:createAwsConf(org.apache.hadoop.conf.Configuration,java.lang.String)	java.lang.Deprecated
org.apache.hadoop.fs.s3a.S3AUtils:closeAll(org.slf4j.Logger,java.io.Closeable[])	java.lang.Deprecated
org.apache.hadoop.fs.s3a.S3AInstrumentation:getMetricsSystem()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.s3a.S3AInstrumentation:hasMetricSystem()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.s3a.DefaultS3ClientFactory:createEndpointConfiguration(java.lang.String,com.amazonaws.ClientConfiguration,java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.s3a.commit.AbstractS3ACommitter:initOutput(org.apache.hadoop.fs.Path)	org.apache.hadoop.classification.VisibleForTesting
org.apache.hadoop.fs.s3a.commit.AbstractS3ACommitter:getUUID()	org.apache.hadoop.classification.VisibleForTesting
org.apache.hadoop.fs.s3a.commit.AbstractS3ACommitter:getUUIDSource()	org.apache.hadoop.classification.VisibleForTesting
org.apache.hadoop.fs.s3a.commit.AbstractS3ACommitter:preCommitJob(org.apache.hadoop.fs.s3a.commit.impl.CommitContext,org.apache.hadoop.fs.s3a.commit.AbstractS3ACommitter$ActiveCommit)	org.apache.hadoop.classification.VisibleForTesting
org.apache.hadoop.fs.s3a.commit.staging.Paths:resetTempFolderCache()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.s3a.commit.staging.Paths:getMultipartUploadCommitsDirectory(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.conf.Configuration,java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.s3a.AWSCredentialProviderList:getProviders()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.s3a.AWSCredentialProviderList:getRefCount()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.s3a.AWSCredentialProviderList:isClosed()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.s3a.auth.AbstractSessionCredentialsProvider:getInitializationException()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.s3a.auth.AssumedRoleCredentialProvider:sanitize(java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.s3a.auth.delegation.S3ADelegationTokens:resetTokenBindingToDT(org.apache.hadoop.security.token.Token)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.s3a.auth.delegation.S3ADelegationTokens:bindToDelegationToken(org.apache.hadoop.security.token.Token)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.s3a.auth.delegation.S3ADelegationTokens:createDelegationToken(org.apache.hadoop.fs.s3a.auth.delegation.EncryptionSecrets,org.apache.hadoop.io.Text)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.s3a.auth.delegation.S3ADelegationTokens:selectTokenFromFSOwner()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.s3a.auth.delegation.S3ADelegationTokens:getTokenService(java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.s3a.auth.delegation.S3ADelegationTokens:lookupToken(org.apache.hadoop.security.Credentials,org.apache.hadoop.io.Text,org.apache.hadoop.io.Text)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.s3a.statistics.impl.BondedS3AStatisticsContext$S3AFSStatisticsSource:getInstanceStatistics()	javax.annotation.Nullable
org.apache.hadoop.fs.s3a.S3AOpContext:getStats()	javax.annotation.Nullable
org.apache.hadoop.fs.s3a.S3AFileSystem:getInstrumentation()	org.apache.hadoop.classification.VisibleForTesting
org.apache.hadoop.fs.s3a.S3AFileSystem:getFsStatistics()	org.apache.hadoop.classification.VisibleForTesting
org.apache.hadoop.fs.s3a.S3AFileSystem:getAuditManager()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.fs.s3a.S3AFileSystem:getAuditor()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.fs.s3a.S3AFileSystem:getActiveAuditSpan()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.fs.s3a.S3AFileSystem:getAuditSpanSource()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.fs.s3a.S3AFileSystem:getRequestFactory()	org.apache.hadoop.classification.VisibleForTesting
org.apache.hadoop.fs.s3a.S3AFileSystem:createDelegationOperations()	org.apache.hadoop.classification.VisibleForTesting
org.apache.hadoop.fs.s3a.S3AFileSystem:setUri(java.net.URI,boolean)	org.apache.hadoop.classification.VisibleForTesting
org.apache.hadoop.fs.s3a.S3AFileSystem:getDefaultPort()	org.apache.hadoop.classification.VisibleForTesting
org.apache.hadoop.fs.s3a.S3AFileSystem:getAmazonS3ClientForTesting(java.lang.String)	org.apache.hadoop.classification.VisibleForTesting
org.apache.hadoop.fs.s3a.S3AFileSystem:getBucketLocation()	org.apache.hadoop.classification.InterfaceAudience$LimitedPrivate	value	{diagnostics}
org.apache.hadoop.fs.s3a.S3AFileSystem:getBucketLocation(java.lang.String)	org.apache.hadoop.classification.VisibleForTesting
org.apache.hadoop.fs.s3a.S3AFileSystem:getInputPolicy()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.fs.s3a.S3AFileSystem:getChangeDetectionPolicy()	org.apache.hadoop.classification.VisibleForTesting
org.apache.hadoop.fs.s3a.S3AFileSystem:setBucket(java.lang.String)	org.apache.hadoop.classification.VisibleForTesting
org.apache.hadoop.fs.s3a.S3AFileSystem:setInputPolicy(org.apache.hadoop.fs.s3a.S3AInputPolicy)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.fs.s3a.S3AFileSystem:setInputPolicy(org.apache.hadoop.fs.s3a.S3AInputPolicy)	java.lang.Deprecated
org.apache.hadoop.fs.s3a.S3AFileSystem:pathToKey(org.apache.hadoop.fs.Path)	org.apache.hadoop.classification.VisibleForTesting
org.apache.hadoop.fs.s3a.S3AFileSystem:maybeAddTrailingSlash(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.fs.s3a.S3AFileSystem:createReadContext(org.apache.hadoop.fs.FileStatus,org.apache.hadoop.fs.store.audit.AuditSpan)	org.apache.hadoop.classification.VisibleForTesting
org.apache.hadoop.fs.s3a.S3AFileSystem:getWriteOperationHelper()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.fs.s3a.S3AFileSystem:createWriteOperationHelper(org.apache.hadoop.fs.store.audit.AuditSpan)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.fs.s3a.S3AFileSystem:getObjectMetadata(org.apache.hadoop.fs.Path)	org.apache.hadoop.classification.InterfaceAudience$LimitedPrivate	value	{utilities}
org.apache.hadoop.fs.s3a.S3AFileSystem:getObjectMetadata(org.apache.hadoop.fs.Path)	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.fs.s3a.S3AFileSystem:getObjectMetadata(org.apache.hadoop.fs.Path)	org.apache.hadoop.classification.VisibleForTesting
org.apache.hadoop.fs.s3a.S3AFileSystem:getObjectMetadata(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$LimitedPrivate	value	{external utilities}
org.apache.hadoop.fs.s3a.S3AFileSystem:getObjectMetadata(java.lang.String)	org.apache.hadoop.classification.VisibleForTesting
org.apache.hadoop.fs.s3a.S3AFileSystem:deleteObject(java.lang.String)	org.apache.hadoop.classification.VisibleForTesting
org.apache.hadoop.fs.s3a.S3AFileSystem:putObjectDirect(com.amazonaws.services.s3.model.PutObjectRequest,org.apache.hadoop.fs.s3a.impl.PutObjectOptions,org.apache.hadoop.fs.statistics.DurationTrackerFactory)	org.apache.hadoop.classification.VisibleForTesting
org.apache.hadoop.fs.s3a.S3AFileSystem:removeKeys(java.util.List,boolean)	org.apache.hadoop.classification.VisibleForTesting
org.apache.hadoop.fs.s3a.S3AFileSystem:deleteWithoutCloseCheck(org.apache.hadoop.fs.Path,boolean)	org.apache.hadoop.classification.VisibleForTesting
org.apache.hadoop.fs.s3a.S3AFileSystem:maybeCreateFakeParentDirectory(org.apache.hadoop.fs.Path)	org.apache.hadoop.classification.VisibleForTesting
org.apache.hadoop.fs.s3a.S3AFileSystem:createListObjectsRequest(java.lang.String,java.lang.String)	org.apache.hadoop.classification.VisibleForTesting
org.apache.hadoop.fs.s3a.S3AFileSystem:createMkdirOperationCallbacks()	org.apache.hadoop.classification.VisibleForTesting
org.apache.hadoop.fs.s3a.S3AFileSystem:innerGetFileStatus(org.apache.hadoop.fs.Path,boolean,java.util.Set)	org.apache.hadoop.classification.VisibleForTesting
org.apache.hadoop.fs.s3a.S3AFileSystem:s3GetFileStatus(org.apache.hadoop.fs.Path,java.lang.String,java.util.Set,boolean)	org.apache.hadoop.classification.VisibleForTesting
org.apache.hadoop.fs.s3a.S3AFileSystem:getDelegationTokens()	org.apache.hadoop.classification.VisibleForTesting
org.apache.hadoop.fs.s3a.S3AFileSystem:listAWSPolicyRules(java.util.Set)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.fs.s3a.S3AFileSystem:finishedWrite(java.lang.String,long,java.lang.String,java.lang.String,org.apache.hadoop.fs.s3a.impl.PutObjectOptions)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.fs.s3a.S3AFileSystem:listFilesAndEmptyDirectories(org.apache.hadoop.fs.Path,boolean)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.fs.s3a.S3AFileSystem:listUploads(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.fs.s3a.S3AFileSystem:listMultipartUploads(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.fs.s3a.S3AFileSystem:hasCapability(java.lang.String)	java.lang.Deprecated
org.apache.hadoop.fs.s3a.S3AFileSystem:createStoreContext()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.fs.s3a.S3AFileSystem:createMarkerToolOperations(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.fs.s3a.S3AFileSystem:initializeClass()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.fs.s3a.S3AFileSystem:getActiveAuditSpan()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.fs.s3a.impl.SDKStreamDrainer:applyRaisingException()	org.apache.hadoop.classification.VisibleForTesting
org.apache.hadoop.fs.s3a.impl.ChangeDetectionPolicy:createPolicy(org.apache.hadoop.fs.s3a.impl.ChangeDetectionPolicy$Mode,org.apache.hadoop.fs.s3a.impl.ChangeDetectionPolicy$Source,boolean)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.s3a.impl.ChangeTracker:getVersionMismatches()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.s3a.impl.S3AMultipartUploader:buildPartHandlePayload(java.lang.String,java.lang.String,int,java.lang.String,long)	org.apache.hadoop.classification.VisibleForTesting
org.apache.hadoop.fs.s3a.impl.S3AMultipartUploader:parsePartHandlePayload(byte[])	org.apache.hadoop.classification.VisibleForTesting
org.apache.hadoop.fs.s3a.S3AInputStream:getInputPolicy()	org.apache.hadoop.classification.VisibleForTesting
org.apache.hadoop.fs.s3a.S3AInputStream:resetConnection()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.fs.s3a.S3AInputStream:remainingInFile()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.fs.s3a.S3AInputStream:remainingInFile()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.fs.s3a.S3AInputStream:remainingInCurrentRequest()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.fs.s3a.S3AInputStream:remainingInCurrentRequest()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.fs.s3a.S3AInputStream:getContentRangeFinish()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.fs.s3a.S3AInputStream:getContentRangeFinish()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.fs.s3a.S3AInputStream:getContentRangeStart()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.fs.s3a.S3AInputStream:getContentRangeStart()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.fs.s3a.S3AInputStream:toString()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.fs.s3a.S3AInputStream:getS3AStreamStatistics()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.fs.s3a.S3AInputStream:getS3AStreamStatistics()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.fs.s3a.S3AInputStream:getS3AStreamStatistics()	org.apache.hadoop.classification.VisibleForTesting
org.apache.hadoop.fs.s3a.S3AInputStream:isObjectStreamOpen()	org.apache.hadoop.classification.VisibleForTesting
org.apache.hadoop.fs.s3a.S3AInstrumentation$InputStreamStatistics:toString()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.fs.s3a.audit.impl.ActiveAuditManagerS3A:prune()	org.apache.hadoop.classification.VisibleForTesting
org.apache.hadoop.fs.s3a.audit.impl.ActiveAuditManagerS3A:removeActiveSpanFromMap()	org.apache.hadoop.classification.VisibleForTesting
org.apache.hadoop.fs.s3a.audit.impl.ActiveAuditManagerS3A:getActiveSpanMap()	org.apache.hadoop.classification.VisibleForTesting
org.apache.hadoop.fs.s3native.S3xLoginHelper:extractLoginDetails(java.net.URI)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.adl.AdlFileSystem:getTokenProvider()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.adl.AdlFileSystem:getAzureTokenProvider()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.adl.AdlFileSystem:getAdlClient()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.adl.AdlFileSystem:rename(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Options$Rename[])	java.lang.Deprecated
org.apache.hadoop.fs.adl.AdlFileSystem:getTransportScheme()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.adl.AdlFileSystem:toRelativeFilePath(org.apache.hadoop.fs.Path)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.adl.AdlFileSystem:getDefaultBlockSize()	java.lang.Deprecated
org.apache.hadoop.fs.adl.AdlFileSystem:getBlockSize(org.apache.hadoop.fs.Path)	java.lang.Deprecated
org.apache.hadoop.fs.adl.AdlFileSystem:getReplication(org.apache.hadoop.fs.Path)	java.lang.Deprecated
org.apache.hadoop.fs.adl.AdlFileSystem:setUserGroupRepresentationAsUPN(boolean)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azure.PageBlobOutputStream:waitForLastFlushCompletion()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azure.PageBlobOutputStream:sync()	java.lang.Deprecated
org.apache.hadoop.fs.azure.PageBlobOutputStream:killIoThreads()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azure.NativeAzureFileSystem$FolderRenamePending:deleteRenamePendingFile(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.fs.Path)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azure.NativeAzureFileSystem$FolderRenamePending:renameFile(org.apache.hadoop.fs.azure.FileMetadata)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azure.NativeFileSystemStore:purge(java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azure.RemoteWasbAuthorizerImpl:updateWasbRemoteCallHelper(org.apache.hadoop.fs.azure.WasbRemoteCallHelper)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azure.AzureFileSystemThreadPoolExecutor:getThreadPool(int)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azure.NativeAzureFileSystem$NativeAzureFsOutputStream:getOutStream()	org.apache.hadoop.classification.InterfaceAudience$LimitedPrivate	value	{HDFS}
org.apache.hadoop.fs.azure.ClientThrottlingAnalyzer:getSleepDuration()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azure.AzureNativeFileSystemStore:suppressRetryPolicy()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azure.AzureNativeFileSystemStore:addTestHookToOperationContext(org.apache.hadoop.fs.azure.AzureNativeFileSystemStore$TestHookOperationContext)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azure.AzureNativeFileSystemStore:setAzureStorageInteractionLayer(org.apache.hadoop.fs.azure.StorageInterface)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azure.AzureNativeFileSystemStore:getBandwidthGaugeUpdater()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azure.AzureNativeFileSystemStore:getAccountKeyFromConfiguration(java.lang.String,org.apache.hadoop.conf.Configuration)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azure.NativeAzureFileSystem:suppressRetryPolicy()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azure.NativeAzureFileSystem:resumeRetryPolicy()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azure.NativeAzureFileSystem:newMetricsSourceName()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azure.NativeAzureFileSystem:updateWasbAuthorizer(org.apache.hadoop.fs.azure.WasbAuthorizerInterface)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azure.NativeAzureFileSystem:pathToKey(org.apache.hadoop.fs.Path)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azure.NativeAzureFileSystem:makeAbsolute(org.apache.hadoop.fs.Path)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azure.NativeAzureFileSystem:getStore()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azure.NativeAzureFileSystem:delete(org.apache.hadoop.fs.Path)	java.lang.Deprecated
org.apache.hadoop.fs.azure.NativeAzureFileSystem:deleteFile(java.lang.String,boolean)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azure.NativeAzureFileSystem:createPermissionStatus(org.apache.hadoop.fs.permission.FsPermission)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azure.NativeAzureFileSystem:prepareAtomicFolderRename(java.lang.String,java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azure.NativeAzureFileSystem:getOwnerForPath(org.apache.hadoop.fs.Path)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azure.NativeAzureFileSystem:updateChownAllowedUsers(java.util.List)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azure.NativeAzureFileSystem:updateChmodAllowedUsers(java.util.List)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azure.NativeAzureFileSystem:updateDaemonUsers(java.util.List)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azure.WasbRemoteCallHelper:updateHttpClient(org.apache.http.client.HttpClient)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azure.WasbFsck:setMockFileSystemForTesting(org.apache.hadoop.fs.FileSystem)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azure.SyncableDataOutputStream:getOutStream()	org.apache.hadoop.classification.InterfaceAudience$LimitedPrivate	value	{HDFS}
org.apache.hadoop.fs.azure.BlockBlobAppendStream:setMaxBlockSize(int)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azure.BlockBlobAppendStream:setCompactionBlockCount(int)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azure.BlockBlobAppendStream:getBlockList()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azurebfs.oauth2.CustomTokenProviderAdapter:getCustomTokenProviderAdaptee()	org.apache.hadoop.classification.VisibleForTesting
org.apache.hadoop.fs.azurebfs.AbfsCountersImpl:toMap()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azurebfs.services.ReadBufferManager:getThresholdAgeMilliseconds()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azurebfs.services.ReadBufferManager:setThresholdAgeMilliseconds(int)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azurebfs.services.ReadBufferManager:getCompletedReadListSize()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azurebfs.services.ReadBufferManager:getCompletedReadListCopy()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azurebfs.services.ReadBufferManager:getFreeListCopy()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azurebfs.services.ReadBufferManager:getReadAheadQueueCopy()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azurebfs.services.ReadBufferManager:getInProgressCopiedList()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azurebfs.services.ReadBufferManager:callTryEvict()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azurebfs.services.ReadBufferManager:testResetReadBufferManager()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azurebfs.services.ReadBufferManager:resetBufferManager()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azurebfs.services.ReadBufferManager:testResetReadBufferManager(int,int)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azurebfs.services.ReadBufferManager:setBlockSize(int)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azurebfs.services.ReadBufferManager:getReadAheadBlockSize()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azurebfs.services.ReadBufferManager:testMimicFullUseAndAddFailedBuffer(org.apache.hadoop.fs.azurebfs.services.ReadBuffer)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azurebfs.services.ReadBufferManager:getNumBuffers()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azurebfs.services.AbfsCounters:toMap()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azurebfs.services.AbfsOutputStreamStatisticsImpl:getBytesToUpload()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azurebfs.services.AbfsOutputStreamStatisticsImpl:getBytesUploadSuccessful()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azurebfs.services.AbfsOutputStreamStatisticsImpl:getBytesUploadFailed()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azurebfs.services.AbfsOutputStreamStatisticsImpl:getTimeSpentOnTaskWait()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azurebfs.services.AbfsOutputStreamStatisticsImpl:getQueueShrunkOps()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azurebfs.services.AbfsOutputStreamStatisticsImpl:getWriteCurrentBufferOperations()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azurebfs.services.AbfsOutputStreamStatisticsImpl:getTimeSpentOnPutRequest()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azurebfs.services.AbfsInputStreamStatisticsImpl:getSeekOperations()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azurebfs.services.AbfsInputStreamStatisticsImpl:getForwardSeekOperations()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azurebfs.services.AbfsInputStreamStatisticsImpl:getBackwardSeekOperations()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azurebfs.services.AbfsInputStreamStatisticsImpl:getBytesRead()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azurebfs.services.AbfsInputStreamStatisticsImpl:getBytesSkippedOnSeek()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azurebfs.services.AbfsInputStreamStatisticsImpl:getBytesBackwardsOnSeek()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azurebfs.services.AbfsInputStreamStatisticsImpl:getSeekInBuffer()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azurebfs.services.AbfsInputStreamStatisticsImpl:getReadOperations()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azurebfs.services.AbfsInputStreamStatisticsImpl:getBytesReadFromBuffer()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azurebfs.services.AbfsInputStreamStatisticsImpl:getRemoteReadOperations()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azurebfs.services.AbfsInputStreamStatisticsImpl:getReadAheadBytesRead()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azurebfs.services.AbfsInputStreamStatisticsImpl:getRemoteBytesRead()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azurebfs.services.AbfsInputStreamStatisticsImpl:getActionHttpGetRequest()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azurebfs.services.AbfsRestOperation:getClientLatency()	org.apache.hadoop.classification.VisibleForTesting
org.apache.hadoop.fs.azurebfs.services.AbfsRestOperation:signRequest(org.apache.hadoop.fs.azurebfs.services.AbfsHttpOperation,int)	org.apache.hadoop.classification.VisibleForTesting
org.apache.hadoop.fs.azurebfs.services.AbfsRestOperation:createHttpOperation()	org.apache.hadoop.classification.VisibleForTesting
org.apache.hadoop.fs.azurebfs.services.ExponentialRetryPolicy:getRetryCount()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azurebfs.services.ExponentialRetryPolicy:getMinBackoff()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azurebfs.services.ExponentialRetryPolicy:getMaxBackoff()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azurebfs.services.ExponentialRetryPolicy:getDeltaBackoff()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azurebfs.services.AbfsOutputStream:waitForPendingUploads()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azurebfs.services.AbfsOutputStream:getOutputStreamStatistics()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azurebfs.services.AbfsOutputStream:getWriteOperationsSize()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azurebfs.services.AbfsOutputStream:getMaxConcurrentRequestCount()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azurebfs.services.AbfsOutputStream:getMaxRequestsThatCanBeQueued()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azurebfs.services.AbfsOutputStream:isAppendBlobStream()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azurebfs.services.AbfsOutputStream:isLeaseFreed()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azurebfs.services.AbfsOutputStream:hasLease()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azurebfs.services.AbfsInputStream:isReadAheadEnabled()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azurebfs.services.AbfsInputStream:getReadAheadRange()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azurebfs.services.AbfsInputStream:setCachedSasToken(org.apache.hadoop.fs.azurebfs.utils.CachedSASToken)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azurebfs.services.AbfsInputStream:getStreamID()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azurebfs.services.AbfsInputStream:getStreamStatistics()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azurebfs.services.AbfsInputStream:registerListener(org.apache.hadoop.fs.azurebfs.utils.Listener)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azurebfs.services.AbfsInputStream:getBytesFromReadAhead()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azurebfs.services.AbfsInputStream:getBytesFromRemoteRead()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azurebfs.services.AbfsInputStream:getBufferSize()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azurebfs.services.AbfsInputStream:getReadAheadQueueDepth()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azurebfs.services.AbfsInputStream:shouldAlwaysReadBufferSize()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azurebfs.services.AbfsInputStream:getBCursor()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azurebfs.services.AbfsInputStream:getFCursor()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azurebfs.services.AbfsInputStream:getFCursorAfterLastRead()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azurebfs.services.AbfsInputStream:getLimit()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azurebfs.services.AbfsLease:<init>(org.apache.hadoop.fs.azurebfs.services.AbfsClient,java.lang.String,int,int,org.apache.hadoop.fs.azurebfs.utils.TracingContext)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azurebfs.services.AbfsLease:getAcquireRetryCount()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azurebfs.services.AbfsLease:getTracingContext()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azurebfs.services.AbfsClientThrottlingAnalyzer:getSleepDuration()	org.apache.hadoop.classification.VisibleForTesting
org.apache.hadoop.fs.azurebfs.services.AbfsClient:createRenameRestOperation(java.net.URL,java.util.List)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azurebfs.services.AbfsClient:isSourceDestEtagEqual(java.lang.String,org.apache.hadoop.fs.azurebfs.services.AbfsHttpOperation)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azurebfs.services.AbfsClient:getAbfsRestOperationForAppend(org.apache.hadoop.fs.azurebfs.services.AbfsRestOperationType,java.lang.String,java.net.URL,java.util.List,byte[],int,int,java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azurebfs.services.AbfsClient:createRequestUrl(java.lang.String,java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azurebfs.services.AbfsClient:initializeUserAgent(org.apache.hadoop.fs.azurebfs.AbfsConfiguration,java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azurebfs.services.AbfsClient:getBaseUrl()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azurebfs.services.AbfsClient:getSasTokenProvider()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azurebfs.services.AbfsClient:getTokenProvider()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azurebfs.utils.CachedSASToken:setForTesting(java.lang.String,java.time.OffsetDateTime)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azurebfs.AzureBlobFileSystemStore:getURIBuilder(java.lang.String,boolean)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azurebfs.AzureBlobFileSystemStore:listStatus(org.apache.hadoop.fs.Path,java.lang.String,org.apache.hadoop.fs.azurebfs.utils.TracingContext)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.fs.azurebfs.AzureBlobFileSystemStore:getClient()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azurebfs.AzureBlobFileSystemStore:setClient(org.apache.hadoop.fs.azurebfs.services.AbfsClient)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azurebfs.AzureBlobFileSystemStore:setNamespaceEnabled(org.apache.hadoop.fs.azurebfs.enums.Trilean)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azurebfs.AzureBlobFileSystemStore:areLeasesFreed()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azurebfs.security.AbfsDelegationTokenManager:getTokenManager()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azurebfs.AbfsConfiguration:setReadAheadEnabled(boolean)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azurebfs.AbfsConfiguration:setReadBufferSize(int)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azurebfs.AbfsConfiguration:setWriteBufferSize(int)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azurebfs.AbfsConfiguration:setEnableFlush(boolean)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azurebfs.AbfsConfiguration:setDisableOutputStreamFlush(boolean)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azurebfs.AbfsConfiguration:setListMaxResults(int)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azurebfs.AbfsConfiguration:setMaxIoRetries(int)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azurebfs.AbfsConfiguration:setMaxBackoffIntervalMilliseconds(int)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azurebfs.AbfsConfiguration:setIsNamespaceEnabledAccount(java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azurebfs.AbfsConfiguration:setReadSmallFilesCompletely(boolean)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azurebfs.AbfsConfiguration:setOptimizeFooterRead(boolean)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azurebfs.AbfsConfiguration:setEnableAbfsListIterator(boolean)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.fs.azurebfs.AzureBlobFileSystem:createResilientCommitSupport(org.apache.hadoop.fs.Path)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.fs.azurebfs.AzureBlobFileSystem:execute(java.lang.String,java.util.concurrent.Callable)	org.apache.hadoop.classification.VisibleForTesting
org.apache.hadoop.fs.azurebfs.AzureBlobFileSystem:execute(java.lang.String,java.util.concurrent.Callable,java.lang.Object)	org.apache.hadoop.classification.VisibleForTesting
org.apache.hadoop.fs.azurebfs.AzureBlobFileSystem:checkException(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.azurebfs.contracts.exceptions.AzureBlobFileSystemException,org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode[])	org.apache.hadoop.classification.VisibleForTesting
org.apache.hadoop.fs.azurebfs.AzureBlobFileSystem:getFsStatistics()	org.apache.hadoop.classification.VisibleForTesting
org.apache.hadoop.fs.azurebfs.AzureBlobFileSystem:setListenerOperation(org.apache.hadoop.fs.azurebfs.constants.FSOperationType)	org.apache.hadoop.classification.VisibleForTesting
org.apache.hadoop.fs.azurebfs.AzureBlobFileSystem:getAbfsStore()	org.apache.hadoop.classification.VisibleForTesting
org.apache.hadoop.fs.azurebfs.AzureBlobFileSystem:getAbfsClient()	org.apache.hadoop.classification.VisibleForTesting
org.apache.hadoop.fs.azurebfs.AzureBlobFileSystem:getDelegationTokenManager()	org.apache.hadoop.classification.VisibleForTesting
org.apache.hadoop.fs.azurebfs.AzureBlobFileSystem:getIsNamespaceEnabled(org.apache.hadoop.fs.azurebfs.utils.TracingContext)	org.apache.hadoop.classification.VisibleForTesting
org.apache.hadoop.fs.azurebfs.AzureBlobFileSystem:getInstrumentationMap()	org.apache.hadoop.classification.VisibleForTesting
org.apache.hadoop.fs.azurebfs.AzureBlobFileSystem:getFileSystemId()	org.apache.hadoop.classification.VisibleForTesting
org.apache.hadoop.fs.azurebfs.AzureBlobFileSystem:getClientCorrelationId()	org.apache.hadoop.classification.VisibleForTesting
org.apache.hadoop.benchmark.VectoredReadBenchmark:asyncRead(org.apache.hadoop.benchmark.VectoredReadBenchmark$FileSystemChoice,org.apache.hadoop.benchmark.VectoredReadBenchmark$BufferChoice,org.openjdk.jmh.infra.Blackhole)	org.openjdk.jmh.annotations.Benchmark
org.apache.hadoop.benchmark.VectoredReadBenchmark:asyncFileChanArray(org.apache.hadoop.benchmark.VectoredReadBenchmark$BufferChoice,org.openjdk.jmh.infra.Blackhole)	org.openjdk.jmh.annotations.Benchmark
org.apache.hadoop.benchmark.VectoredReadBenchmark:syncRead(org.apache.hadoop.benchmark.VectoredReadBenchmark$FileSystemChoice,org.openjdk.jmh.infra.Blackhole)	org.openjdk.jmh.annotations.Benchmark
org.apache.hadoop.benchmark.VectoredReadBenchmark$BufferChoice:setup()	org.openjdk.jmh.annotations.Setup	value	Trial
org.apache.hadoop.benchmark.VectoredReadBenchmark$FileSystemChoice:setup()	org.openjdk.jmh.annotations.Setup	value	Trial
org.apache.hadoop.tools.mapred.RetriableFileCopyCommand:copyBytes(org.apache.hadoop.tools.CopyListingFileStatus,long,java.io.OutputStream,int,org.apache.hadoop.mapreduce.Mapper$Context)	org.apache.hadoop.classification.VisibleForTesting
org.apache.hadoop.tools.mapred.RetriableFileCopyCommand:getNumBytesToRead(long,long,long)	org.apache.hadoop.classification.VisibleForTesting
org.apache.hadoop.tools.RegexCopyFilter:setFilters(java.util.List)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.tools.SimpleCopyListing:<init>(org.apache.hadoop.conf.Configuration,org.apache.hadoop.security.Credentials,int,int,boolean)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.tools.SimpleCopyListing:doBuildListingWithSnapshotDiff(org.apache.hadoop.io.SequenceFile$Writer,org.apache.hadoop.tools.DistCpContext)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.tools.SimpleCopyListing:doBuildListing(org.apache.hadoop.io.SequenceFile$Writer,org.apache.hadoop.tools.DistCpContext)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.tools.SimpleCopyListing:setSeedForRandomListing(long)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.tools.DistCpOptions$Builder:withSourcePaths(java.util.List)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.tools.DistCpOptions$Builder:withCRC(boolean)	java.lang.Deprecated
org.apache.hadoop.tools.DistCp:<init>()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.tools.DistCpSync:setCopyFilter(org.apache.hadoop.tools.CopyFilter)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.tools.dynamometer.ApplicationMaster$NMCallbackHandler:onContainerResourceIncreased(org.apache.hadoop.yarn.api.records.ContainerId,org.apache.hadoop.yarn.api.records.Resource)	java.lang.Deprecated
org.apache.hadoop.tools.dynamometer.ApplicationMaster$NMCallbackHandler:onIncreaseContainerResourceError(org.apache.hadoop.yarn.api.records.ContainerId,java.lang.Throwable)	java.lang.Deprecated
org.apache.hadoop.tools.dynamometer.Client:getNameNodeInfoPath()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.tools.dynamometer.Client:getWorkloadJob()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.hdfs.server.namenode.TreePath:<init>(org.apache.hadoop.fs.FileStatus,long,org.apache.hadoop.hdfs.server.namenode.TreeWalk$TreeIterator)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.mapred.gridmix.emulators.resourceusage.TotalHeapUsageEmulatorPlugin$DefaultHeapUsageEmulator:getHeapSpaceSize()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.resourceestimator.service.ResourceEstimatorService:parseFile(java.lang.String)	javax.ws.rs.POST
org.apache.hadoop.resourceestimator.service.ResourceEstimatorService:parseFile(java.lang.String)	javax.ws.rs.Path	value	/translator/{logFile : .+}
org.apache.hadoop.resourceestimator.service.ResourceEstimatorService:getPrediction(java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.resourceestimator.service.ResourceEstimatorService:getPrediction(java.lang.String)	javax.ws.rs.Path	value	/estimator/{pipelineId}
org.apache.hadoop.resourceestimator.service.ResourceEstimatorService:getPrediction(java.lang.String)	javax.ws.rs.Produces	value	{application/json}
org.apache.hadoop.resourceestimator.service.ResourceEstimatorService:getHistoryResourceSkyline(java.lang.String,java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.resourceestimator.service.ResourceEstimatorService:getHistoryResourceSkyline(java.lang.String,java.lang.String)	javax.ws.rs.Path	value	/skylinestore/history/{pipelineId}/{runId}
org.apache.hadoop.resourceestimator.service.ResourceEstimatorService:getHistoryResourceSkyline(java.lang.String,java.lang.String)	javax.ws.rs.Produces	value	{application/json}
org.apache.hadoop.resourceestimator.service.ResourceEstimatorService:getEstimatedResourceAllocation(java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.resourceestimator.service.ResourceEstimatorService:getEstimatedResourceAllocation(java.lang.String)	javax.ws.rs.Path	value	/skylinestore/estimation/{pipelineId}
org.apache.hadoop.resourceestimator.service.ResourceEstimatorService:getEstimatedResourceAllocation(java.lang.String)	javax.ws.rs.Produces	value	{application/json}
org.apache.hadoop.resourceestimator.service.ResourceEstimatorService:deleteHistoryResourceSkyline(java.lang.String,java.lang.String)	javax.ws.rs.DELETE
org.apache.hadoop.resourceestimator.service.ResourceEstimatorService:deleteHistoryResourceSkyline(java.lang.String,java.lang.String)	javax.ws.rs.Path	value	/skylinestore/history/{pipelineId}/{runId}
org.apache.hadoop.tools.rumen.LoggedSingleRelativeRanking:setUnknownAttribute(java.lang.String,java.lang.Object)	com.fasterxml.jackson.annotation.JsonAnySetter
org.apache.hadoop.tools.rumen.state.StatePool:isUpdated()	com.fasterxml.jackson.annotation.JsonIgnore
org.apache.hadoop.tools.rumen.state.State:isUpdated()	com.fasterxml.jackson.annotation.JsonIgnore
org.apache.hadoop.tools.rumen.LoggedTask:setUnknownAttribute(java.lang.String,java.lang.Object)	com.fasterxml.jackson.annotation.JsonAnySetter
org.apache.hadoop.tools.rumen.ParsedConfigFile:<init>(java.lang.String,java.lang.String)	java.lang.Deprecated
org.apache.hadoop.tools.rumen.LoggedJob:setUnknownAttribute(java.lang.String,java.lang.Object)	com.fasterxml.jackson.annotation.JsonAnySetter
org.apache.hadoop.tools.rumen.LoggedLocation:setUnknownAttribute(java.lang.String,java.lang.Object)	com.fasterxml.jackson.annotation.JsonAnySetter
org.apache.hadoop.tools.rumen.datatypes.NodeName$NodeNameState:isUpdated()	com.fasterxml.jackson.annotation.JsonIgnore
org.apache.hadoop.tools.rumen.ReduceTaskAttemptInfo:<init>(org.apache.hadoop.mapred.TaskStatus$State,org.apache.hadoop.tools.rumen.TaskInfo,long,long,long)	java.lang.Deprecated
org.apache.hadoop.tools.rumen.MapTaskAttemptInfo:<init>(org.apache.hadoop.mapred.TaskStatus$State,org.apache.hadoop.tools.rumen.TaskInfo,long)	java.lang.Deprecated
org.apache.hadoop.tools.rumen.LoggedTaskAttempt:setUnknownAttribute(java.lang.String,java.lang.Object)	com.fasterxml.jackson.annotation.JsonAnySetter
org.apache.hadoop.tools.rumen.LoggedNetworkTopology:setUnknownAttribute(java.lang.String,java.lang.Object)	com.fasterxml.jackson.annotation.JsonAnySetter
org.apache.hadoop.yarn.sls.nodemanager.NMSimulator:getRunningContainers()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.sls.nodemanager.NMSimulator:getAMContainers()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.sls.nodemanager.NMSimulator:getCompletedContainers()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.sls.scheduler.FairSchedulerMetrics$Metric:getValue()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.sls.appmaster.DAGAMSimulator:getToBeScheduledContainers(java.util.List,long)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.sls.synthetic.SynthTraceJobProducer$Sample:<init>(java.lang.Double,java.lang.Double,java.lang.String,java.util.List,java.util.List)	org.codehaus.jackson.annotate.JsonCreator
org.apache.hadoop.streaming.StreamJob:<init>(java.lang.String[],boolean)	java.lang.Deprecated
org.apache.hadoop.streaming.StreamJob:go()	java.lang.Deprecated
org.apache.hadoop.streaming.StreamJob:getClusterNick()	java.lang.Deprecated
org.apache.hadoop.yarn.api.ApplicationClientProtocol:getNewApplication(org.apache.hadoop.yarn.api.protocolrecords.GetNewApplicationRequest)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.ApplicationClientProtocol:getNewApplication(org.apache.hadoop.yarn.api.protocolrecords.GetNewApplicationRequest)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.ApplicationClientProtocol:getNewApplication(org.apache.hadoop.yarn.api.protocolrecords.GetNewApplicationRequest)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.yarn.api.ApplicationClientProtocol:submitApplication(org.apache.hadoop.yarn.api.protocolrecords.SubmitApplicationRequest)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.ApplicationClientProtocol:submitApplication(org.apache.hadoop.yarn.api.protocolrecords.SubmitApplicationRequest)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.ApplicationClientProtocol:submitApplication(org.apache.hadoop.yarn.api.protocolrecords.SubmitApplicationRequest)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.yarn.api.ApplicationClientProtocol:failApplicationAttempt(org.apache.hadoop.yarn.api.protocolrecords.FailApplicationAttemptRequest)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.ApplicationClientProtocol:failApplicationAttempt(org.apache.hadoop.yarn.api.protocolrecords.FailApplicationAttemptRequest)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.ApplicationClientProtocol:forceKillApplication(org.apache.hadoop.yarn.api.protocolrecords.KillApplicationRequest)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.ApplicationClientProtocol:forceKillApplication(org.apache.hadoop.yarn.api.protocolrecords.KillApplicationRequest)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.ApplicationClientProtocol:forceKillApplication(org.apache.hadoop.yarn.api.protocolrecords.KillApplicationRequest)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.yarn.api.ApplicationClientProtocol:getClusterMetrics(org.apache.hadoop.yarn.api.protocolrecords.GetClusterMetricsRequest)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.ApplicationClientProtocol:getClusterMetrics(org.apache.hadoop.yarn.api.protocolrecords.GetClusterMetricsRequest)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.ApplicationClientProtocol:getClusterMetrics(org.apache.hadoop.yarn.api.protocolrecords.GetClusterMetricsRequest)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.yarn.api.ApplicationClientProtocol:getClusterNodes(org.apache.hadoop.yarn.api.protocolrecords.GetClusterNodesRequest)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.ApplicationClientProtocol:getClusterNodes(org.apache.hadoop.yarn.api.protocolrecords.GetClusterNodesRequest)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.ApplicationClientProtocol:getClusterNodes(org.apache.hadoop.yarn.api.protocolrecords.GetClusterNodesRequest)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.yarn.api.ApplicationClientProtocol:getQueueInfo(org.apache.hadoop.yarn.api.protocolrecords.GetQueueInfoRequest)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.ApplicationClientProtocol:getQueueInfo(org.apache.hadoop.yarn.api.protocolrecords.GetQueueInfoRequest)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.ApplicationClientProtocol:getQueueInfo(org.apache.hadoop.yarn.api.protocolrecords.GetQueueInfoRequest)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.yarn.api.ApplicationClientProtocol:getQueueUserAcls(org.apache.hadoop.yarn.api.protocolrecords.GetQueueUserAclsInfoRequest)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.ApplicationClientProtocol:getQueueUserAcls(org.apache.hadoop.yarn.api.protocolrecords.GetQueueUserAclsInfoRequest)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.ApplicationClientProtocol:getQueueUserAcls(org.apache.hadoop.yarn.api.protocolrecords.GetQueueUserAclsInfoRequest)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.yarn.api.ApplicationClientProtocol:moveApplicationAcrossQueues(org.apache.hadoop.yarn.api.protocolrecords.MoveApplicationAcrossQueuesRequest)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.ApplicationClientProtocol:moveApplicationAcrossQueues(org.apache.hadoop.yarn.api.protocolrecords.MoveApplicationAcrossQueuesRequest)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.ApplicationClientProtocol:moveApplicationAcrossQueues(org.apache.hadoop.yarn.api.protocolrecords.MoveApplicationAcrossQueuesRequest)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.yarn.api.ApplicationClientProtocol:getNewReservation(org.apache.hadoop.yarn.api.protocolrecords.GetNewReservationRequest)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.ApplicationClientProtocol:getNewReservation(org.apache.hadoop.yarn.api.protocolrecords.GetNewReservationRequest)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.ApplicationClientProtocol:getNewReservation(org.apache.hadoop.yarn.api.protocolrecords.GetNewReservationRequest)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.yarn.api.ApplicationClientProtocol:submitReservation(org.apache.hadoop.yarn.api.protocolrecords.ReservationSubmissionRequest)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.ApplicationClientProtocol:submitReservation(org.apache.hadoop.yarn.api.protocolrecords.ReservationSubmissionRequest)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.ApplicationClientProtocol:submitReservation(org.apache.hadoop.yarn.api.protocolrecords.ReservationSubmissionRequest)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.yarn.api.ApplicationClientProtocol:updateReservation(org.apache.hadoop.yarn.api.protocolrecords.ReservationUpdateRequest)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.ApplicationClientProtocol:updateReservation(org.apache.hadoop.yarn.api.protocolrecords.ReservationUpdateRequest)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.ApplicationClientProtocol:deleteReservation(org.apache.hadoop.yarn.api.protocolrecords.ReservationDeleteRequest)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.ApplicationClientProtocol:deleteReservation(org.apache.hadoop.yarn.api.protocolrecords.ReservationDeleteRequest)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.ApplicationClientProtocol:listReservations(org.apache.hadoop.yarn.api.protocolrecords.ReservationListRequest)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.ApplicationClientProtocol:listReservations(org.apache.hadoop.yarn.api.protocolrecords.ReservationListRequest)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.ApplicationClientProtocol:getNodeToLabels(org.apache.hadoop.yarn.api.protocolrecords.GetNodesToLabelsRequest)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.ApplicationClientProtocol:getNodeToLabels(org.apache.hadoop.yarn.api.protocolrecords.GetNodesToLabelsRequest)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.ApplicationClientProtocol:getLabelsToNodes(org.apache.hadoop.yarn.api.protocolrecords.GetLabelsToNodesRequest)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.ApplicationClientProtocol:getLabelsToNodes(org.apache.hadoop.yarn.api.protocolrecords.GetLabelsToNodesRequest)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.ApplicationClientProtocol:getClusterNodeLabels(org.apache.hadoop.yarn.api.protocolrecords.GetClusterNodeLabelsRequest)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.ApplicationClientProtocol:getClusterNodeLabels(org.apache.hadoop.yarn.api.protocolrecords.GetClusterNodeLabelsRequest)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.ApplicationClientProtocol:updateApplicationPriority(org.apache.hadoop.yarn.api.protocolrecords.UpdateApplicationPriorityRequest)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.ApplicationClientProtocol:updateApplicationPriority(org.apache.hadoop.yarn.api.protocolrecords.UpdateApplicationPriorityRequest)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.ApplicationClientProtocol:updateApplicationPriority(org.apache.hadoop.yarn.api.protocolrecords.UpdateApplicationPriorityRequest)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.yarn.api.ApplicationClientProtocol:signalToContainer(org.apache.hadoop.yarn.api.protocolrecords.SignalContainerRequest)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.ApplicationClientProtocol:signalToContainer(org.apache.hadoop.yarn.api.protocolrecords.SignalContainerRequest)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.ApplicationClientProtocol:updateApplicationTimeouts(org.apache.hadoop.yarn.api.protocolrecords.UpdateApplicationTimeoutsRequest)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.ApplicationClientProtocol:updateApplicationTimeouts(org.apache.hadoop.yarn.api.protocolrecords.UpdateApplicationTimeoutsRequest)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.ApplicationClientProtocol:updateApplicationTimeouts(org.apache.hadoop.yarn.api.protocolrecords.UpdateApplicationTimeoutsRequest)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.yarn.api.ApplicationClientProtocol:getResourceProfiles(org.apache.hadoop.yarn.api.protocolrecords.GetAllResourceProfilesRequest)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.ApplicationClientProtocol:getResourceProfiles(org.apache.hadoop.yarn.api.protocolrecords.GetAllResourceProfilesRequest)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.ApplicationClientProtocol:getResourceProfile(org.apache.hadoop.yarn.api.protocolrecords.GetResourceProfileRequest)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.ApplicationClientProtocol:getResourceProfile(org.apache.hadoop.yarn.api.protocolrecords.GetResourceProfileRequest)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.ApplicationClientProtocol:getResourceTypeInfo(org.apache.hadoop.yarn.api.protocolrecords.GetAllResourceTypeInfoRequest)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.ApplicationClientProtocol:getResourceTypeInfo(org.apache.hadoop.yarn.api.protocolrecords.GetAllResourceTypeInfoRequest)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.ApplicationClientProtocol:getAttributesToNodes(org.apache.hadoop.yarn.api.protocolrecords.GetAttributesToNodesRequest)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.ApplicationClientProtocol:getAttributesToNodes(org.apache.hadoop.yarn.api.protocolrecords.GetAttributesToNodesRequest)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.ApplicationClientProtocol:getClusterNodeAttributes(org.apache.hadoop.yarn.api.protocolrecords.GetClusterNodeAttributesRequest)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.ApplicationClientProtocol:getClusterNodeAttributes(org.apache.hadoop.yarn.api.protocolrecords.GetClusterNodeAttributesRequest)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.ApplicationClientProtocol:getNodesToAttributes(org.apache.hadoop.yarn.api.protocolrecords.GetNodesToAttributesRequest)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.ApplicationClientProtocol:getNodesToAttributes(org.apache.hadoop.yarn.api.protocolrecords.GetNodesToAttributesRequest)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.ApplicationConstants$Environment:$$()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.ApplicationConstants$Environment:$$()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.ContainerManagementProtocol:startContainers(org.apache.hadoop.yarn.api.protocolrecords.StartContainersRequest)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.ContainerManagementProtocol:startContainers(org.apache.hadoop.yarn.api.protocolrecords.StartContainersRequest)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.ContainerManagementProtocol:stopContainers(org.apache.hadoop.yarn.api.protocolrecords.StopContainersRequest)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.ContainerManagementProtocol:stopContainers(org.apache.hadoop.yarn.api.protocolrecords.StopContainersRequest)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.ContainerManagementProtocol:getContainerStatuses(org.apache.hadoop.yarn.api.protocolrecords.GetContainerStatusesRequest)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.ContainerManagementProtocol:getContainerStatuses(org.apache.hadoop.yarn.api.protocolrecords.GetContainerStatusesRequest)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.ContainerManagementProtocol:increaseContainersResource(org.apache.hadoop.yarn.api.protocolrecords.IncreaseContainersResourceRequest)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.ContainerManagementProtocol:increaseContainersResource(org.apache.hadoop.yarn.api.protocolrecords.IncreaseContainersResourceRequest)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.ContainerManagementProtocol:increaseContainersResource(org.apache.hadoop.yarn.api.protocolrecords.IncreaseContainersResourceRequest)	java.lang.Deprecated
org.apache.hadoop.yarn.api.ContainerManagementProtocol:updateContainer(org.apache.hadoop.yarn.api.protocolrecords.ContainerUpdateRequest)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.ContainerManagementProtocol:updateContainer(org.apache.hadoop.yarn.api.protocolrecords.ContainerUpdateRequest)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.ContainerManagementProtocol:localize(org.apache.hadoop.yarn.api.protocolrecords.ResourceLocalizationRequest)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.ContainerManagementProtocol:localize(org.apache.hadoop.yarn.api.protocolrecords.ResourceLocalizationRequest)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.ContainerManagementProtocol:reInitializeContainer(org.apache.hadoop.yarn.api.protocolrecords.ReInitializeContainerRequest)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.ContainerManagementProtocol:reInitializeContainer(org.apache.hadoop.yarn.api.protocolrecords.ReInitializeContainerRequest)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.ContainerManagementProtocol:restartContainer(org.apache.hadoop.yarn.api.records.ContainerId)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.ContainerManagementProtocol:restartContainer(org.apache.hadoop.yarn.api.records.ContainerId)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.ContainerManagementProtocol:rollbackLastReInitialization(org.apache.hadoop.yarn.api.records.ContainerId)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.ContainerManagementProtocol:rollbackLastReInitialization(org.apache.hadoop.yarn.api.records.ContainerId)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.ContainerManagementProtocol:commitLastReInitialization(org.apache.hadoop.yarn.api.records.ContainerId)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.ContainerManagementProtocol:commitLastReInitialization(org.apache.hadoop.yarn.api.records.ContainerId)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.ContainerManagementProtocol:getLocalizationStatuses(org.apache.hadoop.yarn.api.protocolrecords.GetLocalizationStatusesRequest)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.ContainerManagementProtocol:getLocalizationStatuses(org.apache.hadoop.yarn.api.protocolrecords.GetLocalizationStatusesRequest)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.ApplicationBaseProtocol:getApplicationReport(org.apache.hadoop.yarn.api.protocolrecords.GetApplicationReportRequest)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.ApplicationBaseProtocol:getApplicationReport(org.apache.hadoop.yarn.api.protocolrecords.GetApplicationReportRequest)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.ApplicationBaseProtocol:getApplicationReport(org.apache.hadoop.yarn.api.protocolrecords.GetApplicationReportRequest)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.yarn.api.ApplicationBaseProtocol:getApplications(org.apache.hadoop.yarn.api.protocolrecords.GetApplicationsRequest)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.ApplicationBaseProtocol:getApplications(org.apache.hadoop.yarn.api.protocolrecords.GetApplicationsRequest)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.ApplicationBaseProtocol:getApplications(org.apache.hadoop.yarn.api.protocolrecords.GetApplicationsRequest)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.yarn.api.ApplicationBaseProtocol:getApplicationAttemptReport(org.apache.hadoop.yarn.api.protocolrecords.GetApplicationAttemptReportRequest)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.ApplicationBaseProtocol:getApplicationAttemptReport(org.apache.hadoop.yarn.api.protocolrecords.GetApplicationAttemptReportRequest)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.ApplicationBaseProtocol:getApplicationAttemptReport(org.apache.hadoop.yarn.api.protocolrecords.GetApplicationAttemptReportRequest)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.yarn.api.ApplicationBaseProtocol:getApplicationAttempts(org.apache.hadoop.yarn.api.protocolrecords.GetApplicationAttemptsRequest)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.ApplicationBaseProtocol:getApplicationAttempts(org.apache.hadoop.yarn.api.protocolrecords.GetApplicationAttemptsRequest)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.ApplicationBaseProtocol:getApplicationAttempts(org.apache.hadoop.yarn.api.protocolrecords.GetApplicationAttemptsRequest)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.yarn.api.ApplicationBaseProtocol:getContainerReport(org.apache.hadoop.yarn.api.protocolrecords.GetContainerReportRequest)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.ApplicationBaseProtocol:getContainerReport(org.apache.hadoop.yarn.api.protocolrecords.GetContainerReportRequest)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.ApplicationBaseProtocol:getContainerReport(org.apache.hadoop.yarn.api.protocolrecords.GetContainerReportRequest)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.yarn.api.ApplicationBaseProtocol:getContainers(org.apache.hadoop.yarn.api.protocolrecords.GetContainersRequest)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.ApplicationBaseProtocol:getContainers(org.apache.hadoop.yarn.api.protocolrecords.GetContainersRequest)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.ApplicationBaseProtocol:getContainers(org.apache.hadoop.yarn.api.protocolrecords.GetContainersRequest)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.yarn.api.ApplicationBaseProtocol:getDelegationToken(org.apache.hadoop.yarn.api.protocolrecords.GetDelegationTokenRequest)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.ApplicationBaseProtocol:getDelegationToken(org.apache.hadoop.yarn.api.protocolrecords.GetDelegationTokenRequest)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.ApplicationBaseProtocol:getDelegationToken(org.apache.hadoop.yarn.api.protocolrecords.GetDelegationTokenRequest)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.yarn.api.ApplicationBaseProtocol:renewDelegationToken(org.apache.hadoop.yarn.api.protocolrecords.RenewDelegationTokenRequest)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.ApplicationBaseProtocol:renewDelegationToken(org.apache.hadoop.yarn.api.protocolrecords.RenewDelegationTokenRequest)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.ApplicationBaseProtocol:renewDelegationToken(org.apache.hadoop.yarn.api.protocolrecords.RenewDelegationTokenRequest)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.yarn.api.ApplicationBaseProtocol:cancelDelegationToken(org.apache.hadoop.yarn.api.protocolrecords.CancelDelegationTokenRequest)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.ApplicationBaseProtocol:cancelDelegationToken(org.apache.hadoop.yarn.api.protocolrecords.CancelDelegationTokenRequest)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.ApplicationBaseProtocol:cancelDelegationToken(org.apache.hadoop.yarn.api.protocolrecords.CancelDelegationTokenRequest)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.yarn.api.protocolrecords.ReservationSubmissionRequest:newInstance(org.apache.hadoop.yarn.api.records.ReservationDefinition,java.lang.String,org.apache.hadoop.yarn.api.records.ReservationId)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.ReservationSubmissionRequest:newInstance(org.apache.hadoop.yarn.api.records.ReservationDefinition,java.lang.String,org.apache.hadoop.yarn.api.records.ReservationId)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.ReservationSubmissionRequest:getReservationDefinition()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.ReservationSubmissionRequest:getReservationDefinition()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.ReservationSubmissionRequest:setReservationDefinition(org.apache.hadoop.yarn.api.records.ReservationDefinition)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.ReservationSubmissionRequest:setReservationDefinition(org.apache.hadoop.yarn.api.records.ReservationDefinition)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.ReservationSubmissionRequest:getQueue()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.ReservationSubmissionRequest:getQueue()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.ReservationSubmissionRequest:setQueue(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.ReservationSubmissionRequest:setQueue(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.ReservationSubmissionRequest:getReservationId()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.ReservationSubmissionRequest:getReservationId()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.ReservationSubmissionRequest:setReservationId(org.apache.hadoop.yarn.api.records.ReservationId)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.ReservationSubmissionRequest:setReservationId(org.apache.hadoop.yarn.api.records.ReservationId)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.GetNodesToAttributesRequest:setHostNames(java.util.Set)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.GetNodesToAttributesRequest:setHostNames(java.util.Set)	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.yarn.api.protocolrecords.GetNodesToAttributesRequest:getHostNames()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.GetNodesToAttributesRequest:getHostNames()	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.yarn.api.protocolrecords.GetApplicationAttemptReportResponse:newInstance(org.apache.hadoop.yarn.api.records.ApplicationAttemptReport)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.GetApplicationAttemptReportResponse:newInstance(org.apache.hadoop.yarn.api.records.ApplicationAttemptReport)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.GetApplicationAttemptReportResponse:getApplicationAttemptReport()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.GetApplicationAttemptReportResponse:getApplicationAttemptReport()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.GetApplicationAttemptReportResponse:setApplicationAttemptReport(org.apache.hadoop.yarn.api.records.ApplicationAttemptReport)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.GetApplicationAttemptReportResponse:setApplicationAttemptReport(org.apache.hadoop.yarn.api.records.ApplicationAttemptReport)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.StartContainersRequest:newInstance(java.util.List)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.StartContainersRequest:newInstance(java.util.List)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.StartContainersRequest:getStartContainerRequests()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.StartContainersRequest:getStartContainerRequests()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.StartContainersRequest:setStartContainerRequests(java.util.List)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.StartContainersRequest:setStartContainerRequests(java.util.List)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.GetApplicationAttemptsRequest:newInstance(org.apache.hadoop.yarn.api.records.ApplicationId)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.GetApplicationAttemptsRequest:newInstance(org.apache.hadoop.yarn.api.records.ApplicationId)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.GetApplicationAttemptsRequest:getApplicationId()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.GetApplicationAttemptsRequest:getApplicationId()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.GetApplicationAttemptsRequest:setApplicationId(org.apache.hadoop.yarn.api.records.ApplicationId)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.GetApplicationAttemptsRequest:setApplicationId(org.apache.hadoop.yarn.api.records.ApplicationId)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.ResourceLocalizationResponse:newInstance()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.ResourceLocalizationResponse:newInstance()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.GetContainerStatusesRequest:newInstance(java.util.List)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.GetContainerStatusesRequest:newInstance(java.util.List)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.GetContainerStatusesRequest:getContainerIds()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.GetContainerStatusesRequest:getContainerIds()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.GetContainerStatusesRequest:setContainerIds(java.util.List)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.GetContainerStatusesRequest:setContainerIds(java.util.List)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.RenewDelegationTokenResponse:newInstance(long)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.RenewDelegationTokenResponse:newInstance(long)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.RenewDelegationTokenResponse:getNextExpirationTime()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.RenewDelegationTokenResponse:getNextExpirationTime()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.RenewDelegationTokenResponse:setNextExpirationTime(long)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.RenewDelegationTokenResponse:setNextExpirationTime(long)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.MoveApplicationAcrossQueuesResponse:newInstance()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.MoveApplicationAcrossQueuesResponse:newInstance()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.ReleaseSharedCacheResourceRequest:getAppId()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.ReleaseSharedCacheResourceRequest:getAppId()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.ReleaseSharedCacheResourceRequest:setAppId(org.apache.hadoop.yarn.api.records.ApplicationId)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.ReleaseSharedCacheResourceRequest:setAppId(org.apache.hadoop.yarn.api.records.ApplicationId)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.ReleaseSharedCacheResourceRequest:getResourceKey()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.ReleaseSharedCacheResourceRequest:getResourceKey()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.ReleaseSharedCacheResourceRequest:setResourceKey(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.ReleaseSharedCacheResourceRequest:setResourceKey(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.GetClusterNodeLabelsResponse:newInstance(java.util.Set)	java.lang.Deprecated
org.apache.hadoop.yarn.api.protocolrecords.GetClusterNodeLabelsResponse:setNodeLabels(java.util.Set)	java.lang.Deprecated
org.apache.hadoop.yarn.api.protocolrecords.GetClusterNodeLabelsResponse:getNodeLabels()	java.lang.Deprecated
org.apache.hadoop.yarn.api.protocolrecords.GetNewReservationRequest:newInstance()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.GetNewReservationRequest:newInstance()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.RegisterApplicationMasterRequest:newInstance(java.lang.String,int,java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.RegisterApplicationMasterRequest:newInstance(java.lang.String,int,java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.RegisterApplicationMasterRequest:getHost()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.RegisterApplicationMasterRequest:getHost()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.RegisterApplicationMasterRequest:setHost(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.RegisterApplicationMasterRequest:setHost(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.RegisterApplicationMasterRequest:getRpcPort()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.RegisterApplicationMasterRequest:getRpcPort()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.RegisterApplicationMasterRequest:setRpcPort(int)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.RegisterApplicationMasterRequest:setRpcPort(int)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.RegisterApplicationMasterRequest:getTrackingUrl()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.RegisterApplicationMasterRequest:getTrackingUrl()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.RegisterApplicationMasterRequest:setTrackingUrl(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.RegisterApplicationMasterRequest:setTrackingUrl(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.RegisterApplicationMasterRequest:getPlacementConstraints()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.RegisterApplicationMasterRequest:getPlacementConstraints()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.RegisterApplicationMasterRequest:setPlacementConstraints(java.util.Map)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.RegisterApplicationMasterRequest:setPlacementConstraints(java.util.Map)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.StopContainersResponse:newInstance(java.util.List,java.util.Map)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.StopContainersResponse:newInstance(java.util.List,java.util.Map)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.StopContainersResponse:getSuccessfullyStoppedContainers()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.StopContainersResponse:getSuccessfullyStoppedContainers()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.StopContainersResponse:setSuccessfullyStoppedContainers(java.util.List)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.StopContainersResponse:setSuccessfullyStoppedContainers(java.util.List)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.StopContainersResponse:getFailedRequests()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.StopContainersResponse:getFailedRequests()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.StopContainersResponse:setFailedRequests(java.util.Map)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.StopContainersResponse:setFailedRequests(java.util.Map)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.StopContainersRequest:newInstance(java.util.List)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.StopContainersRequest:newInstance(java.util.List)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.StopContainersRequest:getContainerIds()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.StopContainersRequest:getContainerIds()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.StopContainersRequest:setContainerIds(java.util.List)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.StopContainersRequest:setContainerIds(java.util.List)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.GetContainersRequest:newInstance(org.apache.hadoop.yarn.api.records.ApplicationAttemptId)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.GetContainersRequest:newInstance(org.apache.hadoop.yarn.api.records.ApplicationAttemptId)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.GetContainersRequest:getApplicationAttemptId()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.GetContainersRequest:getApplicationAttemptId()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.GetContainersRequest:setApplicationAttemptId(org.apache.hadoop.yarn.api.records.ApplicationAttemptId)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.GetContainersRequest:setApplicationAttemptId(org.apache.hadoop.yarn.api.records.ApplicationAttemptId)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.GetLabelsToNodesResponse:setLabelsToNodes(java.util.Map)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.GetLabelsToNodesResponse:setLabelsToNodes(java.util.Map)	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.yarn.api.protocolrecords.GetLabelsToNodesResponse:getLabelsToNodes()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.GetLabelsToNodesResponse:getLabelsToNodes()	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.yarn.api.protocolrecords.GetContainerReportResponse:newInstance(org.apache.hadoop.yarn.api.records.ContainerReport)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.GetContainerReportResponse:newInstance(org.apache.hadoop.yarn.api.records.ContainerReport)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.GetContainerReportResponse:getContainerReport()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.GetContainerReportResponse:getContainerReport()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.GetContainerReportResponse:setContainerReport(org.apache.hadoop.yarn.api.records.ContainerReport)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.GetContainerReportResponse:setContainerReport(org.apache.hadoop.yarn.api.records.ContainerReport)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.CancelDelegationTokenRequest:newInstance(org.apache.hadoop.yarn.api.records.Token)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.CancelDelegationTokenRequest:newInstance(org.apache.hadoop.yarn.api.records.Token)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.CancelDelegationTokenRequest:getDelegationToken()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.CancelDelegationTokenRequest:getDelegationToken()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.CancelDelegationTokenRequest:setDelegationToken(org.apache.hadoop.yarn.api.records.Token)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.CancelDelegationTokenRequest:setDelegationToken(org.apache.hadoop.yarn.api.records.Token)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.GetAttributesToNodesRequest:setNodeAttributes(java.util.Set)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.GetAttributesToNodesRequest:setNodeAttributes(java.util.Set)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.GetAttributesToNodesRequest:getNodeAttributes()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.GetAttributesToNodesRequest:getNodeAttributes()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.GetDelegationTokenRequest:newInstance(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.GetDelegationTokenRequest:newInstance(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.GetDelegationTokenRequest:getRenewer()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.GetDelegationTokenRequest:getRenewer()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.GetDelegationTokenRequest:setRenewer(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.GetDelegationTokenRequest:setRenewer(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.GetAttributesToNodesResponse:setAttributeToNodes(java.util.Map)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.GetAttributesToNodesResponse:setAttributeToNodes(java.util.Map)	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.yarn.api.protocolrecords.GetAttributesToNodesResponse:getAttributesToNodes()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.GetAttributesToNodesResponse:getAttributesToNodes()	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.yarn.api.protocolrecords.GetClusterNodesRequest:newInstance(java.util.EnumSet)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.GetClusterNodesRequest:newInstance(java.util.EnumSet)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.GetClusterNodesRequest:newInstance()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.GetClusterNodesRequest:newInstance()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.GetContainerStatusesResponse:newInstance(java.util.List,java.util.Map)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.GetContainerStatusesResponse:newInstance(java.util.List,java.util.Map)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.GetContainerStatusesResponse:getContainerStatuses()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.GetContainerStatusesResponse:getContainerStatuses()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.GetContainerStatusesResponse:setContainerStatuses(java.util.List)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.GetContainerStatusesResponse:setContainerStatuses(java.util.List)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.GetContainerStatusesResponse:getFailedRequests()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.GetContainerStatusesResponse:getFailedRequests()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.GetContainerStatusesResponse:setFailedRequests(java.util.Map)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.GetContainerStatusesResponse:setFailedRequests(java.util.Map)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.GetClusterNodeAttributesResponse:setNodeAttributes(java.util.Set)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.GetClusterNodeAttributesResponse:setNodeAttributes(java.util.Set)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.GetClusterNodeAttributesResponse:getNodeAttributes()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.GetClusterNodeAttributesResponse:getNodeAttributes()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.FailApplicationAttemptResponse:newInstance()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.FailApplicationAttemptResponse:newInstance()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.GetClusterMetricsRequest:newInstance()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.GetClusterMetricsRequest:newInstance()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.ReInitializeContainerResponse:newInstance()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.ReInitializeContainerResponse:newInstance()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.GetApplicationReportRequest:newInstance(org.apache.hadoop.yarn.api.records.ApplicationId)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.GetApplicationReportRequest:newInstance(org.apache.hadoop.yarn.api.records.ApplicationId)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.GetApplicationReportRequest:getApplicationId()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.GetApplicationReportRequest:getApplicationId()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.GetApplicationReportRequest:setApplicationId(org.apache.hadoop.yarn.api.records.ApplicationId)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.GetApplicationReportRequest:setApplicationId(org.apache.hadoop.yarn.api.records.ApplicationId)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.GetQueueInfoRequest:newInstance(java.lang.String,boolean,boolean,boolean)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.GetQueueInfoRequest:newInstance(java.lang.String,boolean,boolean,boolean)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.GetQueueInfoRequest:getQueueName()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.GetQueueInfoRequest:getQueueName()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.GetQueueInfoRequest:setQueueName(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.GetQueueInfoRequest:setQueueName(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.GetQueueInfoRequest:getIncludeApplications()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.GetQueueInfoRequest:getIncludeApplications()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.GetQueueInfoRequest:setIncludeApplications(boolean)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.GetQueueInfoRequest:setIncludeApplications(boolean)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.GetQueueInfoRequest:getIncludeChildQueues()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.GetQueueInfoRequest:getIncludeChildQueues()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.GetQueueInfoRequest:setIncludeChildQueues(boolean)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.GetQueueInfoRequest:setIncludeChildQueues(boolean)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.GetQueueInfoRequest:getRecursive()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.GetQueueInfoRequest:getRecursive()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.GetQueueInfoRequest:setRecursive(boolean)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.GetQueueInfoRequest:setRecursive(boolean)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.GetNewApplicationResponse:newInstance(org.apache.hadoop.yarn.api.records.ApplicationId,org.apache.hadoop.yarn.api.records.Resource,org.apache.hadoop.yarn.api.records.Resource)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.GetNewApplicationResponse:newInstance(org.apache.hadoop.yarn.api.records.ApplicationId,org.apache.hadoop.yarn.api.records.Resource,org.apache.hadoop.yarn.api.records.Resource)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.GetNewApplicationResponse:getApplicationId()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.GetNewApplicationResponse:getApplicationId()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.GetNewApplicationResponse:setApplicationId(org.apache.hadoop.yarn.api.records.ApplicationId)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.GetNewApplicationResponse:setApplicationId(org.apache.hadoop.yarn.api.records.ApplicationId)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.GetNewApplicationResponse:getMaximumResourceCapability()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.GetNewApplicationResponse:getMaximumResourceCapability()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.GetNewApplicationResponse:setMaximumResourceCapability(org.apache.hadoop.yarn.api.records.Resource)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.GetNewApplicationResponse:setMaximumResourceCapability(org.apache.hadoop.yarn.api.records.Resource)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.AllocateRequest$AllocateRequestBuilder:responseId(int)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.AllocateRequest$AllocateRequestBuilder:responseId(int)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.AllocateRequest$AllocateRequestBuilder:progress(float)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.AllocateRequest$AllocateRequestBuilder:progress(float)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.AllocateRequest$AllocateRequestBuilder:askList(java.util.List)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.AllocateRequest$AllocateRequestBuilder:askList(java.util.List)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.AllocateRequest$AllocateRequestBuilder:releaseList(java.util.List)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.AllocateRequest$AllocateRequestBuilder:releaseList(java.util.List)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.AllocateRequest$AllocateRequestBuilder:resourceBlacklistRequest(org.apache.hadoop.yarn.api.records.ResourceBlacklistRequest)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.AllocateRequest$AllocateRequestBuilder:resourceBlacklistRequest(org.apache.hadoop.yarn.api.records.ResourceBlacklistRequest)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.AllocateRequest$AllocateRequestBuilder:updateRequests(java.util.List)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.AllocateRequest$AllocateRequestBuilder:updateRequests(java.util.List)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.AllocateRequest$AllocateRequestBuilder:schedulingRequests(java.util.List)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.AllocateRequest$AllocateRequestBuilder:schedulingRequests(java.util.List)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.AllocateRequest$AllocateRequestBuilder:trackingUrl(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.AllocateRequest$AllocateRequestBuilder:trackingUrl(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.AllocateRequest$AllocateRequestBuilder:build()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.AllocateRequest$AllocateRequestBuilder:build()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.GetApplicationsRequest:newInstance()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.GetApplicationsRequest:newInstance()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.GetApplicationsRequest:newInstance(org.apache.hadoop.yarn.api.protocolrecords.ApplicationsRequestScope,java.util.Set,java.util.Set,java.util.Set,java.util.Set,java.util.EnumSet,org.apache.commons.lang3.Range,org.apache.commons.lang3.Range,java.lang.Long)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.GetApplicationsRequest:newInstance(org.apache.hadoop.yarn.api.protocolrecords.ApplicationsRequestScope,java.util.Set,java.util.Set,java.util.Set,java.util.Set,java.util.EnumSet,org.apache.commons.lang3.Range,org.apache.commons.lang3.Range,java.lang.Long)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.GetApplicationsRequest:newInstance(org.apache.hadoop.yarn.api.protocolrecords.ApplicationsRequestScope)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.GetApplicationsRequest:newInstance(org.apache.hadoop.yarn.api.protocolrecords.ApplicationsRequestScope)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.GetApplicationsRequest:newInstance(java.util.Set)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.GetApplicationsRequest:newInstance(java.util.Set)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.GetApplicationsRequest:newInstance(java.util.EnumSet)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.GetApplicationsRequest:newInstance(java.util.EnumSet)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.GetApplicationsRequest:newInstance(java.util.Set,java.util.EnumSet)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.GetApplicationsRequest:newInstance(java.util.Set,java.util.EnumSet)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.GetApplicationsRequest:getApplicationTypes()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.GetApplicationsRequest:getApplicationTypes()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.GetApplicationsRequest:setApplicationTypes(java.util.Set)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.GetApplicationsRequest:setApplicationTypes(java.util.Set)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.GetApplicationsRequest:getApplicationStates()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.GetApplicationsRequest:getApplicationStates()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.GetApplicationsRequest:setApplicationStates(java.util.EnumSet)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.GetApplicationsRequest:setApplicationStates(java.util.EnumSet)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.GetApplicationsRequest:setApplicationStates(java.util.Set)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.GetApplicationsRequest:setApplicationStates(java.util.Set)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.GetApplicationsRequest:getUsers()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.GetApplicationsRequest:getUsers()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.GetApplicationsRequest:setUsers(java.util.Set)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.GetApplicationsRequest:setUsers(java.util.Set)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.GetApplicationsRequest:getQueues()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.GetApplicationsRequest:getQueues()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.GetApplicationsRequest:setQueues(java.util.Set)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.GetApplicationsRequest:setQueues(java.util.Set)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.GetApplicationsRequest:getLimit()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.GetApplicationsRequest:getLimit()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.GetApplicationsRequest:setLimit(long)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.GetApplicationsRequest:setLimit(long)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.GetApplicationsRequest:getStartRange()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.GetApplicationsRequest:getStartRange()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.GetApplicationsRequest:setStartRange(org.apache.commons.lang3.Range)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.GetApplicationsRequest:setStartRange(org.apache.commons.lang3.Range)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.GetApplicationsRequest:setStartRange(long,long)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.GetApplicationsRequest:setStartRange(long,long)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.GetApplicationsRequest:getFinishRange()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.GetApplicationsRequest:getFinishRange()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.GetApplicationsRequest:setFinishRange(org.apache.commons.lang3.Range)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.GetApplicationsRequest:setFinishRange(org.apache.commons.lang3.Range)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.GetApplicationsRequest:setFinishRange(long,long)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.GetApplicationsRequest:setFinishRange(long,long)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.GetApplicationsRequest:getApplicationTags()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.GetApplicationsRequest:getApplicationTags()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.GetApplicationsRequest:setApplicationTags(java.util.Set)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.GetApplicationsRequest:setApplicationTags(java.util.Set)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.GetApplicationsRequest:getScope()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.GetApplicationsRequest:getScope()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.GetApplicationsRequest:setScope(org.apache.hadoop.yarn.api.protocolrecords.ApplicationsRequestScope)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.GetApplicationsRequest:setScope(org.apache.hadoop.yarn.api.protocolrecords.ApplicationsRequestScope)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.GetApplicationsRequest:getName()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.GetApplicationsRequest:getName()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.GetApplicationsRequest:setName(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.GetApplicationsRequest:setName(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.GetApplicationsResponse:newInstance(java.util.List)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.GetApplicationsResponse:newInstance(java.util.List)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.GetApplicationsResponse:getApplicationList()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.GetApplicationsResponse:getApplicationList()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.GetApplicationsResponse:setApplicationList(java.util.List)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.GetApplicationsResponse:setApplicationList(java.util.List)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.ReInitializeContainerRequest:newInstance(org.apache.hadoop.yarn.api.records.ContainerId,org.apache.hadoop.yarn.api.records.ContainerLaunchContext,boolean)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.ReInitializeContainerRequest:newInstance(org.apache.hadoop.yarn.api.records.ContainerId,org.apache.hadoop.yarn.api.records.ContainerLaunchContext,boolean)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.ReInitializeContainerRequest:getContainerId()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.ReInitializeContainerRequest:getContainerId()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.ReInitializeContainerRequest:setContainerId(org.apache.hadoop.yarn.api.records.ContainerId)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.ReInitializeContainerRequest:setContainerId(org.apache.hadoop.yarn.api.records.ContainerId)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.ReInitializeContainerRequest:getContainerLaunchContext()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.ReInitializeContainerRequest:getContainerLaunchContext()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.ReInitializeContainerRequest:setContainerLaunchContext(org.apache.hadoop.yarn.api.records.ContainerLaunchContext)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.ReInitializeContainerRequest:setContainerLaunchContext(org.apache.hadoop.yarn.api.records.ContainerLaunchContext)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.ReInitializeContainerRequest:getAutoCommit()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.ReInitializeContainerRequest:getAutoCommit()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.ReInitializeContainerRequest:setAutoCommit(boolean)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.ReInitializeContainerRequest:setAutoCommit(boolean)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.FinishApplicationMasterRequest:newInstance(org.apache.hadoop.yarn.api.records.FinalApplicationStatus,java.lang.String,java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.FinishApplicationMasterRequest:newInstance(org.apache.hadoop.yarn.api.records.FinalApplicationStatus,java.lang.String,java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.FinishApplicationMasterRequest:getFinalApplicationStatus()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.FinishApplicationMasterRequest:getFinalApplicationStatus()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.FinishApplicationMasterRequest:setFinalApplicationStatus(org.apache.hadoop.yarn.api.records.FinalApplicationStatus)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.FinishApplicationMasterRequest:setFinalApplicationStatus(org.apache.hadoop.yarn.api.records.FinalApplicationStatus)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.FinishApplicationMasterRequest:getDiagnostics()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.FinishApplicationMasterRequest:getDiagnostics()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.FinishApplicationMasterRequest:setDiagnostics(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.FinishApplicationMasterRequest:setDiagnostics(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.FinishApplicationMasterRequest:getTrackingUrl()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.FinishApplicationMasterRequest:getTrackingUrl()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.FinishApplicationMasterRequest:setTrackingUrl(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.FinishApplicationMasterRequest:setTrackingUrl(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.ResourceLocalizationRequest:newInstance(org.apache.hadoop.yarn.api.records.ContainerId,java.util.Map)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.ResourceLocalizationRequest:newInstance(org.apache.hadoop.yarn.api.records.ContainerId,java.util.Map)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.ResourceLocalizationRequest:getContainerId()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.ResourceLocalizationRequest:getContainerId()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.ResourceLocalizationRequest:setContainerId(org.apache.hadoop.yarn.api.records.ContainerId)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.ResourceLocalizationRequest:setContainerId(org.apache.hadoop.yarn.api.records.ContainerId)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.ResourceLocalizationRequest:getLocalResources()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.ResourceLocalizationRequest:getLocalResources()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.ResourceLocalizationRequest:setLocalResources(java.util.Map)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.ResourceLocalizationRequest:setLocalResources(java.util.Map)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.CommitResponse:newInstance()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.CommitResponse:newInstance()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.RegisterApplicationMasterResponse:newInstance(org.apache.hadoop.yarn.api.records.Resource,org.apache.hadoop.yarn.api.records.Resource,java.util.Map,java.nio.ByteBuffer,java.util.List,java.lang.String,java.util.List)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.RegisterApplicationMasterResponse:newInstance(org.apache.hadoop.yarn.api.records.Resource,org.apache.hadoop.yarn.api.records.Resource,java.util.Map,java.nio.ByteBuffer,java.util.List,java.lang.String,java.util.List)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.RegisterApplicationMasterResponse:getMaximumResourceCapability()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.RegisterApplicationMasterResponse:getMaximumResourceCapability()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.RegisterApplicationMasterResponse:setMaximumResourceCapability(org.apache.hadoop.yarn.api.records.Resource)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.RegisterApplicationMasterResponse:setMaximumResourceCapability(org.apache.hadoop.yarn.api.records.Resource)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.RegisterApplicationMasterResponse:getApplicationACLs()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.RegisterApplicationMasterResponse:getApplicationACLs()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.RegisterApplicationMasterResponse:setApplicationACLs(java.util.Map)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.RegisterApplicationMasterResponse:setApplicationACLs(java.util.Map)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.RegisterApplicationMasterResponse:getClientToAMTokenMasterKey()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.RegisterApplicationMasterResponse:getClientToAMTokenMasterKey()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.RegisterApplicationMasterResponse:setClientToAMTokenMasterKey(java.nio.ByteBuffer)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.RegisterApplicationMasterResponse:setClientToAMTokenMasterKey(java.nio.ByteBuffer)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.RegisterApplicationMasterResponse:getQueue()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.RegisterApplicationMasterResponse:getQueue()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.RegisterApplicationMasterResponse:setQueue(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.RegisterApplicationMasterResponse:setQueue(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.RegisterApplicationMasterResponse:getContainersFromPreviousAttempts()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.RegisterApplicationMasterResponse:getContainersFromPreviousAttempts()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.RegisterApplicationMasterResponse:setContainersFromPreviousAttempts(java.util.List)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.RegisterApplicationMasterResponse:setContainersFromPreviousAttempts(java.util.List)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.RegisterApplicationMasterResponse:getNMTokensFromPreviousAttempts()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.RegisterApplicationMasterResponse:getNMTokensFromPreviousAttempts()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.RegisterApplicationMasterResponse:setNMTokensFromPreviousAttempts(java.util.List)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.RegisterApplicationMasterResponse:setNMTokensFromPreviousAttempts(java.util.List)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.RegisterApplicationMasterResponse:getSchedulerResourceTypes()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.RegisterApplicationMasterResponse:getSchedulerResourceTypes()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.RegisterApplicationMasterResponse:setSchedulerResourceTypes(java.util.EnumSet)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.RegisterApplicationMasterResponse:setSchedulerResourceTypes(java.util.EnumSet)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.RegisterApplicationMasterResponse:getResourceProfiles()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.RegisterApplicationMasterResponse:getResourceProfiles()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.RegisterApplicationMasterResponse:setResourceProfiles(java.util.Map)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.RegisterApplicationMasterResponse:setResourceProfiles(java.util.Map)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.RegisterApplicationMasterResponse:getResourceTypes()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.RegisterApplicationMasterResponse:getResourceTypes()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.RegisterApplicationMasterResponse:setResourceTypes(java.util.List)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.RegisterApplicationMasterResponse:setResourceTypes(java.util.List)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.GetQueueUserAclsInfoRequest:newInstance()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.GetQueueUserAclsInfoRequest:newInstance()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.RestartContainerResponse:newInstance()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.RestartContainerResponse:newInstance()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.KillApplicationResponse:newInstance(boolean)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.KillApplicationResponse:newInstance(boolean)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.KillApplicationResponse:getIsKillCompleted()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.KillApplicationResponse:getIsKillCompleted()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.KillApplicationResponse:setIsKillCompleted(boolean)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.KillApplicationResponse:setIsKillCompleted(boolean)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.GetClusterMetricsResponse:newInstance(org.apache.hadoop.yarn.api.records.YarnClusterMetrics)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.GetClusterMetricsResponse:newInstance(org.apache.hadoop.yarn.api.records.YarnClusterMetrics)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.GetClusterMetricsResponse:getClusterMetrics()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.GetClusterMetricsResponse:getClusterMetrics()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.GetClusterMetricsResponse:setClusterMetrics(org.apache.hadoop.yarn.api.records.YarnClusterMetrics)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.GetClusterMetricsResponse:setClusterMetrics(org.apache.hadoop.yarn.api.records.YarnClusterMetrics)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse$AllocateResponseBuilder:amCommand(org.apache.hadoop.yarn.api.records.AMCommand)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse$AllocateResponseBuilder:amCommand(org.apache.hadoop.yarn.api.records.AMCommand)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse$AllocateResponseBuilder:responseId(int)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse$AllocateResponseBuilder:responseId(int)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse$AllocateResponseBuilder:allocatedContainers(java.util.List)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse$AllocateResponseBuilder:allocatedContainers(java.util.List)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse$AllocateResponseBuilder:availableResources(org.apache.hadoop.yarn.api.records.Resource)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse$AllocateResponseBuilder:availableResources(org.apache.hadoop.yarn.api.records.Resource)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse$AllocateResponseBuilder:completedContainersStatuses(java.util.List)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse$AllocateResponseBuilder:completedContainersStatuses(java.util.List)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse$AllocateResponseBuilder:updatedNodes(java.util.List)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse$AllocateResponseBuilder:updatedNodes(java.util.List)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse$AllocateResponseBuilder:numClusterNodes(int)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse$AllocateResponseBuilder:numClusterNodes(int)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse$AllocateResponseBuilder:preemptionMessage(org.apache.hadoop.yarn.api.records.PreemptionMessage)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse$AllocateResponseBuilder:preemptionMessage(org.apache.hadoop.yarn.api.records.PreemptionMessage)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse$AllocateResponseBuilder:nmTokens(java.util.List)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse$AllocateResponseBuilder:nmTokens(java.util.List)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse$AllocateResponseBuilder:updatedContainers(java.util.List)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse$AllocateResponseBuilder:updatedContainers(java.util.List)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse$AllocateResponseBuilder:amRmToken(org.apache.hadoop.yarn.api.records.Token)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse$AllocateResponseBuilder:amRmToken(org.apache.hadoop.yarn.api.records.Token)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse$AllocateResponseBuilder:applicationPriority(org.apache.hadoop.yarn.api.records.Priority)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse$AllocateResponseBuilder:applicationPriority(org.apache.hadoop.yarn.api.records.Priority)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse$AllocateResponseBuilder:collectorInfo(org.apache.hadoop.yarn.api.records.CollectorInfo)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse$AllocateResponseBuilder:collectorInfo(org.apache.hadoop.yarn.api.records.CollectorInfo)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse$AllocateResponseBuilder:updateErrors(java.util.List)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse$AllocateResponseBuilder:updateErrors(java.util.List)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse$AllocateResponseBuilder:containersFromPreviousAttempt(java.util.List)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse$AllocateResponseBuilder:containersFromPreviousAttempt(java.util.List)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse$AllocateResponseBuilder:build()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse$AllocateResponseBuilder:build()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.GetContainerReportRequest:newInstance(org.apache.hadoop.yarn.api.records.ContainerId)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.GetContainerReportRequest:newInstance(org.apache.hadoop.yarn.api.records.ContainerId)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.GetContainerReportRequest:getContainerId()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.GetContainerReportRequest:getContainerId()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.GetContainerReportRequest:setContainerId(org.apache.hadoop.yarn.api.records.ContainerId)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.GetContainerReportRequest:setContainerId(org.apache.hadoop.yarn.api.records.ContainerId)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.GetClusterNodesResponse:newInstance(java.util.List)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.GetClusterNodesResponse:newInstance(java.util.List)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.GetClusterNodesResponse:getNodeReports()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.GetClusterNodesResponse:getNodeReports()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.GetClusterNodesResponse:setNodeReports(java.util.List)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.GetClusterNodesResponse:setNodeReports(java.util.List)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.ReservationDeleteResponse:newInstance()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.ReservationDeleteResponse:newInstance()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.GetContainersResponse:newInstance(java.util.List)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.GetContainersResponse:newInstance(java.util.List)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.GetContainersResponse:getContainerList()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.GetContainersResponse:getContainerList()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.GetContainersResponse:setContainerList(java.util.List)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.GetContainersResponse:setContainerList(java.util.List)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.ReservationDeleteRequest:newInstance(org.apache.hadoop.yarn.api.records.ReservationId)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.ReservationDeleteRequest:newInstance(org.apache.hadoop.yarn.api.records.ReservationId)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.ReservationDeleteRequest:getReservationId()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.ReservationDeleteRequest:getReservationId()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.ReservationDeleteRequest:setReservationId(org.apache.hadoop.yarn.api.records.ReservationId)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.ReservationDeleteRequest:setReservationId(org.apache.hadoop.yarn.api.records.ReservationId)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse:newInstance(int,java.util.List,java.util.List,java.util.List,org.apache.hadoop.yarn.api.records.Resource,org.apache.hadoop.yarn.api.records.AMCommand,int,org.apache.hadoop.yarn.api.records.PreemptionMessage,java.util.List)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse:newInstance(int,java.util.List,java.util.List,java.util.List,org.apache.hadoop.yarn.api.records.Resource,org.apache.hadoop.yarn.api.records.AMCommand,int,org.apache.hadoop.yarn.api.records.PreemptionMessage,java.util.List)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse:newInstance(int,java.util.List,java.util.List,java.util.List,org.apache.hadoop.yarn.api.records.Resource,org.apache.hadoop.yarn.api.records.AMCommand,int,org.apache.hadoop.yarn.api.records.PreemptionMessage,java.util.List,org.apache.hadoop.yarn.api.records.CollectorInfo)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse:newInstance(int,java.util.List,java.util.List,java.util.List,org.apache.hadoop.yarn.api.records.Resource,org.apache.hadoop.yarn.api.records.AMCommand,int,org.apache.hadoop.yarn.api.records.PreemptionMessage,java.util.List,org.apache.hadoop.yarn.api.records.CollectorInfo)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse:newInstance(int,java.util.List,java.util.List,java.util.List,org.apache.hadoop.yarn.api.records.Resource,org.apache.hadoop.yarn.api.records.AMCommand,int,org.apache.hadoop.yarn.api.records.PreemptionMessage,java.util.List,org.apache.hadoop.yarn.api.records.Token,java.util.List)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse:newInstance(int,java.util.List,java.util.List,java.util.List,org.apache.hadoop.yarn.api.records.Resource,org.apache.hadoop.yarn.api.records.AMCommand,int,org.apache.hadoop.yarn.api.records.PreemptionMessage,java.util.List,org.apache.hadoop.yarn.api.records.Token,java.util.List)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse:newInstance(int,java.util.List,java.util.List,java.util.List,org.apache.hadoop.yarn.api.records.Resource,org.apache.hadoop.yarn.api.records.AMCommand,int,org.apache.hadoop.yarn.api.records.PreemptionMessage,java.util.List,org.apache.hadoop.yarn.api.records.Token,java.util.List,org.apache.hadoop.yarn.api.records.CollectorInfo)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse:newInstance(int,java.util.List,java.util.List,java.util.List,org.apache.hadoop.yarn.api.records.Resource,org.apache.hadoop.yarn.api.records.AMCommand,int,org.apache.hadoop.yarn.api.records.PreemptionMessage,java.util.List,org.apache.hadoop.yarn.api.records.Token,java.util.List,org.apache.hadoop.yarn.api.records.CollectorInfo)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse:getAMCommand()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse:getAMCommand()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse:setAMCommand(org.apache.hadoop.yarn.api.records.AMCommand)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse:setAMCommand(org.apache.hadoop.yarn.api.records.AMCommand)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse:getResponseId()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse:getResponseId()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse:setResponseId(int)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse:setResponseId(int)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse:getAllocatedContainers()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse:getAllocatedContainers()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse:setAllocatedContainers(java.util.List)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse:setAllocatedContainers(java.util.List)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse:getAvailableResources()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse:getAvailableResources()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse:setAvailableResources(org.apache.hadoop.yarn.api.records.Resource)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse:setAvailableResources(org.apache.hadoop.yarn.api.records.Resource)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse:getCompletedContainersStatuses()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse:getCompletedContainersStatuses()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse:setCompletedContainersStatuses(java.util.List)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse:setCompletedContainersStatuses(java.util.List)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse:getUpdatedNodes()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse:getUpdatedNodes()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse:setUpdatedNodes(java.util.List)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse:setUpdatedNodes(java.util.List)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse:getNumClusterNodes()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse:getNumClusterNodes()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse:setNumClusterNodes(int)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse:setNumClusterNodes(int)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse:getPreemptionMessage()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse:getPreemptionMessage()	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse:setPreemptionMessage(org.apache.hadoop.yarn.api.records.PreemptionMessage)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse:setPreemptionMessage(org.apache.hadoop.yarn.api.records.PreemptionMessage)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse:getNMTokens()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse:getNMTokens()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse:setNMTokens(java.util.List)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse:setNMTokens(java.util.List)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse:getUpdatedContainers()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse:getUpdatedContainers()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse:setUpdatedContainers(java.util.List)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse:setUpdatedContainers(java.util.List)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse:getAMRMToken()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse:getAMRMToken()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse:setAMRMToken(org.apache.hadoop.yarn.api.records.Token)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse:setAMRMToken(org.apache.hadoop.yarn.api.records.Token)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse:getApplicationPriority()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse:getApplicationPriority()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse:setApplicationPriority(org.apache.hadoop.yarn.api.records.Priority)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse:setApplicationPriority(org.apache.hadoop.yarn.api.records.Priority)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse:getCollectorInfo()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse:getCollectorInfo()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse:setCollectorInfo(org.apache.hadoop.yarn.api.records.CollectorInfo)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse:setCollectorInfo(org.apache.hadoop.yarn.api.records.CollectorInfo)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse:getUpdateErrors()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse:getUpdateErrors()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse:setUpdateErrors(java.util.List)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse:setUpdateErrors(java.util.List)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse:getContainersFromPreviousAttempts()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse:getContainersFromPreviousAttempts()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse:setContainersFromPreviousAttempts(java.util.List)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse:setContainersFromPreviousAttempts(java.util.List)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse:getRejectedSchedulingRequests()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse:getRejectedSchedulingRequests()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse:setRejectedSchedulingRequests(java.util.List)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse:setRejectedSchedulingRequests(java.util.List)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse:newBuilder()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse:newBuilder()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.CancelDelegationTokenResponse:newInstance()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.CancelDelegationTokenResponse:newInstance()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.StartContainerRequest:newInstance(org.apache.hadoop.yarn.api.records.ContainerLaunchContext,org.apache.hadoop.yarn.api.records.Token)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.StartContainerRequest:newInstance(org.apache.hadoop.yarn.api.records.ContainerLaunchContext,org.apache.hadoop.yarn.api.records.Token)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.StartContainerRequest:getContainerLaunchContext()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.StartContainerRequest:getContainerLaunchContext()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.StartContainerRequest:setContainerLaunchContext(org.apache.hadoop.yarn.api.records.ContainerLaunchContext)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.StartContainerRequest:setContainerLaunchContext(org.apache.hadoop.yarn.api.records.ContainerLaunchContext)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.StartContainerRequest:getContainerToken()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.StartContainerRequest:getContainerToken()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.StartContainerRequest:setContainerToken(org.apache.hadoop.yarn.api.records.Token)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.StartContainerRequest:setContainerToken(org.apache.hadoop.yarn.api.records.Token)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.ReservationUpdateRequest:newInstance(org.apache.hadoop.yarn.api.records.ReservationDefinition,org.apache.hadoop.yarn.api.records.ReservationId)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.ReservationUpdateRequest:newInstance(org.apache.hadoop.yarn.api.records.ReservationDefinition,org.apache.hadoop.yarn.api.records.ReservationId)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.ReservationUpdateRequest:getReservationDefinition()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.ReservationUpdateRequest:getReservationDefinition()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.ReservationUpdateRequest:setReservationDefinition(org.apache.hadoop.yarn.api.records.ReservationDefinition)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.ReservationUpdateRequest:setReservationDefinition(org.apache.hadoop.yarn.api.records.ReservationDefinition)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.ReservationUpdateRequest:getReservationId()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.ReservationUpdateRequest:getReservationId()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.ReservationUpdateRequest:setReservationId(org.apache.hadoop.yarn.api.records.ReservationId)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.ReservationUpdateRequest:setReservationId(org.apache.hadoop.yarn.api.records.ReservationId)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.FailApplicationAttemptRequest:newInstance(org.apache.hadoop.yarn.api.records.ApplicationAttemptId)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.FailApplicationAttemptRequest:newInstance(org.apache.hadoop.yarn.api.records.ApplicationAttemptId)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.FailApplicationAttemptRequest:getApplicationAttemptId()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.FailApplicationAttemptRequest:getApplicationAttemptId()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.FailApplicationAttemptRequest:setApplicationAttemptId(org.apache.hadoop.yarn.api.records.ApplicationAttemptId)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.FailApplicationAttemptRequest:setApplicationAttemptId(org.apache.hadoop.yarn.api.records.ApplicationAttemptId)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.UseSharedCacheResourceResponse:getPath()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.UseSharedCacheResourceResponse:getPath()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.UseSharedCacheResourceResponse:setPath(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.UseSharedCacheResourceResponse:setPath(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.StartContainersResponse:newInstance(java.util.Map,java.util.List,java.util.Map)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.StartContainersResponse:newInstance(java.util.Map,java.util.List,java.util.Map)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.StartContainersResponse:getSuccessfullyStartedContainers()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.StartContainersResponse:getSuccessfullyStartedContainers()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.StartContainersResponse:setSuccessfullyStartedContainers(java.util.List)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.StartContainersResponse:setSuccessfullyStartedContainers(java.util.List)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.StartContainersResponse:getFailedRequests()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.StartContainersResponse:getFailedRequests()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.StartContainersResponse:setFailedRequests(java.util.Map)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.StartContainersResponse:setFailedRequests(java.util.Map)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.StartContainersResponse:getAllServicesMetaData()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.StartContainersResponse:getAllServicesMetaData()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.StartContainersResponse:setAllServicesMetaData(java.util.Map)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.StartContainersResponse:setAllServicesMetaData(java.util.Map)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.ReservationUpdateResponse:newInstance()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.ReservationUpdateResponse:newInstance()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.GetNodesToLabelsResponse:setNodeToLabels(java.util.Map)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.GetNodesToLabelsResponse:setNodeToLabels(java.util.Map)	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.yarn.api.protocolrecords.GetNodesToLabelsResponse:getNodeToLabels()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.GetNodesToLabelsResponse:getNodeToLabels()	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.yarn.api.protocolrecords.IncreaseContainersResourceResponse:newInstance(java.util.List,java.util.Map)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.IncreaseContainersResourceResponse:newInstance(java.util.List,java.util.Map)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.IncreaseContainersResourceResponse:getSuccessfullyIncreasedContainers()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.IncreaseContainersResourceResponse:getSuccessfullyIncreasedContainers()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.IncreaseContainersResourceResponse:setSuccessfullyIncreasedContainers(java.util.List)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.IncreaseContainersResourceResponse:setSuccessfullyIncreasedContainers(java.util.List)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.IncreaseContainersResourceResponse:getFailedRequests()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.IncreaseContainersResourceResponse:getFailedRequests()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.IncreaseContainersResourceResponse:setFailedRequests(java.util.Map)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.IncreaseContainersResourceResponse:setFailedRequests(java.util.Map)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.GetApplicationAttemptReportRequest:newInstance(org.apache.hadoop.yarn.api.records.ApplicationAttemptId)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.GetApplicationAttemptReportRequest:newInstance(org.apache.hadoop.yarn.api.records.ApplicationAttemptId)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.GetApplicationAttemptReportRequest:getApplicationAttemptId()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.GetApplicationAttemptReportRequest:getApplicationAttemptId()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.GetApplicationAttemptReportRequest:setApplicationAttemptId(org.apache.hadoop.yarn.api.records.ApplicationAttemptId)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.GetApplicationAttemptReportRequest:setApplicationAttemptId(org.apache.hadoop.yarn.api.records.ApplicationAttemptId)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.ReservationListRequest:newInstance(java.lang.String,java.lang.String,long,long,boolean)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.ReservationListRequest:newInstance(java.lang.String,java.lang.String,long,long,boolean)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.ReservationListRequest:newInstance(java.lang.String,java.lang.String,boolean)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.ReservationListRequest:newInstance(java.lang.String,java.lang.String,boolean)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.ReservationListRequest:newInstance(java.lang.String,java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.ReservationListRequest:newInstance(java.lang.String,java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.ReservationListRequest:getQueue()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.ReservationListRequest:getQueue()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.ReservationListRequest:setQueue(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.ReservationListRequest:setQueue(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.ReservationListRequest:getReservationId()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.ReservationListRequest:getReservationId()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.ReservationListRequest:setReservationId(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.ReservationListRequest:setReservationId(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.ReservationListRequest:getStartTime()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.ReservationListRequest:getStartTime()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.ReservationListRequest:setStartTime(long)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.ReservationListRequest:setStartTime(long)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.ReservationListRequest:getEndTime()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.ReservationListRequest:getEndTime()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.ReservationListRequest:setEndTime(long)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.ReservationListRequest:setEndTime(long)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.ReservationListRequest:getIncludeResourceAllocations()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.ReservationListRequest:getIncludeResourceAllocations()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.ReservationListRequest:setIncludeResourceAllocations(boolean)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.ReservationListRequest:setIncludeResourceAllocations(boolean)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.SubmitApplicationRequest:newInstance(org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.SubmitApplicationRequest:newInstance(org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.SubmitApplicationRequest:getApplicationSubmissionContext()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.SubmitApplicationRequest:getApplicationSubmissionContext()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.SubmitApplicationRequest:setApplicationSubmissionContext(org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.SubmitApplicationRequest:setApplicationSubmissionContext(org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.GetLocalizationStatusesResponse:setLocalizationStatuses(java.util.Map)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.GetLocalizationStatusesResponse:getFailedRequests()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.GetLocalizationStatusesResponse:setFailedRequests(java.util.Map)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.GetNewApplicationRequest:newInstance()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.GetNewApplicationRequest:newInstance()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.GetDelegationTokenResponse:newInstance(org.apache.hadoop.yarn.api.records.Token)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.GetDelegationTokenResponse:newInstance(org.apache.hadoop.yarn.api.records.Token)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.GetDelegationTokenResponse:getRMDelegationToken()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.GetDelegationTokenResponse:getRMDelegationToken()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.GetDelegationTokenResponse:setRMDelegationToken(org.apache.hadoop.yarn.api.records.Token)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.GetDelegationTokenResponse:setRMDelegationToken(org.apache.hadoop.yarn.api.records.Token)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.GetApplicationAttemptsResponse:newInstance(java.util.List)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.GetApplicationAttemptsResponse:newInstance(java.util.List)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.GetApplicationAttemptsResponse:getApplicationAttemptList()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.GetApplicationAttemptsResponse:getApplicationAttemptList()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.GetApplicationAttemptsResponse:setApplicationAttemptList(java.util.List)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.GetApplicationAttemptsResponse:setApplicationAttemptList(java.util.List)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.GetQueueInfoResponse:newInstance(org.apache.hadoop.yarn.api.records.QueueInfo)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.GetQueueInfoResponse:newInstance(org.apache.hadoop.yarn.api.records.QueueInfo)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.GetQueueInfoResponse:getQueueInfo()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.GetQueueInfoResponse:getQueueInfo()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.GetQueueInfoResponse:setQueueInfo(org.apache.hadoop.yarn.api.records.QueueInfo)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.GetQueueInfoResponse:setQueueInfo(org.apache.hadoop.yarn.api.records.QueueInfo)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.FinishApplicationMasterResponse:newInstance(boolean)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.FinishApplicationMasterResponse:newInstance(boolean)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.FinishApplicationMasterResponse:getIsUnregistered()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.FinishApplicationMasterResponse:getIsUnregistered()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.FinishApplicationMasterResponse:setIsUnregistered(boolean)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.FinishApplicationMasterResponse:setIsUnregistered(boolean)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.ReservationSubmissionResponse:newInstance()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.ReservationSubmissionResponse:newInstance()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.ReservationListResponse:newInstance(java.util.List)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.ReservationListResponse:newInstance(java.util.List)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.ReservationListResponse:getReservationAllocationState()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.ReservationListResponse:getReservationAllocationState()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.ReservationListResponse:setReservationAllocationState(java.util.List)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.ReservationListResponse:setReservationAllocationState(java.util.List)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.GetNewReservationResponse:newInstance(org.apache.hadoop.yarn.api.records.ReservationId)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.GetNewReservationResponse:newInstance(org.apache.hadoop.yarn.api.records.ReservationId)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.GetNewReservationResponse:getReservationId()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.GetNewReservationResponse:getReservationId()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.GetNewReservationResponse:setReservationId(org.apache.hadoop.yarn.api.records.ReservationId)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.GetNewReservationResponse:setReservationId(org.apache.hadoop.yarn.api.records.ReservationId)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.ContainerUpdateResponse:getSuccessfullyUpdatedContainers()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.ContainerUpdateResponse:getSuccessfullyUpdatedContainers()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.ContainerUpdateResponse:setSuccessfullyUpdatedContainers(java.util.List)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.ContainerUpdateResponse:setSuccessfullyUpdatedContainers(java.util.List)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.ContainerUpdateResponse:getFailedRequests()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.ContainerUpdateResponse:getFailedRequests()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.ContainerUpdateResponse:setFailedRequests(java.util.Map)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.ContainerUpdateResponse:setFailedRequests(java.util.Map)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.AllocateRequest:newInstance(int,float,java.util.List,java.util.List,org.apache.hadoop.yarn.api.records.ResourceBlacklistRequest)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.AllocateRequest:newInstance(int,float,java.util.List,java.util.List,org.apache.hadoop.yarn.api.records.ResourceBlacklistRequest)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.AllocateRequest:newInstance(int,float,java.util.List,java.util.List,org.apache.hadoop.yarn.api.records.ResourceBlacklistRequest,java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.AllocateRequest:newInstance(int,float,java.util.List,java.util.List,org.apache.hadoop.yarn.api.records.ResourceBlacklistRequest,java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.AllocateRequest:newInstance(int,float,java.util.List,java.util.List,java.util.List,org.apache.hadoop.yarn.api.records.ResourceBlacklistRequest)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.AllocateRequest:newInstance(int,float,java.util.List,java.util.List,java.util.List,org.apache.hadoop.yarn.api.records.ResourceBlacklistRequest)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.AllocateRequest:getResponseId()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.AllocateRequest:getResponseId()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.AllocateRequest:setResponseId(int)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.AllocateRequest:setResponseId(int)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.AllocateRequest:getProgress()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.AllocateRequest:getProgress()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.AllocateRequest:setProgress(float)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.AllocateRequest:setProgress(float)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.AllocateRequest:getAskList()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.AllocateRequest:getAskList()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.AllocateRequest:setAskList(java.util.List)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.AllocateRequest:setAskList(java.util.List)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.AllocateRequest:getReleaseList()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.AllocateRequest:getReleaseList()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.AllocateRequest:setReleaseList(java.util.List)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.AllocateRequest:setReleaseList(java.util.List)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.AllocateRequest:getResourceBlacklistRequest()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.AllocateRequest:getResourceBlacklistRequest()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.AllocateRequest:setResourceBlacklistRequest(org.apache.hadoop.yarn.api.records.ResourceBlacklistRequest)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.AllocateRequest:setResourceBlacklistRequest(org.apache.hadoop.yarn.api.records.ResourceBlacklistRequest)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.AllocateRequest:getUpdateRequests()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.AllocateRequest:getUpdateRequests()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.AllocateRequest:setUpdateRequests(java.util.List)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.AllocateRequest:setUpdateRequests(java.util.List)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.AllocateRequest:getSchedulingRequests()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.AllocateRequest:getSchedulingRequests()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.AllocateRequest:setSchedulingRequests(java.util.List)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.AllocateRequest:setSchedulingRequests(java.util.List)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.AllocateRequest:getTrackingUrl()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.AllocateRequest:getTrackingUrl()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.AllocateRequest:setTrackingUrl(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.AllocateRequest:setTrackingUrl(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.AllocateRequest:newBuilder()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.AllocateRequest:newBuilder()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.UseSharedCacheResourceRequest:getAppId()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.UseSharedCacheResourceRequest:getAppId()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.UseSharedCacheResourceRequest:setAppId(org.apache.hadoop.yarn.api.records.ApplicationId)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.UseSharedCacheResourceRequest:setAppId(org.apache.hadoop.yarn.api.records.ApplicationId)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.UseSharedCacheResourceRequest:getResourceKey()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.UseSharedCacheResourceRequest:getResourceKey()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.UseSharedCacheResourceRequest:setResourceKey(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.UseSharedCacheResourceRequest:setResourceKey(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.SignalContainerRequest:newInstance(org.apache.hadoop.yarn.api.records.ContainerId,org.apache.hadoop.yarn.api.records.SignalContainerCommand)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.SignalContainerRequest:newInstance(org.apache.hadoop.yarn.api.records.ContainerId,org.apache.hadoop.yarn.api.records.SignalContainerCommand)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.SignalContainerRequest:getContainerId()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.SignalContainerRequest:getContainerId()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.SignalContainerRequest:setContainerId(org.apache.hadoop.yarn.api.records.ContainerId)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.SignalContainerRequest:setContainerId(org.apache.hadoop.yarn.api.records.ContainerId)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.SignalContainerRequest:getCommand()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.SignalContainerRequest:getCommand()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.SignalContainerRequest:setCommand(org.apache.hadoop.yarn.api.records.SignalContainerCommand)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.SignalContainerRequest:setCommand(org.apache.hadoop.yarn.api.records.SignalContainerCommand)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.GetQueueUserAclsInfoResponse:newInstance(java.util.List)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.GetQueueUserAclsInfoResponse:newInstance(java.util.List)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.GetQueueUserAclsInfoResponse:getUserAclsInfoList()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.GetQueueUserAclsInfoResponse:getUserAclsInfoList()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.GetQueueUserAclsInfoResponse:setUserAclsInfoList(java.util.List)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.GetQueueUserAclsInfoResponse:setUserAclsInfoList(java.util.List)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.RollbackResponse:newInstance()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.RollbackResponse:newInstance()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.SubmitApplicationResponse:newInstance()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.SubmitApplicationResponse:newInstance()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.GetApplicationReportResponse:newInstance(org.apache.hadoop.yarn.api.records.ApplicationReport)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.GetApplicationReportResponse:newInstance(org.apache.hadoop.yarn.api.records.ApplicationReport)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.GetApplicationReportResponse:getApplicationReport()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.GetApplicationReportResponse:getApplicationReport()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.GetApplicationReportResponse:setApplicationReport(org.apache.hadoop.yarn.api.records.ApplicationReport)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.GetApplicationReportResponse:setApplicationReport(org.apache.hadoop.yarn.api.records.ApplicationReport)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.ContainerUpdateRequest:newInstance(java.util.List)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.ContainerUpdateRequest:newInstance(java.util.List)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.ContainerUpdateRequest:getContainersToUpdate()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.ContainerUpdateRequest:getContainersToUpdate()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.ContainerUpdateRequest:setContainersToUpdate(java.util.List)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.ContainerUpdateRequest:setContainersToUpdate(java.util.List)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.IncreaseContainersResourceRequest:newInstance(java.util.List)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.IncreaseContainersResourceRequest:newInstance(java.util.List)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.IncreaseContainersResourceRequest:getContainersToIncrease()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.IncreaseContainersResourceRequest:getContainersToIncrease()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.IncreaseContainersResourceRequest:setContainersToIncrease(java.util.List)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.IncreaseContainersResourceRequest:setContainersToIncrease(java.util.List)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.GetLocalizationStatusesRequest:newInstance(java.util.List)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.GetLocalizationStatusesRequest:newInstance(java.util.List)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.GetLocalizationStatusesRequest:getContainerIds()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.GetLocalizationStatusesRequest:getContainerIds()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.GetLocalizationStatusesRequest:setContainerIds(java.util.List)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.GetLocalizationStatusesRequest:setContainerIds(java.util.List)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.KillApplicationRequest:newInstance(org.apache.hadoop.yarn.api.records.ApplicationId)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.KillApplicationRequest:newInstance(org.apache.hadoop.yarn.api.records.ApplicationId)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.KillApplicationRequest:getApplicationId()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.KillApplicationRequest:getApplicationId()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.KillApplicationRequest:setApplicationId(org.apache.hadoop.yarn.api.records.ApplicationId)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.KillApplicationRequest:setApplicationId(org.apache.hadoop.yarn.api.records.ApplicationId)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.protocolrecords.KillApplicationRequest:getDiagnostics()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.KillApplicationRequest:getDiagnostics()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.KillApplicationRequest:setDiagnostics(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.KillApplicationRequest:setDiagnostics(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.GetNodesToAttributesResponse:setNodeToAttributes(java.util.Map)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.GetNodesToAttributesResponse:setNodeToAttributes(java.util.Map)	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.yarn.api.protocolrecords.GetNodesToAttributesResponse:getNodeToAttributes()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.GetNodesToAttributesResponse:getNodeToAttributes()	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.yarn.api.protocolrecords.RenewDelegationTokenRequest:newInstance(org.apache.hadoop.yarn.api.records.Token)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.RenewDelegationTokenRequest:newInstance(org.apache.hadoop.yarn.api.records.Token)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.RenewDelegationTokenRequest:getDelegationToken()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.RenewDelegationTokenRequest:getDelegationToken()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.protocolrecords.RenewDelegationTokenRequest:setDelegationToken(org.apache.hadoop.yarn.api.records.Token)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.protocolrecords.RenewDelegationTokenRequest:setDelegationToken(org.apache.hadoop.yarn.api.records.Token)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.ApplicationMasterProtocol:registerApplicationMaster(org.apache.hadoop.yarn.api.protocolrecords.RegisterApplicationMasterRequest)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.ApplicationMasterProtocol:registerApplicationMaster(org.apache.hadoop.yarn.api.protocolrecords.RegisterApplicationMasterRequest)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.ApplicationMasterProtocol:registerApplicationMaster(org.apache.hadoop.yarn.api.protocolrecords.RegisterApplicationMasterRequest)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.yarn.api.ApplicationMasterProtocol:finishApplicationMaster(org.apache.hadoop.yarn.api.protocolrecords.FinishApplicationMasterRequest)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.ApplicationMasterProtocol:finishApplicationMaster(org.apache.hadoop.yarn.api.protocolrecords.FinishApplicationMasterRequest)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.ApplicationMasterProtocol:finishApplicationMaster(org.apache.hadoop.yarn.api.protocolrecords.FinishApplicationMasterRequest)	org.apache.hadoop.io.retry.AtMostOnce
org.apache.hadoop.yarn.api.ApplicationMasterProtocol:allocate(org.apache.hadoop.yarn.api.protocolrecords.AllocateRequest)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.ApplicationMasterProtocol:allocate(org.apache.hadoop.yarn.api.protocolrecords.AllocateRequest)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.ApplicationMasterProtocol:allocate(org.apache.hadoop.yarn.api.protocolrecords.AllocateRequest)	org.apache.hadoop.io.retry.AtMostOnce
org.apache.hadoop.yarn.api.records.UpdateContainerRequest:newInstance(int,org.apache.hadoop.yarn.api.records.ContainerId,org.apache.hadoop.yarn.api.records.ContainerUpdateType,org.apache.hadoop.yarn.api.records.Resource,org.apache.hadoop.yarn.api.records.ExecutionType)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.UpdateContainerRequest:newInstance(int,org.apache.hadoop.yarn.api.records.ContainerId,org.apache.hadoop.yarn.api.records.ContainerUpdateType,org.apache.hadoop.yarn.api.records.Resource,org.apache.hadoop.yarn.api.records.ExecutionType)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.UpdateContainerRequest:getContainerVersion()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.UpdateContainerRequest:getContainerVersion()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.UpdateContainerRequest:setContainerVersion(int)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.UpdateContainerRequest:setContainerVersion(int)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.UpdateContainerRequest:getContainerUpdateType()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.UpdateContainerRequest:getContainerUpdateType()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.UpdateContainerRequest:setContainerUpdateType(org.apache.hadoop.yarn.api.records.ContainerUpdateType)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.UpdateContainerRequest:setContainerUpdateType(org.apache.hadoop.yarn.api.records.ContainerUpdateType)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.UpdateContainerRequest:getContainerId()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.UpdateContainerRequest:getContainerId()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.UpdateContainerRequest:setContainerId(org.apache.hadoop.yarn.api.records.ContainerId)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.UpdateContainerRequest:setContainerId(org.apache.hadoop.yarn.api.records.ContainerId)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.UpdateContainerRequest:getExecutionType()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.UpdateContainerRequest:getExecutionType()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.UpdateContainerRequest:setExecutionType(org.apache.hadoop.yarn.api.records.ExecutionType)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.UpdateContainerRequest:setExecutionType(org.apache.hadoop.yarn.api.records.ExecutionType)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.UpdateContainerRequest:setCapability(org.apache.hadoop.yarn.api.records.Resource)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.UpdateContainerRequest:setCapability(org.apache.hadoop.yarn.api.records.Resource)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.UpdateContainerRequest:getCapability()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.UpdateContainerRequest:getCapability()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ReservationId:newInstance(long,long)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.ReservationId:newInstance(long,long)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ReservationId:getId()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ReservationId:getId()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ReservationId:setId(long)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.ReservationId:setId(long)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ReservationId:getClusterTimestamp()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ReservationId:getClusterTimestamp()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ReservationId:setClusterTimestamp(long)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.ReservationId:setClusterTimestamp(long)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ReservationId:parseReservationId(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ReservationId:parseReservationId(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ApplicationAttemptId:newInstance(org.apache.hadoop.yarn.api.records.ApplicationId,int)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ApplicationAttemptId:newInstance(org.apache.hadoop.yarn.api.records.ApplicationId,int)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ApplicationAttemptId:getApplicationId()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ApplicationAttemptId:getApplicationId()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.ApplicationAttemptId:setApplicationId(org.apache.hadoop.yarn.api.records.ApplicationId)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.ApplicationAttemptId:setApplicationId(org.apache.hadoop.yarn.api.records.ApplicationId)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ApplicationAttemptId:getAttemptId()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ApplicationAttemptId:getAttemptId()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.ApplicationAttemptId:setAttemptId(int)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.ApplicationAttemptId:setAttemptId(int)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ApplicationAttemptId:fromString(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ApplicationAttemptId:fromString(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.ApplicationId:newInstance(long,int)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ApplicationId:newInstance(long,int)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ApplicationId:getId()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ApplicationId:getId()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.ApplicationId:setId(int)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.ApplicationId:setId(int)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ApplicationId:getClusterTimestamp()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ApplicationId:getClusterTimestamp()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.ApplicationId:setClusterTimestamp(long)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.ApplicationId:setClusterTimestamp(long)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ApplicationId:fromString(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ApplicationId:fromString(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.ExecutionTypeRequest:newInstance()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ExecutionTypeRequest:newInstance()	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.yarn.api.records.ExecutionTypeRequest:newInstance(org.apache.hadoop.yarn.api.records.ExecutionType)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ExecutionTypeRequest:newInstance(org.apache.hadoop.yarn.api.records.ExecutionType)	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.yarn.api.records.ExecutionTypeRequest:newInstance(org.apache.hadoop.yarn.api.records.ExecutionType,boolean)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ExecutionTypeRequest:newInstance(org.apache.hadoop.yarn.api.records.ExecutionType,boolean)	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.yarn.api.records.ExecutionTypeRequest:setExecutionType(org.apache.hadoop.yarn.api.records.ExecutionType)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ExecutionTypeRequest:getExecutionType()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ExecutionTypeRequest:setEnforceExecutionType(boolean)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ExecutionTypeRequest:getEnforceExecutionType()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ResourceAllocationRequest:newInstance(long,long,org.apache.hadoop.yarn.api.records.Resource)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ResourceAllocationRequest:newInstance(long,long,org.apache.hadoop.yarn.api.records.Resource)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.ResourceAllocationRequest:getStartTime()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ResourceAllocationRequest:getStartTime()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ResourceAllocationRequest:setStartTime(long)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.ResourceAllocationRequest:setStartTime(long)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ResourceAllocationRequest:getEndTime()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ResourceAllocationRequest:getEndTime()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ResourceAllocationRequest:setEndTime(long)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.ResourceAllocationRequest:setEndTime(long)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ResourceAllocationRequest:getCapability()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ResourceAllocationRequest:getCapability()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ResourceAllocationRequest:setCapability(org.apache.hadoop.yarn.api.records.Resource)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.ResourceAllocationRequest:setCapability(org.apache.hadoop.yarn.api.records.Resource)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext:newInstance(org.apache.hadoop.yarn.api.records.ApplicationId,java.lang.String,java.lang.String,org.apache.hadoop.yarn.api.records.Priority,org.apache.hadoop.yarn.api.records.ContainerLaunchContext,boolean,boolean,int,org.apache.hadoop.yarn.api.records.Resource,java.lang.String,boolean,java.lang.String,java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext:newInstance(org.apache.hadoop.yarn.api.records.ApplicationId,java.lang.String,java.lang.String,org.apache.hadoop.yarn.api.records.Priority,org.apache.hadoop.yarn.api.records.ContainerLaunchContext,boolean,boolean,int,org.apache.hadoop.yarn.api.records.Resource,java.lang.String,boolean,java.lang.String,java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext:newInstance(org.apache.hadoop.yarn.api.records.ApplicationId,java.lang.String,java.lang.String,org.apache.hadoop.yarn.api.records.Priority,org.apache.hadoop.yarn.api.records.ContainerLaunchContext,boolean,boolean,int,org.apache.hadoop.yarn.api.records.Resource,java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext:newInstance(org.apache.hadoop.yarn.api.records.ApplicationId,java.lang.String,java.lang.String,org.apache.hadoop.yarn.api.records.Priority,org.apache.hadoop.yarn.api.records.ContainerLaunchContext,boolean,boolean,int,org.apache.hadoop.yarn.api.records.Resource,java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext:newInstance(org.apache.hadoop.yarn.api.records.ApplicationId,java.lang.String,java.lang.String,org.apache.hadoop.yarn.api.records.Priority,org.apache.hadoop.yarn.api.records.ContainerLaunchContext,boolean,boolean,int,org.apache.hadoop.yarn.api.records.Resource)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext:newInstance(org.apache.hadoop.yarn.api.records.ApplicationId,java.lang.String,java.lang.String,org.apache.hadoop.yarn.api.records.Priority,org.apache.hadoop.yarn.api.records.ContainerLaunchContext,boolean,boolean,int,org.apache.hadoop.yarn.api.records.Resource)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext:newInstance(org.apache.hadoop.yarn.api.records.ApplicationId,java.lang.String,java.lang.String,org.apache.hadoop.yarn.api.records.ContainerLaunchContext,boolean,boolean,int,java.lang.String,boolean,java.lang.String,org.apache.hadoop.yarn.api.records.ResourceRequest)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext:newInstance(org.apache.hadoop.yarn.api.records.ApplicationId,java.lang.String,java.lang.String,org.apache.hadoop.yarn.api.records.ContainerLaunchContext,boolean,boolean,int,java.lang.String,boolean,java.lang.String,org.apache.hadoop.yarn.api.records.ResourceRequest)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext:newInstance(org.apache.hadoop.yarn.api.records.ApplicationId,java.lang.String,java.lang.String,org.apache.hadoop.yarn.api.records.Priority,org.apache.hadoop.yarn.api.records.ContainerLaunchContext,boolean,boolean,int,org.apache.hadoop.yarn.api.records.Resource,java.lang.String,boolean,long)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext:newInstance(org.apache.hadoop.yarn.api.records.ApplicationId,java.lang.String,java.lang.String,org.apache.hadoop.yarn.api.records.Priority,org.apache.hadoop.yarn.api.records.ContainerLaunchContext,boolean,boolean,int,org.apache.hadoop.yarn.api.records.Resource,java.lang.String,boolean,long)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext:newInstance(org.apache.hadoop.yarn.api.records.ApplicationId,java.lang.String,java.lang.String,org.apache.hadoop.yarn.api.records.Priority,org.apache.hadoop.yarn.api.records.ContainerLaunchContext,boolean,boolean,int,org.apache.hadoop.yarn.api.records.Resource,java.lang.String,boolean,org.apache.hadoop.yarn.api.records.LogAggregationContext)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext:newInstance(org.apache.hadoop.yarn.api.records.ApplicationId,java.lang.String,java.lang.String,org.apache.hadoop.yarn.api.records.Priority,org.apache.hadoop.yarn.api.records.ContainerLaunchContext,boolean,boolean,int,org.apache.hadoop.yarn.api.records.Resource,java.lang.String,boolean,org.apache.hadoop.yarn.api.records.LogAggregationContext)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext:getApplicationId()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext:getApplicationId()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext:setApplicationId(org.apache.hadoop.yarn.api.records.ApplicationId)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext:setApplicationId(org.apache.hadoop.yarn.api.records.ApplicationId)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext:getApplicationName()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext:getApplicationName()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext:setApplicationName(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext:setApplicationName(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext:getQueue()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext:getQueue()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext:setQueue(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext:setQueue(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext:getPriority()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext:getPriority()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext:setPriority(org.apache.hadoop.yarn.api.records.Priority)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext:setPriority(org.apache.hadoop.yarn.api.records.Priority)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext:getAMContainerSpec()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext:getAMContainerSpec()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext:setAMContainerSpec(org.apache.hadoop.yarn.api.records.ContainerLaunchContext)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext:setAMContainerSpec(org.apache.hadoop.yarn.api.records.ContainerLaunchContext)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext:getUnmanagedAM()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext:getUnmanagedAM()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext:setUnmanagedAM(boolean)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext:setUnmanagedAM(boolean)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext:getCancelTokensWhenComplete()	org.apache.hadoop.classification.InterfaceAudience$LimitedPrivate	value	{mapreduce}
org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext:getCancelTokensWhenComplete()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext:setCancelTokensWhenComplete(boolean)	org.apache.hadoop.classification.InterfaceAudience$LimitedPrivate	value	{mapreduce}
org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext:setCancelTokensWhenComplete(boolean)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext:getMaxAppAttempts()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext:getMaxAppAttempts()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext:setMaxAppAttempts(int)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext:setMaxAppAttempts(int)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext:getResource()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext:setResource(org.apache.hadoop.yarn.api.records.Resource)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext:getApplicationType()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext:getApplicationType()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext:setApplicationType(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext:setApplicationType(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext:getKeepContainersAcrossApplicationAttempts()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext:getKeepContainersAcrossApplicationAttempts()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext:setKeepContainersAcrossApplicationAttempts(boolean)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext:setKeepContainersAcrossApplicationAttempts(boolean)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext:getApplicationTags()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext:getApplicationTags()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext:setApplicationTags(java.util.Set)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext:setApplicationTags(java.util.Set)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext:getNodeLabelExpression()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext:getNodeLabelExpression()	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext:setNodeLabelExpression(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext:setNodeLabelExpression(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext:getAMContainerResourceRequest()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext:getAMContainerResourceRequest()	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext:getAMContainerResourceRequest()	java.lang.Deprecated
org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext:setAMContainerResourceRequest(org.apache.hadoop.yarn.api.records.ResourceRequest)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext:setAMContainerResourceRequest(org.apache.hadoop.yarn.api.records.ResourceRequest)	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext:setAMContainerResourceRequest(org.apache.hadoop.yarn.api.records.ResourceRequest)	java.lang.Deprecated
org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext:getAMContainerResourceRequests()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext:getAMContainerResourceRequests()	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext:setAMContainerResourceRequests(java.util.List)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext:setAMContainerResourceRequests(java.util.List)	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext:getAttemptFailuresValidityInterval()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext:getAttemptFailuresValidityInterval()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext:setAttemptFailuresValidityInterval(long)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext:setAttemptFailuresValidityInterval(long)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext:getLogAggregationContext()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext:getLogAggregationContext()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext:setLogAggregationContext(org.apache.hadoop.yarn.api.records.LogAggregationContext)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext:setLogAggregationContext(org.apache.hadoop.yarn.api.records.LogAggregationContext)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext:getReservationID()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext:getReservationID()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext:setReservationID(org.apache.hadoop.yarn.api.records.ReservationId)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext:setReservationID(org.apache.hadoop.yarn.api.records.ReservationId)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext:getApplicationTimeouts()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext:getApplicationTimeouts()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext:setApplicationTimeouts(java.util.Map)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext:setApplicationTimeouts(java.util.Map)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext:getApplicationSchedulingPropertiesMap()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext:getApplicationSchedulingPropertiesMap()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext:setApplicationSchedulingPropertiesMap(java.util.Map)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext:setApplicationSchedulingPropertiesMap(java.util.Map)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.Token:newInstance(byte[],java.lang.String,byte[],java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.Token:newInstance(byte[],java.lang.String,byte[],java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.Token:getIdentifier()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.Token:getIdentifier()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.Token:setIdentifier(java.nio.ByteBuffer)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.Token:setIdentifier(java.nio.ByteBuffer)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.Token:getPassword()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.Token:getPassword()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.Token:setPassword(java.nio.ByteBuffer)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.Token:setPassword(java.nio.ByteBuffer)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.Token:getKind()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.Token:getKind()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.Token:setKind(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.Token:setKind(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.Token:getService()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.Token:getService()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.Token:setService(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.Token:setService(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ResourceInformation:setUnitsWithoutValidation(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.ApplicationTimeout:newInstance(org.apache.hadoop.yarn.api.records.ApplicationTimeoutType,java.lang.String,long)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ApplicationTimeout:newInstance(org.apache.hadoop.yarn.api.records.ApplicationTimeoutType,java.lang.String,long)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ApplicationTimeout:getTimeoutType()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ApplicationTimeout:getTimeoutType()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ApplicationTimeout:setTimeoutType(org.apache.hadoop.yarn.api.records.ApplicationTimeoutType)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ApplicationTimeout:setTimeoutType(org.apache.hadoop.yarn.api.records.ApplicationTimeoutType)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ApplicationTimeout:getExpiryTime()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ApplicationTimeout:getExpiryTime()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ApplicationTimeout:setExpiryTime(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ApplicationTimeout:setExpiryTime(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ApplicationTimeout:getRemainingTime()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ApplicationTimeout:getRemainingTime()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ApplicationTimeout:setRemainingTime(long)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ApplicationTimeout:setRemainingTime(long)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ResourceTypeInfo:newInstance(org.apache.hadoop.yarn.api.records.ResourceTypeInfo)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ResourceTypeInfo:newInstance(org.apache.hadoop.yarn.api.records.ResourceTypeInfo)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ResourceTypeInfo:newInstance(java.lang.String,java.lang.String,org.apache.hadoop.yarn.api.protocolrecords.ResourceTypes)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ResourceTypeInfo:newInstance(java.lang.String,java.lang.String,org.apache.hadoop.yarn.api.protocolrecords.ResourceTypes)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ResourceTypeInfo:newInstance(java.lang.String,java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ResourceTypeInfo:newInstance(java.lang.String,java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ResourceTypeInfo:newInstance(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ResourceTypeInfo:newInstance(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ResourceUtilization:newInstance(int,int,float)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ResourceUtilization:newInstance(int,int,float)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ResourceUtilization:newInstance(int,int,float,java.util.Map)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ResourceUtilization:newInstance(int,int,float,java.util.Map)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ResourceUtilization:newInstance(org.apache.hadoop.yarn.api.records.ResourceUtilization)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ResourceUtilization:newInstance(org.apache.hadoop.yarn.api.records.ResourceUtilization)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ResourceUtilization:getVirtualMemory()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ResourceUtilization:getVirtualMemory()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ResourceUtilization:setVirtualMemory(int)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ResourceUtilization:setVirtualMemory(int)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ResourceUtilization:getPhysicalMemory()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ResourceUtilization:getPhysicalMemory()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ResourceUtilization:setPhysicalMemory(int)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ResourceUtilization:setPhysicalMemory(int)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ResourceUtilization:getCPU()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ResourceUtilization:getCPU()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ResourceUtilization:setCPU(float)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ResourceUtilization:setCPU(float)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ResourceUtilization:getCustomResource(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ResourceUtilization:getCustomResource(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ResourceUtilization:getCustomResources()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ResourceUtilization:getCustomResources()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ResourceUtilization:setCustomResources(java.util.Map)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ResourceUtilization:setCustomResources(java.util.Map)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ResourceUtilization:setCustomResource(java.lang.String,float)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ResourceUtilization:setCustomResource(java.lang.String,float)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ResourceUtilization:addTo(int,int,float)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ResourceUtilization:addTo(int,int,float)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ResourceUtilization:addTo(int,int,float,java.lang.String,float)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ResourceUtilization:addTo(int,int,float,java.lang.String,float)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ResourceUtilization:subtractFrom(int,int,float)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ResourceUtilization:subtractFrom(int,int,float)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ResourceUtilization:subtractFrom(int,int,float,java.lang.String,float)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ResourceUtilization:subtractFrom(int,int,float,java.lang.String,float)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.LogAggregationContext:newInstance(java.lang.String,java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.LogAggregationContext:newInstance(java.lang.String,java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.LogAggregationContext:newInstance(java.lang.String,java.lang.String,java.lang.String,java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.LogAggregationContext:newInstance(java.lang.String,java.lang.String,java.lang.String,java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.LogAggregationContext:newInstance(java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.LogAggregationContext:newInstance(java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.LogAggregationContext:getIncludePattern()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.LogAggregationContext:getIncludePattern()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.LogAggregationContext:setIncludePattern(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.LogAggregationContext:setIncludePattern(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.LogAggregationContext:getExcludePattern()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.LogAggregationContext:getExcludePattern()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.LogAggregationContext:setExcludePattern(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.LogAggregationContext:setExcludePattern(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.LogAggregationContext:getRolledLogsIncludePattern()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.LogAggregationContext:getRolledLogsIncludePattern()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.LogAggregationContext:setRolledLogsIncludePattern(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.LogAggregationContext:setRolledLogsIncludePattern(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.LogAggregationContext:getRolledLogsExcludePattern()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.LogAggregationContext:getRolledLogsExcludePattern()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.LogAggregationContext:setRolledLogsExcludePattern(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.LogAggregationContext:setRolledLogsExcludePattern(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.LogAggregationContext:getLogAggregationPolicyClassName()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.LogAggregationContext:getLogAggregationPolicyClassName()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.LogAggregationContext:setLogAggregationPolicyClassName(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.LogAggregationContext:setLogAggregationPolicyClassName(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.LogAggregationContext:getLogAggregationPolicyParameters()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.LogAggregationContext:getLogAggregationPolicyParameters()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.LogAggregationContext:setLogAggregationPolicyParameters(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.LogAggregationContext:setLogAggregationPolicyParameters(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.NMToken:newInstance(org.apache.hadoop.yarn.api.records.NodeId,org.apache.hadoop.yarn.api.records.Token)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.NMToken:newInstance(org.apache.hadoop.yarn.api.records.NodeId,org.apache.hadoop.yarn.api.records.Token)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.NMToken:getNodeId()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.NMToken:getNodeId()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.NMToken:setNodeId(org.apache.hadoop.yarn.api.records.NodeId)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.NMToken:setNodeId(org.apache.hadoop.yarn.api.records.NodeId)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.NMToken:getToken()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.NMToken:getToken()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.NMToken:setToken(org.apache.hadoop.yarn.api.records.Token)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.NMToken:setToken(org.apache.hadoop.yarn.api.records.Token)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.YarnClusterMetrics:newInstance(int)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.YarnClusterMetrics:newInstance(int)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.YarnClusterMetrics:getNumNodeManagers()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.YarnClusterMetrics:getNumNodeManagers()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.YarnClusterMetrics:setNumNodeManagers(int)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.YarnClusterMetrics:setNumNodeManagers(int)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.YarnClusterMetrics:getNumDecommissioningNodeManagers()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.YarnClusterMetrics:getNumDecommissioningNodeManagers()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.YarnClusterMetrics:setNumDecommissioningNodeManagers(int)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.YarnClusterMetrics:setNumDecommissioningNodeManagers(int)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.YarnClusterMetrics:getNumDecommissionedNodeManagers()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.YarnClusterMetrics:getNumDecommissionedNodeManagers()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.YarnClusterMetrics:setNumDecommissionedNodeManagers(int)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.YarnClusterMetrics:setNumDecommissionedNodeManagers(int)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.YarnClusterMetrics:getNumActiveNodeManagers()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.YarnClusterMetrics:getNumActiveNodeManagers()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.YarnClusterMetrics:setNumActiveNodeManagers(int)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.YarnClusterMetrics:setNumActiveNodeManagers(int)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.YarnClusterMetrics:getNumLostNodeManagers()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.YarnClusterMetrics:getNumLostNodeManagers()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.YarnClusterMetrics:setNumLostNodeManagers(int)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.YarnClusterMetrics:setNumLostNodeManagers(int)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.YarnClusterMetrics:getNumUnhealthyNodeManagers()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.YarnClusterMetrics:getNumUnhealthyNodeManagers()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.YarnClusterMetrics:setNumUnhealthyNodeManagers(int)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.YarnClusterMetrics:setNumUnhealthyNodeManagers(int)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.YarnClusterMetrics:getNumRebootedNodeManagers()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.YarnClusterMetrics:getNumRebootedNodeManagers()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.YarnClusterMetrics:setNumRebootedNodeManagers(int)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.YarnClusterMetrics:setNumRebootedNodeManagers(int)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.YarnClusterMetrics:getNumShutdownNodeManagers()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.YarnClusterMetrics:getNumShutdownNodeManagers()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.YarnClusterMetrics:setNumShutdownNodeManagers(int)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.YarnClusterMetrics:setNumShutdownNodeManagers(int)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ResourceRequest$ResourceRequestBuilder:priority(org.apache.hadoop.yarn.api.records.Priority)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ResourceRequest$ResourceRequestBuilder:priority(org.apache.hadoop.yarn.api.records.Priority)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.ResourceRequest$ResourceRequestBuilder:resourceName(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ResourceRequest$ResourceRequestBuilder:resourceName(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.ResourceRequest$ResourceRequestBuilder:capability(org.apache.hadoop.yarn.api.records.Resource)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ResourceRequest$ResourceRequestBuilder:capability(org.apache.hadoop.yarn.api.records.Resource)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.ResourceRequest$ResourceRequestBuilder:numContainers(int)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ResourceRequest$ResourceRequestBuilder:numContainers(int)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.ResourceRequest$ResourceRequestBuilder:relaxLocality(boolean)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ResourceRequest$ResourceRequestBuilder:relaxLocality(boolean)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.ResourceRequest$ResourceRequestBuilder:nodeLabelExpression(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ResourceRequest$ResourceRequestBuilder:nodeLabelExpression(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.yarn.api.records.ResourceRequest$ResourceRequestBuilder:executionTypeRequest(org.apache.hadoop.yarn.api.records.ExecutionTypeRequest)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ResourceRequest$ResourceRequestBuilder:executionTypeRequest(org.apache.hadoop.yarn.api.records.ExecutionTypeRequest)	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.yarn.api.records.ResourceRequest$ResourceRequestBuilder:executionType(org.apache.hadoop.yarn.api.records.ExecutionType)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ResourceRequest$ResourceRequestBuilder:executionType(org.apache.hadoop.yarn.api.records.ExecutionType)	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.yarn.api.records.ResourceRequest$ResourceRequestBuilder:allocationRequestId(long)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ResourceRequest$ResourceRequestBuilder:allocationRequestId(long)	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.yarn.api.records.ResourceRequest$ResourceRequestBuilder:build()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ResourceRequest$ResourceRequestBuilder:build()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.UpdateContainerError:newInstance(java.lang.String,org.apache.hadoop.yarn.api.records.UpdateContainerRequest)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.UpdateContainerError:newInstance(java.lang.String,org.apache.hadoop.yarn.api.records.UpdateContainerRequest)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.UpdateContainerError:getReason()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.UpdateContainerError:getReason()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.UpdateContainerError:setReason(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.UpdateContainerError:setReason(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.UpdateContainerError:getCurrentContainerVersion()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.UpdateContainerError:getCurrentContainerVersion()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.UpdateContainerError:setCurrentContainerVersion(int)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.UpdateContainerError:setCurrentContainerVersion(int)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.UpdateContainerError:getUpdateContainerRequest()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.UpdateContainerError:getUpdateContainerRequest()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.UpdateContainerError:setUpdateContainerRequest(org.apache.hadoop.yarn.api.records.UpdateContainerRequest)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.UpdateContainerError:setUpdateContainerRequest(org.apache.hadoop.yarn.api.records.UpdateContainerRequest)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.NodeAttribute:getAttributeKey()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.NodeAttribute:getAttributeKey()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.NodeAttribute:setAttributeKey(org.apache.hadoop.yarn.api.records.NodeAttributeKey)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.NodeAttribute:setAttributeKey(org.apache.hadoop.yarn.api.records.NodeAttributeKey)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.NodeAttribute:getAttributeValue()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.NodeAttribute:getAttributeValue()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.NodeAttribute:setAttributeValue(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.NodeAttribute:setAttributeValue(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.NodeAttribute:getAttributeType()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.NodeAttribute:getAttributeType()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.NodeAttribute:setAttributeType(org.apache.hadoop.yarn.api.records.NodeAttributeType)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.NodeAttribute:setAttributeType(org.apache.hadoop.yarn.api.records.NodeAttributeType)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.PreemptionMessage:newInstance(org.apache.hadoop.yarn.api.records.StrictPreemptionContract,org.apache.hadoop.yarn.api.records.PreemptionContract)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.PreemptionMessage:newInstance(org.apache.hadoop.yarn.api.records.StrictPreemptionContract,org.apache.hadoop.yarn.api.records.PreemptionContract)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.PreemptionMessage:getStrictContract()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.PreemptionMessage:getStrictContract()	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.yarn.api.records.PreemptionMessage:setStrictContract(org.apache.hadoop.yarn.api.records.StrictPreemptionContract)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.PreemptionMessage:setStrictContract(org.apache.hadoop.yarn.api.records.StrictPreemptionContract)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.PreemptionMessage:getContract()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.PreemptionMessage:getContract()	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.yarn.api.records.PreemptionMessage:setContract(org.apache.hadoop.yarn.api.records.PreemptionContract)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.PreemptionMessage:setContract(org.apache.hadoop.yarn.api.records.PreemptionContract)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.Container:newInstance(org.apache.hadoop.yarn.api.records.ContainerId,org.apache.hadoop.yarn.api.records.NodeId,java.lang.String,org.apache.hadoop.yarn.api.records.Resource,org.apache.hadoop.yarn.api.records.Priority,org.apache.hadoop.yarn.api.records.Token)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.Container:newInstance(org.apache.hadoop.yarn.api.records.ContainerId,org.apache.hadoop.yarn.api.records.NodeId,java.lang.String,org.apache.hadoop.yarn.api.records.Resource,org.apache.hadoop.yarn.api.records.Priority,org.apache.hadoop.yarn.api.records.Token)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.Container:newInstance(org.apache.hadoop.yarn.api.records.ContainerId,org.apache.hadoop.yarn.api.records.NodeId,java.lang.String,org.apache.hadoop.yarn.api.records.Resource,org.apache.hadoop.yarn.api.records.Priority,org.apache.hadoop.yarn.api.records.Token,org.apache.hadoop.yarn.api.records.ExecutionType)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.Container:newInstance(org.apache.hadoop.yarn.api.records.ContainerId,org.apache.hadoop.yarn.api.records.NodeId,java.lang.String,org.apache.hadoop.yarn.api.records.Resource,org.apache.hadoop.yarn.api.records.Priority,org.apache.hadoop.yarn.api.records.Token,org.apache.hadoop.yarn.api.records.ExecutionType)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.Container:getId()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.Container:getId()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.Container:setId(org.apache.hadoop.yarn.api.records.ContainerId)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.Container:setId(org.apache.hadoop.yarn.api.records.ContainerId)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.Container:getNodeId()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.Container:getNodeId()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.Container:setNodeId(org.apache.hadoop.yarn.api.records.NodeId)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.Container:setNodeId(org.apache.hadoop.yarn.api.records.NodeId)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.Container:getNodeHttpAddress()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.Container:getNodeHttpAddress()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.Container:setNodeHttpAddress(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.Container:setNodeHttpAddress(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.Container:getExposedPorts()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.Container:getExposedPorts()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.Container:setExposedPorts(java.util.Map)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.Container:setExposedPorts(java.util.Map)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.Container:getResource()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.Container:getResource()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.Container:setResource(org.apache.hadoop.yarn.api.records.Resource)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.Container:setResource(org.apache.hadoop.yarn.api.records.Resource)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.Container:getPriority()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.Container:getPriority()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.Container:setPriority(org.apache.hadoop.yarn.api.records.Priority)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.Container:setPriority(org.apache.hadoop.yarn.api.records.Priority)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.Container:getContainerToken()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.Container:getContainerToken()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.Container:setContainerToken(org.apache.hadoop.yarn.api.records.Token)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.Container:setContainerToken(org.apache.hadoop.yarn.api.records.Token)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.Container:getExecutionType()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.Container:getExecutionType()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.Container:setExecutionType(org.apache.hadoop.yarn.api.records.ExecutionType)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.Container:setExecutionType(org.apache.hadoop.yarn.api.records.ExecutionType)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.Container:getAllocationRequestId()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.Container:getAllocationRequestId()	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.yarn.api.records.Container:setAllocationRequestId(long)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.Container:setAllocationRequestId(long)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.Container:getVersion()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.Container:getVersion()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.Container:setVersion(int)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.Container:setVersion(int)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.Container:getAllocationTags()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.Container:getAllocationTags()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.Container:setAllocationTags(java.util.Set)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.Container:setAllocationTags(java.util.Set)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.PreemptionContract:newInstance(java.util.List,java.util.Set)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.PreemptionContract:newInstance(java.util.List,java.util.Set)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.PreemptionContract:getResourceRequest()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.PreemptionContract:getResourceRequest()	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.yarn.api.records.PreemptionContract:setResourceRequest(java.util.List)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.PreemptionContract:setResourceRequest(java.util.List)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.PreemptionContract:getContainers()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.PreemptionContract:getContainers()	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.yarn.api.records.PreemptionContract:setContainers(java.util.Set)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.PreemptionContract:setContainers(java.util.Set)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.PreemptionResourceRequest:newInstance(org.apache.hadoop.yarn.api.records.ResourceRequest)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.PreemptionResourceRequest:newInstance(org.apache.hadoop.yarn.api.records.ResourceRequest)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.PreemptionResourceRequest:getResourceRequest()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.PreemptionResourceRequest:getResourceRequest()	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.yarn.api.records.PreemptionResourceRequest:setResourceRequest(org.apache.hadoop.yarn.api.records.ResourceRequest)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.PreemptionResourceRequest:setResourceRequest(org.apache.hadoop.yarn.api.records.ResourceRequest)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ContainerId:newContainerId(org.apache.hadoop.yarn.api.records.ApplicationAttemptId,long)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ContainerId:newContainerId(org.apache.hadoop.yarn.api.records.ApplicationAttemptId,long)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ContainerId:newInstance(org.apache.hadoop.yarn.api.records.ApplicationAttemptId,int)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.ContainerId:newInstance(org.apache.hadoop.yarn.api.records.ApplicationAttemptId,int)	java.lang.Deprecated
org.apache.hadoop.yarn.api.records.ContainerId:newInstance(org.apache.hadoop.yarn.api.records.ApplicationAttemptId,int)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ContainerId:getApplicationAttemptId()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ContainerId:getApplicationAttemptId()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.ContainerId:setApplicationAttemptId(org.apache.hadoop.yarn.api.records.ApplicationAttemptId)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.ContainerId:setApplicationAttemptId(org.apache.hadoop.yarn.api.records.ApplicationAttemptId)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ContainerId:getId()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ContainerId:getId()	java.lang.Deprecated
org.apache.hadoop.yarn.api.records.ContainerId:getId()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ContainerId:getContainerId()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ContainerId:getContainerId()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ContainerId:setContainerId(long)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.ContainerId:setContainerId(long)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ContainerId:fromString(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ContainerId:fromString(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.ResourceSizing:newInstance(org.apache.hadoop.yarn.api.records.Resource)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ResourceSizing:newInstance(org.apache.hadoop.yarn.api.records.Resource)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ResourceSizing:newInstance(int,org.apache.hadoop.yarn.api.records.Resource)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ResourceSizing:newInstance(int,org.apache.hadoop.yarn.api.records.Resource)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ResourceSizing:getNumAllocations()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ResourceSizing:getNumAllocations()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ResourceSizing:setNumAllocations(int)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ResourceSizing:setNumAllocations(int)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ResourceSizing:getResources()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ResourceSizing:getResources()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ResourceSizing:setResources(org.apache.hadoop.yarn.api.records.Resource)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ResourceSizing:setResources(org.apache.hadoop.yarn.api.records.Resource)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ContainerReport:newInstance(org.apache.hadoop.yarn.api.records.ContainerId,org.apache.hadoop.yarn.api.records.Resource,org.apache.hadoop.yarn.api.records.NodeId,org.apache.hadoop.yarn.api.records.Priority,long,long,java.lang.String,java.lang.String,int,org.apache.hadoop.yarn.api.records.ContainerState,java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.ContainerReport:newInstance(org.apache.hadoop.yarn.api.records.ContainerId,org.apache.hadoop.yarn.api.records.Resource,org.apache.hadoop.yarn.api.records.NodeId,org.apache.hadoop.yarn.api.records.Priority,long,long,java.lang.String,java.lang.String,int,org.apache.hadoop.yarn.api.records.ContainerState,java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ContainerReport:newInstance(org.apache.hadoop.yarn.api.records.ContainerId,org.apache.hadoop.yarn.api.records.Resource,org.apache.hadoop.yarn.api.records.NodeId,org.apache.hadoop.yarn.api.records.Priority,long,long,java.lang.String,java.lang.String,int,org.apache.hadoop.yarn.api.records.ContainerState,java.lang.String,org.apache.hadoop.yarn.api.records.ExecutionType)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.ContainerReport:newInstance(org.apache.hadoop.yarn.api.records.ContainerId,org.apache.hadoop.yarn.api.records.Resource,org.apache.hadoop.yarn.api.records.NodeId,org.apache.hadoop.yarn.api.records.Priority,long,long,java.lang.String,java.lang.String,int,org.apache.hadoop.yarn.api.records.ContainerState,java.lang.String,org.apache.hadoop.yarn.api.records.ExecutionType)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ContainerReport:getContainerId()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ContainerReport:getContainerId()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ContainerReport:setContainerId(org.apache.hadoop.yarn.api.records.ContainerId)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ContainerReport:setContainerId(org.apache.hadoop.yarn.api.records.ContainerId)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ContainerReport:getAllocatedResource()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ContainerReport:getAllocatedResource()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ContainerReport:setAllocatedResource(org.apache.hadoop.yarn.api.records.Resource)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ContainerReport:setAllocatedResource(org.apache.hadoop.yarn.api.records.Resource)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ContainerReport:getAssignedNode()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ContainerReport:getAssignedNode()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ContainerReport:setAssignedNode(org.apache.hadoop.yarn.api.records.NodeId)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ContainerReport:setAssignedNode(org.apache.hadoop.yarn.api.records.NodeId)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ContainerReport:getPriority()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ContainerReport:getPriority()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ContainerReport:setPriority(org.apache.hadoop.yarn.api.records.Priority)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ContainerReport:setPriority(org.apache.hadoop.yarn.api.records.Priority)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ContainerReport:getCreationTime()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ContainerReport:getCreationTime()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ContainerReport:setCreationTime(long)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ContainerReport:setCreationTime(long)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ContainerReport:getFinishTime()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ContainerReport:getFinishTime()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ContainerReport:setFinishTime(long)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ContainerReport:setFinishTime(long)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ContainerReport:getDiagnosticsInfo()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ContainerReport:getDiagnosticsInfo()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ContainerReport:setDiagnosticsInfo(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ContainerReport:setDiagnosticsInfo(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ContainerReport:getLogUrl()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ContainerReport:getLogUrl()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ContainerReport:setLogUrl(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ContainerReport:setLogUrl(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ContainerReport:getContainerState()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ContainerReport:getContainerState()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ContainerReport:setContainerState(org.apache.hadoop.yarn.api.records.ContainerState)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ContainerReport:setContainerState(org.apache.hadoop.yarn.api.records.ContainerState)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ContainerReport:getContainerExitStatus()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ContainerReport:getContainerExitStatus()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ContainerReport:setContainerExitStatus(int)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ContainerReport:setContainerExitStatus(int)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ContainerReport:getExposedPorts()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ContainerReport:getExposedPorts()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ContainerReport:setExposedPorts(java.util.Map)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.ContainerReport:setExposedPorts(java.util.Map)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ContainerReport:getNodeHttpAddress()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ContainerReport:getNodeHttpAddress()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ContainerReport:setNodeHttpAddress(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.ContainerReport:setNodeHttpAddress(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ContainerReport:getExecutionType()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ContainerReport:getExecutionType()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ContainerReport:setExecutionType(org.apache.hadoop.yarn.api.records.ExecutionType)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.ContainerReport:setExecutionType(org.apache.hadoop.yarn.api.records.ExecutionType)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.Resource:newInstance(int,int)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.Resource:newInstance(int,int)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.Resource:newInstance(long,int)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.Resource:newInstance(long,int)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.Resource:newInstance(long,int,java.util.Map)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.Resource:newInstance(long,int,java.util.Map)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.Resource:newInstance(org.apache.hadoop.yarn.api.records.Resource)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.Resource:newInstance(org.apache.hadoop.yarn.api.records.Resource)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.Resource:copy(org.apache.hadoop.yarn.api.records.Resource,org.apache.hadoop.yarn.api.records.Resource)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.Resource:copy(org.apache.hadoop.yarn.api.records.Resource,org.apache.hadoop.yarn.api.records.Resource)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.Resource:getMemory()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.Resource:getMemory()	java.lang.Deprecated
org.apache.hadoop.yarn.api.records.Resource:getMemorySize()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.Resource:getMemorySize()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.Resource:setMemory(int)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.Resource:setMemory(int)	java.lang.Deprecated
org.apache.hadoop.yarn.api.records.Resource:setMemorySize(long)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.Resource:setMemorySize(long)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.Resource:getVirtualCores()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.Resource:getVirtualCores()	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.yarn.api.records.Resource:setVirtualCores(int)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.Resource:setVirtualCores(int)	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.yarn.api.records.Resource:getResources()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.Resource:getResources()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.Resource:getAllResourcesListCopy()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.Resource:getAllResourcesListCopy()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.Resource:getResourceInformation(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.Resource:getResourceInformation(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.Resource:getResourceInformation(int)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.Resource:getResourceInformation(int)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.Resource:getResourceValue(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.Resource:getResourceValue(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.Resource:setResourceInformation(java.lang.String,org.apache.hadoop.yarn.api.records.ResourceInformation)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.Resource:setResourceInformation(java.lang.String,org.apache.hadoop.yarn.api.records.ResourceInformation)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.Resource:setResourceInformation(int,org.apache.hadoop.yarn.api.records.ResourceInformation)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.Resource:setResourceInformation(int,org.apache.hadoop.yarn.api.records.ResourceInformation)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.Resource:setResourceValue(java.lang.String,long)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.Resource:setResourceValue(java.lang.String,long)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.Resource:setResourceValue(int,long)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.Resource:setResourceValue(int,long)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ApplicationReport:newInstance(org.apache.hadoop.yarn.api.records.ApplicationId,org.apache.hadoop.yarn.api.records.ApplicationAttemptId,java.lang.String,java.lang.String,java.lang.String,java.lang.String,int,org.apache.hadoop.yarn.api.records.Token,org.apache.hadoop.yarn.api.records.YarnApplicationState,java.lang.String,java.lang.String,long,long,long,org.apache.hadoop.yarn.api.records.FinalApplicationStatus,org.apache.hadoop.yarn.api.records.ApplicationResourceUsageReport,java.lang.String,float,java.lang.String,org.apache.hadoop.yarn.api.records.Token)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.ApplicationReport:newInstance(org.apache.hadoop.yarn.api.records.ApplicationId,org.apache.hadoop.yarn.api.records.ApplicationAttemptId,java.lang.String,java.lang.String,java.lang.String,java.lang.String,int,org.apache.hadoop.yarn.api.records.Token,org.apache.hadoop.yarn.api.records.YarnApplicationState,java.lang.String,java.lang.String,long,long,long,org.apache.hadoop.yarn.api.records.FinalApplicationStatus,org.apache.hadoop.yarn.api.records.ApplicationResourceUsageReport,java.lang.String,float,java.lang.String,org.apache.hadoop.yarn.api.records.Token)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ApplicationReport:newInstance(org.apache.hadoop.yarn.api.records.ApplicationId,org.apache.hadoop.yarn.api.records.ApplicationAttemptId,java.lang.String,java.lang.String,java.lang.String,java.lang.String,int,org.apache.hadoop.yarn.api.records.Token,org.apache.hadoop.yarn.api.records.YarnApplicationState,java.lang.String,java.lang.String,long,long,long,long,org.apache.hadoop.yarn.api.records.FinalApplicationStatus,org.apache.hadoop.yarn.api.records.ApplicationResourceUsageReport,java.lang.String,float,java.lang.String,org.apache.hadoop.yarn.api.records.Token)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.ApplicationReport:newInstance(org.apache.hadoop.yarn.api.records.ApplicationId,org.apache.hadoop.yarn.api.records.ApplicationAttemptId,java.lang.String,java.lang.String,java.lang.String,java.lang.String,int,org.apache.hadoop.yarn.api.records.Token,org.apache.hadoop.yarn.api.records.YarnApplicationState,java.lang.String,java.lang.String,long,long,long,long,org.apache.hadoop.yarn.api.records.FinalApplicationStatus,org.apache.hadoop.yarn.api.records.ApplicationResourceUsageReport,java.lang.String,float,java.lang.String,org.apache.hadoop.yarn.api.records.Token)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ApplicationReport:newInstance(org.apache.hadoop.yarn.api.records.ApplicationId,org.apache.hadoop.yarn.api.records.ApplicationAttemptId,java.lang.String,java.lang.String,java.lang.String,java.lang.String,int,org.apache.hadoop.yarn.api.records.Token,org.apache.hadoop.yarn.api.records.YarnApplicationState,java.lang.String,java.lang.String,long,long,org.apache.hadoop.yarn.api.records.FinalApplicationStatus,org.apache.hadoop.yarn.api.records.ApplicationResourceUsageReport,java.lang.String,float,java.lang.String,org.apache.hadoop.yarn.api.records.Token,java.util.Set,boolean,org.apache.hadoop.yarn.api.records.Priority,java.lang.String,java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.ApplicationReport:newInstance(org.apache.hadoop.yarn.api.records.ApplicationId,org.apache.hadoop.yarn.api.records.ApplicationAttemptId,java.lang.String,java.lang.String,java.lang.String,java.lang.String,int,org.apache.hadoop.yarn.api.records.Token,org.apache.hadoop.yarn.api.records.YarnApplicationState,java.lang.String,java.lang.String,long,long,org.apache.hadoop.yarn.api.records.FinalApplicationStatus,org.apache.hadoop.yarn.api.records.ApplicationResourceUsageReport,java.lang.String,float,java.lang.String,org.apache.hadoop.yarn.api.records.Token,java.util.Set,boolean,org.apache.hadoop.yarn.api.records.Priority,java.lang.String,java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ApplicationReport:newInstance(org.apache.hadoop.yarn.api.records.ApplicationId,org.apache.hadoop.yarn.api.records.ApplicationAttemptId,java.lang.String,java.lang.String,java.lang.String,java.lang.String,int,org.apache.hadoop.yarn.api.records.Token,org.apache.hadoop.yarn.api.records.YarnApplicationState,java.lang.String,java.lang.String,long,long,long,org.apache.hadoop.yarn.api.records.FinalApplicationStatus,org.apache.hadoop.yarn.api.records.ApplicationResourceUsageReport,java.lang.String,float,java.lang.String,org.apache.hadoop.yarn.api.records.Token,java.util.Set,boolean,org.apache.hadoop.yarn.api.records.Priority,java.lang.String,java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.ApplicationReport:newInstance(org.apache.hadoop.yarn.api.records.ApplicationId,org.apache.hadoop.yarn.api.records.ApplicationAttemptId,java.lang.String,java.lang.String,java.lang.String,java.lang.String,int,org.apache.hadoop.yarn.api.records.Token,org.apache.hadoop.yarn.api.records.YarnApplicationState,java.lang.String,java.lang.String,long,long,long,org.apache.hadoop.yarn.api.records.FinalApplicationStatus,org.apache.hadoop.yarn.api.records.ApplicationResourceUsageReport,java.lang.String,float,java.lang.String,org.apache.hadoop.yarn.api.records.Token,java.util.Set,boolean,org.apache.hadoop.yarn.api.records.Priority,java.lang.String,java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ApplicationReport:newInstance(org.apache.hadoop.yarn.api.records.ApplicationId,org.apache.hadoop.yarn.api.records.ApplicationAttemptId,java.lang.String,java.lang.String,java.lang.String,java.lang.String,int,org.apache.hadoop.yarn.api.records.Token,org.apache.hadoop.yarn.api.records.YarnApplicationState,java.lang.String,java.lang.String,long,long,long,long,org.apache.hadoop.yarn.api.records.FinalApplicationStatus,org.apache.hadoop.yarn.api.records.ApplicationResourceUsageReport,java.lang.String,float,java.lang.String,org.apache.hadoop.yarn.api.records.Token,java.util.Set,boolean,org.apache.hadoop.yarn.api.records.Priority,java.lang.String,java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.ApplicationReport:newInstance(org.apache.hadoop.yarn.api.records.ApplicationId,org.apache.hadoop.yarn.api.records.ApplicationAttemptId,java.lang.String,java.lang.String,java.lang.String,java.lang.String,int,org.apache.hadoop.yarn.api.records.Token,org.apache.hadoop.yarn.api.records.YarnApplicationState,java.lang.String,java.lang.String,long,long,long,long,org.apache.hadoop.yarn.api.records.FinalApplicationStatus,org.apache.hadoop.yarn.api.records.ApplicationResourceUsageReport,java.lang.String,float,java.lang.String,org.apache.hadoop.yarn.api.records.Token,java.util.Set,boolean,org.apache.hadoop.yarn.api.records.Priority,java.lang.String,java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ApplicationReport:getApplicationId()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ApplicationReport:getApplicationId()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.ApplicationReport:setApplicationId(org.apache.hadoop.yarn.api.records.ApplicationId)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.ApplicationReport:setApplicationId(org.apache.hadoop.yarn.api.records.ApplicationId)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ApplicationReport:getCurrentApplicationAttemptId()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ApplicationReport:getCurrentApplicationAttemptId()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.ApplicationReport:setCurrentApplicationAttemptId(org.apache.hadoop.yarn.api.records.ApplicationAttemptId)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.ApplicationReport:setCurrentApplicationAttemptId(org.apache.hadoop.yarn.api.records.ApplicationAttemptId)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ApplicationReport:getUser()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ApplicationReport:getUser()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.ApplicationReport:setUser(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.ApplicationReport:setUser(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ApplicationReport:getQueue()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ApplicationReport:getQueue()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.ApplicationReport:setQueue(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.ApplicationReport:setQueue(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ApplicationReport:getName()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ApplicationReport:getName()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.ApplicationReport:setName(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.ApplicationReport:setName(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ApplicationReport:getHost()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ApplicationReport:getHost()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.ApplicationReport:setHost(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.ApplicationReport:setHost(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ApplicationReport:getRpcPort()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ApplicationReport:getRpcPort()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.ApplicationReport:setRpcPort(int)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.ApplicationReport:setRpcPort(int)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ApplicationReport:getClientToAMToken()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ApplicationReport:getClientToAMToken()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.ApplicationReport:setClientToAMToken(org.apache.hadoop.yarn.api.records.Token)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.ApplicationReport:setClientToAMToken(org.apache.hadoop.yarn.api.records.Token)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ApplicationReport:getYarnApplicationState()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ApplicationReport:getYarnApplicationState()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.ApplicationReport:setYarnApplicationState(org.apache.hadoop.yarn.api.records.YarnApplicationState)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.ApplicationReport:setYarnApplicationState(org.apache.hadoop.yarn.api.records.YarnApplicationState)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ApplicationReport:getDiagnostics()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ApplicationReport:getDiagnostics()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.ApplicationReport:setDiagnostics(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.ApplicationReport:setDiagnostics(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ApplicationReport:getTrackingUrl()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ApplicationReport:getTrackingUrl()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.ApplicationReport:setTrackingUrl(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.ApplicationReport:setTrackingUrl(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ApplicationReport:getOriginalTrackingUrl()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.ApplicationReport:getOriginalTrackingUrl()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ApplicationReport:setOriginalTrackingUrl(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.ApplicationReport:setOriginalTrackingUrl(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ApplicationReport:getStartTime()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ApplicationReport:getStartTime()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.ApplicationReport:setStartTime(long)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.ApplicationReport:setStartTime(long)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ApplicationReport:getSubmitTime()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ApplicationReport:getSubmitTime()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.ApplicationReport:setSubmitTime(long)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.ApplicationReport:setSubmitTime(long)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ApplicationReport:setLaunchTime(long)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.ApplicationReport:setLaunchTime(long)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ApplicationReport:getLaunchTime()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ApplicationReport:getLaunchTime()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ApplicationReport:getFinishTime()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ApplicationReport:getFinishTime()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.ApplicationReport:setFinishTime(long)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.ApplicationReport:setFinishTime(long)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ApplicationReport:getFinalApplicationStatus()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ApplicationReport:getFinalApplicationStatus()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.ApplicationReport:setFinalApplicationStatus(org.apache.hadoop.yarn.api.records.FinalApplicationStatus)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.ApplicationReport:setFinalApplicationStatus(org.apache.hadoop.yarn.api.records.FinalApplicationStatus)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ApplicationReport:getApplicationResourceUsageReport()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ApplicationReport:getApplicationResourceUsageReport()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.ApplicationReport:setApplicationResourceUsageReport(org.apache.hadoop.yarn.api.records.ApplicationResourceUsageReport)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.ApplicationReport:setApplicationResourceUsageReport(org.apache.hadoop.yarn.api.records.ApplicationResourceUsageReport)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ApplicationReport:getProgress()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ApplicationReport:getProgress()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.ApplicationReport:setProgress(float)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.ApplicationReport:setProgress(float)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ApplicationReport:getApplicationType()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ApplicationReport:getApplicationType()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.ApplicationReport:setApplicationType(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.ApplicationReport:setApplicationType(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ApplicationReport:getApplicationTags()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ApplicationReport:getApplicationTags()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.ApplicationReport:setApplicationTags(java.util.Set)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.ApplicationReport:setApplicationTags(java.util.Set)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ApplicationReport:setAMRMToken(org.apache.hadoop.yarn.api.records.Token)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.ApplicationReport:setAMRMToken(org.apache.hadoop.yarn.api.records.Token)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.ApplicationReport:getAMRMToken()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ApplicationReport:getAMRMToken()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.ApplicationReport:getLogAggregationStatus()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ApplicationReport:getLogAggregationStatus()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.ApplicationReport:setLogAggregationStatus(org.apache.hadoop.yarn.api.records.LogAggregationStatus)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.ApplicationReport:setLogAggregationStatus(org.apache.hadoop.yarn.api.records.LogAggregationStatus)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ApplicationReport:isUnmanagedApp()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ApplicationReport:isUnmanagedApp()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ApplicationReport:setUnmanagedApp(boolean)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ApplicationReport:setUnmanagedApp(boolean)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ApplicationReport:getPriority()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ApplicationReport:getPriority()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.ApplicationReport:setPriority(org.apache.hadoop.yarn.api.records.Priority)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.ApplicationReport:setPriority(org.apache.hadoop.yarn.api.records.Priority)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ApplicationReport:getAppNodeLabelExpression()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ApplicationReport:setAppNodeLabelExpression(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ApplicationReport:getAmNodeLabelExpression()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ApplicationReport:setAmNodeLabelExpression(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ApplicationReport:getApplicationTimeouts()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ApplicationReport:getApplicationTimeouts()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ApplicationReport:setApplicationTimeouts(java.util.Map)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.ApplicationReport:setApplicationTimeouts(java.util.Map)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.SerializedException:newInstance(java.lang.Throwable)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.SerializedException:newInstance(java.lang.Throwable)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.SerializedException:init(java.lang.String,java.lang.Throwable)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.SerializedException:init(java.lang.String,java.lang.Throwable)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.SerializedException:init(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.SerializedException:init(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.SerializedException:init(java.lang.Throwable)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.SerializedException:init(java.lang.Throwable)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.SerializedException:getMessage()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.SerializedException:getMessage()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.SerializedException:getRemoteTrace()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.SerializedException:getRemoteTrace()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.SerializedException:getCause()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.SerializedException:getCause()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.SerializedException:deSerialize()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.SerializedException:deSerialize()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ContainerStatus:newInstance(org.apache.hadoop.yarn.api.records.ContainerId,org.apache.hadoop.yarn.api.records.ContainerState,java.lang.String,int)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.ContainerStatus:newInstance(org.apache.hadoop.yarn.api.records.ContainerId,org.apache.hadoop.yarn.api.records.ContainerState,java.lang.String,int)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ContainerStatus:newInstance(org.apache.hadoop.yarn.api.records.ContainerId,org.apache.hadoop.yarn.api.records.ExecutionType,org.apache.hadoop.yarn.api.records.ContainerState,java.lang.String,int)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.ContainerStatus:newInstance(org.apache.hadoop.yarn.api.records.ContainerId,org.apache.hadoop.yarn.api.records.ExecutionType,org.apache.hadoop.yarn.api.records.ContainerState,java.lang.String,int)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ContainerStatus:getContainerId()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ContainerStatus:getContainerId()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.ContainerStatus:setContainerId(org.apache.hadoop.yarn.api.records.ContainerId)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.ContainerStatus:setContainerId(org.apache.hadoop.yarn.api.records.ContainerId)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ContainerStatus:getExecutionType()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ContainerStatus:getExecutionType()	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.yarn.api.records.ContainerStatus:setExecutionType(org.apache.hadoop.yarn.api.records.ExecutionType)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.ContainerStatus:setExecutionType(org.apache.hadoop.yarn.api.records.ExecutionType)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ContainerStatus:getState()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ContainerStatus:getState()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.ContainerStatus:setState(org.apache.hadoop.yarn.api.records.ContainerState)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.ContainerStatus:setState(org.apache.hadoop.yarn.api.records.ContainerState)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ContainerStatus:getExitStatus()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ContainerStatus:getExitStatus()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ContainerStatus:setExitStatus(int)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.ContainerStatus:setExitStatus(int)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ContainerStatus:getDiagnostics()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ContainerStatus:getDiagnostics()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.ContainerStatus:setDiagnostics(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.ContainerStatus:setDiagnostics(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ContainerStatus:getCapability()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ContainerStatus:getCapability()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ContainerStatus:setCapability(org.apache.hadoop.yarn.api.records.Resource)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.ContainerStatus:setCapability(org.apache.hadoop.yarn.api.records.Resource)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ContainerStatus:getIPs()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ContainerStatus:getIPs()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ContainerStatus:setIPs(java.util.List)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.ContainerStatus:setIPs(java.util.List)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ContainerStatus:getHost()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ContainerStatus:getHost()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ContainerStatus:setHost(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.ContainerStatus:setHost(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ContainerStatus:setContainerSubState(org.apache.hadoop.yarn.api.records.ContainerSubState)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.ContainerStatus:setContainerSubState(org.apache.hadoop.yarn.api.records.ContainerSubState)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ContainerStatus:getContainerSubState()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.ContainerStatus:getContainerSubState()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ContainerStatus:getExposedPorts()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ContainerStatus:getExposedPorts()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ContainerStatus:setExposedPorts(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.ContainerStatus:setExposedPorts(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.NodeReport:newInstance(org.apache.hadoop.yarn.api.records.NodeId,org.apache.hadoop.yarn.api.records.NodeState,java.lang.String,java.lang.String,org.apache.hadoop.yarn.api.records.Resource,org.apache.hadoop.yarn.api.records.Resource,int,java.lang.String,long)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.NodeReport:newInstance(org.apache.hadoop.yarn.api.records.NodeId,org.apache.hadoop.yarn.api.records.NodeState,java.lang.String,java.lang.String,org.apache.hadoop.yarn.api.records.Resource,org.apache.hadoop.yarn.api.records.Resource,int,java.lang.String,long)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.NodeReport:newInstance(org.apache.hadoop.yarn.api.records.NodeId,org.apache.hadoop.yarn.api.records.NodeState,java.lang.String,java.lang.String,org.apache.hadoop.yarn.api.records.Resource,org.apache.hadoop.yarn.api.records.Resource,int,java.lang.String,long,java.util.Set,java.lang.Integer,org.apache.hadoop.yarn.api.records.NodeUpdateType)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.NodeReport:newInstance(org.apache.hadoop.yarn.api.records.NodeId,org.apache.hadoop.yarn.api.records.NodeState,java.lang.String,java.lang.String,org.apache.hadoop.yarn.api.records.Resource,org.apache.hadoop.yarn.api.records.Resource,int,java.lang.String,long,java.util.Set,java.lang.Integer,org.apache.hadoop.yarn.api.records.NodeUpdateType)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.NodeReport:getNodeId()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.NodeReport:getNodeId()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.NodeReport:setNodeId(org.apache.hadoop.yarn.api.records.NodeId)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.NodeReport:setNodeId(org.apache.hadoop.yarn.api.records.NodeId)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.NodeReport:getNodeState()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.NodeReport:getNodeState()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.NodeReport:setNodeState(org.apache.hadoop.yarn.api.records.NodeState)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.NodeReport:setNodeState(org.apache.hadoop.yarn.api.records.NodeState)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.NodeReport:getHttpAddress()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.NodeReport:getHttpAddress()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.NodeReport:setHttpAddress(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.NodeReport:setHttpAddress(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.NodeReport:getRackName()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.NodeReport:getRackName()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.NodeReport:setRackName(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.NodeReport:setRackName(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.NodeReport:getUsed()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.NodeReport:getUsed()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.NodeReport:setUsed(org.apache.hadoop.yarn.api.records.Resource)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.NodeReport:setUsed(org.apache.hadoop.yarn.api.records.Resource)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.NodeReport:getCapability()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.NodeReport:getCapability()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.NodeReport:setCapability(org.apache.hadoop.yarn.api.records.Resource)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.NodeReport:setCapability(org.apache.hadoop.yarn.api.records.Resource)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.NodeReport:getNumContainers()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.NodeReport:getNumContainers()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.NodeReport:setNumContainers(int)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.NodeReport:setNumContainers(int)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.NodeReport:getHealthReport()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.NodeReport:getHealthReport()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.NodeReport:setHealthReport(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.NodeReport:setHealthReport(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.NodeReport:getLastHealthReportTime()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.NodeReport:getLastHealthReportTime()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.NodeReport:setLastHealthReportTime(long)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.NodeReport:setLastHealthReportTime(long)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.NodeReport:getNodeLabels()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.NodeReport:getNodeLabels()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.NodeReport:setNodeLabels(java.util.Set)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.NodeReport:setNodeLabels(java.util.Set)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.NodeReport:getAggregatedContainersUtilization()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.NodeReport:getAggregatedContainersUtilization()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.NodeReport:setAggregatedContainersUtilization(org.apache.hadoop.yarn.api.records.ResourceUtilization)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.NodeReport:setAggregatedContainersUtilization(org.apache.hadoop.yarn.api.records.ResourceUtilization)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.NodeReport:getNodeUtilization()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.NodeReport:getNodeUtilization()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.NodeReport:setNodeUtilization(org.apache.hadoop.yarn.api.records.ResourceUtilization)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.NodeReport:setNodeUtilization(org.apache.hadoop.yarn.api.records.ResourceUtilization)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ReservationRequest:newInstance(org.apache.hadoop.yarn.api.records.Resource,int)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ReservationRequest:newInstance(org.apache.hadoop.yarn.api.records.Resource,int)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ReservationRequest:newInstance(org.apache.hadoop.yarn.api.records.Resource,int,int,long)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ReservationRequest:newInstance(org.apache.hadoop.yarn.api.records.Resource,int,int,long)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ReservationRequest:getCapability()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ReservationRequest:getCapability()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ReservationRequest:setCapability(org.apache.hadoop.yarn.api.records.Resource)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ReservationRequest:setCapability(org.apache.hadoop.yarn.api.records.Resource)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ReservationRequest:getNumContainers()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ReservationRequest:getNumContainers()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ReservationRequest:setNumContainers(int)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ReservationRequest:setNumContainers(int)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ReservationRequest:getConcurrency()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ReservationRequest:getConcurrency()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ReservationRequest:setConcurrency(int)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ReservationRequest:setConcurrency(int)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ReservationRequest:getDuration()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ReservationRequest:getDuration()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ReservationRequest:setDuration(long)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ReservationRequest:setDuration(long)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ReservationRequests:newInstance(java.util.List,org.apache.hadoop.yarn.api.records.ReservationRequestInterpreter)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ReservationRequests:newInstance(java.util.List,org.apache.hadoop.yarn.api.records.ReservationRequestInterpreter)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ReservationRequests:getReservationResources()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ReservationRequests:getReservationResources()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ReservationRequests:setReservationResources(java.util.List)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ReservationRequests:setReservationResources(java.util.List)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ReservationRequests:getInterpreter()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ReservationRequests:getInterpreter()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ReservationRequests:setInterpreter(org.apache.hadoop.yarn.api.records.ReservationRequestInterpreter)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ReservationRequests:setInterpreter(org.apache.hadoop.yarn.api.records.ReservationRequestInterpreter)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ApplicationAttemptReport:newInstance(org.apache.hadoop.yarn.api.records.ApplicationAttemptId,java.lang.String,int,java.lang.String,java.lang.String,java.lang.String,org.apache.hadoop.yarn.api.records.YarnApplicationAttemptState,org.apache.hadoop.yarn.api.records.ContainerId,long,long)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.ApplicationAttemptReport:newInstance(org.apache.hadoop.yarn.api.records.ApplicationAttemptId,java.lang.String,int,java.lang.String,java.lang.String,java.lang.String,org.apache.hadoop.yarn.api.records.YarnApplicationAttemptState,org.apache.hadoop.yarn.api.records.ContainerId,long,long)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ApplicationAttemptReport:getYarnApplicationAttemptState()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ApplicationAttemptReport:getYarnApplicationAttemptState()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ApplicationAttemptReport:setYarnApplicationAttemptState(org.apache.hadoop.yarn.api.records.YarnApplicationAttemptState)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.ApplicationAttemptReport:setYarnApplicationAttemptState(org.apache.hadoop.yarn.api.records.YarnApplicationAttemptState)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ApplicationAttemptReport:getRpcPort()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ApplicationAttemptReport:getRpcPort()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ApplicationAttemptReport:setRpcPort(int)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.ApplicationAttemptReport:setRpcPort(int)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ApplicationAttemptReport:getHost()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ApplicationAttemptReport:getHost()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ApplicationAttemptReport:setHost(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.ApplicationAttemptReport:setHost(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ApplicationAttemptReport:getDiagnostics()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ApplicationAttemptReport:getDiagnostics()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ApplicationAttemptReport:setDiagnostics(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.ApplicationAttemptReport:setDiagnostics(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ApplicationAttemptReport:getTrackingUrl()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ApplicationAttemptReport:getTrackingUrl()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ApplicationAttemptReport:setTrackingUrl(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.ApplicationAttemptReport:setTrackingUrl(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ApplicationAttemptReport:getOriginalTrackingUrl()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ApplicationAttemptReport:getOriginalTrackingUrl()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ApplicationAttemptReport:setOriginalTrackingUrl(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.ApplicationAttemptReport:setOriginalTrackingUrl(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ApplicationAttemptReport:getApplicationAttemptId()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ApplicationAttemptReport:getApplicationAttemptId()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ApplicationAttemptReport:setApplicationAttemptId(org.apache.hadoop.yarn.api.records.ApplicationAttemptId)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.ApplicationAttemptReport:setApplicationAttemptId(org.apache.hadoop.yarn.api.records.ApplicationAttemptId)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ApplicationAttemptReport:getAMContainerId()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ApplicationAttemptReport:getAMContainerId()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ApplicationAttemptReport:setAMContainerId(org.apache.hadoop.yarn.api.records.ContainerId)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.ApplicationAttemptReport:setAMContainerId(org.apache.hadoop.yarn.api.records.ContainerId)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ApplicationAttemptReport:getStartTime()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ApplicationAttemptReport:getStartTime()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ApplicationAttemptReport:setStartTime(long)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.ApplicationAttemptReport:setStartTime(long)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ApplicationAttemptReport:getFinishTime()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ApplicationAttemptReport:getFinishTime()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ApplicationAttemptReport:setFinishTime(long)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.ApplicationAttemptReport:setFinishTime(long)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.NodeToAttributeValue:getAttributeValue()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.NodeToAttributeValue:getAttributeValue()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.NodeToAttributeValue:setAttributeValue(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.NodeToAttributeValue:setAttributeValue(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.NodeToAttributeValue:getHostname()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.NodeToAttributeValue:getHostname()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.NodeToAttributeValue:setHostname(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.NodeToAttributeValue:setHostname(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ResourceRequest:newInstance(org.apache.hadoop.yarn.api.records.Priority,java.lang.String,org.apache.hadoop.yarn.api.records.Resource,int)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ResourceRequest:newInstance(org.apache.hadoop.yarn.api.records.Priority,java.lang.String,org.apache.hadoop.yarn.api.records.Resource,int)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.ResourceRequest:newInstance(org.apache.hadoop.yarn.api.records.Priority,java.lang.String,org.apache.hadoop.yarn.api.records.Resource,int,boolean)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ResourceRequest:newInstance(org.apache.hadoop.yarn.api.records.Priority,java.lang.String,org.apache.hadoop.yarn.api.records.Resource,int,boolean)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.ResourceRequest:newInstance(org.apache.hadoop.yarn.api.records.Priority,java.lang.String,org.apache.hadoop.yarn.api.records.Resource,int,boolean,java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ResourceRequest:newInstance(org.apache.hadoop.yarn.api.records.Priority,java.lang.String,org.apache.hadoop.yarn.api.records.Resource,int,boolean,java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.ResourceRequest:newInstance(org.apache.hadoop.yarn.api.records.Priority,java.lang.String,org.apache.hadoop.yarn.api.records.Resource,int,boolean,java.lang.String,org.apache.hadoop.yarn.api.records.ExecutionTypeRequest)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ResourceRequest:newInstance(org.apache.hadoop.yarn.api.records.Priority,java.lang.String,org.apache.hadoop.yarn.api.records.Resource,int,boolean,java.lang.String,org.apache.hadoop.yarn.api.records.ExecutionTypeRequest)	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.yarn.api.records.ResourceRequest:clone(org.apache.hadoop.yarn.api.records.ResourceRequest)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ResourceRequest:clone(org.apache.hadoop.yarn.api.records.ResourceRequest)	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.yarn.api.records.ResourceRequest:newBuilder()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ResourceRequest:newBuilder()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ResourceRequest:isAnyLocation(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ResourceRequest:isAnyLocation(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.ResourceRequest:getPriority()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ResourceRequest:getPriority()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.ResourceRequest:setPriority(org.apache.hadoop.yarn.api.records.Priority)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ResourceRequest:setPriority(org.apache.hadoop.yarn.api.records.Priority)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.ResourceRequest:getResourceName()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ResourceRequest:getResourceName()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.ResourceRequest:setResourceName(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ResourceRequest:setResourceName(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.ResourceRequest:getNumContainers()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ResourceRequest:getNumContainers()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.ResourceRequest:setNumContainers(int)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ResourceRequest:setNumContainers(int)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.ResourceRequest:getRelaxLocality()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ResourceRequest:getRelaxLocality()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.ResourceRequest:setExecutionTypeRequest(org.apache.hadoop.yarn.api.records.ExecutionTypeRequest)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ResourceRequest:setExecutionTypeRequest(org.apache.hadoop.yarn.api.records.ExecutionTypeRequest)	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.yarn.api.records.ResourceRequest:getExecutionTypeRequest()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ResourceRequest:getExecutionTypeRequest()	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.yarn.api.records.ResourceRequest:setRelaxLocality(boolean)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ResourceRequest:setRelaxLocality(boolean)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.ResourceRequest:getNodeLabelExpression()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ResourceRequest:getNodeLabelExpression()	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.yarn.api.records.ResourceRequest:setNodeLabelExpression(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ResourceRequest:setNodeLabelExpression(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.yarn.api.records.ResourceRequest:getAllocationRequestId()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ResourceRequest:getAllocationRequestId()	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.yarn.api.records.ResourceRequest:setAllocationRequestId(long)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ResourceRequest:setAllocationRequestId(long)	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.yarn.api.records.ResourceRequest:setCapability(org.apache.hadoop.yarn.api.records.Resource)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ResourceRequest:setCapability(org.apache.hadoop.yarn.api.records.Resource)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.ResourceRequest:getCapability()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ResourceRequest:getCapability()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.ReservationDefinition:newInstance(long,long,org.apache.hadoop.yarn.api.records.ReservationRequests,java.lang.String,java.lang.String,org.apache.hadoop.yarn.api.records.Priority)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ReservationDefinition:newInstance(long,long,org.apache.hadoop.yarn.api.records.ReservationRequests,java.lang.String,java.lang.String,org.apache.hadoop.yarn.api.records.Priority)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ReservationDefinition:newInstance(long,long,org.apache.hadoop.yarn.api.records.ReservationRequests,java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ReservationDefinition:newInstance(long,long,org.apache.hadoop.yarn.api.records.ReservationRequests,java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ReservationDefinition:getArrival()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ReservationDefinition:getArrival()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ReservationDefinition:setArrival(long)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ReservationDefinition:setArrival(long)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ReservationDefinition:getDeadline()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ReservationDefinition:getDeadline()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ReservationDefinition:setDeadline(long)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ReservationDefinition:setDeadline(long)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ReservationDefinition:getReservationRequests()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ReservationDefinition:getReservationRequests()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ReservationDefinition:setReservationRequests(org.apache.hadoop.yarn.api.records.ReservationRequests)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ReservationDefinition:setReservationRequests(org.apache.hadoop.yarn.api.records.ReservationRequests)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ReservationDefinition:getReservationName()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ReservationDefinition:getReservationName()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ReservationDefinition:setReservationName(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ReservationDefinition:setReservationName(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ReservationDefinition:getRecurrenceExpression()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ReservationDefinition:getRecurrenceExpression()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ReservationDefinition:setRecurrenceExpression(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ReservationDefinition:setRecurrenceExpression(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ReservationDefinition:getPriority()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ReservationDefinition:getPriority()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ReservationDefinition:setPriority(org.apache.hadoop.yarn.api.records.Priority)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ReservationDefinition:setPriority(org.apache.hadoop.yarn.api.records.Priority)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.timelineservice.TimelineEvent:getId()	javax.xml.bind.annotation.XmlElement	name	id
org.apache.hadoop.yarn.api.records.timelineservice.TimelineEvent:getInfoJAXB()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.timelineservice.TimelineEvent:getInfoJAXB()	javax.xml.bind.annotation.XmlElement	name	info
org.apache.hadoop.yarn.api.records.timelineservice.TimelineEvent:getTimestamp()	javax.xml.bind.annotation.XmlElement	name	timestamp
org.apache.hadoop.yarn.api.records.timelineservice.FlowActivityEntity:getId()	javax.xml.bind.annotation.XmlElement	name	id
org.apache.hadoop.yarn.api.records.timelineservice.FlowActivityEntity:getFlowRuns()	javax.xml.bind.annotation.XmlElement	name	flowruns
org.apache.hadoop.yarn.api.records.timelineservice.TimelineEntities:getEntities()	javax.xml.bind.annotation.XmlElement	name	entities
org.apache.hadoop.yarn.api.records.timelineservice.TimelineWriteResponse:getErrors()	javax.xml.bind.annotation.XmlElement	name	errors
org.apache.hadoop.yarn.api.records.timelineservice.TimelineDomain:getId()	javax.xml.bind.annotation.XmlElement	name	id
org.apache.hadoop.yarn.api.records.timelineservice.TimelineDomain:getDescription()	javax.xml.bind.annotation.XmlElement	name	description
org.apache.hadoop.yarn.api.records.timelineservice.TimelineDomain:getOwner()	javax.xml.bind.annotation.XmlElement	name	owner
org.apache.hadoop.yarn.api.records.timelineservice.TimelineDomain:getReaders()	javax.xml.bind.annotation.XmlElement	name	readers
org.apache.hadoop.yarn.api.records.timelineservice.TimelineDomain:getWriters()	javax.xml.bind.annotation.XmlElement	name	writers
org.apache.hadoop.yarn.api.records.timelineservice.TimelineDomain:getCreatedTime()	javax.xml.bind.annotation.XmlElement	name	createdtime
org.apache.hadoop.yarn.api.records.timelineservice.TimelineDomain:getModifiedTime()	javax.xml.bind.annotation.XmlElement	name	modifiedtime
org.apache.hadoop.yarn.api.records.timelineservice.FlowRunEntity:getId()	javax.xml.bind.annotation.XmlElement	name	id
org.apache.hadoop.yarn.api.records.timelineservice.TimelineMetric:getType()	javax.xml.bind.annotation.XmlElement	name	type
org.apache.hadoop.yarn.api.records.timelineservice.TimelineMetric:getId()	javax.xml.bind.annotation.XmlElement	name	id
org.apache.hadoop.yarn.api.records.timelineservice.TimelineMetric:getRealtimeAggregationOp()	javax.xml.bind.annotation.XmlElement	name	aggregationOp
org.apache.hadoop.yarn.api.records.timelineservice.TimelineMetric:getValuesJAXB()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.timelineservice.TimelineMetric:getValuesJAXB()	javax.xml.bind.annotation.XmlElement	name	values
org.apache.hadoop.yarn.api.records.timelineservice.TimelineWriteResponse$TimelineWriteError:getEntityId()	javax.xml.bind.annotation.XmlElement	name	entity
org.apache.hadoop.yarn.api.records.timelineservice.TimelineWriteResponse$TimelineWriteError:getEntityType()	javax.xml.bind.annotation.XmlElement	name	entitytype
org.apache.hadoop.yarn.api.records.timelineservice.TimelineWriteResponse$TimelineWriteError:getErrorCode()	javax.xml.bind.annotation.XmlElement	name	errorcode
org.apache.hadoop.yarn.api.records.timelineservice.TimelineEntity:getType()	javax.xml.bind.annotation.XmlElement	name	type
org.apache.hadoop.yarn.api.records.timelineservice.TimelineEntity:getId()	javax.xml.bind.annotation.XmlElement	name	id
org.apache.hadoop.yarn.api.records.timelineservice.TimelineEntity:getInfoJAXB()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.timelineservice.TimelineEntity:getInfoJAXB()	javax.xml.bind.annotation.XmlElement	name	info
org.apache.hadoop.yarn.api.records.timelineservice.TimelineEntity:getConfigsJAXB()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.timelineservice.TimelineEntity:getConfigsJAXB()	javax.xml.bind.annotation.XmlElement	name	configs
org.apache.hadoop.yarn.api.records.timelineservice.TimelineEntity:getMetrics()	javax.xml.bind.annotation.XmlElement	name	metrics
org.apache.hadoop.yarn.api.records.timelineservice.TimelineEntity:getEvents()	javax.xml.bind.annotation.XmlElement	name	events
org.apache.hadoop.yarn.api.records.timelineservice.TimelineEntity:getIsRelatedToEntitiesJAXB()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.timelineservice.TimelineEntity:getIsRelatedToEntitiesJAXB()	javax.xml.bind.annotation.XmlElement	name	isrelatedto
org.apache.hadoop.yarn.api.records.timelineservice.TimelineEntity:setIsRelatedToEntities(java.util.Map)	com.fasterxml.jackson.annotation.JsonSetter	value	isrelatedto
org.apache.hadoop.yarn.api.records.timelineservice.TimelineEntity:getRelatesToEntitiesJAXB()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.timelineservice.TimelineEntity:getRelatesToEntitiesJAXB()	javax.xml.bind.annotation.XmlElement	name	relatesto
org.apache.hadoop.yarn.api.records.timelineservice.TimelineEntity:setRelatesToEntities(java.util.Map)	com.fasterxml.jackson.annotation.JsonSetter	value	relatesto
org.apache.hadoop.yarn.api.records.timelineservice.TimelineEntity:getCreatedTime()	javax.xml.bind.annotation.XmlElement	name	createdtime
org.apache.hadoop.yarn.api.records.timelineservice.TimelineEntity:setCreatedTime(java.lang.Long)	com.fasterxml.jackson.annotation.JsonSetter	value	createdtime
org.apache.hadoop.yarn.api.records.timelineservice.TimelineEntity:getIdPrefix()	javax.xml.bind.annotation.XmlElement	name	idprefix
org.apache.hadoop.yarn.api.records.timelineservice.TimelineEntity:setIdPrefix(long)	com.fasterxml.jackson.annotation.JsonSetter	value	idprefix
org.apache.hadoop.yarn.api.records.timelineservice.TimelineEntity$Identifier:getType()	javax.xml.bind.annotation.XmlElement	name	type
org.apache.hadoop.yarn.api.records.timelineservice.TimelineEntity$Identifier:getId()	javax.xml.bind.annotation.XmlElement	name	id
org.apache.hadoop.yarn.api.records.QueueInfo:newInstance(java.lang.String,float,float,float,java.util.List,java.util.List,org.apache.hadoop.yarn.api.records.QueueState,java.util.Set,java.lang.String,org.apache.hadoop.yarn.api.records.QueueStatistics,boolean)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.QueueInfo:newInstance(java.lang.String,float,float,float,java.util.List,java.util.List,org.apache.hadoop.yarn.api.records.QueueState,java.util.Set,java.lang.String,org.apache.hadoop.yarn.api.records.QueueStatistics,boolean)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.QueueInfo:newInstance(java.lang.String,float,float,float,java.util.List,java.util.List,org.apache.hadoop.yarn.api.records.QueueState,java.util.Set,java.lang.String,org.apache.hadoop.yarn.api.records.QueueStatistics,boolean,java.util.Map)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.QueueInfo:newInstance(java.lang.String,float,float,float,java.util.List,java.util.List,org.apache.hadoop.yarn.api.records.QueueState,java.util.Set,java.lang.String,org.apache.hadoop.yarn.api.records.QueueStatistics,boolean,java.util.Map)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.QueueInfo:newInstance(java.lang.String,float,float,float,java.util.List,java.util.List,org.apache.hadoop.yarn.api.records.QueueState,java.util.Set,java.lang.String,org.apache.hadoop.yarn.api.records.QueueStatistics,boolean,java.util.Map,boolean)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.QueueInfo:newInstance(java.lang.String,float,float,float,java.util.List,java.util.List,org.apache.hadoop.yarn.api.records.QueueState,java.util.Set,java.lang.String,org.apache.hadoop.yarn.api.records.QueueStatistics,boolean,java.util.Map,boolean)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.QueueInfo:getQueueName()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.QueueInfo:getQueueName()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.QueueInfo:setQueueName(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.QueueInfo:setQueueName(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.QueueInfo:getCapacity()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.QueueInfo:getCapacity()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.QueueInfo:setCapacity(float)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.QueueInfo:setCapacity(float)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.QueueInfo:getMaximumCapacity()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.QueueInfo:getMaximumCapacity()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.QueueInfo:setMaximumCapacity(float)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.QueueInfo:setMaximumCapacity(float)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.QueueInfo:getCurrentCapacity()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.QueueInfo:getCurrentCapacity()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.QueueInfo:setCurrentCapacity(float)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.QueueInfo:setCurrentCapacity(float)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.QueueInfo:getChildQueues()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.QueueInfo:getChildQueues()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.QueueInfo:setChildQueues(java.util.List)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.QueueInfo:setChildQueues(java.util.List)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.QueueInfo:getApplications()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.QueueInfo:getApplications()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.QueueInfo:setApplications(java.util.List)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.QueueInfo:setApplications(java.util.List)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.QueueInfo:getQueueState()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.QueueInfo:getQueueState()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.QueueInfo:setQueueState(org.apache.hadoop.yarn.api.records.QueueState)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.QueueInfo:setQueueState(org.apache.hadoop.yarn.api.records.QueueState)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.QueueInfo:getAccessibleNodeLabels()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.QueueInfo:getAccessibleNodeLabels()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.QueueInfo:setAccessibleNodeLabels(java.util.Set)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.QueueInfo:setAccessibleNodeLabels(java.util.Set)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.QueueInfo:getDefaultNodeLabelExpression()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.QueueInfo:getDefaultNodeLabelExpression()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.QueueInfo:setDefaultNodeLabelExpression(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.QueueInfo:setDefaultNodeLabelExpression(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.QueueInfo:getQueueStatistics()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.QueueInfo:getQueueStatistics()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.QueueInfo:setQueueStatistics(org.apache.hadoop.yarn.api.records.QueueStatistics)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.QueueInfo:setQueueStatistics(org.apache.hadoop.yarn.api.records.QueueStatistics)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.QueueInfo:getPreemptionDisabled()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.QueueInfo:getPreemptionDisabled()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.QueueInfo:setPreemptionDisabled(boolean)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.QueueInfo:setPreemptionDisabled(boolean)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.QueueInfo:getQueueConfigurations()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.QueueInfo:getQueueConfigurations()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.QueueInfo:setQueueConfigurations(java.util.Map)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.QueueInfo:setQueueConfigurations(java.util.Map)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.QueueInfo:getIntraQueuePreemptionDisabled()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.QueueInfo:getIntraQueuePreemptionDisabled()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.QueueInfo:setIntraQueuePreemptionDisabled(boolean)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.QueueInfo:setIntraQueuePreemptionDisabled(boolean)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.Priority:newInstance(int)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.Priority:newInstance(int)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.Priority:getPriority()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.Priority:getPriority()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.Priority:setPriority(int)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.Priority:setPriority(int)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.NodeAttributeInfo:getAttributeKey()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.NodeAttributeInfo:getAttributeKey()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.NodeAttributeInfo:setAttributeKey(org.apache.hadoop.yarn.api.records.NodeAttributeKey)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.NodeAttributeInfo:setAttributeKey(org.apache.hadoop.yarn.api.records.NodeAttributeKey)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.NodeAttributeInfo:getAttributeType()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.NodeAttributeInfo:getAttributeType()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.NodeAttributeInfo:setAttributeType(org.apache.hadoop.yarn.api.records.NodeAttributeType)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.NodeAttributeInfo:setAttributeType(org.apache.hadoop.yarn.api.records.NodeAttributeType)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.LocalResource:newInstance(org.apache.hadoop.yarn.api.records.URL,org.apache.hadoop.yarn.api.records.LocalResourceType,org.apache.hadoop.yarn.api.records.LocalResourceVisibility,long,long,java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.LocalResource:newInstance(org.apache.hadoop.yarn.api.records.URL,org.apache.hadoop.yarn.api.records.LocalResourceType,org.apache.hadoop.yarn.api.records.LocalResourceVisibility,long,long,java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.LocalResource:newInstance(org.apache.hadoop.yarn.api.records.URL,org.apache.hadoop.yarn.api.records.LocalResourceType,org.apache.hadoop.yarn.api.records.LocalResourceVisibility,long,long,java.lang.String,boolean)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.LocalResource:newInstance(org.apache.hadoop.yarn.api.records.URL,org.apache.hadoop.yarn.api.records.LocalResourceType,org.apache.hadoop.yarn.api.records.LocalResourceVisibility,long,long,java.lang.String,boolean)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.LocalResource:newInstance(org.apache.hadoop.yarn.api.records.URL,org.apache.hadoop.yarn.api.records.LocalResourceType,org.apache.hadoop.yarn.api.records.LocalResourceVisibility,long,long)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.LocalResource:newInstance(org.apache.hadoop.yarn.api.records.URL,org.apache.hadoop.yarn.api.records.LocalResourceType,org.apache.hadoop.yarn.api.records.LocalResourceVisibility,long,long)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.LocalResource:newInstance(org.apache.hadoop.yarn.api.records.URL,org.apache.hadoop.yarn.api.records.LocalResourceType,org.apache.hadoop.yarn.api.records.LocalResourceVisibility,long,long,boolean)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.LocalResource:newInstance(org.apache.hadoop.yarn.api.records.URL,org.apache.hadoop.yarn.api.records.LocalResourceType,org.apache.hadoop.yarn.api.records.LocalResourceVisibility,long,long,boolean)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.LocalResource:getResource()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.LocalResource:getResource()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.LocalResource:setResource(org.apache.hadoop.yarn.api.records.URL)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.LocalResource:setResource(org.apache.hadoop.yarn.api.records.URL)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.LocalResource:getSize()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.LocalResource:getSize()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.LocalResource:setSize(long)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.LocalResource:setSize(long)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.LocalResource:getTimestamp()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.LocalResource:getTimestamp()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.LocalResource:setTimestamp(long)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.LocalResource:setTimestamp(long)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.LocalResource:getType()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.LocalResource:getType()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.LocalResource:setType(org.apache.hadoop.yarn.api.records.LocalResourceType)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.LocalResource:setType(org.apache.hadoop.yarn.api.records.LocalResourceType)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.LocalResource:getVisibility()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.LocalResource:getVisibility()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.LocalResource:setVisibility(org.apache.hadoop.yarn.api.records.LocalResourceVisibility)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.LocalResource:setVisibility(org.apache.hadoop.yarn.api.records.LocalResourceVisibility)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.LocalResource:getPattern()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.LocalResource:getPattern()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.LocalResource:setPattern(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.LocalResource:setPattern(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.LocalResource:getShouldBeUploadedToSharedCache()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.LocalResource:getShouldBeUploadedToSharedCache()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.LocalResource:setShouldBeUploadedToSharedCache(boolean)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.LocalResource:setShouldBeUploadedToSharedCache(boolean)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.NodeAttributeKey:getAttributePrefix()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.NodeAttributeKey:getAttributePrefix()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.NodeAttributeKey:setAttributePrefix(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.NodeAttributeKey:setAttributePrefix(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.NodeAttributeKey:getAttributeName()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.NodeAttributeKey:getAttributeName()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.NodeAttributeKey:setAttributeName(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.NodeAttributeKey:setAttributeName(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.SchedulingRequest:newInstance(long,org.apache.hadoop.yarn.api.records.Priority,org.apache.hadoop.yarn.api.records.ExecutionTypeRequest,java.util.Set,org.apache.hadoop.yarn.api.records.ResourceSizing,org.apache.hadoop.yarn.api.resource.PlacementConstraint)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.SchedulingRequest:newInstance(long,org.apache.hadoop.yarn.api.records.Priority,org.apache.hadoop.yarn.api.records.ExecutionTypeRequest,java.util.Set,org.apache.hadoop.yarn.api.records.ResourceSizing,org.apache.hadoop.yarn.api.resource.PlacementConstraint)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.SchedulingRequest:newBuilder()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.SchedulingRequest:newBuilder()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.timeline.TimelinePutResponse:getErrors()	javax.xml.bind.annotation.XmlElement	name	errors
org.apache.hadoop.yarn.api.records.timeline.TimelineEvent:getTimestamp()	javax.xml.bind.annotation.XmlElement	name	timestamp
org.apache.hadoop.yarn.api.records.timeline.TimelineEvent:getEventType()	javax.xml.bind.annotation.XmlElement	name	eventtype
org.apache.hadoop.yarn.api.records.timeline.TimelineEvent:getEventInfoJAXB()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.timeline.TimelineEvent:getEventInfoJAXB()	javax.xml.bind.annotation.XmlElement	name	eventinfo
org.apache.hadoop.yarn.api.records.timeline.TimelineEvents$EventsOfOneEntity:getEntityId()	javax.xml.bind.annotation.XmlElement	name	entity
org.apache.hadoop.yarn.api.records.timeline.TimelineEvents$EventsOfOneEntity:getEntityType()	javax.xml.bind.annotation.XmlElement	name	entitytype
org.apache.hadoop.yarn.api.records.timeline.TimelineEvents$EventsOfOneEntity:getEvents()	javax.xml.bind.annotation.XmlElement	name	events
org.apache.hadoop.yarn.api.records.timeline.TimelineEvents:getAllEvents()	javax.xml.bind.annotation.XmlElement	name	events
org.apache.hadoop.yarn.api.records.timeline.TimelinePutResponse$TimelinePutError:getEntityId()	javax.xml.bind.annotation.XmlElement	name	entity
org.apache.hadoop.yarn.api.records.timeline.TimelinePutResponse$TimelinePutError:getEntityType()	javax.xml.bind.annotation.XmlElement	name	entitytype
org.apache.hadoop.yarn.api.records.timeline.TimelinePutResponse$TimelinePutError:getErrorCode()	javax.xml.bind.annotation.XmlElement	name	errorcode
org.apache.hadoop.yarn.api.records.timeline.TimelineEntityGroupId:setTimelineEntityGroupId(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.timeline.TimelineEntityGroupId:setTimelineEntityGroupId(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.timeline.TimelineEntities:getEntities()	javax.xml.bind.annotation.XmlElement	name	entities
org.apache.hadoop.yarn.api.records.timeline.TimelineAbout:getAbout()	javax.xml.bind.annotation.XmlElement	name	About
org.apache.hadoop.yarn.api.records.timeline.TimelineAbout:getTimelineServiceVersion()	javax.xml.bind.annotation.XmlElement	name	timeline-service-version
org.apache.hadoop.yarn.api.records.timeline.TimelineAbout:getTimelineServiceBuildVersion()	javax.xml.bind.annotation.XmlElement	name	timeline-service-build-version
org.apache.hadoop.yarn.api.records.timeline.TimelineAbout:getTimelineServiceVersionBuiltOn()	javax.xml.bind.annotation.XmlElement	name	timeline-service-version-built-on
org.apache.hadoop.yarn.api.records.timeline.TimelineAbout:getHadoopVersion()	javax.xml.bind.annotation.XmlElement	name	hadoop-version
org.apache.hadoop.yarn.api.records.timeline.TimelineAbout:getHadoopBuildVersion()	javax.xml.bind.annotation.XmlElement	name	hadoop-build-version
org.apache.hadoop.yarn.api.records.timeline.TimelineAbout:getHadoopVersionBuiltOn()	javax.xml.bind.annotation.XmlElement	name	hadoop-version-built-on
org.apache.hadoop.yarn.api.records.timeline.TimelineDelegationTokenResponse:getType()	javax.xml.bind.annotation.XmlElement	name	type
org.apache.hadoop.yarn.api.records.timeline.TimelineDelegationTokenResponse:getContent()	javax.xml.bind.annotation.XmlElement	name	content
org.apache.hadoop.yarn.api.records.timeline.TimelineDomain:getId()	javax.xml.bind.annotation.XmlElement	name	id
org.apache.hadoop.yarn.api.records.timeline.TimelineDomain:getDescription()	javax.xml.bind.annotation.XmlElement	name	description
org.apache.hadoop.yarn.api.records.timeline.TimelineDomain:getOwner()	javax.xml.bind.annotation.XmlElement	name	owner
org.apache.hadoop.yarn.api.records.timeline.TimelineDomain:getReaders()	javax.xml.bind.annotation.XmlElement	name	readers
org.apache.hadoop.yarn.api.records.timeline.TimelineDomain:getWriters()	javax.xml.bind.annotation.XmlElement	name	writers
org.apache.hadoop.yarn.api.records.timeline.TimelineDomain:getCreatedTime()	javax.xml.bind.annotation.XmlElement	name	createdtime
org.apache.hadoop.yarn.api.records.timeline.TimelineDomain:getModifiedTime()	javax.xml.bind.annotation.XmlElement	name	modifiedtime
org.apache.hadoop.yarn.api.records.timeline.TimelineDomains:getDomains()	javax.xml.bind.annotation.XmlElement	name	domains
org.apache.hadoop.yarn.api.records.timeline.TimelineEntity:getEntityType()	javax.xml.bind.annotation.XmlElement	name	entitytype
org.apache.hadoop.yarn.api.records.timeline.TimelineEntity:getEntityId()	javax.xml.bind.annotation.XmlElement	name	entity
org.apache.hadoop.yarn.api.records.timeline.TimelineEntity:getStartTime()	javax.xml.bind.annotation.XmlElement	name	starttime
org.apache.hadoop.yarn.api.records.timeline.TimelineEntity:getEvents()	javax.xml.bind.annotation.XmlElement	name	events
org.apache.hadoop.yarn.api.records.timeline.TimelineEntity:getRelatedEntitiesJAXB()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.timeline.TimelineEntity:getRelatedEntitiesJAXB()	javax.xml.bind.annotation.XmlElement	name	relatedentities
org.apache.hadoop.yarn.api.records.timeline.TimelineEntity:getPrimaryFiltersJAXB()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.timeline.TimelineEntity:getPrimaryFiltersJAXB()	javax.xml.bind.annotation.XmlElement	name	primaryfilters
org.apache.hadoop.yarn.api.records.timeline.TimelineEntity:getOtherInfoJAXB()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.timeline.TimelineEntity:getOtherInfoJAXB()	javax.xml.bind.annotation.XmlElement	name	otherinfo
org.apache.hadoop.yarn.api.records.timeline.TimelineEntity:getDomainId()	javax.xml.bind.annotation.XmlElement	name	domain
org.apache.hadoop.yarn.api.records.timeline.TimelineHealth:getHealthStatus()	javax.xml.bind.annotation.XmlElement	name	healthStatus
org.apache.hadoop.yarn.api.records.timeline.TimelineHealth:getDiagnosticsInfo()	javax.xml.bind.annotation.XmlElement	name	diagnosticsInfo
org.apache.hadoop.yarn.api.records.ReservationAllocationState:newInstance(long,java.lang.String,java.util.List,org.apache.hadoop.yarn.api.records.ReservationId,org.apache.hadoop.yarn.api.records.ReservationDefinition)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ReservationAllocationState:newInstance(long,java.lang.String,java.util.List,org.apache.hadoop.yarn.api.records.ReservationId,org.apache.hadoop.yarn.api.records.ReservationDefinition)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.ReservationAllocationState:getAcceptanceTime()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ReservationAllocationState:getAcceptanceTime()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ReservationAllocationState:setAcceptanceTime(long)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.ReservationAllocationState:setAcceptanceTime(long)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ReservationAllocationState:getUser()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ReservationAllocationState:getUser()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ReservationAllocationState:setUser(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.ReservationAllocationState:setUser(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ReservationAllocationState:getResourceAllocationRequests()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ReservationAllocationState:getResourceAllocationRequests()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ReservationAllocationState:setResourceAllocationRequests(java.util.List)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.ReservationAllocationState:setResourceAllocationRequests(java.util.List)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ReservationAllocationState:getReservationId()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ReservationAllocationState:getReservationId()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ReservationAllocationState:setReservationId(org.apache.hadoop.yarn.api.records.ReservationId)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.ReservationAllocationState:setReservationId(org.apache.hadoop.yarn.api.records.ReservationId)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ReservationAllocationState:getReservationDefinition()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ReservationAllocationState:getReservationDefinition()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ReservationAllocationState:setReservationDefinition(org.apache.hadoop.yarn.api.records.ReservationDefinition)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.ReservationAllocationState:setReservationDefinition(org.apache.hadoop.yarn.api.records.ReservationDefinition)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.NodeLabel:newInstance(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.NodeLabel:newInstance(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.NodeLabel:newInstance(java.lang.String,boolean)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.NodeLabel:newInstance(java.lang.String,boolean)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.NodeLabel:getName()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.NodeLabel:getName()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.NodeLabel:setName(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.NodeLabel:setName(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.NodeLabel:isExclusive()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.NodeLabel:isExclusive()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.NodeLabel:setExclusivity(boolean)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.NodeLabel:setExclusivity(boolean)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.StrictPreemptionContract:newInstance(java.util.Set)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.StrictPreemptionContract:newInstance(java.util.Set)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.StrictPreemptionContract:getContainers()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.StrictPreemptionContract:getContainers()	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.yarn.api.records.StrictPreemptionContract:setContainers(java.util.Set)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.StrictPreemptionContract:setContainers(java.util.Set)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.QueueConfigurations:newInstance(float,float,float,float,float)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.QueueConfigurations:newInstance(float,float,float,float,float)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.QueueConfigurations:getCapacity()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.QueueConfigurations:getCapacity()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.QueueConfigurations:setCapacity(float)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.QueueConfigurations:setCapacity(float)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.QueueConfigurations:getAbsoluteCapacity()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.QueueConfigurations:getAbsoluteCapacity()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.QueueConfigurations:setAbsoluteCapacity(float)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.QueueConfigurations:setAbsoluteCapacity(float)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.QueueConfigurations:getMaxCapacity()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.QueueConfigurations:getMaxCapacity()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.QueueConfigurations:setMaxCapacity(float)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.QueueConfigurations:setMaxCapacity(float)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.QueueConfigurations:getAbsoluteMaxCapacity()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.QueueConfigurations:getAbsoluteMaxCapacity()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.QueueConfigurations:setAbsoluteMaxCapacity(float)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.QueueConfigurations:setAbsoluteMaxCapacity(float)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.QueueConfigurations:getMaxAMPercentage()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.QueueConfigurations:getMaxAMPercentage()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.QueueConfigurations:setMaxAMPercentage(float)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.QueueConfigurations:setMaxAMPercentage(float)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.QueueConfigurations:getEffectiveMinCapacity()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.QueueConfigurations:getEffectiveMinCapacity()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.QueueConfigurations:setEffectiveMinCapacity(org.apache.hadoop.yarn.api.records.Resource)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.QueueConfigurations:setEffectiveMinCapacity(org.apache.hadoop.yarn.api.records.Resource)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.QueueConfigurations:getEffectiveMaxCapacity()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.QueueConfigurations:getEffectiveMaxCapacity()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.QueueConfigurations:setEffectiveMaxCapacity(org.apache.hadoop.yarn.api.records.Resource)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.QueueConfigurations:setEffectiveMaxCapacity(org.apache.hadoop.yarn.api.records.Resource)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.QueueConfigurations:getConfiguredMinCapacity()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.QueueConfigurations:getConfiguredMinCapacity()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.QueueConfigurations:setConfiguredMinCapacity(org.apache.hadoop.yarn.api.records.Resource)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.QueueConfigurations:setConfiguredMinCapacity(org.apache.hadoop.yarn.api.records.Resource)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.QueueConfigurations:getConfiguredMaxCapacity()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.QueueConfigurations:getConfiguredMaxCapacity()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.QueueConfigurations:setConfiguredMaxCapacity(org.apache.hadoop.yarn.api.records.Resource)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.QueueConfigurations:setConfiguredMaxCapacity(org.apache.hadoop.yarn.api.records.Resource)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.URL:newInstance(java.lang.String,java.lang.String,int,java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.URL:newInstance(java.lang.String,java.lang.String,int,java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.URL:getScheme()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.URL:getScheme()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.URL:setScheme(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.URL:setScheme(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.URL:getUserInfo()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.URL:getUserInfo()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.URL:setUserInfo(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.URL:setUserInfo(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.URL:getHost()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.URL:getHost()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.URL:setHost(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.URL:setHost(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.URL:getPort()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.URL:getPort()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.URL:setPort(int)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.URL:setPort(int)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.URL:getFile()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.URL:getFile()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.URL:setFile(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.URL:setFile(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.URL:toPath()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.URL:toPath()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.URL:fromURI(java.net.URI,org.apache.hadoop.conf.Configuration)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.URL:fromURI(java.net.URI,org.apache.hadoop.conf.Configuration)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.api.records.URL:fromURI(java.net.URI)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.URL:fromURI(java.net.URI)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.URL:fromPath(org.apache.hadoop.fs.Path,org.apache.hadoop.conf.Configuration)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.URL:fromPath(org.apache.hadoop.fs.Path,org.apache.hadoop.conf.Configuration)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.api.records.URL:fromPath(org.apache.hadoop.fs.Path)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.URL:fromPath(org.apache.hadoop.fs.Path)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.PreemptionContainer:newInstance(org.apache.hadoop.yarn.api.records.ContainerId)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.PreemptionContainer:newInstance(org.apache.hadoop.yarn.api.records.ContainerId)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.PreemptionContainer:getId()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.PreemptionContainer:getId()	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.yarn.api.records.PreemptionContainer:setId(org.apache.hadoop.yarn.api.records.ContainerId)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.PreemptionContainer:setId(org.apache.hadoop.yarn.api.records.ContainerId)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.UpdatedContainer:newInstance(org.apache.hadoop.yarn.api.records.ContainerUpdateType,org.apache.hadoop.yarn.api.records.Container)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.UpdatedContainer:newInstance(org.apache.hadoop.yarn.api.records.ContainerUpdateType,org.apache.hadoop.yarn.api.records.Container)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.SchedulingRequest$SchedulingRequestBuilder:allocationRequestId(long)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.SchedulingRequest$SchedulingRequestBuilder:allocationRequestId(long)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.SchedulingRequest$SchedulingRequestBuilder:priority(org.apache.hadoop.yarn.api.records.Priority)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.SchedulingRequest$SchedulingRequestBuilder:priority(org.apache.hadoop.yarn.api.records.Priority)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.SchedulingRequest$SchedulingRequestBuilder:executionType(org.apache.hadoop.yarn.api.records.ExecutionTypeRequest)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.SchedulingRequest$SchedulingRequestBuilder:executionType(org.apache.hadoop.yarn.api.records.ExecutionTypeRequest)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.SchedulingRequest$SchedulingRequestBuilder:allocationTags(java.util.Set)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.SchedulingRequest$SchedulingRequestBuilder:allocationTags(java.util.Set)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.SchedulingRequest$SchedulingRequestBuilder:resourceSizing(org.apache.hadoop.yarn.api.records.ResourceSizing)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.SchedulingRequest$SchedulingRequestBuilder:resourceSizing(org.apache.hadoop.yarn.api.records.ResourceSizing)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.SchedulingRequest$SchedulingRequestBuilder:placementConstraintExpression(org.apache.hadoop.yarn.api.resource.PlacementConstraint)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.SchedulingRequest$SchedulingRequestBuilder:placementConstraintExpression(org.apache.hadoop.yarn.api.resource.PlacementConstraint)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.SchedulingRequest$SchedulingRequestBuilder:build()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.SchedulingRequest$SchedulingRequestBuilder:build()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.QueueStatistics:newInstance(long,long,long,long,long,long,long,long,long,long,long,long,long,long,long)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.QueueStatistics:newInstance(long,long,long,long,long,long,long,long,long,long,long,long,long,long,long)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ResourceBlacklistRequest:newInstance(java.util.List,java.util.List)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ResourceBlacklistRequest:newInstance(java.util.List,java.util.List)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.ResourceBlacklistRequest:getBlacklistAdditions()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ResourceBlacklistRequest:getBlacklistAdditions()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.ResourceBlacklistRequest:setBlacklistAdditions(java.util.List)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ResourceBlacklistRequest:setBlacklistAdditions(java.util.List)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.ResourceBlacklistRequest:getBlacklistRemovals()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ResourceBlacklistRequest:getBlacklistRemovals()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.ResourceBlacklistRequest:setBlacklistRemovals(java.util.List)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ResourceBlacklistRequest:setBlacklistRemovals(java.util.List)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.NodeId:newInstance(java.lang.String,int)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.NodeId:newInstance(java.lang.String,int)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.NodeId:getHost()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.NodeId:getHost()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.NodeId:setHost(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.NodeId:setHost(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.NodeId:getPort()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.NodeId:getPort()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.NodeId:setPort(int)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.NodeId:setPort(int)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.NodeId:fromString(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.NodeId:fromString(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.QueueUserACLInfo:newInstance(java.lang.String,java.util.List)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.QueueUserACLInfo:newInstance(java.lang.String,java.util.List)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.QueueUserACLInfo:getQueueName()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.QueueUserACLInfo:getQueueName()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.QueueUserACLInfo:setQueueName(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.QueueUserACLInfo:setQueueName(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.QueueUserACLInfo:getUserAcls()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.QueueUserACLInfo:getUserAcls()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.QueueUserACLInfo:setUserAcls(java.util.List)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.QueueUserACLInfo:setUserAcls(java.util.List)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.LocalizationStatus:setResourceKey(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.LocalizationStatus:setLocalizationState(org.apache.hadoop.yarn.api.records.LocalizationState)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.LocalizationStatus:setDiagnostics(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.ResourceOption:getResource()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.ResourceOption:getResource()	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.yarn.api.records.ResourceOption:setResource(org.apache.hadoop.yarn.api.records.Resource)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.ResourceOption:setResource(org.apache.hadoop.yarn.api.records.Resource)	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.yarn.api.records.ResourceOption:getOverCommitTimeout()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.ResourceOption:getOverCommitTimeout()	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.yarn.api.records.ResourceOption:setOverCommitTimeout(int)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.ResourceOption:setOverCommitTimeout(int)	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.yarn.api.records.ResourceOption:build()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.ResourceOption:build()	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.yarn.api.records.ContainerLaunchContext:newInstance(java.util.Map,java.util.Map,java.util.List,java.util.Map,java.nio.ByteBuffer,java.util.Map)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ContainerLaunchContext:newInstance(java.util.Map,java.util.Map,java.util.List,java.util.Map,java.nio.ByteBuffer,java.util.Map)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.ContainerLaunchContext:newInstance(java.util.Map,java.util.Map,java.util.List,java.util.Map,java.nio.ByteBuffer,java.util.Map,org.apache.hadoop.yarn.api.records.ContainerRetryContext)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ContainerLaunchContext:newInstance(java.util.Map,java.util.Map,java.util.List,java.util.Map,java.nio.ByteBuffer,java.util.Map,org.apache.hadoop.yarn.api.records.ContainerRetryContext)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ContainerLaunchContext:getTokens()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ContainerLaunchContext:getTokens()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.ContainerLaunchContext:setTokens(java.nio.ByteBuffer)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ContainerLaunchContext:setTokens(java.nio.ByteBuffer)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.ContainerLaunchContext:getTokensConf()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ContainerLaunchContext:getTokensConf()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ContainerLaunchContext:setTokensConf(java.nio.ByteBuffer)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ContainerLaunchContext:setTokensConf(java.nio.ByteBuffer)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ContainerLaunchContext:getLocalResources()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ContainerLaunchContext:getLocalResources()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.ContainerLaunchContext:setLocalResources(java.util.Map)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ContainerLaunchContext:setLocalResources(java.util.Map)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.ContainerLaunchContext:getServiceData()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ContainerLaunchContext:getServiceData()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.ContainerLaunchContext:setServiceData(java.util.Map)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ContainerLaunchContext:setServiceData(java.util.Map)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.ContainerLaunchContext:getEnvironment()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ContainerLaunchContext:getEnvironment()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.ContainerLaunchContext:setEnvironment(java.util.Map)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ContainerLaunchContext:setEnvironment(java.util.Map)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.ContainerLaunchContext:getCommands()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ContainerLaunchContext:getCommands()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.ContainerLaunchContext:setCommands(java.util.List)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ContainerLaunchContext:setCommands(java.util.List)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.ContainerLaunchContext:getApplicationACLs()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ContainerLaunchContext:getApplicationACLs()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.ContainerLaunchContext:setApplicationACLs(java.util.Map)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ContainerLaunchContext:setApplicationACLs(java.util.Map)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.ContainerLaunchContext:getContainerRetryContext()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ContainerLaunchContext:getContainerRetryContext()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ContainerLaunchContext:setContainerRetryContext(org.apache.hadoop.yarn.api.records.ContainerRetryContext)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ContainerLaunchContext:setContainerRetryContext(org.apache.hadoop.yarn.api.records.ContainerRetryContext)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ApplicationResourceUsageReport:newInstance(int,int,org.apache.hadoop.yarn.api.records.Resource,org.apache.hadoop.yarn.api.records.Resource,org.apache.hadoop.yarn.api.records.Resource,java.util.Map,float,float,java.util.Map)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.ApplicationResourceUsageReport:newInstance(int,int,org.apache.hadoop.yarn.api.records.Resource,org.apache.hadoop.yarn.api.records.Resource,org.apache.hadoop.yarn.api.records.Resource,java.util.Map,float,float,java.util.Map)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ApplicationResourceUsageReport:getNumUsedContainers()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ApplicationResourceUsageReport:getNumUsedContainers()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.ApplicationResourceUsageReport:setNumUsedContainers(int)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.ApplicationResourceUsageReport:setNumUsedContainers(int)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ApplicationResourceUsageReport:getNumReservedContainers()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.ApplicationResourceUsageReport:getNumReservedContainers()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ApplicationResourceUsageReport:setNumReservedContainers(int)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.ApplicationResourceUsageReport:setNumReservedContainers(int)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ApplicationResourceUsageReport:getUsedResources()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ApplicationResourceUsageReport:getUsedResources()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.ApplicationResourceUsageReport:setUsedResources(org.apache.hadoop.yarn.api.records.Resource)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.ApplicationResourceUsageReport:setUsedResources(org.apache.hadoop.yarn.api.records.Resource)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ApplicationResourceUsageReport:getReservedResources()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ApplicationResourceUsageReport:getReservedResources()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.ApplicationResourceUsageReport:setReservedResources(org.apache.hadoop.yarn.api.records.Resource)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.ApplicationResourceUsageReport:setReservedResources(org.apache.hadoop.yarn.api.records.Resource)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ApplicationResourceUsageReport:getNeededResources()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ApplicationResourceUsageReport:getNeededResources()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.ApplicationResourceUsageReport:setNeededResources(org.apache.hadoop.yarn.api.records.Resource)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.ApplicationResourceUsageReport:setNeededResources(org.apache.hadoop.yarn.api.records.Resource)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ApplicationResourceUsageReport:setMemorySeconds(long)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.ApplicationResourceUsageReport:setMemorySeconds(long)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ApplicationResourceUsageReport:getMemorySeconds()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ApplicationResourceUsageReport:getMemorySeconds()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ApplicationResourceUsageReport:setVcoreSeconds(long)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.ApplicationResourceUsageReport:setVcoreSeconds(long)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ApplicationResourceUsageReport:getVcoreSeconds()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ApplicationResourceUsageReport:getVcoreSeconds()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ApplicationResourceUsageReport:getQueueUsagePercentage()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ApplicationResourceUsageReport:getQueueUsagePercentage()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.ApplicationResourceUsageReport:setQueueUsagePercentage(float)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.ApplicationResourceUsageReport:setQueueUsagePercentage(float)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ApplicationResourceUsageReport:getClusterUsagePercentage()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ApplicationResourceUsageReport:getClusterUsagePercentage()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.api.records.ApplicationResourceUsageReport:setClusterUsagePercentage(float)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.ApplicationResourceUsageReport:setClusterUsagePercentage(float)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ApplicationResourceUsageReport:setPreemptedMemorySeconds(long)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.ApplicationResourceUsageReport:setPreemptedMemorySeconds(long)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ApplicationResourceUsageReport:getPreemptedMemorySeconds()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ApplicationResourceUsageReport:getPreemptedMemorySeconds()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ApplicationResourceUsageReport:setPreemptedVcoreSeconds(long)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.ApplicationResourceUsageReport:setPreemptedVcoreSeconds(long)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ApplicationResourceUsageReport:getPreemptedVcoreSeconds()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ApplicationResourceUsageReport:getPreemptedVcoreSeconds()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ApplicationResourceUsageReport:getResourceSecondsMap()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ApplicationResourceUsageReport:getResourceSecondsMap()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ApplicationResourceUsageReport:setResourceSecondsMap(java.util.Map)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.ApplicationResourceUsageReport:setResourceSecondsMap(java.util.Map)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ApplicationResourceUsageReport:getPreemptedResourceSecondsMap()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.records.ApplicationResourceUsageReport:getPreemptedResourceSecondsMap()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ApplicationResourceUsageReport:setPreemptedResourceSecondsMap(java.util.Map)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.ApplicationResourceUsageReport:setPreemptedResourceSecondsMap(java.util.Map)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ContainerRetryContext:newInstance(org.apache.hadoop.yarn.api.records.ContainerRetryPolicy,java.util.Set,int,int,long)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.ContainerRetryContext:newInstance(org.apache.hadoop.yarn.api.records.ContainerRetryPolicy,java.util.Set,int,int,long)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.api.records.ContainerRetryContext:newInstance(org.apache.hadoop.yarn.api.records.ContainerRetryPolicy,java.util.Set,int,int)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.api.records.ContainerRetryContext:newInstance(org.apache.hadoop.yarn.api.records.ContainerRetryPolicy,java.util.Set,int,int)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.conf.YarnConfiguration:getExclusiveEnforcedPartitions(org.apache.hadoop.conf.Configuration)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.conf.YarnConfiguration:isDistributedNodeLabelConfiguration(org.apache.hadoop.conf.Configuration)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.conf.YarnConfiguration:isCentralizedNodeLabelConfiguration(org.apache.hadoop.conf.Configuration)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.conf.YarnConfiguration:isDelegatedCentralizedNodeLabelConfiguration(org.apache.hadoop.conf.Configuration)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.conf.YarnConfiguration:areNodeLabelsEnabled(org.apache.hadoop.conf.Configuration)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.conf.YarnConfiguration:getServiceAddressConfKeys(org.apache.hadoop.conf.Configuration)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.conf.YarnConfiguration:getRMDefaultPortNumber(java.lang.String,org.apache.hadoop.conf.Configuration)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.conf.YarnConfiguration:getClusterId(org.apache.hadoop.conf.Configuration)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.conf.HAUtil:getNeedToSetValueMessage(java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.conf.HAUtil:getInvalidValueMessage(java.lang.String,java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.conf.HAUtil:getRMHAIdNeedToBeIncludedMessage(java.lang.String,java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.conf.HAUtil:getRMHAIdsWarningMessage(java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.conf.HAUtil:getConfKeyForRMInstance(java.lang.String,org.apache.hadoop.conf.Configuration)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.conf.HAUtil:getConfKeyForRMInstance(java.lang.String,org.apache.hadoop.conf.Configuration)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.proto.YarnProtos$CompositePlacementConstraintProto$CompositeType:valueOf(int)	java.lang.Deprecated
org.apache.hadoop.yarn.proto.YarnProtos$NodeStateProto:valueOf(int)	java.lang.Deprecated
org.apache.hadoop.yarn.proto.YarnServerResourceManagerServiceProtos$AttributeMappingOperationTypeProto:valueOf(int)	java.lang.Deprecated
org.apache.hadoop.yarn.proto.YarnProtos$ContainerExitStatusProto:valueOf(int)	java.lang.Deprecated
org.apache.hadoop.yarn.proto.YarnServiceProtos$ApplicationsRequestScopeProto:valueOf(int)	java.lang.Deprecated
org.apache.hadoop.yarn.proto.YarnProtos$AMCommandProto:valueOf(int)	java.lang.Deprecated
org.apache.hadoop.yarn.proto.CsiAdaptorProtos$VolumeCapability$AccessMode:valueOf(int)	java.lang.Deprecated
org.apache.hadoop.yarn.proto.YarnProtos$ContainerRetryPolicyProto:valueOf(int)	java.lang.Deprecated
org.apache.hadoop.yarn.proto.YarnProtos$LocalResourceTypeProto:valueOf(int)	java.lang.Deprecated
org.apache.hadoop.yarn.proto.YarnServiceProtos$ContainerUpdateTypeProto:valueOf(int)	java.lang.Deprecated
org.apache.hadoop.yarn.proto.YarnServiceProtos$SchedulerResourceTypes:valueOf(int)	java.lang.Deprecated
org.apache.hadoop.yarn.proto.YarnProtos$ContainerSubStateProto:valueOf(int)	java.lang.Deprecated
org.apache.hadoop.yarn.proto.YarnProtos$YarnApplicationAttemptStateProto:valueOf(int)	java.lang.Deprecated
org.apache.hadoop.yarn.proto.YarnProtos$FinalApplicationStatusProto:valueOf(int)	java.lang.Deprecated
org.apache.hadoop.yarn.proto.YarnProtos$RejectionReasonProto:valueOf(int)	java.lang.Deprecated
org.apache.hadoop.yarn.proto.YarnProtos$NodeAttributeTypeProto:valueOf(int)	java.lang.Deprecated
org.apache.hadoop.yarn.proto.YarnProtos$LocalResourceVisibilityProto:valueOf(int)	java.lang.Deprecated
org.apache.hadoop.yarn.proto.YarnServiceProtos$LocalizationStateProto:valueOf(int)	java.lang.Deprecated
org.apache.hadoop.yarn.proto.YarnProtos$NodeUpdateTypeProto:valueOf(int)	java.lang.Deprecated
org.apache.hadoop.yarn.proto.CsiAdaptorProtos$VolumeCapability$VolumeType:valueOf(int)	java.lang.Deprecated
org.apache.hadoop.yarn.proto.YarnProtos$ResourceTypesProto:valueOf(int)	java.lang.Deprecated
org.apache.hadoop.yarn.proto.YarnProtos$ApplicationTimeoutTypeProto:valueOf(int)	java.lang.Deprecated
org.apache.hadoop.yarn.proto.YarnProtos$LogAggregationStatusProto:valueOf(int)	java.lang.Deprecated
org.apache.hadoop.yarn.proto.YarnProtos$TimedPlacementConstraintProto$DelayUnit:valueOf(int)	java.lang.Deprecated
org.apache.hadoop.yarn.proto.YarnProtos$PlacementConstraintTargetProto$TargetType:valueOf(int)	java.lang.Deprecated
org.apache.hadoop.yarn.proto.YarnProtos$ReservationRequestInterpreterProto:valueOf(int)	java.lang.Deprecated
org.apache.hadoop.yarn.proto.YarnProtos$ApplicationAccessTypeProto:valueOf(int)	java.lang.Deprecated
org.apache.hadoop.yarn.proto.YarnProtos$QueueACLProto:valueOf(int)	java.lang.Deprecated
org.apache.hadoop.yarn.proto.YarnProtos$ContainerStateProto:valueOf(int)	java.lang.Deprecated
org.apache.hadoop.yarn.proto.YarnProtos$NodeAttributeOpCodeProto:valueOf(int)	java.lang.Deprecated
org.apache.hadoop.yarn.proto.YarnServerResourceManagerServiceProtos$DecommissionTypeProto:valueOf(int)	java.lang.Deprecated
org.apache.hadoop.yarn.proto.YarnProtos$YarnApplicationStateProto:valueOf(int)	java.lang.Deprecated
org.apache.hadoop.yarn.proto.YarnProtos$ContainerTypeProto:valueOf(int)	java.lang.Deprecated
org.apache.hadoop.yarn.proto.YarnProtos$QueueStateProto:valueOf(int)	java.lang.Deprecated
org.apache.hadoop.yarn.proto.YarnProtos$SignalContainerCommandProto:valueOf(int)	java.lang.Deprecated
org.apache.hadoop.yarn.proto.YarnProtos$ExecutionTypeProto:valueOf(int)	java.lang.Deprecated
org.apache.hadoop.yarn.server.api.protocolrecords.ReplaceLabelsOnNodeRequest:setNodeToLabels(java.util.Map)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.api.protocolrecords.ReplaceLabelsOnNodeRequest:setNodeToLabels(java.util.Map)	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.yarn.server.api.protocolrecords.ReplaceLabelsOnNodeRequest:getNodeToLabels()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.api.protocolrecords.ReplaceLabelsOnNodeRequest:getNodeToLabels()	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.yarn.server.api.protocolrecords.ReplaceLabelsOnNodeRequest:setFailOnUnknownNodes(boolean)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.api.protocolrecords.ReplaceLabelsOnNodeRequest:setFailOnUnknownNodes(boolean)	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.yarn.server.api.protocolrecords.ReplaceLabelsOnNodeRequest:getFailOnUnknownNodes()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.api.protocolrecords.ReplaceLabelsOnNodeRequest:getFailOnUnknownNodes()	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.yarn.server.api.protocolrecords.CheckForDecommissioningNodesRequest:newInstance()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.api.protocolrecords.CheckForDecommissioningNodesRequest:newInstance()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.api.protocolrecords.AddToClusterNodeLabelsRequest:newInstance(java.util.List)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.api.protocolrecords.AddToClusterNodeLabelsRequest:newInstance(java.util.List)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.api.protocolrecords.AddToClusterNodeLabelsRequest:setNodeLabels(java.util.List)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.api.protocolrecords.AddToClusterNodeLabelsRequest:setNodeLabels(java.util.List)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.api.protocolrecords.AddToClusterNodeLabelsRequest:getNodeLabels()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.api.protocolrecords.AddToClusterNodeLabelsRequest:getNodeLabels()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.api.protocolrecords.UpdateNodeResourceRequest:newInstance(java.util.Map)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.api.protocolrecords.UpdateNodeResourceRequest:newInstance(java.util.Map)	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.yarn.server.api.protocolrecords.UpdateNodeResourceRequest:getNodeResourceMap()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.api.protocolrecords.UpdateNodeResourceRequest:getNodeResourceMap()	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.yarn.server.api.protocolrecords.UpdateNodeResourceRequest:setNodeResourceMap(java.util.Map)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.api.protocolrecords.UpdateNodeResourceRequest:setNodeResourceMap(java.util.Map)	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.yarn.server.api.protocolrecords.RefreshSuperUserGroupsConfigurationResponse:newInstance()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.api.protocolrecords.RefreshSuperUserGroupsConfigurationResponse:newInstance()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.api.protocolrecords.RefreshNodesResourcesRequest:newInstance()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.api.protocolrecords.RefreshNodesResourcesRequest:newInstance()	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.yarn.server.api.protocolrecords.RefreshServiceAclsResponse:newInstance()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.api.protocolrecords.RefreshServiceAclsResponse:newInstance()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.api.protocolrecords.RunSharedCacheCleanerTaskResponse:getAccepted()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.api.protocolrecords.RunSharedCacheCleanerTaskResponse:getAccepted()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.api.protocolrecords.RunSharedCacheCleanerTaskResponse:setAccepted(boolean)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.api.protocolrecords.RunSharedCacheCleanerTaskResponse:setAccepted(boolean)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.api.protocolrecords.RefreshSuperUserGroupsConfigurationRequest:newInstance()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.api.protocolrecords.RefreshSuperUserGroupsConfigurationRequest:newInstance()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.server.api.protocolrecords.NodesToAttributesMappingRequest:setNodesToAttributes(java.util.List)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.api.protocolrecords.NodesToAttributesMappingRequest:setNodesToAttributes(java.util.List)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.api.protocolrecords.NodesToAttributesMappingRequest:getNodesToAttributes()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.api.protocolrecords.NodesToAttributesMappingRequest:getNodesToAttributes()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.api.protocolrecords.NodesToAttributesMappingRequest:setFailOnUnknownNodes(boolean)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.api.protocolrecords.NodesToAttributesMappingRequest:setFailOnUnknownNodes(boolean)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.api.protocolrecords.NodesToAttributesMappingRequest:getFailOnUnknownNodes()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.api.protocolrecords.NodesToAttributesMappingRequest:getFailOnUnknownNodes()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.api.protocolrecords.NodesToAttributesMappingRequest:setOperation(org.apache.hadoop.yarn.server.api.protocolrecords.AttributeMappingOperationType)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.api.protocolrecords.NodesToAttributesMappingRequest:setOperation(org.apache.hadoop.yarn.server.api.protocolrecords.AttributeMappingOperationType)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.api.protocolrecords.NodesToAttributesMappingRequest:getOperation()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.api.protocolrecords.NodesToAttributesMappingRequest:getOperation()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.api.protocolrecords.RefreshUserToGroupsMappingsRequest:newInstance()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.api.protocolrecords.RefreshUserToGroupsMappingsRequest:newInstance()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.server.api.protocolrecords.RefreshUserToGroupsMappingsResponse:newInstance()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.api.protocolrecords.RefreshUserToGroupsMappingsResponse:newInstance()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.api.protocolrecords.RefreshQueuesRequest:newInstance()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.api.protocolrecords.RefreshQueuesRequest:newInstance()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.server.api.protocolrecords.RefreshAdminAclsRequest:newInstance()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.api.protocolrecords.RefreshAdminAclsRequest:newInstance()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.server.api.protocolrecords.CheckForDecommissioningNodesResponse:newInstance(java.util.Set)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.api.protocolrecords.CheckForDecommissioningNodesResponse:newInstance(java.util.Set)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.api.protocolrecords.RefreshNodesRequest:newInstance()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.api.protocolrecords.RefreshNodesRequest:newInstance()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.server.api.protocolrecords.RefreshNodesRequest:newInstance(org.apache.hadoop.yarn.api.records.DecommissionType)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.api.protocolrecords.RefreshNodesRequest:newInstance(org.apache.hadoop.yarn.api.records.DecommissionType)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.api.protocolrecords.RefreshNodesRequest:newInstance(org.apache.hadoop.yarn.api.records.DecommissionType,java.lang.Integer)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.api.protocolrecords.RefreshNodesRequest:newInstance(org.apache.hadoop.yarn.api.records.DecommissionType,java.lang.Integer)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.api.protocolrecords.RefreshServiceAclsRequest:newInstance()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.api.protocolrecords.RefreshServiceAclsRequest:newInstance()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.server.api.protocolrecords.NodeToAttributes:getNode()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.api.protocolrecords.NodeToAttributes:getNode()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.api.protocolrecords.NodeToAttributes:setNode(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.api.protocolrecords.NodeToAttributes:setNode(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.api.protocolrecords.NodeToAttributes:getNodeAttributes()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.api.protocolrecords.NodeToAttributes:getNodeAttributes()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.api.protocolrecords.NodeToAttributes:setNodeAttributes(java.util.List)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.api.protocolrecords.NodeToAttributes:setNodeAttributes(java.util.List)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.api.protocolrecords.RefreshNodesResourcesResponse:newInstance()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.api.protocolrecords.RefreshNodesResourcesResponse:newInstance()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.api.protocolrecords.RemoveFromClusterNodeLabelsRequest:setNodeLabels(java.util.Set)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.api.protocolrecords.RemoveFromClusterNodeLabelsRequest:setNodeLabels(java.util.Set)	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.yarn.server.api.protocolrecords.RemoveFromClusterNodeLabelsRequest:getNodeLabels()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.api.protocolrecords.RemoveFromClusterNodeLabelsRequest:getNodeLabels()	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.yarn.server.api.protocolrecords.RefreshClusterMaxPriorityRequest:newInstance()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.api.protocolrecords.RefreshClusterMaxPriorityRequest:newInstance()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.api.protocolrecords.RefreshAdminAclsResponse:newInstance()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.api.protocolrecords.RefreshAdminAclsResponse:newInstance()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.api.protocolrecords.RefreshNodesResponse:newInstance()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.api.protocolrecords.RefreshNodesResponse:newInstance()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.api.protocolrecords.RefreshClusterMaxPriorityResponse:newInstance()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.api.protocolrecords.RefreshClusterMaxPriorityResponse:newInstance()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.api.protocolrecords.RefreshQueuesResponse:newInstance()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.api.protocolrecords.RefreshQueuesResponse:newInstance()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.api.ContainerContext:<init>(java.lang.String,org.apache.hadoop.yarn.api.records.ContainerId,org.apache.hadoop.yarn.api.records.Resource)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.api.ContainerContext:<init>(java.lang.String,org.apache.hadoop.yarn.api.records.ContainerId,org.apache.hadoop.yarn.api.records.Resource)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.api.ContainerContext:<init>(java.lang.String,org.apache.hadoop.yarn.api.records.ContainerId,org.apache.hadoop.yarn.api.records.Resource,org.apache.hadoop.yarn.server.api.ContainerType)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.api.ContainerContext:<init>(java.lang.String,org.apache.hadoop.yarn.api.records.ContainerId,org.apache.hadoop.yarn.api.records.Resource,org.apache.hadoop.yarn.server.api.ContainerType)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.api.ContainerContext:<init>(java.lang.String,org.apache.hadoop.yarn.api.records.ContainerId,org.apache.hadoop.yarn.api.records.Resource,org.apache.hadoop.yarn.server.api.ContainerType,org.apache.hadoop.yarn.api.records.ExecutionType)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.api.ContainerContext:<init>(java.lang.String,org.apache.hadoop.yarn.api.records.ContainerId,org.apache.hadoop.yarn.api.records.Resource,org.apache.hadoop.yarn.server.api.ContainerType,org.apache.hadoop.yarn.api.records.ExecutionType)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.api.ResourceManagerAdministrationProtocol:refreshQueues(org.apache.hadoop.yarn.server.api.protocolrecords.RefreshQueuesRequest)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.api.ResourceManagerAdministrationProtocol:refreshQueues(org.apache.hadoop.yarn.server.api.protocolrecords.RefreshQueuesRequest)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.yarn.server.api.ResourceManagerAdministrationProtocol:refreshNodes(org.apache.hadoop.yarn.server.api.protocolrecords.RefreshNodesRequest)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.api.ResourceManagerAdministrationProtocol:refreshNodes(org.apache.hadoop.yarn.server.api.protocolrecords.RefreshNodesRequest)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.yarn.server.api.ResourceManagerAdministrationProtocol:refreshSuperUserGroupsConfiguration(org.apache.hadoop.yarn.server.api.protocolrecords.RefreshSuperUserGroupsConfigurationRequest)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.api.ResourceManagerAdministrationProtocol:refreshSuperUserGroupsConfiguration(org.apache.hadoop.yarn.server.api.protocolrecords.RefreshSuperUserGroupsConfigurationRequest)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.yarn.server.api.ResourceManagerAdministrationProtocol:refreshUserToGroupsMappings(org.apache.hadoop.yarn.server.api.protocolrecords.RefreshUserToGroupsMappingsRequest)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.api.ResourceManagerAdministrationProtocol:refreshUserToGroupsMappings(org.apache.hadoop.yarn.server.api.protocolrecords.RefreshUserToGroupsMappingsRequest)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.yarn.server.api.ResourceManagerAdministrationProtocol:refreshAdminAcls(org.apache.hadoop.yarn.server.api.protocolrecords.RefreshAdminAclsRequest)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.api.ResourceManagerAdministrationProtocol:refreshAdminAcls(org.apache.hadoop.yarn.server.api.protocolrecords.RefreshAdminAclsRequest)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.yarn.server.api.ResourceManagerAdministrationProtocol:refreshServiceAcls(org.apache.hadoop.yarn.server.api.protocolrecords.RefreshServiceAclsRequest)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.api.ResourceManagerAdministrationProtocol:refreshServiceAcls(org.apache.hadoop.yarn.server.api.protocolrecords.RefreshServiceAclsRequest)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.yarn.server.api.ResourceManagerAdministrationProtocol:updateNodeResource(org.apache.hadoop.yarn.server.api.protocolrecords.UpdateNodeResourceRequest)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.api.ResourceManagerAdministrationProtocol:updateNodeResource(org.apache.hadoop.yarn.server.api.protocolrecords.UpdateNodeResourceRequest)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.yarn.server.api.ResourceManagerAdministrationProtocol:refreshNodesResources(org.apache.hadoop.yarn.server.api.protocolrecords.RefreshNodesResourcesRequest)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.api.ResourceManagerAdministrationProtocol:refreshNodesResources(org.apache.hadoop.yarn.server.api.protocolrecords.RefreshNodesResourcesRequest)	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.yarn.server.api.ResourceManagerAdministrationProtocol:refreshNodesResources(org.apache.hadoop.yarn.server.api.protocolrecords.RefreshNodesResourcesRequest)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.yarn.server.api.ResourceManagerAdministrationProtocol:addToClusterNodeLabels(org.apache.hadoop.yarn.server.api.protocolrecords.AddToClusterNodeLabelsRequest)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.api.ResourceManagerAdministrationProtocol:addToClusterNodeLabels(org.apache.hadoop.yarn.server.api.protocolrecords.AddToClusterNodeLabelsRequest)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.yarn.server.api.ResourceManagerAdministrationProtocol:removeFromClusterNodeLabels(org.apache.hadoop.yarn.server.api.protocolrecords.RemoveFromClusterNodeLabelsRequest)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.api.ResourceManagerAdministrationProtocol:removeFromClusterNodeLabels(org.apache.hadoop.yarn.server.api.protocolrecords.RemoveFromClusterNodeLabelsRequest)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.yarn.server.api.ResourceManagerAdministrationProtocol:replaceLabelsOnNode(org.apache.hadoop.yarn.server.api.protocolrecords.ReplaceLabelsOnNodeRequest)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.api.ResourceManagerAdministrationProtocol:replaceLabelsOnNode(org.apache.hadoop.yarn.server.api.protocolrecords.ReplaceLabelsOnNodeRequest)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.yarn.server.api.ResourceManagerAdministrationProtocol:checkForDecommissioningNodes(org.apache.hadoop.yarn.server.api.protocolrecords.CheckForDecommissioningNodesRequest)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.api.ResourceManagerAdministrationProtocol:checkForDecommissioningNodes(org.apache.hadoop.yarn.server.api.protocolrecords.CheckForDecommissioningNodesRequest)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.yarn.server.api.ResourceManagerAdministrationProtocol:refreshClusterMaxPriority(org.apache.hadoop.yarn.server.api.protocolrecords.RefreshClusterMaxPriorityRequest)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.api.ResourceManagerAdministrationProtocol:refreshClusterMaxPriority(org.apache.hadoop.yarn.server.api.protocolrecords.RefreshClusterMaxPriorityRequest)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.yarn.server.api.ResourceManagerAdministrationProtocol:mapAttributesToNodes(org.apache.hadoop.yarn.server.api.protocolrecords.NodesToAttributesMappingRequest)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.api.ResourceManagerAdministrationProtocol:mapAttributesToNodes(org.apache.hadoop.yarn.server.api.protocolrecords.NodesToAttributesMappingRequest)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.yarn.server.api.ApplicationTerminationContext:<init>(org.apache.hadoop.yarn.api.records.ApplicationId)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.api.ApplicationTerminationContext:<init>(org.apache.hadoop.yarn.api.records.ApplicationId)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.api.SCMAdminProtocol:runCleanerTask(org.apache.hadoop.yarn.server.api.protocolrecords.RunSharedCacheCleanerTaskRequest)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.api.SCMAdminProtocol:runCleanerTask(org.apache.hadoop.yarn.server.api.protocolrecords.RunSharedCacheCleanerTaskRequest)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.api.ContainerTerminationContext:<init>(java.lang.String,org.apache.hadoop.yarn.api.records.ContainerId,org.apache.hadoop.yarn.api.records.Resource)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.api.ContainerTerminationContext:<init>(java.lang.String,org.apache.hadoop.yarn.api.records.ContainerId,org.apache.hadoop.yarn.api.records.Resource)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.api.ContainerTerminationContext:<init>(java.lang.String,org.apache.hadoop.yarn.api.records.ContainerId,org.apache.hadoop.yarn.api.records.Resource,org.apache.hadoop.yarn.server.api.ContainerType)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.api.ContainerTerminationContext:<init>(java.lang.String,org.apache.hadoop.yarn.api.records.ContainerId,org.apache.hadoop.yarn.api.records.Resource,org.apache.hadoop.yarn.server.api.ContainerType)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.api.ContainerInitializationContext:<init>(java.lang.String,org.apache.hadoop.yarn.api.records.ContainerId,org.apache.hadoop.yarn.api.records.Resource)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.api.ContainerInitializationContext:<init>(java.lang.String,org.apache.hadoop.yarn.api.records.ContainerId,org.apache.hadoop.yarn.api.records.Resource)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.api.ContainerInitializationContext:<init>(java.lang.String,org.apache.hadoop.yarn.api.records.ContainerId,org.apache.hadoop.yarn.api.records.Resource,org.apache.hadoop.yarn.server.api.ContainerType)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.api.ContainerInitializationContext:<init>(java.lang.String,org.apache.hadoop.yarn.api.records.ContainerId,org.apache.hadoop.yarn.api.records.Resource,org.apache.hadoop.yarn.server.api.ContainerType)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.api.ContainerLogContext:<init>(org.apache.hadoop.yarn.api.records.ContainerId,org.apache.hadoop.yarn.server.api.ContainerType,int)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.api.ContainerLogContext:<init>(org.apache.hadoop.yarn.api.records.ContainerId,org.apache.hadoop.yarn.server.api.ContainerType,int)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.api.ApplicationInitializationContext:<init>(java.lang.String,org.apache.hadoop.yarn.api.records.ApplicationId,java.nio.ByteBuffer)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.api.ApplicationInitializationContext:<init>(java.lang.String,org.apache.hadoop.yarn.api.records.ApplicationId,java.nio.ByteBuffer)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.util.resource.ResourceUtils:validateNameOfResourceNameAndThrowException(java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.util.resource.ResourceUtils:initializeResourcesMap(org.apache.hadoop.conf.Configuration)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.util.resource.ResourceUtils:initializeResourcesFromResourceInformationMap(java.util.Map)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.util.resource.ResourceUtils:resetResourceTypes()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.util.resource.ResourceUtils:resetResourceTypes(org.apache.hadoop.conf.Configuration)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.util.resource.ResourceUtils:resetNodeResources()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.util.resource.ResourceUtils:createResourceWithSameValue(long)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.util.resource.ResourceUtils:createResourceWithSameValue(long)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.util.resource.ResourceUtils:createResourceFromString(java.lang.String,java.util.List)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.util.resource.ResourceUtils:createResourceFromString(java.lang.String,java.util.List)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.appcatalog.controller.AppDetailsController:getDetails(java.lang.String)	javax.ws.rs.Path	value	config/{id}
org.apache.hadoop.yarn.appcatalog.controller.AppDetailsController:getDetails(java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.yarn.appcatalog.controller.AppDetailsController:getDetails(java.lang.String)	javax.ws.rs.Produces	value	{application/json}
org.apache.hadoop.yarn.appcatalog.controller.AppDetailsController:getStatus(java.lang.String)	javax.ws.rs.Path	value	status/{id}
org.apache.hadoop.yarn.appcatalog.controller.AppDetailsController:getStatus(java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.yarn.appcatalog.controller.AppDetailsController:getStatus(java.lang.String)	javax.ws.rs.Produces	value	{application/json}
org.apache.hadoop.yarn.appcatalog.controller.AppDetailsController:stopApp(java.lang.String)	javax.ws.rs.Path	value	stop/{id}
org.apache.hadoop.yarn.appcatalog.controller.AppDetailsController:stopApp(java.lang.String)	javax.ws.rs.POST
org.apache.hadoop.yarn.appcatalog.controller.AppDetailsController:stopApp(java.lang.String)	javax.ws.rs.Produces	value	{application/json}
org.apache.hadoop.yarn.appcatalog.controller.AppDetailsController:restartApp(java.lang.String)	javax.ws.rs.Path	value	restart/{id}
org.apache.hadoop.yarn.appcatalog.controller.AppDetailsController:restartApp(java.lang.String)	javax.ws.rs.POST
org.apache.hadoop.yarn.appcatalog.controller.AppDetailsController:restartApp(java.lang.String)	javax.ws.rs.Produces	value	{application/json}
org.apache.hadoop.yarn.appcatalog.controller.AppDetailsController:upgradeApp(java.lang.String,org.apache.hadoop.yarn.service.api.records.Service)	javax.ws.rs.Path	value	upgrade/{id}
org.apache.hadoop.yarn.appcatalog.controller.AppDetailsController:upgradeApp(java.lang.String,org.apache.hadoop.yarn.service.api.records.Service)	javax.ws.rs.PUT
org.apache.hadoop.yarn.appcatalog.controller.AppDetailsController:upgradeApp(java.lang.String,org.apache.hadoop.yarn.service.api.records.Service)	javax.ws.rs.Consumes	value	{application/json}
org.apache.hadoop.yarn.appcatalog.controller.AppDetailsController:upgradeApp(java.lang.String,org.apache.hadoop.yarn.service.api.records.Service)	javax.ws.rs.Produces	value	{application/json}
org.apache.hadoop.yarn.appcatalog.controller.AppStoreController:get()	javax.ws.rs.GET
org.apache.hadoop.yarn.appcatalog.controller.AppStoreController:get()	javax.ws.rs.Path	value	recommended
org.apache.hadoop.yarn.appcatalog.controller.AppStoreController:get()	javax.ws.rs.Produces	value	{application/json}
org.apache.hadoop.yarn.appcatalog.controller.AppStoreController:search(java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.yarn.appcatalog.controller.AppStoreController:search(java.lang.String)	javax.ws.rs.Path	value	search
org.apache.hadoop.yarn.appcatalog.controller.AppStoreController:search(java.lang.String)	javax.ws.rs.Produces	value	{application/json}
org.apache.hadoop.yarn.appcatalog.controller.AppStoreController:get(java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.yarn.appcatalog.controller.AppStoreController:get(java.lang.String)	javax.ws.rs.Path	value	get/{id}
org.apache.hadoop.yarn.appcatalog.controller.AppStoreController:get(java.lang.String)	javax.ws.rs.Produces	value	{application/json}
org.apache.hadoop.yarn.appcatalog.controller.AppStoreController:register(org.apache.hadoop.yarn.appcatalog.model.Application)	javax.ws.rs.POST
org.apache.hadoop.yarn.appcatalog.controller.AppStoreController:register(org.apache.hadoop.yarn.appcatalog.model.Application)	javax.ws.rs.Path	value	register
org.apache.hadoop.yarn.appcatalog.controller.AppStoreController:register(org.apache.hadoop.yarn.appcatalog.model.Application)	javax.ws.rs.Produces	value	{application/json}
org.apache.hadoop.yarn.appcatalog.controller.AppListController:getList()	javax.ws.rs.GET
org.apache.hadoop.yarn.appcatalog.controller.AppListController:getList()	javax.ws.rs.Produces	value	{application/json}
org.apache.hadoop.yarn.appcatalog.controller.AppListController:delete(java.lang.String,java.lang.String)	javax.ws.rs.DELETE
org.apache.hadoop.yarn.appcatalog.controller.AppListController:delete(java.lang.String,java.lang.String)	javax.ws.rs.Path	value	{id}/{name}
org.apache.hadoop.yarn.appcatalog.controller.AppListController:delete(java.lang.String,java.lang.String)	javax.ws.rs.Produces	value	{application/json}
org.apache.hadoop.yarn.appcatalog.controller.AppListController:deploy(java.lang.String,org.apache.hadoop.yarn.service.api.records.Service)	javax.ws.rs.POST
org.apache.hadoop.yarn.appcatalog.controller.AppListController:deploy(java.lang.String,org.apache.hadoop.yarn.service.api.records.Service)	javax.ws.rs.Path	value	{id}
org.apache.hadoop.yarn.appcatalog.controller.AppListController:deploy(java.lang.String,org.apache.hadoop.yarn.service.api.records.Service)	javax.ws.rs.Consumes	value	{application/json}
org.apache.hadoop.yarn.appcatalog.controller.AppListController:deploy(java.lang.String,org.apache.hadoop.yarn.service.api.records.Service)	javax.ws.rs.Produces	value	{application/json}
org.apache.hadoop.yarn.appcatalog.model.Application:getOrganization()	com.fasterxml.jackson.annotation.JsonProperty	value	organization
org.apache.hadoop.yarn.appcatalog.model.Application:getDescription()	com.fasterxml.jackson.annotation.JsonProperty	value	description
org.apache.hadoop.yarn.appcatalog.model.Application:getIcon()	com.fasterxml.jackson.annotation.JsonProperty	value	icon
org.apache.hadoop.yarn.applications.distributedshell.ApplicationMaster$NMCallbackHandler:onIncreaseContainerResourceError(org.apache.hadoop.yarn.api.records.ContainerId,java.lang.Throwable)	java.lang.Deprecated
org.apache.hadoop.yarn.applications.distributedshell.ApplicationMaster$NMCallbackHandler:onContainerResourceIncreased(org.apache.hadoop.yarn.api.records.ContainerId,org.apache.hadoop.yarn.api.records.Resource)	java.lang.Deprecated
org.apache.hadoop.yarn.applications.distributedshell.ApplicationMaster:startTimelineClient(org.apache.hadoop.conf.Configuration)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.applications.distributedshell.ApplicationMaster:createNMCallbackHandler()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.applications.distributedshell.ApplicationMaster:finish()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.applications.distributedshell.ApplicationMaster:publishContainerEndEvent(org.apache.hadoop.yarn.client.api.TimelineClient,org.apache.hadoop.yarn.api.records.ContainerStatus,java.lang.String,org.apache.hadoop.security.UserGroupInformation)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.applications.distributedshell.ApplicationMaster:setAmRMClient(org.apache.hadoop.yarn.client.api.async.AMRMClientAsync)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.applications.distributedshell.ApplicationMaster:getNumCompletedContainers()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.applications.distributedshell.ApplicationMaster:getDone()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.applications.distributedshell.ApplicationMaster:createLaunchContainerThread(org.apache.hadoop.yarn.api.records.Container,java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.applications.distributedshell.Client:specifyLogAggregationContext(org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.applications.distributedshell.Client:getAppId()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.applications.distributedshell.Client:sendStopSignal()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.service.client.SystemServiceManagerImpl:getIgnoredUserServices()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.service.client.SystemServiceManagerImpl:getSyncUserServices()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.service.client.SystemServiceManagerImpl:getBadFileNameExtensionSkipCounter()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.service.client.SystemServiceManagerImpl:getBadDirSkipCounter()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.service.webapp.ApiServer:<init>(org.apache.hadoop.conf.Configuration)	com.google.inject.Inject
org.apache.hadoop.yarn.service.webapp.ApiServer:getVersion()	javax.ws.rs.GET
org.apache.hadoop.yarn.service.webapp.ApiServer:getVersion()	javax.ws.rs.Path	value	/services/version
org.apache.hadoop.yarn.service.webapp.ApiServer:getVersion()	javax.ws.rs.Consumes	value	{application/json}
org.apache.hadoop.yarn.service.webapp.ApiServer:getVersion()	javax.ws.rs.Produces	value	{application/json;charset=utf-8}
org.apache.hadoop.yarn.service.webapp.ApiServer:createService(javax.servlet.http.HttpServletRequest,org.apache.hadoop.yarn.service.api.records.Service)	javax.ws.rs.POST
org.apache.hadoop.yarn.service.webapp.ApiServer:createService(javax.servlet.http.HttpServletRequest,org.apache.hadoop.yarn.service.api.records.Service)	javax.ws.rs.Path	value	/services
org.apache.hadoop.yarn.service.webapp.ApiServer:createService(javax.servlet.http.HttpServletRequest,org.apache.hadoop.yarn.service.api.records.Service)	javax.ws.rs.Consumes	value	{application/json}
org.apache.hadoop.yarn.service.webapp.ApiServer:createService(javax.servlet.http.HttpServletRequest,org.apache.hadoop.yarn.service.api.records.Service)	javax.ws.rs.Produces	value	{application/json;charset=utf-8}
org.apache.hadoop.yarn.service.webapp.ApiServer:getService(javax.servlet.http.HttpServletRequest,java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.yarn.service.webapp.ApiServer:getService(javax.servlet.http.HttpServletRequest,java.lang.String)	javax.ws.rs.Path	value	/services/{service_name}
org.apache.hadoop.yarn.service.webapp.ApiServer:getService(javax.servlet.http.HttpServletRequest,java.lang.String)	javax.ws.rs.Consumes	value	{application/json}
org.apache.hadoop.yarn.service.webapp.ApiServer:getService(javax.servlet.http.HttpServletRequest,java.lang.String)	javax.ws.rs.Produces	value	{application/json;charset=utf-8}
org.apache.hadoop.yarn.service.webapp.ApiServer:deleteService(javax.servlet.http.HttpServletRequest,java.lang.String)	javax.ws.rs.DELETE
org.apache.hadoop.yarn.service.webapp.ApiServer:deleteService(javax.servlet.http.HttpServletRequest,java.lang.String)	javax.ws.rs.Path	value	/services/{service_name}
org.apache.hadoop.yarn.service.webapp.ApiServer:deleteService(javax.servlet.http.HttpServletRequest,java.lang.String)	javax.ws.rs.Consumes	value	{application/json}
org.apache.hadoop.yarn.service.webapp.ApiServer:deleteService(javax.servlet.http.HttpServletRequest,java.lang.String)	javax.ws.rs.Produces	value	{application/json;charset=utf-8}
org.apache.hadoop.yarn.service.webapp.ApiServer:updateComponents(javax.servlet.http.HttpServletRequest,java.lang.String,java.util.List)	javax.ws.rs.PUT
org.apache.hadoop.yarn.service.webapp.ApiServer:updateComponents(javax.servlet.http.HttpServletRequest,java.lang.String,java.util.List)	javax.ws.rs.Path	value	/services/{service_name}/components
org.apache.hadoop.yarn.service.webapp.ApiServer:updateComponents(javax.servlet.http.HttpServletRequest,java.lang.String,java.util.List)	javax.ws.rs.Consumes	value	{application/json}
org.apache.hadoop.yarn.service.webapp.ApiServer:updateComponents(javax.servlet.http.HttpServletRequest,java.lang.String,java.util.List)	javax.ws.rs.Produces	value	{application/json;charset=utf-8,text/plain}
org.apache.hadoop.yarn.service.webapp.ApiServer:updateComponent(javax.servlet.http.HttpServletRequest,java.lang.String,java.lang.String,org.apache.hadoop.yarn.service.api.records.Component)	javax.ws.rs.PUT
org.apache.hadoop.yarn.service.webapp.ApiServer:updateComponent(javax.servlet.http.HttpServletRequest,java.lang.String,java.lang.String,org.apache.hadoop.yarn.service.api.records.Component)	javax.ws.rs.Path	value	/services/{service_name}/components/{component_name}
org.apache.hadoop.yarn.service.webapp.ApiServer:updateComponent(javax.servlet.http.HttpServletRequest,java.lang.String,java.lang.String,org.apache.hadoop.yarn.service.api.records.Component)	javax.ws.rs.Consumes	value	{application/json}
org.apache.hadoop.yarn.service.webapp.ApiServer:updateComponent(javax.servlet.http.HttpServletRequest,java.lang.String,java.lang.String,org.apache.hadoop.yarn.service.api.records.Component)	javax.ws.rs.Produces	value	{application/json;charset=utf-8,text/plain}
org.apache.hadoop.yarn.service.webapp.ApiServer:updateService(javax.servlet.http.HttpServletRequest,java.lang.String,org.apache.hadoop.yarn.service.api.records.Service)	javax.ws.rs.PUT
org.apache.hadoop.yarn.service.webapp.ApiServer:updateService(javax.servlet.http.HttpServletRequest,java.lang.String,org.apache.hadoop.yarn.service.api.records.Service)	javax.ws.rs.Path	value	/services/{service_name}
org.apache.hadoop.yarn.service.webapp.ApiServer:updateService(javax.servlet.http.HttpServletRequest,java.lang.String,org.apache.hadoop.yarn.service.api.records.Service)	javax.ws.rs.Consumes	value	{application/json}
org.apache.hadoop.yarn.service.webapp.ApiServer:updateService(javax.servlet.http.HttpServletRequest,java.lang.String,org.apache.hadoop.yarn.service.api.records.Service)	javax.ws.rs.Produces	value	{application/json;charset=utf-8}
org.apache.hadoop.yarn.service.webapp.ApiServer:updateComponentInstance(javax.servlet.http.HttpServletRequest,java.lang.String,java.lang.String,java.lang.String,org.apache.hadoop.yarn.service.api.records.Container)	javax.ws.rs.PUT
org.apache.hadoop.yarn.service.webapp.ApiServer:updateComponentInstance(javax.servlet.http.HttpServletRequest,java.lang.String,java.lang.String,java.lang.String,org.apache.hadoop.yarn.service.api.records.Container)	javax.ws.rs.Path	value	/services/{service_name}/components/{component_name}/component-instances/{component_instance_name}
org.apache.hadoop.yarn.service.webapp.ApiServer:updateComponentInstance(javax.servlet.http.HttpServletRequest,java.lang.String,java.lang.String,java.lang.String,org.apache.hadoop.yarn.service.api.records.Container)	javax.ws.rs.Consumes	value	{application/json}
org.apache.hadoop.yarn.service.webapp.ApiServer:updateComponentInstance(javax.servlet.http.HttpServletRequest,java.lang.String,java.lang.String,java.lang.String,org.apache.hadoop.yarn.service.api.records.Container)	javax.ws.rs.Produces	value	{application/json;charset=utf-8,text/plain}
org.apache.hadoop.yarn.service.webapp.ApiServer:updateComponentInstances(javax.servlet.http.HttpServletRequest,java.lang.String,java.util.List)	javax.ws.rs.PUT
org.apache.hadoop.yarn.service.webapp.ApiServer:updateComponentInstances(javax.servlet.http.HttpServletRequest,java.lang.String,java.util.List)	javax.ws.rs.Path	value	/services/{service_name}/component-instances
org.apache.hadoop.yarn.service.webapp.ApiServer:updateComponentInstances(javax.servlet.http.HttpServletRequest,java.lang.String,java.util.List)	javax.ws.rs.Consumes	value	{application/json}
org.apache.hadoop.yarn.service.webapp.ApiServer:updateComponentInstances(javax.servlet.http.HttpServletRequest,java.lang.String,java.util.List)	javax.ws.rs.Produces	value	{application/json;charset=utf-8,text/plain}
org.apache.hadoop.yarn.service.webapp.ApiServer:getComponentInstances(javax.servlet.http.HttpServletRequest,java.lang.String,java.util.List,java.lang.String,java.util.List)	javax.ws.rs.GET
org.apache.hadoop.yarn.service.webapp.ApiServer:getComponentInstances(javax.servlet.http.HttpServletRequest,java.lang.String,java.util.List,java.lang.String,java.util.List)	javax.ws.rs.Path	value	/services/{service_name}/component-instances
org.apache.hadoop.yarn.service.webapp.ApiServer:getComponentInstances(javax.servlet.http.HttpServletRequest,java.lang.String,java.util.List,java.lang.String,java.util.List)	javax.ws.rs.Produces	value	{application/json;charset=utf-8}
org.apache.hadoop.yarn.service.provider.defaultImpl.DefaultClientProvider:validateConfigFile(org.apache.hadoop.yarn.service.api.records.ConfigFile,java.lang.String,org.apache.hadoop.fs.FileSystem)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.service.api.records.Artifact:getId()	io.swagger.annotations.ApiModelProperty	example	null
org.apache.hadoop.yarn.service.api.records.Artifact:getId()	io.swagger.annotations.ApiModelProperty	required	true
org.apache.hadoop.yarn.service.api.records.Artifact:getId()	io.swagger.annotations.ApiModelProperty	value	Artifact id. Examples are package location uri for tarball based services, image name for docker, etc.
org.apache.hadoop.yarn.service.api.records.Artifact:getId()	com.fasterxml.jackson.annotation.JsonProperty	value	id
org.apache.hadoop.yarn.service.api.records.Artifact:getType()	io.swagger.annotations.ApiModelProperty	example	null
org.apache.hadoop.yarn.service.api.records.Artifact:getType()	io.swagger.annotations.ApiModelProperty	value	Artifact type, like docker, tarball, etc. (optional).
org.apache.hadoop.yarn.service.api.records.Artifact:getType()	com.fasterxml.jackson.annotation.JsonProperty	value	type
org.apache.hadoop.yarn.service.api.records.Artifact:getUri()	io.swagger.annotations.ApiModelProperty	example	null
org.apache.hadoop.yarn.service.api.records.Artifact:getUri()	io.swagger.annotations.ApiModelProperty	value	Artifact location to support multiple artifact stores (optional).
org.apache.hadoop.yarn.service.api.records.Artifact:getUri()	com.fasterxml.jackson.annotation.JsonProperty	value	uri
org.apache.hadoop.yarn.service.api.records.PlacementConstraint:getName()	io.swagger.annotations.ApiModelProperty	example	C1
org.apache.hadoop.yarn.service.api.records.PlacementConstraint:getName()	io.swagger.annotations.ApiModelProperty	required	true
org.apache.hadoop.yarn.service.api.records.PlacementConstraint:getName()	com.fasterxml.jackson.annotation.JsonProperty	value	name
org.apache.hadoop.yarn.service.api.records.PlacementConstraint:getType()	io.swagger.annotations.ApiModelProperty	example	null
org.apache.hadoop.yarn.service.api.records.PlacementConstraint:getType()	io.swagger.annotations.ApiModelProperty	required	true
org.apache.hadoop.yarn.service.api.records.PlacementConstraint:getType()	com.fasterxml.jackson.annotation.JsonProperty	value	type
org.apache.hadoop.yarn.service.api.records.PlacementConstraint:getScope()	io.swagger.annotations.ApiModelProperty	example	null
org.apache.hadoop.yarn.service.api.records.PlacementConstraint:getScope()	io.swagger.annotations.ApiModelProperty	required	true
org.apache.hadoop.yarn.service.api.records.PlacementConstraint:getScope()	com.fasterxml.jackson.annotation.JsonProperty	value	scope
org.apache.hadoop.yarn.service.api.records.PlacementConstraint:getTargetTags()	io.swagger.annotations.ApiModelProperty	example	["hbase-regionserver"]
org.apache.hadoop.yarn.service.api.records.PlacementConstraint:getNodeAttributes()	io.swagger.annotations.ApiModelProperty	example	"JavaVersion":["1.7", "1.8"]
org.apache.hadoop.yarn.service.api.records.PlacementConstraint:getNodePartitions()	io.swagger.annotations.ApiModelProperty	example	["gpu", "fast_disk"]
org.apache.hadoop.yarn.service.api.records.PlacementConstraint:getMinCardinality()	io.swagger.annotations.ApiModelProperty	example	2
org.apache.hadoop.yarn.service.api.records.PlacementConstraint:getMaxCardinality()	io.swagger.annotations.ApiModelProperty	example	3
org.apache.hadoop.yarn.service.api.records.ResourceInformation:getTags()	io.swagger.annotations.ApiModelProperty	value	
org.apache.hadoop.yarn.service.api.records.ResourceInformation:getTags()	com.fasterxml.jackson.annotation.JsonProperty	value	tags
org.apache.hadoop.yarn.service.api.records.ResourceInformation:getAttributes()	io.swagger.annotations.ApiModelProperty	value	
org.apache.hadoop.yarn.service.api.records.ResourceInformation:getAttributes()	com.fasterxml.jackson.annotation.JsonProperty	value	attributes
org.apache.hadoop.yarn.service.api.records.ResourceInformation:getValue()	io.swagger.annotations.ApiModelProperty	value	Integer value of the resource.
org.apache.hadoop.yarn.service.api.records.ResourceInformation:getValue()	com.fasterxml.jackson.annotation.JsonProperty	value	value
org.apache.hadoop.yarn.service.api.records.ResourceInformation:getUnit()	io.swagger.annotations.ApiModelProperty	value	
org.apache.hadoop.yarn.service.api.records.ResourceInformation:getUnit()	com.fasterxml.jackson.annotation.JsonProperty	value	unit
org.apache.hadoop.yarn.service.api.records.PlacementScope:toString()	com.fasterxml.jackson.annotation.JsonValue
org.apache.hadoop.yarn.service.api.records.Artifact$TypeEnum:toString()	com.fasterxml.jackson.annotation.JsonValue
org.apache.hadoop.yarn.service.api.records.ConfigFile:getType()	io.swagger.annotations.ApiModelProperty	example	null
org.apache.hadoop.yarn.service.api.records.ConfigFile:getType()	io.swagger.annotations.ApiModelProperty	value	Config file in the standard format like xml, properties, json, yaml, template.
org.apache.hadoop.yarn.service.api.records.ConfigFile:getType()	com.fasterxml.jackson.annotation.JsonProperty	value	type
org.apache.hadoop.yarn.service.api.records.ConfigFile:getDestFile()	io.swagger.annotations.ApiModelProperty	example	null
org.apache.hadoop.yarn.service.api.records.ConfigFile:getDestFile()	io.swagger.annotations.ApiModelProperty	value	The absolute path that this configuration file should be mounted as, in the service container.
org.apache.hadoop.yarn.service.api.records.ConfigFile:getDestFile()	com.fasterxml.jackson.annotation.JsonProperty	value	dest_file
org.apache.hadoop.yarn.service.api.records.ConfigFile:setDestFile(java.lang.String)	javax.xml.bind.annotation.XmlElement	name	dest_file
org.apache.hadoop.yarn.service.api.records.ConfigFile:getSrcFile()	io.swagger.annotations.ApiModelProperty	example	null
org.apache.hadoop.yarn.service.api.records.ConfigFile:getSrcFile()	io.swagger.annotations.ApiModelProperty	value	This provides the source location of the configuration file, the content of which is dumped to dest_file post property substitutions, in the format as specified in type. Typically the src_file would point to a source controlled network accessible file maintained by tools like puppet, chef, or hdfs etc. Currently, only hdfs is supported.
org.apache.hadoop.yarn.service.api.records.ConfigFile:getSrcFile()	com.fasterxml.jackson.annotation.JsonProperty	value	src_file
org.apache.hadoop.yarn.service.api.records.ConfigFile:setSrcFile(java.lang.String)	javax.xml.bind.annotation.XmlElement	name	src_file
org.apache.hadoop.yarn.service.api.records.ConfigFile:getVisibility()	io.swagger.annotations.ApiModelProperty	example	null
org.apache.hadoop.yarn.service.api.records.ConfigFile:getVisibility()	io.swagger.annotations.ApiModelProperty	value	Visibility of the Config file
org.apache.hadoop.yarn.service.api.records.ConfigFile:getVisibility()	com.fasterxml.jackson.annotation.JsonProperty	value	visibility
org.apache.hadoop.yarn.service.api.records.ConfigFile:setVisibility(org.apache.hadoop.yarn.api.records.LocalResourceVisibility)	javax.xml.bind.annotation.XmlElement	name	visibility
org.apache.hadoop.yarn.service.api.records.ConfigFile:setVisibility(org.apache.hadoop.yarn.api.records.LocalResourceVisibility)	javax.xml.bind.annotation.XmlElement	defaultValue	APPLICATION
org.apache.hadoop.yarn.service.api.records.ConfigFile:getProperties()	io.swagger.annotations.ApiModelProperty	example	null
org.apache.hadoop.yarn.service.api.records.ConfigFile:getProperties()	io.swagger.annotations.ApiModelProperty	value	A blob of key value pairs that will be dumped in the dest_file in the format as specified in type. If src_file is specified, src_file content are dumped in the dest_file and these properties will overwrite, if any, existing properties in src_file or be added as new properties in src_file.
org.apache.hadoop.yarn.service.api.records.ConfigFile:getProperties()	com.fasterxml.jackson.annotation.JsonProperty	value	properties
org.apache.hadoop.yarn.service.api.records.ServiceStatus:getDiagnostics()	io.swagger.annotations.ApiModelProperty	example	null
org.apache.hadoop.yarn.service.api.records.ServiceStatus:getDiagnostics()	io.swagger.annotations.ApiModelProperty	value	Diagnostic information (if any) for the reason of the current state of the service. It typically has a non-null value, if the service is in a non-running state.
org.apache.hadoop.yarn.service.api.records.ServiceStatus:getDiagnostics()	com.fasterxml.jackson.annotation.JsonProperty	value	diagnostics
org.apache.hadoop.yarn.service.api.records.ServiceStatus:getState()	io.swagger.annotations.ApiModelProperty	example	null
org.apache.hadoop.yarn.service.api.records.ServiceStatus:getState()	io.swagger.annotations.ApiModelProperty	value	Service state.
org.apache.hadoop.yarn.service.api.records.ServiceStatus:getState()	com.fasterxml.jackson.annotation.JsonProperty	value	state
org.apache.hadoop.yarn.service.api.records.ServiceStatus:getCode()	io.swagger.annotations.ApiModelProperty	example	null
org.apache.hadoop.yarn.service.api.records.ServiceStatus:getCode()	io.swagger.annotations.ApiModelProperty	value	An error code specific to a scenario which service owners should be able to use to understand the failure in addition to the diagnostic information.
org.apache.hadoop.yarn.service.api.records.ServiceStatus:getCode()	com.fasterxml.jackson.annotation.JsonProperty	value	code
org.apache.hadoop.yarn.service.api.records.Container:getId()	io.swagger.annotations.ApiModelProperty	example	null
org.apache.hadoop.yarn.service.api.records.Container:getId()	io.swagger.annotations.ApiModelProperty	value	Unique container id of a running service, e.g. container_e3751_1458061340047_0008_01_000002.
org.apache.hadoop.yarn.service.api.records.Container:getId()	com.fasterxml.jackson.annotation.JsonProperty	value	id
org.apache.hadoop.yarn.service.api.records.Container:getLaunchTime()	io.swagger.annotations.ApiModelProperty	example	null
org.apache.hadoop.yarn.service.api.records.Container:getLaunchTime()	io.swagger.annotations.ApiModelProperty	value	The time when the container was created, e.g. 2016-03-16T01:01:49.000Z. This will most likely be different from cluster launch time.
org.apache.hadoop.yarn.service.api.records.Container:getLaunchTime()	com.fasterxml.jackson.annotation.JsonProperty	value	launch_time
org.apache.hadoop.yarn.service.api.records.Container:setLaunchTime(java.util.Date)	javax.xml.bind.annotation.XmlElement	name	launch_time
org.apache.hadoop.yarn.service.api.records.Container:getIp()	io.swagger.annotations.ApiModelProperty	example	null
org.apache.hadoop.yarn.service.api.records.Container:getIp()	io.swagger.annotations.ApiModelProperty	value	IP address of a running container, e.g. 172.31.42.141. The IP address and hostname attribute values are dependent on the cluster/docker network setup as per YARN-4007.
org.apache.hadoop.yarn.service.api.records.Container:getIp()	com.fasterxml.jackson.annotation.JsonProperty	value	ip
org.apache.hadoop.yarn.service.api.records.Container:getHostname()	io.swagger.annotations.ApiModelProperty	example	null
org.apache.hadoop.yarn.service.api.records.Container:getHostname()	io.swagger.annotations.ApiModelProperty	value	Fully qualified hostname of a running container, e.g. ctr-e3751-1458061340047-0008-01-000002.examplestg.site. The IP address and hostname attribute values are dependent on the cluster/docker network setup as per YARN-4007.
org.apache.hadoop.yarn.service.api.records.Container:getHostname()	com.fasterxml.jackson.annotation.JsonProperty	value	hostname
org.apache.hadoop.yarn.service.api.records.Container:getBareHost()	io.swagger.annotations.ApiModelProperty	example	null
org.apache.hadoop.yarn.service.api.records.Container:getBareHost()	io.swagger.annotations.ApiModelProperty	value	The bare node or host in which the container is running, e.g. cn008.example.com.
org.apache.hadoop.yarn.service.api.records.Container:getBareHost()	com.fasterxml.jackson.annotation.JsonProperty	value	bare_host
org.apache.hadoop.yarn.service.api.records.Container:setBareHost(java.lang.String)	javax.xml.bind.annotation.XmlElement	name	bare_host
org.apache.hadoop.yarn.service.api.records.Container:getState()	io.swagger.annotations.ApiModelProperty	example	null
org.apache.hadoop.yarn.service.api.records.Container:getState()	io.swagger.annotations.ApiModelProperty	value	State of the container of an service.
org.apache.hadoop.yarn.service.api.records.Container:getState()	com.fasterxml.jackson.annotation.JsonProperty	value	state
org.apache.hadoop.yarn.service.api.records.Container:getComponentInstanceName()	io.swagger.annotations.ApiModelProperty	example	null
org.apache.hadoop.yarn.service.api.records.Container:getComponentInstanceName()	io.swagger.annotations.ApiModelProperty	value	Name of the component instance that this container instance belongs to.
org.apache.hadoop.yarn.service.api.records.Container:getComponentInstanceName()	com.fasterxml.jackson.annotation.JsonProperty	value	component_instance_name
org.apache.hadoop.yarn.service.api.records.Container:setComponentInstanceName(java.lang.String)	javax.xml.bind.annotation.XmlElement	name	component_instance_name
org.apache.hadoop.yarn.service.api.records.Container:getResource()	io.swagger.annotations.ApiModelProperty	example	null
org.apache.hadoop.yarn.service.api.records.Container:getResource()	io.swagger.annotations.ApiModelProperty	value	Resource used for this container.
org.apache.hadoop.yarn.service.api.records.Container:getResource()	com.fasterxml.jackson.annotation.JsonProperty	value	resource
org.apache.hadoop.yarn.service.api.records.Container:getArtifact()	io.swagger.annotations.ApiModelProperty	example	null
org.apache.hadoop.yarn.service.api.records.Container:getArtifact()	io.swagger.annotations.ApiModelProperty	value	Artifact used for this container.
org.apache.hadoop.yarn.service.api.records.Container:getArtifact()	com.fasterxml.jackson.annotation.JsonProperty	value	artifact
org.apache.hadoop.yarn.service.api.records.Container:getPrivilegedContainer()	io.swagger.annotations.ApiModelProperty	example	null
org.apache.hadoop.yarn.service.api.records.Container:getPrivilegedContainer()	io.swagger.annotations.ApiModelProperty	value	Container running in privileged mode or not.
org.apache.hadoop.yarn.service.api.records.Container:getPrivilegedContainer()	com.fasterxml.jackson.annotation.JsonProperty	value	privileged_container
org.apache.hadoop.yarn.service.api.records.Container:getExposedPorts()	io.swagger.annotations.ApiModelProperty	example	null
org.apache.hadoop.yarn.service.api.records.Container:getExposedPorts()	io.swagger.annotations.ApiModelProperty	value	Ports exposed for this container.
org.apache.hadoop.yarn.service.api.records.Container:getExposedPorts()	com.fasterxml.jackson.annotation.JsonProperty	value	exposed_ports
org.apache.hadoop.yarn.service.api.records.Container:getLocalizationStatuses()	io.swagger.annotations.ApiModelProperty	example	null
org.apache.hadoop.yarn.service.api.records.Container:getLocalizationStatuses()	io.swagger.annotations.ApiModelProperty	value	Localization statuses of a container.
org.apache.hadoop.yarn.service.api.records.Container:getLocalizationStatuses()	com.fasterxml.jackson.annotation.JsonProperty	value	localization_statuses
org.apache.hadoop.yarn.service.api.records.Container:setLocalizationStatuses(java.util.List)	javax.xml.bind.annotation.XmlElement	name	localization_statuses
org.apache.hadoop.yarn.service.api.records.ReadinessCheck$TypeEnum:toString()	com.fasterxml.jackson.annotation.JsonValue
org.apache.hadoop.yarn.service.api.records.Service:getName()	io.swagger.annotations.ApiModelProperty	example	null
org.apache.hadoop.yarn.service.api.records.Service:getName()	io.swagger.annotations.ApiModelProperty	required	true
org.apache.hadoop.yarn.service.api.records.Service:getName()	io.swagger.annotations.ApiModelProperty	value	A unique service name.
org.apache.hadoop.yarn.service.api.records.Service:getName()	com.fasterxml.jackson.annotation.JsonProperty	value	name
org.apache.hadoop.yarn.service.api.records.Service:getId()	io.swagger.annotations.ApiModelProperty	example	null
org.apache.hadoop.yarn.service.api.records.Service:getId()	io.swagger.annotations.ApiModelProperty	value	A unique service id.
org.apache.hadoop.yarn.service.api.records.Service:getId()	com.fasterxml.jackson.annotation.JsonProperty	value	id
org.apache.hadoop.yarn.service.api.records.Service:getVersion()	io.swagger.annotations.ApiModelProperty	example	null
org.apache.hadoop.yarn.service.api.records.Service:getVersion()	io.swagger.annotations.ApiModelProperty	required	true
org.apache.hadoop.yarn.service.api.records.Service:getVersion()	io.swagger.annotations.ApiModelProperty	value	Version of the service.
org.apache.hadoop.yarn.service.api.records.Service:getVersion()	com.fasterxml.jackson.annotation.JsonProperty	value	version
org.apache.hadoop.yarn.service.api.records.Service:getDescription()	io.swagger.annotations.ApiModelProperty	example	null
org.apache.hadoop.yarn.service.api.records.Service:getDescription()	io.swagger.annotations.ApiModelProperty	value	Description of the service.
org.apache.hadoop.yarn.service.api.records.Service:getDescription()	com.fasterxml.jackson.annotation.JsonProperty	value	description
org.apache.hadoop.yarn.service.api.records.Service:getArtifact()	io.swagger.annotations.ApiModelProperty	example	null
org.apache.hadoop.yarn.service.api.records.Service:getArtifact()	io.swagger.annotations.ApiModelProperty	value	Artifact of single-component services. Mandatory if components attribute is not specified.
org.apache.hadoop.yarn.service.api.records.Service:getArtifact()	com.fasterxml.jackson.annotation.JsonProperty	value	artifact
org.apache.hadoop.yarn.service.api.records.Service:getResource()	io.swagger.annotations.ApiModelProperty	example	null
org.apache.hadoop.yarn.service.api.records.Service:getResource()	io.swagger.annotations.ApiModelProperty	value	Resource of single-component services or the global default for multi-component services. Mandatory if it is a single-component service and if cpus and memory are not specified at the Service level.
org.apache.hadoop.yarn.service.api.records.Service:getResource()	com.fasterxml.jackson.annotation.JsonProperty	value	resource
org.apache.hadoop.yarn.service.api.records.Service:getLaunchTime()	io.swagger.annotations.ApiModelProperty	example	null
org.apache.hadoop.yarn.service.api.records.Service:getLaunchTime()	io.swagger.annotations.ApiModelProperty	value	The time when the service was created, e.g. 2016-03-16T01:01:49.000Z.
org.apache.hadoop.yarn.service.api.records.Service:getNumberOfRunningContainers()	io.swagger.annotations.ApiModelProperty	example	null
org.apache.hadoop.yarn.service.api.records.Service:getNumberOfRunningContainers()	io.swagger.annotations.ApiModelProperty	value	In get response this provides the total number of running containers for this service (across all components) at the time of request. Note, a subsequent request can return a different number as and when more containers get allocated until it reaches the total number of containers or if a flex request has been made between the two requests.
org.apache.hadoop.yarn.service.api.records.Service:getLifetime()	io.swagger.annotations.ApiModelProperty	example	null
org.apache.hadoop.yarn.service.api.records.Service:getLifetime()	io.swagger.annotations.ApiModelProperty	value	Life time (in seconds) of the service from the time it reaches the RUNNING_BUT_UNREADY state (after which it is automatically destroyed by YARN). For unlimited lifetime do not set a lifetime value.
org.apache.hadoop.yarn.service.api.records.Service:getLifetime()	com.fasterxml.jackson.annotation.JsonProperty	value	lifetime
org.apache.hadoop.yarn.service.api.records.Service:getComponents()	io.swagger.annotations.ApiModelProperty	example	null
org.apache.hadoop.yarn.service.api.records.Service:getComponents()	io.swagger.annotations.ApiModelProperty	value	Components of an service.
org.apache.hadoop.yarn.service.api.records.Service:getComponents()	com.fasterxml.jackson.annotation.JsonProperty	value	components
org.apache.hadoop.yarn.service.api.records.Service:getConfiguration()	io.swagger.annotations.ApiModelProperty	example	null
org.apache.hadoop.yarn.service.api.records.Service:getConfiguration()	io.swagger.annotations.ApiModelProperty	value	Config properties of an service. Configurations provided at the service/global level are available to all the components. Specific properties can be overridden at the component level.
org.apache.hadoop.yarn.service.api.records.Service:getConfiguration()	com.fasterxml.jackson.annotation.JsonProperty	value	configuration
org.apache.hadoop.yarn.service.api.records.Service:getState()	io.swagger.annotations.ApiModelProperty	example	null
org.apache.hadoop.yarn.service.api.records.Service:getState()	io.swagger.annotations.ApiModelProperty	value	State of the service. Specifying a value for this attribute for the POST payload raises a validation error. This attribute is available only in the GET response of a started service.
org.apache.hadoop.yarn.service.api.records.Service:getState()	com.fasterxml.jackson.annotation.JsonProperty	value	state
org.apache.hadoop.yarn.service.api.records.Service:getQuicklinks()	io.swagger.annotations.ApiModelProperty	example	null
org.apache.hadoop.yarn.service.api.records.Service:getQuicklinks()	io.swagger.annotations.ApiModelProperty	value	A blob of key-value pairs of quicklinks to be exported for an service.
org.apache.hadoop.yarn.service.api.records.Service:getQuicklinks()	com.fasterxml.jackson.annotation.JsonProperty	value	quicklinks
org.apache.hadoop.yarn.service.api.records.Service:getQueue()	io.swagger.annotations.ApiModelProperty	example	null
org.apache.hadoop.yarn.service.api.records.Service:getQueue()	io.swagger.annotations.ApiModelProperty	value	The YARN queue that this service should be submitted to.
org.apache.hadoop.yarn.service.api.records.Service:getQueue()	com.fasterxml.jackson.annotation.JsonProperty	value	queue
org.apache.hadoop.yarn.service.api.records.Service:getDependencies()	io.swagger.annotations.ApiModelProperty	example	null
org.apache.hadoop.yarn.service.api.records.Service:getDependencies()	io.swagger.annotations.ApiModelProperty	value	A list of dependent services.
org.apache.hadoop.yarn.service.api.records.Service:getDependencies()	javax.xml.bind.annotation.XmlElement	name	dependencies
org.apache.hadoop.yarn.service.api.records.Service:getDependencies()	com.fasterxml.jackson.annotation.JsonProperty	value	dependencies
org.apache.hadoop.yarn.service.api.records.Service:getKerberosPrincipal()	io.swagger.annotations.ApiModelProperty	value	The Kerberos Principal of the service
org.apache.hadoop.yarn.service.api.records.Service:dockerClientConfig(java.lang.String)	com.fasterxml.jackson.annotation.JsonProperty	value	docker_client_config
org.apache.hadoop.yarn.service.api.records.Service:dockerClientConfig(java.lang.String)	javax.xml.bind.annotation.XmlElement	name	docker_client_config
org.apache.hadoop.yarn.service.api.records.Service:getDockerClientConfig()	io.swagger.annotations.ApiModelProperty	value	The Docker client config for the service
org.apache.hadoop.yarn.service.api.records.Resource:getProfile()	io.swagger.annotations.ApiModelProperty	example	null
org.apache.hadoop.yarn.service.api.records.Resource:getProfile()	io.swagger.annotations.ApiModelProperty	value	Each resource profile has a unique id which is associated with a cluster-level predefined memory, cpus, etc.
org.apache.hadoop.yarn.service.api.records.Resource:getProfile()	com.fasterxml.jackson.annotation.JsonProperty	value	profile
org.apache.hadoop.yarn.service.api.records.Resource:getCpus()	io.swagger.annotations.ApiModelProperty	example	null
org.apache.hadoop.yarn.service.api.records.Resource:getCpus()	io.swagger.annotations.ApiModelProperty	value	Amount of vcores allocated to each container (optional but overrides cpus in profile if specified).
org.apache.hadoop.yarn.service.api.records.Resource:getCpus()	com.fasterxml.jackson.annotation.JsonProperty	value	cpus
org.apache.hadoop.yarn.service.api.records.Resource:getMemory()	io.swagger.annotations.ApiModelProperty	example	null
org.apache.hadoop.yarn.service.api.records.Resource:getMemory()	io.swagger.annotations.ApiModelProperty	value	Amount of memory allocated to each container (optional but overrides memory in profile if specified). Currently accepts only an integer value and default unit is in MB.
org.apache.hadoop.yarn.service.api.records.Resource:getMemory()	com.fasterxml.jackson.annotation.JsonProperty	value	memory
org.apache.hadoop.yarn.service.api.records.Resource:calcMemoryMB()	com.fasterxml.jackson.annotation.JsonIgnoreProperties	ignoreUnknown	true
org.apache.hadoop.yarn.service.api.records.Resource:getAdditional()	io.swagger.annotations.ApiModelProperty	value	Map of resource name to ResourceInformation
org.apache.hadoop.yarn.service.api.records.Resource:getAdditional()	com.fasterxml.jackson.annotation.JsonProperty	value	additional
org.apache.hadoop.yarn.service.api.records.PlacementPolicy:getConstraints()	io.swagger.annotations.ApiModelProperty	example	null
org.apache.hadoop.yarn.service.api.records.PlacementPolicy:getConstraints()	io.swagger.annotations.ApiModelProperty	required	true
org.apache.hadoop.yarn.service.api.records.PlacementPolicy:getConstraints()	com.fasterxml.jackson.annotation.JsonProperty	value	constraints
org.apache.hadoop.yarn.service.api.records.Configuration:getProperties()	io.swagger.annotations.ApiModelProperty	example	null
org.apache.hadoop.yarn.service.api.records.Configuration:getProperties()	io.swagger.annotations.ApiModelProperty	value	A blob of key-value pairs of common service properties.
org.apache.hadoop.yarn.service.api.records.Configuration:getProperties()	com.fasterxml.jackson.annotation.JsonProperty	value	properties
org.apache.hadoop.yarn.service.api.records.Configuration:getEnv()	io.swagger.annotations.ApiModelProperty	example	null
org.apache.hadoop.yarn.service.api.records.Configuration:getEnv()	io.swagger.annotations.ApiModelProperty	value	A blob of key-value pairs which will be appended to the default system properties and handed off to the service at start time. All placeholder references to properties will be substituted before injection.
org.apache.hadoop.yarn.service.api.records.Configuration:getEnv()	com.fasterxml.jackson.annotation.JsonProperty	value	env
org.apache.hadoop.yarn.service.api.records.Configuration:getFiles()	io.swagger.annotations.ApiModelProperty	example	null
org.apache.hadoop.yarn.service.api.records.Configuration:getFiles()	io.swagger.annotations.ApiModelProperty	value	Array of list of files that needs to be created and made available as volumes in the service component containers.
org.apache.hadoop.yarn.service.api.records.Configuration:getFiles()	com.fasterxml.jackson.annotation.JsonProperty	value	files
org.apache.hadoop.yarn.service.api.records.Error:getCode()	io.swagger.annotations.ApiModelProperty	example	null
org.apache.hadoop.yarn.service.api.records.Error:getCode()	io.swagger.annotations.ApiModelProperty	value	
org.apache.hadoop.yarn.service.api.records.Error:getCode()	com.fasterxml.jackson.annotation.JsonProperty	value	code
org.apache.hadoop.yarn.service.api.records.Error:getMessage()	io.swagger.annotations.ApiModelProperty	example	null
org.apache.hadoop.yarn.service.api.records.Error:getMessage()	io.swagger.annotations.ApiModelProperty	value	
org.apache.hadoop.yarn.service.api.records.Error:getMessage()	com.fasterxml.jackson.annotation.JsonProperty	value	message
org.apache.hadoop.yarn.service.api.records.Error:getFields()	io.swagger.annotations.ApiModelProperty	example	null
org.apache.hadoop.yarn.service.api.records.Error:getFields()	io.swagger.annotations.ApiModelProperty	value	
org.apache.hadoop.yarn.service.api.records.Error:getFields()	com.fasterxml.jackson.annotation.JsonProperty	value	fields
org.apache.hadoop.yarn.service.api.records.KerberosPrincipal:getPrincipalName()	io.swagger.annotations.ApiModelProperty	value	The principal name of the service.
org.apache.hadoop.yarn.service.api.records.KerberosPrincipal:getKeytab()	io.swagger.annotations.ApiModelProperty	value	The URI of the kerberos keytab. It supports two schemes "hdfs" and "file". If the URI starts with "hdfs://" scheme, it indicates the path on hdfs where the keytab is stored. The keytab will be localized by YARN and made available to AM in its local directory. If the URI starts with "file://" scheme, it indicates a path on the local host where the keytab is presumbaly installed by admins upfront. 
org.apache.hadoop.yarn.service.api.records.ReadinessCheck:getType()	io.swagger.annotations.ApiModelProperty	example	null
org.apache.hadoop.yarn.service.api.records.ReadinessCheck:getType()	io.swagger.annotations.ApiModelProperty	value	E.g. HTTP (YARN will perform a simple REST call at a regular interval and expect a 204 No content).
org.apache.hadoop.yarn.service.api.records.ReadinessCheck:getProperties()	io.swagger.annotations.ApiModelProperty	example	null
org.apache.hadoop.yarn.service.api.records.ReadinessCheck:getProperties()	io.swagger.annotations.ApiModelProperty	value	A blob of key value pairs that will be used to configure the check.
org.apache.hadoop.yarn.service.api.records.ReadinessCheck:getArtifact()	io.swagger.annotations.ApiModelProperty	example	null
org.apache.hadoop.yarn.service.api.records.ReadinessCheck:getArtifact()	io.swagger.annotations.ApiModelProperty	value	Artifact of the pluggable readiness check helper container (optional). If specified, this helper container typically hosts the http uri and encapsulates the complex scripts required to perform actual container readiness check. At the end it is expected to respond a 204 No content just like the simplified use case. This pluggable framework benefits service owners who can run services without any packaging modifications. Note, artifacts of type docker only is supported for now.
org.apache.hadoop.yarn.service.api.records.ConfigFile$TypeEnum:toString()	com.fasterxml.jackson.annotation.JsonValue
org.apache.hadoop.yarn.service.api.records.Component$RestartPolicyEnum:toString()	com.fasterxml.jackson.annotation.JsonValue
org.apache.hadoop.yarn.service.api.records.ComponentContainers:getComponentName()	io.swagger.annotations.ApiModelProperty	example	null
org.apache.hadoop.yarn.service.api.records.ComponentContainers:getComponentName()	io.swagger.annotations.ApiModelProperty	required	true
org.apache.hadoop.yarn.service.api.records.ComponentContainers:getComponentName()	io.swagger.annotations.ApiModelProperty	value	Name of the component.
org.apache.hadoop.yarn.service.api.records.ComponentContainers:getContainers()	io.swagger.annotations.ApiModelProperty	example	null
org.apache.hadoop.yarn.service.api.records.ComponentContainers:getContainers()	io.swagger.annotations.ApiModelProperty	value	Containers of the component.
org.apache.hadoop.yarn.service.api.records.LocalizationStatus:getDestFile()	com.fasterxml.jackson.annotation.JsonProperty	value	dest_file
org.apache.hadoop.yarn.service.api.records.LocalizationStatus:setDestFile(java.lang.String)	javax.xml.bind.annotation.XmlElement	name	dest_file
org.apache.hadoop.yarn.service.api.records.LocalizationStatus:getState()	com.fasterxml.jackson.annotation.JsonProperty	value	state
org.apache.hadoop.yarn.service.api.records.LocalizationStatus:setState(org.apache.hadoop.yarn.api.records.LocalizationState)	javax.xml.bind.annotation.XmlElement	name	state
org.apache.hadoop.yarn.service.api.records.LocalizationStatus:getDiagnostics()	com.fasterxml.jackson.annotation.JsonProperty	value	diagnostics
org.apache.hadoop.yarn.service.api.records.LocalizationStatus:setDiagnostics(java.lang.String)	javax.xml.bind.annotation.XmlElement	name	diagnostics
org.apache.hadoop.yarn.service.api.records.Component:getRestartPolicy()	io.swagger.annotations.ApiModelProperty	value	Policy of restart component. Including ALWAYS (Always restart component even if instance exit code = 0); ON_FAILURE (Only restart component if instance exit code != 0); NEVER (Do not restart in any cases)
org.apache.hadoop.yarn.service.api.records.Component:getName()	io.swagger.annotations.ApiModelProperty	example	null
org.apache.hadoop.yarn.service.api.records.Component:getName()	io.swagger.annotations.ApiModelProperty	required	true
org.apache.hadoop.yarn.service.api.records.Component:getName()	io.swagger.annotations.ApiModelProperty	value	Name of the service component (mandatory).
org.apache.hadoop.yarn.service.api.records.Component:getDependencies()	io.swagger.annotations.ApiModelProperty	example	null
org.apache.hadoop.yarn.service.api.records.Component:getDependencies()	io.swagger.annotations.ApiModelProperty	value	An array of service components which should be in READY state (as defined by readiness check), before this component can be started. The dependencies across all components of an service should be represented as a DAG.
org.apache.hadoop.yarn.service.api.records.Component:getReadinessCheck()	io.swagger.annotations.ApiModelProperty	example	null
org.apache.hadoop.yarn.service.api.records.Component:getReadinessCheck()	io.swagger.annotations.ApiModelProperty	value	Readiness check for this component.
org.apache.hadoop.yarn.service.api.records.Component:getArtifact()	io.swagger.annotations.ApiModelProperty	example	null
org.apache.hadoop.yarn.service.api.records.Component:getArtifact()	io.swagger.annotations.ApiModelProperty	value	Artifact of the component (optional). If not specified, the service level global artifact takes effect.
org.apache.hadoop.yarn.service.api.records.Component:getLaunchCommand()	io.swagger.annotations.ApiModelProperty	example	null
org.apache.hadoop.yarn.service.api.records.Component:getLaunchCommand()	io.swagger.annotations.ApiModelProperty	value	The custom launch command of this component (optional). When specified at the component level, it overrides the value specified at the global level (if any).
org.apache.hadoop.yarn.service.api.records.Component:getResource()	io.swagger.annotations.ApiModelProperty	example	null
org.apache.hadoop.yarn.service.api.records.Component:getResource()	io.swagger.annotations.ApiModelProperty	value	Resource of this component (optional). If not specified, the service level global resource takes effect.
org.apache.hadoop.yarn.service.api.records.Component:getNumberOfContainers()	io.swagger.annotations.ApiModelProperty	example	null
org.apache.hadoop.yarn.service.api.records.Component:getNumberOfContainers()	io.swagger.annotations.ApiModelProperty	value	Number of containers for this component (optional). If not specified, the service level global number_of_containers takes effect.
org.apache.hadoop.yarn.service.api.records.Component:getDecommissionedInstances()	io.swagger.annotations.ApiModelProperty	example	null
org.apache.hadoop.yarn.service.api.records.Component:getDecommissionedInstances()	io.swagger.annotations.ApiModelProperty	value	A list of decommissioned component instances.
org.apache.hadoop.yarn.service.api.records.Component:getContainers()	io.swagger.annotations.ApiModelProperty	example	null
org.apache.hadoop.yarn.service.api.records.Component:getContainers()	io.swagger.annotations.ApiModelProperty	value	Containers of a started component. Specifying a value for this attribute for the POST payload raises a validation error. This blob is available only in the GET response of a started service.
org.apache.hadoop.yarn.service.api.records.Component:getRunPrivilegedContainer()	io.swagger.annotations.ApiModelProperty	example	null
org.apache.hadoop.yarn.service.api.records.Component:getRunPrivilegedContainer()	io.swagger.annotations.ApiModelProperty	value	Run all containers of this component in privileged mode (YARN-4262).
org.apache.hadoop.yarn.service.api.records.Component:getPlacementPolicy()	io.swagger.annotations.ApiModelProperty	example	null
org.apache.hadoop.yarn.service.api.records.Component:getPlacementPolicy()	io.swagger.annotations.ApiModelProperty	value	Advanced scheduling and placement policies for all containers of this component.
org.apache.hadoop.yarn.service.api.records.Component:getConfiguration()	io.swagger.annotations.ApiModelProperty	example	null
org.apache.hadoop.yarn.service.api.records.Component:getConfiguration()	io.swagger.annotations.ApiModelProperty	value	Config properties for this component.
org.apache.hadoop.yarn.service.api.records.Component:getQuicklinks()	io.swagger.annotations.ApiModelProperty	example	null
org.apache.hadoop.yarn.service.api.records.Component:getQuicklinks()	io.swagger.annotations.ApiModelProperty	value	A list of quicklink keys defined at the service level, and to be resolved by this component.
org.apache.hadoop.yarn.service.api.records.Component:getState()	io.swagger.annotations.ApiModelProperty	example	null
org.apache.hadoop.yarn.service.api.records.Component:getState()	io.swagger.annotations.ApiModelProperty	value	State of the component.
org.apache.hadoop.yarn.service.utils.ServiceApiUtil:setJsonSerDeser(org.apache.hadoop.yarn.service.utils.JsonSerDeser)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.service.utils.ServiceApiUtil:validateAndResolveService(org.apache.hadoop.yarn.service.api.records.Service,org.apache.hadoop.yarn.service.utils.SliderFileSystem,org.apache.hadoop.conf.Configuration)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.service.utils.ServiceApiUtil:getComponents(org.apache.hadoop.yarn.service.utils.SliderFileSystem,java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.service.containerlaunch.AbstractLauncher:getDockerImage()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.service.ServiceManager:getServiceSpec()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.service.ClientAMService:getNMHostName()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.service.client.ServiceClient:submitApp(org.apache.hadoop.yarn.service.api.records.Service)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.service.client.ServiceClient:addAMEnv()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.service.client.ServiceClient:setFileSystem(org.apache.hadoop.yarn.service.utils.SliderFileSystem)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.service.client.ServiceClient:setYarnClient(org.apache.hadoop.yarn.client.api.YarnClient)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.service.ServiceMaster:createClientAMService()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.service.ServiceMaster:recordTokensForContainers()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.service.component.instance.ComponentInstance:handleComponentInstanceRelaunch(org.apache.hadoop.yarn.service.component.instance.ComponentInstance,org.apache.hadoop.yarn.service.component.instance.ComponentInstanceEvent,boolean,java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.service.component.instance.ComponentInstance:updateLocalizationStatuses(java.util.List)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.service.component.instance.ComponentInstance:isLclRetrieverActive()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.service.component.Component:checkIfStable(org.apache.hadoop.yarn.service.component.Component)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.client.api.NMClient:createNMClient()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.client.api.NMClient:createNMClient(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.client.api.NMClient:<init>(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.client.api.NMClient:increaseContainerResource(org.apache.hadoop.yarn.api.records.Container)	java.lang.Deprecated
org.apache.hadoop.yarn.client.api.NMClient:localize(org.apache.hadoop.yarn.api.records.ContainerId,org.apache.hadoop.yarn.api.records.NodeId,java.util.Map)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.client.api.NMClient:getLocalizationStatuses(org.apache.hadoop.yarn.api.records.ContainerId,org.apache.hadoop.yarn.api.records.NodeId)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.client.api.YarnClient:createYarnClient()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.client.api.YarnClient:<init>(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.client.api.YarnClient:submitReservation(org.apache.hadoop.yarn.api.protocolrecords.ReservationSubmissionRequest)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.client.api.YarnClient:submitReservation(org.apache.hadoop.yarn.api.protocolrecords.ReservationSubmissionRequest)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.client.api.YarnClient:updateReservation(org.apache.hadoop.yarn.api.protocolrecords.ReservationUpdateRequest)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.client.api.YarnClient:updateReservation(org.apache.hadoop.yarn.api.protocolrecords.ReservationUpdateRequest)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.client.api.YarnClient:deleteReservation(org.apache.hadoop.yarn.api.protocolrecords.ReservationDeleteRequest)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.client.api.YarnClient:deleteReservation(org.apache.hadoop.yarn.api.protocolrecords.ReservationDeleteRequest)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.client.api.YarnClient:listReservations(org.apache.hadoop.yarn.api.protocolrecords.ReservationListRequest)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.client.api.YarnClient:listReservations(org.apache.hadoop.yarn.api.protocolrecords.ReservationListRequest)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.client.api.YarnClient:getNodeToLabels()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.client.api.YarnClient:getNodeToLabels()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.client.api.YarnClient:getLabelsToNodes()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.client.api.YarnClient:getLabelsToNodes()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.client.api.YarnClient:getLabelsToNodes(java.util.Set)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.client.api.YarnClient:getLabelsToNodes(java.util.Set)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.client.api.YarnClient:getClusterNodeLabels()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.client.api.YarnClient:getClusterNodeLabels()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.client.api.YarnClient:updateApplicationPriority(org.apache.hadoop.yarn.api.records.ApplicationId,org.apache.hadoop.yarn.api.records.Priority)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.client.api.YarnClient:updateApplicationPriority(org.apache.hadoop.yarn.api.records.ApplicationId,org.apache.hadoop.yarn.api.records.Priority)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.client.api.YarnClient:updateApplicationTimeouts(org.apache.hadoop.yarn.api.protocolrecords.UpdateApplicationTimeoutsRequest)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.client.api.YarnClient:updateApplicationTimeouts(org.apache.hadoop.yarn.api.protocolrecords.UpdateApplicationTimeoutsRequest)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.client.api.YarnClient:getResourceProfiles()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.client.api.YarnClient:getResourceProfiles()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.client.api.YarnClient:getResourceProfile(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.client.api.YarnClient:getResourceProfile(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.client.api.YarnClient:getResourceTypeInfo()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.client.api.YarnClient:getResourceTypeInfo()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.client.api.YarnClient:getClusterAttributes()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.client.api.YarnClient:getClusterAttributes()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.client.api.YarnClient:getAttributesToNodes(java.util.Set)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.client.api.YarnClient:getAttributesToNodes(java.util.Set)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.client.api.YarnClient:getNodeToAttributes(java.util.Set)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.client.api.YarnClient:getNodeToAttributes(java.util.Set)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.client.api.YarnClient:shellToContainer(org.apache.hadoop.yarn.api.records.ContainerId,org.apache.hadoop.yarn.api.records.ShellContainerCommand)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.client.api.YarnClient:shellToContainer(org.apache.hadoop.yarn.api.records.ContainerId,org.apache.hadoop.yarn.api.records.ShellContainerCommand)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.client.api.AMRMClient:createAMRMClient()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.client.api.AMRMClient:<init>(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.client.api.AMRMClient:addSchedulingRequests(java.util.Collection)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.client.api.AMRMClient:addSchedulingRequests(java.util.Collection)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.client.api.AMRMClient:registerApplicationMaster(java.lang.String,int,java.lang.String,java.util.Map)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.client.api.AMRMClient:registerApplicationMaster(java.lang.String,int,java.lang.String,java.util.Map)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.client.api.AMRMClient:requestContainerResourceChange(org.apache.hadoop.yarn.api.records.Container,org.apache.hadoop.yarn.api.records.Resource)	java.lang.Deprecated
org.apache.hadoop.yarn.client.api.AMRMClient:getMatchingRequests(org.apache.hadoop.yarn.api.records.Priority,java.lang.String,org.apache.hadoop.yarn.api.records.Resource)	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.yarn.client.api.AMRMClient:getMatchingRequests(org.apache.hadoop.yarn.api.records.Priority,java.lang.String,org.apache.hadoop.yarn.api.records.ExecutionType,org.apache.hadoop.yarn.api.records.Resource)	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.yarn.client.api.AMRMClient:getMatchingRequests(org.apache.hadoop.yarn.api.records.Priority,java.lang.String,org.apache.hadoop.yarn.api.records.ExecutionType,org.apache.hadoop.yarn.api.records.Resource,java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.yarn.client.api.AMRMClient:getMatchingRequests(long)	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.yarn.client.api.AMRMClient:updateTrackingUrl(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.client.api.AMRMClient:updateTrackingUrl(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.client.api.AMRMClient$ContainerRequest:<init>(org.apache.hadoop.yarn.api.records.Resource,java.lang.String[],java.lang.String[],org.apache.hadoop.yarn.api.records.Priority,java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.client.api.AMRMClient$ContainerRequest:<init>(org.apache.hadoop.yarn.api.records.Resource,java.lang.String[],java.lang.String[],org.apache.hadoop.yarn.api.records.Priority,long)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.client.api.AMRMClient$ContainerRequest:<init>(org.apache.hadoop.yarn.api.records.Resource,java.lang.String[],java.lang.String[],org.apache.hadoop.yarn.api.records.Priority,long)	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.yarn.client.api.AMRMClient$ContainerRequest:<init>(org.apache.hadoop.yarn.api.records.Resource,java.lang.String[],java.lang.String[],org.apache.hadoop.yarn.api.records.Priority,long,boolean)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.client.api.AMRMClient$ContainerRequest:<init>(org.apache.hadoop.yarn.api.records.Resource,java.lang.String[],java.lang.String[],org.apache.hadoop.yarn.api.records.Priority,long,boolean)	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.yarn.client.api.AMRMClient$ContainerRequest:<init>(org.apache.hadoop.yarn.api.records.Resource,java.lang.String[],java.lang.String[],org.apache.hadoop.yarn.api.records.Priority,long,boolean,java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.client.api.AMRMClient$ContainerRequest:<init>(org.apache.hadoop.yarn.api.records.Resource,java.lang.String[],java.lang.String[],org.apache.hadoop.yarn.api.records.Priority,long,boolean,java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.yarn.client.api.async.NMClientAsync$AbstractCallbackHandler:onContainerResourceIncreased(org.apache.hadoop.yarn.api.records.ContainerId,org.apache.hadoop.yarn.api.records.Resource)	java.lang.Deprecated
org.apache.hadoop.yarn.client.api.async.NMClientAsync$AbstractCallbackHandler:onIncreaseContainerResourceError(org.apache.hadoop.yarn.api.records.ContainerId,java.lang.Throwable)	java.lang.Deprecated
org.apache.hadoop.yarn.client.api.async.NMClientAsync:createNMClientAsync(org.apache.hadoop.yarn.client.api.async.NMClientAsync$CallbackHandler)	java.lang.Deprecated
org.apache.hadoop.yarn.client.api.async.NMClientAsync:<init>(org.apache.hadoop.yarn.client.api.async.NMClientAsync$CallbackHandler)	java.lang.Deprecated
org.apache.hadoop.yarn.client.api.async.NMClientAsync:<init>(java.lang.String,org.apache.hadoop.yarn.client.api.async.NMClientAsync$CallbackHandler)	java.lang.Deprecated
org.apache.hadoop.yarn.client.api.async.NMClientAsync:<init>(java.lang.String,org.apache.hadoop.yarn.client.api.NMClient,org.apache.hadoop.yarn.client.api.async.NMClientAsync$CallbackHandler)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.client.api.async.NMClientAsync:<init>(java.lang.String,org.apache.hadoop.yarn.client.api.NMClient,org.apache.hadoop.yarn.client.api.async.NMClientAsync$CallbackHandler)	java.lang.Deprecated
org.apache.hadoop.yarn.client.api.async.NMClientAsync:<init>(java.lang.String,org.apache.hadoop.yarn.client.api.NMClient,org.apache.hadoop.yarn.client.api.async.NMClientAsync$CallbackHandler)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.client.api.async.NMClientAsync:increaseContainerResourceAsync(org.apache.hadoop.yarn.api.records.Container)	java.lang.Deprecated
org.apache.hadoop.yarn.client.api.async.AMRMClientAsync$AbstractCallbackHandler:onContainersUpdated(java.util.List)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.client.api.async.AMRMClientAsync$AbstractCallbackHandler:onContainersUpdated(java.util.List)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.client.api.async.AMRMClientAsync$AbstractCallbackHandler:onRequestsRejected(java.util.List)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.client.api.async.AMRMClientAsync$AbstractCallbackHandler:onRequestsRejected(java.util.List)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.client.api.async.AMRMClientAsync$AbstractCallbackHandler:onPreemptionMessageReceived(org.apache.hadoop.yarn.api.records.PreemptionMessage)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.client.api.async.AMRMClientAsync$AbstractCallbackHandler:onPreemptionMessageReceived(org.apache.hadoop.yarn.api.records.PreemptionMessage)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.client.api.async.impl.AMRMClientAsyncImpl:<init>(int,org.apache.hadoop.yarn.client.api.async.AMRMClientAsync$CallbackHandler)	java.lang.Deprecated
org.apache.hadoop.yarn.client.api.async.impl.AMRMClientAsyncImpl:<init>(org.apache.hadoop.yarn.client.api.AMRMClient,int,org.apache.hadoop.yarn.client.api.async.AMRMClientAsync$CallbackHandler)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.client.api.async.impl.AMRMClientAsyncImpl:<init>(org.apache.hadoop.yarn.client.api.AMRMClient,int,org.apache.hadoop.yarn.client.api.async.AMRMClientAsync$CallbackHandler)	java.lang.Deprecated
org.apache.hadoop.yarn.client.api.async.impl.AMRMClientAsyncImpl:<init>(org.apache.hadoop.yarn.client.api.AMRMClient,int,org.apache.hadoop.yarn.client.api.async.AMRMClientAsync$CallbackHandler)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.client.api.async.impl.NMClientAsyncImpl:<init>(java.lang.String,org.apache.hadoop.yarn.client.api.NMClient,org.apache.hadoop.yarn.client.api.async.NMClientAsync$AbstractCallbackHandler)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.client.api.async.impl.NMClientAsyncImpl:<init>(java.lang.String,org.apache.hadoop.yarn.client.api.NMClient,org.apache.hadoop.yarn.client.api.async.NMClientAsync$AbstractCallbackHandler)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.client.api.async.impl.NMClientAsyncImpl:<init>(org.apache.hadoop.yarn.client.api.async.NMClientAsync$CallbackHandler)	java.lang.Deprecated
org.apache.hadoop.yarn.client.api.async.impl.NMClientAsyncImpl:<init>(java.lang.String,org.apache.hadoop.yarn.client.api.async.NMClientAsync$CallbackHandler)	java.lang.Deprecated
org.apache.hadoop.yarn.client.api.async.impl.NMClientAsyncImpl:<init>(java.lang.String,org.apache.hadoop.yarn.client.api.NMClient,org.apache.hadoop.yarn.client.api.async.NMClientAsync$CallbackHandler)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.client.api.async.impl.NMClientAsyncImpl:<init>(java.lang.String,org.apache.hadoop.yarn.client.api.NMClient,org.apache.hadoop.yarn.client.api.async.NMClientAsync$CallbackHandler)	java.lang.Deprecated
org.apache.hadoop.yarn.client.api.async.impl.NMClientAsyncImpl:<init>(java.lang.String,org.apache.hadoop.yarn.client.api.NMClient,org.apache.hadoop.yarn.client.api.async.NMClientAsync$CallbackHandler)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.client.api.async.impl.NMClientAsyncImpl:increaseContainerResourceAsync(org.apache.hadoop.yarn.api.records.Container)	java.lang.Deprecated
org.apache.hadoop.yarn.client.api.async.AMRMClientAsync:<init>(org.apache.hadoop.yarn.client.api.AMRMClient,int,org.apache.hadoop.yarn.client.api.async.AMRMClientAsync$AbstractCallbackHandler)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.client.api.async.AMRMClientAsync:<init>(org.apache.hadoop.yarn.client.api.AMRMClient,int,org.apache.hadoop.yarn.client.api.async.AMRMClientAsync$AbstractCallbackHandler)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.client.api.async.AMRMClientAsync:createAMRMClientAsync(int,org.apache.hadoop.yarn.client.api.async.AMRMClientAsync$CallbackHandler)	java.lang.Deprecated
org.apache.hadoop.yarn.client.api.async.AMRMClientAsync:createAMRMClientAsync(org.apache.hadoop.yarn.client.api.AMRMClient,int,org.apache.hadoop.yarn.client.api.async.AMRMClientAsync$CallbackHandler)	java.lang.Deprecated
org.apache.hadoop.yarn.client.api.async.AMRMClientAsync:<init>(int,org.apache.hadoop.yarn.client.api.async.AMRMClientAsync$CallbackHandler)	java.lang.Deprecated
org.apache.hadoop.yarn.client.api.async.AMRMClientAsync:<init>(org.apache.hadoop.yarn.client.api.AMRMClient,int,org.apache.hadoop.yarn.client.api.async.AMRMClientAsync$CallbackHandler)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.client.api.async.AMRMClientAsync:<init>(org.apache.hadoop.yarn.client.api.AMRMClient,int,org.apache.hadoop.yarn.client.api.async.AMRMClientAsync$CallbackHandler)	java.lang.Deprecated
org.apache.hadoop.yarn.client.api.async.AMRMClientAsync:<init>(org.apache.hadoop.yarn.client.api.AMRMClient,int,org.apache.hadoop.yarn.client.api.async.AMRMClientAsync$CallbackHandler)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.client.api.async.AMRMClientAsync:addSchedulingRequests(java.util.Collection)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.client.api.async.AMRMClientAsync:addSchedulingRequests(java.util.Collection)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.client.api.async.AMRMClientAsync:registerApplicationMaster(java.lang.String,int,java.lang.String,java.util.Map)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.client.api.async.AMRMClientAsync:registerApplicationMaster(java.lang.String,int,java.lang.String,java.util.Map)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.client.api.async.AMRMClientAsync:requestContainerResourceChange(org.apache.hadoop.yarn.api.records.Container,org.apache.hadoop.yarn.api.records.Resource)	java.lang.Deprecated
org.apache.hadoop.yarn.client.api.async.AMRMClientAsync:updateTrackingUrl(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.client.api.async.AMRMClientAsync:updateTrackingUrl(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.client.api.ContainerShellWebSocket:onText(org.eclipse.jetty.websocket.api.Session,java.lang.String)	org.eclipse.jetty.websocket.api.annotations.OnWebSocketMessage
org.apache.hadoop.yarn.client.api.ContainerShellWebSocket:onConnect(org.eclipse.jetty.websocket.api.Session)	org.eclipse.jetty.websocket.api.annotations.OnWebSocketConnect
org.apache.hadoop.yarn.client.api.ContainerShellWebSocket:onClose(org.eclipse.jetty.websocket.api.Session,int,java.lang.String)	org.eclipse.jetty.websocket.api.annotations.OnWebSocketClose
org.apache.hadoop.yarn.client.api.NMTokenCache:getNMToken(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.client.api.NMTokenCache:setNMToken(java.lang.String,org.apache.hadoop.yarn.api.records.Token)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.client.api.NMTokenCache:getToken(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.client.api.NMTokenCache:getToken(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.yarn.client.api.NMTokenCache:setToken(java.lang.String,org.apache.hadoop.yarn.api.records.Token)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.client.api.NMTokenCache:setToken(java.lang.String,org.apache.hadoop.yarn.api.records.Token)	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.yarn.client.api.NMTokenCache:containsToken(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.client.api.NMTokenCache:containsToken(java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.client.api.NMTokenCache:numberOfTokensInCache()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.client.api.NMTokenCache:numberOfTokensInCache()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.client.api.NMTokenCache:removeToken(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.client.api.NMTokenCache:removeToken(java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.client.api.NMTokenCache:clearCache()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.client.api.NMTokenCache:clearCache()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.client.api.impl.AHSv2ClientImpl:setReaderClient(org.apache.hadoop.yarn.client.api.TimelineReaderClient)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl:<init>(org.apache.hadoop.yarn.api.ApplicationMasterProtocol)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl:populateNMTokens(java.util.List)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl:populateNMTokens(java.util.List)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl:getTable(long)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl:getOutstandingSchedRequests()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData:<init>(org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy,org.apache.hadoop.yarn.ipc.YarnRPC,java.lang.String,org.apache.hadoop.yarn.api.records.ContainerId,org.apache.hadoop.yarn.api.records.Token)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData:<init>(org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy,org.apache.hadoop.yarn.ipc.YarnRPC,java.lang.String,org.apache.hadoop.yarn.api.records.ContainerId,org.apache.hadoop.yarn.api.records.Token)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData:newProxy(org.apache.hadoop.yarn.ipc.YarnRPC,java.lang.String,org.apache.hadoop.yarn.api.records.ContainerId,org.apache.hadoop.yarn.api.records.Token)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData:newProxy(org.apache.hadoop.yarn.ipc.YarnRPC,java.lang.String,org.apache.hadoop.yarn.api.records.ContainerId,org.apache.hadoop.yarn.api.records.Token)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.client.api.impl.SharedCacheClientImpl:createClientProxy()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.client.api.impl.SharedCacheClientImpl:stopClientProxy()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.client.api.impl.YarnClientImpl:getTimelineDelegationToken()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.client.api.impl.YarnClientImpl:isSecurityEnabled()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.client.api.impl.YarnClientImpl:isSecurityEnabled()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.client.api.impl.YarnClientImpl:enforceAsyncAPITimeout()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.client.api.impl.YarnClientImpl:setRMClient(org.apache.hadoop.yarn.api.ApplicationClientProtocol)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.client.api.impl.YarnClientImpl:setRMClient(org.apache.hadoop.yarn.api.ApplicationClientProtocol)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.client.api.impl.NMClientImpl:increaseContainerResource(org.apache.hadoop.yarn.api.records.Container)	java.lang.Deprecated
org.apache.hadoop.yarn.client.api.SharedCacheClient:createSharedCacheClient()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.client.api.SharedCacheClient:<init>(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.client.api.SharedCacheClient:use(org.apache.hadoop.yarn.api.records.ApplicationId,java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.client.api.SharedCacheClient:use(org.apache.hadoop.yarn.api.records.ApplicationId,java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.client.api.SharedCacheClient:release(org.apache.hadoop.yarn.api.records.ApplicationId,java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.client.api.SharedCacheClient:release(org.apache.hadoop.yarn.api.records.ApplicationId,java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.client.api.SharedCacheClient:getFileChecksum(org.apache.hadoop.fs.Path)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.client.api.SharedCacheClient:getFileChecksum(org.apache.hadoop.fs.Path)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.client.api.AHSClient:createAHSClient()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.client.api.AHSClient:createAHSv2Client()	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.yarn.client.api.AHSClient:createAHSv2Client()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.client.api.AHSClient:<init>(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.client.cli.SchedConfCLI:getSchedulerConf(java.lang.String,com.sun.jersey.api.client.WebResource)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.client.cli.SchedConfCLI:formatSchedulerConf(java.lang.String,com.sun.jersey.api.client.WebResource)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.client.cli.SchedConfCLI:updateSchedulerConfOnRMNode(java.lang.String,org.apache.hadoop.yarn.webapp.dao.SchedConfUpdateInfo)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.client.cli.SchedConfCLI:addQueues(java.lang.String,org.apache.hadoop.yarn.webapp.dao.SchedConfUpdateInfo)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.client.cli.SchedConfCLI:removeQueues(java.lang.String,org.apache.hadoop.yarn.webapp.dao.SchedConfUpdateInfo)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.client.cli.SchedConfCLI:updateQueues(java.lang.String,org.apache.hadoop.yarn.webapp.dao.SchedConfUpdateInfo)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.client.cli.SchedConfCLI:globalUpdates(java.lang.String,org.apache.hadoop.yarn.webapp.dao.SchedConfUpdateInfo)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.client.cli.LogsCLI$ClientConnectionRetry:getRetired()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.client.cli.LogsCLI$ClientConnectionRetry:getRetired()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.client.cli.TopCLI:getHAClusterUrl(org.apache.hadoop.conf.Configuration,java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.client.cli.TopCLI:showTopScreen()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.client.cli.ClusterCLI:getNodeLabelManagerInstance(org.apache.hadoop.conf.Configuration)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.client.cli.ClusterCLI:printUsage(org.apache.commons.cli.Options)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.client.cli.LogsCLI:createYarnClient()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.client.cli.LogsCLI:printContainerLogsFromRunningApplication(org.apache.hadoop.conf.Configuration,org.apache.hadoop.yarn.logaggregation.ContainerLogsRequest,org.apache.hadoop.yarn.logaggregation.LogCLIHelpers,boolean,boolean)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.client.cli.LogsCLI:printContainerLogsFromRunningApplication(org.apache.hadoop.conf.Configuration,org.apache.hadoop.yarn.logaggregation.ContainerLogsRequest,org.apache.hadoop.yarn.logaggregation.LogCLIHelpers,boolean,boolean)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.client.cli.LogsCLI:getContainerReport(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.client.cli.LogsCLI:getContainerReport(java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.client.cli.LogsCLI:getMatchedContainerLogFiles(org.apache.hadoop.yarn.logaggregation.ContainerLogsRequest,boolean,boolean)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.client.cli.LogsCLI:getResponseFromNMWebService(org.apache.hadoop.conf.Configuration,com.sun.jersey.api.client.Client,org.apache.hadoop.yarn.logaggregation.ContainerLogsRequest,java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.client.cli.LogsCLI:getNodeHttpAddressFromRMWebString(org.apache.hadoop.yarn.logaggregation.ContainerLogsRequest)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.client.cli.LogsCLI:getMatchedOptionForRunningApp(org.apache.hadoop.yarn.logaggregation.ContainerLogsRequest,boolean,boolean)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.client.cli.LogsCLI:getMatchedOptionForRunningApp(org.apache.hadoop.yarn.logaggregation.ContainerLogsRequest,boolean,boolean)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.client.cli.LogsCLI:getMatchedLogTypesForRunningApp(java.util.List,boolean,boolean)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.client.cli.LogsCLI:getMatchedLogTypesForRunningApp(java.util.List,boolean,boolean)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.client.cli.ApplicationCLI:preProcessArgs(java.lang.String[])	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.client.cli.ApplicationCLI:printUsage(java.lang.String,org.apache.commons.cli.Options)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.client.cli.QueueCLI:printUsage(org.apache.commons.cli.Options)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.client.util.YarnClientUtils:getYarnConfWithRmHaId(org.apache.hadoop.conf.Configuration)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.nodelabels.CommonNodeLabelsManager:addToCluserNodeLabelsWithDefaultExclusivity(java.util.Set)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.event.EventDispatcher:disableExitOnError()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.event.AsyncDispatcher:disableExitOnDispatchException()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.event.AsyncDispatcher:isEventThreadWaiting()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.security.ApplicationACLsManager:<init>()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.api.protocolrecords.impl.pb.GetLabelsToNodesResponsePBImpl:setLabelsToNodes(java.util.Map)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.impl.pb.GetLabelsToNodesResponsePBImpl:setLabelsToNodes(java.util.Map)	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.yarn.api.protocolrecords.impl.pb.GetLabelsToNodesResponsePBImpl:getLabelsToNodes()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.api.protocolrecords.impl.pb.GetLabelsToNodesResponsePBImpl:getLabelsToNodes()	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.yarn.api.protocolrecords.impl.pb.GetClusterNodeLabelsResponsePBImpl:getNodeLabels()	java.lang.Deprecated
org.apache.hadoop.yarn.api.protocolrecords.impl.pb.GetClusterNodeLabelsResponsePBImpl:setNodeLabels(java.util.Set)	java.lang.Deprecated
org.apache.hadoop.yarn.api.records.impl.pb.ApplicationSubmissionContextPBImpl:getAMContainerResourceRequest()	java.lang.Deprecated
org.apache.hadoop.yarn.api.records.impl.pb.ApplicationSubmissionContextPBImpl:setAMContainerResourceRequest(org.apache.hadoop.yarn.api.records.ResourceRequest)	java.lang.Deprecated
org.apache.hadoop.yarn.api.records.impl.pb.ContainerIdPBImpl:getId()	java.lang.Deprecated
org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl:increaseContainersResource(org.apache.hadoop.yarn.api.protocolrecords.IncreaseContainersResourceRequest)	java.lang.Deprecated
org.apache.hadoop.yarn.webapp.View$ViewContext:<init>(org.apache.hadoop.yarn.webapp.Controller$RequestContext)	com.google.inject.Inject
org.apache.hadoop.yarn.webapp.WebApp:httpServer()	com.google.inject.Provides
org.apache.hadoop.yarn.webapp.WebApp:conf()	com.google.inject.Provides
org.apache.hadoop.yarn.webapp.WebApp:router()	com.google.inject.Provides
org.apache.hadoop.yarn.webapp.WebApp:webApp()	com.google.inject.Provides
org.apache.hadoop.yarn.webapp.example.MyApp$MyController:<init>(org.apache.hadoop.yarn.webapp.example.MyApp,org.apache.hadoop.yarn.webapp.Controller$RequestContext)	com.google.inject.Inject
org.apache.hadoop.yarn.webapp.log.AggregatedLogsBlock:<init>(org.apache.hadoop.conf.Configuration)	com.google.inject.Inject
org.apache.hadoop.yarn.webapp.dao.SchedConfUpdateInfo:getGlobalParams()	javax.xml.bind.annotation.XmlElementWrapper	name	global-updates
org.apache.hadoop.yarn.webapp.Controller$RequestContext:<init>(com.google.inject.Injector,javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)	com.google.inject.Inject
org.apache.hadoop.yarn.webapp.DefaultWrapperServlet:doGet(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.webapp.view.InfoBlock:<init>(org.apache.hadoop.yarn.webapp.ResponseInfo)	com.google.inject.Inject
org.apache.hadoop.yarn.webapp.util.WebServiceClient:getSSLFactory()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.webapp.util.WebServiceClient:getHttpURLConnectionFactory()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.webapp.Dispatcher:<init>(org.apache.hadoop.yarn.webapp.WebApp,com.google.inject.Injector,org.apache.hadoop.yarn.webapp.Router)	com.google.inject.Inject
org.apache.hadoop.yarn.logaggregation.AggregatedLogFormat$LogValue:getPendingLogFilesToUploadForThisContainer()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.logaggregation.AggregatedLogFormat$LogValue:secureOpenFile(java.io.File)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.logaggregation.filecontroller.ifile.LogAggregationIndexedFileController:parseCheckSumFiles(java.util.List)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.logaggregation.filecontroller.ifile.LogAggregationIndexedFileController:getNodeLogFileToRead(java.util.List,java.lang.String,org.apache.hadoop.yarn.api.records.ApplicationId)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.logaggregation.filecontroller.ifile.LogAggregationIndexedFileController:getAllChecksumFiles(java.util.Map,java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.logaggregation.filecontroller.ifile.LogAggregationIndexedFileController:loadIndexedLogsMeta(org.apache.hadoop.fs.Path,long,org.apache.hadoop.yarn.api.records.ApplicationId)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.logaggregation.filecontroller.ifile.LogAggregationIndexedFileController:getFSOutputBufferSize(org.apache.hadoop.conf.Configuration)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.logaggregation.filecontroller.ifile.LogAggregationIndexedFileController:getFSInputBufferSize(org.apache.hadoop.conf.Configuration)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.logaggregation.filecontroller.ifile.LogAggregationIndexedFileController:getRollOverLogMaxSize(org.apache.hadoop.conf.Configuration)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.logaggregation.filecontroller.ifile.LogAggregationIndexedFileController:getRollOverLogMaxSize(org.apache.hadoop.conf.Configuration)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.logaggregation.filecontroller.ifile.LogAggregationIndexedFileController:isRollover(org.apache.hadoop.fs.FileContext,org.apache.hadoop.fs.Path)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.logaggregation.filecontroller.ifile.LogAggregationIndexedFileController:isRollover(org.apache.hadoop.fs.FileContext,org.apache.hadoop.fs.Path)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.logaggregation.filecontroller.ifile.LogAggregationIndexedFileController:getSystemClock()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.logaggregation.filecontroller.ifile.LogAggregationIndexedFileController:getSystemClock()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.logaggregation.filecontroller.ifile.IndexedFileAggregatedLogsBlock:<init>(org.apache.hadoop.yarn.webapp.View$ViewContext,org.apache.hadoop.conf.Configuration,org.apache.hadoop.yarn.logaggregation.filecontroller.ifile.LogAggregationIndexedFileController)	com.google.inject.Inject
org.apache.hadoop.yarn.logaggregation.filecontroller.tfile.TFileAggregatedLogsBlock:<init>(org.apache.hadoop.yarn.webapp.View$ViewContext,org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path,java.lang.String)	com.google.inject.Inject
org.apache.hadoop.yarn.logaggregation.filecontroller.LogAggregationFileController:getFileSystem(org.apache.hadoop.conf.Configuration)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.logaggregation.filecontroller.LogAggregationFileControllerFactory:getConfiguredLogAggregationFileControllerList()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.logaggregation.filecontroller.LogAggregationFileControllerFactory:getConfiguredLogAggregationFileControllerList()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.logaggregation.filecontroller.LogAggregationHtmlBlock:<init>(org.apache.hadoop.yarn.webapp.View$ViewContext)	com.google.inject.Inject
org.apache.hadoop.yarn.logaggregation.AggregatedLogFormat$LogKey:write(java.io.DataOutput)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.logaggregation.AggregatedLogFormat$LogKey:readFields(java.io.DataInput)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.logaggregation.AggregatedLogDeletionService:createRMClient()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.logaggregation.AggregatedLogDeletionService:stopRMClient()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.logaggregation.LogCLIHelpers:dumpAContainersLogs(java.lang.String,java.lang.String,java.lang.String,java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.logaggregation.LogCLIHelpers:dumpAContainersLogs(java.lang.String,java.lang.String,java.lang.String,java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.logaggregation.LogCLIHelpers:getOwnerForAppIdOrNull(org.apache.hadoop.yarn.api.records.ApplicationId,java.lang.String,org.apache.hadoop.conf.Configuration)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.logaggregation.LogCLIHelpers:getOwnerForAppIdOrNull(org.apache.hadoop.yarn.api.records.ApplicationId,java.lang.String,org.apache.hadoop.conf.Configuration)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.logaggregation.LogCLIHelpers:dumpAContainerLogsForLogType(org.apache.hadoop.yarn.logaggregation.ContainerLogsRequest)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.logaggregation.LogCLIHelpers:dumpAContainerLogsForLogType(org.apache.hadoop.yarn.logaggregation.ContainerLogsRequest)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.logaggregation.LogCLIHelpers:dumpAContainerLogsForLogType(org.apache.hadoop.yarn.logaggregation.ContainerLogsRequest,boolean)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.logaggregation.LogCLIHelpers:dumpAContainerLogsForLogType(org.apache.hadoop.yarn.logaggregation.ContainerLogsRequest,boolean)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.logaggregation.LogCLIHelpers:dumpAContainerLogsForLogTypeWithoutNodeId(org.apache.hadoop.yarn.logaggregation.ContainerLogsRequest)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.logaggregation.LogCLIHelpers:dumpAllContainersLogs(org.apache.hadoop.yarn.logaggregation.ContainerLogsRequest)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.logaggregation.LogCLIHelpers:printAContainerLogMetadata(org.apache.hadoop.yarn.logaggregation.ContainerLogsRequest,java.io.PrintStream,java.io.PrintStream)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.logaggregation.LogCLIHelpers:printNodesList(org.apache.hadoop.yarn.logaggregation.ContainerLogsRequest,java.io.PrintStream,java.io.PrintStream)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.logaggregation.LogCLIHelpers:printContainersList(org.apache.hadoop.yarn.logaggregation.ContainerLogsRequest,java.io.PrintStream,java.io.PrintStream)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.logaggregation.LogCLIHelpers:listContainerLogs(org.apache.hadoop.yarn.logaggregation.ContainerLogsRequest)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.logaggregation.AggregatedLogFormat$LogWriter:getWriter()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.logaggregation.AggregatedLogFormat$LogReader:getContainerLogsReader(org.apache.hadoop.yarn.api.records.ContainerId)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.logaggregation.AggregatedLogFormat$LogReader:readContainerMetaDataAndSkipData(java.io.DataInputStream)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.logaggregation.LogAggregationUtils:getNodeString(org.apache.hadoop.yarn.api.records.NodeId)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.logaggregation.LogAggregationUtils:getNodeString(java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.security.AMRMTokenIdentifier:getApplicationAttemptId()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.security.YarnAuthorizationProvider:destroy()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.security.ContainerTokenIdentifier:<init>(org.apache.hadoop.yarn.api.records.ContainerId,java.lang.String,java.lang.String,org.apache.hadoop.yarn.api.records.Resource,long,int,long,org.apache.hadoop.yarn.api.records.Priority,long,org.apache.hadoop.yarn.api.records.LogAggregationContext)	java.lang.Deprecated
org.apache.hadoop.yarn.security.client.YARNDelegationTokenIdentifier:writeInOldFormat(java.io.DataOutput)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.security.client.RMDelegationTokenIdentifier$Renewer:setSecretManager(org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager,java.net.InetSocketAddress)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.security.client.BaseClientToAMTokenSecretManager:getMasterKey(org.apache.hadoop.yarn.api.records.ApplicationAttemptId)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.security.client.BaseClientToAMTokenSecretManager:createPassword(org.apache.hadoop.yarn.security.client.ClientToAMTokenIdentifier)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.security.client.BaseClientToAMTokenSecretManager:retrievePassword(org.apache.hadoop.yarn.security.client.ClientToAMTokenIdentifier)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.security.client.BaseClientToAMTokenSecretManager:createIdentifier()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.security.client.BaseClientToAMTokenSecretManager:createIdentifier()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.security.client.BaseClientToAMTokenSecretManager:retrievePassword(org.apache.hadoop.security.token.TokenIdentifier)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.security.client.BaseClientToAMTokenSecretManager:createPassword(org.apache.hadoop.security.token.TokenIdentifier)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.util.AdHocLogDumper:getState()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.util.ConverterUtils:getPathFromYarnURL(org.apache.hadoop.yarn.api.records.URL)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.util.ConverterUtils:getPathFromYarnURL(org.apache.hadoop.yarn.api.records.URL)	java.lang.Deprecated
org.apache.hadoop.yarn.util.ConverterUtils:getYarnUrlFromPath(org.apache.hadoop.fs.Path)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.util.ConverterUtils:getYarnUrlFromPath(org.apache.hadoop.fs.Path)	java.lang.Deprecated
org.apache.hadoop.yarn.util.ConverterUtils:getYarnUrlFromURI(java.net.URI)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.util.ConverterUtils:getYarnUrlFromURI(java.net.URI)	java.lang.Deprecated
org.apache.hadoop.yarn.util.ConverterUtils:toString(org.apache.hadoop.yarn.api.records.ApplicationId)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.util.ConverterUtils:toString(org.apache.hadoop.yarn.api.records.ApplicationId)	java.lang.Deprecated
org.apache.hadoop.yarn.util.ConverterUtils:toApplicationId(org.apache.hadoop.yarn.factories.RecordFactory,java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.util.ConverterUtils:toApplicationId(org.apache.hadoop.yarn.factories.RecordFactory,java.lang.String)	java.lang.Deprecated
org.apache.hadoop.yarn.util.ConverterUtils:toString(org.apache.hadoop.yarn.api.records.ContainerId)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.util.ConverterUtils:toString(org.apache.hadoop.yarn.api.records.ContainerId)	java.lang.Deprecated
org.apache.hadoop.yarn.util.ConverterUtils:toNodeIdWithDefaultPort(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.util.ConverterUtils:toNodeIdWithDefaultPort(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.util.ConverterUtils:toNodeId(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.util.ConverterUtils:toNodeId(java.lang.String)	java.lang.Deprecated
org.apache.hadoop.yarn.util.ConverterUtils:toContainerId(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.util.ConverterUtils:toContainerId(java.lang.String)	java.lang.Deprecated
org.apache.hadoop.yarn.util.ConverterUtils:toApplicationAttemptId(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.util.ConverterUtils:toApplicationAttemptId(java.lang.String)	java.lang.Deprecated
org.apache.hadoop.yarn.util.ConverterUtils:toApplicationId(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.util.ConverterUtils:toApplicationId(java.lang.String)	java.lang.Deprecated
org.apache.hadoop.yarn.util.FSDownload:isPublic(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.fs.Path,org.apache.hadoop.fs.FileStatus,org.apache.hadoop.thirdparty.com.google.common.cache.LoadingCache)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.util.FSDownload:ancestorsHaveExecutePermissions(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.fs.Path,org.apache.hadoop.thirdparty.com.google.common.cache.LoadingCache)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.util.Apps:setEnvFromInputString(java.util.Map,java.lang.String)	java.lang.Deprecated
org.apache.hadoop.yarn.util.Apps:addToEnvironment(java.util.Map,java.lang.String,java.lang.String,java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.util.Apps:addToEnvironment(java.util.Map,java.lang.String,java.lang.String,java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.util.Apps:addToEnvironment(java.util.Map,java.lang.String,java.lang.String)	java.lang.Deprecated
org.apache.hadoop.yarn.util.Apps:shouldCountTowardsNodeBlacklisting(int)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.util.Apps:shouldCountTowardsNodeBlacklisting(int)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.util.SystemClock:<init>()	java.lang.Deprecated
org.apache.hadoop.yarn.util.RackResolver:getDnsToSwitchMapping()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.util.RackResolver:getDnsToSwitchMapping()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.util.RackResolver:reset()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.util.RackResolver:reset()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.util.timeline.TimelineUtils:removeUUID(java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.client.api.TimelineClient:createTimelineClient()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.client.api.TimelineClient:putEntities(org.apache.hadoop.yarn.api.records.timeline.TimelineEntity[])	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.client.api.TimelineClient:putEntities(org.apache.hadoop.yarn.api.records.ApplicationAttemptId,org.apache.hadoop.yarn.api.records.timeline.TimelineEntityGroupId,org.apache.hadoop.yarn.api.records.timeline.TimelineEntity[])	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.client.api.TimelineClient:putDomain(org.apache.hadoop.yarn.api.records.timeline.TimelineDomain)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.client.api.TimelineClient:putDomain(org.apache.hadoop.yarn.api.records.ApplicationAttemptId,org.apache.hadoop.yarn.api.records.timeline.TimelineDomain)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.client.api.TimelineClient:getDelegationToken(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.client.api.TimelineClient:renewDelegationToken(org.apache.hadoop.security.token.Token)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.client.api.TimelineClient:cancelDelegationToken(org.apache.hadoop.security.token.Token)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.client.api.TimelineV2Client:createTimelineClient(org.apache.hadoop.yarn.api.records.ApplicationId)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.client.api.TimelineV2Client:putEntities(org.apache.hadoop.yarn.api.records.timelineservice.TimelineEntity[])	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.client.api.TimelineV2Client:putEntitiesAsync(org.apache.hadoop.yarn.api.records.timelineservice.TimelineEntity[])	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.client.api.TimelineV2Client:putSubAppEntities(org.apache.hadoop.yarn.api.records.timelineservice.TimelineEntity[])	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.client.api.TimelineV2Client:putSubAppEntitiesAsync(org.apache.hadoop.yarn.api.records.timelineservice.TimelineEntity[])	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.client.api.TimelineReaderClient:createTimelineReaderClient()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.client.api.TimelineReaderClient:<init>(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.client.api.AppAdminClient:<init>()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.client.api.AppAdminClient:createAppAdminClient(java.lang.String,org.apache.hadoop.conf.Configuration)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.client.api.AppAdminClient:createAppAdminClient(java.lang.String,org.apache.hadoop.conf.Configuration)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.client.api.AppAdminClient:actionLaunch(java.lang.String,java.lang.String,java.lang.Long,java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.client.api.AppAdminClient:actionLaunch(java.lang.String,java.lang.String,java.lang.Long,java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.client.api.AppAdminClient:actionStop(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.client.api.AppAdminClient:actionStop(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.client.api.AppAdminClient:actionStart(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.client.api.AppAdminClient:actionStart(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.client.api.AppAdminClient:actionSave(java.lang.String,java.lang.String,java.lang.Long,java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.client.api.AppAdminClient:actionSave(java.lang.String,java.lang.String,java.lang.Long,java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.client.api.AppAdminClient:actionDestroy(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.client.api.AppAdminClient:actionDestroy(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.client.api.AppAdminClient:actionFlex(java.lang.String,java.util.Map)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.client.api.AppAdminClient:actionFlex(java.lang.String,java.util.Map)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.client.api.AppAdminClient:enableFastLaunch(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.client.api.AppAdminClient:enableFastLaunch(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.client.api.AppAdminClient:getStatusString(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.client.api.AppAdminClient:getStatusString(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.client.api.AppAdminClient:initiateUpgrade(java.lang.String,java.lang.String,boolean)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.client.api.AppAdminClient:initiateUpgrade(java.lang.String,java.lang.String,boolean)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.client.api.AppAdminClient:actionUpgradeInstances(java.lang.String,java.util.List)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.client.api.AppAdminClient:actionUpgradeInstances(java.lang.String,java.util.List)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.client.api.AppAdminClient:actionUpgradeComponents(java.lang.String,java.util.List)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.client.api.AppAdminClient:actionUpgradeComponents(java.lang.String,java.util.List)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.client.api.AppAdminClient:actionCleanUp(java.lang.String,java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.client.api.AppAdminClient:actionCleanUp(java.lang.String,java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.client.api.AppAdminClient:getInstances(java.lang.String,java.util.List,java.lang.String,java.util.List)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.client.api.AppAdminClient:getInstances(java.lang.String,java.util.List,java.lang.String,java.util.List)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.client.api.AppAdminClient:actionUpgradeExpress(java.lang.String,java.io.File)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.client.api.AppAdminClient:actionUpgradeExpress(java.lang.String,java.io.File)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.client.api.AppAdminClient:actionCancelUpgrade(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.client.api.AppAdminClient:actionCancelUpgrade(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.client.api.AppAdminClient:actionDecommissionInstances(java.lang.String,java.util.List)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.client.api.AppAdminClient:actionDecommissionInstances(java.lang.String,java.util.List)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.client.api.impl.TimelineConnector:createRetryOpForOperateDelegationToken(java.security.PrivilegedExceptionAction)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.client.api.impl.TimelineConnector:createRetryOpForOperateDelegationToken(java.security.PrivilegedExceptionAction)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.client.api.impl.TimelineReaderClientImpl:encodeValue(java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.client.api.impl.TimelineReaderClientImpl:doGetUri(java.net.URI,java.lang.String,javax.ws.rs.core.MultivaluedMap)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.client.api.impl.TimelineClientImpl:createTimelineConnector()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.client.api.impl.TimelineClientImpl:getUgi()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.client.api.impl.TimelineClientImpl:getUgi()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.client.api.impl.TimelineClientImpl:setTimelineWriter(org.apache.hadoop.yarn.client.api.impl.TimelineWriter)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.client.api.impl.TimelineClientImpl:setTimelineWriter(org.apache.hadoop.yarn.client.api.impl.TimelineWriter)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.client.api.impl.TimelineConnector$TimelineClientConnectionRetry:getRetired()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.client.api.impl.TimelineConnector$TimelineClientConnectionRetry:getRetired()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.client.api.impl.TimelineWriter:doPostingObject(java.lang.Object,java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.client.api.impl.TimelineWriter:doPostingObject(java.lang.Object,java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.client.api.impl.TimelineV2ClientImpl:putObjects(java.lang.String,javax.ws.rs.core.MultivaluedMap,java.lang.Object)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.client.AMRMClientUtils:createRMProxy(org.apache.hadoop.conf.Configuration,java.lang.Class,org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.security.token.Token)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.client.AMRMClientUtils:createRMProxy(org.apache.hadoop.conf.Configuration,java.lang.Class,org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.security.token.Token)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.client.ClientRMProxy:getRMAddress(org.apache.hadoop.yarn.conf.YarnConfiguration,java.lang.Class)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.client.ClientRMProxy:checkAllowedProtocols(java.lang.Class)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.client.ClientRMProxy:getRMDelegationTokenService(org.apache.hadoop.conf.Configuration)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.client.ClientRMProxy:getAMRMTokenService(org.apache.hadoop.conf.Configuration)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.client.ClientRMProxy:getTokenService(org.apache.hadoop.conf.Configuration,java.lang.String,java.lang.String,int)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.client.RMProxy:checkAllowedProtocols(java.lang.Class)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.client.RMProxy:getRMAddress(org.apache.hadoop.yarn.conf.YarnConfiguration,java.lang.Class)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.client.RMProxy:createRMProxy(org.apache.hadoop.conf.Configuration,java.lang.Class,org.apache.hadoop.yarn.client.RMProxy)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.client.RMProxy:createRMProxy(org.apache.hadoop.conf.Configuration,java.lang.Class,org.apache.hadoop.yarn.client.RMProxy,long,long)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.client.RMProxy:getProxy(org.apache.hadoop.conf.Configuration,java.lang.Class,java.net.InetSocketAddress)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.client.RMProxy:createRetryPolicy(org.apache.hadoop.conf.Configuration,boolean)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.client.RMProxy:createRetryPolicy(org.apache.hadoop.conf.Configuration,boolean)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
csi.v0.Csi$PluginCapability$TypeCase:valueOf(int)	java.lang.Deprecated
csi.v0.Csi$NodeStageVolumeRequest:getPublishInfo()	java.lang.Deprecated
csi.v0.Csi$NodeStageVolumeRequest:getNodeStageSecrets()	java.lang.Deprecated
csi.v0.Csi$NodeStageVolumeRequest:getVolumeAttributes()	java.lang.Deprecated
csi.v0.Csi$ValidateVolumeCapabilitiesRequest$Builder:getVolumeAttributes()	java.lang.Deprecated
csi.v0.Csi$ValidateVolumeCapabilitiesRequest$Builder:getMutableVolumeAttributes()	java.lang.Deprecated
csi.v0.Csi$DeleteSnapshotRequestOrBuilder:getDeleteSnapshotSecrets()	java.lang.Deprecated
csi.v0.Csi$PluginCapability$Service$Type:valueOf(int)	java.lang.Deprecated
csi.v0.Csi$GetPluginInfoResponse:getManifest()	java.lang.Deprecated
csi.v0.ControllerGrpc:getCreateVolumeMethod()	io.grpc.stub.annotations.RpcMethod	fullMethodName	csi.v0.Controller/CreateVolume
csi.v0.ControllerGrpc:getCreateVolumeMethod()	io.grpc.stub.annotations.RpcMethod	requestType	Lcsi/v0/Csi$CreateVolumeRequest;
csi.v0.ControllerGrpc:getCreateVolumeMethod()	io.grpc.stub.annotations.RpcMethod	responseType	Lcsi/v0/Csi$CreateVolumeResponse;
csi.v0.ControllerGrpc:getCreateVolumeMethod()	io.grpc.stub.annotations.RpcMethod	methodType	UNARY
csi.v0.ControllerGrpc:getDeleteVolumeMethod()	io.grpc.stub.annotations.RpcMethod	fullMethodName	csi.v0.Controller/DeleteVolume
csi.v0.ControllerGrpc:getDeleteVolumeMethod()	io.grpc.stub.annotations.RpcMethod	requestType	Lcsi/v0/Csi$DeleteVolumeRequest;
csi.v0.ControllerGrpc:getDeleteVolumeMethod()	io.grpc.stub.annotations.RpcMethod	responseType	Lcsi/v0/Csi$DeleteVolumeResponse;
csi.v0.ControllerGrpc:getDeleteVolumeMethod()	io.grpc.stub.annotations.RpcMethod	methodType	UNARY
csi.v0.ControllerGrpc:getControllerPublishVolumeMethod()	io.grpc.stub.annotations.RpcMethod	fullMethodName	csi.v0.Controller/ControllerPublishVolume
csi.v0.ControllerGrpc:getControllerPublishVolumeMethod()	io.grpc.stub.annotations.RpcMethod	requestType	Lcsi/v0/Csi$ControllerPublishVolumeRequest;
csi.v0.ControllerGrpc:getControllerPublishVolumeMethod()	io.grpc.stub.annotations.RpcMethod	responseType	Lcsi/v0/Csi$ControllerPublishVolumeResponse;
csi.v0.ControllerGrpc:getControllerPublishVolumeMethod()	io.grpc.stub.annotations.RpcMethod	methodType	UNARY
csi.v0.ControllerGrpc:getControllerUnpublishVolumeMethod()	io.grpc.stub.annotations.RpcMethod	fullMethodName	csi.v0.Controller/ControllerUnpublishVolume
csi.v0.ControllerGrpc:getControllerUnpublishVolumeMethod()	io.grpc.stub.annotations.RpcMethod	requestType	Lcsi/v0/Csi$ControllerUnpublishVolumeRequest;
csi.v0.ControllerGrpc:getControllerUnpublishVolumeMethod()	io.grpc.stub.annotations.RpcMethod	responseType	Lcsi/v0/Csi$ControllerUnpublishVolumeResponse;
csi.v0.ControllerGrpc:getControllerUnpublishVolumeMethod()	io.grpc.stub.annotations.RpcMethod	methodType	UNARY
csi.v0.ControllerGrpc:getValidateVolumeCapabilitiesMethod()	io.grpc.stub.annotations.RpcMethod	fullMethodName	csi.v0.Controller/ValidateVolumeCapabilities
csi.v0.ControllerGrpc:getValidateVolumeCapabilitiesMethod()	io.grpc.stub.annotations.RpcMethod	requestType	Lcsi/v0/Csi$ValidateVolumeCapabilitiesRequest;
csi.v0.ControllerGrpc:getValidateVolumeCapabilitiesMethod()	io.grpc.stub.annotations.RpcMethod	responseType	Lcsi/v0/Csi$ValidateVolumeCapabilitiesResponse;
csi.v0.ControllerGrpc:getValidateVolumeCapabilitiesMethod()	io.grpc.stub.annotations.RpcMethod	methodType	UNARY
csi.v0.ControllerGrpc:getListVolumesMethod()	io.grpc.stub.annotations.RpcMethod	fullMethodName	csi.v0.Controller/ListVolumes
csi.v0.ControllerGrpc:getListVolumesMethod()	io.grpc.stub.annotations.RpcMethod	requestType	Lcsi/v0/Csi$ListVolumesRequest;
csi.v0.ControllerGrpc:getListVolumesMethod()	io.grpc.stub.annotations.RpcMethod	responseType	Lcsi/v0/Csi$ListVolumesResponse;
csi.v0.ControllerGrpc:getListVolumesMethod()	io.grpc.stub.annotations.RpcMethod	methodType	UNARY
csi.v0.ControllerGrpc:getGetCapacityMethod()	io.grpc.stub.annotations.RpcMethod	fullMethodName	csi.v0.Controller/GetCapacity
csi.v0.ControllerGrpc:getGetCapacityMethod()	io.grpc.stub.annotations.RpcMethod	requestType	Lcsi/v0/Csi$GetCapacityRequest;
csi.v0.ControllerGrpc:getGetCapacityMethod()	io.grpc.stub.annotations.RpcMethod	responseType	Lcsi/v0/Csi$GetCapacityResponse;
csi.v0.ControllerGrpc:getGetCapacityMethod()	io.grpc.stub.annotations.RpcMethod	methodType	UNARY
csi.v0.ControllerGrpc:getControllerGetCapabilitiesMethod()	io.grpc.stub.annotations.RpcMethod	fullMethodName	csi.v0.Controller/ControllerGetCapabilities
csi.v0.ControllerGrpc:getControllerGetCapabilitiesMethod()	io.grpc.stub.annotations.RpcMethod	requestType	Lcsi/v0/Csi$ControllerGetCapabilitiesRequest;
csi.v0.ControllerGrpc:getControllerGetCapabilitiesMethod()	io.grpc.stub.annotations.RpcMethod	responseType	Lcsi/v0/Csi$ControllerGetCapabilitiesResponse;
csi.v0.ControllerGrpc:getControllerGetCapabilitiesMethod()	io.grpc.stub.annotations.RpcMethod	methodType	UNARY
csi.v0.ControllerGrpc:getCreateSnapshotMethod()	io.grpc.stub.annotations.RpcMethod	fullMethodName	csi.v0.Controller/CreateSnapshot
csi.v0.ControllerGrpc:getCreateSnapshotMethod()	io.grpc.stub.annotations.RpcMethod	requestType	Lcsi/v0/Csi$CreateSnapshotRequest;
csi.v0.ControllerGrpc:getCreateSnapshotMethod()	io.grpc.stub.annotations.RpcMethod	responseType	Lcsi/v0/Csi$CreateSnapshotResponse;
csi.v0.ControllerGrpc:getCreateSnapshotMethod()	io.grpc.stub.annotations.RpcMethod	methodType	UNARY
csi.v0.ControllerGrpc:getDeleteSnapshotMethod()	io.grpc.stub.annotations.RpcMethod	fullMethodName	csi.v0.Controller/DeleteSnapshot
csi.v0.ControllerGrpc:getDeleteSnapshotMethod()	io.grpc.stub.annotations.RpcMethod	requestType	Lcsi/v0/Csi$DeleteSnapshotRequest;
csi.v0.ControllerGrpc:getDeleteSnapshotMethod()	io.grpc.stub.annotations.RpcMethod	responseType	Lcsi/v0/Csi$DeleteSnapshotResponse;
csi.v0.ControllerGrpc:getDeleteSnapshotMethod()	io.grpc.stub.annotations.RpcMethod	methodType	UNARY
csi.v0.ControllerGrpc:getListSnapshotsMethod()	io.grpc.stub.annotations.RpcMethod	fullMethodName	csi.v0.Controller/ListSnapshots
csi.v0.ControllerGrpc:getListSnapshotsMethod()	io.grpc.stub.annotations.RpcMethod	requestType	Lcsi/v0/Csi$ListSnapshotsRequest;
csi.v0.ControllerGrpc:getListSnapshotsMethod()	io.grpc.stub.annotations.RpcMethod	responseType	Lcsi/v0/Csi$ListSnapshotsResponse;
csi.v0.ControllerGrpc:getListSnapshotsMethod()	io.grpc.stub.annotations.RpcMethod	methodType	UNARY
csi.v0.Csi$ValidateVolumeCapabilitiesRequest:getVolumeAttributes()	java.lang.Deprecated
csi.v0.Csi$ControllerServiceCapability$RPC$Type:valueOf(int)	java.lang.Deprecated
csi.v0.Csi$ControllerServiceCapability$TypeCase:valueOf(int)	java.lang.Deprecated
csi.v0.Csi$CreateVolumeRequestOrBuilder:getParameters()	java.lang.Deprecated
csi.v0.Csi$CreateVolumeRequestOrBuilder:getControllerCreateSecrets()	java.lang.Deprecated
csi.v0.Csi$DeleteSnapshotRequest:getDeleteSnapshotSecrets()	java.lang.Deprecated
csi.v0.NodeGrpc$NodeFutureStub:nodeGetId(csi.v0.Csi$NodeGetIdRequest)	java.lang.Deprecated
csi.v0.Csi$VolumeCapability$AccessMode$Mode:valueOf(int)	java.lang.Deprecated
csi.v0.Csi$ControllerUnpublishVolumeRequestOrBuilder:getControllerUnpublishSecrets()	java.lang.Deprecated
csi.v0.NodeGrpc$NodeBlockingStub:nodeGetId(csi.v0.Csi$NodeGetIdRequest)	java.lang.Deprecated
csi.v0.Csi$ControllerPublishVolumeRequest$Builder:getControllerPublishSecrets()	java.lang.Deprecated
csi.v0.Csi$ControllerPublishVolumeRequest$Builder:getMutableControllerPublishSecrets()	java.lang.Deprecated
csi.v0.Csi$ControllerPublishVolumeRequest$Builder:getVolumeAttributes()	java.lang.Deprecated
csi.v0.Csi$ControllerPublishVolumeRequest$Builder:getMutableVolumeAttributes()	java.lang.Deprecated
csi.v0.Csi$NodePublishVolumeRequestOrBuilder:getPublishInfo()	java.lang.Deprecated
csi.v0.Csi$NodePublishVolumeRequestOrBuilder:getNodePublishSecrets()	java.lang.Deprecated
csi.v0.Csi$NodePublishVolumeRequestOrBuilder:getVolumeAttributes()	java.lang.Deprecated
csi.v0.Csi$CreateSnapshotRequestOrBuilder:getCreateSnapshotSecrets()	java.lang.Deprecated
csi.v0.Csi$CreateSnapshotRequestOrBuilder:getParameters()	java.lang.Deprecated
csi.v0.Csi$DeleteVolumeRequestOrBuilder:getControllerDeleteSecrets()	java.lang.Deprecated
csi.v0.Csi$CreateSnapshotRequest:getCreateSnapshotSecrets()	java.lang.Deprecated
csi.v0.Csi$CreateSnapshotRequest:getParameters()	java.lang.Deprecated
csi.v0.Csi$ControllerPublishVolumeResponse$Builder:getPublishInfo()	java.lang.Deprecated
csi.v0.Csi$ControllerPublishVolumeResponse$Builder:getMutablePublishInfo()	java.lang.Deprecated
csi.v0.Csi$GetCapacityRequest$Builder:getParameters()	java.lang.Deprecated
csi.v0.Csi$GetCapacityRequest$Builder:getMutableParameters()	java.lang.Deprecated
csi.v0.Csi$ControllerPublishVolumeResponse:getPublishInfo()	java.lang.Deprecated
csi.v0.Csi$NodeStageVolumeRequest$Builder:getPublishInfo()	java.lang.Deprecated
csi.v0.Csi$NodeStageVolumeRequest$Builder:getMutablePublishInfo()	java.lang.Deprecated
csi.v0.Csi$NodeStageVolumeRequest$Builder:getNodeStageSecrets()	java.lang.Deprecated
csi.v0.Csi$NodeStageVolumeRequest$Builder:getMutableNodeStageSecrets()	java.lang.Deprecated
csi.v0.Csi$NodeStageVolumeRequest$Builder:getVolumeAttributes()	java.lang.Deprecated
csi.v0.Csi$NodeStageVolumeRequest$Builder:getMutableVolumeAttributes()	java.lang.Deprecated
csi.v0.Csi$VolumeCapability$AccessTypeCase:valueOf(int)	java.lang.Deprecated
csi.v0.Csi$Topology:getSegments()	java.lang.Deprecated
csi.v0.Csi$DeleteVolumeRequest:getControllerDeleteSecrets()	java.lang.Deprecated
csi.v0.NodeGrpc$NodeStub:nodeGetId(csi.v0.Csi$NodeGetIdRequest,io.grpc.stub.StreamObserver)	java.lang.Deprecated
csi.v0.Csi$ValidateVolumeCapabilitiesRequestOrBuilder:getVolumeAttributes()	java.lang.Deprecated
csi.v0.Csi$CreateVolumeRequest:getParameters()	java.lang.Deprecated
csi.v0.Csi$CreateVolumeRequest:getControllerCreateSecrets()	java.lang.Deprecated
csi.v0.Csi$CreateVolumeRequest$Builder:getParameters()	java.lang.Deprecated
csi.v0.Csi$CreateVolumeRequest$Builder:getMutableParameters()	java.lang.Deprecated
csi.v0.Csi$CreateVolumeRequest$Builder:getControllerCreateSecrets()	java.lang.Deprecated
csi.v0.Csi$CreateVolumeRequest$Builder:getMutableControllerCreateSecrets()	java.lang.Deprecated
csi.v0.Csi$Topology$Builder:getSegments()	java.lang.Deprecated
csi.v0.Csi$Topology$Builder:getMutableSegments()	java.lang.Deprecated
csi.v0.Csi$NodeStageVolumeRequestOrBuilder:getPublishInfo()	java.lang.Deprecated
csi.v0.Csi$NodeStageVolumeRequestOrBuilder:getNodeStageSecrets()	java.lang.Deprecated
csi.v0.Csi$NodeStageVolumeRequestOrBuilder:getVolumeAttributes()	java.lang.Deprecated
csi.v0.Csi$SnapshotStatus$Type:valueOf(int)	java.lang.Deprecated
csi.v0.NodeGrpc:getNodeStageVolumeMethod()	io.grpc.stub.annotations.RpcMethod	fullMethodName	csi.v0.Node/NodeStageVolume
csi.v0.NodeGrpc:getNodeStageVolumeMethod()	io.grpc.stub.annotations.RpcMethod	requestType	Lcsi/v0/Csi$NodeStageVolumeRequest;
csi.v0.NodeGrpc:getNodeStageVolumeMethod()	io.grpc.stub.annotations.RpcMethod	responseType	Lcsi/v0/Csi$NodeStageVolumeResponse;
csi.v0.NodeGrpc:getNodeStageVolumeMethod()	io.grpc.stub.annotations.RpcMethod	methodType	UNARY
csi.v0.NodeGrpc:getNodeUnstageVolumeMethod()	io.grpc.stub.annotations.RpcMethod	fullMethodName	csi.v0.Node/NodeUnstageVolume
csi.v0.NodeGrpc:getNodeUnstageVolumeMethod()	io.grpc.stub.annotations.RpcMethod	requestType	Lcsi/v0/Csi$NodeUnstageVolumeRequest;
csi.v0.NodeGrpc:getNodeUnstageVolumeMethod()	io.grpc.stub.annotations.RpcMethod	responseType	Lcsi/v0/Csi$NodeUnstageVolumeResponse;
csi.v0.NodeGrpc:getNodeUnstageVolumeMethod()	io.grpc.stub.annotations.RpcMethod	methodType	UNARY
csi.v0.NodeGrpc:getNodePublishVolumeMethod()	io.grpc.stub.annotations.RpcMethod	fullMethodName	csi.v0.Node/NodePublishVolume
csi.v0.NodeGrpc:getNodePublishVolumeMethod()	io.grpc.stub.annotations.RpcMethod	requestType	Lcsi/v0/Csi$NodePublishVolumeRequest;
csi.v0.NodeGrpc:getNodePublishVolumeMethod()	io.grpc.stub.annotations.RpcMethod	responseType	Lcsi/v0/Csi$NodePublishVolumeResponse;
csi.v0.NodeGrpc:getNodePublishVolumeMethod()	io.grpc.stub.annotations.RpcMethod	methodType	UNARY
csi.v0.NodeGrpc:getNodeUnpublishVolumeMethod()	io.grpc.stub.annotations.RpcMethod	fullMethodName	csi.v0.Node/NodeUnpublishVolume
csi.v0.NodeGrpc:getNodeUnpublishVolumeMethod()	io.grpc.stub.annotations.RpcMethod	requestType	Lcsi/v0/Csi$NodeUnpublishVolumeRequest;
csi.v0.NodeGrpc:getNodeUnpublishVolumeMethod()	io.grpc.stub.annotations.RpcMethod	responseType	Lcsi/v0/Csi$NodeUnpublishVolumeResponse;
csi.v0.NodeGrpc:getNodeUnpublishVolumeMethod()	io.grpc.stub.annotations.RpcMethod	methodType	UNARY
csi.v0.NodeGrpc:getNodeGetIdMethod()	io.grpc.stub.annotations.RpcMethod	fullMethodName	csi.v0.Node/NodeGetId
csi.v0.NodeGrpc:getNodeGetIdMethod()	io.grpc.stub.annotations.RpcMethod	requestType	Lcsi/v0/Csi$NodeGetIdRequest;
csi.v0.NodeGrpc:getNodeGetIdMethod()	io.grpc.stub.annotations.RpcMethod	responseType	Lcsi/v0/Csi$NodeGetIdResponse;
csi.v0.NodeGrpc:getNodeGetIdMethod()	io.grpc.stub.annotations.RpcMethod	methodType	UNARY
csi.v0.NodeGrpc:getNodeGetCapabilitiesMethod()	io.grpc.stub.annotations.RpcMethod	fullMethodName	csi.v0.Node/NodeGetCapabilities
csi.v0.NodeGrpc:getNodeGetCapabilitiesMethod()	io.grpc.stub.annotations.RpcMethod	requestType	Lcsi/v0/Csi$NodeGetCapabilitiesRequest;
csi.v0.NodeGrpc:getNodeGetCapabilitiesMethod()	io.grpc.stub.annotations.RpcMethod	responseType	Lcsi/v0/Csi$NodeGetCapabilitiesResponse;
csi.v0.NodeGrpc:getNodeGetCapabilitiesMethod()	io.grpc.stub.annotations.RpcMethod	methodType	UNARY
csi.v0.NodeGrpc:getNodeGetInfoMethod()	io.grpc.stub.annotations.RpcMethod	fullMethodName	csi.v0.Node/NodeGetInfo
csi.v0.NodeGrpc:getNodeGetInfoMethod()	io.grpc.stub.annotations.RpcMethod	requestType	Lcsi/v0/Csi$NodeGetInfoRequest;
csi.v0.NodeGrpc:getNodeGetInfoMethod()	io.grpc.stub.annotations.RpcMethod	responseType	Lcsi/v0/Csi$NodeGetInfoResponse;
csi.v0.NodeGrpc:getNodeGetInfoMethod()	io.grpc.stub.annotations.RpcMethod	methodType	UNARY
csi.v0.Csi$VolumeOrBuilder:getAttributes()	java.lang.Deprecated
csi.v0.Csi$Volume$Builder:getAttributes()	java.lang.Deprecated
csi.v0.Csi$Volume$Builder:getMutableAttributes()	java.lang.Deprecated
csi.v0.Csi$ControllerPublishVolumeRequest:getControllerPublishSecrets()	java.lang.Deprecated
csi.v0.Csi$ControllerPublishVolumeRequest:getVolumeAttributes()	java.lang.Deprecated
csi.v0.Csi$ControllerPublishVolumeResponseOrBuilder:getPublishInfo()	java.lang.Deprecated
csi.v0.Csi$NodePublishVolumeRequest:getPublishInfo()	java.lang.Deprecated
csi.v0.Csi$NodePublishVolumeRequest:getNodePublishSecrets()	java.lang.Deprecated
csi.v0.Csi$NodePublishVolumeRequest:getVolumeAttributes()	java.lang.Deprecated
csi.v0.Csi$NodeServiceCapability$TypeCase:valueOf(int)	java.lang.Deprecated
csi.v0.Csi$TopologyOrBuilder:getSegments()	java.lang.Deprecated
csi.v0.Csi$ControllerPublishVolumeRequestOrBuilder:getControllerPublishSecrets()	java.lang.Deprecated
csi.v0.Csi$ControllerPublishVolumeRequestOrBuilder:getVolumeAttributes()	java.lang.Deprecated
csi.v0.Csi$GetCapacityRequestOrBuilder:getParameters()	java.lang.Deprecated
csi.v0.Csi$VolumeContentSource$TypeCase:valueOf(int)	java.lang.Deprecated
csi.v0.Csi$GetPluginInfoResponse$Builder:getManifest()	java.lang.Deprecated
csi.v0.Csi$GetPluginInfoResponse$Builder:getMutableManifest()	java.lang.Deprecated
csi.v0.NodeGrpc$NodeImplBase:nodeGetId(csi.v0.Csi$NodeGetIdRequest,io.grpc.stub.StreamObserver)	java.lang.Deprecated
csi.v0.Csi$ControllerUnpublishVolumeRequest:getControllerUnpublishSecrets()	java.lang.Deprecated
csi.v0.Csi$GetPluginInfoResponseOrBuilder:getManifest()	java.lang.Deprecated
csi.v0.Csi$Volume:getAttributes()	java.lang.Deprecated
csi.v0.Csi$NodePublishVolumeRequest$Builder:getPublishInfo()	java.lang.Deprecated
csi.v0.Csi$NodePublishVolumeRequest$Builder:getMutablePublishInfo()	java.lang.Deprecated
csi.v0.Csi$NodePublishVolumeRequest$Builder:getNodePublishSecrets()	java.lang.Deprecated
csi.v0.Csi$NodePublishVolumeRequest$Builder:getMutableNodePublishSecrets()	java.lang.Deprecated
csi.v0.Csi$NodePublishVolumeRequest$Builder:getVolumeAttributes()	java.lang.Deprecated
csi.v0.Csi$NodePublishVolumeRequest$Builder:getMutableVolumeAttributes()	java.lang.Deprecated
csi.v0.Csi$DeleteVolumeRequest$Builder:getControllerDeleteSecrets()	java.lang.Deprecated
csi.v0.Csi$DeleteVolumeRequest$Builder:getMutableControllerDeleteSecrets()	java.lang.Deprecated
csi.v0.Csi$DeleteSnapshotRequest$Builder:getDeleteSnapshotSecrets()	java.lang.Deprecated
csi.v0.Csi$DeleteSnapshotRequest$Builder:getMutableDeleteSnapshotSecrets()	java.lang.Deprecated
csi.v0.Csi$NodeServiceCapability$RPC$Type:valueOf(int)	java.lang.Deprecated
csi.v0.Csi$GetCapacityRequest:getParameters()	java.lang.Deprecated
csi.v0.Csi$ControllerUnpublishVolumeRequest$Builder:getControllerUnpublishSecrets()	java.lang.Deprecated
csi.v0.Csi$ControllerUnpublishVolumeRequest$Builder:getMutableControllerUnpublishSecrets()	java.lang.Deprecated
csi.v0.Csi$CreateSnapshotRequest$Builder:getCreateSnapshotSecrets()	java.lang.Deprecated
csi.v0.Csi$CreateSnapshotRequest$Builder:getMutableCreateSnapshotSecrets()	java.lang.Deprecated
csi.v0.Csi$CreateSnapshotRequest$Builder:getParameters()	java.lang.Deprecated
csi.v0.Csi$CreateSnapshotRequest$Builder:getMutableParameters()	java.lang.Deprecated
csi.v0.IdentityGrpc:getGetPluginInfoMethod()	io.grpc.stub.annotations.RpcMethod	fullMethodName	csi.v0.Identity/GetPluginInfo
csi.v0.IdentityGrpc:getGetPluginInfoMethod()	io.grpc.stub.annotations.RpcMethod	requestType	Lcsi/v0/Csi$GetPluginInfoRequest;
csi.v0.IdentityGrpc:getGetPluginInfoMethod()	io.grpc.stub.annotations.RpcMethod	responseType	Lcsi/v0/Csi$GetPluginInfoResponse;
csi.v0.IdentityGrpc:getGetPluginInfoMethod()	io.grpc.stub.annotations.RpcMethod	methodType	UNARY
csi.v0.IdentityGrpc:getGetPluginCapabilitiesMethod()	io.grpc.stub.annotations.RpcMethod	fullMethodName	csi.v0.Identity/GetPluginCapabilities
csi.v0.IdentityGrpc:getGetPluginCapabilitiesMethod()	io.grpc.stub.annotations.RpcMethod	requestType	Lcsi/v0/Csi$GetPluginCapabilitiesRequest;
csi.v0.IdentityGrpc:getGetPluginCapabilitiesMethod()	io.grpc.stub.annotations.RpcMethod	responseType	Lcsi/v0/Csi$GetPluginCapabilitiesResponse;
csi.v0.IdentityGrpc:getGetPluginCapabilitiesMethod()	io.grpc.stub.annotations.RpcMethod	methodType	UNARY
csi.v0.IdentityGrpc:getProbeMethod()	io.grpc.stub.annotations.RpcMethod	fullMethodName	csi.v0.Identity/Probe
csi.v0.IdentityGrpc:getProbeMethod()	io.grpc.stub.annotations.RpcMethod	requestType	Lcsi/v0/Csi$ProbeRequest;
csi.v0.IdentityGrpc:getProbeMethod()	io.grpc.stub.annotations.RpcMethod	responseType	Lcsi/v0/Csi$ProbeResponse;
csi.v0.IdentityGrpc:getProbeMethod()	io.grpc.stub.annotations.RpcMethod	methodType	UNARY
org.apache.hadoop.yarn.server.applicationhistoryservice.ApplicationHistoryClientService:getBindAddress()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.applicationhistoryservice.ApplicationHistoryManagerImpl:getHistoryStore()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.applicationhistoryservice.ApplicationHistoryManagerImpl:getHistoryStore()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationFinishData:newInstance(org.apache.hadoop.yarn.api.records.ApplicationId,long,java.lang.String,org.apache.hadoop.yarn.api.records.FinalApplicationStatus,org.apache.hadoop.yarn.api.records.YarnApplicationState)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationFinishData:newInstance(org.apache.hadoop.yarn.api.records.ApplicationId,long,java.lang.String,org.apache.hadoop.yarn.api.records.FinalApplicationStatus,org.apache.hadoop.yarn.api.records.YarnApplicationState)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationFinishData:getApplicationId()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationFinishData:getApplicationId()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationFinishData:setApplicationId(org.apache.hadoop.yarn.api.records.ApplicationId)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationFinishData:setApplicationId(org.apache.hadoop.yarn.api.records.ApplicationId)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationFinishData:getFinishTime()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationFinishData:getFinishTime()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationFinishData:setFinishTime(long)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationFinishData:setFinishTime(long)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationFinishData:getDiagnosticsInfo()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationFinishData:getDiagnosticsInfo()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationFinishData:setDiagnosticsInfo(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationFinishData:setDiagnosticsInfo(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationFinishData:getFinalApplicationStatus()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationFinishData:getFinalApplicationStatus()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationFinishData:setFinalApplicationStatus(org.apache.hadoop.yarn.api.records.FinalApplicationStatus)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationFinishData:setFinalApplicationStatus(org.apache.hadoop.yarn.api.records.FinalApplicationStatus)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationFinishData:getYarnApplicationState()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationFinishData:getYarnApplicationState()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationFinishData:setYarnApplicationState(org.apache.hadoop.yarn.api.records.YarnApplicationState)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationFinishData:setYarnApplicationState(org.apache.hadoop.yarn.api.records.YarnApplicationState)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationHistoryData:newInstance(org.apache.hadoop.yarn.api.records.ApplicationId,java.lang.String,java.lang.String,java.lang.String,java.lang.String,long,long,long,java.lang.String,org.apache.hadoop.yarn.api.records.FinalApplicationStatus,org.apache.hadoop.yarn.api.records.YarnApplicationState)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationHistoryData:newInstance(org.apache.hadoop.yarn.api.records.ApplicationId,java.lang.String,java.lang.String,java.lang.String,java.lang.String,long,long,long,java.lang.String,org.apache.hadoop.yarn.api.records.FinalApplicationStatus,org.apache.hadoop.yarn.api.records.YarnApplicationState)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationHistoryData:getApplicationId()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationHistoryData:getApplicationId()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationHistoryData:setApplicationId(org.apache.hadoop.yarn.api.records.ApplicationId)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationHistoryData:setApplicationId(org.apache.hadoop.yarn.api.records.ApplicationId)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationHistoryData:getApplicationName()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationHistoryData:getApplicationName()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationHistoryData:setApplicationName(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationHistoryData:setApplicationName(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationHistoryData:getApplicationType()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationHistoryData:getApplicationType()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationHistoryData:setApplicationType(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationHistoryData:setApplicationType(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationHistoryData:getUser()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationHistoryData:getUser()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationHistoryData:setUser(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationHistoryData:setUser(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationHistoryData:getQueue()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationHistoryData:getQueue()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationHistoryData:setQueue(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationHistoryData:setQueue(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationHistoryData:getSubmitTime()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationHistoryData:getSubmitTime()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationHistoryData:setSubmitTime(long)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationHistoryData:setSubmitTime(long)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationHistoryData:getStartTime()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationHistoryData:getStartTime()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationHistoryData:setStartTime(long)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationHistoryData:setStartTime(long)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationHistoryData:getFinishTime()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationHistoryData:getFinishTime()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationHistoryData:setFinishTime(long)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationHistoryData:setFinishTime(long)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationHistoryData:getDiagnosticsInfo()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationHistoryData:getDiagnosticsInfo()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationHistoryData:setDiagnosticsInfo(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationHistoryData:setDiagnosticsInfo(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationHistoryData:getFinalApplicationStatus()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationHistoryData:getFinalApplicationStatus()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationHistoryData:setFinalApplicationStatus(org.apache.hadoop.yarn.api.records.FinalApplicationStatus)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationHistoryData:setFinalApplicationStatus(org.apache.hadoop.yarn.api.records.FinalApplicationStatus)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationHistoryData:getYarnApplicationState()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationHistoryData:getYarnApplicationState()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationHistoryData:setYarnApplicationState(org.apache.hadoop.yarn.api.records.YarnApplicationState)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationHistoryData:setYarnApplicationState(org.apache.hadoop.yarn.api.records.YarnApplicationState)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ContainerHistoryData:newInstance(org.apache.hadoop.yarn.api.records.ContainerId,org.apache.hadoop.yarn.api.records.Resource,org.apache.hadoop.yarn.api.records.NodeId,org.apache.hadoop.yarn.api.records.Priority,long,long,java.lang.String,int,org.apache.hadoop.yarn.api.records.ContainerState)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ContainerHistoryData:newInstance(org.apache.hadoop.yarn.api.records.ContainerId,org.apache.hadoop.yarn.api.records.Resource,org.apache.hadoop.yarn.api.records.NodeId,org.apache.hadoop.yarn.api.records.Priority,long,long,java.lang.String,int,org.apache.hadoop.yarn.api.records.ContainerState)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ContainerHistoryData:getContainerId()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ContainerHistoryData:getContainerId()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ContainerHistoryData:setContainerId(org.apache.hadoop.yarn.api.records.ContainerId)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ContainerHistoryData:setContainerId(org.apache.hadoop.yarn.api.records.ContainerId)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ContainerHistoryData:getAllocatedResource()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ContainerHistoryData:getAllocatedResource()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ContainerHistoryData:setAllocatedResource(org.apache.hadoop.yarn.api.records.Resource)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ContainerHistoryData:setAllocatedResource(org.apache.hadoop.yarn.api.records.Resource)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ContainerHistoryData:getAssignedNode()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ContainerHistoryData:getAssignedNode()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ContainerHistoryData:setAssignedNode(org.apache.hadoop.yarn.api.records.NodeId)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ContainerHistoryData:setAssignedNode(org.apache.hadoop.yarn.api.records.NodeId)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ContainerHistoryData:getPriority()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ContainerHistoryData:getPriority()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ContainerHistoryData:setPriority(org.apache.hadoop.yarn.api.records.Priority)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ContainerHistoryData:setPriority(org.apache.hadoop.yarn.api.records.Priority)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ContainerHistoryData:getStartTime()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ContainerHistoryData:getStartTime()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ContainerHistoryData:setStartTime(long)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ContainerHistoryData:setStartTime(long)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ContainerHistoryData:getFinishTime()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ContainerHistoryData:getFinishTime()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ContainerHistoryData:setFinishTime(long)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ContainerHistoryData:setFinishTime(long)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ContainerHistoryData:getDiagnosticsInfo()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ContainerHistoryData:getDiagnosticsInfo()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ContainerHistoryData:setDiagnosticsInfo(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ContainerHistoryData:setDiagnosticsInfo(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ContainerHistoryData:getContainerExitStatus()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ContainerHistoryData:getContainerExitStatus()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ContainerHistoryData:setContainerExitStatus(int)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ContainerHistoryData:setContainerExitStatus(int)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ContainerHistoryData:getContainerState()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ContainerHistoryData:getContainerState()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ContainerHistoryData:setContainerState(org.apache.hadoop.yarn.api.records.ContainerState)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ContainerHistoryData:setContainerState(org.apache.hadoop.yarn.api.records.ContainerState)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ContainerFinishData:newInstance(org.apache.hadoop.yarn.api.records.ContainerId,long,java.lang.String,int,org.apache.hadoop.yarn.api.records.ContainerState)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ContainerFinishData:newInstance(org.apache.hadoop.yarn.api.records.ContainerId,long,java.lang.String,int,org.apache.hadoop.yarn.api.records.ContainerState)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ContainerFinishData:getContainerId()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ContainerFinishData:getContainerId()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ContainerFinishData:setContainerId(org.apache.hadoop.yarn.api.records.ContainerId)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ContainerFinishData:setContainerId(org.apache.hadoop.yarn.api.records.ContainerId)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ContainerFinishData:getFinishTime()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ContainerFinishData:getFinishTime()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ContainerFinishData:setFinishTime(long)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ContainerFinishData:setFinishTime(long)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ContainerFinishData:getDiagnosticsInfo()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ContainerFinishData:getDiagnosticsInfo()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ContainerFinishData:setDiagnosticsInfo(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ContainerFinishData:setDiagnosticsInfo(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ContainerFinishData:getContainerExitStatus()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ContainerFinishData:getContainerExitStatus()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ContainerFinishData:setContainerExitStatus(int)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ContainerFinishData:setContainerExitStatus(int)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ContainerFinishData:getContainerState()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ContainerFinishData:getContainerState()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ContainerFinishData:setContainerState(org.apache.hadoop.yarn.api.records.ContainerState)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ContainerFinishData:setContainerState(org.apache.hadoop.yarn.api.records.ContainerState)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationAttemptStartData:newInstance(org.apache.hadoop.yarn.api.records.ApplicationAttemptId,java.lang.String,int,org.apache.hadoop.yarn.api.records.ContainerId)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationAttemptStartData:newInstance(org.apache.hadoop.yarn.api.records.ApplicationAttemptId,java.lang.String,int,org.apache.hadoop.yarn.api.records.ContainerId)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationAttemptStartData:getApplicationAttemptId()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationAttemptStartData:getApplicationAttemptId()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationAttemptStartData:setApplicationAttemptId(org.apache.hadoop.yarn.api.records.ApplicationAttemptId)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationAttemptStartData:setApplicationAttemptId(org.apache.hadoop.yarn.api.records.ApplicationAttemptId)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationAttemptStartData:getHost()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationAttemptStartData:getHost()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationAttemptStartData:setHost(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationAttemptStartData:setHost(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationAttemptStartData:getRPCPort()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationAttemptStartData:getRPCPort()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationAttemptStartData:setRPCPort(int)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationAttemptStartData:setRPCPort(int)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationAttemptStartData:getMasterContainerId()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationAttemptStartData:getMasterContainerId()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationAttemptStartData:setMasterContainerId(org.apache.hadoop.yarn.api.records.ContainerId)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationAttemptStartData:setMasterContainerId(org.apache.hadoop.yarn.api.records.ContainerId)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationStartData:newInstance(org.apache.hadoop.yarn.api.records.ApplicationId,java.lang.String,java.lang.String,java.lang.String,java.lang.String,long,long)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationStartData:newInstance(org.apache.hadoop.yarn.api.records.ApplicationId,java.lang.String,java.lang.String,java.lang.String,java.lang.String,long,long)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationStartData:getApplicationId()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationStartData:getApplicationId()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationStartData:setApplicationId(org.apache.hadoop.yarn.api.records.ApplicationId)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationStartData:setApplicationId(org.apache.hadoop.yarn.api.records.ApplicationId)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationStartData:getApplicationName()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationStartData:getApplicationName()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationStartData:setApplicationName(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationStartData:setApplicationName(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationStartData:getApplicationType()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationStartData:getApplicationType()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationStartData:setApplicationType(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationStartData:setApplicationType(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationStartData:getUser()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationStartData:getUser()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationStartData:setUser(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationStartData:setUser(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationStartData:getQueue()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationStartData:getQueue()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationStartData:setQueue(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationStartData:setQueue(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationStartData:getSubmitTime()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationStartData:getSubmitTime()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationStartData:setSubmitTime(long)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationStartData:setSubmitTime(long)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationStartData:getStartTime()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationStartData:getStartTime()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationStartData:setStartTime(long)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationStartData:setStartTime(long)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationAttemptFinishData:newInstance(org.apache.hadoop.yarn.api.records.ApplicationAttemptId,java.lang.String,java.lang.String,org.apache.hadoop.yarn.api.records.FinalApplicationStatus,org.apache.hadoop.yarn.api.records.YarnApplicationAttemptState)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationAttemptFinishData:newInstance(org.apache.hadoop.yarn.api.records.ApplicationAttemptId,java.lang.String,java.lang.String,org.apache.hadoop.yarn.api.records.FinalApplicationStatus,org.apache.hadoop.yarn.api.records.YarnApplicationAttemptState)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationAttemptFinishData:getApplicationAttemptId()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationAttemptFinishData:getApplicationAttemptId()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationAttemptFinishData:setApplicationAttemptId(org.apache.hadoop.yarn.api.records.ApplicationAttemptId)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationAttemptFinishData:setApplicationAttemptId(org.apache.hadoop.yarn.api.records.ApplicationAttemptId)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationAttemptFinishData:getTrackingURL()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationAttemptFinishData:getTrackingURL()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationAttemptFinishData:setTrackingURL(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationAttemptFinishData:setTrackingURL(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationAttemptFinishData:getDiagnosticsInfo()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationAttemptFinishData:getDiagnosticsInfo()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationAttemptFinishData:setDiagnosticsInfo(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationAttemptFinishData:setDiagnosticsInfo(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationAttemptFinishData:getFinalApplicationStatus()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationAttemptFinishData:getFinalApplicationStatus()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationAttemptFinishData:setFinalApplicationStatus(org.apache.hadoop.yarn.api.records.FinalApplicationStatus)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationAttemptFinishData:setFinalApplicationStatus(org.apache.hadoop.yarn.api.records.FinalApplicationStatus)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationAttemptFinishData:getYarnApplicationAttemptState()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationAttemptFinishData:getYarnApplicationAttemptState()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationAttemptFinishData:setYarnApplicationAttemptState(org.apache.hadoop.yarn.api.records.YarnApplicationAttemptState)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationAttemptFinishData:setYarnApplicationAttemptState(org.apache.hadoop.yarn.api.records.YarnApplicationAttemptState)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationAttemptHistoryData:newInstance(org.apache.hadoop.yarn.api.records.ApplicationAttemptId,java.lang.String,int,org.apache.hadoop.yarn.api.records.ContainerId,java.lang.String,java.lang.String,org.apache.hadoop.yarn.api.records.FinalApplicationStatus,org.apache.hadoop.yarn.api.records.YarnApplicationAttemptState)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationAttemptHistoryData:newInstance(org.apache.hadoop.yarn.api.records.ApplicationAttemptId,java.lang.String,int,org.apache.hadoop.yarn.api.records.ContainerId,java.lang.String,java.lang.String,org.apache.hadoop.yarn.api.records.FinalApplicationStatus,org.apache.hadoop.yarn.api.records.YarnApplicationAttemptState)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationAttemptHistoryData:getApplicationAttemptId()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationAttemptHistoryData:getApplicationAttemptId()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationAttemptHistoryData:setApplicationAttemptId(org.apache.hadoop.yarn.api.records.ApplicationAttemptId)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationAttemptHistoryData:setApplicationAttemptId(org.apache.hadoop.yarn.api.records.ApplicationAttemptId)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationAttemptHistoryData:getHost()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationAttemptHistoryData:getHost()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationAttemptHistoryData:setHost(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationAttemptHistoryData:setHost(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationAttemptHistoryData:getRPCPort()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationAttemptHistoryData:getRPCPort()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationAttemptHistoryData:setRPCPort(int)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationAttemptHistoryData:setRPCPort(int)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationAttemptHistoryData:getTrackingURL()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationAttemptHistoryData:getTrackingURL()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationAttemptHistoryData:setTrackingURL(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationAttemptHistoryData:setTrackingURL(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationAttemptHistoryData:getDiagnosticsInfo()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationAttemptHistoryData:getDiagnosticsInfo()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationAttemptHistoryData:setDiagnosticsInfo(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationAttemptHistoryData:setDiagnosticsInfo(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationAttemptHistoryData:getFinalApplicationStatus()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationAttemptHistoryData:getFinalApplicationStatus()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationAttemptHistoryData:setFinalApplicationStatus(org.apache.hadoop.yarn.api.records.FinalApplicationStatus)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationAttemptHistoryData:setFinalApplicationStatus(org.apache.hadoop.yarn.api.records.FinalApplicationStatus)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationAttemptHistoryData:getMasterContainerId()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationAttemptHistoryData:getMasterContainerId()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationAttemptHistoryData:setMasterContainerId(org.apache.hadoop.yarn.api.records.ContainerId)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationAttemptHistoryData:setMasterContainerId(org.apache.hadoop.yarn.api.records.ContainerId)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationAttemptHistoryData:getYarnApplicationAttemptState()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationAttemptHistoryData:getYarnApplicationAttemptState()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationAttemptHistoryData:setYarnApplicationAttemptState(org.apache.hadoop.yarn.api.records.YarnApplicationAttemptState)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationAttemptHistoryData:setYarnApplicationAttemptState(org.apache.hadoop.yarn.api.records.YarnApplicationAttemptState)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ContainerStartData:newInstance(org.apache.hadoop.yarn.api.records.ContainerId,org.apache.hadoop.yarn.api.records.Resource,org.apache.hadoop.yarn.api.records.NodeId,org.apache.hadoop.yarn.api.records.Priority,long)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ContainerStartData:newInstance(org.apache.hadoop.yarn.api.records.ContainerId,org.apache.hadoop.yarn.api.records.Resource,org.apache.hadoop.yarn.api.records.NodeId,org.apache.hadoop.yarn.api.records.Priority,long)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ContainerStartData:getContainerId()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ContainerStartData:getContainerId()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ContainerStartData:setContainerId(org.apache.hadoop.yarn.api.records.ContainerId)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ContainerStartData:setContainerId(org.apache.hadoop.yarn.api.records.ContainerId)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ContainerStartData:getAllocatedResource()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ContainerStartData:getAllocatedResource()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ContainerStartData:setAllocatedResource(org.apache.hadoop.yarn.api.records.Resource)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ContainerStartData:setAllocatedResource(org.apache.hadoop.yarn.api.records.Resource)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ContainerStartData:getAssignedNode()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ContainerStartData:getAssignedNode()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ContainerStartData:setAssignedNode(org.apache.hadoop.yarn.api.records.NodeId)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ContainerStartData:setAssignedNode(org.apache.hadoop.yarn.api.records.NodeId)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ContainerStartData:getPriority()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ContainerStartData:getPriority()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ContainerStartData:setPriority(org.apache.hadoop.yarn.api.records.Priority)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ContainerStartData:setPriority(org.apache.hadoop.yarn.api.records.Priority)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ContainerStartData:getStartTime()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ContainerStartData:getStartTime()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ContainerStartData:setStartTime(long)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ContainerStartData:setStartTime(long)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.ApplicationHistoryManager:getApplication(org.apache.hadoop.yarn.api.records.ApplicationId)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.ApplicationHistoryManager:getApplication(org.apache.hadoop.yarn.api.records.ApplicationId)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.ApplicationHistoryManager:getApplications(long,long,long)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.ApplicationHistoryManager:getApplications(long,long,long)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.ApplicationHistoryManager:getApplicationAttempts(org.apache.hadoop.yarn.api.records.ApplicationId)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.ApplicationHistoryManager:getApplicationAttempts(org.apache.hadoop.yarn.api.records.ApplicationId)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.ApplicationHistoryManager:getApplicationAttempt(org.apache.hadoop.yarn.api.records.ApplicationAttemptId)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.ApplicationHistoryManager:getApplicationAttempt(org.apache.hadoop.yarn.api.records.ApplicationAttemptId)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.ApplicationHistoryManager:getContainer(org.apache.hadoop.yarn.api.records.ContainerId)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.ApplicationHistoryManager:getContainer(org.apache.hadoop.yarn.api.records.ContainerId)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.ApplicationHistoryManager:getAMContainer(org.apache.hadoop.yarn.api.records.ApplicationAttemptId)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.ApplicationHistoryManager:getAMContainer(org.apache.hadoop.yarn.api.records.ApplicationAttemptId)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.ApplicationHistoryManager:getContainers(org.apache.hadoop.yarn.api.records.ApplicationAttemptId)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.ApplicationHistoryManager:getContainers(org.apache.hadoop.yarn.api.records.ApplicationAttemptId)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.ApplicationHistoryServer:getClientService()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.applicationhistoryservice.ApplicationHistoryServer:getClientService()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.applicationhistoryservice.ApplicationHistoryServer:getPort()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.applicationhistoryservice.ApplicationHistoryServer:getPort()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.applicationhistoryservice.ApplicationHistoryServer:getTimelineStore()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.applicationhistoryservice.ApplicationHistoryServer:getTimelineStore()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.applicationhistoryservice.ApplicationHistoryServer:getApplicationHistoryManager()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.applicationhistoryservice.ApplicationHistoryServer:getApplicationHistoryManager()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.applicationhistoryservice.webapp.AboutBlock:<init>(org.apache.hadoop.yarn.webapp.View$ViewContext)	com.google.inject.Inject
org.apache.hadoop.yarn.server.applicationhistoryservice.webapp.AHSController:<init>(org.apache.hadoop.yarn.webapp.Controller$RequestContext)	com.google.inject.Inject
org.apache.hadoop.yarn.server.applicationhistoryservice.webapp.AHSWebServices:<init>(org.apache.hadoop.yarn.api.ApplicationBaseProtocol,org.apache.hadoop.conf.Configuration)	com.google.inject.Inject
org.apache.hadoop.yarn.server.applicationhistoryservice.webapp.AHSWebServices:about(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.applicationhistoryservice.webapp.AHSWebServices:about(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)	javax.ws.rs.Path	value	/about
org.apache.hadoop.yarn.server.applicationhistoryservice.webapp.AHSWebServices:about(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.applicationhistoryservice.webapp.AHSWebServices:get(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.applicationhistoryservice.webapp.AHSWebServices:get(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.applicationhistoryservice.webapp.AHSWebServices:getApps(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.util.Set,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.util.Set)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.applicationhistoryservice.webapp.AHSWebServices:getApps(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.util.Set,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.util.Set)	javax.ws.rs.Path	value	/apps
org.apache.hadoop.yarn.server.applicationhistoryservice.webapp.AHSWebServices:getApps(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.util.Set,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.util.Set)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.applicationhistoryservice.webapp.AHSWebServices:getApp(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.applicationhistoryservice.webapp.AHSWebServices:getApp(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String)	javax.ws.rs.Path	value	/apps/{appid}
org.apache.hadoop.yarn.server.applicationhistoryservice.webapp.AHSWebServices:getApp(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.applicationhistoryservice.webapp.AHSWebServices:getAppAttempts(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.applicationhistoryservice.webapp.AHSWebServices:getAppAttempts(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String)	javax.ws.rs.Path	value	/apps/{appid}/appattempts
org.apache.hadoop.yarn.server.applicationhistoryservice.webapp.AHSWebServices:getAppAttempts(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.applicationhistoryservice.webapp.AHSWebServices:getAppAttempt(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.applicationhistoryservice.webapp.AHSWebServices:getAppAttempt(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String)	javax.ws.rs.Path	value	/apps/{appid}/appattempts/{appattemptid}
org.apache.hadoop.yarn.server.applicationhistoryservice.webapp.AHSWebServices:getAppAttempt(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.applicationhistoryservice.webapp.AHSWebServices:getContainers(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.applicationhistoryservice.webapp.AHSWebServices:getContainers(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String)	javax.ws.rs.Path	value	/apps/{appid}/appattempts/{appattemptid}/containers
org.apache.hadoop.yarn.server.applicationhistoryservice.webapp.AHSWebServices:getContainers(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.applicationhistoryservice.webapp.AHSWebServices:getContainer(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.applicationhistoryservice.webapp.AHSWebServices:getContainer(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.Path	value	/apps/{appid}/appattempts/{appattemptid}/containers/{containerid}
org.apache.hadoop.yarn.server.applicationhistoryservice.webapp.AHSWebServices:getContainer(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.applicationhistoryservice.webapp.AHSWebServices:getContainerLogsInfo(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,boolean,boolean)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.applicationhistoryservice.webapp.AHSWebServices:getContainerLogsInfo(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,boolean,boolean)	javax.ws.rs.Path	value	/containers/{containerid}/logs
org.apache.hadoop.yarn.server.applicationhistoryservice.webapp.AHSWebServices:getContainerLogsInfo(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,boolean,boolean)	javax.ws.rs.Produces	value	{application/json,application/xml}
org.apache.hadoop.yarn.server.applicationhistoryservice.webapp.AHSWebServices:getContainerLogFile(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,boolean,boolean)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.applicationhistoryservice.webapp.AHSWebServices:getContainerLogFile(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,boolean,boolean)	javax.ws.rs.Path	value	/containers/{containerid}/logs/{filename}
org.apache.hadoop.yarn.server.applicationhistoryservice.webapp.AHSWebServices:getContainerLogFile(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,boolean,boolean)	javax.ws.rs.Produces	value	{text/plain}
org.apache.hadoop.yarn.server.applicationhistoryservice.webapp.AHSWebServices:getContainerLogFile(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,boolean,boolean)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.webapp.AHSWebServices:getContainerLogFile(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,boolean,boolean)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.webapp.AHSWebServices:getLogs(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,boolean,boolean)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.applicationhistoryservice.webapp.AHSWebServices:getLogs(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,boolean,boolean)	javax.ws.rs.Path	value	/containerlogs/{containerid}/{filename}
org.apache.hadoop.yarn.server.applicationhistoryservice.webapp.AHSWebServices:getLogs(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,boolean,boolean)	javax.ws.rs.Produces	value	{text/plain; charset=utf-8}
org.apache.hadoop.yarn.server.applicationhistoryservice.webapp.AHSWebServices:getLogs(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,boolean,boolean)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.applicationhistoryservice.webapp.AHSWebServices:getLogs(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,boolean,boolean)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.applicationhistoryservice.webapp.AHSWebServices:getLogServlet()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.applicationhistoryservice.webapp.AHSWebServices:getLogServlet()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.applicationhistoryservice.webapp.AHSWebServices:setLogServlet(org.apache.hadoop.yarn.server.webapp.LogServlet)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.applicationhistoryservice.webapp.AHSWebServices:setLogServlet(org.apache.hadoop.yarn.server.webapp.LogServlet)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.timeline.RollingLevelDBTimelineStore:setFactory(org.fusesource.leveldbjni.JniDBFactory)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.timeline.RollingLevelDBTimelineStore:clearStartTimeCache()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.timeline.RollingLevelDBTimelineStore:getStartTimeReadCacheSize(org.apache.hadoop.conf.Configuration)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.timeline.RollingLevelDBTimelineStore:getStartTimeWriteCacheSize(org.apache.hadoop.conf.Configuration)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.timeline.RollingLevelDBTimelineStore:evictOldStartTimes(long)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.timeline.RollingLevelDBTimelineStore:discardOldEntities(long)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.timeline.RollingLevelDBTimelineStore:storeVersion(org.apache.hadoop.yarn.server.records.Version)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.timeline.LeveldbTimelineStore:setFactory(org.fusesource.leveldbjni.JniDBFactory)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.timeline.LeveldbTimelineStore:putWithNoDomainId(org.apache.hadoop.yarn.api.records.timeline.TimelineEntities)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.timeline.LeveldbTimelineStore:putWithNoDomainId(org.apache.hadoop.yarn.api.records.timeline.TimelineEntities)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.timeline.LeveldbTimelineStore:clearStartTimeCache()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.timeline.LeveldbTimelineStore:getStartTimeReadCacheSize(org.apache.hadoop.conf.Configuration)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.timeline.LeveldbTimelineStore:getStartTimeWriteCacheSize(org.apache.hadoop.conf.Configuration)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.timeline.LeveldbTimelineStore:getEntityTypes()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.timeline.LeveldbTimelineStore:deleteNextEntity(java.lang.String,byte[],org.apache.hadoop.yarn.server.utils.LeveldbIterator,org.apache.hadoop.yarn.server.utils.LeveldbIterator,boolean)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.timeline.LeveldbTimelineStore:discardOldEntities(long)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.timeline.LeveldbTimelineStore:getDbIterator(boolean)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.timeline.LeveldbTimelineStore:storeVersion(org.apache.hadoop.yarn.server.records.Version)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.timeline.recovery.LeveldbTimelineStateStore:loadVersion()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.timeline.recovery.LeveldbTimelineStateStore:storeVersion(org.apache.hadoop.yarn.server.records.Version)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.timeline.recovery.LeveldbTimelineStateStore:getCurrentVersion()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.timeline.webapp.TimelineWebServices:<init>(org.apache.hadoop.yarn.server.timeline.TimelineDataManager)	com.google.inject.Inject
org.apache.hadoop.yarn.server.timeline.webapp.TimelineWebServices:about(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.timeline.webapp.TimelineWebServices:about(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)	javax.ws.rs.Produces	value	{application/json; charset=utf-8}
org.apache.hadoop.yarn.server.timeline.webapp.TimelineWebServices:getEntities(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.timeline.webapp.TimelineWebServices:getEntities(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.Path	value	/{entityType}
org.apache.hadoop.yarn.server.timeline.webapp.TimelineWebServices:getEntities(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.Produces	value	{application/json; charset=utf-8}
org.apache.hadoop.yarn.server.timeline.webapp.TimelineWebServices:getEntity(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.timeline.webapp.TimelineWebServices:getEntity(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.Path	value	/{entityType}/{entityId}
org.apache.hadoop.yarn.server.timeline.webapp.TimelineWebServices:getEntity(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.Produces	value	{application/json; charset=utf-8}
org.apache.hadoop.yarn.server.timeline.webapp.TimelineWebServices:getEvents(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.timeline.webapp.TimelineWebServices:getEvents(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.Path	value	/{entityType}/events
org.apache.hadoop.yarn.server.timeline.webapp.TimelineWebServices:getEvents(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.Produces	value	{application/json; charset=utf-8}
org.apache.hadoop.yarn.server.timeline.webapp.TimelineWebServices:postEntities(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,org.apache.hadoop.yarn.api.records.timeline.TimelineEntities)	javax.ws.rs.POST
org.apache.hadoop.yarn.server.timeline.webapp.TimelineWebServices:postEntities(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,org.apache.hadoop.yarn.api.records.timeline.TimelineEntities)	javax.ws.rs.Consumes	value	{application/json}
org.apache.hadoop.yarn.server.timeline.webapp.TimelineWebServices:postEntities(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,org.apache.hadoop.yarn.api.records.timeline.TimelineEntities)	javax.ws.rs.Produces	value	{application/json; charset=utf-8}
org.apache.hadoop.yarn.server.timeline.webapp.TimelineWebServices:putDomain(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,org.apache.hadoop.yarn.api.records.timeline.TimelineDomain)	javax.ws.rs.PUT
org.apache.hadoop.yarn.server.timeline.webapp.TimelineWebServices:putDomain(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,org.apache.hadoop.yarn.api.records.timeline.TimelineDomain)	javax.ws.rs.Path	value	/domain
org.apache.hadoop.yarn.server.timeline.webapp.TimelineWebServices:putDomain(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,org.apache.hadoop.yarn.api.records.timeline.TimelineDomain)	javax.ws.rs.Consumes	value	{application/json}
org.apache.hadoop.yarn.server.timeline.webapp.TimelineWebServices:putDomain(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,org.apache.hadoop.yarn.api.records.timeline.TimelineDomain)	javax.ws.rs.Produces	value	{application/json; charset=utf-8}
org.apache.hadoop.yarn.server.timeline.webapp.TimelineWebServices:getDomain(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.timeline.webapp.TimelineWebServices:getDomain(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String)	javax.ws.rs.Path	value	/domain/{domainId}
org.apache.hadoop.yarn.server.timeline.webapp.TimelineWebServices:getDomain(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String)	javax.ws.rs.Produces	value	{application/json; charset=utf-8}
org.apache.hadoop.yarn.server.timeline.webapp.TimelineWebServices:getDomains(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.timeline.webapp.TimelineWebServices:getDomains(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String)	javax.ws.rs.Path	value	/domain
org.apache.hadoop.yarn.server.timeline.webapp.TimelineWebServices:getDomains(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String)	javax.ws.rs.Produces	value	{application/json; charset=utf-8}
org.apache.hadoop.yarn.server.timeline.security.TimelineACLsManager:setAdminACLsManager(org.apache.hadoop.yarn.security.AdminACLsManager)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.timeline.security.TimelineACLsManager:setAdminACLsManager(org.apache.hadoop.yarn.security.AdminACLsManager)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.timeline.TimelineDataManagerMetrics:totalOps()	org.apache.hadoop.metrics2.annotation.Metric	value	{Total calls}
org.apache.hadoop.yarn.federation.proto.YarnServerFederationProtos$SubClusterStateProto:valueOf(int)	java.lang.Deprecated
org.apache.hadoop.yarn.proto.YarnServerCommonProtos$NodeActionProto:valueOf(int)	java.lang.Deprecated
org.apache.hadoop.yarn.server.AMHeartbeatRequestHandler:drainHeartbeatThread()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.AMHeartbeatRequestHandler:getRequestQueueSize()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.metrics.AMRMClientRelayerMetrics:getPendingMetric(java.lang.String,org.apache.hadoop.yarn.server.metrics.AMRMClientRelayerMetrics$RequestType)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.metrics.AMRMClientRelayerMetrics:setClientPending(java.lang.String,org.apache.hadoop.yarn.server.metrics.AMRMClientRelayerMetrics$RequestType,int)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.metrics.AMRMClientRelayerMetrics:getFulfillLatencyMetric(java.lang.String,org.apache.hadoop.yarn.server.metrics.AMRMClientRelayerMetrics$RequestType)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.metrics.AMRMClientRelayerMetrics:getRequestedQPSMetric(java.lang.String,org.apache.hadoop.yarn.server.metrics.AMRMClientRelayerMetrics$RequestType)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.metrics.AMRMClientRelayerMetrics:getFulfilledQPSMetric(java.lang.String,org.apache.hadoop.yarn.server.metrics.AMRMClientRelayerMetrics$RequestType)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.metrics.AMRMClientRelayerMetrics:getRMMasterSlaveSwitchMetric(java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.metrics.AMRMClientRelayerMetrics:getHeartbeatLatencyMetric(java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.metrics.AMRMClientRelayerMetrics:getHeartbeatFailureMetric(java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.metrics.AMRMClientRelayerMetrics:getHeartbeatSuccessMetric(java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.metrics.OpportunisticSchedulerMetrics:getAllocatedContainers()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.metrics.OpportunisticSchedulerMetrics:getAggregatedAllocatedContainers()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.metrics.OpportunisticSchedulerMetrics:getAggregatedReleasedContainers()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.metrics.OpportunisticSchedulerMetrics:getAggregatedNodeLocalContainers()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.metrics.OpportunisticSchedulerMetrics:getAggregatedRackLocalContainers()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.metrics.OpportunisticSchedulerMetrics:getAggregatedOffSwitchContainers()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.sharedcache.SharedCacheUtil:getCacheDepth(org.apache.hadoop.conf.Configuration)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.sharedcache.SharedCacheUtil:getCacheEntryPath(int,java.lang.String,java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.sharedcache.SharedCacheUtil:getCacheEntryGlobPattern(int)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.federation.policies.amrmproxy.LocalityMulticastAMRMProxyPolicy:computeIntegerAssignment(int,java.util.ArrayList)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.federation.policies.FederationPolicyUtils:setRand(long)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.federation.policies.manager.WeightedLocalityPolicyManager:getWeightedPolicyInfo()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.federation.policies.manager.WeightedLocalityPolicyManager:setWeightedPolicyInfo(org.apache.hadoop.yarn.server.federation.policies.dao.WeightedPolicyInfo)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.federation.policies.manager.PriorityBroadcastPolicyManager:getWeightedPolicyInfo()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.federation.policies.manager.PriorityBroadcastPolicyManager:setWeightedPolicyInfo(org.apache.hadoop.yarn.server.federation.policies.dao.WeightedPolicyInfo)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.federation.utils.FederationRegistryClient:cleanAllApplications()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.federation.utils.FederationStateStoreFacade:reinitialize(org.apache.hadoop.yarn.server.federation.store.FederationStateStore,org.apache.hadoop.conf.Configuration)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.federation.store.metrics.FederationStateStoreClientMetrics:getNumFailedCallsForMethod(java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.federation.store.metrics.FederationStateStoreClientMetrics:getNumSucceessfulCallsForMethod(java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.federation.store.metrics.FederationStateStoreClientMetrics:getLatencySucceessfulCallsForMethod(java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.federation.store.metrics.FederationStateStoreClientMetrics:getNumFailedCalls()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.federation.store.metrics.FederationStateStoreClientMetrics:getNumSucceededCalls()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.federation.store.metrics.FederationStateStoreClientMetrics:getLatencySucceededCalls()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.federation.store.records.GetSubClusterInfoResponse:newInstance(org.apache.hadoop.yarn.server.federation.store.records.SubClusterInfo)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.federation.store.records.GetSubClusterInfoResponse:newInstance(org.apache.hadoop.yarn.server.federation.store.records.SubClusterInfo)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.federation.store.records.GetSubClusterInfoResponse:getSubClusterInfo()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.federation.store.records.GetSubClusterInfoResponse:getSubClusterInfo()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.federation.store.records.GetSubClusterInfoResponse:setSubClusterInfo(org.apache.hadoop.yarn.server.federation.store.records.SubClusterInfo)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.federation.store.records.GetSubClusterInfoResponse:setSubClusterInfo(org.apache.hadoop.yarn.server.federation.store.records.SubClusterInfo)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.federation.store.records.SubClusterInfo:newInstance(org.apache.hadoop.yarn.server.federation.store.records.SubClusterId,java.lang.String,java.lang.String,java.lang.String,java.lang.String,org.apache.hadoop.yarn.server.federation.store.records.SubClusterState,long,java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.federation.store.records.SubClusterInfo:newInstance(org.apache.hadoop.yarn.server.federation.store.records.SubClusterId,java.lang.String,java.lang.String,java.lang.String,java.lang.String,org.apache.hadoop.yarn.server.federation.store.records.SubClusterState,long,java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.federation.store.records.SubClusterInfo:newInstance(org.apache.hadoop.yarn.server.federation.store.records.SubClusterId,java.lang.String,java.lang.String,java.lang.String,java.lang.String,long,org.apache.hadoop.yarn.server.federation.store.records.SubClusterState,long,java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.federation.store.records.SubClusterInfo:newInstance(org.apache.hadoop.yarn.server.federation.store.records.SubClusterId,java.lang.String,java.lang.String,java.lang.String,java.lang.String,long,org.apache.hadoop.yarn.server.federation.store.records.SubClusterState,long,java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.federation.store.records.SubClusterInfo:getSubClusterId()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.federation.store.records.SubClusterInfo:getSubClusterId()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.federation.store.records.SubClusterInfo:setSubClusterId(org.apache.hadoop.yarn.server.federation.store.records.SubClusterId)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.federation.store.records.SubClusterInfo:setSubClusterId(org.apache.hadoop.yarn.server.federation.store.records.SubClusterId)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.federation.store.records.SubClusterInfo:getAMRMServiceAddress()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.federation.store.records.SubClusterInfo:getAMRMServiceAddress()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.federation.store.records.SubClusterInfo:setAMRMServiceAddress(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.federation.store.records.SubClusterInfo:setAMRMServiceAddress(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.federation.store.records.SubClusterInfo:getClientRMServiceAddress()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.federation.store.records.SubClusterInfo:getClientRMServiceAddress()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.federation.store.records.SubClusterInfo:setClientRMServiceAddress(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.federation.store.records.SubClusterInfo:setClientRMServiceAddress(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.federation.store.records.SubClusterInfo:getRMAdminServiceAddress()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.federation.store.records.SubClusterInfo:getRMAdminServiceAddress()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.federation.store.records.SubClusterInfo:setRMAdminServiceAddress(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.federation.store.records.SubClusterInfo:setRMAdminServiceAddress(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.federation.store.records.SubClusterInfo:getRMWebServiceAddress()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.federation.store.records.SubClusterInfo:getRMWebServiceAddress()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.federation.store.records.SubClusterInfo:setRMWebServiceAddress(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.federation.store.records.SubClusterInfo:setRMWebServiceAddress(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.federation.store.records.SubClusterInfo:getLastHeartBeat()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.federation.store.records.SubClusterInfo:getLastHeartBeat()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.federation.store.records.SubClusterInfo:setLastHeartBeat(long)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.federation.store.records.SubClusterInfo:setLastHeartBeat(long)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.federation.store.records.SubClusterInfo:getState()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.federation.store.records.SubClusterInfo:getState()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.federation.store.records.SubClusterInfo:setState(org.apache.hadoop.yarn.server.federation.store.records.SubClusterState)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.federation.store.records.SubClusterInfo:setState(org.apache.hadoop.yarn.server.federation.store.records.SubClusterState)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.federation.store.records.SubClusterInfo:getLastStartTime()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.federation.store.records.SubClusterInfo:getLastStartTime()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.federation.store.records.SubClusterInfo:setLastStartTime(long)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.federation.store.records.SubClusterInfo:setLastStartTime(long)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.federation.store.records.SubClusterInfo:getCapability()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.federation.store.records.SubClusterInfo:getCapability()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.federation.store.records.SubClusterInfo:setCapability(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.federation.store.records.SubClusterInfo:setCapability(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.federation.store.records.GetSubClusterPoliciesConfigurationsResponse:newInstance(java.util.List)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.federation.store.records.GetSubClusterPoliciesConfigurationsResponse:newInstance(java.util.List)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.federation.store.records.GetSubClusterPoliciesConfigurationsResponse:getPoliciesConfigs()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.federation.store.records.GetSubClusterPoliciesConfigurationsResponse:getPoliciesConfigs()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.federation.store.records.GetSubClusterPoliciesConfigurationsResponse:setPoliciesConfigs(java.util.List)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.federation.store.records.GetSubClusterPoliciesConfigurationsResponse:setPoliciesConfigs(java.util.List)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.federation.store.records.SubClusterRegisterRequest:newInstance(org.apache.hadoop.yarn.server.federation.store.records.SubClusterInfo)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.federation.store.records.SubClusterRegisterRequest:newInstance(org.apache.hadoop.yarn.server.federation.store.records.SubClusterInfo)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.federation.store.records.SubClusterRegisterRequest:getSubClusterInfo()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.federation.store.records.SubClusterRegisterRequest:getSubClusterInfo()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.federation.store.records.SubClusterRegisterRequest:setSubClusterInfo(org.apache.hadoop.yarn.server.federation.store.records.SubClusterInfo)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.federation.store.records.SubClusterRegisterRequest:setSubClusterInfo(org.apache.hadoop.yarn.server.federation.store.records.SubClusterInfo)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.federation.store.records.UpdateApplicationHomeSubClusterRequest:newInstance(org.apache.hadoop.yarn.server.federation.store.records.ApplicationHomeSubCluster)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.federation.store.records.UpdateApplicationHomeSubClusterRequest:newInstance(org.apache.hadoop.yarn.server.federation.store.records.ApplicationHomeSubCluster)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.federation.store.records.UpdateApplicationHomeSubClusterRequest:getApplicationHomeSubCluster()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.federation.store.records.UpdateApplicationHomeSubClusterRequest:getApplicationHomeSubCluster()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.federation.store.records.UpdateApplicationHomeSubClusterRequest:setApplicationHomeSubCluster(org.apache.hadoop.yarn.server.federation.store.records.ApplicationHomeSubCluster)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.federation.store.records.UpdateApplicationHomeSubClusterRequest:setApplicationHomeSubCluster(org.apache.hadoop.yarn.server.federation.store.records.ApplicationHomeSubCluster)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.federation.store.records.SubClusterRegisterResponse:newInstance()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.federation.store.records.SubClusterRegisterResponse:newInstance()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.federation.store.records.GetSubClusterInfoRequest:newInstance(org.apache.hadoop.yarn.server.federation.store.records.SubClusterId)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.federation.store.records.GetSubClusterInfoRequest:newInstance(org.apache.hadoop.yarn.server.federation.store.records.SubClusterId)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.federation.store.records.GetSubClusterInfoRequest:getSubClusterId()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.federation.store.records.GetSubClusterInfoRequest:getSubClusterId()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.federation.store.records.GetSubClusterInfoRequest:setSubClusterId(org.apache.hadoop.yarn.server.federation.store.records.SubClusterId)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.federation.store.records.GetSubClusterInfoRequest:setSubClusterId(org.apache.hadoop.yarn.server.federation.store.records.SubClusterId)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.federation.store.records.SubClusterDeregisterResponse:newInstance()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.federation.store.records.SubClusterDeregisterResponse:newInstance()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.federation.store.records.GetSubClustersInfoResponse:newInstance(java.util.List)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.federation.store.records.GetSubClustersInfoResponse:newInstance(java.util.List)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.federation.store.records.GetSubClustersInfoResponse:getSubClusters()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.federation.store.records.GetSubClustersInfoResponse:getSubClusters()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.federation.store.records.GetSubClustersInfoResponse:setSubClusters(java.util.List)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.federation.store.records.GetSubClustersInfoResponse:setSubClusters(java.util.List)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.federation.store.records.SetSubClusterPolicyConfigurationRequest:newInstance(org.apache.hadoop.yarn.server.federation.store.records.SubClusterPolicyConfiguration)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.federation.store.records.SetSubClusterPolicyConfigurationRequest:newInstance(org.apache.hadoop.yarn.server.federation.store.records.SubClusterPolicyConfiguration)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.federation.store.records.SetSubClusterPolicyConfigurationRequest:getPolicyConfiguration()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.federation.store.records.SetSubClusterPolicyConfigurationRequest:getPolicyConfiguration()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.federation.store.records.SetSubClusterPolicyConfigurationRequest:setPolicyConfiguration(org.apache.hadoop.yarn.server.federation.store.records.SubClusterPolicyConfiguration)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.federation.store.records.SetSubClusterPolicyConfigurationRequest:setPolicyConfiguration(org.apache.hadoop.yarn.server.federation.store.records.SubClusterPolicyConfiguration)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.federation.store.records.SubClusterDeregisterRequest:newInstance(org.apache.hadoop.yarn.server.federation.store.records.SubClusterId,org.apache.hadoop.yarn.server.federation.store.records.SubClusterState)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.federation.store.records.SubClusterDeregisterRequest:newInstance(org.apache.hadoop.yarn.server.federation.store.records.SubClusterId,org.apache.hadoop.yarn.server.federation.store.records.SubClusterState)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.federation.store.records.SubClusterDeregisterRequest:getSubClusterId()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.federation.store.records.SubClusterDeregisterRequest:getSubClusterId()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.federation.store.records.SubClusterDeregisterRequest:setSubClusterId(org.apache.hadoop.yarn.server.federation.store.records.SubClusterId)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.federation.store.records.SubClusterDeregisterRequest:setSubClusterId(org.apache.hadoop.yarn.server.federation.store.records.SubClusterId)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.federation.store.records.SubClusterDeregisterRequest:getState()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.federation.store.records.SubClusterDeregisterRequest:getState()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.federation.store.records.SubClusterDeregisterRequest:setState(org.apache.hadoop.yarn.server.federation.store.records.SubClusterState)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.federation.store.records.SubClusterDeregisterRequest:setState(org.apache.hadoop.yarn.server.federation.store.records.SubClusterState)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.federation.store.records.ApplicationHomeSubCluster:newInstance(org.apache.hadoop.yarn.api.records.ApplicationId,org.apache.hadoop.yarn.server.federation.store.records.SubClusterId)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.federation.store.records.ApplicationHomeSubCluster:newInstance(org.apache.hadoop.yarn.api.records.ApplicationId,org.apache.hadoop.yarn.server.federation.store.records.SubClusterId)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.federation.store.records.ApplicationHomeSubCluster:getApplicationId()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.federation.store.records.ApplicationHomeSubCluster:getApplicationId()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.federation.store.records.ApplicationHomeSubCluster:setApplicationId(org.apache.hadoop.yarn.api.records.ApplicationId)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.federation.store.records.ApplicationHomeSubCluster:setApplicationId(org.apache.hadoop.yarn.api.records.ApplicationId)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.federation.store.records.ApplicationHomeSubCluster:getHomeSubCluster()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.federation.store.records.ApplicationHomeSubCluster:getHomeSubCluster()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.federation.store.records.ApplicationHomeSubCluster:setHomeSubCluster(org.apache.hadoop.yarn.server.federation.store.records.SubClusterId)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.federation.store.records.ApplicationHomeSubCluster:setHomeSubCluster(org.apache.hadoop.yarn.server.federation.store.records.SubClusterId)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.federation.store.records.GetApplicationHomeSubClusterRequest:newInstance(org.apache.hadoop.yarn.api.records.ApplicationId)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.federation.store.records.GetApplicationHomeSubClusterRequest:newInstance(org.apache.hadoop.yarn.api.records.ApplicationId)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.federation.store.records.GetApplicationHomeSubClusterRequest:getApplicationId()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.federation.store.records.GetApplicationHomeSubClusterRequest:getApplicationId()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.federation.store.records.GetApplicationHomeSubClusterRequest:setApplicationId(org.apache.hadoop.yarn.api.records.ApplicationId)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.federation.store.records.GetApplicationHomeSubClusterRequest:setApplicationId(org.apache.hadoop.yarn.api.records.ApplicationId)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.federation.store.records.SubClusterHeartbeatResponse:newInstance()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.federation.store.records.SubClusterHeartbeatResponse:newInstance()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.federation.store.records.AddApplicationHomeSubClusterRequest:newInstance(org.apache.hadoop.yarn.server.federation.store.records.ApplicationHomeSubCluster)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.federation.store.records.AddApplicationHomeSubClusterRequest:newInstance(org.apache.hadoop.yarn.server.federation.store.records.ApplicationHomeSubCluster)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.federation.store.records.AddApplicationHomeSubClusterRequest:getApplicationHomeSubCluster()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.federation.store.records.AddApplicationHomeSubClusterRequest:getApplicationHomeSubCluster()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.federation.store.records.AddApplicationHomeSubClusterRequest:setApplicationHomeSubCluster(org.apache.hadoop.yarn.server.federation.store.records.ApplicationHomeSubCluster)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.federation.store.records.AddApplicationHomeSubClusterRequest:setApplicationHomeSubCluster(org.apache.hadoop.yarn.server.federation.store.records.ApplicationHomeSubCluster)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.federation.store.records.SubClusterHeartbeatRequest:newInstance(org.apache.hadoop.yarn.server.federation.store.records.SubClusterId,org.apache.hadoop.yarn.server.federation.store.records.SubClusterState,java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.federation.store.records.SubClusterHeartbeatRequest:newInstance(org.apache.hadoop.yarn.server.federation.store.records.SubClusterId,org.apache.hadoop.yarn.server.federation.store.records.SubClusterState,java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.federation.store.records.SubClusterHeartbeatRequest:newInstance(org.apache.hadoop.yarn.server.federation.store.records.SubClusterId,long,org.apache.hadoop.yarn.server.federation.store.records.SubClusterState,java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.federation.store.records.SubClusterHeartbeatRequest:newInstance(org.apache.hadoop.yarn.server.federation.store.records.SubClusterId,long,org.apache.hadoop.yarn.server.federation.store.records.SubClusterState,java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.federation.store.records.SubClusterHeartbeatRequest:getSubClusterId()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.federation.store.records.SubClusterHeartbeatRequest:getSubClusterId()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.federation.store.records.SubClusterHeartbeatRequest:setSubClusterId(org.apache.hadoop.yarn.server.federation.store.records.SubClusterId)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.federation.store.records.SubClusterHeartbeatRequest:setSubClusterId(org.apache.hadoop.yarn.server.federation.store.records.SubClusterId)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.federation.store.records.SubClusterHeartbeatRequest:getLastHeartBeat()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.federation.store.records.SubClusterHeartbeatRequest:getLastHeartBeat()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.federation.store.records.SubClusterHeartbeatRequest:setLastHeartBeat(long)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.federation.store.records.SubClusterHeartbeatRequest:setLastHeartBeat(long)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.federation.store.records.SubClusterHeartbeatRequest:getState()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.federation.store.records.SubClusterHeartbeatRequest:getState()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.federation.store.records.SubClusterHeartbeatRequest:setState(org.apache.hadoop.yarn.server.federation.store.records.SubClusterState)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.federation.store.records.SubClusterHeartbeatRequest:setState(org.apache.hadoop.yarn.server.federation.store.records.SubClusterState)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.federation.store.records.SubClusterHeartbeatRequest:getCapability()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.federation.store.records.SubClusterHeartbeatRequest:getCapability()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.federation.store.records.SubClusterHeartbeatRequest:setCapability(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.federation.store.records.SubClusterHeartbeatRequest:setCapability(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.federation.store.records.GetApplicationHomeSubClusterResponse:newInstance(org.apache.hadoop.yarn.server.federation.store.records.ApplicationHomeSubCluster)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.federation.store.records.GetApplicationHomeSubClusterResponse:newInstance(org.apache.hadoop.yarn.server.federation.store.records.ApplicationHomeSubCluster)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.federation.store.records.GetApplicationHomeSubClusterResponse:getApplicationHomeSubCluster()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.federation.store.records.GetApplicationHomeSubClusterResponse:getApplicationHomeSubCluster()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.federation.store.records.GetApplicationHomeSubClusterResponse:setApplicationHomeSubCluster(org.apache.hadoop.yarn.server.federation.store.records.ApplicationHomeSubCluster)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.federation.store.records.GetApplicationHomeSubClusterResponse:setApplicationHomeSubCluster(org.apache.hadoop.yarn.server.federation.store.records.ApplicationHomeSubCluster)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.federation.store.records.GetSubClusterPolicyConfigurationRequest:newInstance(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.federation.store.records.GetSubClusterPolicyConfigurationRequest:newInstance(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.federation.store.records.GetSubClusterPolicyConfigurationRequest:getQueue()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.federation.store.records.GetSubClusterPolicyConfigurationRequest:getQueue()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.federation.store.records.GetSubClusterPolicyConfigurationRequest:setQueue(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.federation.store.records.GetSubClusterPolicyConfigurationRequest:setQueue(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.federation.store.records.DeleteApplicationHomeSubClusterResponse:newInstance()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.federation.store.records.DeleteApplicationHomeSubClusterResponse:newInstance()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.federation.store.records.SubClusterPolicyConfiguration:newInstance(java.lang.String,java.lang.String,java.nio.ByteBuffer)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.federation.store.records.SubClusterPolicyConfiguration:newInstance(java.lang.String,java.lang.String,java.nio.ByteBuffer)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.federation.store.records.SubClusterPolicyConfiguration:newInstance(org.apache.hadoop.yarn.server.federation.store.records.SubClusterPolicyConfiguration)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.federation.store.records.SubClusterPolicyConfiguration:newInstance(org.apache.hadoop.yarn.server.federation.store.records.SubClusterPolicyConfiguration)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.federation.store.records.SubClusterPolicyConfiguration:getQueue()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.federation.store.records.SubClusterPolicyConfiguration:getQueue()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.federation.store.records.SubClusterPolicyConfiguration:setQueue(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.federation.store.records.SubClusterPolicyConfiguration:setQueue(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.federation.store.records.SubClusterPolicyConfiguration:getType()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.federation.store.records.SubClusterPolicyConfiguration:getType()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.federation.store.records.SubClusterPolicyConfiguration:setType(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.federation.store.records.SubClusterPolicyConfiguration:setType(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.federation.store.records.SubClusterPolicyConfiguration:getParams()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.federation.store.records.SubClusterPolicyConfiguration:getParams()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.federation.store.records.SubClusterPolicyConfiguration:setParams(java.nio.ByteBuffer)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.federation.store.records.SubClusterPolicyConfiguration:setParams(java.nio.ByteBuffer)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.federation.store.records.GetApplicationsHomeSubClusterRequest:newInstance()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.federation.store.records.GetApplicationsHomeSubClusterRequest:newInstance()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.federation.store.records.UpdateApplicationHomeSubClusterResponse:newInstance()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.federation.store.records.UpdateApplicationHomeSubClusterResponse:newInstance()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.federation.store.records.GetApplicationsHomeSubClusterResponse:newInstance(java.util.List)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.federation.store.records.GetApplicationsHomeSubClusterResponse:newInstance(java.util.List)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.federation.store.records.GetApplicationsHomeSubClusterResponse:getAppsHomeSubClusters()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.federation.store.records.GetApplicationsHomeSubClusterResponse:getAppsHomeSubClusters()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.federation.store.records.GetApplicationsHomeSubClusterResponse:setAppsHomeSubClusters(java.util.List)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.federation.store.records.GetApplicationsHomeSubClusterResponse:setAppsHomeSubClusters(java.util.List)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.federation.store.records.SubClusterId:newInstance(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.federation.store.records.SubClusterId:newInstance(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.federation.store.records.SubClusterId:getId()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.federation.store.records.SubClusterId:getId()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.federation.store.records.SubClusterId:setId(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.federation.store.records.SubClusterId:setId(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.federation.store.records.GetSubClusterPolicyConfigurationResponse:newInstance(org.apache.hadoop.yarn.server.federation.store.records.SubClusterPolicyConfiguration)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.federation.store.records.GetSubClusterPolicyConfigurationResponse:newInstance(org.apache.hadoop.yarn.server.federation.store.records.SubClusterPolicyConfiguration)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.federation.store.records.GetSubClusterPolicyConfigurationResponse:getPolicyConfiguration()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.federation.store.records.GetSubClusterPolicyConfigurationResponse:getPolicyConfiguration()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.federation.store.records.GetSubClusterPolicyConfigurationResponse:setPolicyConfiguration(org.apache.hadoop.yarn.server.federation.store.records.SubClusterPolicyConfiguration)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.federation.store.records.GetSubClusterPolicyConfigurationResponse:setPolicyConfiguration(org.apache.hadoop.yarn.server.federation.store.records.SubClusterPolicyConfiguration)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.federation.store.records.DeleteApplicationHomeSubClusterRequest:newInstance(org.apache.hadoop.yarn.api.records.ApplicationId)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.federation.store.records.DeleteApplicationHomeSubClusterRequest:newInstance(org.apache.hadoop.yarn.api.records.ApplicationId)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.federation.store.records.DeleteApplicationHomeSubClusterRequest:getApplicationId()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.federation.store.records.DeleteApplicationHomeSubClusterRequest:getApplicationId()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.federation.store.records.DeleteApplicationHomeSubClusterRequest:setApplicationId(org.apache.hadoop.yarn.api.records.ApplicationId)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.federation.store.records.DeleteApplicationHomeSubClusterRequest:setApplicationId(org.apache.hadoop.yarn.api.records.ApplicationId)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.federation.store.records.AddApplicationHomeSubClusterResponse:newInstance(org.apache.hadoop.yarn.server.federation.store.records.SubClusterId)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.federation.store.records.AddApplicationHomeSubClusterResponse:newInstance(org.apache.hadoop.yarn.server.federation.store.records.SubClusterId)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.federation.store.records.GetSubClustersInfoRequest:newInstance(boolean)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.federation.store.records.GetSubClustersInfoRequest:newInstance(boolean)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.federation.store.records.GetSubClustersInfoRequest:getFilterInactiveSubClusters()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.federation.store.records.GetSubClustersInfoRequest:getFilterInactiveSubClusters()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.federation.store.records.GetSubClustersInfoRequest:setFilterInactiveSubClusters(boolean)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.federation.store.records.GetSubClustersInfoRequest:setFilterInactiveSubClusters(boolean)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.federation.failover.FederationProxyProviderUtil:createRMProxy(org.apache.hadoop.conf.Configuration,java.lang.Class,org.apache.hadoop.yarn.server.federation.store.records.SubClusterId,org.apache.hadoop.security.UserGroupInformation)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.federation.failover.FederationProxyProviderUtil:createRMProxy(org.apache.hadoop.conf.Configuration,java.lang.Class,org.apache.hadoop.yarn.server.federation.store.records.SubClusterId,org.apache.hadoop.security.UserGroupInformation)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.federation.failover.FederationProxyProviderUtil:createRMProxy(org.apache.hadoop.conf.Configuration,java.lang.Class,org.apache.hadoop.yarn.server.federation.store.records.SubClusterId,org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.security.token.Token)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.federation.failover.FederationProxyProviderUtil:createRMProxy(org.apache.hadoop.conf.Configuration,java.lang.Class,org.apache.hadoop.yarn.server.federation.store.records.SubClusterId,org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.security.token.Token)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.federation.failover.FederationRMFailoverProxyProvider:createRMProxy(java.net.InetSocketAddress)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.AMRMClientRelayer:getRemotePendingAsks()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.scheduler.OpportunisticContainerContext:getOppSchedulerMetrics()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.uam.UnmanagedAMPoolManager:createUAM(org.apache.hadoop.conf.Configuration,org.apache.hadoop.yarn.api.records.ApplicationId,java.lang.String,java.lang.String,java.lang.String,boolean,java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.uam.UnmanagedAMPoolManager:getRequestQueueSize(java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.uam.UnmanagedAMPoolManager:drainUAMHeartbeats()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.uam.UnmanagedApplicationManager:createAMHeartbeatRequestHandler(org.apache.hadoop.conf.Configuration,org.apache.hadoop.yarn.api.records.ApplicationId,org.apache.hadoop.yarn.server.AMRMClientRelayer)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.uam.UnmanagedApplicationManager:getRequestQueueSize()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.uam.UnmanagedApplicationManager:drainHeartbeatThread()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.uam.UnmanagedApplicationManager:isHeartbeatThreadAlive()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.api.protocolrecords.RegisterDistributedSchedulingAMResponse:newInstance(org.apache.hadoop.yarn.api.protocolrecords.RegisterApplicationMasterResponse)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.api.protocolrecords.RegisterDistributedSchedulingAMResponse:newInstance(org.apache.hadoop.yarn.api.protocolrecords.RegisterApplicationMasterResponse)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.api.protocolrecords.RegisterDistributedSchedulingAMResponse:setRegisterResponse(org.apache.hadoop.yarn.api.protocolrecords.RegisterApplicationMasterResponse)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.api.protocolrecords.RegisterDistributedSchedulingAMResponse:setRegisterResponse(org.apache.hadoop.yarn.api.protocolrecords.RegisterApplicationMasterResponse)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.api.protocolrecords.RegisterDistributedSchedulingAMResponse:getRegisterResponse()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.api.protocolrecords.RegisterDistributedSchedulingAMResponse:getRegisterResponse()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.api.protocolrecords.RegisterDistributedSchedulingAMResponse:setMinContainerResource(org.apache.hadoop.yarn.api.records.Resource)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.api.protocolrecords.RegisterDistributedSchedulingAMResponse:setMinContainerResource(org.apache.hadoop.yarn.api.records.Resource)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.api.protocolrecords.RegisterDistributedSchedulingAMResponse:getMinContainerResource()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.api.protocolrecords.RegisterDistributedSchedulingAMResponse:getMinContainerResource()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.api.protocolrecords.RegisterDistributedSchedulingAMResponse:setMaxContainerResource(org.apache.hadoop.yarn.api.records.Resource)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.api.protocolrecords.RegisterDistributedSchedulingAMResponse:setMaxContainerResource(org.apache.hadoop.yarn.api.records.Resource)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.api.protocolrecords.RegisterDistributedSchedulingAMResponse:getMaxContainerResource()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.api.protocolrecords.RegisterDistributedSchedulingAMResponse:getMaxContainerResource()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.api.protocolrecords.RegisterDistributedSchedulingAMResponse:setIncrContainerResource(org.apache.hadoop.yarn.api.records.Resource)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.api.protocolrecords.RegisterDistributedSchedulingAMResponse:setIncrContainerResource(org.apache.hadoop.yarn.api.records.Resource)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.api.protocolrecords.RegisterDistributedSchedulingAMResponse:getIncrContainerResource()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.api.protocolrecords.RegisterDistributedSchedulingAMResponse:getIncrContainerResource()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.api.protocolrecords.RegisterDistributedSchedulingAMResponse:setContainerTokenExpiryInterval(int)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.api.protocolrecords.RegisterDistributedSchedulingAMResponse:setContainerTokenExpiryInterval(int)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.api.protocolrecords.RegisterDistributedSchedulingAMResponse:getContainerTokenExpiryInterval()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.api.protocolrecords.RegisterDistributedSchedulingAMResponse:getContainerTokenExpiryInterval()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.api.protocolrecords.RegisterDistributedSchedulingAMResponse:setContainerIdStart(long)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.api.protocolrecords.RegisterDistributedSchedulingAMResponse:setContainerIdStart(long)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.api.protocolrecords.RegisterDistributedSchedulingAMResponse:getContainerIdStart()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.api.protocolrecords.RegisterDistributedSchedulingAMResponse:getContainerIdStart()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.api.protocolrecords.RegisterDistributedSchedulingAMResponse:setNodesForScheduling(java.util.List)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.api.protocolrecords.RegisterDistributedSchedulingAMResponse:setNodesForScheduling(java.util.List)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.api.protocolrecords.RegisterDistributedSchedulingAMResponse:getNodesForScheduling()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.api.protocolrecords.RegisterDistributedSchedulingAMResponse:getNodesForScheduling()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.api.protocolrecords.LogAggregationReport:newInstance(org.apache.hadoop.yarn.api.records.ApplicationId,org.apache.hadoop.yarn.api.records.LogAggregationStatus,java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.api.protocolrecords.LogAggregationReport:newInstance(org.apache.hadoop.yarn.api.records.ApplicationId,org.apache.hadoop.yarn.api.records.LogAggregationStatus,java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.api.protocolrecords.LogAggregationReport:getApplicationId()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.api.protocolrecords.LogAggregationReport:getApplicationId()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.api.protocolrecords.LogAggregationReport:setApplicationId(org.apache.hadoop.yarn.api.records.ApplicationId)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.api.protocolrecords.LogAggregationReport:setApplicationId(org.apache.hadoop.yarn.api.records.ApplicationId)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.api.protocolrecords.LogAggregationReport:getLogAggregationStatus()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.api.protocolrecords.LogAggregationReport:getLogAggregationStatus()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.api.protocolrecords.LogAggregationReport:setLogAggregationStatus(org.apache.hadoop.yarn.api.records.LogAggregationStatus)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.api.protocolrecords.LogAggregationReport:setLogAggregationStatus(org.apache.hadoop.yarn.api.records.LogAggregationStatus)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.api.protocolrecords.LogAggregationReport:getDiagnosticMessage()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.api.protocolrecords.LogAggregationReport:getDiagnosticMessage()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.api.protocolrecords.LogAggregationReport:setDiagnosticMessage(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.api.protocolrecords.LogAggregationReport:setDiagnosticMessage(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.api.protocolrecords.DistributedSchedulingAllocateResponse:newInstance(org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.api.protocolrecords.DistributedSchedulingAllocateResponse:newInstance(org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.api.protocolrecords.DistributedSchedulingAllocateResponse:setAllocateResponse(org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.api.protocolrecords.DistributedSchedulingAllocateResponse:setAllocateResponse(org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.api.protocolrecords.DistributedSchedulingAllocateResponse:getAllocateResponse()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.api.protocolrecords.DistributedSchedulingAllocateResponse:getAllocateResponse()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.api.protocolrecords.DistributedSchedulingAllocateResponse:setNodesForScheduling(java.util.List)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.api.protocolrecords.DistributedSchedulingAllocateResponse:setNodesForScheduling(java.util.List)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.api.protocolrecords.DistributedSchedulingAllocateResponse:getNodesForScheduling()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.api.protocolrecords.DistributedSchedulingAllocateResponse:getNodesForScheduling()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.api.protocolrecords.ReportNewCollectorInfoResponse:newInstance()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.api.protocolrecords.RemoteNode:newInstance(org.apache.hadoop.yarn.api.records.NodeId,java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.api.protocolrecords.RemoteNode:newInstance(org.apache.hadoop.yarn.api.records.NodeId,java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.api.protocolrecords.RemoteNode:newInstance(org.apache.hadoop.yarn.api.records.NodeId,java.lang.String,java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.api.protocolrecords.RemoteNode:newInstance(org.apache.hadoop.yarn.api.records.NodeId,java.lang.String,java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.api.protocolrecords.RemoteNode:newInstance(org.apache.hadoop.yarn.api.records.NodeId,java.lang.String,java.lang.String,java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.api.protocolrecords.RemoteNode:newInstance(org.apache.hadoop.yarn.api.records.NodeId,java.lang.String,java.lang.String,java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.api.protocolrecords.RemoteNode:getNodeId()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.api.protocolrecords.RemoteNode:getNodeId()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.api.protocolrecords.RemoteNode:setNodeId(org.apache.hadoop.yarn.api.records.NodeId)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.api.protocolrecords.RemoteNode:setNodeId(org.apache.hadoop.yarn.api.records.NodeId)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.api.protocolrecords.RemoteNode:getHttpAddress()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.api.protocolrecords.RemoteNode:getHttpAddress()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.api.protocolrecords.RemoteNode:setHttpAddress(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.api.protocolrecords.RemoteNode:setHttpAddress(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.api.protocolrecords.RemoteNode:getRackName()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.api.protocolrecords.RemoteNode:getRackName()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.api.protocolrecords.RemoteNode:setRackName(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.api.protocolrecords.RemoteNode:setRackName(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.api.protocolrecords.RemoteNode:getNodePartition()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.api.protocolrecords.RemoteNode:getNodePartition()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.api.protocolrecords.RemoteNode:setNodePartition(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.api.protocolrecords.RemoteNode:setNodePartition(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.api.protocolrecords.DistributedSchedulingAllocateRequest:getAllocateRequest()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.api.protocolrecords.DistributedSchedulingAllocateRequest:getAllocateRequest()	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.yarn.server.api.protocolrecords.DistributedSchedulingAllocateRequest:setAllocateRequest(org.apache.hadoop.yarn.api.protocolrecords.AllocateRequest)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.api.protocolrecords.DistributedSchedulingAllocateRequest:setAllocateRequest(org.apache.hadoop.yarn.api.protocolrecords.AllocateRequest)	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.yarn.server.api.protocolrecords.DistributedSchedulingAllocateRequest:getAllocatedContainers()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.api.protocolrecords.DistributedSchedulingAllocateRequest:getAllocatedContainers()	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.yarn.server.api.protocolrecords.DistributedSchedulingAllocateRequest:setAllocatedContainers(java.util.List)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.api.protocolrecords.DistributedSchedulingAllocateRequest:setAllocatedContainers(java.util.List)	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.yarn.server.api.ServerRMProxy:getRMAddress(org.apache.hadoop.yarn.conf.YarnConfiguration,java.lang.Class)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.api.ServerRMProxy:checkAllowedProtocols(java.lang.Class)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.api.ResourceTracker:registerNodeManager(org.apache.hadoop.yarn.server.api.protocolrecords.RegisterNodeManagerRequest)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.yarn.server.api.ResourceTracker:nodeHeartbeat(org.apache.hadoop.yarn.server.api.protocolrecords.NodeHeartbeatRequest)	org.apache.hadoop.io.retry.AtMostOnce
org.apache.hadoop.yarn.server.api.ResourceTracker:unRegisterNodeManager(org.apache.hadoop.yarn.server.api.protocolrecords.UnRegisterNodeManagerRequest)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.yarn.server.api.records.OpportunisticContainersStatus:getRunningOpportContainers()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.api.records.OpportunisticContainersStatus:getRunningOpportContainers()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.api.records.OpportunisticContainersStatus:setRunningOpportContainers(int)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.api.records.OpportunisticContainersStatus:setRunningOpportContainers(int)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.api.records.OpportunisticContainersStatus:getOpportMemoryUsed()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.api.records.OpportunisticContainersStatus:getOpportMemoryUsed()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.api.records.OpportunisticContainersStatus:setOpportMemoryUsed(long)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.api.records.OpportunisticContainersStatus:setOpportMemoryUsed(long)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.api.records.OpportunisticContainersStatus:getOpportCoresUsed()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.api.records.OpportunisticContainersStatus:getOpportCoresUsed()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.api.records.OpportunisticContainersStatus:setOpportCoresUsed(int)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.api.records.OpportunisticContainersStatus:setOpportCoresUsed(int)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.api.records.OpportunisticContainersStatus:getQueuedOpportContainers()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.api.records.OpportunisticContainersStatus:getQueuedOpportContainers()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.api.records.OpportunisticContainersStatus:setQueuedOpportContainers(int)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.api.records.OpportunisticContainersStatus:setQueuedOpportContainers(int)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.api.records.OpportunisticContainersStatus:getWaitQueueLength()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.api.records.OpportunisticContainersStatus:getWaitQueueLength()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.api.records.OpportunisticContainersStatus:setWaitQueueLength(int)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.api.records.OpportunisticContainersStatus:setWaitQueueLength(int)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.api.records.OpportunisticContainersStatus:getEstimatedQueueWaitTime()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.api.records.OpportunisticContainersStatus:getEstimatedQueueWaitTime()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.api.records.OpportunisticContainersStatus:setEstimatedQueueWaitTime(int)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.api.records.OpportunisticContainersStatus:setEstimatedQueueWaitTime(int)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.api.records.OpportunisticContainersStatus:getOpportQueueCapacity()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.api.records.OpportunisticContainersStatus:getOpportQueueCapacity()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.api.records.OpportunisticContainersStatus:setOpportQueueCapacity(int)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.api.records.OpportunisticContainersStatus:setOpportQueueCapacity(int)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.api.records.NodeStatus:getContainersUtilization()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.api.records.NodeStatus:getContainersUtilization()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.server.api.records.NodeStatus:setContainersUtilization(org.apache.hadoop.yarn.api.records.ResourceUtilization)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.api.records.NodeStatus:setContainersUtilization(org.apache.hadoop.yarn.api.records.ResourceUtilization)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.api.records.NodeStatus:getNodeUtilization()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.api.records.NodeStatus:getNodeUtilization()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.server.api.records.NodeStatus:setNodeUtilization(org.apache.hadoop.yarn.api.records.ResourceUtilization)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.api.records.NodeStatus:setNodeUtilization(org.apache.hadoop.yarn.api.records.ResourceUtilization)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.api.records.NodeStatus:getIncreasedContainers()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.api.records.NodeStatus:getIncreasedContainers()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.api.records.NodeStatus:setIncreasedContainers(java.util.List)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.api.records.NodeStatus:setIncreasedContainers(java.util.List)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.api.records.NodeStatus:getOpportunisticContainersStatus()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.api.records.NodeStatus:getOpportunisticContainersStatus()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.api.records.NodeStatus:setOpportunisticContainersStatus(org.apache.hadoop.yarn.server.api.records.OpportunisticContainersStatus)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.api.records.NodeStatus:setOpportunisticContainersStatus(org.apache.hadoop.yarn.server.api.records.OpportunisticContainersStatus)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.api.records.NodeHealthStatus:newInstance(boolean,java.lang.String,long)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.api.records.NodeHealthStatus:getIsNodeHealthy()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.api.records.NodeHealthStatus:getIsNodeHealthy()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.server.api.records.NodeHealthStatus:setIsNodeHealthy(boolean)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.api.records.NodeHealthStatus:setIsNodeHealthy(boolean)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.api.records.NodeHealthStatus:getHealthReport()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.api.records.NodeHealthStatus:getHealthReport()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.server.api.records.NodeHealthStatus:setHealthReport(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.api.records.NodeHealthStatus:setHealthReport(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.api.records.NodeHealthStatus:getLastHealthReportTime()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.api.records.NodeHealthStatus:getLastHealthReportTime()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.server.api.records.NodeHealthStatus:setLastHealthReportTime(long)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.api.records.NodeHealthStatus:setLastHealthReportTime(long)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.api.DistributedSchedulingAMProtocol:registerApplicationMasterForDistributedScheduling(org.apache.hadoop.yarn.api.protocolrecords.RegisterApplicationMasterRequest)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.api.DistributedSchedulingAMProtocol:registerApplicationMasterForDistributedScheduling(org.apache.hadoop.yarn.api.protocolrecords.RegisterApplicationMasterRequest)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.api.DistributedSchedulingAMProtocol:registerApplicationMasterForDistributedScheduling(org.apache.hadoop.yarn.api.protocolrecords.RegisterApplicationMasterRequest)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.yarn.server.api.DistributedSchedulingAMProtocol:allocateForDistributedScheduling(org.apache.hadoop.yarn.server.api.protocolrecords.DistributedSchedulingAllocateRequest)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.api.DistributedSchedulingAMProtocol:allocateForDistributedScheduling(org.apache.hadoop.yarn.server.api.protocolrecords.DistributedSchedulingAllocateRequest)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.api.DistributedSchedulingAMProtocol:allocateForDistributedScheduling(org.apache.hadoop.yarn.server.api.protocolrecords.DistributedSchedulingAllocateRequest)	org.apache.hadoop.io.retry.Idempotent
org.apache.hadoop.yarn.server.api.impl.pb.client.CollectorNodemanagerProtocolPBClientImpl:<init>(long,java.net.InetSocketAddress,org.apache.hadoop.conf.Configuration)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.utils.BuilderUtils:newContainerToken(org.apache.hadoop.yarn.api.records.NodeId,byte[],org.apache.hadoop.yarn.security.ContainerTokenIdentifier)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.webapp.AppBlock:<init>(org.apache.hadoop.yarn.api.ApplicationBaseProtocol,org.apache.hadoop.yarn.webapp.View$ViewContext,org.apache.hadoop.conf.Configuration)	com.google.inject.Inject
org.apache.hadoop.yarn.server.webapp.LogWebService:getContainerLogsInfo(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,boolean,java.lang.String,boolean)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.webapp.LogWebService:getContainerLogsInfo(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,boolean,java.lang.String,boolean)	javax.ws.rs.Path	value	/containers/{containerid}/logs
org.apache.hadoop.yarn.server.webapp.LogWebService:getContainerLogsInfo(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,boolean,java.lang.String,boolean)	javax.ws.rs.Produces	value	{application/json,application/xml}
org.apache.hadoop.yarn.server.webapp.LogWebService:getContainerLogFile(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,boolean,java.lang.String,boolean)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.webapp.LogWebService:getContainerLogFile(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,boolean,java.lang.String,boolean)	javax.ws.rs.Path	value	/containers/{containerid}/logs/{filename}
org.apache.hadoop.yarn.server.webapp.LogWebService:getContainerLogFile(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,boolean,java.lang.String,boolean)	javax.ws.rs.Produces	value	{text/plain}
org.apache.hadoop.yarn.server.webapp.LogWebService:getContainerLogFile(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,boolean,java.lang.String,boolean)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.webapp.LogWebService:getContainerLogFile(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,boolean,java.lang.String,boolean)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.webapp.LogWebService:getLogs(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,boolean,java.lang.String,boolean)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.webapp.LogWebService:getLogs(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,boolean,java.lang.String,boolean)	javax.ws.rs.Path	value	/containerlogs/{containerid}/{filename}
org.apache.hadoop.yarn.server.webapp.LogWebService:getLogs(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,boolean,java.lang.String,boolean)	javax.ws.rs.Produces	value	{text/plain; charset=utf-8}
org.apache.hadoop.yarn.server.webapp.LogWebService:getLogs(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,boolean,java.lang.String,boolean)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.webapp.LogWebService:getLogs(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,boolean,java.lang.String,boolean)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.webapp.LogWebService:getEntity(java.lang.String,javax.ws.rs.core.MultivaluedMap)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.webapp.ContainerBlock:<init>(org.apache.hadoop.yarn.api.ApplicationBaseProtocol,org.apache.hadoop.yarn.webapp.View$ViewContext)	com.google.inject.Inject
org.apache.hadoop.yarn.server.webapp.ContainerBlock:getResources(org.apache.hadoop.yarn.server.webapp.dao.ContainerInfo)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.webapp.ErrorsAndWarningsBlock$WarningMetrics:<init>(org.apache.hadoop.yarn.webapp.View$ViewContext)	com.google.inject.Inject
org.apache.hadoop.yarn.server.webapp.ErrorsAndWarningsBlock$ErrorMetrics:<init>(org.apache.hadoop.yarn.webapp.View$ViewContext)	com.google.inject.Inject
org.apache.hadoop.yarn.server.webapp.AppAttemptBlock:<init>(org.apache.hadoop.yarn.api.ApplicationBaseProtocol,org.apache.hadoop.yarn.webapp.View$ViewContext)	com.google.inject.Inject
org.apache.hadoop.yarn.server.webapp.AppsBlock:<init>(org.apache.hadoop.yarn.api.ApplicationBaseProtocol,org.apache.hadoop.yarn.webapp.View$ViewContext)	com.google.inject.Inject
org.apache.hadoop.yarn.server.webapp.ErrorsAndWarningsBlock:<init>(org.apache.hadoop.yarn.webapp.View$ViewContext,org.apache.hadoop.conf.Configuration)	com.google.inject.Inject
org.apache.hadoop.yarn.server.webapp.LogServlet:getNMWebAddressFromRM(java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.security.BaseContainerTokenSecretManager:getCurrentKey()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.security.BaseNMTokenSecretManager:getCurrentKey()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.proto.YarnServerNodemanagerServiceProtos$ResourceStatusTypeProto:valueOf(int)	java.lang.Deprecated
org.apache.hadoop.yarn.proto.YarnServerNodemanagerServiceProtos$LocalizerActionProto:valueOf(int)	java.lang.Deprecated
org.apache.hadoop.yarn.server.nodemanager.DirectoryCollection:getErroredDirs()	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.yarn.server.nodemanager.DirectoryCollection:getDirectoryErrorInfo(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.yarn.server.nodemanager.DirectoryCollection:isDiskUnHealthy(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.yarn.server.nodemanager.DirectoryCollection:getDiskUtilizationPercentageCutoffHigh()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.DirectoryCollection:getDiskUtilizationPercentageCutoffLow()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.DirectoryCollection:getDiskUtilizationSpaceCutoffLow()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.DirectoryCollection:getDiskUtilizationSpaceCutoffHigh()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.DirectoryCollection:getDiskUtilizationThresholdEnabled()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.DirectoryCollection:getDiskFreeSpaceThresholdEnabled()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.DirectoryCollection:setDiskUtilizationThresholdEnabled(boolean)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.DirectoryCollection:setDiskFreeSpaceThresholdEnabled(boolean)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.nodelabels.AbstractNodeDescriptorsProvider:getScheduler()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.nodelabels.ConfigurationNodeAttributesProvider:parseAttributes(java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.metrics.NodeManagerMetrics:getKilledContainers()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.metrics.NodeManagerMetrics:getFailedContainers()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.metrics.NodeManagerMetrics:getCompletedContainers()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.metrics.NodeManagerMetrics:getBadLogDirs()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.metrics.NodeManagerMetrics:getBadLocalDirs()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.metrics.NodeManagerMetrics:getGoodLogDirsDiskUtilizationPerc()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.metrics.NodeManagerMetrics:getGoodLocalDirsDiskUtilizationPerc()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.metrics.NodeManagerMetrics:getReInitializingContainer()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.metrics.NodeManagerMetrics:getContainersRolledbackOnFailure()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.metrics.NodeManagerMetrics:getQueuedOpportunisticContainers()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.metrics.NodeManagerMetrics:getQueuedGuaranteedContainers()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.NodeManager:createResourcePluginManager()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.NodeManager:createContainerExecutor(org.apache.hadoop.conf.Configuration)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.NodeManager:getNMContext()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.NodeManager:getNMCollectorService()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.NodeManager:getNodeStatusUpdater()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.nodemanager.NodeManager:getNodeStatusUpdater()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.amrmproxy.DefaultRequestInterceptor:setRMClient(org.apache.hadoop.yarn.api.ApplicationMasterProtocol)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.amrmproxy.DefaultRequestInterceptor:getTokenService(org.apache.hadoop.conf.Configuration,java.lang.String,java.lang.String,int)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.nodemanager.amrmproxy.AMRMProxyTokenSecretManager:setNMStateStoreService(org.apache.hadoop.yarn.server.nodemanager.recovery.NMStateStoreService)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.amrmproxy.AMRMProxyTokenSecretManager:rollMasterKey()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.nodemanager.amrmproxy.AMRMProxyTokenSecretManager:rollMasterKey()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.amrmproxy.AMRMProxyTokenSecretManager:activateNextMasterKey()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.nodemanager.amrmproxy.AMRMProxyTokenSecretManager:activateNextMasterKey()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.amrmproxy.AMRMProxyTokenSecretManager:createNewMasterKey()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.nodemanager.amrmproxy.AMRMProxyTokenSecretManager:createNewMasterKey()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.amrmproxy.AMRMProxyTokenSecretManager:getMasterKey()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.amrmproxy.AMRMProxyTokenSecretManager:getCurrentMasterKeyData()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.nodemanager.amrmproxy.AMRMProxyTokenSecretManager:getCurrentMasterKeyData()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.amrmproxy.AMRMProxyTokenSecretManager:getNextMasterKeyData()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.nodemanager.amrmproxy.AMRMProxyTokenSecretManager:getNextMasterKeyData()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.amrmproxy.AMRMProxyTokenSecretManager:createPassword(org.apache.hadoop.yarn.security.AMRMTokenIdentifier)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.nodemanager.amrmproxy.AMRMProxyTokenSecretManager:createPassword(org.apache.hadoop.security.token.TokenIdentifier)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.nodemanager.amrmproxy.AMRMProxyService:getBindAddress()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.nodemanager.amrmproxy.AMRMProxyService:getSecretManager()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.nodemanager.amrmproxy.AMRMProxyMetrics:getNumSucceededAppStartRequests()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.amrmproxy.AMRMProxyMetrics:getLatencySucceededAppStartRequests()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.amrmproxy.AMRMProxyMetrics:getNumSucceededRegisterAMRequests()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.amrmproxy.AMRMProxyMetrics:getLatencySucceededRegisterAMRequests()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.amrmproxy.AMRMProxyMetrics:getNumSucceededFinishAMRequests()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.amrmproxy.AMRMProxyMetrics:getLatencySucceededFinishAMRequests()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.amrmproxy.AMRMProxyMetrics:getNumSucceededAllocateRequests()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.amrmproxy.AMRMProxyMetrics:getLatencySucceededAllocateRequests()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.amrmproxy.FederationInterceptor:cleanupRegistry()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.amrmproxy.FederationInterceptor:getRegistryClient()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.amrmproxy.FederationInterceptor:getAttemptId()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.amrmproxy.FederationInterceptor:getHomeHeartbeartHandler()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.amrmproxy.FederationInterceptor:createUnmanagedAMPoolManager(java.util.concurrent.ExecutorService)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.amrmproxy.FederationInterceptor:createHomeHeartbeartHandler(org.apache.hadoop.conf.Configuration,org.apache.hadoop.yarn.api.records.ApplicationId,org.apache.hadoop.yarn.server.AMRMClientRelayer)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.amrmproxy.FederationInterceptor:mergeAllocateResponse(org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse,org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse,org.apache.hadoop.yarn.server.federation.store.records.SubClusterId)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.amrmproxy.FederationInterceptor:getUnmanagedAMPoolSize()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.amrmproxy.FederationInterceptor:getUnmanagedAMPool()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.amrmproxy.FederationInterceptor:getUamRegisterFutures()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.amrmproxy.FederationInterceptor:getAsyncResponseSink()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.amrmproxy.AMRMProxyApplicationContextImpl:getLocalAMRMTokenKeyId()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.nodemanager.LocalDirsHandlerService:checkDirs()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.DeletionService:isTerminated()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor:buildMainArgs(java.util.List,java.lang.String,java.lang.String,java.lang.String,java.net.InetSocketAddress,java.lang.String,java.util.List)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor:getResourceHandler()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor:postComplete(org.apache.hadoop.yarn.api.records.ContainerId)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.scheduler.DistributedScheduler:initLocal(long,org.apache.hadoop.yarn.api.records.ApplicationAttemptId,org.apache.hadoop.yarn.server.scheduler.OpportunisticContainerAllocator,org.apache.hadoop.yarn.server.nodemanager.security.NMTokenSecretManagerInNM,java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.recovery.NMLeveldbStateStoreService:isHealthy()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.recovery.NMLeveldbStateStoreService:getContainerVersionKey(java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.recovery.NMLeveldbStateStoreService:storeVersion(org.apache.hadoop.yarn.server.records.Version)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.recovery.NMLeveldbStateStoreService:getDB()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.recovery.NMLeveldbStateStoreService:setDB(org.iq80.leveldb.DB)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.timelineservice.NMTimelinePublisher:getAppToClientMap()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.ContainerExecutor:writeLaunchEnv(java.io.OutputStream,java.util.Map,java.util.Map,java.util.List,org.apache.hadoop.fs.Path,java.lang.String,java.lang.String,java.util.LinkedHashSet)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.ContainerExecutor:getNMEnvVar(java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.health.NodeHealthCheckerService:addHealthReporter(org.apache.hadoop.service.Service)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.health.TimedHealthReporterService:setTimerTask(java.util.TimerTask)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.health.TimedHealthReporterService:getTimerTask()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.webapp.AllContainersPage$AllContainersBlock:<init>(org.apache.hadoop.yarn.server.nodemanager.Context)	com.google.inject.Inject
org.apache.hadoop.yarn.server.nodemanager.webapp.NMWebServices:<init>(org.apache.hadoop.yarn.server.nodemanager.Context,org.apache.hadoop.yarn.server.nodemanager.ResourceView,org.apache.hadoop.yarn.webapp.WebApp)	com.google.inject.Inject
org.apache.hadoop.yarn.server.nodemanager.webapp.NMWebServices:get()	javax.ws.rs.GET
org.apache.hadoop.yarn.server.nodemanager.webapp.NMWebServices:get()	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.nodemanager.webapp.NMWebServices:getNodeInfo()	javax.ws.rs.GET
org.apache.hadoop.yarn.server.nodemanager.webapp.NMWebServices:getNodeInfo()	javax.ws.rs.Path	value	/info
org.apache.hadoop.yarn.server.nodemanager.webapp.NMWebServices:getNodeInfo()	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.nodemanager.webapp.NMWebServices:getNodeApps(javax.servlet.http.HttpServletRequest,java.lang.String,java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.nodemanager.webapp.NMWebServices:getNodeApps(javax.servlet.http.HttpServletRequest,java.lang.String,java.lang.String)	javax.ws.rs.Path	value	/apps
org.apache.hadoop.yarn.server.nodemanager.webapp.NMWebServices:getNodeApps(javax.servlet.http.HttpServletRequest,java.lang.String,java.lang.String)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.nodemanager.webapp.NMWebServices:getNodeApp(java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.nodemanager.webapp.NMWebServices:getNodeApp(java.lang.String)	javax.ws.rs.Path	value	/apps/{appid}
org.apache.hadoop.yarn.server.nodemanager.webapp.NMWebServices:getNodeApp(java.lang.String)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.nodemanager.webapp.NMWebServices:getNodeContainers(javax.servlet.http.HttpServletRequest)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.nodemanager.webapp.NMWebServices:getNodeContainers(javax.servlet.http.HttpServletRequest)	javax.ws.rs.Path	value	/containers
org.apache.hadoop.yarn.server.nodemanager.webapp.NMWebServices:getNodeContainers(javax.servlet.http.HttpServletRequest)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.nodemanager.webapp.NMWebServices:getNodeContainer(javax.servlet.http.HttpServletRequest,java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.nodemanager.webapp.NMWebServices:getNodeContainer(javax.servlet.http.HttpServletRequest,java.lang.String)	javax.ws.rs.Path	value	/containers/{containerid}
org.apache.hadoop.yarn.server.nodemanager.webapp.NMWebServices:getNodeContainer(javax.servlet.http.HttpServletRequest,java.lang.String)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.nodemanager.webapp.NMWebServices:getContainerLogsInfo(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.nodemanager.webapp.NMWebServices:getContainerLogsInfo(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String)	javax.ws.rs.Path	value	/containers/{containerid}/logs
org.apache.hadoop.yarn.server.nodemanager.webapp.NMWebServices:getContainerLogsInfo(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.nodemanager.webapp.NMWebServices:getContainerLogFile(java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.nodemanager.webapp.NMWebServices:getContainerLogFile(java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.Path	value	/containers/{containerid}/logs/{filename}
org.apache.hadoop.yarn.server.nodemanager.webapp.NMWebServices:getContainerLogFile(java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.Produces	value	{text/plain; charset=utf-8}
org.apache.hadoop.yarn.server.nodemanager.webapp.NMWebServices:getContainerLogFile(java.lang.String,java.lang.String,java.lang.String,java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.nodemanager.webapp.NMWebServices:getContainerLogFile(java.lang.String,java.lang.String,java.lang.String,java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.nodemanager.webapp.NMWebServices:getLogs(java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.nodemanager.webapp.NMWebServices:getLogs(java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.Path	value	/containerlogs/{containerid}/{filename}
org.apache.hadoop.yarn.server.nodemanager.webapp.NMWebServices:getLogs(java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.Produces	value	{text/plain; charset=utf-8}
org.apache.hadoop.yarn.server.nodemanager.webapp.NMWebServices:getLogs(java.lang.String,java.lang.String,java.lang.String,java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.nodemanager.webapp.NMWebServices:getLogs(java.lang.String,java.lang.String,java.lang.String,java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.nodemanager.webapp.NMWebServices:getNMResourceInfo(java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.nodemanager.webapp.NMWebServices:getNMResourceInfo(java.lang.String)	javax.ws.rs.Path	value	/resources/{resourcename}
org.apache.hadoop.yarn.server.nodemanager.webapp.NMWebServices:getNMResourceInfo(java.lang.String)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.nodemanager.webapp.NMWebServices:getAuxiliaryServices(javax.servlet.http.HttpServletRequest)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.nodemanager.webapp.NMWebServices:getAuxiliaryServices(javax.servlet.http.HttpServletRequest)	javax.ws.rs.Path	value	/auxiliaryservices
org.apache.hadoop.yarn.server.nodemanager.webapp.NMWebServices:getAuxiliaryServices(javax.servlet.http.HttpServletRequest)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.nodemanager.webapp.NMWebServices:putAuxiliaryServices(javax.servlet.http.HttpServletRequest,org.apache.hadoop.yarn.server.nodemanager.containermanager.records.AuxServiceRecords)	javax.ws.rs.PUT
org.apache.hadoop.yarn.server.nodemanager.webapp.NMWebServices:putAuxiliaryServices(javax.servlet.http.HttpServletRequest,org.apache.hadoop.yarn.server.nodemanager.containermanager.records.AuxServiceRecords)	javax.ws.rs.Path	value	/auxiliaryservices
org.apache.hadoop.yarn.server.nodemanager.webapp.NMWebServices:putAuxiliaryServices(javax.servlet.http.HttpServletRequest,org.apache.hadoop.yarn.server.nodemanager.containermanager.records.AuxServiceRecords)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.nodemanager.webapp.NMWebServices:syncYarnSysFS(javax.servlet.http.HttpServletRequest,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.PUT
org.apache.hadoop.yarn.server.nodemanager.webapp.NMWebServices:syncYarnSysFS(javax.servlet.http.HttpServletRequest,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.Path	value	/yarn/sysfs/{user}/{appId}
org.apache.hadoop.yarn.server.nodemanager.webapp.NMWebServices:syncYarnSysFS(javax.servlet.http.HttpServletRequest,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.nodemanager.webapp.NodePage$NodeBlock:<init>(org.apache.hadoop.yarn.server.nodemanager.Context,org.apache.hadoop.yarn.server.nodemanager.ResourceView)	com.google.inject.Inject
org.apache.hadoop.yarn.server.nodemanager.webapp.ContainerPage$ContainerBlock:<init>(org.apache.hadoop.yarn.server.nodemanager.Context)	com.google.inject.Inject
org.apache.hadoop.yarn.server.nodemanager.webapp.ApplicationPage$ApplicationBlock:<init>(org.apache.hadoop.yarn.server.nodemanager.Context,org.apache.hadoop.conf.Configuration)	com.google.inject.Inject
org.apache.hadoop.yarn.server.nodemanager.webapp.NMController:<init>(org.apache.hadoop.yarn.webapp.Controller$RequestContext)	com.google.inject.Inject
org.apache.hadoop.yarn.server.nodemanager.webapp.NMWebAppFilter:<init>(com.google.inject.Injector,org.apache.hadoop.yarn.server.nodemanager.Context)	javax.inject.Inject
org.apache.hadoop.yarn.server.nodemanager.webapp.NavBlock:<init>(org.apache.hadoop.conf.Configuration)	com.google.inject.Inject
org.apache.hadoop.yarn.server.nodemanager.webapp.AllApplicationsPage$AllApplicationsBlock:<init>(org.apache.hadoop.yarn.server.nodemanager.Context)	com.google.inject.Inject
org.apache.hadoop.yarn.server.nodemanager.webapp.dao.gpu.PerGpuTemperature:getCurrentGpuTemp()	javax.xml.bind.annotation.adapters.XmlJavaTypeAdapter	value	Lorg/apache/hadoop/yarn/server/nodemanager/webapp/dao/gpu/PerGpuDeviceInformation$StrToFloatBeforeSpaceAdapter;
org.apache.hadoop.yarn.server.nodemanager.webapp.dao.gpu.PerGpuTemperature:getCurrentGpuTemp()	javax.xml.bind.annotation.XmlElement	name	gpu_temp
org.apache.hadoop.yarn.server.nodemanager.webapp.dao.gpu.PerGpuTemperature:getMaxGpuTemp()	javax.xml.bind.annotation.adapters.XmlJavaTypeAdapter	value	Lorg/apache/hadoop/yarn/server/nodemanager/webapp/dao/gpu/PerGpuDeviceInformation$StrToFloatBeforeSpaceAdapter;
org.apache.hadoop.yarn.server.nodemanager.webapp.dao.gpu.PerGpuTemperature:getMaxGpuTemp()	javax.xml.bind.annotation.XmlElement	name	gpu_temp_max_threshold
org.apache.hadoop.yarn.server.nodemanager.webapp.dao.gpu.PerGpuTemperature:getSlowThresholdGpuTemp()	javax.xml.bind.annotation.adapters.XmlJavaTypeAdapter	value	Lorg/apache/hadoop/yarn/server/nodemanager/webapp/dao/gpu/PerGpuDeviceInformation$StrToFloatBeforeSpaceAdapter;
org.apache.hadoop.yarn.server.nodemanager.webapp.dao.gpu.PerGpuTemperature:getSlowThresholdGpuTemp()	javax.xml.bind.annotation.XmlElement	name	gpu_temp_slow_threshold
org.apache.hadoop.yarn.server.nodemanager.webapp.dao.gpu.GpuDeviceInformation:getGpus()	javax.xml.bind.annotation.XmlElement	name	gpu
org.apache.hadoop.yarn.server.nodemanager.webapp.dao.gpu.GpuDeviceInformation:getDriverVersion()	javax.xml.bind.annotation.XmlElement	name	driver_version
org.apache.hadoop.yarn.server.nodemanager.webapp.dao.gpu.PerGpuUtilizations:getOverallGpuUtilization()	javax.xml.bind.annotation.adapters.XmlJavaTypeAdapter	value	Lorg/apache/hadoop/yarn/server/nodemanager/webapp/dao/gpu/PerGpuDeviceInformation$StrToFloatBeforeSpaceAdapter;
org.apache.hadoop.yarn.server.nodemanager.webapp.dao.gpu.PerGpuUtilizations:getOverallGpuUtilization()	javax.xml.bind.annotation.XmlElement	name	gpu_util
org.apache.hadoop.yarn.server.nodemanager.webapp.dao.gpu.PerGpuDeviceInformation:getTemperature()	javax.xml.bind.annotation.XmlElement	name	temperature
org.apache.hadoop.yarn.server.nodemanager.webapp.dao.gpu.PerGpuDeviceInformation:getUuid()	javax.xml.bind.annotation.XmlElement	name	uuid
org.apache.hadoop.yarn.server.nodemanager.webapp.dao.gpu.PerGpuDeviceInformation:getProductName()	javax.xml.bind.annotation.XmlElement	name	product_name
org.apache.hadoop.yarn.server.nodemanager.webapp.dao.gpu.PerGpuDeviceInformation:getMinorNumber()	javax.xml.bind.annotation.XmlElement	name	minor_number
org.apache.hadoop.yarn.server.nodemanager.webapp.dao.gpu.PerGpuDeviceInformation:getGpuUtilizations()	javax.xml.bind.annotation.XmlElement	name	utilization
org.apache.hadoop.yarn.server.nodemanager.webapp.dao.gpu.PerGpuDeviceInformation:getGpuMemoryUsage()	javax.xml.bind.annotation.XmlElement	name	fb_memory_usage
org.apache.hadoop.yarn.server.nodemanager.webapp.dao.gpu.PerGpuMemoryUsage:getUsedMemoryMiB()	javax.xml.bind.annotation.adapters.XmlJavaTypeAdapter	value	Lorg/apache/hadoop/yarn/server/nodemanager/webapp/dao/gpu/PerGpuDeviceInformation$StrToMemAdapter;
org.apache.hadoop.yarn.server.nodemanager.webapp.dao.gpu.PerGpuMemoryUsage:getUsedMemoryMiB()	javax.xml.bind.annotation.XmlElement	name	used
org.apache.hadoop.yarn.server.nodemanager.webapp.dao.gpu.PerGpuMemoryUsage:getAvailMemoryMiB()	javax.xml.bind.annotation.adapters.XmlJavaTypeAdapter	value	Lorg/apache/hadoop/yarn/server/nodemanager/webapp/dao/gpu/PerGpuDeviceInformation$StrToMemAdapter;
org.apache.hadoop.yarn.server.nodemanager.webapp.dao.gpu.PerGpuMemoryUsage:getAvailMemoryMiB()	javax.xml.bind.annotation.XmlElement	name	free
org.apache.hadoop.yarn.server.nodemanager.webapp.ContainerLogsPage$ContainersLogsBlock:<init>(org.apache.hadoop.yarn.server.nodemanager.Context)	com.google.inject.Inject
org.apache.hadoop.yarn.server.nodemanager.webapp.ContainerShellWebSocket:onText(org.eclipse.jetty.websocket.api.Session,java.lang.String)	org.eclipse.jetty.websocket.api.annotations.OnWebSocketMessage
org.apache.hadoop.yarn.server.nodemanager.webapp.ContainerShellWebSocket:onConnect(org.eclipse.jetty.websocket.api.Session)	org.eclipse.jetty.websocket.api.annotations.OnWebSocketConnect
org.apache.hadoop.yarn.server.nodemanager.webapp.ContainerShellWebSocket:onClose(org.eclipse.jetty.websocket.api.Session,int,java.lang.String)	org.eclipse.jetty.websocket.api.annotations.OnWebSocketClose
org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor:<init>()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor:createContainerLocalizer(java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.util.List,org.apache.hadoop.fs.FileContext)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor:createContainerLocalizer(java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.util.List,org.apache.hadoop.fs.FileContext)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor:containerIsAlive(java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor:pickDirectory(long,long[])	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor:pickDirectory(long,long[])	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor:getLogDirPermissions()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor:clearLogDirPermissions()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.security.NMContainerTokenSecretManager:setMasterKey(org.apache.hadoop.yarn.server.api.records.MasterKey)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.nodemanager.security.NMTokenSecretManagerInNM:setMasterKey(org.apache.hadoop.yarn.server.api.records.MasterKey)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.nodemanager.security.NMTokenSecretManagerInNM:isAppAttemptNMTokenKeyPresent(org.apache.hadoop.yarn.api.records.ApplicationAttemptId)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.nodemanager.security.NMTokenSecretManagerInNM:isAppAttemptNMTokenKeyPresent(org.apache.hadoop.yarn.api.records.ApplicationAttemptId)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.security.NMTokenSecretManagerInNM:getNodeId()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.nodemanager.security.NMTokenSecretManagerInNM:getNodeId()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.security.authorize.NMPolicyProvider:getInstance()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.nodemanager.security.authorize.NMPolicyProvider:getInstance()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl:stopRMProxy()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl:isTokenKeepAliveEnabled(org.apache.hadoop.conf.Configuration)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl:getRMClient()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl:registerWithRM()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl:getNodeStatus(int)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl:getContainerStatuses()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl:removeOrTrackCompletedContainersFromContext(java.util.List)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl:removeOrTrackCompletedContainersFromContext(java.util.List)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl:getStatusUpdaterThreadState()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl:removeVeryOldStoppedContainersFromCache()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl:removeVeryOldStoppedContainersFromCache()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.util.CgroupsLCEResourcesHandler:initConfig()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.util.CgroupsLCEResourcesHandler:init(org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor,org.apache.hadoop.yarn.util.ResourceCalculatorPlugin)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.util.CgroupsLCEResourcesHandler:checkAndDeleteCgroup(java.io.File)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.util.CgroupsLCEResourcesHandler:deleteCgroup(java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.util.CgroupsLCEResourcesHandler:findControllerInMtab(java.lang.String,java.util.Map)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.util.CgroupsLCEResourcesHandler:getMtabFileName()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.util.CgroupsLCEResourcesHandler:getControllerPaths()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationImpl:setAppLogInitedTimestamp(long)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationImpl:getLogAggregationContext()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch:expandEnvironment(java.lang.String,org.apache.hadoop.fs.Path)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch:translateCommandToSignal(org.apache.hadoop.yarn.api.records.SignalContainerCommand)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncher:<init>(org.apache.hadoop.yarn.server.nodemanager.Context,org.apache.hadoop.yarn.event.Dispatcher,org.apache.hadoop.yarn.server.nodemanager.ContainerExecutor,org.apache.hadoop.yarn.server.nodemanager.LocalDirsHandlerService,org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncher:cleanup(org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncherEvent,org.apache.hadoop.yarn.api.records.ContainerId,boolean)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch$ShellScriptBuilder:create(org.apache.hadoop.util.Shell$OSType)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.deviceframework.DeviceMappingManager:getAllAllowedDevices()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.deviceframework.DeviceMappingManager:getAllUsedDevices()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.deviceframework.DeviceMappingManager:getDevicePluginSchedulers()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.deviceframework.DeviceMappingManager:getAllocatedDevices(java.lang.String,org.apache.hadoop.yarn.api.records.ContainerId)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.deviceframework.DeviceMappingManager:addDevicePluginScheduler(java.lang.String,org.apache.hadoop.yarn.server.nodemanager.api.deviceplugin.DevicePluginScheduler)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.deviceframework.DeviceResourceHandlerImpl:<init>(java.lang.String,org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.deviceframework.DevicePluginAdapter,org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.deviceframework.DeviceMappingManager,org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.CGroupsHandler,org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.privileged.PrivilegedOperationExecutor,org.apache.hadoop.yarn.server.nodemanager.Context,org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.deviceframework.ShellWrapper)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.deviceframework.DevicePluginAdapter:setDeviceResourceHandler(org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.deviceframework.DeviceResourceHandlerImpl)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.fpga.FpgaDiscoverer:setScriptRunner(java.util.function.Function)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.fpga.IntelFpgaOpenclPlugin:setInnerShellExecutor(org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.fpga.IntelFpgaOpenclPlugin$InnerShellExecutor)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.fpga.IntelFpgaOpenclPlugin:getPathToExecutable()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.fpga.IntelFpgaOpenclPlugin:setEnvProvider(java.util.function.Function)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.gpu.NvidiaDockerV2CommandPlugin:requestsGpu(org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.gpu.NvidiaDockerV1CommandPlugin:requestsGpu(org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.gpu.GpuDiscoverer:getEnvironmentToRunCommand()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.gpu.GpuDiscoverer:getPathOfGpuBinary()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.com.nec.NECVEPlugin:<init>(java.util.function.Function,java.lang.String[],org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.com.nec.UdevUtil)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.com.nec.NECVEPlugin:setCommandExecutorProvider(java.util.function.Function)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.com.nec.NECVEPlugin:setVeDeviceDiscoverer(org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.com.nec.VEDeviceDiscoverer)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.com.nec.NECVEPlugin:getBinaryPath()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.com.nec.VEDeviceDiscoverer:setCommandExecutorProvider(java.util.function.Function)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.com.nvidia.NvidiaGPUPluginForRuntimeV2:initCostTable()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.com.nvidia.NvidiaGPUPluginForRuntimeV2:computeCostOfDevices(org.apache.hadoop.yarn.server.nodemanager.api.deviceplugin.Device[])	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.com.nvidia.NvidiaGPUPluginForRuntimeV2:topologyAwareSchedule(java.util.Set,int,java.util.Map,java.util.Set,java.util.Map)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.com.nvidia.NvidiaGPUPluginForRuntimeV2:basicSchedule(java.util.Set,int,java.util.Set)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.com.nvidia.NvidiaGPUPluginForRuntimeV2:setPathOfGpuBinary(java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.com.nvidia.NvidiaGPUPluginForRuntimeV2:setShellExecutor(org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.com.nvidia.NvidiaGPUPluginForRuntimeV2$NvidiaCommandExecutor)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.com.nvidia.NvidiaGPUPluginForRuntimeV2:isTopoInitialized()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.com.nvidia.NvidiaGPUPluginForRuntimeV2:getCostTable()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.com.nvidia.NvidiaGPUPluginForRuntimeV2:getDevicePairToWeight()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.ResourcePluginManager:checkInterfaceCompatibility(java.lang.Class,java.lang.Class)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.ResourcePluginManager:isConfiguredResourceName(java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.ResourcePluginManager:setDeviceMappingManager(org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.deviceframework.DeviceMappingManager)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.scheduler.ContainerScheduler:<init>(org.apache.hadoop.yarn.server.nodemanager.Context,org.apache.hadoop.yarn.event.AsyncDispatcher,org.apache.hadoop.yarn.server.nodemanager.metrics.NodeManagerMetrics,int)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.scheduler.ContainerScheduler:getNumQueuedGuaranteedContainers()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.scheduler.ContainerScheduler:getNumQueuedOpportunisticContainers()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.scheduler.ContainerScheduler:getNumRunningContainers()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.scheduler.ContainerScheduler:setUsePauseEventForPreemption(boolean)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.scheduler.ContainerScheduler:scheduleContainer(org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.scheduler.ContainerScheduler:getCurrentUtilization()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl:createContainerScheduler(org.apache.hadoop.yarn.server.nodemanager.Context)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl:createNMTimelinePublisher(org.apache.hadoop.yarn.server.nodemanager.Context)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl:selectNMTokenIdentifier(org.apache.hadoop.security.UserGroupInformation)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl:selectNMTokenIdentifier(org.apache.hadoop.security.UserGroupInformation)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl:authorizeStartAndResourceIncreaseRequest(org.apache.hadoop.yarn.security.NMTokenIdentifier,org.apache.hadoop.yarn.security.ContainerTokenIdentifier,boolean)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl:authorizeStartAndResourceIncreaseRequest(org.apache.hadoop.yarn.security.NMTokenIdentifier,org.apache.hadoop.yarn.security.ContainerTokenIdentifier,boolean)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl:increaseContainersResource(org.apache.hadoop.yarn.api.protocolrecords.IncreaseContainersResourceRequest)	java.lang.Deprecated
org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl:updateNMTokenIdentifier(org.apache.hadoop.yarn.security.NMTokenIdentifier)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl:updateNMTokenIdentifier(org.apache.hadoop.yarn.security.NMTokenIdentifier)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl:authorizeGetAndStopContainerRequest(org.apache.hadoop.yarn.api.records.ContainerId,org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container,boolean,org.apache.hadoop.yarn.security.NMTokenIdentifier,java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl:authorizeGetAndStopContainerRequest(org.apache.hadoop.yarn.api.records.ContainerId,org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container,boolean,org.apache.hadoop.yarn.security.NMTokenIdentifier,java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl:getAMRMProxyService()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl:setAMRMProxyService(org.apache.hadoop.yarn.server.nodemanager.amrmproxy.AMRMProxyService)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.nodemanager.containermanager.records.AuxServiceFile$TypeEnum:toString()	com.fasterxml.jackson.annotation.JsonValue
org.apache.hadoop.yarn.server.nodemanager.containermanager.records.AuxServiceRecord:getName()	com.fasterxml.jackson.annotation.JsonProperty	value	name
org.apache.hadoop.yarn.server.nodemanager.containermanager.records.AuxServiceRecord:getVersion()	com.fasterxml.jackson.annotation.JsonProperty	value	version
org.apache.hadoop.yarn.server.nodemanager.containermanager.records.AuxServiceRecord:getDescription()	com.fasterxml.jackson.annotation.JsonProperty	value	description
org.apache.hadoop.yarn.server.nodemanager.containermanager.records.AuxServiceRecord:getLaunchTime()	com.fasterxml.jackson.annotation.JsonProperty	value	launch_time
org.apache.hadoop.yarn.server.nodemanager.containermanager.records.AuxServiceRecord:getConfiguration()	com.fasterxml.jackson.annotation.JsonProperty	value	configuration
org.apache.hadoop.yarn.server.nodemanager.containermanager.records.AuxServiceFile:getType()	com.fasterxml.jackson.annotation.JsonProperty	value	type
org.apache.hadoop.yarn.server.nodemanager.containermanager.records.AuxServiceFile:getSrcFile()	com.fasterxml.jackson.annotation.JsonProperty	value	src_file
org.apache.hadoop.yarn.server.nodemanager.containermanager.records.AuxServiceConfiguration:getProperties()	com.fasterxml.jackson.annotation.JsonProperty	value	properties
org.apache.hadoop.yarn.server.nodemanager.containermanager.records.AuxServiceConfiguration:getFiles()	com.fasterxml.jackson.annotation.JsonProperty	value	files
org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.sharedcache.SharedCacheUploader:getActualPath()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.sharedcache.SharedCacheUploader:verifyAccess()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.sharedcache.SharedCacheUploader:fileIsPublic(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.FileSystem,org.apache.hadoop.fs.FileStatus)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.sharedcache.SharedCacheUploader:uploadFile(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.sharedcache.SharedCacheUploader:computeChecksum(org.apache.hadoop.fs.Path)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.sharedcache.SharedCacheUploader:notifySharedCacheManager(java.lang.String,java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ContainerLocalizer:initConfiguration()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ContainerLocalizer:initConfiguration()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ContainerLocalizer:getProxy(java.net.InetSocketAddress)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ContainerLocalizer:getProxy(java.net.InetSocketAddress)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService:handleCacheCleanup()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService:getPublicLocalizer()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService:getPublicLocalizer()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService:getLocalizerRunner(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService:getLocalizerRunner(java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService:getPrivateLocalizers()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService:getPrivateLocalizers()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService:buildTokenFingerprint(org.apache.hadoop.security.token.Token)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService:checkAndInitializeLocalDirs()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalCacheDirectoryManager:getDirectory(java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalResourcesTrackerImpl:checkLocalResource(org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalResourcesTrackerImpl:getDirectoryManager(org.apache.hadoop.fs.Path)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalResourcesTrackerImpl:getDirsHandler()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices:maybeDownloadJars(java.lang.String,java.lang.String,java.lang.String,org.apache.hadoop.yarn.server.nodemanager.containermanager.records.AuxServiceFile$TypeEnum,org.apache.hadoop.conf.Configuration)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices:reloadManifest()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices:loadManifest(org.apache.hadoop.conf.Configuration,boolean)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.AppLogAggregatorImpl:doLogAggregationOutOfBand()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.AppLogAggregatorImpl:doLogAggregationOutOfBand()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.AppLogAggregatorImpl:getUgi()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.AppLogAggregatorImpl:getLogAggregationFileController()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.AppLogAggregatorImpl:getLogAggregationFileControllerContext()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.LogAggregationService:getNumAggregators()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.LogAggregationService:getAppLogAggregators()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.LogAggregationService:getNodeId()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.LogAggregationService:getRollingMonitorInterval()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.LogAggregationService:getLogAggregationFileController(org.apache.hadoop.conf.Configuration)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.numa.NumaResourceAllocator:executeNGetCmdOutput(org.apache.hadoop.conf.Configuration)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.numa.NumaResourceAllocator:getNumaNodesList()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.fpga.FpgaResourceHandlerImpl:<init>(org.apache.hadoop.yarn.server.nodemanager.Context,org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.CGroupsHandler,org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.privileged.PrivilegedOperationExecutor,org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.fpga.AbstractFpgaVendorPlugin,org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.fpga.FpgaDiscoverer)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.fpga.FpgaResourceHandlerImpl:getFpgaAllocator()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.fpga.FpgaResourceAllocator:getAvailableFpga()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.fpga.FpgaResourceAllocator:getAllowedFpga()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.fpga.FpgaResourceAllocator:getAvailableFpgaCount()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.fpga.FpgaResourceAllocator:getUsedFpga()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.fpga.FpgaResourceAllocator:getUsedFpgaCount()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.CGroupElasticMemoryController:<init>(org.apache.hadoop.conf.Configuration,org.apache.hadoop.yarn.server.nodemanager.Context,org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.CGroupsHandler,boolean,boolean,long,java.lang.Runnable)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.CGroupsCpuResourceHandlerImpl:bootstrap(org.apache.hadoop.yarn.util.ResourceCalculatorPlugin,org.apache.hadoop.conf.Configuration)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.CGroupsCpuResourceHandlerImpl:cpuLimitsExist(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.CGroupsCpuResourceHandlerImpl:getOverallLimits(float)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.CGroupsCpuResourceHandlerImpl:getOverallLimits(float)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.gpu.GpuResourceAllocator:<init>(org.apache.hadoop.yarn.server.nodemanager.Context,int)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.gpu.GpuResourceAllocator:getAvailableGpus()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.gpu.GpuResourceAllocator:getDeviceAllocationMapping()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.DefaultOOMHandler:getCGroupsHandler()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.NetworkPacketTaggingHandlerImpl:createNetworkTagMappingManager(org.apache.hadoop.conf.Configuration)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.NetworkPacketTaggingHandlerImpl:createNetworkTagMappingManager(org.apache.hadoop.conf.Configuration)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.ResourceHandlerChain:getResourceHandlerList()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.CGroupsMemoryResourceHandlerImpl:getSwappiness()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.NetworkTagMappingJsonManager:getNetworkTagMapping()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.NetworkTagMappingJsonManager:getNetworkTagMapping()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.CGroupsHandlerImpl:initializeControllerPathsFromMtab(java.util.Map)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.CGroupsHandlerImpl:parseMtab(java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.CGroupsHandlerImpl:findControllerInMtab(java.lang.String,java.util.Map)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.CGroupsResourceCalculator:<init>(java.lang.String,java.lang.String,org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.CGroupsHandler,org.apache.hadoop.yarn.util.Clock,long)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.ResourceHandlerModule:nullifyResourceHandlerChain()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.runtime.DelegatingLinuxContainerRuntime:pickContainerRuntime(java.util.Map)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.runtime.DelegatingLinuxContainerRuntime:isRuntimeAllowed(java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.runtime.OCIContainerRuntime:mountReadOnlyPath(java.lang.String,java.util.Map)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.runtime.RuncContainerRuntime:<init>(org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.privileged.PrivilegedOperationExecutor,org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.CGroupsHandler)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.runtime.DockerLinuxContainerRuntime:<init>(org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.privileged.PrivilegedOperationExecutor,org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.CGroupsHandler)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.runtime.DockerLinuxContainerRuntime:addCGroupParentIfRequired(java.lang.String,java.lang.String,org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.runtime.docker.DockerRunCommand)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl:getContainerRetryContext()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl:getRetryPolicy()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.proto.YarnServerResourceManagerRecoveryProtos$RMAppAttemptStateProto:valueOf(int)	java.lang.Deprecated
org.apache.hadoop.yarn.proto.YarnServerResourceManagerRecoveryProtos$RMAppStateProto:valueOf(int)	java.lang.Deprecated
org.apache.hadoop.yarn.server.resourcemanager.resource.ResourceProfilesManagerImpl:reloadProfiles()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.nodelabels.NodeAttributesManagerImpl:internalUpdateAttributesOnNodes(java.util.Map,org.apache.hadoop.yarn.server.api.protocolrecords.AttributeMappingOperationType,java.util.Map,java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.metrics.TimelineServiceV2Publisher:isPublishContainerEvents()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl:onInvalidStateTransition(org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerEventType,org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerState)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.AdminService:refreshQueues()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.AdminService:refreshAll()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.AdminService:getAccessControlList()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.AdminService:getServer()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.NodesListManager:getNodeRemovalCheckInterval()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.NodesListManager:setNodeRemovalCheckInterval(int)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.NodesListManager:getResolver()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.NodesListManager:getHostsReader()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.RMSecretManagerService:createRMDelegationTokenSecretManager(org.apache.hadoop.conf.Configuration,org.apache.hadoop.yarn.server.resourcemanager.RMContext)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.placement.FSPlacementRule:getParentRule()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.placement.UserGroupMappingPlacementRule:<init>(boolean,java.util.List,org.apache.hadoop.security.Groups)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.placement.UserGroupMappingPlacementRule:initialize(org.apache.hadoop.yarn.server.resourcemanager.scheduler.ResourceScheduler)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.placement.UserGroupMappingPlacementRule:getQueueMappings()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.placement.UserGroupMappingPlacementRule:setQueueManager(org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerQueueManager)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.placement.UserGroupMappingPlacementRule:setQueueManager(org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerQueueManager)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.placement.PlacementManager:getPlacementRules()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.volume.csi.VolumeManagerImpl:registerCsiDriverAdaptor(java.lang.String,org.apache.hadoop.yarn.api.CsiAdaptorProtocol)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.volume.csi.lifecycle.VolumeImpl:setClient(org.apache.hadoop.yarn.api.CsiAdaptorProtocol)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.federation.FederationStateStoreService:getStateStoreClient()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.federation.FederationStateStoreService:getStateStoreHeartbeatThread()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.NodesListManager$CachedResolver:addToCache(java.lang.String,java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.NodesListManager$CachedResolver:getExpireChecker()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.DBManager:setDb(org.iq80.leveldb.DB)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.CuratorBasedElectorService:getCuratorClient()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.YarnScheduler:getQueueInfo(java.lang.String,boolean,boolean)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.resourcemanager.scheduler.YarnScheduler:getQueueInfo(java.lang.String,boolean,boolean)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.server.resourcemanager.scheduler.YarnScheduler:getQueueUserAclInfo()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.resourcemanager.scheduler.YarnScheduler:getQueueUserAclInfo()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.server.resourcemanager.scheduler.YarnScheduler:getClusterResource()	org.apache.hadoop.classification.InterfaceAudience$LimitedPrivate	value	{yarn}
org.apache.hadoop.yarn.server.resourcemanager.scheduler.YarnScheduler:getClusterResource()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.resourcemanager.scheduler.YarnScheduler:getMinimumResourceCapability()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.resourcemanager.scheduler.YarnScheduler:getMinimumResourceCapability()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.server.resourcemanager.scheduler.YarnScheduler:getMaximumResourceCapability()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.resourcemanager.scheduler.YarnScheduler:getMaximumResourceCapability()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.server.resourcemanager.scheduler.YarnScheduler:getMaximumResourceCapability(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.resourcemanager.scheduler.YarnScheduler:getMaximumResourceCapability(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.server.resourcemanager.scheduler.YarnScheduler:getResourceCalculator()	org.apache.hadoop.classification.InterfaceAudience$LimitedPrivate	value	{yarn}
org.apache.hadoop.yarn.server.resourcemanager.scheduler.YarnScheduler:getResourceCalculator()	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.yarn.server.resourcemanager.scheduler.YarnScheduler:getNumClusterNodes()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.resourcemanager.scheduler.YarnScheduler:getNumClusterNodes()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.server.resourcemanager.scheduler.YarnScheduler:allocate(org.apache.hadoop.yarn.api.records.ApplicationAttemptId,java.util.List,java.util.List,java.util.List,java.util.List,java.util.List,org.apache.hadoop.yarn.server.resourcemanager.scheduler.ContainerUpdates)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.resourcemanager.scheduler.YarnScheduler:allocate(org.apache.hadoop.yarn.api.records.ApplicationAttemptId,java.util.List,java.util.List,java.util.List,java.util.List,java.util.List,org.apache.hadoop.yarn.server.resourcemanager.scheduler.ContainerUpdates)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.server.resourcemanager.scheduler.YarnScheduler:getNodeReport(org.apache.hadoop.yarn.api.records.NodeId)	org.apache.hadoop.classification.InterfaceAudience$LimitedPrivate	value	{yarn}
org.apache.hadoop.yarn.server.resourcemanager.scheduler.YarnScheduler:getNodeReport(org.apache.hadoop.yarn.api.records.NodeId)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.server.resourcemanager.scheduler.YarnScheduler:getSchedulerAppInfo(org.apache.hadoop.yarn.api.records.ApplicationAttemptId)	org.apache.hadoop.classification.InterfaceAudience$LimitedPrivate	value	{yarn}
org.apache.hadoop.yarn.server.resourcemanager.scheduler.YarnScheduler:getSchedulerAppInfo(org.apache.hadoop.yarn.api.records.ApplicationAttemptId)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.server.resourcemanager.scheduler.YarnScheduler:getAppResourceUsageReport(org.apache.hadoop.yarn.api.records.ApplicationAttemptId)	org.apache.hadoop.classification.InterfaceAudience$LimitedPrivate	value	{yarn}
org.apache.hadoop.yarn.server.resourcemanager.scheduler.YarnScheduler:getAppResourceUsageReport(org.apache.hadoop.yarn.api.records.ApplicationAttemptId)	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.yarn.server.resourcemanager.scheduler.YarnScheduler:getRootQueueMetrics()	org.apache.hadoop.classification.InterfaceAudience$LimitedPrivate	value	{yarn}
org.apache.hadoop.yarn.server.resourcemanager.scheduler.YarnScheduler:getRootQueueMetrics()	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.yarn.server.resourcemanager.scheduler.YarnScheduler:getAppsInQueue(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$LimitedPrivate	value	{yarn}
org.apache.hadoop.yarn.server.resourcemanager.scheduler.YarnScheduler:getAppsInQueue(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.server.resourcemanager.scheduler.YarnScheduler:getRMContainer(org.apache.hadoop.yarn.api.records.ContainerId)	org.apache.hadoop.classification.InterfaceAudience$LimitedPrivate	value	{yarn}
org.apache.hadoop.yarn.server.resourcemanager.scheduler.YarnScheduler:getRMContainer(org.apache.hadoop.yarn.api.records.ContainerId)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.resourcemanager.scheduler.YarnScheduler:moveApplication(org.apache.hadoop.yarn.api.records.ApplicationId,java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$LimitedPrivate	value	{yarn}
org.apache.hadoop.yarn.server.resourcemanager.scheduler.YarnScheduler:moveApplication(org.apache.hadoop.yarn.api.records.ApplicationId,java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.yarn.server.resourcemanager.scheduler.YarnScheduler:preValidateMoveApplication(org.apache.hadoop.yarn.api.records.ApplicationId,java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$LimitedPrivate	value	{yarn}
org.apache.hadoop.yarn.server.resourcemanager.scheduler.YarnScheduler:preValidateMoveApplication(org.apache.hadoop.yarn.api.records.ApplicationId,java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.yarn.server.resourcemanager.scheduler.YarnScheduler:checkAndGetApplicationLifetime(java.lang.String,long)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.resourcemanager.scheduler.YarnScheduler:checkAndGetApplicationLifetime(java.lang.String,long)	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.yarn.server.resourcemanager.scheduler.YarnScheduler:getMaximumApplicationLifetime(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.resourcemanager.scheduler.YarnScheduler:getMaximumApplicationLifetime(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Evolving
org.apache.hadoop.yarn.server.resourcemanager.scheduler.ActiveUsersManager:activateApplication(java.lang.String,org.apache.hadoop.yarn.api.records.ApplicationId)	org.apache.hadoop.yarn.server.utils.Lock	value	{Lorg/apache/hadoop/yarn/server/resourcemanager/scheduler/Queue;,Lorg/apache/hadoop/yarn/server/resourcemanager/scheduler/SchedulerApplicationAttempt;}
org.apache.hadoop.yarn.server.resourcemanager.scheduler.ActiveUsersManager:deactivateApplication(java.lang.String,org.apache.hadoop.yarn.api.records.ApplicationId)	org.apache.hadoop.yarn.server.utils.Lock	value	{Lorg/apache/hadoop/yarn/server/resourcemanager/scheduler/Queue;,Lorg/apache/hadoop/yarn/server/resourcemanager/scheduler/SchedulerApplicationAttempt;}
org.apache.hadoop.yarn.server.resourcemanager.scheduler.ActiveUsersManager:getNumActiveUsers()	org.apache.hadoop.yarn.server.utils.Lock	value	{Lorg/apache/hadoop/yarn/server/resourcemanager/scheduler/Queue;,Lorg/apache/hadoop/yarn/server/resourcemanager/scheduler/SchedulerApplicationAttempt;}
org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp:getNodeIdToUnreserve(org.apache.hadoop.yarn.server.scheduler.SchedulerRequestKey,org.apache.hadoop.yarn.api.records.Resource,org.apache.hadoop.yarn.util.resource.ResourceCalculator)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp:findNodeToUnreserve(org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerNode,org.apache.hadoop.yarn.server.scheduler.SchedulerRequestKey,org.apache.hadoop.yarn.api.records.Resource)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode:deductUnallocatedResource(org.apache.hadoop.yarn.api.records.Resource)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.placement.SingleConstraintAppPlacementAllocator:getTargetNodePartition()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.placement.MultiNodeSorter:getMultiNodeLookupPolicy()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.placement.MultiNodeSorter:reSortClusterNodes()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerApplicationAttempt:getCurrentReservation()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerApplicationAttempt:getCurrentReservation()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerApplicationAttempt:setSchedulingOpportunities(org.apache.hadoop.yarn.server.scheduler.SchedulerRequestKey,int)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerApplicationAttempt:getLiveContainersMap()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerApplicationAttempt:hasPendingResourceRequest(java.lang.String,org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.SchedulingMode)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerApplicationAttempt:getAppAttemptResourceUsage()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.QueueMetrics:clearQueueMetrics()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.scheduler.QueueMetrics:getAggregatedPreemptedSecondsResources()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.QueueMetrics:getAggregateMemoryMBSecondsPreempted()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.QueueMetrics:getAggregateVcoreSecondsPreempted()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.QueueMetrics:getAggregateMemoryMBPreempted()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.QueueMetrics:getAggregateVcoresPreempted()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.QueueMetrics:getQueueMetricsForCustomResources()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.Allocation:setResourceLimit(org.apache.hadoop.yarn.api.records.Resource)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.ClusterNodeTracker:setForceConfiguredMaxAllocation(boolean)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.conf.FSSchedulerConfigurationStore:writeTmpConfig(org.apache.hadoop.conf.Configuration)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.conf.FSSchedulerConfigurationStore:writeConfigurationToFileSystem(org.apache.hadoop.conf.Configuration)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.conf.ZKConfigurationStore:getLogs()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.conf.ZKConfigurationStore:getZkData(java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.conf.ZKConfigurationStore:setZkData(java.lang.String,byte[])	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.conf.ZKConfigurationStore:safeCreateZkData(java.lang.String,byte[])	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.conf.MutableCSConfigurationProvider:getConfStore()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.conf.LeveldbConfigurationStore:getLogs()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.conf.LeveldbConfigurationStore:getDB()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.conf.LeveldbConfigurationStore:storeVersion(org.apache.hadoop.yarn.server.records.Version)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerMetrics:destroy()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerMetrics:getNumOfNodeUpdate()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerMetrics:getNumOfAllocates()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerMetrics:getNumOfCommitSuccess()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.UsersManager:getUsageRatio(java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.UsersManager:getNumActiveUsersWithOnlyPendingApps()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration:setCapacity(java.lang.String,java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration:setCapacityByLabel(java.lang.String,java.lang.String,java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration:setState(java.lang.String,org.apache.hadoop.yarn.api.records.QueueState)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration:setState(java.lang.String,org.apache.hadoop.yarn.api.records.QueueState)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration:setReservationAcls(java.lang.String,java.util.Map)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration:setPriorityAcls(java.lang.String,org.apache.hadoop.yarn.api.records.Priority,org.apache.hadoop.yarn.api.records.Priority,java.lang.String[])	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration:getQueuePriority(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration:setQueuePriority(java.lang.String,int)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration:setNodeLocalityDelay(int)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration:setOverrideWithQueueMappings(boolean)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration:setOverrideWithQueueMappings(boolean)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration:setQueueMappingEntities(java.util.List,java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration:setQueuePlacementRules(java.util.Collection)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration:setQueuePlacementRules(java.util.Collection)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration:setQueueMappings(java.util.List)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration:setQueueMappings(java.util.List)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration:setWorkflowPriorityMappings(java.util.List)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration:setWorkflowPriorityMappings(java.util.List)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration:setOrderingPolicy(java.lang.String,java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration:setOrderingPolicyParameter(java.lang.String,java.lang.String,java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration:setQueueOrderingPolicy(java.lang.String,java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration:getQueueOrderingPolicy(java.lang.String,java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration:setPUOrderingPolicyUnderUtilizedPreemptionEnabled(boolean)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration:setPUOrderingPolicyUnderUtilizedPreemptionDelay(long)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration:setPUOrderingPolicyUnderUtilizedPreemptionMoveReservation(boolean)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration:isAutoCreateChildQueueEnabled(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration:setAutoCreateChildQueueEnabled(java.lang.String,boolean)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration:setAutoCreateChildQueueEnabled(java.lang.String,boolean)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration:getAutoCreatedQueueTemplateConfPrefix(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration:getShouldFailAutoQueueCreationWhenGuaranteedCapacityExceeded(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration:setShouldFailAutoQueueCreationWhenGuaranteedCapacityExceeded(java.lang.String,boolean)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration:setShouldFailAutoQueueCreationWhenGuaranteedCapacityExceeded(java.lang.String,boolean)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration:getAutoCreatedQueuesMaxChildQueuesLimit(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration:getAutoCreatedQueueManagementPolicy(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration:getAutoCreatedQueueManagementPolicyClass(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration:setAutoCreatedLeafQueueConfigCapacity(java.lang.String,float)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration:setAutoCreatedLeafQueueConfigCapacity(java.lang.String,float)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration:setAutoCreatedLeafQueueTemplateCapacityByLabel(java.lang.String,java.lang.String,float)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration:setAutoCreatedLeafQueueTemplateCapacityByLabel(java.lang.String,java.lang.String,float)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration:setAutoCreatedLeafQueueConfigMaxCapacity(java.lang.String,float)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration:setAutoCreatedLeafQueueConfigMaxCapacity(java.lang.String,float)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration:setAutoCreatedLeafQueueTemplateMaxCapacity(java.lang.String,java.lang.String,float)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration:setAutoCreatedLeafQueueTemplateMaxCapacity(java.lang.String,java.lang.String,float)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration:setAutoCreatedLeafQueueConfigUserLimit(java.lang.String,int)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration:setAutoCreatedLeafQueueConfigUserLimit(java.lang.String,int)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration:setAutoCreatedLeafQueueConfigUserLimitFactor(java.lang.String,float)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration:setAutoCreatedLeafQueueConfigUserLimitFactor(java.lang.String,float)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration:setAutoCreatedLeafQueueConfigDefaultNodeLabelExpression(java.lang.String,java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration:setAutoCreatedLeafQueueConfigDefaultNodeLabelExpression(java.lang.String,java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration:setAutoCreatedLeafQueueConfigMaximumAllocation(java.lang.String,java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration:setAutoCreatedLeafQueueConfigMaximumAllocation(java.lang.String,java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration:setMinimumResourceRequirement(java.lang.String,java.lang.String,org.apache.hadoop.yarn.api.records.Resource)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration:setMaximumResourceRequirement(java.lang.String,java.lang.String,org.apache.hadoop.yarn.api.records.Resource)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CSQueue:assignContainers(org.apache.hadoop.yarn.api.records.Resource,org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerNode,org.apache.hadoop.yarn.server.resourcemanager.scheduler.ResourceLimits,org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.SchedulingMode)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler:setResourceCalculator(org.apache.hadoop.yarn.util.resource.ResourceCalculator)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler:initScheduler(org.apache.hadoop.conf.Configuration)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler:getUserGroupMappingPlacementRule()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler:updatePlacementRules()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler:initializeQueues(org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration)	org.apache.hadoop.yarn.server.utils.Lock	value	{Lorg/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/CapacityScheduler;}
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler:reinitializeQueues(org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration)	org.apache.hadoop.yarn.server.utils.Lock	value	{Lorg/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/CapacityScheduler;}
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler:allocate(org.apache.hadoop.yarn.api.records.ApplicationAttemptId,java.util.List,java.util.List,java.util.List,java.util.List,java.util.List,org.apache.hadoop.yarn.server.resourcemanager.scheduler.ContainerUpdates)	org.apache.hadoop.yarn.server.utils.Lock	value	{Lorg/apache/hadoop/yarn/server/utils/Lock$NoLock;}
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler:getQueueInfo(java.lang.String,boolean,boolean)	org.apache.hadoop.yarn.server.utils.Lock	value	{Lorg/apache/hadoop/yarn/server/utils/Lock$NoLock;}
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler:getQueueUserAclInfo()	org.apache.hadoop.yarn.server.utils.Lock	value	{Lorg/apache/hadoop/yarn/server/utils/Lock$NoLock;}
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler:allocateContainersToNode(org.apache.hadoop.yarn.server.resourcemanager.scheduler.placement.CandidateNodeSet,boolean)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler:getApplicationAttempt(org.apache.hadoop.yarn.api.records.ApplicationAttemptId)	org.apache.hadoop.yarn.server.utils.Lock	value	{Lorg/apache/hadoop/yarn/server/utils/Lock$NoLock;}
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler:getApplicationAttempt(org.apache.hadoop.yarn.api.records.ApplicationAttemptId)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler:getNode(org.apache.hadoop.yarn.api.records.NodeId)	org.apache.hadoop.yarn.server.utils.Lock	value	{Lorg/apache/hadoop/yarn/server/utils/Lock$NoLock;}
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler:getAllNodes()	org.apache.hadoop.yarn.server.utils.Lock	value	{Lorg/apache/hadoop/yarn/server/utils/Lock$NoLock;}
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler:recover(org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$RMState)	org.apache.hadoop.yarn.server.utils.Lock	value	{Lorg/apache/hadoop/yarn/server/utils/Lock$NoLock;}
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler:killContainer(org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainer)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler:submitResourceCommitRequest(org.apache.hadoop.yarn.api.records.Resource,org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CSAssignment)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler:createResourceCommitRequest(org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CSAssignment)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler:setMaxRunningAppsEnforcer(org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CSMaxRunningAppsEnforcer)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler:setQueueManager(org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerQueueManager)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler:getNode(org.apache.hadoop.yarn.api.records.NodeId)	org.apache.hadoop.yarn.server.utils.Lock	value	{Lorg/apache/hadoop/yarn/server/utils/Lock$NoLock;}
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler:getApplicationAttempt(org.apache.hadoop.yarn.api.records.ApplicationAttemptId)	org.apache.hadoop.yarn.server.utils.Lock	value	{Lorg/apache/hadoop/yarn/server/utils/Lock$NoLock;}
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler:getApplicationAttempt(org.apache.hadoop.yarn.api.records.ApplicationAttemptId)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerQueueManager:getShortNameQueues()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerQueueManager:setQueueAcls(org.apache.hadoop.yarn.security.YarnAuthorizationProvider,org.apache.hadoop.yarn.server.resourcemanager.security.AppPriorityACLsManager,org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CSQueueStore)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerQueueManager:getQueueStateManager()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CSQueueStore:getShortNameQueues()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.policy.PriorityUtilizationQueueOrderingPolicy:getQueues()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.UsersManager$User:setResourceUsage(org.apache.hadoop.yarn.server.resourcemanager.scheduler.ResourceUsage)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.AbstractCSQueue:getMaximumAllocation()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.AbstractCSQueue:getMinimumAllocation()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.AbstractCSQueue:getReservationContinueLooking()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.AbstractCSQueue:getACLs()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.AbstractCSQueue:getPreemptionDisabled()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.AbstractCSQueue:getIntraQueuePreemptionDisabled()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.AbstractCSQueue:getIntraQueuePreemptionDisabledInHierarchy()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.AbstractCSQueue:getQueueCapacities()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.AbstractCSQueue:getQueueResourceUsage()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.AbstractCSQueue:assignContainers(org.apache.hadoop.yarn.api.records.Resource,org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerNode,org.apache.hadoop.yarn.server.resourcemanager.scheduler.ResourceLimits,org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.SchedulingMode)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CSQueueUtils:updateQueueStatistics(org.apache.hadoop.yarn.util.resource.ResourceCalculator,org.apache.hadoop.yarn.api.records.Resource,org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.AbstractCSQueue,org.apache.hadoop.yarn.server.resourcemanager.nodelabels.RMNodeLabelsManager,java.lang.String)	org.apache.hadoop.yarn.server.utils.Lock	value	{Lorg/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/CSQueue;}
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.WorkflowPriorityMappingsManager:initialize(org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.QueueManagementDynamicEditPolicy:<init>(org.apache.hadoop.yarn.server.resourcemanager.RMContext,org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.QueueManagementDynamicEditPolicy:<init>(org.apache.hadoop.yarn.server.resourcemanager.RMContext,org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler,org.apache.hadoop.yarn.util.Clock)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.QueueManagementDynamicEditPolicy:manageAutoCreatedLeafQueues()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.QueueManagementDynamicEditPolicy:computeQueueManagementChanges(org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ManagedParentQueue)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.preemption.PreemptionManager:getKillableContainersMap(java.lang.String,java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.queuemanagement.GuaranteedOrZeroCapacityOverTimePolicy:updateLeafQueueState()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.queuemanagement.GuaranteedOrZeroCapacityOverTimePolicy:isActive(org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.AutoCreatedLeafQueue,java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.queuemanagement.GuaranteedOrZeroCapacityOverTimePolicy:getMaxLeavesToBeActivated(float,float,int)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.queuemanagement.GuaranteedOrZeroCapacityOverTimePolicy:getLeafQueueState(org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue,java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.queuemanagement.GuaranteedOrZeroCapacityOverTimePolicy:getAbsoluteActivatedChildQueueCapacity(java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue:getMinimumAllocationFactor()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue:getMaxAMResourcePerQueuePercent()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue:setUserLimit(int)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue:setUserLimitFactor(float)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue:getNumPendingApplications(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue:getNumActiveApplications(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue:getUserLimit()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue:getUserLimitFactor()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue:getUser(java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue:getPriorityACLs()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue:calculateAndGetAMResourceLimit()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue:getUserAMResourceLimit()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue:computeUserLimitAndSetHeadroom(org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp,org.apache.hadoop.yarn.api.records.Resource,java.lang.String,org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.SchedulingMode,org.apache.hadoop.yarn.api.records.Resource)	org.apache.hadoop.yarn.server.utils.Lock	value	{Lorg/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/LeafQueue;}
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue:getNodeLocalityDelay()	org.apache.hadoop.yarn.server.utils.Lock	value	{Lorg/apache/hadoop/yarn/server/utils/Lock$NoLock;}
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue:getRackLocalityAdditionalDelay()	org.apache.hadoop.yarn.server.utils.Lock	value	{Lorg/apache/hadoop/yarn/server/utils/Lock$NoLock;}
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue:getRackLocalityFullReset()	org.apache.hadoop.yarn.server.utils.Lock	value	{Lorg/apache/hadoop/yarn/server/utils/Lock$NoLock;}
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue:canAssignToUser(org.apache.hadoop.yarn.api.records.Resource,java.lang.String,org.apache.hadoop.yarn.api.records.Resource,org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp,java.lang.String,org.apache.hadoop.yarn.server.resourcemanager.scheduler.ResourceLimits)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSQueue:getMaxAMShare()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.AllocationFileLoaderService:getAllocationFile(org.apache.hadoop.conf.Configuration)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSSchedulerNode:getPreemptionList()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSLeafQueue:isStarvedForMinShare()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSLeafQueue:isStarvedForFairShare()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSLeafQueue:isStarved()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.DominantResourceFairnessPolicy$DominantResourceFairnessComparator2:calculateClusterAndFairRatios(org.apache.hadoop.yarn.api.records.ResourceInformation[],float,org.apache.hadoop.yarn.api.records.ResourceInformation[],double[])	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.DominantResourceFairnessPolicy$DominantResourceFairnessComparator2:calculateMinShareRatios(org.apache.hadoop.yarn.api.records.ResourceInformation[],org.apache.hadoop.yarn.api.records.ResourceInformation[])	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.DominantResourceFairnessPolicy$DominantResourceFairnessComparatorN:sortRatios(float[][],float[][])	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.DominantResourceFairnessPolicy$DominantResourceFairnessComparatorN:calculateClusterAndFairRatios(org.apache.hadoop.yarn.api.records.Resource,org.apache.hadoop.yarn.api.records.Resource,float[][],float)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.DominantResourceFairnessPolicy$DominantResourceFairnessComparatorN:calculateMinShareRatios(org.apache.hadoop.yarn.api.records.Resource,org.apache.hadoop.yarn.api.records.Resource,float[][])	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.DominantResourceFairnessPolicy$DominantResourceFairnessComparatorN:compareRatios(float[][],float[][],int)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.SchedulingPolicy:initialize(org.apache.hadoop.yarn.api.records.Resource)	java.lang.Deprecated
org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.converter.FSConfigToCSConfigConverter:convert(org.apache.hadoop.conf.Configuration)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.converter.FSConfigToCSConfigConverter:getClusterResource()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.converter.FSConfigToCSConfigConverter:setClusterResource(org.apache.hadoop.yarn.api.records.Resource)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.converter.FSConfigToCSConfigConverter:getRuleHandler()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.converter.FSConfigToCSConfigConverter:getYarnSiteConfig()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.converter.FSConfigToCSConfigConverter:getCapacitySchedulerConfig()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.converter.FSConfigToCSConfigConverter:setConvertPlacementRules(boolean)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.converter.FSConfigToCSConfigConverter:setPlacementConverter(org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.converter.QueuePlacementConverter)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.converter.FSConfigToCSConfigArgumentHandler:<init>(org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.converter.ConversionOptions,org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.converter.ConvertedConfigValidator)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.converter.FSConfigToCSConfigArgumentHandler:setConverterSupplier(java.util.function.Supplier)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.converter.FSConfigToCSConfigRuleHandler:<init>(java.util.Properties,org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.converter.ConversionOptions)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.converter.FSConfigToCSConfigRuleHandler:getActions()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSQueueMetrics:getSchedulingPolicy()	org.apache.hadoop.metrics2.annotation.Metric	value	{Scheduling policy}
org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSQueueMetrics:forQueue(org.apache.hadoop.metrics2.MetricsSystem,java.lang.String,org.apache.hadoop.yarn.server.resourcemanager.scheduler.Queue,boolean,org.apache.hadoop.conf.Configuration)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt:setEnableAMPreemption(boolean)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSOpDurations:addContinuousSchedulingRunDuration(long)	java.lang.Deprecated
org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSOpDurations:hasUpdateThreadRunChanged()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.QueueManager:createQueue(java.lang.String,org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSQueueType)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.QueueManager:isQueueNameValid(java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler:update()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler:getNodeLocalityDelayMs()	java.lang.Deprecated
org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler:getRackLocalityDelayMs()	java.lang.Deprecated
org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler:isContinuousSchedulingEnabled()	java.lang.Deprecated
org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler:getContinuousSchedulingSleepMs()	java.lang.Deprecated
org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler:killContainer(org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainer)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler:continuousSchedulingAttempt()	java.lang.Deprecated
org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler:attemptScheduling(org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSSchedulerNode)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler:createPreemptionThread()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler:findLowestCommonAncestorQueue(org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSQueue,org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSQueue)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.AllocationConfiguration:getQueueMaxApps(java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.AllocationConfiguration:getQueueMaxAMShare(java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.AllocationConfiguration:getMinResources(java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.AllocationConfiguration:getMaxResources(java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.AllocationConfiguration:getQueueMaxContainerAllocation(java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.AllocationConfiguration:getMaxChildResources(java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.AllocationConfiguration:getSchedulingPolicy(java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.AllocationConfiguration:setReservationWindow(long)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.AllocationConfiguration:setAverageCapacity(int)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.ReservationQueueConfiguration:setReservationWindow(long)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.ReservationQueueConfiguration:setAverageCapacity(int)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairSchedulerConfiguration:isContinuousSchedulingEnabled()	java.lang.Deprecated
org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairSchedulerConfiguration:getContinuousSchedulingSleepMs()	java.lang.Deprecated
org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairSchedulerConfiguration:getLocalityDelayNodeMs()	java.lang.Deprecated
org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairSchedulerConfiguration:getLocalityDelayRackMs()	java.lang.Deprecated
org.apache.hadoop.yarn.server.resourcemanager.scheduler.policy.FairOrderingPolicy:getSizeBasedWeight()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.policy.FairOrderingPolicy:setSizeBasedWeight(boolean)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.activities.ActivitiesManager:getAppActivitiesMaxQueueLength()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerUtils:normalizeRequest(org.apache.hadoop.yarn.api.records.ResourceRequest,org.apache.hadoop.yarn.util.resource.ResourceCalculator,org.apache.hadoop.yarn.api.records.Resource,org.apache.hadoop.yarn.api.records.Resource)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerUtils:checkResourceRequestAgainstAvailableResource(org.apache.hadoop.yarn.api.records.Resource,org.apache.hadoop.yarn.api.records.Resource)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerUtils:checkResourceRequestAgainstAvailableResource(org.apache.hadoop.yarn.api.records.Resource,org.apache.hadoop.yarn.api.records.Resource)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerUtils:hasPendingResourceRequest(org.apache.hadoop.yarn.util.resource.ResourceCalculator,org.apache.hadoop.yarn.server.resourcemanager.scheduler.ResourceUsage,java.lang.String,org.apache.hadoop.yarn.api.records.Resource,org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.SchedulingMode)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.scheduler.fifo.FifoScheduler:addApplication(org.apache.hadoop.yarn.api.records.ApplicationId,java.lang.String,java.lang.String,boolean)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.fifo.FifoScheduler:addApplicationAttempt(org.apache.hadoop.yarn.api.records.ApplicationAttemptId,boolean,boolean)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.fifo.FifoScheduler:completedContainerInternal(org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainer,org.apache.hadoop.yarn.api.records.ContainerStatus,org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerEventType)	org.apache.hadoop.yarn.server.utils.Lock	value	{Lorg/apache/hadoop/yarn/server/resourcemanager/scheduler/fifo/FifoScheduler;}
org.apache.hadoop.yarn.server.resourcemanager.scheduler.fifo.FifoScheduler:killContainer(org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainer)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.constraint.AllocationTagsManager:getPerAppNodeMappings()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.constraint.AllocationTagsManager:getPerAppRackMappings()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.constraint.AllocationTagsManager:getGlobalNodeMapping()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.constraint.AllocationTagsManager:getGlobalRackMapping()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.constraint.AllocationTags:createSingleAppAllocationTags(org.apache.hadoop.yarn.api.records.ApplicationId,java.util.Set)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.constraint.AllocationTags:createGlobalAllocationTags(java.util.Set)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.constraint.AllocationTags:createOtherAppAllocationTags(org.apache.hadoop.yarn.api.records.ApplicationId,java.util.Set)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.constraint.AllocationTagsManager$TypeToCountedTags:getTypeToTagsWithCount()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.distributed.NodeQueueLoadMonitor:<init>(org.apache.hadoop.yarn.server.resourcemanager.scheduler.distributed.NodeQueueLoadMonitor$LoadComparator)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.distributed.CentralizedOpportunisticContainerAllocator:setNodeQueueLoadMonitor(org.apache.hadoop.yarn.server.resourcemanager.scheduler.distributed.NodeQueueLoadMonitor)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler:getNodeTracker()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler:getSchedulingMonitorManager()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler:clearPendingContainerCache()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler:completedContainer(org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainer,org.apache.hadoop.yarn.api.records.ContainerStatus,org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerEventType)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler:completedContainer(org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainer,org.apache.hadoop.yarn.api.records.ContainerStatus,org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerEventType)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler:setClock(org.apache.hadoop.yarn.util.Clock)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler:getNode(org.apache.hadoop.yarn.api.records.NodeId)	org.apache.hadoop.yarn.server.utils.Lock	value	{Lorg/apache/hadoop/yarn/server/utils/Lock$NoLock;}
org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler:killContainer(org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainer)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler:update()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore:isFencedState()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.recovery.FileSystemRMStateStore:getAppDir(org.apache.hadoop.yarn.api.records.ApplicationId)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.recovery.FileSystemRMStateStore:getAppAttemptDir(org.apache.hadoop.yarn.api.records.ApplicationAttemptId)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.recovery.FileSystemRMStateStore:renameFile(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.recovery.FileSystemRMStateStore:renameFile(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.recovery.FileSystemRMStateStore:getNodePath(org.apache.hadoop.fs.Path,java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.recovery.FileSystemRMStateStore:getNodePath(org.apache.hadoop.fs.Path,java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.recovery.FileSystemRMStateStore:getNumRetries()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.recovery.FileSystemRMStateStore:getRetryInterval()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.recovery.MemoryRMStateStore:getState()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.recovery.records.ApplicationStateData:getSubmitTime()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.resourcemanager.recovery.records.ApplicationStateData:getSubmitTime()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.resourcemanager.recovery.records.ApplicationStateData:setSubmitTime(long)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.resourcemanager.recovery.records.ApplicationStateData:setSubmitTime(long)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.resourcemanager.recovery.records.ApplicationStateData:getStartTime()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.resourcemanager.recovery.records.ApplicationStateData:getStartTime()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.server.resourcemanager.recovery.records.ApplicationStateData:setStartTime(long)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.recovery.records.ApplicationStateData:setStartTime(long)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.resourcemanager.recovery.records.ApplicationStateData:getLaunchTime()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.resourcemanager.recovery.records.ApplicationStateData:getLaunchTime()	org.apache.hadoop.classification.InterfaceStability$Stable
org.apache.hadoop.yarn.server.resourcemanager.recovery.records.ApplicationStateData:setLaunchTime(long)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.recovery.records.ApplicationStateData:setLaunchTime(long)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.resourcemanager.recovery.records.ApplicationStateData:setUser(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.resourcemanager.recovery.records.ApplicationStateData:setUser(java.lang.String)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.resourcemanager.recovery.records.ApplicationStateData:getUser()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.resourcemanager.recovery.records.ApplicationStateData:getUser()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.resourcemanager.recovery.records.ApplicationStateData:getApplicationSubmissionContext()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.resourcemanager.recovery.records.ApplicationStateData:getApplicationSubmissionContext()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.resourcemanager.recovery.records.ApplicationStateData:setApplicationSubmissionContext(org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.resourcemanager.recovery.records.ApplicationStateData:setApplicationSubmissionContext(org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.resourcemanager.recovery.records.ApplicationStateData:getApplicationTimeouts()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.resourcemanager.recovery.records.ApplicationStateData:setApplicationTimeouts(java.util.Map)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.resourcemanager.recovery.records.ApplicationAttemptStateData:getAttemptId()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.resourcemanager.recovery.records.ApplicationAttemptStateData:getAttemptId()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.resourcemanager.recovery.records.ApplicationAttemptStateData:getMasterContainer()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.resourcemanager.recovery.records.ApplicationAttemptStateData:getMasterContainer()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.resourcemanager.recovery.records.ApplicationAttemptStateData:getAppAttemptTokens()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.resourcemanager.recovery.records.ApplicationAttemptStateData:getAppAttemptTokens()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.resourcemanager.recovery.records.ApplicationAttemptStateData:getMemorySeconds()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.resourcemanager.recovery.records.ApplicationAttemptStateData:getMemorySeconds()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.resourcemanager.recovery.records.ApplicationAttemptStateData:setMemorySeconds(long)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.resourcemanager.recovery.records.ApplicationAttemptStateData:setMemorySeconds(long)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.resourcemanager.recovery.records.ApplicationAttemptStateData:getVcoreSeconds()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.resourcemanager.recovery.records.ApplicationAttemptStateData:getVcoreSeconds()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.resourcemanager.recovery.records.ApplicationAttemptStateData:setVcoreSeconds(long)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.resourcemanager.recovery.records.ApplicationAttemptStateData:setVcoreSeconds(long)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.resourcemanager.recovery.records.ApplicationAttemptStateData:getPreemptedMemorySeconds()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.resourcemanager.recovery.records.ApplicationAttemptStateData:getPreemptedMemorySeconds()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.resourcemanager.recovery.records.ApplicationAttemptStateData:setPreemptedMemorySeconds(long)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.resourcemanager.recovery.records.ApplicationAttemptStateData:setPreemptedMemorySeconds(long)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.resourcemanager.recovery.records.ApplicationAttemptStateData:getPreemptedVcoreSeconds()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.resourcemanager.recovery.records.ApplicationAttemptStateData:getPreemptedVcoreSeconds()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.resourcemanager.recovery.records.ApplicationAttemptStateData:setPreemptedVcoreSeconds(long)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.resourcemanager.recovery.records.ApplicationAttemptStateData:setPreemptedVcoreSeconds(long)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.resourcemanager.recovery.records.ApplicationAttemptStateData:getResourceSecondsMap()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.resourcemanager.recovery.records.ApplicationAttemptStateData:getResourceSecondsMap()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.resourcemanager.recovery.records.ApplicationAttemptStateData:setResourceSecondsMap(java.util.Map)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.resourcemanager.recovery.records.ApplicationAttemptStateData:setResourceSecondsMap(java.util.Map)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.resourcemanager.recovery.records.ApplicationAttemptStateData:getPreemptedResourceSecondsMap()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.resourcemanager.recovery.records.ApplicationAttemptStateData:getPreemptedResourceSecondsMap()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.resourcemanager.recovery.records.ApplicationAttemptStateData:setPreemptedResourceSecondsMap(java.util.Map)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.resourcemanager.recovery.records.ApplicationAttemptStateData:setPreemptedResourceSecondsMap(java.util.Map)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.resourcemanager.recovery.records.ApplicationAttemptStateData:getTotalAllocatedContainers()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.resourcemanager.recovery.records.ApplicationAttemptStateData:getTotalAllocatedContainers()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.resourcemanager.recovery.records.ApplicationAttemptStateData:setTotalAllocatedContainers(int)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.resourcemanager.recovery.records.ApplicationAttemptStateData:setTotalAllocatedContainers(int)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.resourcemanager.recovery.records.AMRMTokenSecretManagerState:getCurrentMasterKey()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.resourcemanager.recovery.records.AMRMTokenSecretManagerState:getCurrentMasterKey()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.resourcemanager.recovery.records.AMRMTokenSecretManagerState:setCurrentMasterKey(org.apache.hadoop.yarn.server.api.records.MasterKey)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.resourcemanager.recovery.records.AMRMTokenSecretManagerState:setCurrentMasterKey(org.apache.hadoop.yarn.server.api.records.MasterKey)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.resourcemanager.recovery.records.AMRMTokenSecretManagerState:getNextMasterKey()	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.resourcemanager.recovery.records.AMRMTokenSecretManagerState:getNextMasterKey()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.resourcemanager.recovery.records.AMRMTokenSecretManagerState:setNextMasterKey(org.apache.hadoop.yarn.server.api.records.MasterKey)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.resourcemanager.recovery.records.AMRMTokenSecretManagerState:setNextMasterKey(org.apache.hadoop.yarn.server.api.records.MasterKey)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore:constructZkRootNodeACL(org.apache.hadoop.conf.Configuration,java.util.List)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore:constructZkRootNodeACL(org.apache.hadoop.conf.Configuration,java.util.List)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore:constructZkRootNodeACL(org.apache.hadoop.conf.Configuration,java.util.List)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore:getNodePath(java.lang.String,java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore:getData(java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore:getACL(java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore:getChildren(java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore:exists(java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore:create(java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore:delete(java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.recovery.LeveldbRMStateStore:isClosed()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.recovery.LeveldbRMStateStore:getDatabase()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.recovery.LeveldbRMStateStore:loadRMAppState(org.apache.hadoop.yarn.api.records.ApplicationId)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.recovery.LeveldbRMStateStore:loadRMAppAttemptState(org.apache.hadoop.yarn.api.records.ApplicationAttemptId)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.recovery.LeveldbRMStateStore:getNumEntriesInDatabase()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.recovery.LeveldbRMStateStore:setDbManager(org.apache.hadoop.yarn.server.resourcemanager.DBManager)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.RMAppManager:logApplicationSummary(org.apache.hadoop.yarn.api.records.ApplicationId)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.RMAppManager:submitApplication(org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext,long,java.lang.String)	java.lang.Deprecated
org.apache.hadoop.yarn.server.resourcemanager.RMAppManager:submitApplication(org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext,long,java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.RMAppManager:submitApplication(org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext,long,org.apache.hadoop.security.UserGroupInformation)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.RMAppManager:placeApplication(org.apache.hadoop.yarn.server.resourcemanager.placement.PlacementManager,org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext,java.lang.String,boolean)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.RMAppManager:getUserNameForPlacement(java.lang.String,org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext,org.apache.hadoop.yarn.server.resourcemanager.placement.PlacementManager)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher:getYarnRPC()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher:setupTokens(org.apache.hadoop.yarn.api.records.ContainerLaunchContext,org.apache.hadoop.yarn.api.records.ContainerId)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher:setupTokens(org.apache.hadoop.yarn.api.records.ContainerLaunchContext,org.apache.hadoop.yarn.api.records.ContainerId)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher:createAndSetAMRMToken()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.preprocessor.SubmissionContextPreProcessor:refresh()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl:setSystemClock(org.apache.hadoop.yarn.util.Clock)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl:setSystemClock(org.apache.hadoop.yarn.util.Clock)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl:getNextAttemptId()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl:getNextAttemptId()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl:getLogAggregationStartTime()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMApp:getCollectorData()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMApp:getCollectorData()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMApp:getCollectorInfo()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMApp:getCollectorInfo()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl:setAMRMToken(org.apache.hadoop.security.token.Token)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl:getAMRMTokenKeyId()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl:appendDiagnostics(java.lang.CharSequence)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl:getJustFinishedContainers()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl:setMasterContainer(org.apache.hadoop.yarn.api.records.Container)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl:setMasterContainer(org.apache.hadoop.yarn.api.records.Container)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttempt:getClientTokenMasterKey()	org.apache.hadoop.classification.InterfaceAudience$LimitedPrivate	value	{RMStateStore}
org.apache.hadoop.yarn.server.resourcemanager.OpportunisticContainerAllocatorAMService:getLeastLoadedNodes()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl:getToBeUpdatedContainers()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl:setNextHeartBeat(boolean)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl:getQueueSize()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl:getUpdatedExistContainers()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl:getLaunchedContainers()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl:getCompletedContainers()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl:getContainersToBeRemovedFromNM()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.monitor.SchedulingMonitor:getSchedulingEditPolicy()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.monitor.SchedulingMonitor:invokePolicy()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.monitor.capacity.CapacitySchedulerPreemptionContext:getIntraQueuePreemptionOrderPolicy()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.resourcemanager.monitor.capacity.PreemptionCandidatesSelector:sortContainers(java.util.List)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.monitor.capacity.ProportionalCapacityPreemptionPolicy:<init>(org.apache.hadoop.yarn.server.resourcemanager.RMContext,org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler,org.apache.hadoop.yarn.util.Clock)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.monitor.capacity.ProportionalCapacityPreemptionPolicy:getToPreemptContainers()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.monitor.capacity.ProportionalCapacityPreemptionPolicy:getQueuePartitions()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.monitor.capacity.ProportionalCapacityPreemptionPolicy:getToPreemptCandidatesPerSelector()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.webapp.CapacitySchedulerPage$QueueBlock:<init>(org.apache.hadoop.yarn.server.resourcemanager.webapp.CapacitySchedulerPage$CSQInfo)	com.google.inject.Inject
org.apache.hadoop.yarn.server.resourcemanager.webapp.MetricsOverviewTable:<init>(org.apache.hadoop.yarn.server.resourcemanager.ResourceManager,org.apache.hadoop.yarn.webapp.View$ViewContext)	com.google.inject.Inject
org.apache.hadoop.yarn.server.resourcemanager.webapp.CapacitySchedulerPage$QueuesBlock:<init>(org.apache.hadoop.yarn.server.resourcemanager.ResourceManager,org.apache.hadoop.yarn.server.resourcemanager.webapp.CapacitySchedulerPage$CSQInfo)	com.google.inject.Inject
org.apache.hadoop.yarn.server.resourcemanager.webapp.ErrorBlock:<init>(org.apache.hadoop.yarn.webapp.View$ViewContext)	com.google.inject.Inject
org.apache.hadoop.yarn.server.resourcemanager.webapp.FairSchedulerPage$ParentQueueBlock:<init>(org.apache.hadoop.yarn.webapp.View$ViewContext,org.apache.hadoop.yarn.server.resourcemanager.webapp.FairSchedulerPage$FSQInfo)	com.google.inject.Inject
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMContainerBlock:<init>(org.apache.hadoop.yarn.server.resourcemanager.ResourceManager,org.apache.hadoop.yarn.webapp.View$ViewContext)	com.google.inject.Inject
org.apache.hadoop.yarn.server.resourcemanager.webapp.FairSchedulerPage$QueueBlock:<init>(org.apache.hadoop.yarn.server.resourcemanager.webapp.FairSchedulerPage$FSQInfo)	com.google.inject.Inject
org.apache.hadoop.yarn.server.resourcemanager.webapp.DefaultSchedulerPage$QueueInfoBlock:<init>(org.apache.hadoop.yarn.webapp.View$ViewContext,org.apache.hadoop.yarn.server.resourcemanager.ResourceManager)	com.google.inject.Inject
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebAppFilter:<init>(com.google.inject.Injector,org.apache.hadoop.conf.Configuration)	javax.inject.Inject
org.apache.hadoop.yarn.server.resourcemanager.webapp.RmController:<init>(org.apache.hadoop.yarn.webapp.Controller$RequestContext)	com.google.inject.Inject
org.apache.hadoop.yarn.server.resourcemanager.webapp.AboutBlock:<init>(org.apache.hadoop.yarn.server.resourcemanager.ResourceManager,org.apache.hadoop.yarn.webapp.View$ViewContext)	com.google.inject.Inject
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMAppsBlock:<init>(org.apache.hadoop.yarn.server.resourcemanager.ResourceManager,org.apache.hadoop.yarn.webapp.View$ViewContext)	com.google.inject.Inject
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:<init>(org.apache.hadoop.yarn.server.resourcemanager.ResourceManager,org.apache.hadoop.conf.Configuration)	com.google.inject.Inject
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:get()	javax.ws.rs.GET
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:get()	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:getClusterInfo()	javax.ws.rs.GET
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:getClusterInfo()	javax.ws.rs.Path	value	/info
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:getClusterInfo()	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:getClusterUserInfo(javax.servlet.http.HttpServletRequest)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:getClusterUserInfo(javax.servlet.http.HttpServletRequest)	javax.ws.rs.Path	value	/userinfo
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:getClusterUserInfo(javax.servlet.http.HttpServletRequest)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:getClusterMetricsInfo()	javax.ws.rs.GET
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:getClusterMetricsInfo()	javax.ws.rs.Path	value	/metrics
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:getClusterMetricsInfo()	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:getSchedulerInfo()	javax.ws.rs.GET
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:getSchedulerInfo()	javax.ws.rs.Path	value	/scheduler
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:getSchedulerInfo()	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:dumpSchedulerLogs(java.lang.String,javax.servlet.http.HttpServletRequest)	javax.ws.rs.POST
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:dumpSchedulerLogs(java.lang.String,javax.servlet.http.HttpServletRequest)	javax.ws.rs.Path	value	/scheduler/logs
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:dumpSchedulerLogs(java.lang.String,javax.servlet.http.HttpServletRequest)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:getNodes(java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:getNodes(java.lang.String)	javax.ws.rs.Path	value	/nodes
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:getNodes(java.lang.String)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:getNode(java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:getNode(java.lang.String)	javax.ws.rs.Path	value	/nodes/{nodeId}
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:getNode(java.lang.String)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:updateNodeResource(javax.servlet.http.HttpServletRequest,java.lang.String,org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ResourceOptionInfo)	javax.ws.rs.POST
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:updateNodeResource(javax.servlet.http.HttpServletRequest,java.lang.String,org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ResourceOptionInfo)	javax.ws.rs.Path	value	/nodes/{nodeId}/resource
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:updateNodeResource(javax.servlet.http.HttpServletRequest,java.lang.String,org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ResourceOptionInfo)	javax.ws.rs.Consumes	value	{application/json,application/xml}
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:updateNodeResource(javax.servlet.http.HttpServletRequest,java.lang.String,org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ResourceOptionInfo)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:getApps(javax.servlet.http.HttpServletRequest,java.lang.String,java.util.Set,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.util.Set,java.util.Set,java.lang.String,java.util.Set)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:getApps(javax.servlet.http.HttpServletRequest,java.lang.String,java.util.Set,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.util.Set,java.util.Set,java.lang.String,java.util.Set)	javax.ws.rs.Path	value	/apps
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:getApps(javax.servlet.http.HttpServletRequest,java.lang.String,java.util.Set,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.util.Set,java.util.Set,java.lang.String,java.util.Set)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:getActivities(javax.servlet.http.HttpServletRequest,java.lang.String,java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:getActivities(javax.servlet.http.HttpServletRequest,java.lang.String,java.lang.String)	javax.ws.rs.Path	value	/scheduler/activities
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:getActivities(javax.servlet.http.HttpServletRequest,java.lang.String,java.lang.String)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:getAppActivities(javax.servlet.http.HttpServletRequest,java.lang.String,java.lang.String,java.util.Set,java.util.Set,java.lang.String,java.lang.String,java.util.Set,boolean)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:getAppActivities(javax.servlet.http.HttpServletRequest,java.lang.String,java.lang.String,java.util.Set,java.util.Set,java.lang.String,java.lang.String,java.util.Set,boolean)	javax.ws.rs.Path	value	/scheduler/app-activities/{appid}
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:getAppActivities(javax.servlet.http.HttpServletRequest,java.lang.String,java.lang.String,java.util.Set,java.util.Set,java.lang.String,java.lang.String,java.util.Set,boolean)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:getAppStatistics(javax.servlet.http.HttpServletRequest,java.util.Set,java.util.Set)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:getAppStatistics(javax.servlet.http.HttpServletRequest,java.util.Set,java.util.Set)	javax.ws.rs.Path	value	/appstatistics
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:getAppStatistics(javax.servlet.http.HttpServletRequest,java.util.Set,java.util.Set)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:getApp(javax.servlet.http.HttpServletRequest,java.lang.String,java.util.Set)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:getApp(javax.servlet.http.HttpServletRequest,java.lang.String,java.util.Set)	javax.ws.rs.Path	value	/apps/{appid}
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:getApp(javax.servlet.http.HttpServletRequest,java.lang.String,java.util.Set)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:getAppAttempts(javax.servlet.http.HttpServletRequest,java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:getAppAttempts(javax.servlet.http.HttpServletRequest,java.lang.String)	javax.ws.rs.Path	value	/apps/{appid}/appattempts
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:getAppAttempts(javax.servlet.http.HttpServletRequest,java.lang.String)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:getAppAttempt(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:getAppAttempt(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String)	javax.ws.rs.Path	value	/apps/{appid}/appattempts/{appattemptid}
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:getAppAttempt(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:getContainers(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:getContainers(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String)	javax.ws.rs.Path	value	/apps/{appid}/appattempts/{appattemptid}/containers
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:getContainers(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:getContainer(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:getContainer(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.Path	value	/apps/{appid}/appattempts/{appattemptid}/containers/{containerid}
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:getContainer(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:getAppState(javax.servlet.http.HttpServletRequest,java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:getAppState(javax.servlet.http.HttpServletRequest,java.lang.String)	javax.ws.rs.Path	value	/apps/{appid}/state
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:getAppState(javax.servlet.http.HttpServletRequest,java.lang.String)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:updateAppState(org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppState,javax.servlet.http.HttpServletRequest,java.lang.String)	javax.ws.rs.PUT
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:updateAppState(org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppState,javax.servlet.http.HttpServletRequest,java.lang.String)	javax.ws.rs.Path	value	/apps/{appid}/state
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:updateAppState(org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppState,javax.servlet.http.HttpServletRequest,java.lang.String)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:updateAppState(org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppState,javax.servlet.http.HttpServletRequest,java.lang.String)	javax.ws.rs.Consumes	value	{application/json,application/xml}
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:getNodeToLabels(javax.servlet.http.HttpServletRequest)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:getNodeToLabels(javax.servlet.http.HttpServletRequest)	javax.ws.rs.Path	value	/get-node-to-labels
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:getNodeToLabels(javax.servlet.http.HttpServletRequest)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:getLabelsToNodes(java.util.Set)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:getLabelsToNodes(java.util.Set)	javax.ws.rs.Path	value	/label-mappings
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:getLabelsToNodes(java.util.Set)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:replaceLabelsOnNodes(org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodeToLabelsEntryList,javax.servlet.http.HttpServletRequest)	javax.ws.rs.POST
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:replaceLabelsOnNodes(org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodeToLabelsEntryList,javax.servlet.http.HttpServletRequest)	javax.ws.rs.Path	value	/replace-node-to-labels
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:replaceLabelsOnNodes(org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodeToLabelsEntryList,javax.servlet.http.HttpServletRequest)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:replaceLabelsOnNode(java.util.Set,javax.servlet.http.HttpServletRequest,java.lang.String)	javax.ws.rs.POST
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:replaceLabelsOnNode(java.util.Set,javax.servlet.http.HttpServletRequest,java.lang.String)	javax.ws.rs.Path	value	/nodes/{nodeId}/replace-labels
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:replaceLabelsOnNode(java.util.Set,javax.servlet.http.HttpServletRequest,java.lang.String)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:getClusterNodeLabels(javax.servlet.http.HttpServletRequest)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:getClusterNodeLabels(javax.servlet.http.HttpServletRequest)	javax.ws.rs.Path	value	/get-node-labels
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:getClusterNodeLabels(javax.servlet.http.HttpServletRequest)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:addToClusterNodeLabels(org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodeLabelsInfo,javax.servlet.http.HttpServletRequest)	javax.ws.rs.POST
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:addToClusterNodeLabels(org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodeLabelsInfo,javax.servlet.http.HttpServletRequest)	javax.ws.rs.Path	value	/add-node-labels
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:addToClusterNodeLabels(org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodeLabelsInfo,javax.servlet.http.HttpServletRequest)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:removeFromCluserNodeLabels(java.util.Set,javax.servlet.http.HttpServletRequest)	javax.ws.rs.POST
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:removeFromCluserNodeLabels(java.util.Set,javax.servlet.http.HttpServletRequest)	javax.ws.rs.Path	value	/remove-node-labels
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:removeFromCluserNodeLabels(java.util.Set,javax.servlet.http.HttpServletRequest)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:getLabelsOnNode(javax.servlet.http.HttpServletRequest,java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:getLabelsOnNode(javax.servlet.http.HttpServletRequest,java.lang.String)	javax.ws.rs.Path	value	/nodes/{nodeId}/get-labels
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:getLabelsOnNode(javax.servlet.http.HttpServletRequest,java.lang.String)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:getAppPriority(javax.servlet.http.HttpServletRequest,java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:getAppPriority(javax.servlet.http.HttpServletRequest,java.lang.String)	javax.ws.rs.Path	value	/apps/{appid}/priority
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:getAppPriority(javax.servlet.http.HttpServletRequest,java.lang.String)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:updateApplicationPriority(org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppPriority,javax.servlet.http.HttpServletRequest,java.lang.String)	javax.ws.rs.PUT
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:updateApplicationPriority(org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppPriority,javax.servlet.http.HttpServletRequest,java.lang.String)	javax.ws.rs.Path	value	/apps/{appid}/priority
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:updateApplicationPriority(org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppPriority,javax.servlet.http.HttpServletRequest,java.lang.String)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:updateApplicationPriority(org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppPriority,javax.servlet.http.HttpServletRequest,java.lang.String)	javax.ws.rs.Consumes	value	{application/json,application/xml}
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:getAppQueue(javax.servlet.http.HttpServletRequest,java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:getAppQueue(javax.servlet.http.HttpServletRequest,java.lang.String)	javax.ws.rs.Path	value	/apps/{appid}/queue
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:getAppQueue(javax.servlet.http.HttpServletRequest,java.lang.String)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:updateAppQueue(org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppQueue,javax.servlet.http.HttpServletRequest,java.lang.String)	javax.ws.rs.PUT
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:updateAppQueue(org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppQueue,javax.servlet.http.HttpServletRequest,java.lang.String)	javax.ws.rs.Path	value	/apps/{appid}/queue
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:updateAppQueue(org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppQueue,javax.servlet.http.HttpServletRequest,java.lang.String)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:updateAppQueue(org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppQueue,javax.servlet.http.HttpServletRequest,java.lang.String)	javax.ws.rs.Consumes	value	{application/json,application/xml}
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:createNewApplication(javax.servlet.http.HttpServletRequest)	javax.ws.rs.POST
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:createNewApplication(javax.servlet.http.HttpServletRequest)	javax.ws.rs.Path	value	/apps/new-application
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:createNewApplication(javax.servlet.http.HttpServletRequest)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:submitApplication(org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ApplicationSubmissionContextInfo,javax.servlet.http.HttpServletRequest)	javax.ws.rs.POST
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:submitApplication(org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ApplicationSubmissionContextInfo,javax.servlet.http.HttpServletRequest)	javax.ws.rs.Path	value	/apps
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:submitApplication(org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ApplicationSubmissionContextInfo,javax.servlet.http.HttpServletRequest)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:submitApplication(org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ApplicationSubmissionContextInfo,javax.servlet.http.HttpServletRequest)	javax.ws.rs.Consumes	value	{application/json,application/xml}
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:postDelegationToken(org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.DelegationToken,javax.servlet.http.HttpServletRequest)	javax.ws.rs.POST
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:postDelegationToken(org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.DelegationToken,javax.servlet.http.HttpServletRequest)	javax.ws.rs.Path	value	/delegation-token
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:postDelegationToken(org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.DelegationToken,javax.servlet.http.HttpServletRequest)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:postDelegationToken(org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.DelegationToken,javax.servlet.http.HttpServletRequest)	javax.ws.rs.Consumes	value	{application/json,application/xml}
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:postDelegationTokenExpiration(javax.servlet.http.HttpServletRequest)	javax.ws.rs.POST
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:postDelegationTokenExpiration(javax.servlet.http.HttpServletRequest)	javax.ws.rs.Path	value	/delegation-token/expiration
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:postDelegationTokenExpiration(javax.servlet.http.HttpServletRequest)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:postDelegationTokenExpiration(javax.servlet.http.HttpServletRequest)	javax.ws.rs.Consumes	value	{application/json,application/xml}
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:cancelDelegationToken(javax.servlet.http.HttpServletRequest)	javax.ws.rs.DELETE
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:cancelDelegationToken(javax.servlet.http.HttpServletRequest)	javax.ws.rs.Path	value	/delegation-token
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:cancelDelegationToken(javax.servlet.http.HttpServletRequest)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:createNewReservation(javax.servlet.http.HttpServletRequest)	javax.ws.rs.POST
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:createNewReservation(javax.servlet.http.HttpServletRequest)	javax.ws.rs.Path	value	/reservation/new-reservation
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:createNewReservation(javax.servlet.http.HttpServletRequest)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:submitReservation(org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationSubmissionRequestInfo,javax.servlet.http.HttpServletRequest)	javax.ws.rs.POST
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:submitReservation(org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationSubmissionRequestInfo,javax.servlet.http.HttpServletRequest)	javax.ws.rs.Path	value	/reservation/submit
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:submitReservation(org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationSubmissionRequestInfo,javax.servlet.http.HttpServletRequest)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:submitReservation(org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationSubmissionRequestInfo,javax.servlet.http.HttpServletRequest)	javax.ws.rs.Consumes	value	{application/json,application/xml}
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:updateReservation(org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationUpdateRequestInfo,javax.servlet.http.HttpServletRequest)	javax.ws.rs.POST
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:updateReservation(org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationUpdateRequestInfo,javax.servlet.http.HttpServletRequest)	javax.ws.rs.Path	value	/reservation/update
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:updateReservation(org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationUpdateRequestInfo,javax.servlet.http.HttpServletRequest)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:updateReservation(org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationUpdateRequestInfo,javax.servlet.http.HttpServletRequest)	javax.ws.rs.Consumes	value	{application/json,application/xml}
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:deleteReservation(org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationDeleteRequestInfo,javax.servlet.http.HttpServletRequest)	javax.ws.rs.POST
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:deleteReservation(org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationDeleteRequestInfo,javax.servlet.http.HttpServletRequest)	javax.ws.rs.Path	value	/reservation/delete
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:deleteReservation(org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationDeleteRequestInfo,javax.servlet.http.HttpServletRequest)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:deleteReservation(org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationDeleteRequestInfo,javax.servlet.http.HttpServletRequest)	javax.ws.rs.Consumes	value	{application/json,application/xml}
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:listReservation(java.lang.String,java.lang.String,long,long,boolean,javax.servlet.http.HttpServletRequest)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:listReservation(java.lang.String,java.lang.String,long,long,boolean,javax.servlet.http.HttpServletRequest)	javax.ws.rs.Path	value	/reservation/list
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:listReservation(java.lang.String,java.lang.String,long,long,boolean,javax.servlet.http.HttpServletRequest)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:getAppTimeout(javax.servlet.http.HttpServletRequest,java.lang.String,java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:getAppTimeout(javax.servlet.http.HttpServletRequest,java.lang.String,java.lang.String)	javax.ws.rs.Path	value	/apps/{appid}/timeouts/{type}
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:getAppTimeout(javax.servlet.http.HttpServletRequest,java.lang.String,java.lang.String)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:getAppTimeouts(javax.servlet.http.HttpServletRequest,java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:getAppTimeouts(javax.servlet.http.HttpServletRequest,java.lang.String)	javax.ws.rs.Path	value	/apps/{appid}/timeouts
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:getAppTimeouts(javax.servlet.http.HttpServletRequest,java.lang.String)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:updateApplicationTimeout(org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppTimeoutInfo,javax.servlet.http.HttpServletRequest,java.lang.String)	javax.ws.rs.PUT
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:updateApplicationTimeout(org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppTimeoutInfo,javax.servlet.http.HttpServletRequest,java.lang.String)	javax.ws.rs.Path	value	/apps/{appid}/timeout
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:updateApplicationTimeout(org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppTimeoutInfo,javax.servlet.http.HttpServletRequest,java.lang.String)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:updateApplicationTimeout(org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppTimeoutInfo,javax.servlet.http.HttpServletRequest,java.lang.String)	javax.ws.rs.Consumes	value	{application/json,application/xml}
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:formatSchedulerConfiguration(javax.servlet.http.HttpServletRequest)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:formatSchedulerConfiguration(javax.servlet.http.HttpServletRequest)	javax.ws.rs.Path	value	/scheduler-conf/format
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:formatSchedulerConfiguration(javax.servlet.http.HttpServletRequest)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:validateAndGetSchedulerConfiguration(org.apache.hadoop.yarn.webapp.dao.SchedConfUpdateInfo,javax.servlet.http.HttpServletRequest)	javax.ws.rs.POST
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:validateAndGetSchedulerConfiguration(org.apache.hadoop.yarn.webapp.dao.SchedConfUpdateInfo,javax.servlet.http.HttpServletRequest)	javax.ws.rs.Path	value	/scheduler-conf/validate
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:validateAndGetSchedulerConfiguration(org.apache.hadoop.yarn.webapp.dao.SchedConfUpdateInfo,javax.servlet.http.HttpServletRequest)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:validateAndGetSchedulerConfiguration(org.apache.hadoop.yarn.webapp.dao.SchedConfUpdateInfo,javax.servlet.http.HttpServletRequest)	javax.ws.rs.Consumes	value	{application/json,application/xml}
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:updateSchedulerConfiguration(org.apache.hadoop.yarn.webapp.dao.SchedConfUpdateInfo,javax.servlet.http.HttpServletRequest)	javax.ws.rs.PUT
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:updateSchedulerConfiguration(org.apache.hadoop.yarn.webapp.dao.SchedConfUpdateInfo,javax.servlet.http.HttpServletRequest)	javax.ws.rs.Path	value	/scheduler-conf
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:updateSchedulerConfiguration(org.apache.hadoop.yarn.webapp.dao.SchedConfUpdateInfo,javax.servlet.http.HttpServletRequest)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:updateSchedulerConfiguration(org.apache.hadoop.yarn.webapp.dao.SchedConfUpdateInfo,javax.servlet.http.HttpServletRequest)	javax.ws.rs.Consumes	value	{application/json,application/xml}
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:getSchedulerConfiguration(javax.servlet.http.HttpServletRequest)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:getSchedulerConfiguration(javax.servlet.http.HttpServletRequest)	javax.ws.rs.Path	value	/scheduler-conf
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:getSchedulerConfiguration(javax.servlet.http.HttpServletRequest)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:getSchedulerConfigurationVersion(javax.servlet.http.HttpServletRequest)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:getSchedulerConfigurationVersion(javax.servlet.http.HttpServletRequest)	javax.ws.rs.Path	value	/scheduler-conf/version
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:getSchedulerConfigurationVersion(javax.servlet.http.HttpServletRequest)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:checkUserAccessToQueue(java.lang.String,java.lang.String,java.lang.String,javax.servlet.http.HttpServletRequest)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:checkUserAccessToQueue(java.lang.String,java.lang.String,java.lang.String,javax.servlet.http.HttpServletRequest)	javax.ws.rs.Path	value	/queues/{queue}/access
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:checkUserAccessToQueue(java.lang.String,java.lang.String,java.lang.String,javax.servlet.http.HttpServletRequest)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:signalToContainer(java.lang.String,java.lang.String,javax.servlet.http.HttpServletRequest)	javax.ws.rs.POST
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:signalToContainer(java.lang.String,java.lang.String,javax.servlet.http.HttpServletRequest)	javax.ws.rs.Path	value	/containers/{containerid}/signal/{command}
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices:signalToContainer(java.lang.String,java.lang.String,javax.servlet.http.HttpServletRequest)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.resourcemanager.webapp.NodesPage$NodesBlock:<init>(org.apache.hadoop.yarn.server.resourcemanager.ResourceManager,org.apache.hadoop.yarn.webapp.View$ViewContext)	com.google.inject.Inject
org.apache.hadoop.yarn.server.resourcemanager.webapp.JAXBContextResolver:<init>(org.apache.hadoop.conf.Configuration)	com.google.inject.Inject
org.apache.hadoop.yarn.server.resourcemanager.webapp.FairSchedulerAppsBlock:<init>(org.apache.hadoop.yarn.server.resourcemanager.ResourceManager,org.apache.hadoop.yarn.webapp.View$ViewContext,org.apache.hadoop.conf.Configuration)	com.google.inject.Inject
org.apache.hadoop.yarn.server.resourcemanager.webapp.DefaultSchedulerPage$QueuesBlock:<init>(org.apache.hadoop.yarn.server.resourcemanager.ResourceManager)	com.google.inject.Inject
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMAppAttemptBlock:<init>(org.apache.hadoop.yarn.webapp.View$ViewContext,org.apache.hadoop.yarn.server.resourcemanager.ResourceManager,org.apache.hadoop.conf.Configuration)	com.google.inject.Inject
org.apache.hadoop.yarn.server.resourcemanager.webapp.FairSchedulerPage$LeafQueueBlock:<init>(org.apache.hadoop.yarn.webapp.View$ViewContext,org.apache.hadoop.yarn.server.resourcemanager.webapp.FairSchedulerPage$FSQInfo)	com.google.inject.Inject
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppInfo:setAMHostHttpAddress(java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppActivitiesInfo:getAllocations()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodeInfo:setId(java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodeInfo:setLastHealthUpdate(long)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.webapp.CapacitySchedulerPage$HealthBlock:<init>(org.apache.hadoop.yarn.server.resourcemanager.ResourceManager)	com.google.inject.Inject
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMAppBlock:<init>(org.apache.hadoop.yarn.webapp.View$ViewContext,org.apache.hadoop.conf.Configuration,org.apache.hadoop.yarn.server.resourcemanager.ResourceManager)	com.google.inject.Inject
org.apache.hadoop.yarn.server.resourcemanager.webapp.NodeLabelsPage$NodeLabelsBlock:<init>(org.apache.hadoop.yarn.server.resourcemanager.ResourceManager,org.apache.hadoop.yarn.webapp.View$ViewContext)	com.google.inject.Inject
org.apache.hadoop.yarn.server.resourcemanager.webapp.CapacitySchedulerPage$LeafQueueInfoBlock:<init>(org.apache.hadoop.yarn.webapp.View$ViewContext,org.apache.hadoop.yarn.server.resourcemanager.webapp.CapacitySchedulerPage$CSQInfo)	com.google.inject.Inject
org.apache.hadoop.yarn.server.resourcemanager.webapp.FairSchedulerPage$QueuesBlock:<init>(org.apache.hadoop.yarn.server.resourcemanager.ResourceManager,org.apache.hadoop.yarn.server.resourcemanager.webapp.FairSchedulerPage$FSQInfo)	com.google.inject.Inject
org.apache.hadoop.yarn.server.resourcemanager.webapp.CapacitySchedulerPage$QueueUsersInfoBlock:<init>(org.apache.hadoop.yarn.webapp.View$ViewContext,org.apache.hadoop.yarn.server.resourcemanager.webapp.CapacitySchedulerPage$CSQInfo)	com.google.inject.Inject
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMAppLogAggregationStatusBlock:<init>(org.apache.hadoop.yarn.webapp.View$ViewContext,org.apache.hadoop.yarn.server.resourcemanager.ResourceManager,org.apache.hadoop.conf.Configuration)	com.google.inject.Inject
org.apache.hadoop.yarn.server.resourcemanager.ClusterMetrics:destroy()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.ClientRMService:getContextPreProcessor()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.ClientRMService:getBindAddress()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.ClientRMService:getServer()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.ClientRMService:setDisplayPerUserApps(boolean)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService:getBindAddress()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService:setAttemptLastResponseId(org.apache.hadoop.yarn.api.records.ApplicationAttemptId,int)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService:getServer()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM:rollMasterKey()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM:getNextKey()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM:activateNextMasterKey()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM:isApplicationAttemptRegistered(org.apache.hadoop.yarn.api.records.ApplicationAttemptId)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM:isApplicationAttemptRegistered(org.apache.hadoop.yarn.api.records.ApplicationAttemptId)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM:isApplicationAttemptNMTokenPresent(org.apache.hadoop.yarn.api.records.ApplicationAttemptId,org.apache.hadoop.yarn.api.records.NodeId)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM:isApplicationAttemptNMTokenPresent(org.apache.hadoop.yarn.api.records.ApplicationAttemptId,org.apache.hadoop.yarn.api.records.NodeId)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.security.DelegationTokenRenewer:getDelegationTokens()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.security.DelegationTokenRenewer:setTimerForTokenRenewal(org.apache.hadoop.yarn.server.resourcemanager.security.DelegationTokenRenewer$DelegationTokenToRenew)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.security.DelegationTokenRenewer:renewToken(org.apache.hadoop.yarn.server.resourcemanager.security.DelegationTokenRenewer$DelegationTokenToRenew)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.security.DelegationTokenRenewer:obtainSystemTokensForUser(java.lang.String,org.apache.hadoop.security.Credentials)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.security.DelegationTokenRenewer:setDelegationTokenRenewerPoolTracker(boolean)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.security.ClientToAMTokenSecretManagerInRM:hasMasterKey(org.apache.hadoop.yarn.api.records.ApplicationAttemptId)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.security.QueueACLsManager:<init>()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager:getAllMasterKeys()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager:getAllMasterKeys()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager:getAllTokens()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager:getAllTokens()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager:getLatestDTSequenceNumber()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager:getLatestDTSequenceNumber()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager:rollMasterKey()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager:getNextKey()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager:activateNextMasterKey()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager:createContainerToken(org.apache.hadoop.yarn.api.records.ContainerId,int,org.apache.hadoop.yarn.api.records.NodeId,java.lang.String,org.apache.hadoop.yarn.api.records.Resource,org.apache.hadoop.yarn.api.records.Priority,long)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.security.DelegationTokenRenewer$DelegationTokenToRenew:cancelTimer()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.security.DelegationTokenRenewer$DelegationTokenToRenew:isTimerCancelled()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager:rollMasterKey()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager:createNewMasterKey()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager:createNewMasterKey()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager:getMasterKey()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager:getCurrnetMasterKeyData()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager:getCurrnetMasterKeyData()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager:getNextMasterKeyData()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager:getNextMasterKeyData()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager:createPassword(org.apache.hadoop.yarn.security.AMRMTokenIdentifier)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager:createPassword(org.apache.hadoop.security.token.TokenIdentifier)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.security.authorize.RMPolicyProvider:getInstance()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.security.authorize.RMPolicyProvider:getInstance()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.resourcemanager.ResourceManager:setClusterTimeStamp(long)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.ResourceManager:getRmDispatcher()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.ResourceManager:createResourceProfileManager()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.ResourceManager:setRMStateStore(org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.ResourceManager:areActiveServicesRunning()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.ResourceManager:getClientRMService()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.ResourceManager:getResourceScheduler()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.ResourceManager:getResourceTrackerService()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.ResourceManager:getApplicationMasterService()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.ResourceManager:getApplicationACLsManager()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.ResourceManager:getQueueACLsManager()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.ResourceManager:getFederationStateStoreService()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.ResourceManager:getFederationStateStoreService()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.ResourceManager:getWebapp()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.ResourceManager:deleteRMStateStore(org.apache.hadoop.conf.Configuration)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.ResourceManager:deleteRMConfStore(org.apache.hadoop.conf.Configuration)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.ResourceManager:removeApplication(org.apache.hadoop.conf.Configuration,java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:<init>(org.apache.hadoop.yarn.event.Dispatcher,org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.ContainerAllocationExpirer,org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.AMLivelinessMonitor,org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.AMLivelinessMonitor,org.apache.hadoop.yarn.server.resourcemanager.security.DelegationTokenRenewer,org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager,org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager,org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM,org.apache.hadoop.yarn.server.resourcemanager.security.ClientToAMTokenSecretManagerInRM,org.apache.hadoop.yarn.server.resourcemanager.scheduler.ResourceScheduler)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:<init>(org.apache.hadoop.yarn.event.Dispatcher,org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.ContainerAllocationExpirer,org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.AMLivelinessMonitor,org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.AMLivelinessMonitor,org.apache.hadoop.yarn.server.resourcemanager.security.DelegationTokenRenewer,org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager,org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager,org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM,org.apache.hadoop.yarn.server.resourcemanager.security.ClientToAMTokenSecretManagerInRM,org.apache.hadoop.yarn.server.resourcemanager.scheduler.ResourceScheduler)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:setStateStore(org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:setStateStore(org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:getClientRMService()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:getClientRMService()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:getApplicationMasterService()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:getApplicationMasterService()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:getResourceTrackerService()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:getResourceTrackerService()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:getStateStore()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:getStateStore()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:getRMApps()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:getRMApps()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:getRMNodes()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:getRMNodes()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:getInactiveRMNodes()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:getInactiveRMNodes()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:getContainerAllocationExpirer()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:getContainerAllocationExpirer()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:getAMLivelinessMonitor()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:getAMLivelinessMonitor()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:getAMFinishingMonitor()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:getAMFinishingMonitor()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:getDelegationTokenRenewer()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:getDelegationTokenRenewer()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:getAMRMTokenSecretManager()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:getAMRMTokenSecretManager()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:getContainerTokenSecretManager()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:getContainerTokenSecretManager()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:getNMTokenSecretManager()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:getNMTokenSecretManager()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:getScheduler()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:getScheduler()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:getReservationSystem()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:getReservationSystem()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:getNodesListManager()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:getNodesListManager()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:getClientToAMTokenSecretManager()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:getClientToAMTokenSecretManager()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:setClientRMService(org.apache.hadoop.yarn.server.resourcemanager.ClientRMService)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:setClientRMService(org.apache.hadoop.yarn.server.resourcemanager.ClientRMService)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:getRMDelegationTokenSecretManager()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:getRMDelegationTokenSecretManager()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:setRMDelegationTokenSecretManager(org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:setRMDelegationTokenSecretManager(org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:setContainerAllocationExpirer(org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.ContainerAllocationExpirer)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:setContainerAllocationExpirer(org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.ContainerAllocationExpirer)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:setAMLivelinessMonitor(org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.AMLivelinessMonitor)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:setAMLivelinessMonitor(org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.AMLivelinessMonitor)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:setAMFinishingMonitor(org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.AMLivelinessMonitor)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:setAMFinishingMonitor(org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.AMLivelinessMonitor)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:setContainerTokenSecretManager(org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:setContainerTokenSecretManager(org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:setNMTokenSecretManager(org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:setNMTokenSecretManager(org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:setScheduler(org.apache.hadoop.yarn.server.resourcemanager.scheduler.ResourceScheduler)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:setScheduler(org.apache.hadoop.yarn.server.resourcemanager.scheduler.ResourceScheduler)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:setReservationSystem(org.apache.hadoop.yarn.server.resourcemanager.reservation.ReservationSystem)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:setReservationSystem(org.apache.hadoop.yarn.server.resourcemanager.reservation.ReservationSystem)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:setDelegationTokenRenewer(org.apache.hadoop.yarn.server.resourcemanager.security.DelegationTokenRenewer)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:setDelegationTokenRenewer(org.apache.hadoop.yarn.server.resourcemanager.security.DelegationTokenRenewer)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:setClientToAMTokenSecretManager(org.apache.hadoop.yarn.server.resourcemanager.security.ClientToAMTokenSecretManagerInRM)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:setClientToAMTokenSecretManager(org.apache.hadoop.yarn.server.resourcemanager.security.ClientToAMTokenSecretManagerInRM)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:setAMRMTokenSecretManager(org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:setAMRMTokenSecretManager(org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:setNodesListManager(org.apache.hadoop.yarn.server.resourcemanager.NodesListManager)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:setNodesListManager(org.apache.hadoop.yarn.server.resourcemanager.NodesListManager)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:setApplicationMasterService(org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:setApplicationMasterService(org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:setResourceTrackerService(org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:setResourceTrackerService(org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:setWorkPreservingRecoveryEnabled(boolean)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:setWorkPreservingRecoveryEnabled(boolean)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:isWorkPreservingRecoveryEnabled()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:isWorkPreservingRecoveryEnabled()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:getEpoch()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:getEpoch()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:setEpoch(long)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:setEpoch(long)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:getNodeLabelManager()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:getNodeLabelManager()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:setNodeLabelManager(org.apache.hadoop.yarn.server.resourcemanager.nodelabels.RMNodeLabelsManager)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:setNodeLabelManager(org.apache.hadoop.yarn.server.resourcemanager.nodelabels.RMNodeLabelsManager)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:getNodeAttributesManager()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:getNodeAttributesManager()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:setNodeAttributesManager(org.apache.hadoop.yarn.nodelabels.NodeAttributesManager)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:setNodeAttributesManager(org.apache.hadoop.yarn.nodelabels.NodeAttributesManager)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:getAllocationTagsManager()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:getAllocationTagsManager()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:setAllocationTagsManager(org.apache.hadoop.yarn.server.resourcemanager.scheduler.constraint.AllocationTagsManager)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:setAllocationTagsManager(org.apache.hadoop.yarn.server.resourcemanager.scheduler.constraint.AllocationTagsManager)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:getPlacementConstraintManager()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:getPlacementConstraintManager()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:setPlacementConstraintManager(org.apache.hadoop.yarn.server.resourcemanager.scheduler.constraint.PlacementConstraintManager)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:setPlacementConstraintManager(org.apache.hadoop.yarn.server.resourcemanager.scheduler.constraint.PlacementConstraintManager)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:getRMDelegatedNodeLabelsUpdater()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:getRMDelegatedNodeLabelsUpdater()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:setRMDelegatedNodeLabelsUpdater(org.apache.hadoop.yarn.server.resourcemanager.nodelabels.RMDelegatedNodeLabelsUpdater)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:setRMDelegatedNodeLabelsUpdater(org.apache.hadoop.yarn.server.resourcemanager.nodelabels.RMDelegatedNodeLabelsUpdater)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:getMultiNodeSortingManager()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:getMultiNodeSortingManager()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:setMultiNodeSortingManager(org.apache.hadoop.yarn.server.resourcemanager.scheduler.placement.MultiNodeSortingManager)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:setMultiNodeSortingManager(org.apache.hadoop.yarn.server.resourcemanager.scheduler.placement.MultiNodeSortingManager)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:setSchedulerRecoveryStartAndWaitTime(long)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:setSchedulerRecoveryStartAndWaitTime(long)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:isSchedulerReadyForAllocatingContainers()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:isSchedulerReadyForAllocatingContainers()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:setSystemClock(org.apache.hadoop.yarn.util.Clock)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:setSystemClock(org.apache.hadoop.yarn.util.Clock)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:getSystemCredentialsForApps()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:getSystemCredentialsForApps()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:getQueuePlacementManager()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:getQueuePlacementManager()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:setQueuePlacementManager(org.apache.hadoop.yarn.server.resourcemanager.placement.PlacementManager)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:setQueuePlacementManager(org.apache.hadoop.yarn.server.resourcemanager.placement.PlacementManager)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:setRMAppLifetimeMonitor(org.apache.hadoop.yarn.server.resourcemanager.rmapp.monitor.RMAppLifetimeMonitor)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:setRMAppLifetimeMonitor(org.apache.hadoop.yarn.server.resourcemanager.rmapp.monitor.RMAppLifetimeMonitor)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:getRMAppLifetimeMonitor()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:getRMAppLifetimeMonitor()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:getNodeManagerQueueLimitCalculator()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:getNodeManagerQueueLimitCalculator()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:setContainerQueueLimitCalculator(org.apache.hadoop.yarn.server.resourcemanager.scheduler.distributed.QueueLimitCalculator)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:setContainerQueueLimitCalculator(org.apache.hadoop.yarn.server.resourcemanager.scheduler.distributed.QueueLimitCalculator)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:getProxyCAManager()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:getProxyCAManager()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:setProxyCAManager(org.apache.hadoop.yarn.server.resourcemanager.security.ProxyCAManager)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:setProxyCAManager(org.apache.hadoop.yarn.server.resourcemanager.security.ProxyCAManager)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:getVolumeManager()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:getVolumeManager()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:setVolumeManager(org.apache.hadoop.yarn.server.resourcemanager.volume.csi.VolumeManager)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:setVolumeManager(org.apache.hadoop.yarn.server.resourcemanager.volume.csi.VolumeManager)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.resourcemanager.reservation.ReservationAllocation:setPeriodicity(long)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.reservation.planning.SimpleCapacityReplanner:<init>(org.apache.hadoop.yarn.util.Clock)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.reservation.PeriodicRLESparseResourceAllocation:<init>(org.apache.hadoop.yarn.server.resourcemanager.reservation.RLESparseResourceAllocation,java.lang.Long)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.RMContextImpl:<init>(org.apache.hadoop.yarn.event.Dispatcher,org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.ContainerAllocationExpirer,org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.AMLivelinessMonitor,org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.AMLivelinessMonitor,org.apache.hadoop.yarn.server.resourcemanager.security.DelegationTokenRenewer,org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager,org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager,org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM,org.apache.hadoop.yarn.server.resourcemanager.security.ClientToAMTokenSecretManagerInRM,org.apache.hadoop.yarn.server.resourcemanager.scheduler.ResourceScheduler)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.RMContextImpl:<init>(org.apache.hadoop.yarn.event.Dispatcher,org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.ContainerAllocationExpirer,org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.AMLivelinessMonitor,org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.AMLivelinessMonitor,org.apache.hadoop.yarn.server.resourcemanager.security.DelegationTokenRenewer,org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager,org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager,org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM,org.apache.hadoop.yarn.server.resourcemanager.security.ClientToAMTokenSecretManagerInRM)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.RMContextImpl:getServiceContext()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.RMContextImpl:getServiceContext()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.resourcemanager.RMContextImpl:setServiceContext(org.apache.hadoop.yarn.server.resourcemanager.RMServiceContext)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.RMContextImpl:setServiceContext(org.apache.hadoop.yarn.server.resourcemanager.RMServiceContext)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.resourcemanager.RMContextImpl:getActiveServiceContext()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.RMContextImpl:getActiveServiceContext()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.resourcemanager.RMContextImpl:setActiveServiceContext(org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.RMContextImpl:setActiveServiceContext(org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.resourcemanager.RMContextImpl:setStateStore(org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.RMContextImpl:setScheduler(org.apache.hadoop.yarn.server.resourcemanager.scheduler.ResourceScheduler)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.RMContextImpl:setSystemClock(org.apache.hadoop.yarn.util.Clock)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.resourcemanager.RMContextImpl:setSystemClock(org.apache.hadoop.yarn.util.Clock)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService:handleNMContainerStatus(org.apache.hadoop.yarn.server.api.protocolrecords.NMContainerStatus,org.apache.hadoop.yarn.api.records.NodeId)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService:getServer()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.router.RouterServerUtil:logAndThrowException(java.lang.String,java.lang.Throwable)	org.apache.hadoop.classification.InterfaceAudience$Public
org.apache.hadoop.yarn.server.router.RouterServerUtil:logAndThrowException(java.lang.String,java.lang.Throwable)	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.router.Router:getWebapp()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.router.Router:startWepApp()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.router.rmadmin.RouterRMAdminService:getServer()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.router.rmadmin.RouterRMAdminService:getInterceptorChain()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.router.rmadmin.RouterRMAdminService:getPipelines()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.router.rmadmin.RouterRMAdminService:createRequestInterceptorChain()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.router.rmadmin.DefaultRMAdminRequestInterceptor:setRMAdmin(org.apache.hadoop.yarn.server.api.ResourceManagerAdministrationProtocol)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.router.RouterMetrics:destroy()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.router.RouterMetrics:getNumSucceededAppsCreated()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.router.RouterMetrics:getNumSucceededAppsSubmitted()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.router.RouterMetrics:getNumSucceededAppsKilled()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.router.RouterMetrics:getNumSucceededAppsRetrieved()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.router.RouterMetrics:getNumSucceededMultipleAppsRetrieved()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.router.RouterMetrics:getLatencySucceededAppsCreated()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.router.RouterMetrics:getLatencySucceededAppsSubmitted()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.router.RouterMetrics:getLatencySucceededAppsKilled()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.router.RouterMetrics:getLatencySucceededGetAppReport()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.router.RouterMetrics:getLatencySucceededMultipleGetAppReport()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.router.RouterMetrics:getAppsFailedCreated()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.router.RouterMetrics:getAppsFailedSubmitted()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.router.RouterMetrics:getAppsFailedKilled()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.router.RouterMetrics:getAppsFailedRetrieved()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.router.RouterMetrics:getMultipleAppsFailedRetrieved()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.router.clientrm.DefaultClientRequestInterceptor:setRMClient(org.apache.hadoop.yarn.api.ApplicationClientProtocol)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.router.clientrm.RouterClientRMService:getServer()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.router.clientrm.RouterClientRMService:getInterceptorChain()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.router.clientrm.RouterClientRMService:getPipelines()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.router.clientrm.RouterClientRMService:createRequestInterceptorChain()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.router.clientrm.FederationClientInterceptor:getClientRMProxyForSubCluster(org.apache.hadoop.yarn.server.federation.store.records.SubClusterId)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.router.webapp.NodesBlock:<init>(org.apache.hadoop.yarn.server.router.Router,org.apache.hadoop.yarn.webapp.View$ViewContext)	com.google.inject.Inject
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:<init>(org.apache.hadoop.yarn.server.router.Router,org.apache.hadoop.conf.Configuration)	com.google.inject.Inject
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:getInterceptorChain(javax.servlet.http.HttpServletRequest)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:getPipelines()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:createRequestInterceptorChain()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:get()	javax.ws.rs.GET
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:get()	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:getClusterInfo()	javax.ws.rs.GET
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:getClusterInfo()	javax.ws.rs.Path	value	/info
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:getClusterInfo()	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:getClusterUserInfo(javax.servlet.http.HttpServletRequest)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:getClusterUserInfo(javax.servlet.http.HttpServletRequest)	javax.ws.rs.Path	value	/userinfo
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:getClusterUserInfo(javax.servlet.http.HttpServletRequest)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:getClusterMetricsInfo()	javax.ws.rs.GET
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:getClusterMetricsInfo()	javax.ws.rs.Path	value	/metrics
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:getClusterMetricsInfo()	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:getSchedulerInfo()	javax.ws.rs.GET
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:getSchedulerInfo()	javax.ws.rs.Path	value	/scheduler
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:getSchedulerInfo()	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:dumpSchedulerLogs(java.lang.String,javax.servlet.http.HttpServletRequest)	javax.ws.rs.POST
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:dumpSchedulerLogs(java.lang.String,javax.servlet.http.HttpServletRequest)	javax.ws.rs.Path	value	/scheduler/logs
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:dumpSchedulerLogs(java.lang.String,javax.servlet.http.HttpServletRequest)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:getNodes(java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:getNodes(java.lang.String)	javax.ws.rs.Path	value	/nodes
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:getNodes(java.lang.String)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:getNode(java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:getNode(java.lang.String)	javax.ws.rs.Path	value	/nodes/{nodeId}
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:getNode(java.lang.String)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:updateNodeResource(javax.servlet.http.HttpServletRequest,java.lang.String,org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ResourceOptionInfo)	javax.ws.rs.POST
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:updateNodeResource(javax.servlet.http.HttpServletRequest,java.lang.String,org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ResourceOptionInfo)	javax.ws.rs.Path	value	/nodes/{nodeId}/resource
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:updateNodeResource(javax.servlet.http.HttpServletRequest,java.lang.String,org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ResourceOptionInfo)	javax.ws.rs.Consumes	value	{application/json,application/xml}
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:updateNodeResource(javax.servlet.http.HttpServletRequest,java.lang.String,org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ResourceOptionInfo)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:getApps(javax.servlet.http.HttpServletRequest,java.lang.String,java.util.Set,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.util.Set,java.util.Set,java.lang.String,java.util.Set)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:getApps(javax.servlet.http.HttpServletRequest,java.lang.String,java.util.Set,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.util.Set,java.util.Set,java.lang.String,java.util.Set)	javax.ws.rs.Path	value	/apps
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:getApps(javax.servlet.http.HttpServletRequest,java.lang.String,java.util.Set,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.util.Set,java.util.Set,java.lang.String,java.util.Set)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:getActivities(javax.servlet.http.HttpServletRequest,java.lang.String,java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:getActivities(javax.servlet.http.HttpServletRequest,java.lang.String,java.lang.String)	javax.ws.rs.Path	value	/scheduler/activities
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:getActivities(javax.servlet.http.HttpServletRequest,java.lang.String,java.lang.String)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:getAppActivities(javax.servlet.http.HttpServletRequest,java.lang.String,java.lang.String,java.util.Set,java.util.Set,java.lang.String,java.lang.String,java.util.Set,boolean)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:getAppActivities(javax.servlet.http.HttpServletRequest,java.lang.String,java.lang.String,java.util.Set,java.util.Set,java.lang.String,java.lang.String,java.util.Set,boolean)	javax.ws.rs.Path	value	/scheduler/app-activities/{appid}
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:getAppActivities(javax.servlet.http.HttpServletRequest,java.lang.String,java.lang.String,java.util.Set,java.util.Set,java.lang.String,java.lang.String,java.util.Set,boolean)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:getAppStatistics(javax.servlet.http.HttpServletRequest,java.util.Set,java.util.Set)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:getAppStatistics(javax.servlet.http.HttpServletRequest,java.util.Set,java.util.Set)	javax.ws.rs.Path	value	/appstatistics
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:getAppStatistics(javax.servlet.http.HttpServletRequest,java.util.Set,java.util.Set)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:getApp(javax.servlet.http.HttpServletRequest,java.lang.String,java.util.Set)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:getApp(javax.servlet.http.HttpServletRequest,java.lang.String,java.util.Set)	javax.ws.rs.Path	value	/apps/{appid}
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:getApp(javax.servlet.http.HttpServletRequest,java.lang.String,java.util.Set)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:getAppState(javax.servlet.http.HttpServletRequest,java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:getAppState(javax.servlet.http.HttpServletRequest,java.lang.String)	javax.ws.rs.Path	value	/apps/{appid}/state
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:getAppState(javax.servlet.http.HttpServletRequest,java.lang.String)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:updateAppState(org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppState,javax.servlet.http.HttpServletRequest,java.lang.String)	javax.ws.rs.PUT
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:updateAppState(org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppState,javax.servlet.http.HttpServletRequest,java.lang.String)	javax.ws.rs.Path	value	/apps/{appid}/state
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:updateAppState(org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppState,javax.servlet.http.HttpServletRequest,java.lang.String)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:getNodeToLabels(javax.servlet.http.HttpServletRequest)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:getNodeToLabels(javax.servlet.http.HttpServletRequest)	javax.ws.rs.Path	value	/get-node-to-labels
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:getNodeToLabels(javax.servlet.http.HttpServletRequest)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:getLabelsToNodes(java.util.Set)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:getLabelsToNodes(java.util.Set)	javax.ws.rs.Path	value	/label-mappings
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:getLabelsToNodes(java.util.Set)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:replaceLabelsOnNodes(org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodeToLabelsEntryList,javax.servlet.http.HttpServletRequest)	javax.ws.rs.POST
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:replaceLabelsOnNodes(org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodeToLabelsEntryList,javax.servlet.http.HttpServletRequest)	javax.ws.rs.Path	value	/replace-node-to-labels
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:replaceLabelsOnNodes(org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodeToLabelsEntryList,javax.servlet.http.HttpServletRequest)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:replaceLabelsOnNode(java.util.Set,javax.servlet.http.HttpServletRequest,java.lang.String)	javax.ws.rs.POST
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:replaceLabelsOnNode(java.util.Set,javax.servlet.http.HttpServletRequest,java.lang.String)	javax.ws.rs.Path	value	/nodes/{nodeId}/replace-labels
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:replaceLabelsOnNode(java.util.Set,javax.servlet.http.HttpServletRequest,java.lang.String)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:getClusterNodeLabels(javax.servlet.http.HttpServletRequest)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:getClusterNodeLabels(javax.servlet.http.HttpServletRequest)	javax.ws.rs.Path	value	/get-node-labels
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:getClusterNodeLabels(javax.servlet.http.HttpServletRequest)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:addToClusterNodeLabels(org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodeLabelsInfo,javax.servlet.http.HttpServletRequest)	javax.ws.rs.POST
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:addToClusterNodeLabels(org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodeLabelsInfo,javax.servlet.http.HttpServletRequest)	javax.ws.rs.Path	value	/add-node-labels
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:addToClusterNodeLabels(org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodeLabelsInfo,javax.servlet.http.HttpServletRequest)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:removeFromCluserNodeLabels(java.util.Set,javax.servlet.http.HttpServletRequest)	javax.ws.rs.POST
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:removeFromCluserNodeLabels(java.util.Set,javax.servlet.http.HttpServletRequest)	javax.ws.rs.Path	value	/remove-node-labels
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:removeFromCluserNodeLabels(java.util.Set,javax.servlet.http.HttpServletRequest)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:getLabelsOnNode(javax.servlet.http.HttpServletRequest,java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:getLabelsOnNode(javax.servlet.http.HttpServletRequest,java.lang.String)	javax.ws.rs.Path	value	/nodes/{nodeId}/get-labels
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:getLabelsOnNode(javax.servlet.http.HttpServletRequest,java.lang.String)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:getAppPriority(javax.servlet.http.HttpServletRequest,java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:getAppPriority(javax.servlet.http.HttpServletRequest,java.lang.String)	javax.ws.rs.Path	value	/apps/{appid}/priority
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:getAppPriority(javax.servlet.http.HttpServletRequest,java.lang.String)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:updateApplicationPriority(org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppPriority,javax.servlet.http.HttpServletRequest,java.lang.String)	javax.ws.rs.PUT
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:updateApplicationPriority(org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppPriority,javax.servlet.http.HttpServletRequest,java.lang.String)	javax.ws.rs.Path	value	/apps/{appid}/priority
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:updateApplicationPriority(org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppPriority,javax.servlet.http.HttpServletRequest,java.lang.String)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:getAppQueue(javax.servlet.http.HttpServletRequest,java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:getAppQueue(javax.servlet.http.HttpServletRequest,java.lang.String)	javax.ws.rs.Path	value	/apps/{appid}/queue
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:getAppQueue(javax.servlet.http.HttpServletRequest,java.lang.String)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:updateAppQueue(org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppQueue,javax.servlet.http.HttpServletRequest,java.lang.String)	javax.ws.rs.PUT
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:updateAppQueue(org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppQueue,javax.servlet.http.HttpServletRequest,java.lang.String)	javax.ws.rs.Path	value	/apps/{appid}/queue
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:updateAppQueue(org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppQueue,javax.servlet.http.HttpServletRequest,java.lang.String)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:createNewApplication(javax.servlet.http.HttpServletRequest)	javax.ws.rs.POST
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:createNewApplication(javax.servlet.http.HttpServletRequest)	javax.ws.rs.Path	value	/apps/new-application
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:createNewApplication(javax.servlet.http.HttpServletRequest)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:submitApplication(org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ApplicationSubmissionContextInfo,javax.servlet.http.HttpServletRequest)	javax.ws.rs.POST
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:submitApplication(org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ApplicationSubmissionContextInfo,javax.servlet.http.HttpServletRequest)	javax.ws.rs.Path	value	/apps
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:submitApplication(org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ApplicationSubmissionContextInfo,javax.servlet.http.HttpServletRequest)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:postDelegationToken(org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.DelegationToken,javax.servlet.http.HttpServletRequest)	javax.ws.rs.POST
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:postDelegationToken(org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.DelegationToken,javax.servlet.http.HttpServletRequest)	javax.ws.rs.Path	value	/delegation-token
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:postDelegationToken(org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.DelegationToken,javax.servlet.http.HttpServletRequest)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:postDelegationTokenExpiration(javax.servlet.http.HttpServletRequest)	javax.ws.rs.POST
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:postDelegationTokenExpiration(javax.servlet.http.HttpServletRequest)	javax.ws.rs.Path	value	/delegation-token/expiration
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:postDelegationTokenExpiration(javax.servlet.http.HttpServletRequest)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:cancelDelegationToken(javax.servlet.http.HttpServletRequest)	javax.ws.rs.DELETE
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:cancelDelegationToken(javax.servlet.http.HttpServletRequest)	javax.ws.rs.Path	value	/delegation-token
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:cancelDelegationToken(javax.servlet.http.HttpServletRequest)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:createNewReservation(javax.servlet.http.HttpServletRequest)	javax.ws.rs.POST
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:createNewReservation(javax.servlet.http.HttpServletRequest)	javax.ws.rs.Path	value	/reservation/new-reservation
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:createNewReservation(javax.servlet.http.HttpServletRequest)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:submitReservation(org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationSubmissionRequestInfo,javax.servlet.http.HttpServletRequest)	javax.ws.rs.POST
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:submitReservation(org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationSubmissionRequestInfo,javax.servlet.http.HttpServletRequest)	javax.ws.rs.Path	value	/reservation/submit
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:submitReservation(org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationSubmissionRequestInfo,javax.servlet.http.HttpServletRequest)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:updateReservation(org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationUpdateRequestInfo,javax.servlet.http.HttpServletRequest)	javax.ws.rs.POST
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:updateReservation(org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationUpdateRequestInfo,javax.servlet.http.HttpServletRequest)	javax.ws.rs.Path	value	/reservation/update
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:updateReservation(org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationUpdateRequestInfo,javax.servlet.http.HttpServletRequest)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:deleteReservation(org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationDeleteRequestInfo,javax.servlet.http.HttpServletRequest)	javax.ws.rs.POST
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:deleteReservation(org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationDeleteRequestInfo,javax.servlet.http.HttpServletRequest)	javax.ws.rs.Path	value	/reservation/delete
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:deleteReservation(org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationDeleteRequestInfo,javax.servlet.http.HttpServletRequest)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:listReservation(java.lang.String,java.lang.String,long,long,boolean,javax.servlet.http.HttpServletRequest)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:listReservation(java.lang.String,java.lang.String,long,long,boolean,javax.servlet.http.HttpServletRequest)	javax.ws.rs.Path	value	/reservation/list
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:listReservation(java.lang.String,java.lang.String,long,long,boolean,javax.servlet.http.HttpServletRequest)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:getAppTimeout(javax.servlet.http.HttpServletRequest,java.lang.String,java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:getAppTimeout(javax.servlet.http.HttpServletRequest,java.lang.String,java.lang.String)	javax.ws.rs.Path	value	/apps/{appid}/timeouts/{type}
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:getAppTimeout(javax.servlet.http.HttpServletRequest,java.lang.String,java.lang.String)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:getAppTimeouts(javax.servlet.http.HttpServletRequest,java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:getAppTimeouts(javax.servlet.http.HttpServletRequest,java.lang.String)	javax.ws.rs.Path	value	/apps/{appid}/timeouts
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:getAppTimeouts(javax.servlet.http.HttpServletRequest,java.lang.String)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:updateApplicationTimeout(org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppTimeoutInfo,javax.servlet.http.HttpServletRequest,java.lang.String)	javax.ws.rs.PUT
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:updateApplicationTimeout(org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppTimeoutInfo,javax.servlet.http.HttpServletRequest,java.lang.String)	javax.ws.rs.Path	value	/apps/{appid}/timeout
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:updateApplicationTimeout(org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppTimeoutInfo,javax.servlet.http.HttpServletRequest,java.lang.String)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:getAppAttempts(javax.servlet.http.HttpServletRequest,java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:getAppAttempts(javax.servlet.http.HttpServletRequest,java.lang.String)	javax.ws.rs.Path	value	/apps/{appid}/appattempts
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:getAppAttempts(javax.servlet.http.HttpServletRequest,java.lang.String)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:checkUserAccessToQueue(java.lang.String,java.lang.String,java.lang.String,javax.servlet.http.HttpServletRequest)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:checkUserAccessToQueue(java.lang.String,java.lang.String,java.lang.String,javax.servlet.http.HttpServletRequest)	javax.ws.rs.Path	value	/queues/{queue}/access
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:checkUserAccessToQueue(java.lang.String,java.lang.String,java.lang.String,javax.servlet.http.HttpServletRequest)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:getAppAttempt(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:getAppAttempt(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String)	javax.ws.rs.Path	value	/apps/{appid}/appattempts/{appattemptid}
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:getAppAttempt(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:getContainers(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:getContainers(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String)	javax.ws.rs.Path	value	/apps/{appid}/appattempts/{appattemptid}/containers
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:getContainers(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:getContainer(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:getContainer(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.Path	value	/apps/{appid}/appattempts/{appattemptid}/containers/{containerid}
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:getContainer(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:setResponse(javax.servlet.http.HttpServletResponse)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:signalToContainer(java.lang.String,java.lang.String,javax.servlet.http.HttpServletRequest)	javax.ws.rs.POST
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:signalToContainer(java.lang.String,java.lang.String,javax.servlet.http.HttpServletRequest)	javax.ws.rs.Path	value	/containers/{containerid}/signal/{command}
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:signalToContainer(java.lang.String,java.lang.String,javax.servlet.http.HttpServletRequest)	javax.ws.rs.Produces	value	{application/json; charset=utf-8,application/xml; charset=utf-8}
org.apache.hadoop.yarn.server.router.webapp.AboutBlock:<init>(org.apache.hadoop.yarn.server.router.Router,org.apache.hadoop.yarn.webapp.View$ViewContext)	com.google.inject.Inject
org.apache.hadoop.yarn.server.router.webapp.FederationBlock:<init>(org.apache.hadoop.yarn.webapp.View$ViewContext,org.apache.hadoop.yarn.server.router.Router)	com.google.inject.Inject
org.apache.hadoop.yarn.server.router.webapp.FederationInterceptorREST:getInterceptorForSubCluster(org.apache.hadoop.yarn.server.federation.store.records.SubClusterId)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.router.webapp.FederationInterceptorREST:getOrCreateInterceptorForSubCluster(org.apache.hadoop.yarn.server.federation.store.records.SubClusterId,java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.router.webapp.RouterController:<init>(org.apache.hadoop.yarn.webapp.Controller$RequestContext)	com.google.inject.Inject
org.apache.hadoop.yarn.server.router.webapp.AppsBlock:<init>(org.apache.hadoop.yarn.server.router.Router,org.apache.hadoop.yarn.webapp.View$ViewContext)	com.google.inject.Inject
org.apache.hadoop.yarn.server.router.security.authorize.RouterPolicyProvider:getInstance()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.router.security.authorize.RouterPolicyProvider:getInstance()	org.apache.hadoop.classification.InterfaceStability$Unstable
org.apache.hadoop.yarn.server.sharedcachemanager.SharedCacheManager:getSCMStore()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.sharedcachemanager.AppChecker:isApplicationActive(org.apache.hadoop.yarn.api.records.ApplicationId)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.sharedcachemanager.AppChecker:getActiveApplications()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.sharedcachemanager.store.InMemorySCMStore:<init>(org.apache.hadoop.yarn.server.sharedcachemanager.AppChecker)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.sharedcachemanager.store.InMemorySCMStore:getInitialCachedResources(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.conf.Configuration)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.sharedcachemanager.store.InMemorySCMStore:getAccessTime(java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.sharedcachemanager.store.SCMStore:<init>(java.lang.String,org.apache.hadoop.yarn.server.sharedcachemanager.AppChecker)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.sharedcachemanager.store.SCMStore:addResource(java.lang.String,java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.sharedcachemanager.store.SCMStore:removeResource(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.sharedcachemanager.store.SCMStore:addResourceReference(java.lang.String,org.apache.hadoop.yarn.server.sharedcachemanager.store.SharedCacheResourceReference)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.sharedcachemanager.store.SCMStore:getResourceReferences(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.sharedcachemanager.store.SCMStore:removeResourceReference(java.lang.String,org.apache.hadoop.yarn.server.sharedcachemanager.store.SharedCacheResourceReference,boolean)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.sharedcachemanager.store.SCMStore:removeResourceReferences(java.lang.String,java.util.Collection,boolean)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.sharedcachemanager.store.SCMStore:cleanResourceReferences(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.sharedcachemanager.store.SCMStore:isResourceEvictable(java.lang.String,org.apache.hadoop.fs.FileStatus)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.sharedcachemanager.store.SCMStore:createAppCheckerService(org.apache.hadoop.conf.Configuration)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.sharedcachemanager.webapp.SCMOverviewPage$SCMOverviewBlock:<init>(org.apache.hadoop.yarn.server.sharedcachemanager.SharedCacheManager,org.apache.hadoop.yarn.webapp.View$ViewContext)	com.google.inject.Inject
org.apache.hadoop.yarn.server.sharedcachemanager.RemoteAppChecker:isApplicationActive(org.apache.hadoop.yarn.api.records.ApplicationId)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.sharedcachemanager.RemoteAppChecker:getActiveApplications()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.timeline.EntityGroupFSTimelineStore:scanActiveLogs()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.timeline.EntityGroupFSTimelineStore:scanActiveLogs()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.timeline.EntityGroupFSTimelineStore:cleanLogs(org.apache.hadoop.fs.Path,long)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.timeline.EntityGroupFSTimelineStore:cleanLogs(org.apache.hadoop.fs.Path,long)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.timeline.EntityGroupFSTimelineStore:createAndInitYarnClient(org.apache.hadoop.conf.Configuration)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.timeline.EntityGroupFSTimelineStore:getAppState(org.apache.hadoop.yarn.api.records.ApplicationId)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.timeline.EntityGroupFSTimelineStore:getPlugins()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.timeline.EntityGroupFSTimelineStore:setFs(org.apache.hadoop.fs.FileSystem)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.timeline.EntityGroupFSTimelineStore:setFs(org.apache.hadoop.fs.FileSystem)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.timeline.EntityGroupFSTimelineStore:setCachedLogs(org.apache.hadoop.yarn.api.records.timeline.TimelineEntityGroupId,org.apache.hadoop.yarn.server.timeline.EntityCacheItem)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.timeline.EntityGroupFSTimelineStore:setCachedLogs(org.apache.hadoop.yarn.api.records.timeline.TimelineEntityGroupId,org.apache.hadoop.yarn.server.timeline.EntityCacheItem)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.timeline.LogInfo:matchesGroupId(java.lang.String)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.timeline.LogInfo:matchesGroupId(java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.timeline.EntityGroupFSTimelineStore$AppLogs:parseSummaryLogs(org.apache.hadoop.yarn.server.timeline.TimelineDataManager)	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.timeline.EntityGroupFSTimelineStore$AppLogs:parseSummaryLogs(org.apache.hadoop.yarn.server.timeline.TimelineDataManager)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.timeline.EntityGroupFSTimelineStore$AppLogs:scanForLogs()	org.apache.hadoop.classification.InterfaceAudience$Private
org.apache.hadoop.yarn.server.timeline.EntityGroupFSTimelineStore$AppLogs:scanForLogs()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.timelineservice.documentstore.writer.cosmosdb.CosmosDBDocumentStoreWriter:applyUpdatesOnPrevDoc(org.apache.hadoop.yarn.server.timelineservice.documentstore.collection.CollectionType,org.apache.hadoop.yarn.server.timelineservice.documentstore.collection.document.TimelineDocument,java.lang.StringBuilder)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.timelineservice.documentstore.writer.cosmosdb.CosmosDBDocumentStoreWriter:fetchLatestDoc(org.apache.hadoop.yarn.server.timelineservice.documentstore.collection.CollectionType,java.lang.String,java.lang.StringBuilder)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.timelineservice.documentstore.reader.cosmosdb.CosmosDBDocumentStoreReader:addPredicates(org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderContext,java.lang.String,java.lang.StringBuilder)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.timelineservice.storage.HBaseTimelineSchemaCreator:createAllTables(org.apache.hadoop.conf.Configuration,boolean)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.timelineservice.storage.flow.FlowScanner:processSummationMajorCompaction(java.util.SortedSet,org.apache.hadoop.yarn.server.timelineservice.storage.common.NumericValueConverter,long)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.timelineservice.collector.AppLevelTimelineCollector:getDelegationTokenForApp()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.timelineservice.collector.TimelineCollectorWebService:about(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.timelineservice.collector.TimelineCollectorWebService:about(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)	javax.ws.rs.Produces	value	{application/json; charset=utf-8}
org.apache.hadoop.yarn.server.timelineservice.collector.TimelineCollectorWebService:putEntities(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,org.apache.hadoop.yarn.api.records.timelineservice.TimelineEntities)	javax.ws.rs.PUT
org.apache.hadoop.yarn.server.timelineservice.collector.TimelineCollectorWebService:putEntities(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,org.apache.hadoop.yarn.api.records.timelineservice.TimelineEntities)	javax.ws.rs.Path	value	/entities
org.apache.hadoop.yarn.server.timelineservice.collector.TimelineCollectorWebService:putEntities(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,org.apache.hadoop.yarn.api.records.timelineservice.TimelineEntities)	javax.ws.rs.Consumes	value	{application/json}
org.apache.hadoop.yarn.server.timelineservice.collector.TimelineCollectorWebService:putDomain(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,org.apache.hadoop.yarn.api.records.timelineservice.TimelineDomain)	javax.ws.rs.PUT
org.apache.hadoop.yarn.server.timelineservice.collector.TimelineCollectorWebService:putDomain(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,org.apache.hadoop.yarn.api.records.timelineservice.TimelineDomain)	javax.ws.rs.Path	value	/domain
org.apache.hadoop.yarn.server.timelineservice.collector.TimelineCollectorWebService:putDomain(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,org.apache.hadoop.yarn.api.records.timelineservice.TimelineDomain)	javax.ws.rs.Consumes	value	{application/json}
org.apache.hadoop.yarn.server.timelineservice.collector.NodeTimelineCollectorManager:<init>()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.timelineservice.collector.NodeTimelineCollectorManager:getTokenManagerService()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.timelineservice.collector.NodeTimelineCollectorManager:generateTokenForAppCollector(java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.timelineservice.collector.NodeTimelineCollectorManager:renewTokenForAppCollector(org.apache.hadoop.yarn.server.timelineservice.collector.AppLevelTimelineCollector)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.timelineservice.collector.NodeTimelineCollectorManager:cancelTokenForAppCollector(org.apache.hadoop.yarn.server.timelineservice.collector.AppLevelTimelineCollector)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.timelineservice.collector.NodeTimelineCollectorManager:getNMCollectorService()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.timelineservice.collector.NodeTimelineCollectorManager:getRestServerBindAddress()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.timelineservice.collector.PerNodeTimelineCollectorsAuxService:<init>(org.apache.hadoop.yarn.server.timelineservice.collector.NodeTimelineCollectorManager)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.timelineservice.collector.PerNodeTimelineCollectorsAuxService:removeApplicationCollector(org.apache.hadoop.yarn.api.records.ContainerId)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.timelineservice.collector.PerNodeTimelineCollectorsAuxService:hasApplication(org.apache.hadoop.yarn.api.records.ApplicationId)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.timelineservice.collector.PerNodeTimelineCollectorsAuxService:launchServer(java.lang.String[],org.apache.hadoop.yarn.server.timelineservice.collector.NodeTimelineCollectorManager,org.apache.hadoop.conf.Configuration)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.timelineservice.collector.TimelineCollectorWebService$AboutInfo:getAbout()	javax.xml.bind.annotation.XmlElement	name	About
org.apache.hadoop.yarn.server.timelineservice.collector.TimelineCollectorManager:writerFlusherRunning()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.timelineservice.metrics.PerNodeAggTimelineCollectorMetrics:getPutEntitiesSuccessLatency()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.timelineservice.metrics.PerNodeAggTimelineCollectorMetrics:getPutEntitiesFailureLatency()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.timelineservice.metrics.PerNodeAggTimelineCollectorMetrics:getAsyncPutEntitiesSuccessLatency()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.timelineservice.metrics.PerNodeAggTimelineCollectorMetrics:getAsyncPutEntitiesFailureLatency()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.timelineservice.metrics.TimelineReaderMetrics:<init>()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.timelineservice.metrics.TimelineReaderMetrics:getGetEntitiesSuccessLatency()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.timelineservice.metrics.TimelineReaderMetrics:getGetEntitiesFailureLatency()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.timelineservice.metrics.TimelineReaderMetrics:getGetEntityTypesSuccessLatency()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.timelineservice.metrics.TimelineReaderMetrics:getGetEntityTypesFailureLatency()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderServer:getWebServerPort()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:about(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:about(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)	javax.ws.rs.Produces	value	{application/json; charset=utf-8}
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:health(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:health(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)	javax.ws.rs.Path	value	/health
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:health(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)	javax.ws.rs.Produces	value	{application/json; charset=utf-8}
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:getEntities(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:getEntities(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.Path	value	/app-uid/{uid}/entities/{entitytype}
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:getEntities(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.Produces	value	{application/json; charset=utf-8}
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:getEntities(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:getEntities(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.Path	value	/apps/{appid}/entities/{entitytype}
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:getEntities(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.Produces	value	{application/json; charset=utf-8}
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:getEntities(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:getEntities(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.Path	value	/clusters/{clusterid}/apps/{appid}/entities/{entitytype}
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:getEntities(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.Produces	value	{application/json; charset=utf-8}
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:getEntity(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:getEntity(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.Path	value	/entity-uid/{uid}/
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:getEntity(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.Produces	value	{application/json; charset=utf-8}
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:getEntity(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:getEntity(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.Path	value	/apps/{appid}/entities/{entitytype}/{entityid}/
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:getEntity(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.Produces	value	{application/json; charset=utf-8}
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:getEntity(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:getEntity(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.Path	value	/clusters/{clusterid}/apps/{appid}/entities/{entitytype}/{entityid}/
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:getEntity(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.Produces	value	{application/json; charset=utf-8}
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:getFlowRun(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:getFlowRun(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String)	javax.ws.rs.Path	value	/run-uid/{uid}/
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:getFlowRun(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String)	javax.ws.rs.Produces	value	{application/json; charset=utf-8}
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:getFlowRun(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:getFlowRun(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.Path	value	/users/{userid}/flows/{flowname}/runs/{flowrunid}/
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:getFlowRun(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.Produces	value	{application/json; charset=utf-8}
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:getFlowRun(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:getFlowRun(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.Path	value	/clusters/{clusterid}/users/{userid}/flows/{flowname}/runs/{flowrunid}/
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:getFlowRun(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.Produces	value	{application/json; charset=utf-8}
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:getFlowRuns(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:getFlowRuns(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.Path	value	/flow-uid/{uid}/runs/
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:getFlowRuns(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.Produces	value	{application/json; charset=utf-8}
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:getFlowRuns(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:getFlowRuns(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.Path	value	/users/{userid}/flows/{flowname}/runs/
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:getFlowRuns(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.Produces	value	{application/json; charset=utf-8}
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:getFlowRuns(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:getFlowRuns(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.Path	value	/clusters/{clusterid}/users/{userid}/flows/{flowname}/runs/
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:getFlowRuns(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.Produces	value	{application/json; charset=utf-8}
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:getFlows(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:getFlows(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.Path	value	/flows/
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:getFlows(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.Produces	value	{application/json; charset=utf-8}
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:getFlows(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:getFlows(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.Path	value	/clusters/{clusterid}/flows/
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:getFlows(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.Produces	value	{application/json; charset=utf-8}
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:getApp(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:getApp(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.Path	value	/app-uid/{uid}/
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:getApp(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.Produces	value	{application/json; charset=utf-8}
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:getApp(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:getApp(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.Path	value	/apps/{appid}/
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:getApp(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.Produces	value	{application/json; charset=utf-8}
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:getApp(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:getApp(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.Path	value	/clusters/{clusterid}/apps/{appid}/
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:getApp(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.Produces	value	{application/json; charset=utf-8}
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:getFlowRunApps(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:getFlowRunApps(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.Path	value	/run-uid/{uid}/apps
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:getFlowRunApps(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.Produces	value	{application/json; charset=utf-8}
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:getFlowRunApps(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:getFlowRunApps(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.Path	value	/users/{userid}/flows/{flowname}/runs/{flowrunid}/apps/
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:getFlowRunApps(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.Produces	value	{application/json; charset=utf-8}
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:getFlowRunApps(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:getFlowRunApps(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.Path	value	/clusters/{clusterid}/users/{userid}/flows/{flowname}/runs/{flowrunid}/apps/
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:getFlowRunApps(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.Produces	value	{application/json; charset=utf-8}
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:getFlowApps(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:getFlowApps(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.Path	value	/users/{userid}/flows/{flowname}/apps/
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:getFlowApps(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.Produces	value	{application/json; charset=utf-8}
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:getFlowApps(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:getFlowApps(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.Path	value	/clusters/{clusterid}/users/{userid}/flows/{flowname}/apps/
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:getFlowApps(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.Produces	value	{application/json; charset=utf-8}
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:getAppAttempts(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:getAppAttempts(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.Path	value	/apps/{appid}/appattempts
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:getAppAttempts(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.Produces	value	{application/json}
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:getAppAttempts(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:getAppAttempts(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.Path	value	/clusters/{clusterid}/apps/{appid}/appattempts
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:getAppAttempts(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.Produces	value	{application/json}
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:getAppAttempt(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:getAppAttempt(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.Path	value	/apps/{appid}/appattempts/{appattemptid}
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:getAppAttempt(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.Produces	value	{application/json}
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:getAppAttempt(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:getAppAttempt(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.Path	value	/clusters/{clusterid}/apps/{appid}/appattempts/{appattemptid}
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:getAppAttempt(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.Produces	value	{application/json}
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:getContainers(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:getContainers(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.Path	value	/apps/{appid}/appattempts/{appattemptid}/containers
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:getContainers(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.Produces	value	{application/json}
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:getContainers(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:getContainers(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.Path	value	/clusters/{clusterid}/apps/{appid}/appattempts/{appattemptid}/containers
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:getContainers(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.Produces	value	{application/json}
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:getContainer(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:getContainer(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.Path	value	/apps/{appid}/containers/{containerid}
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:getContainer(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.Produces	value	{application/json}
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:getContainer(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:getContainer(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.Path	value	/clusters/{clusterid}/apps/{appid}/containers/{containerid}
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:getContainer(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.Produces	value	{application/json}
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:getEntityTypes(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:getEntityTypes(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.Path	value	/apps/{appid}/entity-types
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:getEntityTypes(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.Produces	value	{application/json}
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:getEntityTypes(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:getEntityTypes(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.Path	value	/clusters/{clusterid}/apps/{appid}/entity-types
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:getEntityTypes(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.Produces	value	{application/json}
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:getSubAppEntities(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:getSubAppEntities(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.Path	value	/users/{userid}/entities/{entitytype}
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:getSubAppEntities(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.Produces	value	{application/json; charset=utf-8}
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:getSubAppEntities(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:getSubAppEntities(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.Path	value	/clusters/{clusterid}/users/{userid}/entities/{entitytype}
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:getSubAppEntities(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.Produces	value	{application/json; charset=utf-8}
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:getSubAppEntities(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:getSubAppEntities(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.Path	value	/users/{userid}/entities/{entitytype}/{entityid}
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:getSubAppEntities(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.Produces	value	{application/json; charset=utf-8}
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:getSubAppEntities(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.GET
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:getSubAppEntities(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.Path	value	/clusters/{clusterid}/users/{userid}/entities/{entitytype}/{entityid}
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices:getSubAppEntities(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String)	javax.ws.rs.Produces	value	{application/json; charset=utf-8}
org.apache.hadoop.yarn.server.timelineservice.storage.FileSystemTimelineWriterImpl:getOutputRoot()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.timelineservice.storage.FileSystemTimelineReaderImpl:getRootPath()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.timelineservice.storage.TimelineSchemaCreator:createTimelineSchema(java.lang.String[],org.apache.hadoop.conf.Configuration)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.webproxy.ProxyCA:createTrustManager(org.apache.hadoop.yarn.api.records.ApplicationId)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.webproxy.ProxyCA:getX509KeyManager()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.webproxy.ProxyCA:setDefaultTrustManager(javax.net.ssl.X509TrustManager)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.webproxy.ProxyCA:getCaCert()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.webproxy.ProxyCA:getCaKeyPair()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.webproxy.amfilter.AmFilterInitializer:getApplicationWebProxyBase()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter:findRedirectUrl()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter:isValidUrl(java.lang.String)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter:setUpdateInterval(long)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.webproxy.WebAppProxyServlet:checkHttpsStrictAndNotProvided(javax.servlet.http.HttpServletResponse,java.net.URI,org.apache.hadoop.yarn.conf.YarnConfiguration)	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
org.apache.hadoop.yarn.server.webproxy.WebAppProxy:getBindAddress()	org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting
