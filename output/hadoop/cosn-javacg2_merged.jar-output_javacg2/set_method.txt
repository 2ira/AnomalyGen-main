org.apache.hadoop.fs.cosn.CosNFileSystem	setWorkingDirectory	workingDir	C	org.apache.hadoop.fs.Path	0	org.apache.hadoop.fs.cosn.CosNFileSystem:setWorkingDirectory(org.apache.hadoop.fs.Path)
org.apache.hadoop.fs.cosn.CosNInputStream$ReadBuffer	setStatus	status	J	int	0	org.apache.hadoop.fs.cosn.CosNInputStream$ReadBuffer:setStatus(int)
org.apache.hadoop.security.authentication.examples.RequestLoggerFilter$XHttpServletResponse	setStatus	status	J	int	0	org.apache.hadoop.security.authentication.examples.RequestLoggerFilter$XHttpServletResponse:setStatus(int)
org.apache.hadoop.security.authentication.client.PseudoAuthenticator	setConnectionConfigurator	connConfigurator	C	org.apache.hadoop.security.authentication.client.ConnectionConfigurator	0	org.apache.hadoop.security.authentication.client.PseudoAuthenticator:setConnectionConfigurator(org.apache.hadoop.security.authentication.client.ConnectionConfigurator)
org.apache.hadoop.security.authentication.client.KerberosAuthenticator	setConnectionConfigurator	connConfigurator	C	org.apache.hadoop.security.authentication.client.ConnectionConfigurator	0	org.apache.hadoop.security.authentication.client.KerberosAuthenticator:setConnectionConfigurator(org.apache.hadoop.security.authentication.client.ConnectionConfigurator)
org.apache.hadoop.security.authentication.server.LdapAuthenticationHandler	setEnableStartTls	enableStartTls	J	java.lang.Boolean	0	org.apache.hadoop.security.authentication.server.LdapAuthenticationHandler:setEnableStartTls(java.lang.Boolean)
org.apache.hadoop.security.authentication.server.LdapAuthenticationHandler	setDisableHostNameVerification	disableHostNameVerification	J	java.lang.Boolean	0	org.apache.hadoop.security.authentication.server.LdapAuthenticationHandler:setDisableHostNameVerification(java.lang.Boolean)
org.apache.hadoop.security.authentication.server.JWTRedirectAuthenticationHandler	setPublicKey	publicKey	J	java.security.interfaces.RSAPublicKey	0	org.apache.hadoop.security.authentication.server.JWTRedirectAuthenticationHandler:setPublicKey(java.security.interfaces.RSAPublicKey)
org.apache.hadoop.security.authentication.util.AuthToken	setMaxInactives	maxInactives	J	long	0	org.apache.hadoop.security.authentication.util.AuthToken:setMaxInactives(long)
org.apache.hadoop.security.authentication.util.AuthToken	setExpires	expires	J	long	0	org.apache.hadoop.security.authentication.util.AuthToken:setExpires(long)
org.apache.hadoop.conf.ReconfigurableBase	setReconfigurationUtil	reconfigurationUtil	C	org.apache.hadoop.conf.ReconfigurationUtil	0	org.apache.hadoop.conf.ReconfigurableBase:setReconfigurationUtil(org.apache.hadoop.conf.ReconfigurationUtil)
org.apache.hadoop.conf.Configuration	setRestrictSystemProperties	restrictSystemProps	J	boolean	0	org.apache.hadoop.conf.Configuration:setRestrictSystemProperties(boolean)
org.apache.hadoop.conf.Configuration	setAllowNullValueProperties	allowNullValueProperties	J	boolean	0	org.apache.hadoop.conf.Configuration:setAllowNullValueProperties(boolean)
org.apache.hadoop.conf.Configuration	setRestrictSystemProps	restrictSystemProps	J	boolean	0	org.apache.hadoop.conf.Configuration:setRestrictSystemProps(boolean)
org.apache.hadoop.conf.Configuration	setClassLoader	classLoader	J	java.lang.ClassLoader	0	org.apache.hadoop.conf.Configuration:setClassLoader(java.lang.ClassLoader)
org.apache.hadoop.conf.Configuration	setQuietMode	quietmode	J	boolean	0	org.apache.hadoop.conf.Configuration:setQuietMode(boolean)
org.apache.hadoop.conf.Configured	setConf	conf	C	org.apache.hadoop.conf.Configuration	0	org.apache.hadoop.conf.Configured:setConf(org.apache.hadoop.conf.Configuration)
org.apache.hadoop.tools.proto.GetUserMappingsProtocolProtos$GetGroupsForUserRequestProto$Builder	setUser	user_	J	java.lang.Object	0	org.apache.hadoop.tools.proto.GetUserMappingsProtocolProtos$GetGroupsForUserRequestProto$Builder:setUser(java.lang.String)
org.apache.hadoop.tools.proto.GetUserMappingsProtocolProtos$GetGroupsForUserRequestProto$Builder	setUserBytes	user_	J	java.lang.Object	0	org.apache.hadoop.tools.proto.GetUserMappingsProtocolProtos$GetGroupsForUserRequestProto$Builder:setUserBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.tools.CommandShell	setSubCommand	subcommand	C	org.apache.hadoop.tools.CommandShell$SubCommand	0	org.apache.hadoop.tools.CommandShell:setSubCommand(org.apache.hadoop.tools.CommandShell$SubCommand)
org.apache.hadoop.tools.CommandShell	setOut	out	J	java.io.PrintStream	0	org.apache.hadoop.tools.CommandShell:setOut(java.io.PrintStream)
org.apache.hadoop.tools.CommandShell	setErr	err	J	java.io.PrintStream	0	org.apache.hadoop.tools.CommandShell:setErr(java.io.PrintStream)
org.apache.hadoop.ipc.proto.GenericRefreshProtocolProtos$GenericRefreshRequestProto$Builder	setIdentifier	identifier_	J	java.lang.Object	0	org.apache.hadoop.ipc.proto.GenericRefreshProtocolProtos$GenericRefreshRequestProto$Builder:setIdentifier(java.lang.String)
org.apache.hadoop.ipc.proto.GenericRefreshProtocolProtos$GenericRefreshRequestProto$Builder	setIdentifierBytes	identifier_	J	java.lang.Object	0	org.apache.hadoop.ipc.proto.GenericRefreshProtocolProtos$GenericRefreshRequestProto$Builder:setIdentifierBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.ipc.proto.GenericRefreshProtocolProtos$GenericRefreshResponseProto$Builder	setExitStatus	exitStatus_	J	int	0	org.apache.hadoop.ipc.proto.GenericRefreshProtocolProtos$GenericRefreshResponseProto$Builder:setExitStatus(int)
org.apache.hadoop.ipc.proto.GenericRefreshProtocolProtos$GenericRefreshResponseProto$Builder	setUserMessage	userMessage_	J	java.lang.Object	0	org.apache.hadoop.ipc.proto.GenericRefreshProtocolProtos$GenericRefreshResponseProto$Builder:setUserMessage(java.lang.String)
org.apache.hadoop.ipc.proto.GenericRefreshProtocolProtos$GenericRefreshResponseProto$Builder	setUserMessageBytes	userMessage_	J	java.lang.Object	0	org.apache.hadoop.ipc.proto.GenericRefreshProtocolProtos$GenericRefreshResponseProto$Builder:setUserMessageBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.ipc.proto.GenericRefreshProtocolProtos$GenericRefreshResponseProto$Builder	setSenderName	senderName_	J	java.lang.Object	0	org.apache.hadoop.ipc.proto.GenericRefreshProtocolProtos$GenericRefreshResponseProto$Builder:setSenderName(java.lang.String)
org.apache.hadoop.ipc.proto.GenericRefreshProtocolProtos$GenericRefreshResponseProto$Builder	setSenderNameBytes	senderName_	J	java.lang.Object	0	org.apache.hadoop.ipc.proto.GenericRefreshProtocolProtos$GenericRefreshResponseProto$Builder:setSenderNameBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.ipc.Server$Connection	setLastContact	lastContact	J	long	0	org.apache.hadoop.ipc.Server$Connection:setLastContact(long)
org.apache.hadoop.ipc.Server$Connection	setServiceClass	serviceClass	J	int	0	org.apache.hadoop.ipc.Server$Connection:setServiceClass(int)
org.apache.hadoop.ipc.protobuf.IpcConnectionContextProtos$IpcConnectionContextProto$Builder	setProtocol	protocol_	J	java.lang.Object	0	org.apache.hadoop.ipc.protobuf.IpcConnectionContextProtos$IpcConnectionContextProto$Builder:setProtocol(java.lang.String)
org.apache.hadoop.ipc.protobuf.IpcConnectionContextProtos$IpcConnectionContextProto$Builder	setProtocolBytes	protocol_	J	java.lang.Object	0	org.apache.hadoop.ipc.protobuf.IpcConnectionContextProtos$IpcConnectionContextProto$Builder:setProtocolBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.ipc.protobuf.ProtocolInfoProtos$ProtocolSignatureProto$Builder	setVersion	version_	J	long	0	org.apache.hadoop.ipc.protobuf.ProtocolInfoProtos$ProtocolSignatureProto$Builder:setVersion(long)
org.apache.hadoop.ipc.protobuf.ProtocolInfoProtos$GetProtocolSignatureRequestProto$Builder	setProtocol	protocol_	J	java.lang.Object	0	org.apache.hadoop.ipc.protobuf.ProtocolInfoProtos$GetProtocolSignatureRequestProto$Builder:setProtocol(java.lang.String)
org.apache.hadoop.ipc.protobuf.ProtocolInfoProtos$GetProtocolSignatureRequestProto$Builder	setProtocolBytes	protocol_	J	java.lang.Object	0	org.apache.hadoop.ipc.protobuf.ProtocolInfoProtos$GetProtocolSignatureRequestProto$Builder:setProtocolBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.ipc.protobuf.ProtocolInfoProtos$GetProtocolSignatureRequestProto$Builder	setRpcKind	rpcKind_	J	java.lang.Object	0	org.apache.hadoop.ipc.protobuf.ProtocolInfoProtos$GetProtocolSignatureRequestProto$Builder:setRpcKind(java.lang.String)
org.apache.hadoop.ipc.protobuf.ProtocolInfoProtos$GetProtocolSignatureRequestProto$Builder	setRpcKindBytes	rpcKind_	J	java.lang.Object	0	org.apache.hadoop.ipc.protobuf.ProtocolInfoProtos$GetProtocolSignatureRequestProto$Builder:setRpcKindBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.ipc.protobuf.ProtobufRpcEngineProtos$RequestHeaderProto$Builder	setMethodName	methodName_	J	java.lang.Object	0	org.apache.hadoop.ipc.protobuf.ProtobufRpcEngineProtos$RequestHeaderProto$Builder:setMethodName(java.lang.String)
org.apache.hadoop.ipc.protobuf.ProtobufRpcEngineProtos$RequestHeaderProto$Builder	setMethodNameBytes	methodName_	J	java.lang.Object	0	org.apache.hadoop.ipc.protobuf.ProtobufRpcEngineProtos$RequestHeaderProto$Builder:setMethodNameBytes(com.google.protobuf.ByteString)
org.apache.hadoop.ipc.protobuf.ProtobufRpcEngineProtos$RequestHeaderProto$Builder	setDeclaringClassProtocolName	declaringClassProtocolName_	J	java.lang.Object	0	org.apache.hadoop.ipc.protobuf.ProtobufRpcEngineProtos$RequestHeaderProto$Builder:setDeclaringClassProtocolName(java.lang.String)
org.apache.hadoop.ipc.protobuf.ProtobufRpcEngineProtos$RequestHeaderProto$Builder	setDeclaringClassProtocolNameBytes	declaringClassProtocolName_	J	java.lang.Object	0	org.apache.hadoop.ipc.protobuf.ProtobufRpcEngineProtos$RequestHeaderProto$Builder:setDeclaringClassProtocolNameBytes(com.google.protobuf.ByteString)
org.apache.hadoop.ipc.protobuf.ProtobufRpcEngineProtos$RequestHeaderProto$Builder	setClientProtocolVersion	clientProtocolVersion_	J	long	0	org.apache.hadoop.ipc.protobuf.ProtobufRpcEngineProtos$RequestHeaderProto$Builder:setClientProtocolVersion(long)
org.apache.hadoop.ipc.protobuf.ProtocolInfoProtos$GetProtocolVersionsRequestProto$Builder	setProtocol	protocol_	J	java.lang.Object	0	org.apache.hadoop.ipc.protobuf.ProtocolInfoProtos$GetProtocolVersionsRequestProto$Builder:setProtocol(java.lang.String)
org.apache.hadoop.ipc.protobuf.ProtocolInfoProtos$GetProtocolVersionsRequestProto$Builder	setProtocolBytes	protocol_	J	java.lang.Object	0	org.apache.hadoop.ipc.protobuf.ProtocolInfoProtos$GetProtocolVersionsRequestProto$Builder:setProtocolBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.ipc.protobuf.ProtocolInfoProtos$ProtocolVersionProto$Builder	setRpcKind	rpcKind_	J	java.lang.Object	0	org.apache.hadoop.ipc.protobuf.ProtocolInfoProtos$ProtocolVersionProto$Builder:setRpcKind(java.lang.String)
org.apache.hadoop.ipc.protobuf.ProtocolInfoProtos$ProtocolVersionProto$Builder	setRpcKindBytes	rpcKind_	J	java.lang.Object	0	org.apache.hadoop.ipc.protobuf.ProtocolInfoProtos$ProtocolVersionProto$Builder:setRpcKindBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RpcResponseHeaderProto$Builder	setCallId	callId_	J	int	0	org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RpcResponseHeaderProto$Builder:setCallId(int)
org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RpcResponseHeaderProto$Builder	setServerIpcVersionNum	serverIpcVersionNum_	J	int	0	org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RpcResponseHeaderProto$Builder:setServerIpcVersionNum(int)
org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RpcResponseHeaderProto$Builder	setExceptionClassName	exceptionClassName_	J	java.lang.Object	0	org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RpcResponseHeaderProto$Builder:setExceptionClassName(java.lang.String)
org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RpcResponseHeaderProto$Builder	setExceptionClassNameBytes	exceptionClassName_	J	java.lang.Object	0	org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RpcResponseHeaderProto$Builder:setExceptionClassNameBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RpcResponseHeaderProto$Builder	setErrorMsg	errorMsg_	J	java.lang.Object	0	org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RpcResponseHeaderProto$Builder:setErrorMsg(java.lang.String)
org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RpcResponseHeaderProto$Builder	setErrorMsgBytes	errorMsg_	J	java.lang.Object	0	org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RpcResponseHeaderProto$Builder:setErrorMsgBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RpcResponseHeaderProto$Builder	setClientId	clientId_	C	org.apache.hadoop.thirdparty.protobuf.ByteString	0	org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RpcResponseHeaderProto$Builder:setClientId(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RpcResponseHeaderProto$Builder	setRetryCount	retryCount_	J	int	0	org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RpcResponseHeaderProto$Builder:setRetryCount(int)
org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RpcResponseHeaderProto$Builder	setStateId	stateId_	J	long	0	org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RpcResponseHeaderProto$Builder:setStateId(long)
org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RpcResponseHeaderProto$Builder	setRouterFederatedState	routerFederatedState_	C	org.apache.hadoop.thirdparty.protobuf.ByteString	0	org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RpcResponseHeaderProto$Builder:setRouterFederatedState(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.ipc.protobuf.ProtobufRpcEngine2Protos$RequestHeaderProto$Builder	setMethodName	methodName_	J	java.lang.Object	0	org.apache.hadoop.ipc.protobuf.ProtobufRpcEngine2Protos$RequestHeaderProto$Builder:setMethodName(java.lang.String)
org.apache.hadoop.ipc.protobuf.ProtobufRpcEngine2Protos$RequestHeaderProto$Builder	setMethodNameBytes	methodName_	J	java.lang.Object	0	org.apache.hadoop.ipc.protobuf.ProtobufRpcEngine2Protos$RequestHeaderProto$Builder:setMethodNameBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.ipc.protobuf.ProtobufRpcEngine2Protos$RequestHeaderProto$Builder	setDeclaringClassProtocolName	declaringClassProtocolName_	J	java.lang.Object	0	org.apache.hadoop.ipc.protobuf.ProtobufRpcEngine2Protos$RequestHeaderProto$Builder:setDeclaringClassProtocolName(java.lang.String)
org.apache.hadoop.ipc.protobuf.ProtobufRpcEngine2Protos$RequestHeaderProto$Builder	setDeclaringClassProtocolNameBytes	declaringClassProtocolName_	J	java.lang.Object	0	org.apache.hadoop.ipc.protobuf.ProtobufRpcEngine2Protos$RequestHeaderProto$Builder:setDeclaringClassProtocolNameBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.ipc.protobuf.ProtobufRpcEngine2Protos$RequestHeaderProto$Builder	setClientProtocolVersion	clientProtocolVersion_	J	long	0	org.apache.hadoop.ipc.protobuf.ProtobufRpcEngine2Protos$RequestHeaderProto$Builder:setClientProtocolVersion(long)
org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RPCTraceInfoProto$Builder	setTraceId	traceId_	J	long	0	org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RPCTraceInfoProto$Builder:setTraceId(long)
org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RPCTraceInfoProto$Builder	setParentId	parentId_	J	long	0	org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RPCTraceInfoProto$Builder:setParentId(long)
org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RPCTraceInfoProto$Builder	setSpanContext	spanContext_	C	org.apache.hadoop.thirdparty.protobuf.ByteString	0	org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RPCTraceInfoProto$Builder:setSpanContext(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RpcRequestHeaderProto$Builder	setCallId	callId_	J	int	0	org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RpcRequestHeaderProto$Builder:setCallId(int)
org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RpcRequestHeaderProto$Builder	setClientId	clientId_	C	org.apache.hadoop.thirdparty.protobuf.ByteString	0	org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RpcRequestHeaderProto$Builder:setClientId(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RpcRequestHeaderProto$Builder	setRetryCount	retryCount_	J	int	0	org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RpcRequestHeaderProto$Builder:setRetryCount(int)
org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RpcRequestHeaderProto$Builder	setStateId	stateId_	J	long	0	org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RpcRequestHeaderProto$Builder:setStateId(long)
org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RpcRequestHeaderProto$Builder	setRouterFederatedState	routerFederatedState_	C	org.apache.hadoop.thirdparty.protobuf.ByteString	0	org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RpcRequestHeaderProto$Builder:setRouterFederatedState(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RpcSaslProto$SaslAuth$Builder	setMethod	method_	J	java.lang.Object	0	org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RpcSaslProto$SaslAuth$Builder:setMethod(java.lang.String)
org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RpcSaslProto$SaslAuth$Builder	setMethodBytes	method_	J	java.lang.Object	0	org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RpcSaslProto$SaslAuth$Builder:setMethodBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RpcSaslProto$SaslAuth$Builder	setMechanism	mechanism_	J	java.lang.Object	0	org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RpcSaslProto$SaslAuth$Builder:setMechanism(java.lang.String)
org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RpcSaslProto$SaslAuth$Builder	setMechanismBytes	mechanism_	J	java.lang.Object	0	org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RpcSaslProto$SaslAuth$Builder:setMechanismBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RpcSaslProto$SaslAuth$Builder	setProtocol	protocol_	J	java.lang.Object	0	org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RpcSaslProto$SaslAuth$Builder:setProtocol(java.lang.String)
org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RpcSaslProto$SaslAuth$Builder	setProtocolBytes	protocol_	J	java.lang.Object	0	org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RpcSaslProto$SaslAuth$Builder:setProtocolBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RpcSaslProto$SaslAuth$Builder	setServerId	serverId_	J	java.lang.Object	0	org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RpcSaslProto$SaslAuth$Builder:setServerId(java.lang.String)
org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RpcSaslProto$SaslAuth$Builder	setServerIdBytes	serverId_	J	java.lang.Object	0	org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RpcSaslProto$SaslAuth$Builder:setServerIdBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RpcSaslProto$SaslAuth$Builder	setChallenge	challenge_	C	org.apache.hadoop.thirdparty.protobuf.ByteString	0	org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RpcSaslProto$SaslAuth$Builder:setChallenge(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RpcSaslProto$Builder	setVersion	version_	J	int	0	org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RpcSaslProto$Builder:setVersion(int)
org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RpcSaslProto$Builder	setToken	token_	C	org.apache.hadoop.thirdparty.protobuf.ByteString	0	org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RpcSaslProto$Builder:setToken(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.ipc.protobuf.IpcConnectionContextProtos$UserInformationProto$Builder	setEffectiveUser	effectiveUser_	J	java.lang.Object	0	org.apache.hadoop.ipc.protobuf.IpcConnectionContextProtos$UserInformationProto$Builder:setEffectiveUser(java.lang.String)
org.apache.hadoop.ipc.protobuf.IpcConnectionContextProtos$UserInformationProto$Builder	setEffectiveUserBytes	effectiveUser_	J	java.lang.Object	0	org.apache.hadoop.ipc.protobuf.IpcConnectionContextProtos$UserInformationProto$Builder:setEffectiveUserBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.ipc.protobuf.IpcConnectionContextProtos$UserInformationProto$Builder	setRealUser	realUser_	J	java.lang.Object	0	org.apache.hadoop.ipc.protobuf.IpcConnectionContextProtos$UserInformationProto$Builder:setRealUser(java.lang.String)
org.apache.hadoop.ipc.protobuf.IpcConnectionContextProtos$UserInformationProto$Builder	setRealUserBytes	realUser_	J	java.lang.Object	0	org.apache.hadoop.ipc.protobuf.IpcConnectionContextProtos$UserInformationProto$Builder:setRealUserBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RPCCallerContextProto$Builder	setContext	context_	J	java.lang.Object	0	org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RPCCallerContextProto$Builder:setContext(java.lang.String)
org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RPCCallerContextProto$Builder	setContextBytes	context_	J	java.lang.Object	0	org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RPCCallerContextProto$Builder:setContextBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RPCCallerContextProto$Builder	setSignature	signature_	C	org.apache.hadoop.thirdparty.protobuf.ByteString	0	org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RPCCallerContextProto$Builder:setSignature(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.ipc.FairCallQueue	setMultiplexer	multiplexer	C	org.apache.hadoop.ipc.RpcMultiplexer	0	org.apache.hadoop.ipc.FairCallQueue:setMultiplexer(org.apache.hadoop.ipc.RpcMultiplexer)
org.apache.hadoop.ipc.RetryCache$CacheEntry	setNext	next	C	org.apache.hadoop.util.LightWeightGSet$LinkedElement	0	org.apache.hadoop.ipc.RetryCache$CacheEntry:setNext(org.apache.hadoop.util.LightWeightGSet$LinkedElement)
org.apache.hadoop.ipc.CallerContext$Builder	setSignature	signature	J	byte	1	org.apache.hadoop.ipc.CallerContext$Builder:setSignature(byte[])
org.apache.hadoop.ipc.WritableRpcEngine$Invocation	setConf	conf	C	org.apache.hadoop.conf.Configuration	0	org.apache.hadoop.ipc.WritableRpcEngine$Invocation:setConf(org.apache.hadoop.conf.Configuration)
org.apache.hadoop.ipc.Client$IpcStreams	setInputStream	in	J	java.io.DataInputStream	0	org.apache.hadoop.ipc.Client$IpcStreams:setInputStream(java.io.InputStream)
org.apache.hadoop.ipc.Client$IpcStreams	setOutputStream	out	J	java.io.DataOutputStream	0	org.apache.hadoop.ipc.Client$IpcStreams:setOutputStream(java.io.OutputStream)
org.apache.hadoop.ipc.Server	setAlignmentContext	alignmentContext	C	org.apache.hadoop.ipc.AlignmentContext	0	org.apache.hadoop.ipc.Server:setAlignmentContext(org.apache.hadoop.ipc.AlignmentContext)
org.apache.hadoop.ipc.Server	setLogSlowRPC	logSlowRPC	J	boolean	0	org.apache.hadoop.ipc.Server:setLogSlowRPC(boolean)
org.apache.hadoop.ipc.Server	setSocketSendBufSize	socketSendBufferSize	J	int	0	org.apache.hadoop.ipc.Server:setSocketSendBufSize(int)
org.apache.hadoop.ipc.Server	setTracer	tracer	C	org.apache.hadoop.tracing.Tracer	0	org.apache.hadoop.ipc.Server:setTracer(org.apache.hadoop.tracing.Tracer)
org.apache.hadoop.ipc.RefreshResponse	setSenderName	senderName	J	java.lang.String	0	org.apache.hadoop.ipc.RefreshResponse:setSenderName(java.lang.String)
org.apache.hadoop.ipc.RefreshResponse	setReturnCode	returnCode	J	int	0	org.apache.hadoop.ipc.RefreshResponse:setReturnCode(int)
org.apache.hadoop.ipc.RefreshResponse	setMessage	message	J	java.lang.String	0	org.apache.hadoop.ipc.RefreshResponse:setMessage(java.lang.String)
org.apache.hadoop.ipc.RPC$Builder	setProtocol	protocol	GC	java.lang.Class	0	org.apache.hadoop.ipc.RPC$Builder:setProtocol(java.lang.Class)
org.apache.hadoop.ipc.RPC$Builder	setInstance	instance	J	java.lang.Object	0	org.apache.hadoop.ipc.RPC$Builder:setInstance(java.lang.Object)
org.apache.hadoop.ipc.RPC$Builder	setBindAddress	bindAddress	J	java.lang.String	0	org.apache.hadoop.ipc.RPC$Builder:setBindAddress(java.lang.String)
org.apache.hadoop.ipc.RPC$Builder	setPort	port	J	int	0	org.apache.hadoop.ipc.RPC$Builder:setPort(int)
org.apache.hadoop.ipc.RPC$Builder	setNumHandlers	numHandlers	J	int	0	org.apache.hadoop.ipc.RPC$Builder:setNumHandlers(int)
org.apache.hadoop.ipc.RPC$Builder	setnumReaders	numReaders	J	int	0	org.apache.hadoop.ipc.RPC$Builder:setnumReaders(int)
org.apache.hadoop.ipc.RPC$Builder	setNumReaders	numReaders	J	int	0	org.apache.hadoop.ipc.RPC$Builder:setNumReaders(int)
org.apache.hadoop.ipc.RPC$Builder	setQueueSizePerHandler	queueSizePerHandler	J	int	0	org.apache.hadoop.ipc.RPC$Builder:setQueueSizePerHandler(int)
org.apache.hadoop.ipc.RPC$Builder	setVerbose	verbose	J	boolean	0	org.apache.hadoop.ipc.RPC$Builder:setVerbose(boolean)
org.apache.hadoop.ipc.RPC$Builder	setSecretManager	secretManager	GC	org.apache.hadoop.security.token.SecretManager	0	org.apache.hadoop.ipc.RPC$Builder:setSecretManager(org.apache.hadoop.security.token.SecretManager)
org.apache.hadoop.ipc.RPC$Builder	setPortRangeConfig	portRangeConfig	J	java.lang.String	0	org.apache.hadoop.ipc.RPC$Builder:setPortRangeConfig(java.lang.String)
org.apache.hadoop.ipc.RPC$Builder	setAlignmentContext	alignmentContext	C	org.apache.hadoop.ipc.AlignmentContext	0	org.apache.hadoop.ipc.RPC$Builder:setAlignmentContext(org.apache.hadoop.ipc.AlignmentContext)
org.apache.hadoop.ipc.CallQueueManager	setClientBackoffEnabled	clientBackOffEnabled	J	boolean	0	org.apache.hadoop.ipc.CallQueueManager:setClientBackoffEnabled(boolean)
org.apache.hadoop.ipc.Client$Call	setAlignmentContext	alignmentContext	C	org.apache.hadoop.ipc.AlignmentContext	0	org.apache.hadoop.ipc.Client$Call:setAlignmentContext(org.apache.hadoop.ipc.AlignmentContext)
org.apache.hadoop.ipc.Client$Call	setException	error	J	java.io.IOException	0	org.apache.hadoop.ipc.Client$Call:setException(java.io.IOException)
org.apache.hadoop.ipc.Client$Call	setRpcResponse	rpcResponse	C	org.apache.hadoop.io.Writable	0	org.apache.hadoop.ipc.Client$Call:setRpcResponse(org.apache.hadoop.io.Writable)
org.apache.hadoop.ipc.Server$Call	setDetailedMetricsName	detailedMetricsName	J	java.lang.String	0	org.apache.hadoop.ipc.Server$Call:setDetailedMetricsName(java.lang.String)
org.apache.hadoop.ipc.Server$Call	setPriorityLevel	priorityLevel	J	int	0	org.apache.hadoop.ipc.Server$Call:setPriorityLevel(int)
org.apache.hadoop.ipc.Server$Call	setClientStateId	clientStateId	J	long	0	org.apache.hadoop.ipc.Server$Call:setClientStateId(long)
org.apache.hadoop.ipc.Server$RpcCall	setResponse	rpcResponse	J	java.nio.ByteBuffer	0	org.apache.hadoop.ipc.Server$RpcCall:setResponse(java.nio.ByteBuffer)
org.apache.hadoop.http.HttpServer2$Builder	setName	name	J	java.lang.String	0	org.apache.hadoop.http.HttpServer2$Builder:setName(java.lang.String)
org.apache.hadoop.http.HttpServer2$Builder	setFindPort	findPort	J	boolean	0	org.apache.hadoop.http.HttpServer2$Builder:setFindPort(boolean)
org.apache.hadoop.http.HttpServer2$Builder	setPortRanges	portRanges	C	org.apache.hadoop.conf.Configuration$IntegerRanges	0	org.apache.hadoop.http.HttpServer2$Builder:setPortRanges(org.apache.hadoop.conf.Configuration$IntegerRanges)
org.apache.hadoop.http.HttpServer2$Builder	setConf	conf	C	org.apache.hadoop.conf.Configuration	0	org.apache.hadoop.http.HttpServer2$Builder:setConf(org.apache.hadoop.conf.Configuration)
org.apache.hadoop.http.HttpServer2$Builder	setSSLConf	sslConf	C	org.apache.hadoop.conf.Configuration	0	org.apache.hadoop.http.HttpServer2$Builder:setSSLConf(org.apache.hadoop.conf.Configuration)
org.apache.hadoop.http.HttpServer2$Builder	setPathSpec	pathSpecs	J	java.lang.String	1	org.apache.hadoop.http.HttpServer2$Builder:setPathSpec(java.lang.String[])
org.apache.hadoop.http.HttpServer2$Builder	setACL	adminsAcl	C	org.apache.hadoop.security.authorize.AccessControlList	0	org.apache.hadoop.http.HttpServer2$Builder:setACL(org.apache.hadoop.security.authorize.AccessControlList)
org.apache.hadoop.http.HttpServer2$Builder	setSecurityEnabled	securityEnabled	J	boolean	0	org.apache.hadoop.http.HttpServer2$Builder:setSecurityEnabled(boolean)
org.apache.hadoop.http.HttpServer2$Builder	setUsernameConfKey	usernameConfKey	J	java.lang.String	0	org.apache.hadoop.http.HttpServer2$Builder:setUsernameConfKey(java.lang.String)
org.apache.hadoop.http.HttpServer2$Builder	setKeytabConfKey	keytabConfKey	J	java.lang.String	0	org.apache.hadoop.http.HttpServer2$Builder:setKeytabConfKey(java.lang.String)
org.apache.hadoop.http.HttpServer2$Builder	setSniHostCheckEnabled	sniHostCheckEnabled	J	boolean	0	org.apache.hadoop.http.HttpServer2$Builder:setSniHostCheckEnabled(boolean)
org.apache.hadoop.http.HttpRequestLogAppender	setRetainDays	retainDays	J	int	0	org.apache.hadoop.http.HttpRequestLogAppender:setRetainDays(int)
org.apache.hadoop.http.HttpRequestLogAppender	setFilename	filename	J	java.lang.String	0	org.apache.hadoop.http.HttpRequestLogAppender:setFilename(java.lang.String)
org.apache.hadoop.metrics2.source.JvmMetrics	setPauseMonitor	pauseMonitor	C	org.apache.hadoop.util.JvmPauseMonitor	0	org.apache.hadoop.metrics2.source.JvmMetrics:setPauseMonitor(org.apache.hadoop.util.JvmPauseMonitor)
org.apache.hadoop.metrics2.source.JvmMetrics	setGcTimeMonitor	gcTimeMonitor	C	org.apache.hadoop.util.GcTimeMonitor	0	org.apache.hadoop.metrics2.source.JvmMetrics:setGcTimeMonitor(org.apache.hadoop.util.GcTimeMonitor)
org.apache.hadoop.metrics2.filter.AbstractPatternFilter	setIncludePattern	includePattern	C	com.google.re2j.Pattern	0	org.apache.hadoop.metrics2.filter.AbstractPatternFilter:setIncludePattern(com.google.re2j.Pattern)
org.apache.hadoop.metrics2.filter.AbstractPatternFilter	setExcludePattern	excludePattern	C	com.google.re2j.Pattern	0	org.apache.hadoop.metrics2.filter.AbstractPatternFilter:setExcludePattern(com.google.re2j.Pattern)
org.apache.hadoop.metrics2.lib.MutableQuantiles	setEstimator	estimator	C	org.apache.hadoop.metrics2.util.QuantileEstimator	0	org.apache.hadoop.metrics2.lib.MutableQuantiles:setEstimator(org.apache.hadoop.metrics2.util.QuantileEstimator)
org.apache.hadoop.metrics2.lib.MutableRollingAverages	setRecordValidityMs	recordValidityMs	J	long	0	org.apache.hadoop.metrics2.lib.MutableRollingAverages:setRecordValidityMs(long)
org.apache.hadoop.metrics2.lib.MutableStat	setExtended	extended	J	boolean	0	org.apache.hadoop.metrics2.lib.MutableStat:setExtended(boolean)
org.apache.hadoop.metrics2.lib.MutableStat	setUpdateTimeStamp	updateTimeStamp	J	boolean	0	org.apache.hadoop.metrics2.lib.MutableStat:setUpdateTimeStamp(boolean)
org.apache.hadoop.metrics2.impl.MetricsCollectorImpl	setRecordFilter	recordFilter	C	org.apache.hadoop.metrics2.MetricsFilter	0	org.apache.hadoop.metrics2.impl.MetricsCollectorImpl:setRecordFilter(org.apache.hadoop.metrics2.MetricsFilter)
org.apache.hadoop.metrics2.impl.MetricsCollectorImpl	setMetricFilter	metricFilter	C	org.apache.hadoop.metrics2.MetricsFilter	0	org.apache.hadoop.metrics2.impl.MetricsCollectorImpl:setMetricFilter(org.apache.hadoop.metrics2.MetricsFilter)
org.apache.hadoop.metrics2.sink.ganglia.AbstractGangliaSink	setDatagramSocket	datagramSocket	J	java.net.DatagramSocket	0	org.apache.hadoop.metrics2.sink.ganglia.AbstractGangliaSink:setDatagramSocket(java.net.DatagramSocket)
org.apache.hadoop.metrics2.sink.ganglia.GangliaConf	setUnits	units	J	java.lang.String	0	org.apache.hadoop.metrics2.sink.ganglia.GangliaConf:setUnits(java.lang.String)
org.apache.hadoop.metrics2.sink.ganglia.GangliaConf	setSlope	slope	C	org.apache.hadoop.metrics2.sink.ganglia.AbstractGangliaSink$GangliaSlope	0	org.apache.hadoop.metrics2.sink.ganglia.GangliaConf:setSlope(org.apache.hadoop.metrics2.sink.ganglia.AbstractGangliaSink$GangliaSlope)
org.apache.hadoop.metrics2.sink.ganglia.GangliaConf	setDmax	dmax	J	int	0	org.apache.hadoop.metrics2.sink.ganglia.GangliaConf:setDmax(int)
org.apache.hadoop.metrics2.sink.ganglia.GangliaConf	setTmax	tmax	J	int	0	org.apache.hadoop.metrics2.sink.ganglia.GangliaConf:setTmax(int)
org.apache.hadoop.net.AbstractDNSToSwitchMapping	setConf	conf	C	org.apache.hadoop.conf.Configuration	0	org.apache.hadoop.net.AbstractDNSToSwitchMapping:setConf(org.apache.hadoop.conf.Configuration)
org.apache.hadoop.net.SocksSocketFactory	setConf	conf	C	org.apache.hadoop.conf.Configuration	0	org.apache.hadoop.net.SocksSocketFactory:setConf(org.apache.hadoop.conf.Configuration)
org.apache.hadoop.net.NodeBase	setNetworkLocation	location	J	java.lang.String	0	org.apache.hadoop.net.NodeBase:setNetworkLocation(java.lang.String)
org.apache.hadoop.net.NodeBase	setParent	parent	C	org.apache.hadoop.net.Node	0	org.apache.hadoop.net.NodeBase:setParent(org.apache.hadoop.net.Node)
org.apache.hadoop.net.NodeBase	setLevel	level	J	int	0	org.apache.hadoop.net.NodeBase:setLevel(int)
org.apache.hadoop.net.SocketIOWithTimeout	setTimeout	timeout	J	long	0	org.apache.hadoop.net.SocketIOWithTimeout:setTimeout(long)
org.apache.hadoop.fs.FSProtos$LocalFileSystemPathHandleProto$Builder	setMtime	mtime_	J	long	0	org.apache.hadoop.fs.FSProtos$LocalFileSystemPathHandleProto$Builder:setMtime(long)
org.apache.hadoop.fs.FSProtos$LocalFileSystemPathHandleProto$Builder	setPath	path_	J	java.lang.Object	0	org.apache.hadoop.fs.FSProtos$LocalFileSystemPathHandleProto$Builder:setPath(java.lang.String)
org.apache.hadoop.fs.FSProtos$LocalFileSystemPathHandleProto$Builder	setPathBytes	path_	J	java.lang.Object	0	org.apache.hadoop.fs.FSProtos$LocalFileSystemPathHandleProto$Builder:setPathBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.fs.QuotaUsage	setQuota	quota	J	long	0	org.apache.hadoop.fs.QuotaUsage:setQuota(long)
org.apache.hadoop.fs.QuotaUsage	setSpaceConsumed	spaceConsumed	J	long	0	org.apache.hadoop.fs.QuotaUsage:setSpaceConsumed(long)
org.apache.hadoop.fs.QuotaUsage	setSpaceQuota	spaceQuota	J	long	0	org.apache.hadoop.fs.QuotaUsage:setSpaceQuota(long)
org.apache.hadoop.fs.shell.PathData	setStat	stat	C	org.apache.hadoop.fs.FileStatus	0	org.apache.hadoop.fs.shell.PathData:setStat(org.apache.hadoop.fs.FileStatus)
org.apache.hadoop.fs.shell.FsUsage	setUsagesTable	usagesTable	C	org.apache.hadoop.fs.shell.FsUsage$TableBuilder	0	org.apache.hadoop.fs.shell.FsUsage:setUsagesTable(org.apache.hadoop.fs.shell.FsUsage$TableBuilder)
org.apache.hadoop.fs.shell.FsUsage	setHumanReadable	humanReadable	J	boolean	0	org.apache.hadoop.fs.shell.FsUsage:setHumanReadable(boolean)
org.apache.hadoop.fs.shell.Command	setRecursive	recursive	J	boolean	0	org.apache.hadoop.fs.shell.Command:setRecursive(boolean)
org.apache.hadoop.fs.shell.Command	setCommandFactory	commandFactory	C	org.apache.hadoop.fs.shell.CommandFactory	0	org.apache.hadoop.fs.shell.Command:setCommandFactory(org.apache.hadoop.fs.shell.CommandFactory)
org.apache.hadoop.fs.shell.Command	setName	name	J	java.lang.String	0	org.apache.hadoop.fs.shell.Command:setName(java.lang.String)
org.apache.hadoop.fs.shell.CommandWithDestination	setOverwrite	overwrite	J	boolean	0	org.apache.hadoop.fs.shell.CommandWithDestination:setOverwrite(boolean)
org.apache.hadoop.fs.shell.CommandWithDestination	setLazyPersist	lazyPersist	J	boolean	0	org.apache.hadoop.fs.shell.CommandWithDestination:setLazyPersist(boolean)
org.apache.hadoop.fs.shell.CommandWithDestination	setVerifyChecksum	verifyChecksum	J	boolean	0	org.apache.hadoop.fs.shell.CommandWithDestination:setVerifyChecksum(boolean)
org.apache.hadoop.fs.shell.CommandWithDestination	setWriteChecksum	writeChecksum	J	boolean	0	org.apache.hadoop.fs.shell.CommandWithDestination:setWriteChecksum(boolean)
org.apache.hadoop.fs.shell.CommandWithDestination	setDirectWrite	direct	J	boolean	0	org.apache.hadoop.fs.shell.CommandWithDestination:setDirectWrite(boolean)
org.apache.hadoop.fs.shell.CopyCommands$AppendToFile	setAppendToNewBlock	appendToNewBlock	J	boolean	0	org.apache.hadoop.fs.shell.CopyCommands$AppendToFile:setAppendToNewBlock(boolean)
org.apache.hadoop.fs.shell.find.Name	setCaseSensitive	caseSensitive	J	boolean	0	org.apache.hadoop.fs.shell.find.Name:setCaseSensitive(boolean)
org.apache.hadoop.fs.shell.find.BaseExpression	setUsage	usage	J	java.lang.String	1	org.apache.hadoop.fs.shell.find.BaseExpression:setUsage(java.lang.String[])
org.apache.hadoop.fs.shell.find.BaseExpression	setHelp	help	J	java.lang.String	1	org.apache.hadoop.fs.shell.find.BaseExpression:setHelp(java.lang.String[])
org.apache.hadoop.fs.shell.find.BaseExpression	setOptions	options	C	org.apache.hadoop.fs.shell.find.FindOptions	0	org.apache.hadoop.fs.shell.find.BaseExpression:setOptions(org.apache.hadoop.fs.shell.find.FindOptions)
org.apache.hadoop.fs.shell.find.BaseExpression	setConf	conf	C	org.apache.hadoop.conf.Configuration	0	org.apache.hadoop.fs.shell.find.BaseExpression:setConf(org.apache.hadoop.conf.Configuration)
org.apache.hadoop.fs.shell.find.Find	setRootExpression	rootExpression	C	org.apache.hadoop.fs.shell.find.Expression	0	org.apache.hadoop.fs.shell.find.Find:setRootExpression(org.apache.hadoop.fs.shell.find.Expression)
org.apache.hadoop.fs.shell.find.FindOptions	setOut	out	J	java.io.PrintStream	0	org.apache.hadoop.fs.shell.find.FindOptions:setOut(java.io.PrintStream)
org.apache.hadoop.fs.shell.find.FindOptions	setErr	err	J	java.io.PrintStream	0	org.apache.hadoop.fs.shell.find.FindOptions:setErr(java.io.PrintStream)
org.apache.hadoop.fs.shell.find.FindOptions	setIn	in	J	java.io.InputStream	0	org.apache.hadoop.fs.shell.find.FindOptions:setIn(java.io.InputStream)
org.apache.hadoop.fs.shell.find.FindOptions	setDepthFirst	depthFirst	J	boolean	0	org.apache.hadoop.fs.shell.find.FindOptions:setDepthFirst(boolean)
org.apache.hadoop.fs.shell.find.FindOptions	setFollowLink	followLink	J	boolean	0	org.apache.hadoop.fs.shell.find.FindOptions:setFollowLink(boolean)
org.apache.hadoop.fs.shell.find.FindOptions	setFollowArgLink	followArgLink	J	boolean	0	org.apache.hadoop.fs.shell.find.FindOptions:setFollowArgLink(boolean)
org.apache.hadoop.fs.shell.find.FindOptions	setStartTime	startTime	J	long	0	org.apache.hadoop.fs.shell.find.FindOptions:setStartTime(long)
org.apache.hadoop.fs.shell.find.FindOptions	setMinDepth	minDepth	J	int	0	org.apache.hadoop.fs.shell.find.FindOptions:setMinDepth(int)
org.apache.hadoop.fs.shell.find.FindOptions	setMaxDepth	maxDepth	J	int	0	org.apache.hadoop.fs.shell.find.FindOptions:setMaxDepth(int)
org.apache.hadoop.fs.shell.find.FindOptions	setCommandFactory	commandFactory	C	org.apache.hadoop.fs.shell.CommandFactory	0	org.apache.hadoop.fs.shell.find.FindOptions:setCommandFactory(org.apache.hadoop.fs.shell.CommandFactory)
org.apache.hadoop.fs.shell.find.FindOptions	setConfiguration	configuration	C	org.apache.hadoop.conf.Configuration	0	org.apache.hadoop.fs.shell.find.FindOptions:setConfiguration(org.apache.hadoop.conf.Configuration)
org.apache.hadoop.fs.CachingGetSpaceUsed	setShouldFirstRefresh	shouldFirstRefresh	J	boolean	0	org.apache.hadoop.fs.CachingGetSpaceUsed:setShouldFirstRefresh(boolean)
org.apache.hadoop.fs.sftp.SFTPConnectionPool$ConnectionInfo	setHost	host	J	java.lang.String	0	org.apache.hadoop.fs.sftp.SFTPConnectionPool$ConnectionInfo:setHost(java.lang.String)
org.apache.hadoop.fs.sftp.SFTPConnectionPool$ConnectionInfo	setPort	port	J	int	0	org.apache.hadoop.fs.sftp.SFTPConnectionPool$ConnectionInfo:setPort(int)
org.apache.hadoop.fs.sftp.SFTPConnectionPool$ConnectionInfo	setUser	user	J	java.lang.String	0	org.apache.hadoop.fs.sftp.SFTPConnectionPool$ConnectionInfo:setUser(java.lang.String)
org.apache.hadoop.fs.sftp.SFTPConnectionPool	setMaxConnection	maxConnection	J	int	0	org.apache.hadoop.fs.sftp.SFTPConnectionPool:setMaxConnection(int)
org.apache.hadoop.fs.FSProtos$FsPermissionProto$Builder	setPerm	perm_	J	int	0	org.apache.hadoop.fs.FSProtos$FsPermissionProto$Builder:setPerm(int)
org.apache.hadoop.fs.PathIOException	setOperation	operation	J	java.lang.String	0	org.apache.hadoop.fs.PathIOException:setOperation(java.lang.String)
org.apache.hadoop.fs.PathIOException	setTargetPath	targetPath	J	java.lang.String	0	org.apache.hadoop.fs.PathIOException:setTargetPath(java.lang.String)
org.apache.hadoop.fs.permission.AclStatus$Builder	setPermission	permission	C	org.apache.hadoop.fs.permission.FsPermission	0	org.apache.hadoop.fs.permission.AclStatus$Builder:setPermission(org.apache.hadoop.fs.permission.FsPermission)
org.apache.hadoop.fs.permission.AclEntry$Builder	setType	type	C	org.apache.hadoop.fs.permission.AclEntryType	0	org.apache.hadoop.fs.permission.AclEntry$Builder:setType(org.apache.hadoop.fs.permission.AclEntryType)
org.apache.hadoop.fs.permission.AclEntry$Builder	setName	name	J	java.lang.String	0	org.apache.hadoop.fs.permission.AclEntry$Builder:setName(java.lang.String)
org.apache.hadoop.fs.permission.AclEntry$Builder	setPermission	permission	C	org.apache.hadoop.fs.permission.FsAction	0	org.apache.hadoop.fs.permission.AclEntry$Builder:setPermission(org.apache.hadoop.fs.permission.FsAction)
org.apache.hadoop.fs.permission.AclEntry$Builder	setScope	scope	C	org.apache.hadoop.fs.permission.AclEntryScope	0	org.apache.hadoop.fs.permission.AclEntry$Builder:setScope(org.apache.hadoop.fs.permission.AclEntryScope)
org.apache.hadoop.fs.FSProtos$FileStatusProto$Builder	setPath	path_	J	java.lang.Object	0	org.apache.hadoop.fs.FSProtos$FileStatusProto$Builder:setPath(java.lang.String)
org.apache.hadoop.fs.FSProtos$FileStatusProto$Builder	setPathBytes	path_	J	java.lang.Object	0	org.apache.hadoop.fs.FSProtos$FileStatusProto$Builder:setPathBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.fs.FSProtos$FileStatusProto$Builder	setLength	length_	J	long	0	org.apache.hadoop.fs.FSProtos$FileStatusProto$Builder:setLength(long)
org.apache.hadoop.fs.FSProtos$FileStatusProto$Builder	setOwner	owner_	J	java.lang.Object	0	org.apache.hadoop.fs.FSProtos$FileStatusProto$Builder:setOwner(java.lang.String)
org.apache.hadoop.fs.FSProtos$FileStatusProto$Builder	setOwnerBytes	owner_	J	java.lang.Object	0	org.apache.hadoop.fs.FSProtos$FileStatusProto$Builder:setOwnerBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.fs.FSProtos$FileStatusProto$Builder	setGroup	group_	J	java.lang.Object	0	org.apache.hadoop.fs.FSProtos$FileStatusProto$Builder:setGroup(java.lang.String)
org.apache.hadoop.fs.FSProtos$FileStatusProto$Builder	setGroupBytes	group_	J	java.lang.Object	0	org.apache.hadoop.fs.FSProtos$FileStatusProto$Builder:setGroupBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.fs.FSProtos$FileStatusProto$Builder	setModificationTime	modificationTime_	J	long	0	org.apache.hadoop.fs.FSProtos$FileStatusProto$Builder:setModificationTime(long)
org.apache.hadoop.fs.FSProtos$FileStatusProto$Builder	setAccessTime	accessTime_	J	long	0	org.apache.hadoop.fs.FSProtos$FileStatusProto$Builder:setAccessTime(long)
org.apache.hadoop.fs.FSProtos$FileStatusProto$Builder	setSymlink	symlink_	J	java.lang.Object	0	org.apache.hadoop.fs.FSProtos$FileStatusProto$Builder:setSymlink(java.lang.String)
org.apache.hadoop.fs.FSProtos$FileStatusProto$Builder	setSymlinkBytes	symlink_	J	java.lang.Object	0	org.apache.hadoop.fs.FSProtos$FileStatusProto$Builder:setSymlinkBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.fs.FSProtos$FileStatusProto$Builder	setBlockReplication	blockReplication_	J	int	0	org.apache.hadoop.fs.FSProtos$FileStatusProto$Builder:setBlockReplication(int)
org.apache.hadoop.fs.FSProtos$FileStatusProto$Builder	setBlockSize	blockSize_	J	long	0	org.apache.hadoop.fs.FSProtos$FileStatusProto$Builder:setBlockSize(long)
org.apache.hadoop.fs.FSProtos$FileStatusProto$Builder	setEncryptionData	encryptionData_	C	org.apache.hadoop.thirdparty.protobuf.ByteString	0	org.apache.hadoop.fs.FSProtos$FileStatusProto$Builder:setEncryptionData(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.fs.FSProtos$FileStatusProto$Builder	setEcData	ecData_	C	org.apache.hadoop.thirdparty.protobuf.ByteString	0	org.apache.hadoop.fs.FSProtos$FileStatusProto$Builder:setEcData(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.fs.FSProtos$FileStatusProto$Builder	setFlags	flags_	J	int	0	org.apache.hadoop.fs.FSProtos$FileStatusProto$Builder:setFlags(int)
org.apache.hadoop.fs.ChecksumFs	setVerifyChecksum	verifyChecksum	J	boolean	0	org.apache.hadoop.fs.ChecksumFs:setVerifyChecksum(boolean)
org.apache.hadoop.fs.FileStatus	setPath	path	C	org.apache.hadoop.fs.Path	0	org.apache.hadoop.fs.FileStatus:setPath(org.apache.hadoop.fs.Path)
org.apache.hadoop.fs.FileStatus	setPermission	permission	C	org.apache.hadoop.fs.permission.FsPermission	0	org.apache.hadoop.fs.FileStatus:setPermission(org.apache.hadoop.fs.permission.FsPermission)
org.apache.hadoop.fs.FileStatus	setOwner	owner	J	java.lang.String	0	org.apache.hadoop.fs.FileStatus:setOwner(java.lang.String)
org.apache.hadoop.fs.FileStatus	setGroup	group	J	java.lang.String	0	org.apache.hadoop.fs.FileStatus:setGroup(java.lang.String)
org.apache.hadoop.fs.FileStatus	setSymlink	symlink	C	org.apache.hadoop.fs.Path	0	org.apache.hadoop.fs.FileStatus:setSymlink(org.apache.hadoop.fs.Path)
org.apache.hadoop.fs.ChecksumFileSystem	setVerifyChecksum	verifyChecksum	J	boolean	0	org.apache.hadoop.fs.ChecksumFileSystem:setVerifyChecksum(boolean)
org.apache.hadoop.fs.ChecksumFileSystem	setWriteChecksum	writeChecksum	J	boolean	0	org.apache.hadoop.fs.ChecksumFileSystem:setWriteChecksum(boolean)
org.apache.hadoop.fs.viewfs.ViewFileSystemOverloadScheme	setSupportAutoAddingFallbackOnNoMounts	supportAutoAddingFallbackOnNoMounts	J	boolean	0	org.apache.hadoop.fs.viewfs.ViewFileSystemOverloadScheme:setSupportAutoAddingFallbackOnNoMounts(boolean)
org.apache.hadoop.fs.viewfs.ChRootedFileSystem	setWorkingDirectory	workingDir	C	org.apache.hadoop.fs.Path	0	org.apache.hadoop.fs.viewfs.ChRootedFileSystem:setWorkingDirectory(org.apache.hadoop.fs.Path)
org.apache.hadoop.fs.viewfs.ViewFileSystem	setWorkingDirectory	workingDir	C	org.apache.hadoop.fs.Path	0	org.apache.hadoop.fs.viewfs.ViewFileSystem:setWorkingDirectory(org.apache.hadoop.fs.Path)
org.apache.hadoop.fs.viewfs.ViewFsFileStatus	setPath	modifiedPath	C	org.apache.hadoop.fs.Path	0	org.apache.hadoop.fs.viewfs.ViewFsFileStatus:setPath(org.apache.hadoop.fs.Path)
org.apache.hadoop.fs.viewfs.InodeTree$INodeDir	setInternalDirFs	internalDirFs	GC	java.lang.Object	0	org.apache.hadoop.fs.viewfs.InodeTree$INodeDir:setInternalDirFs(java.lang.Object)
org.apache.hadoop.fs.viewfs.InodeTree$INodeDir	setRoot	isRoot	J	boolean	0	org.apache.hadoop.fs.viewfs.InodeTree$INodeDir:setRoot(boolean)
org.apache.hadoop.fs.viewfs.ViewFsLocatedFileStatus	setPath	modifiedPath	C	org.apache.hadoop.fs.Path	0	org.apache.hadoop.fs.viewfs.ViewFsLocatedFileStatus:setPath(org.apache.hadoop.fs.Path)
org.apache.hadoop.fs.statistics.MeanStatistic	setSum	sum	J	long	0	org.apache.hadoop.fs.statistics.MeanStatistic:setSum(long)
org.apache.hadoop.fs.statistics.MeanStatistic	setSamples	samples	J	long	0	org.apache.hadoop.fs.statistics.MeanStatistic:setSamples(long)
org.apache.hadoop.fs.statistics.impl.EvaluatingStatisticsMap$EntryImpl	setValue	value	GC	java.lang.Object	0	org.apache.hadoop.fs.statistics.impl.EvaluatingStatisticsMap$EntryImpl:setValue(java.lang.Object)
org.apache.hadoop.fs.statistics.impl.WrappedIOStatistics	setWrapped	wrapped	C	org.apache.hadoop.fs.statistics.IOStatistics	0	org.apache.hadoop.fs.statistics.impl.WrappedIOStatistics:setWrapped(org.apache.hadoop.fs.statistics.IOStatistics)
org.apache.hadoop.fs.RawLocalFileSystem	setWorkingDirectory	workingDir	C	org.apache.hadoop.fs.Path	0	org.apache.hadoop.fs.RawLocalFileSystem:setWorkingDirectory(org.apache.hadoop.fs.Path)
org.apache.hadoop.fs.impl.prefetch.BlockOperations	setDebug	debugMode	J	boolean	0	org.apache.hadoop.fs.impl.prefetch.BlockOperations:setDebug(boolean)
org.apache.hadoop.fs.impl.prefetch.BufferData	setPrefetch	action	GJ	java.util.concurrent.Future	0	org.apache.hadoop.fs.impl.prefetch.BufferData:setPrefetch(java.util.concurrent.Future)
org.apache.hadoop.fs.impl.FileRangeImpl	setOffset	offset	J	long	0	org.apache.hadoop.fs.impl.FileRangeImpl:setOffset(long)
org.apache.hadoop.fs.impl.FileRangeImpl	setLength	length	J	int	0	org.apache.hadoop.fs.impl.FileRangeImpl:setLength(int)
org.apache.hadoop.fs.impl.FileRangeImpl	setData	reader	GJ	java.util.concurrent.CompletableFuture	0	org.apache.hadoop.fs.impl.FileRangeImpl:setData(java.util.concurrent.CompletableFuture)
org.apache.hadoop.fs.BlockLocation	setOffset	offset	J	long	0	org.apache.hadoop.fs.BlockLocation:setOffset(long)
org.apache.hadoop.fs.BlockLocation	setLength	length	J	long	0	org.apache.hadoop.fs.BlockLocation:setLength(long)
org.apache.hadoop.fs.BlockLocation	setCorrupt	corrupt	J	boolean	0	org.apache.hadoop.fs.BlockLocation:setCorrupt(boolean)
org.apache.hadoop.fs.BlockLocation	setHosts	hosts	J	java.lang.String	1	org.apache.hadoop.fs.BlockLocation:setHosts(java.lang.String[])
org.apache.hadoop.fs.BlockLocation	setCachedHosts	cachedHosts	J	java.lang.String	1	org.apache.hadoop.fs.BlockLocation:setCachedHosts(java.lang.String[])
org.apache.hadoop.fs.BlockLocation	setNames	names	J	java.lang.String	1	org.apache.hadoop.fs.BlockLocation:setNames(java.lang.String[])
org.apache.hadoop.fs.BlockLocation	setTopologyPaths	topologyPaths	J	java.lang.String	1	org.apache.hadoop.fs.BlockLocation:setTopologyPaths(java.lang.String[])
org.apache.hadoop.fs.BlockLocation	setStorageIds	storageIds	J	java.lang.String	1	org.apache.hadoop.fs.BlockLocation:setStorageIds(java.lang.String[])
org.apache.hadoop.fs.BlockLocation	setStorageTypes	storageTypes	C	org.apache.hadoop.fs.StorageType	1	org.apache.hadoop.fs.BlockLocation:setStorageTypes(org.apache.hadoop.fs.StorageType[])
org.apache.hadoop.fs.FileContext	setUMask	umask	C	org.apache.hadoop.fs.permission.FsPermission	0	org.apache.hadoop.fs.FileContext:setUMask(org.apache.hadoop.fs.permission.FsPermission)
org.apache.hadoop.fs.GetSpaceUsed$Builder	setConf	conf	C	org.apache.hadoop.conf.Configuration	0	org.apache.hadoop.fs.GetSpaceUsed$Builder:setConf(org.apache.hadoop.conf.Configuration)
org.apache.hadoop.fs.GetSpaceUsed$Builder	setKlass	klass	GC	java.lang.Class	0	org.apache.hadoop.fs.GetSpaceUsed$Builder:setKlass(java.lang.Class)
org.apache.hadoop.fs.GetSpaceUsed$Builder	setPath	path	J	java.io.File	0	org.apache.hadoop.fs.GetSpaceUsed$Builder:setPath(java.io.File)
org.apache.hadoop.fs.GetSpaceUsed$Builder	setJitter	jitter	J	java.lang.Long	0	org.apache.hadoop.fs.GetSpaceUsed$Builder:setJitter(java.lang.Long)
org.apache.hadoop.fs.GetSpaceUsed$Builder	setCons	cons	GC	java.lang.reflect.Constructor	0	org.apache.hadoop.fs.GetSpaceUsed$Builder:setCons(java.lang.reflect.Constructor)
org.apache.hadoop.fs.LocatedFileStatus	setBlockLocations	locations	C	org.apache.hadoop.fs.BlockLocation	1	org.apache.hadoop.fs.LocatedFileStatus:setBlockLocations(org.apache.hadoop.fs.BlockLocation[])
org.apache.hadoop.crypto.key.kms.KMSClientProvider	setClientTokenProvider	clientTokenProvider	C	org.apache.hadoop.crypto.key.KeyProviderDelegationTokenExtension$DelegationTokenExtension	0	org.apache.hadoop.crypto.key.kms.KMSClientProvider:setClientTokenProvider(org.apache.hadoop.crypto.key.KeyProviderDelegationTokenExtension$DelegationTokenExtension)
org.apache.hadoop.crypto.key.KeyProvider$Options	setCipher	cipher	J	java.lang.String	0	org.apache.hadoop.crypto.key.KeyProvider$Options:setCipher(java.lang.String)
org.apache.hadoop.crypto.key.KeyProvider$Options	setBitLength	bitLength	J	int	0	org.apache.hadoop.crypto.key.KeyProvider$Options:setBitLength(int)
org.apache.hadoop.crypto.key.KeyProvider$Options	setDescription	description	J	java.lang.String	0	org.apache.hadoop.crypto.key.KeyProvider$Options:setDescription(java.lang.String)
org.apache.hadoop.crypto.key.KeyProvider$Options	setAttributes	attributes	GJ	java.util.Map	0	org.apache.hadoop.crypto.key.KeyProvider$Options:setAttributes(java.util.Map)
org.apache.hadoop.crypto.random.OsSecureRandom	setConf	conf	C	org.apache.hadoop.conf.Configuration	0	org.apache.hadoop.crypto.random.OsSecureRandom:setConf(org.apache.hadoop.conf.Configuration)
org.apache.hadoop.io.VLongWritable	set	value	J	long	0	org.apache.hadoop.io.VLongWritable:set(long)
org.apache.hadoop.io.LongWritable	set	value	J	long	0	org.apache.hadoop.io.LongWritable:set(long)
org.apache.hadoop.io.VIntWritable	set	value	J	int	0	org.apache.hadoop.io.VIntWritable:set(int)
org.apache.hadoop.io.FloatWritable	set	value	J	float	0	org.apache.hadoop.io.FloatWritable:set(float)
org.apache.hadoop.io.ArrayWritable	set	values	C	org.apache.hadoop.io.Writable	1	org.apache.hadoop.io.ArrayWritable:set(org.apache.hadoop.io.Writable[])
org.apache.hadoop.io.DoubleWritable	set	value	J	double	0	org.apache.hadoop.io.DoubleWritable:set(double)
org.apache.hadoop.io.SequenceFile$Sorter$SortPass	setProgressable	progressable	C	org.apache.hadoop.util.Progressable	0	org.apache.hadoop.io.SequenceFile$Sorter$SortPass:setProgressable(org.apache.hadoop.util.Progressable)
org.apache.hadoop.io.MapFile$Writer	setIndexInterval	indexInterval	J	int	0	org.apache.hadoop.io.MapFile$Writer:setIndexInterval(int)
org.apache.hadoop.io.IntWritable	set	value	J	int	0	org.apache.hadoop.io.IntWritable:set(int)
org.apache.hadoop.io.ObjectWritable	set	instance	J	java.lang.Object	0	org.apache.hadoop.io.ObjectWritable:set(java.lang.Object)
org.apache.hadoop.io.ObjectWritable	setConf	conf	C	org.apache.hadoop.conf.Configuration	0	org.apache.hadoop.io.ObjectWritable:setConf(org.apache.hadoop.conf.Configuration)
org.apache.hadoop.io.WritableComparator	setConf	conf	C	org.apache.hadoop.conf.Configuration	0	org.apache.hadoop.io.WritableComparator:setConf(org.apache.hadoop.conf.Configuration)
org.apache.hadoop.io.SequenceFile$Sorter	setFactor	factor	J	int	0	org.apache.hadoop.io.SequenceFile$Sorter:setFactor(int)
org.apache.hadoop.io.SequenceFile$Sorter	setMemory	memory	J	int	0	org.apache.hadoop.io.SequenceFile$Sorter:setMemory(int)
org.apache.hadoop.io.SequenceFile$Sorter	setProgressable	progressable	C	org.apache.hadoop.util.Progressable	0	org.apache.hadoop.io.SequenceFile$Sorter:setProgressable(org.apache.hadoop.util.Progressable)
org.apache.hadoop.io.ShortWritable	set	value	J	short	0	org.apache.hadoop.io.ShortWritable:set(short)
org.apache.hadoop.io.retry.AsyncCallHandler$AsyncValue	set	value	GC	java.lang.Object	0	org.apache.hadoop.io.retry.AsyncCallHandler$AsyncValue:set(java.lang.Object)
org.apache.hadoop.io.compress.SplitCompressionInputStream	setStart	start	J	long	0	org.apache.hadoop.io.compress.SplitCompressionInputStream:setStart(long)
org.apache.hadoop.io.compress.SplitCompressionInputStream	setEnd	end	J	long	0	org.apache.hadoop.io.compress.SplitCompressionInputStream:setEnd(long)
org.apache.hadoop.io.compress.BZip2Codec	setConf	conf	C	org.apache.hadoop.conf.Configuration	0	org.apache.hadoop.io.compress.BZip2Codec:setConf(org.apache.hadoop.conf.Configuration)
org.apache.hadoop.io.compress.SnappyCodec	setConf	conf	C	org.apache.hadoop.conf.Configuration	0	org.apache.hadoop.io.compress.SnappyCodec:setConf(org.apache.hadoop.conf.Configuration)
org.apache.hadoop.io.compress.bzip2.CRC	setGlobalCRC	globalCrc	J	int	0	org.apache.hadoop.io.compress.bzip2.CRC:setGlobalCRC(int)
org.apache.hadoop.io.compress.CompressionInputStream	setTrackedDecompressor	trackedDecompressor	C	org.apache.hadoop.io.compress.Decompressor	0	org.apache.hadoop.io.compress.CompressionInputStream:setTrackedDecompressor(org.apache.hadoop.io.compress.Decompressor)
org.apache.hadoop.io.compress.ZStandardCodec	setConf	conf	C	org.apache.hadoop.conf.Configuration	0	org.apache.hadoop.io.compress.ZStandardCodec:setConf(org.apache.hadoop.conf.Configuration)
org.apache.hadoop.io.compress.Lz4Codec	setConf	conf	C	org.apache.hadoop.conf.Configuration	0	org.apache.hadoop.io.compress.Lz4Codec:setConf(org.apache.hadoop.conf.Configuration)
org.apache.hadoop.io.compress.DefaultCodec	setConf	conf	C	org.apache.hadoop.conf.Configuration	0	org.apache.hadoop.io.compress.DefaultCodec:setConf(org.apache.hadoop.conf.Configuration)
org.apache.hadoop.io.compress.CompressionOutputStream	setTrackedCompressor	trackedCompressor	C	org.apache.hadoop.io.compress.Compressor	0	org.apache.hadoop.io.compress.CompressionOutputStream:setTrackedCompressor(org.apache.hadoop.io.compress.Compressor)
org.apache.hadoop.io.TwoDArrayWritable	set	values	C	org.apache.hadoop.io.Writable	2	org.apache.hadoop.io.TwoDArrayWritable:set(org.apache.hadoop.io.Writable[][])
org.apache.hadoop.io.erasurecode.ECChunk	setAllZero	allZero	J	boolean	0	org.apache.hadoop.io.erasurecode.ECChunk:setAllZero(boolean)
org.apache.hadoop.io.erasurecode.codec.ErasureCodec	setCodecOptions	codecOptions	C	org.apache.hadoop.io.erasurecode.ErasureCodecOptions	0	org.apache.hadoop.io.erasurecode.codec.ErasureCodec:setCodecOptions(org.apache.hadoop.io.erasurecode.ErasureCodecOptions)
org.apache.hadoop.io.erasurecode.codec.ErasureCodec	setCoderOptions	coderOptions	C	org.apache.hadoop.io.erasurecode.ErasureCoderOptions	0	org.apache.hadoop.io.erasurecode.codec.ErasureCodec:setCoderOptions(org.apache.hadoop.io.erasurecode.ErasureCoderOptions)
org.apache.hadoop.io.erasurecode.grouper.BlockGrouper	setSchema	schema	C	org.apache.hadoop.io.erasurecode.ECSchema	0	org.apache.hadoop.io.erasurecode.grouper.BlockGrouper:setSchema(org.apache.hadoop.io.erasurecode.ECSchema)
org.apache.hadoop.io.erasurecode.ECBlock	setParity	isParity	J	boolean	0	org.apache.hadoop.io.erasurecode.ECBlock:setParity(boolean)
org.apache.hadoop.io.erasurecode.ECBlock	setErased	isErased	J	boolean	0	org.apache.hadoop.io.erasurecode.ECBlock:setErased(boolean)
org.apache.hadoop.io.EnumSetWritable	setConf	conf	C	org.apache.hadoop.conf.Configuration	0	org.apache.hadoop.io.EnumSetWritable:setConf(org.apache.hadoop.conf.Configuration)
org.apache.hadoop.io.BooleanWritable	set	value	J	boolean	0	org.apache.hadoop.io.BooleanWritable:set(boolean)
org.apache.hadoop.io.GenericWritable	setConf	conf	C	org.apache.hadoop.conf.Configuration	0	org.apache.hadoop.io.GenericWritable:setConf(org.apache.hadoop.conf.Configuration)
org.apache.hadoop.io.ByteWritable	set	value	J	byte	0	org.apache.hadoop.io.ByteWritable:set(byte)
org.apache.hadoop.service.launcher.ServiceLauncher	setService	service	GC	org.apache.hadoop.service.Service	0	org.apache.hadoop.service.launcher.ServiceLauncher:setService(org.apache.hadoop.service.Service)
org.apache.hadoop.service.AbstractService	setConfig	config	C	org.apache.hadoop.conf.Configuration	0	org.apache.hadoop.service.AbstractService:setConfig(org.apache.hadoop.conf.Configuration)
org.apache.hadoop.security.proto.SecurityProtos$TokenProto$Builder	setIdentifier	identifier_	C	org.apache.hadoop.thirdparty.protobuf.ByteString	0	org.apache.hadoop.security.proto.SecurityProtos$TokenProto$Builder:setIdentifier(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.security.proto.SecurityProtos$TokenProto$Builder	setPassword	password_	C	org.apache.hadoop.thirdparty.protobuf.ByteString	0	org.apache.hadoop.security.proto.SecurityProtos$TokenProto$Builder:setPassword(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.security.proto.SecurityProtos$TokenProto$Builder	setKind	kind_	J	java.lang.Object	0	org.apache.hadoop.security.proto.SecurityProtos$TokenProto$Builder:setKind(java.lang.String)
org.apache.hadoop.security.proto.SecurityProtos$TokenProto$Builder	setKindBytes	kind_	J	java.lang.Object	0	org.apache.hadoop.security.proto.SecurityProtos$TokenProto$Builder:setKindBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.security.proto.SecurityProtos$TokenProto$Builder	setService	service_	J	java.lang.Object	0	org.apache.hadoop.security.proto.SecurityProtos$TokenProto$Builder:setService(java.lang.String)
org.apache.hadoop.security.proto.SecurityProtos$TokenProto$Builder	setServiceBytes	service_	J	java.lang.Object	0	org.apache.hadoop.security.proto.SecurityProtos$TokenProto$Builder:setServiceBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.security.proto.SecurityProtos$CredentialsKVProto$Builder	setAlias	alias_	J	java.lang.Object	0	org.apache.hadoop.security.proto.SecurityProtos$CredentialsKVProto$Builder:setAlias(java.lang.String)
org.apache.hadoop.security.proto.SecurityProtos$CredentialsKVProto$Builder	setAliasBytes	alias_	J	java.lang.Object	0	org.apache.hadoop.security.proto.SecurityProtos$CredentialsKVProto$Builder:setAliasBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.security.proto.SecurityProtos$CredentialsKVProto$Builder	setSecret	secret_	C	org.apache.hadoop.thirdparty.protobuf.ByteString	0	org.apache.hadoop.security.proto.SecurityProtos$CredentialsKVProto$Builder:setSecret(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.security.proto.SecurityProtos$GetDelegationTokenRequestProto$Builder	setRenewer	renewer_	J	java.lang.Object	0	org.apache.hadoop.security.proto.SecurityProtos$GetDelegationTokenRequestProto$Builder:setRenewer(java.lang.String)
org.apache.hadoop.security.proto.SecurityProtos$GetDelegationTokenRequestProto$Builder	setRenewerBytes	renewer_	J	java.lang.Object	0	org.apache.hadoop.security.proto.SecurityProtos$GetDelegationTokenRequestProto$Builder:setRenewerBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.security.proto.SecurityProtos$RenewDelegationTokenResponseProto$Builder	setNewExpiryTime	newExpiryTime_	J	long	0	org.apache.hadoop.security.proto.SecurityProtos$RenewDelegationTokenResponseProto$Builder:setNewExpiryTime(long)
org.apache.hadoop.security.UserGroupInformation$AutoRenewalForUserCredsRunnable	setRunRenewalLoop	runRenewalLoop	J	boolean	0	org.apache.hadoop.security.UserGroupInformation$AutoRenewalForUserCredsRunnable:setRunRenewalLoop(boolean)
org.apache.hadoop.security.token.Token	setID	identifier	J	byte	1	org.apache.hadoop.security.token.Token:setID(byte[])
org.apache.hadoop.security.token.Token	setPassword	password	J	byte	1	org.apache.hadoop.security.token.Token:setPassword(byte[])
org.apache.hadoop.security.token.Token	setKind	kind	C	org.apache.hadoop.io.Text	0	org.apache.hadoop.security.token.Token:setKind(org.apache.hadoop.io.Text)
org.apache.hadoop.security.token.Token	setService	service	C	org.apache.hadoop.io.Text	0	org.apache.hadoop.security.token.Token:setService(org.apache.hadoop.io.Text)
org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager	setCurrentKeyId	currentId	J	int	0	org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager:setCurrentKeyId(int)
org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager	setDelegationTokenSeqNum	delegationTokenSequenceNumber	J	int	0	org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager:setDelegationTokenSeqNum(int)
org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticator	setConnectionConfigurator	connConfigurator	C	org.apache.hadoop.security.authentication.client.ConnectionConfigurator	0	org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticator:setConnectionConfigurator(org.apache.hadoop.security.authentication.client.ConnectionConfigurator)
org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticatedURL$Token	setDelegationToken	delegationToken	GC	org.apache.hadoop.security.token.Token	0	org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticatedURL$Token:setDelegationToken(org.apache.hadoop.security.token.Token)
org.apache.hadoop.security.token.delegation.web.DelegationTokenManager	setExternalDelegationTokenSecretManager	secretManager	C	org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager	0	org.apache.hadoop.security.token.delegation.web.DelegationTokenManager:setExternalDelegationTokenSecretManager(org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager)
org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticatedURL	setUseQueryStringForDelegationToken	useQueryStringforDelegationToken	J	boolean	0	org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticatedURL:setUseQueryStringForDelegationToken(boolean)
org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticationFilter	setHandlerAuthMethod	handlerAuthMethod	C	org.apache.hadoop.security.SaslRpcServer$AuthMethod	0	org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticationFilter:setHandlerAuthMethod(org.apache.hadoop.security.SaslRpcServer$AuthMethod)
org.apache.hadoop.security.token.delegation.DelegationKey	setExpiryDate	expiryDate	J	long	0	org.apache.hadoop.security.token.delegation.DelegationKey:setExpiryDate(long)
org.apache.hadoop.security.token.delegation.AbstractDelegationTokenIdentifier	setOwner	owner	C	org.apache.hadoop.io.Text	0	org.apache.hadoop.security.token.delegation.AbstractDelegationTokenIdentifier:setOwner(org.apache.hadoop.io.Text)
org.apache.hadoop.security.token.delegation.AbstractDelegationTokenIdentifier	setRealUser	realUser	C	org.apache.hadoop.io.Text	0	org.apache.hadoop.security.token.delegation.AbstractDelegationTokenIdentifier:setRealUser(org.apache.hadoop.io.Text)
org.apache.hadoop.security.token.delegation.AbstractDelegationTokenIdentifier	setIssueDate	issueDate	J	long	0	org.apache.hadoop.security.token.delegation.AbstractDelegationTokenIdentifier:setIssueDate(long)
org.apache.hadoop.security.token.delegation.AbstractDelegationTokenIdentifier	setMaxDate	maxDate	J	long	0	org.apache.hadoop.security.token.delegation.AbstractDelegationTokenIdentifier:setMaxDate(long)
org.apache.hadoop.security.token.delegation.AbstractDelegationTokenIdentifier	setSequenceNumber	sequenceNumber	J	int	0	org.apache.hadoop.security.token.delegation.AbstractDelegationTokenIdentifier:setSequenceNumber(int)
org.apache.hadoop.security.token.delegation.AbstractDelegationTokenIdentifier	setMasterKeyId	masterKeyId	J	int	0	org.apache.hadoop.security.token.delegation.AbstractDelegationTokenIdentifier:setMasterKeyId(int)
org.apache.hadoop.security.ssl.FileBasedKeyStoresFactory	setConf	conf	C	org.apache.hadoop.conf.Configuration	0	org.apache.hadoop.security.ssl.FileBasedKeyStoresFactory:setConf(org.apache.hadoop.conf.Configuration)
org.apache.hadoop.security.KerberosAuthException	setUser	user	J	java.lang.String	0	org.apache.hadoop.security.KerberosAuthException:setUser(java.lang.String)
org.apache.hadoop.security.KerberosAuthException	setPrincipal	principal	J	java.lang.String	0	org.apache.hadoop.security.KerberosAuthException:setPrincipal(java.lang.String)
org.apache.hadoop.security.KerberosAuthException	setKeytabFile	keytabFile	J	java.lang.String	0	org.apache.hadoop.security.KerberosAuthException:setKeytabFile(java.lang.String)
org.apache.hadoop.security.KerberosAuthException	setTicketCacheFile	ticketCacheFile	J	java.lang.String	0	org.apache.hadoop.security.KerberosAuthException:setTicketCacheFile(java.lang.String)
org.apache.hadoop.security.CompositeGroupsMapping	setConf	conf	C	org.apache.hadoop.conf.Configuration	0	org.apache.hadoop.security.CompositeGroupsMapping:setConf(org.apache.hadoop.conf.Configuration)
org.apache.hadoop.security.User	setAuthenticationMethod	authMethod	C	org.apache.hadoop.security.UserGroupInformation$AuthenticationMethod	0	org.apache.hadoop.security.User:setAuthenticationMethod(org.apache.hadoop.security.UserGroupInformation$AuthenticationMethod)
org.apache.hadoop.security.User	setLogin	login	J	javax.security.auth.login.LoginContext	0	org.apache.hadoop.security.User:setLogin(javax.security.auth.login.LoginContext)
org.apache.hadoop.security.User	setLastLogin	lastLogin	J	long	0	org.apache.hadoop.security.User:setLastLogin(long)
org.apache.hadoop.security.alias.AbstractJavaKeyStoreProvider	setPath	path	C	org.apache.hadoop.fs.Path	0	org.apache.hadoop.security.alias.AbstractJavaKeyStoreProvider:setPath(org.apache.hadoop.fs.Path)
org.apache.hadoop.security.alias.AbstractJavaKeyStoreProvider	setPassword	password	J	char	1	org.apache.hadoop.security.alias.AbstractJavaKeyStoreProvider:setPassword(char[])
org.apache.hadoop.security.alias.AbstractJavaKeyStoreProvider	setChanged	changed	J	boolean	0	org.apache.hadoop.security.alias.AbstractJavaKeyStoreProvider:setChanged(boolean)
org.apache.hadoop.security.alias.AbstractJavaKeyStoreProvider	setReadLock	readLock	J	java.util.concurrent.locks.Lock	0	org.apache.hadoop.security.alias.AbstractJavaKeyStoreProvider:setReadLock(java.util.concurrent.locks.Lock)
org.apache.hadoop.security.alias.AbstractJavaKeyStoreProvider	setWriteLock	writeLock	J	java.util.concurrent.locks.Lock	0	org.apache.hadoop.security.alias.AbstractJavaKeyStoreProvider:setWriteLock(java.util.concurrent.locks.Lock)
org.apache.hadoop.security.alias.CredentialShell	setPasswordReader	passwordReader	C	org.apache.hadoop.security.alias.CredentialShell$PasswordReader	0	org.apache.hadoop.security.alias.CredentialShell:setPasswordReader(org.apache.hadoop.security.alias.CredentialShell$PasswordReader)
org.apache.hadoop.security.authorize.DefaultImpersonationProvider	setConf	conf	C	org.apache.hadoop.conf.Configuration	0	org.apache.hadoop.security.authorize.DefaultImpersonationProvider:setConf(org.apache.hadoop.conf.Configuration)
org.apache.hadoop.tracing.TraceAdminPB$RemoveSpanReceiverRequestProto$Builder	setId	id_	J	long	0	org.apache.hadoop.tracing.TraceAdminPB$RemoveSpanReceiverRequestProto$Builder:setId(long)
org.apache.hadoop.tracing.TraceAdminPB$ConfigPair$Builder	setKey	key_	J	java.lang.Object	0	org.apache.hadoop.tracing.TraceAdminPB$ConfigPair$Builder:setKey(java.lang.String)
org.apache.hadoop.tracing.TraceAdminPB$ConfigPair$Builder	setKeyBytes	key_	J	java.lang.Object	0	org.apache.hadoop.tracing.TraceAdminPB$ConfigPair$Builder:setKeyBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.tracing.TraceAdminPB$ConfigPair$Builder	setValue	value_	J	java.lang.Object	0	org.apache.hadoop.tracing.TraceAdminPB$ConfigPair$Builder:setValue(java.lang.String)
org.apache.hadoop.tracing.TraceAdminPB$ConfigPair$Builder	setValueBytes	value_	J	java.lang.Object	0	org.apache.hadoop.tracing.TraceAdminPB$ConfigPair$Builder:setValueBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.tracing.TraceAdminPB$AddSpanReceiverRequestProto$Builder	setClassName	className_	J	java.lang.Object	0	org.apache.hadoop.tracing.TraceAdminPB$AddSpanReceiverRequestProto$Builder:setClassName(java.lang.String)
org.apache.hadoop.tracing.TraceAdminPB$AddSpanReceiverRequestProto$Builder	setClassNameBytes	className_	J	java.lang.Object	0	org.apache.hadoop.tracing.TraceAdminPB$AddSpanReceiverRequestProto$Builder:setClassNameBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.tracing.TraceAdminPB$SpanReceiverListInfo$Builder	setId	id_	J	long	0	org.apache.hadoop.tracing.TraceAdminPB$SpanReceiverListInfo$Builder:setId(long)
org.apache.hadoop.tracing.TraceAdminPB$SpanReceiverListInfo$Builder	setClassName	className_	J	java.lang.Object	0	org.apache.hadoop.tracing.TraceAdminPB$SpanReceiverListInfo$Builder:setClassName(java.lang.String)
org.apache.hadoop.tracing.TraceAdminPB$SpanReceiverListInfo$Builder	setClassNameBytes	className_	J	java.lang.Object	0	org.apache.hadoop.tracing.TraceAdminPB$SpanReceiverListInfo$Builder:setClassNameBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.tracing.TraceAdminPB$AddSpanReceiverResponseProto$Builder	setId	id_	J	long	0	org.apache.hadoop.tracing.TraceAdminPB$AddSpanReceiverResponseProto$Builder:setId(long)
org.apache.hadoop.util.LightWeightGSet$SetIterator	setTrackModification	trackModification	J	boolean	0	org.apache.hadoop.util.LightWeightGSet$SetIterator:setTrackModification(boolean)
org.apache.hadoop.util.Progress	setParent	parent	C	org.apache.hadoop.util.Progress	0	org.apache.hadoop.util.Progress:setParent(org.apache.hadoop.util.Progress)
org.apache.hadoop.util.Progress	setStatus	status	J	java.lang.String	0	org.apache.hadoop.util.Progress:setStatus(java.lang.String)
org.apache.hadoop.util.Shell	setEnvironment	environment	GJ	java.util.Map	0	org.apache.hadoop.util.Shell:setEnvironment(java.util.Map)
org.apache.hadoop.util.Shell	setWorkingDirectory	dir	J	java.io.File	0	org.apache.hadoop.util.Shell:setWorkingDirectory(java.io.File)
org.apache.hadoop.util.SysInfoLinux	setReadCpuInfoFile	readCpuInfoFile	J	boolean	0	org.apache.hadoop.util.SysInfoLinux:setReadCpuInfoFile(boolean)
org.apache.hadoop.ha.proto.ZKFCProtocolProtos$CedeActiveRequestProto$Builder	setMillisToCede	millisToCede_	J	int	0	org.apache.hadoop.ha.proto.ZKFCProtocolProtos$CedeActiveRequestProto$Builder:setMillisToCede(int)
org.apache.hadoop.ha.proto.HAServiceProtocolProtos$GetServiceStatusResponseProto$Builder	setReadyToBecomeActive	readyToBecomeActive_	J	boolean	0	org.apache.hadoop.ha.proto.HAServiceProtocolProtos$GetServiceStatusResponseProto$Builder:setReadyToBecomeActive(boolean)
org.apache.hadoop.ha.proto.HAServiceProtocolProtos$GetServiceStatusResponseProto$Builder	setNotReadyReason	notReadyReason_	J	java.lang.Object	0	org.apache.hadoop.ha.proto.HAServiceProtocolProtos$GetServiceStatusResponseProto$Builder:setNotReadyReason(java.lang.String)
org.apache.hadoop.ha.proto.HAServiceProtocolProtos$GetServiceStatusResponseProto$Builder	setNotReadyReasonBytes	notReadyReason_	J	java.lang.Object	0	org.apache.hadoop.ha.proto.HAServiceProtocolProtos$GetServiceStatusResponseProto$Builder:setNotReadyReasonBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.ha.HealthMonitor	setLastServiceStatus	lastServiceState	C	org.apache.hadoop.ha.HAServiceStatus	0	org.apache.hadoop.ha.HealthMonitor:setLastServiceStatus(org.apache.hadoop.ha.HAServiceStatus)
org.apache.hadoop.ha.ZKFailoverController	setLastHealthState	lastHealthState	C	org.apache.hadoop.ha.HealthMonitor$State	0	org.apache.hadoop.ha.ZKFailoverController:setLastHealthState(org.apache.hadoop.ha.HealthMonitor$State)
org.apache.hadoop.ha.ActiveStandbyElector$WatcherWithClientRef	setZooKeeperRef	zk	C	org.apache.zookeeper.ZooKeeper	0	org.apache.hadoop.ha.ActiveStandbyElector$WatcherWithClientRef:setZooKeeperRef(org.apache.zookeeper.ZooKeeper)
org.apache.hadoop.ha.HAAdmin	setRequestSource	requestSource	C	org.apache.hadoop.ha.HAServiceProtocol$RequestSource	0	org.apache.hadoop.ha.HAAdmin:setRequestSource(org.apache.hadoop.ha.HAServiceProtocol$RequestSource)
org.apache.hadoop.ha.HAServiceTarget	setTransitionTargetHAStatus	transitionTargetHAStatus	C	org.apache.hadoop.ha.HAServiceProtocol$HAServiceState	0	org.apache.hadoop.ha.HAServiceTarget:setTransitionTargetHAStatus(org.apache.hadoop.ha.HAServiceProtocol$HAServiceState)
org.apache.hadoop.ha.HAServiceStatus	setNotReadyToBecomeActive	notReadyReason	J	java.lang.String	0	org.apache.hadoop.ha.HAServiceStatus:setNotReadyToBecomeActive(java.lang.String)
org.apache.hadoop.crypto.key.kms.server.KMSAuditLogger$AuditEvent	setEndTime	endTime	J	long	0	org.apache.hadoop.crypto.key.kms.server.KMSAuditLogger$AuditEvent:setEndTime(long)
org.apache.hadoop.crypto.key.kms.server.KMSAuthenticationFilter$KMSResponse	setStatus	statusCode	J	int	0	org.apache.hadoop.crypto.key.kms.server.KMSAuthenticationFilter$KMSResponse:setStatus(int)
org.apache.hadoop.minikdc.MiniKdc	setTransport	transport	J	java.lang.String	0	org.apache.hadoop.minikdc.MiniKdc:setTransport(java.lang.String)
org.apache.hadoop.nfs.nfs3.response.GETATTR3Response	setPostOpAttr	postOpAttr	C	org.apache.hadoop.nfs.nfs3.Nfs3FileAttributes	0	org.apache.hadoop.nfs.nfs3.response.GETATTR3Response:setPostOpAttr(org.apache.hadoop.nfs.nfs3.Nfs3FileAttributes)
org.apache.hadoop.nfs.nfs3.response.NFS3Response	setStatus	status	J	int	0	org.apache.hadoop.nfs.nfs3.response.NFS3Response:setStatus(int)
org.apache.hadoop.nfs.nfs3.response.WccData	setPreOpAttr	preOpAttr	C	org.apache.hadoop.nfs.nfs3.response.WccAttr	0	org.apache.hadoop.nfs.nfs3.response.WccData:setPreOpAttr(org.apache.hadoop.nfs.nfs3.response.WccAttr)
org.apache.hadoop.nfs.nfs3.response.WccData	setPostOpAttr	postOpAttr	C	org.apache.hadoop.nfs.nfs3.Nfs3FileAttributes	0	org.apache.hadoop.nfs.nfs3.response.WccData:setPostOpAttr(org.apache.hadoop.nfs.nfs3.Nfs3FileAttributes)
org.apache.hadoop.nfs.nfs3.request.LOOKUP3Request	setName	name	J	java.lang.String	0	org.apache.hadoop.nfs.nfs3.request.LOOKUP3Request:setName(java.lang.String)
org.apache.hadoop.nfs.nfs3.request.WRITE3Request	setOffset	offset	J	long	0	org.apache.hadoop.nfs.nfs3.request.WRITE3Request:setOffset(long)
org.apache.hadoop.nfs.nfs3.request.WRITE3Request	setCount	count	J	int	0	org.apache.hadoop.nfs.nfs3.request.WRITE3Request:setCount(int)
org.apache.hadoop.nfs.nfs3.request.SetAttr3	setGid	gid	J	int	0	org.apache.hadoop.nfs.nfs3.request.SetAttr3:setGid(int)
org.apache.hadoop.nfs.nfs3.request.SetAttr3	setUpdateFields	updateFields	GC	java.util.EnumSet	0	org.apache.hadoop.nfs.nfs3.request.SetAttr3:setUpdateFields(java.util.EnumSet)
org.apache.hadoop.nfs.nfs3.Nfs3FileAttributes	setSize	size	J	long	0	org.apache.hadoop.nfs.nfs3.Nfs3FileAttributes:setSize(long)
org.apache.hadoop.nfs.nfs3.Nfs3FileAttributes	setUsed	used	J	long	0	org.apache.hadoop.nfs.nfs3.Nfs3FileAttributes:setUsed(long)
org.apache.hadoop.nfs.nfs3.Nfs3FileAttributes	setRdev	rdev	C	org.apache.hadoop.nfs.nfs3.Nfs3FileAttributes$Specdata3	0	org.apache.hadoop.nfs.nfs3.Nfs3FileAttributes:setRdev(org.apache.hadoop.nfs.nfs3.Nfs3FileAttributes$Specdata3)
org.apache.hadoop.nfs.NfsExports$AccessCacheEntry	setNext	next	C	org.apache.hadoop.util.LightWeightGSet$LinkedElement	0	org.apache.hadoop.nfs.NfsExports$AccessCacheEntry:setNext(org.apache.hadoop.util.LightWeightGSet$LinkedElement)
org.apache.hadoop.oncrpc.security.CredentialsSys	setGID	mGID	J	int	0	org.apache.hadoop.oncrpc.security.CredentialsSys:setGID(int)
org.apache.hadoop.oncrpc.security.CredentialsSys	setUID	mUID	J	int	0	org.apache.hadoop.oncrpc.security.CredentialsSys:setUID(int)
org.apache.hadoop.oncrpc.security.CredentialsSys	setStamp	mStamp	J	int	0	org.apache.hadoop.oncrpc.security.CredentialsSys:setStamp(int)
org.apache.hadoop.oncrpc.security.CredentialsSys	setHostName	mHostName	J	java.lang.String	0	org.apache.hadoop.oncrpc.security.CredentialsSys:setHostName(java.lang.String)
org.apache.hadoop.oncrpc.RpcCallCache$CacheEntry	setResponse	response	C	org.apache.hadoop.oncrpc.RpcResponse	0	org.apache.hadoop.oncrpc.RpcCallCache$CacheEntry:setResponse(org.apache.hadoop.oncrpc.RpcResponse)
org.apache.hadoop.registry.server.dns.BaseServiceRecordProcessor	setPath	path	J	java.lang.String	0	org.apache.hadoop.registry.server.dns.BaseServiceRecordProcessor:setPath(java.lang.String)
org.apache.hadoop.registry.server.dns.RecordCreatorFactory$HostPortInfo	setHost	host	C	org.xbill.DNS.Name	0	org.apache.hadoop.registry.server.dns.RecordCreatorFactory$HostPortInfo:setHost(org.xbill.DNS.Name)
org.apache.hadoop.registry.server.dns.RecordCreatorFactory$HostPortInfo	setPort	port	J	int	0	org.apache.hadoop.registry.server.dns.RecordCreatorFactory$HostPortInfo:setPort(int)
org.apache.hadoop.registry.server.dns.BaseServiceRecordProcessor$ApplicationRecordDescriptor	setEndpoint	srEndpoint	C	org.apache.hadoop.registry.client.types.Endpoint	0	org.apache.hadoop.registry.server.dns.BaseServiceRecordProcessor$ApplicationRecordDescriptor:setEndpoint(org.apache.hadoop.registry.client.types.Endpoint)
org.apache.hadoop.registry.server.dns.BaseServiceRecordProcessor$RecordDescriptor	setNames	names	C	org.xbill.DNS.Name	1	org.apache.hadoop.registry.server.dns.BaseServiceRecordProcessor$RecordDescriptor:setNames(org.xbill.DNS.Name[])
org.apache.hadoop.registry.server.dns.BaseServiceRecordProcessor$RecordDescriptor	setTarget	target	GC	java.lang.Object	0	org.apache.hadoop.registry.server.dns.BaseServiceRecordProcessor$RecordDescriptor:setTarget(java.lang.Object)
org.apache.hadoop.fs.XAttr$Builder	setNameSpace	ns	C	org.apache.hadoop.fs.XAttr$NameSpace	0	org.apache.hadoop.fs.XAttr$Builder:setNameSpace(org.apache.hadoop.fs.XAttr$NameSpace)
org.apache.hadoop.fs.XAttr$Builder	setName	name	J	java.lang.String	0	org.apache.hadoop.fs.XAttr$Builder:setName(java.lang.String)
org.apache.hadoop.fs.XAttr$Builder	setValue	value	J	byte	1	org.apache.hadoop.fs.XAttr$Builder:setValue(byte[])
org.apache.hadoop.fs.Hdfs	setVerifyChecksum	verifyChecksum	J	boolean	0	org.apache.hadoop.fs.Hdfs:setVerifyChecksum(boolean)
org.apache.hadoop.hdfs.StripeReader	setReadTo	readTo	J	long	0	org.apache.hadoop.hdfs.StripeReader:setReadTo(long)
org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer	setTimeout	timeout	J	int	0	org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer:setTimeout(int)
org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer	setRemaining	remaining	J	long	0	org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer:setRemaining(long)
org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer	setBytesPerCRC	bytesPerCRC	J	int	0	org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer:setBytesPerCRC(int)
org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer	setCrcType	crcType	C	org.apache.hadoop.util.DataChecksum$Type	0	org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer:setCrcType(org.apache.hadoop.util.DataChecksum$Type)
org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer	setCrcPerBlock	crcPerBlock	J	long	0	org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer:setCrcPerBlock(long)
org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer	setRefetchBlocks	isRefetchBlocks	J	boolean	0	org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer:setRefetchBlocks(boolean)
org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer	setLastRetriedIndex	lastRetriedIndex	J	int	0	org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer:setLastRetriedIndex(int)
org.apache.hadoop.hdfs.DataStreamer$ErrorState	setBadNodeIndex	badNodeIndex	J	int	0	org.apache.hadoop.hdfs.DataStreamer$ErrorState:setBadNodeIndex(int)
org.apache.hadoop.hdfs.DeadNodeDetector	setSuspectQueue	suspectNodesProbeQueue	GC	org.apache.hadoop.hdfs.DeadNodeDetector$UniqueQueue	0	org.apache.hadoop.hdfs.DeadNodeDetector:setSuspectQueue(org.apache.hadoop.hdfs.DeadNodeDetector$UniqueQueue)
org.apache.hadoop.hdfs.DeadNodeDetector	setDeadQueue	deadNodesProbeQueue	GC	org.apache.hadoop.hdfs.DeadNodeDetector$UniqueQueue	0	org.apache.hadoop.hdfs.DeadNodeDetector:setDeadQueue(org.apache.hadoop.hdfs.DeadNodeDetector$UniqueQueue)
org.apache.hadoop.hdfs.StripeReader$BlockReaderInfo	setOffset	blockReaderOffset	J	long	0	org.apache.hadoop.hdfs.StripeReader$BlockReaderInfo:setOffset(long)
org.apache.hadoop.hdfs.web.oauth2.AccessTokenProvider	setConf	conf	C	org.apache.hadoop.conf.Configuration	0	org.apache.hadoop.hdfs.web.oauth2.AccessTokenProvider:setConf(org.apache.hadoop.conf.Configuration)
org.apache.hadoop.hdfs.web.ByteRangeInputStream$URLOpener	setURL	url	J	java.net.URL	0	org.apache.hadoop.hdfs.web.ByteRangeInputStream$URLOpener:setURL(java.net.URL)
org.apache.hadoop.hdfs.web.WebHdfsFileSystem$WebHdfsInputStream	setReadRunner	readRunner	C	org.apache.hadoop.hdfs.web.WebHdfsFileSystem$ReadRunner	0	org.apache.hadoop.hdfs.web.WebHdfsFileSystem$WebHdfsInputStream:setReadRunner(org.apache.hadoop.hdfs.web.WebHdfsFileSystem$ReadRunner)
org.apache.hadoop.hdfs.web.WebHdfsFileSystem$ReadRunner	setInputStream	in	J	java.io.InputStream	0	org.apache.hadoop.hdfs.web.WebHdfsFileSystem$ReadRunner:setInputStream(java.io.InputStream)
org.apache.hadoop.hdfs.web.WebHdfsFileSystem$ReadRunner	setFileLength	fileLength	J	long	0	org.apache.hadoop.hdfs.web.WebHdfsFileSystem$ReadRunner:setFileLength(long)
org.apache.hadoop.hdfs.web.WebHdfsFileSystem	setDelegationToken	delegationToken	GC	org.apache.hadoop.security.token.Token	0	org.apache.hadoop.hdfs.web.WebHdfsFileSystem:setDelegationToken(org.apache.hadoop.security.token.Token)
org.apache.hadoop.hdfs.web.WebHdfsFileSystem	setRetryPolicy	retryPolicy	C	org.apache.hadoop.io.retry.RetryPolicy	0	org.apache.hadoop.hdfs.web.WebHdfsFileSystem:setRetryPolicy(org.apache.hadoop.io.retry.RetryPolicy)
org.apache.hadoop.hdfs.web.WebHdfsFileSystem	setTestProvider	testProvider	C	org.apache.hadoop.crypto.key.KeyProvider	0	org.apache.hadoop.hdfs.web.WebHdfsFileSystem:setTestProvider(org.apache.hadoop.crypto.key.KeyProvider)
org.apache.hadoop.hdfs.DataStreamer$BlockToWrite	setCurrentBlock	currentBlock	C	org.apache.hadoop.hdfs.protocol.ExtendedBlock	0	org.apache.hadoop.hdfs.DataStreamer$BlockToWrite:setCurrentBlock(org.apache.hadoop.hdfs.protocol.ExtendedBlock)
org.apache.hadoop.hdfs.server.datanode.DiskBalancerWorkItem	setErrMsg	errMsg	J	java.lang.String	0	org.apache.hadoop.hdfs.server.datanode.DiskBalancerWorkItem:setErrMsg(java.lang.String)
org.apache.hadoop.hdfs.server.datanode.DiskBalancerWorkItem	setBytesCopied	bytesCopied	J	long	0	org.apache.hadoop.hdfs.server.datanode.DiskBalancerWorkItem:setBytesCopied(long)
org.apache.hadoop.hdfs.server.datanode.DiskBalancerWorkItem	setErrorCount	errorCount	J	long	0	org.apache.hadoop.hdfs.server.datanode.DiskBalancerWorkItem:setErrorCount(long)
org.apache.hadoop.hdfs.server.datanode.DiskBalancerWorkItem	setBlocksCopied	blocksCopied	J	long	0	org.apache.hadoop.hdfs.server.datanode.DiskBalancerWorkItem:setBlocksCopied(long)
org.apache.hadoop.hdfs.server.datanode.DiskBalancerWorkItem	setMaxDiskErrors	maxDiskErrors	J	long	0	org.apache.hadoop.hdfs.server.datanode.DiskBalancerWorkItem:setMaxDiskErrors(long)
org.apache.hadoop.hdfs.server.datanode.DiskBalancerWorkItem	setTolerancePercent	tolerancePercent	J	long	0	org.apache.hadoop.hdfs.server.datanode.DiskBalancerWorkItem:setTolerancePercent(long)
org.apache.hadoop.hdfs.server.datanode.DiskBalancerWorkItem	setBandwidth	bandwidth	J	long	0	org.apache.hadoop.hdfs.server.datanode.DiskBalancerWorkItem:setBandwidth(long)
org.apache.hadoop.hdfs.server.datanode.DiskBalancerWorkItem	setStartTime	startTime	J	long	0	org.apache.hadoop.hdfs.server.datanode.DiskBalancerWorkItem:setStartTime(long)
org.apache.hadoop.hdfs.server.datanode.DiskBalancerWorkItem	setSecondsElapsed	secondsElapsed	J	long	0	org.apache.hadoop.hdfs.server.datanode.DiskBalancerWorkItem:setSecondsElapsed(long)
org.apache.hadoop.hdfs.server.datanode.DiskBalancerWorkStatus$DiskBalancerWorkEntry	setSourcePath	sourcePath	J	java.lang.String	0	org.apache.hadoop.hdfs.server.datanode.DiskBalancerWorkStatus$DiskBalancerWorkEntry:setSourcePath(java.lang.String)
org.apache.hadoop.hdfs.server.datanode.DiskBalancerWorkStatus$DiskBalancerWorkEntry	setDestPath	destPath	J	java.lang.String	0	org.apache.hadoop.hdfs.server.datanode.DiskBalancerWorkStatus$DiskBalancerWorkEntry:setDestPath(java.lang.String)
org.apache.hadoop.hdfs.server.datanode.DiskBalancerWorkStatus$DiskBalancerWorkEntry	setWorkItem	workItem	C	org.apache.hadoop.hdfs.server.datanode.DiskBalancerWorkItem	0	org.apache.hadoop.hdfs.server.datanode.DiskBalancerWorkStatus$DiskBalancerWorkEntry:setWorkItem(org.apache.hadoop.hdfs.server.datanode.DiskBalancerWorkItem)
org.apache.hadoop.hdfs.server.datanode.CachingStrategy$Builder	setDropBehind	dropBehind	J	java.lang.Boolean	0	org.apache.hadoop.hdfs.server.datanode.CachingStrategy$Builder:setDropBehind(java.lang.Boolean)
org.apache.hadoop.hdfs.server.datanode.CachingStrategy$Builder	setReadahead	readahead	J	java.lang.Long	0	org.apache.hadoop.hdfs.server.datanode.CachingStrategy$Builder:setReadahead(java.lang.Long)
org.apache.hadoop.hdfs.server.namenode.ha.ClientHAProxyFactory	setAlignmentContext	alignmentContext	C	org.apache.hadoop.ipc.AlignmentContext	0	org.apache.hadoop.hdfs.server.namenode.ha.ClientHAProxyFactory:setAlignmentContext(org.apache.hadoop.ipc.AlignmentContext)
org.apache.hadoop.hdfs.server.namenode.ha.AbstractNNFailoverProxyProvider	setFallbackToSimpleAuth	fallbackToSimpleAuth	J	java.util.concurrent.atomic.AtomicBoolean	0	org.apache.hadoop.hdfs.server.namenode.ha.AbstractNNFailoverProxyProvider:setFallbackToSimpleAuth(java.util.concurrent.atomic.AtomicBoolean)
org.apache.hadoop.hdfs.server.namenode.ha.AbstractNNFailoverProxyProvider$NNProxyInfo	setCachedState	cachedState	C	org.apache.hadoop.ha.HAServiceProtocol$HAServiceState	0	org.apache.hadoop.hdfs.server.namenode.ha.AbstractNNFailoverProxyProvider$NNProxyInfo:setCachedState(org.apache.hadoop.ha.HAServiceProtocol$HAServiceState)
org.apache.hadoop.hdfs.server.namenode.ha.ObserverReadProxyProvider	setObserverReadEnabled	observerReadEnabled	J	boolean	0	org.apache.hadoop.hdfs.server.namenode.ha.ObserverReadProxyProvider:setObserverReadEnabled(boolean)
org.apache.hadoop.hdfs.server.protocol.DataNodeUsageReport$Builder	setBytesWrittenPerSec	bytesWrittenPerSec	J	long	0	org.apache.hadoop.hdfs.server.protocol.DataNodeUsageReport$Builder:setBytesWrittenPerSec(long)
org.apache.hadoop.hdfs.server.protocol.DataNodeUsageReport$Builder	setBytesReadPerSec	bytesReadPerSec	J	long	0	org.apache.hadoop.hdfs.server.protocol.DataNodeUsageReport$Builder:setBytesReadPerSec(long)
org.apache.hadoop.hdfs.server.protocol.DataNodeUsageReport$Builder	setWriteTime	writeTime	J	long	0	org.apache.hadoop.hdfs.server.protocol.DataNodeUsageReport$Builder:setWriteTime(long)
org.apache.hadoop.hdfs.server.protocol.DataNodeUsageReport$Builder	setReadTime	readTime	J	long	0	org.apache.hadoop.hdfs.server.protocol.DataNodeUsageReport$Builder:setReadTime(long)
org.apache.hadoop.hdfs.server.protocol.DataNodeUsageReport$Builder	setBlocksWrittenPerSec	blocksWrittenPerSec	J	long	0	org.apache.hadoop.hdfs.server.protocol.DataNodeUsageReport$Builder:setBlocksWrittenPerSec(long)
org.apache.hadoop.hdfs.server.protocol.DataNodeUsageReport$Builder	setBlocksReadPerSec	blocksReadPerSec	J	long	0	org.apache.hadoop.hdfs.server.protocol.DataNodeUsageReport$Builder:setBlocksReadPerSec(long)
org.apache.hadoop.hdfs.server.protocol.DataNodeUsageReport$Builder	setTimestamp	timestamp	J	long	0	org.apache.hadoop.hdfs.server.protocol.DataNodeUsageReport$Builder:setTimestamp(long)
org.apache.hadoop.hdfs.ReadStatistics	setBlockType	blockType	C	org.apache.hadoop.hdfs.protocol.BlockType	0	org.apache.hadoop.hdfs.ReadStatistics:setBlockType(org.apache.hadoop.hdfs.protocol.BlockType)
org.apache.hadoop.hdfs.DistributedFileSystem	setVerifyChecksum	verifyChecksum	J	boolean	0	org.apache.hadoop.hdfs.DistributedFileSystem:setVerifyChecksum(boolean)
org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache$CacheCleaner	setFuture	future	GC	java.util.concurrent.ScheduledFuture	0	org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache$CacheCleaner:setFuture(java.util.concurrent.ScheduledFuture)
org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache	setMaxTotalSize	maxTotalSize	J	int	0	org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache:setMaxTotalSize(int)
org.apache.hadoop.hdfs.shortcircuit.ShortCircuitReplica	setEvictableTimeNs	evictableTimeNs	J	java.lang.Long	0	org.apache.hadoop.hdfs.shortcircuit.ShortCircuitReplica:setEvictableTimeNs(java.lang.Long)
org.apache.hadoop.hdfs.DFSInputStream	setLastRefreshedBlocksAtForTesting	lastRefreshedBlocksAt	J	long	0	org.apache.hadoop.hdfs.DFSInputStream:setLastRefreshedBlocksAtForTesting(long)
org.apache.hadoop.hdfs.DFSPacket	setSyncBlock	syncBlock	J	boolean	0	org.apache.hadoop.hdfs.DFSPacket:setSyncBlock(boolean)
org.apache.hadoop.hdfs.DFSPacket	setSpan	span	C	org.apache.hadoop.tracing.Span	0	org.apache.hadoop.hdfs.DFSPacket:setSpan(org.apache.hadoop.tracing.Span)
org.apache.hadoop.hdfs.security.token.block.BlockTokenIdentifier	setExpiryDate	expiryDate	J	long	0	org.apache.hadoop.hdfs.security.token.block.BlockTokenIdentifier:setExpiryDate(long)
org.apache.hadoop.hdfs.security.token.block.BlockTokenIdentifier	setKeyId	keyId	J	int	0	org.apache.hadoop.hdfs.security.token.block.BlockTokenIdentifier:setKeyId(int)
org.apache.hadoop.hdfs.security.token.block.BlockTokenIdentifier	setHandshakeMsg	handshakeMsg	J	byte	1	org.apache.hadoop.hdfs.security.token.block.BlockTokenIdentifier:setHandshakeMsg(byte[])
org.apache.hadoop.hdfs.DataStreamer	setAccessToken	accessToken	GC	org.apache.hadoop.security.token.Token	0	org.apache.hadoop.hdfs.DataStreamer:setAccessToken(org.apache.hadoop.security.token.Token)
org.apache.hadoop.hdfs.DataStreamer	setAppendChunk	appendChunk	J	boolean	0	org.apache.hadoop.hdfs.DataStreamer:setAppendChunk(boolean)
org.apache.hadoop.hdfs.DataStreamer	setBytesCurBlock	bytesCurBlock	J	long	0	org.apache.hadoop.hdfs.DataStreamer:setBytesCurBlock(long)
org.apache.hadoop.hdfs.DataStreamer	setArtificialSlowdown	artificialSlowdown	J	long	0	org.apache.hadoop.hdfs.DataStreamer:setArtificialSlowdown(long)
org.apache.hadoop.hdfs.DFSOutputStream	setChunksPerPacket	chunksPerPacket	J	int	0	org.apache.hadoop.hdfs.DFSOutputStream:setChunksPerPacket(int)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ConcatRequestProto$Builder	setTrg	trg_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ConcatRequestProto$Builder:setTrg(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ConcatRequestProto$Builder	setTrgBytes	trg_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ConcatRequestProto$Builder:setTrgBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportListingRequestProto$Builder	setSnapshotRoot	snapshotRoot_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportListingRequestProto$Builder:setSnapshotRoot(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportListingRequestProto$Builder	setSnapshotRootBytes	snapshotRoot_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportListingRequestProto$Builder:setSnapshotRootBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportListingRequestProto$Builder	setFromSnapshot	fromSnapshot_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportListingRequestProto$Builder:setFromSnapshot(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportListingRequestProto$Builder	setFromSnapshotBytes	fromSnapshot_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportListingRequestProto$Builder:setFromSnapshotBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportListingRequestProto$Builder	setToSnapshot	toSnapshot_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportListingRequestProto$Builder:setToSnapshot(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportListingRequestProto$Builder	setToSnapshotBytes	toSnapshot_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportListingRequestProto$Builder:setToSnapshotBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpReplaceBlockProto$Builder	setDelHint	delHint_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpReplaceBlockProto$Builder:setDelHint(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpReplaceBlockProto$Builder	setDelHintBytes	delHint_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpReplaceBlockProto$Builder:setDelHintBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpReplaceBlockProto$Builder	setStorageId	storageId_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpReplaceBlockProto$Builder:setStorageId(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpReplaceBlockProto$Builder	setStorageIdBytes	storageId_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpReplaceBlockProto$Builder:setStorageIdBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.AclProtos$SetAclRequestProto$Builder	setSrc	src_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.AclProtos$SetAclRequestProto$Builder:setSrc(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.AclProtos$SetAclRequestProto$Builder	setSrcBytes	src_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.AclProtos$SetAclRequestProto$Builder:setSrcBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpRequestShortCircuitAccessProto$Builder	setMaxVersion	maxVersion_	J	int	0	org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpRequestShortCircuitAccessProto$Builder:setMaxVersion(int)
org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpRequestShortCircuitAccessProto$Builder	setSupportsReceiptVerification	supportsReceiptVerification_	J	boolean	0	org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpRequestShortCircuitAccessProto$Builder:setSupportsReceiptVerification(boolean)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCacheDirectiveRequestProto$Builder	setId	id_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCacheDirectiveRequestProto$Builder:setId(long)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetTimesRequestProto$Builder	setSrc	src_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetTimesRequestProto$Builder:setSrc(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetTimesRequestProto$Builder	setSrcBytes	src_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetTimesRequestProto$Builder:setSrcBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetTimesRequestProto$Builder	setMtime	mtime_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetTimesRequestProto$Builder:setMtime(long)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetTimesRequestProto$Builder	setAtime	atime_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetTimesRequestProto$Builder:setAtime(long)
org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$MetadataUpdateEventProto$Builder	setPath	path_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$MetadataUpdateEventProto$Builder:setPath(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$MetadataUpdateEventProto$Builder	setPathBytes	path_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$MetadataUpdateEventProto$Builder:setPathBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$MetadataUpdateEventProto$Builder	setMtime	mtime_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$MetadataUpdateEventProto$Builder:setMtime(long)
org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$MetadataUpdateEventProto$Builder	setAtime	atime_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$MetadataUpdateEventProto$Builder:setAtime(long)
org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$MetadataUpdateEventProto$Builder	setReplication	replication_	J	int	0	org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$MetadataUpdateEventProto$Builder:setReplication(int)
org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$MetadataUpdateEventProto$Builder	setOwnerName	ownerName_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$MetadataUpdateEventProto$Builder:setOwnerName(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$MetadataUpdateEventProto$Builder	setOwnerNameBytes	ownerName_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$MetadataUpdateEventProto$Builder:setOwnerNameBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$MetadataUpdateEventProto$Builder	setGroupName	groupName_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$MetadataUpdateEventProto$Builder:setGroupName(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$MetadataUpdateEventProto$Builder	setGroupNameBytes	groupName_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$MetadataUpdateEventProto$Builder:setGroupNameBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$MetadataUpdateEventProto$Builder	setXAttrsRemoved	xAttrsRemoved_	J	boolean	0	org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$MetadataUpdateEventProto$Builder:setXAttrsRemoved(boolean)
org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclRequestProto$Builder	setSrc	src_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclRequestProto$Builder:setSrc(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclRequestProto$Builder	setSrcBytes	src_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclRequestProto$Builder:setSrcBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListReencryptionStatusResponseProto$Builder	setHasMore	hasMore_	J	boolean	0	org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListReencryptionStatusResponseProto$Builder:setHasMore(boolean)
org.apache.hadoop.hdfs.protocol.proto.AclProtos$AclEntryProto$Builder	setName	name_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.AclProtos$AclEntryProto$Builder:setName(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.AclProtos$AclEntryProto$Builder	setNameBytes	name_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.AclProtos$AclEntryProto$Builder:setNameBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$CloseEventProto$Builder	setPath	path_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$CloseEventProto$Builder:setPath(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$CloseEventProto$Builder	setPathBytes	path_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$CloseEventProto$Builder:setPathBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$CloseEventProto$Builder	setFileSize	fileSize_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$CloseEventProto$Builder:setFileSize(long)
org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$CloseEventProto$Builder	setTimestamp	timestamp_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$CloseEventProto$Builder:setTimestamp(long)
org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$XAttrProto$Builder	setName	name_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$XAttrProto$Builder:setName(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$XAttrProto$Builder	setNameBytes	name_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$XAttrProto$Builder:setNameBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$XAttrProto$Builder	setValue	value_	C	org.apache.hadoop.thirdparty.protobuf.ByteString	0	org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$XAttrProto$Builder:setValue(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$RemoveXAttrRequestProto$Builder	setSrc	src_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$RemoveXAttrRequestProto$Builder:setSrc(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$RemoveXAttrRequestProto$Builder	setSrcBytes	src_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$RemoveXAttrRequestProto$Builder:setSrcBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveInfoExpirationProto$Builder	setMillis	millis_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveInfoExpirationProto$Builder:setMillis(long)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveInfoExpirationProto$Builder	setIsRelative	isRelative_	J	boolean	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveInfoExpirationProto$Builder:setIsRelative(boolean)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$PerFileEncryptionInfoProto$Builder	setKey	key_	C	org.apache.hadoop.thirdparty.protobuf.ByteString	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$PerFileEncryptionInfoProto$Builder:setKey(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$PerFileEncryptionInfoProto$Builder	setIv	iv_	C	org.apache.hadoop.thirdparty.protobuf.ByteString	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$PerFileEncryptionInfoProto$Builder:setIv(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$PerFileEncryptionInfoProto$Builder	setEzKeyVersionName	ezKeyVersionName_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$PerFileEncryptionInfoProto$Builder:setEzKeyVersionName(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$PerFileEncryptionInfoProto$Builder	setEzKeyVersionNameBytes	ezKeyVersionName_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$PerFileEncryptionInfoProto$Builder:setEzKeyVersionNameBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCacheDirectiveResponseProto$Builder	setId	id_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCacheDirectiveResponseProto$Builder:setId(long)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SaveNamespaceRequestProto$Builder	setTimeWindow	timeWindow_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SaveNamespaceRequestProto$Builder:setTimeWindow(long)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SaveNamespaceRequestProto$Builder	setTxGap	txGap_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SaveNamespaceRequestProto$Builder:setTxGap(long)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetContentSummaryRequestProto$Builder	setPath	path_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetContentSummaryRequestProto$Builder:setPath(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetContentSummaryRequestProto$Builder	setPathBytes	path_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetContentSummaryRequestProto$Builder:setPathBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveDefaultAclRequestProto$Builder	setSrc	src_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveDefaultAclRequestProto$Builder:setSrc(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveDefaultAclRequestProto$Builder	setSrcBytes	src_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveDefaultAclRequestProto$Builder:setSrcBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$PipelineAckProto$Builder	setSeqno	seqno_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$PipelineAckProto$Builder:setSeqno(long)
org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$PipelineAckProto$Builder	setDownstreamAckTimeNanos	downstreamAckTimeNanos_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$PipelineAckProto$Builder:setDownstreamAckTimeNanos(long)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetPreferredBlockSizeResponseProto$Builder	setBsize	bsize_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetPreferredBlockSizeResponseProto$Builder:setBsize(long)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetOwnerRequestProto$Builder	setSrc	src_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetOwnerRequestProto$Builder:setSrc(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetOwnerRequestProto$Builder	setSrcBytes	src_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetOwnerRequestProto$Builder:setSrcBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetOwnerRequestProto$Builder	setUsername	username_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetOwnerRequestProto$Builder:setUsername(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetOwnerRequestProto$Builder	setUsernameBytes	username_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetOwnerRequestProto$Builder:setUsernameBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetOwnerRequestProto$Builder	setGroupname	groupname_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetOwnerRequestProto$Builder:setGroupname(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetOwnerRequestProto$Builder	setGroupnameBytes	groupname_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetOwnerRequestProto$Builder:setGroupnameBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetBatchedListingResponseProto$Builder	setHasMore	hasMore_	J	boolean	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetBatchedListingResponseProto$Builder:setHasMore(boolean)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetBatchedListingResponseProto$Builder	setStartAfter	startAfter_	C	org.apache.hadoop.thirdparty.protobuf.ByteString	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetBatchedListingResponseProto$Builder:setStartAfter(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetSafeModeResponseProto$Builder	setResult	result_	J	boolean	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetSafeModeResponseProto$Builder:setResult(boolean)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FsyncRequestProto$Builder	setSrc	src_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FsyncRequestProto$Builder:setSrc(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FsyncRequestProto$Builder	setSrcBytes	src_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FsyncRequestProto$Builder:setSrcBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FsyncRequestProto$Builder	setClient	client_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FsyncRequestProto$Builder:setClient(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FsyncRequestProto$Builder	setClientBytes	client_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FsyncRequestProto$Builder:setClientBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FsyncRequestProto$Builder	setLastBlockLength	lastBlockLength_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FsyncRequestProto$Builder:setLastBlockLength(long)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FsyncRequestProto$Builder	setFileId	fileId_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FsyncRequestProto$Builder:setFileId(long)
org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$GetEZForPathRequestProto$Builder	setSrc	src_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$GetEZForPathRequestProto$Builder:setSrc(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$GetEZForPathRequestProto$Builder	setSrcBytes	src_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$GetEZForPathRequestProto$Builder:setSrcBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$TriggerBlockReportRequestProto$Builder	setIncremental	incremental_	J	boolean	0	org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$TriggerBlockReportRequestProto$Builder:setIncremental(boolean)
org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$TriggerBlockReportRequestProto$Builder	setNnAddress	nnAddress_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$TriggerBlockReportRequestProto$Builder:setNnAddress(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$TriggerBlockReportRequestProto$Builder	setNnAddressBytes	nnAddress_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$TriggerBlockReportRequestProto$Builder:setNnAddressBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileLinkInfoRequestProto$Builder	setSrc	src_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileLinkInfoRequestProto$Builder:setSrc(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileLinkInfoRequestProto$Builder	setSrcBytes	src_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileLinkInfoRequestProto$Builder:setSrcBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$CreateEventProto$Builder	setPath	path_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$CreateEventProto$Builder:setPath(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$CreateEventProto$Builder	setPathBytes	path_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$CreateEventProto$Builder:setPathBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$CreateEventProto$Builder	setCtime	ctime_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$CreateEventProto$Builder:setCtime(long)
org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$CreateEventProto$Builder	setOwnerName	ownerName_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$CreateEventProto$Builder:setOwnerName(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$CreateEventProto$Builder	setOwnerNameBytes	ownerName_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$CreateEventProto$Builder:setOwnerNameBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$CreateEventProto$Builder	setGroupName	groupName_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$CreateEventProto$Builder:setGroupName(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$CreateEventProto$Builder	setGroupNameBytes	groupName_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$CreateEventProto$Builder:setGroupNameBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$CreateEventProto$Builder	setReplication	replication_	J	int	0	org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$CreateEventProto$Builder:setReplication(int)
org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$CreateEventProto$Builder	setSymlinkTarget	symlinkTarget_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$CreateEventProto$Builder:setSymlinkTarget(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$CreateEventProto$Builder	setSymlinkTargetBytes	symlinkTarget_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$CreateEventProto$Builder:setSymlinkTargetBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$CreateEventProto$Builder	setOverwrite	overwrite_	J	boolean	0	org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$CreateEventProto$Builder:setOverwrite(boolean)
org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$CreateEventProto$Builder	setDefaultBlockSize	defaultBlockSize_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$CreateEventProto$Builder:setDefaultBlockSize(long)
org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$CreateEventProto$Builder	setErasureCoded	erasureCoded_	J	boolean	0	org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$CreateEventProto$Builder:setErasureCoded(boolean)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$RemoteExceptionProto$Builder	setClassName	className_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$RemoteExceptionProto$Builder:setClassName(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$RemoteExceptionProto$Builder	setClassNameBytes	className_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$RemoteExceptionProto$Builder:setClassNameBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$RemoteExceptionProto$Builder	setMessage	message_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$RemoteExceptionProto$Builder:setMessage(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$RemoteExceptionProto$Builder	setMessageBytes	message_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$RemoteExceptionProto$Builder:setMessageBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCorruptFileBlocksRequestProto$Builder	setPath	path_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCorruptFileBlocksRequestProto$Builder:setPath(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCorruptFileBlocksRequestProto$Builder	setPathBytes	path_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCorruptFileBlocksRequestProto$Builder:setPathBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCorruptFileBlocksRequestProto$Builder	setCookie	cookie_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCorruptFileBlocksRequestProto$Builder:setCookie(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCorruptFileBlocksRequestProto$Builder	setCookieBytes	cookie_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCorruptFileBlocksRequestProto$Builder:setCookieBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$CachingStrategyProto$Builder	setDropBehind	dropBehind_	J	boolean	0	org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$CachingStrategyProto$Builder:setDropBehind(boolean)
org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$CachingStrategyProto$Builder	setReadahead	readahead_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$CachingStrategyProto$Builder:setReadahead(long)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePolicyRequestProto$Builder	setPath	path_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePolicyRequestProto$Builder:setPath(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePolicyRequestProto$Builder	setPathBytes	path_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePolicyRequestProto$Builder:setPathBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetQuotaRequestProto$Builder	setPath	path_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetQuotaRequestProto$Builder:setPath(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetQuotaRequestProto$Builder	setPathBytes	path_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetQuotaRequestProto$Builder:setPathBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetQuotaRequestProto$Builder	setNamespaceQuota	namespaceQuota_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetQuotaRequestProto$Builder:setNamespaceQuota(long)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetQuotaRequestProto$Builder	setStoragespaceQuota	storagespaceQuota_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetQuotaRequestProto$Builder:setStoragespaceQuota(long)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BatchedDirectoryListingProto$Builder	setParentIdx	parentIdx_	J	int	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BatchedDirectoryListingProto$Builder:setParentIdx(int)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsPathHandleProto$Builder	setInodeId	inodeId_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsPathHandleProto$Builder:setInodeId(long)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsPathHandleProto$Builder	setMtime	mtime_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsPathHandleProto$Builder:setMtime(long)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsPathHandleProto$Builder	setPath	path_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsPathHandleProto$Builder:setPath(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsPathHandleProto$Builder	setPathBytes	path_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsPathHandleProto$Builder:setPathBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$EventBatchProto$Builder	setTxid	txid_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$EventBatchProto$Builder:setTxid(long)
org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListEncryptionZonesResponseProto$Builder	setHasMore	hasMore_	J	boolean	0	org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListEncryptionZonesResponseProto$Builder:setHasMore(boolean)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$LocatedBlocksProto$Builder	setFileLength	fileLength_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$LocatedBlocksProto$Builder:setFileLength(long)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$LocatedBlocksProto$Builder	setUnderConstruction	underConstruction_	J	boolean	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$LocatedBlocksProto$Builder:setUnderConstruction(boolean)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$LocatedBlocksProto$Builder	setIsLastBlockComplete	isLastBlockComplete_	J	boolean	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$LocatedBlocksProto$Builder:setIsLastBlockComplete(boolean)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MkdirsResponseProto$Builder	setResult	result_	J	boolean	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MkdirsResponseProto$Builder:setResult(boolean)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CompleteResponseProto$Builder	setResult	result_	J	boolean	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CompleteResponseProto$Builder:setResult(boolean)
org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPolicyRequestProto$Builder	setSrc	src_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPolicyRequestProto$Builder:setSrc(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPolicyRequestProto$Builder	setSrcBytes	src_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPolicyRequestProto$Builder:setSrcBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsStatsResponseProto$Builder	setCapacity	capacity_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsStatsResponseProto$Builder:setCapacity(long)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsStatsResponseProto$Builder	setUsed	used_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsStatsResponseProto$Builder:setUsed(long)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsStatsResponseProto$Builder	setRemaining	remaining_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsStatsResponseProto$Builder:setRemaining(long)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsStatsResponseProto$Builder	setUnderReplicated	underReplicated_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsStatsResponseProto$Builder:setUnderReplicated(long)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsStatsResponseProto$Builder	setCorruptBlocks	corruptBlocks_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsStatsResponseProto$Builder:setCorruptBlocks(long)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsStatsResponseProto$Builder	setMissingBlocks	missingBlocks_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsStatsResponseProto$Builder:setMissingBlocks(long)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsStatsResponseProto$Builder	setMissingReplOneBlocks	missingReplOneBlocks_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsStatsResponseProto$Builder:setMissingReplOneBlocks(long)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsStatsResponseProto$Builder	setBlocksInFuture	blocksInFuture_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsStatsResponseProto$Builder:setBlocksInFuture(long)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsStatsResponseProto$Builder	setPendingDeletionBlocks	pendingDeletionBlocks_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsStatsResponseProto$Builder:setPendingDeletionBlocks(long)
org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$SetXAttrRequestProto$Builder	setSrc	src_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$SetXAttrRequestProto$Builder:setSrc(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$SetXAttrRequestProto$Builder	setSrcBytes	src_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$SetXAttrRequestProto$Builder:setSrcBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$SetXAttrRequestProto$Builder	setFlag	flag_	J	int	0	org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$SetXAttrRequestProto$Builder:setFlag(int)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetEditsFromTxidRequestProto$Builder	setTxid	txid_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetEditsFromTxidRequestProto$Builder:setTxid(long)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetBalancerBandwidthRequestProto$Builder	setBandwidth	bandwidth_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetBalancerBandwidthRequestProto$Builder:setBandwidth(long)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$TruncateRequestProto$Builder	setSrc	src_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$TruncateRequestProto$Builder:setSrc(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$TruncateRequestProto$Builder	setSrcBytes	src_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$TruncateRequestProto$Builder:setSrcBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$TruncateRequestProto$Builder	setNewLength	newLength_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$TruncateRequestProto$Builder:setNewLength(long)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$TruncateRequestProto$Builder	setClientName	clientName_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$TruncateRequestProto$Builder:setClientName(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$TruncateRequestProto$Builder	setClientNameBytes	clientName_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$TruncateRequestProto$Builder:setClientNameBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MetaSaveRequestProto$Builder	setFilename	filename_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MetaSaveRequestProto$Builder:setFilename(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MetaSaveRequestProto$Builder	setFilenameBytes	filename_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MetaSaveRequestProto$Builder:setFilenameBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportCursorProto$Builder	setStartPath	startPath_	C	org.apache.hadoop.thirdparty.protobuf.ByteString	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportCursorProto$Builder:setStartPath(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportCursorProto$Builder	setIndex	index_	J	int	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportCursorProto$Builder:setIndex(int)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetSafeModeRequestProto$Builder	setChecked	checked_	J	boolean	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetSafeModeRequestProto$Builder:setChecked(boolean)
org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$EventProto$Builder	setContents	contents_	C	org.apache.hadoop.thirdparty.protobuf.ByteString	0	org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$EventProto$Builder:setContents(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateRequestProto$Builder	setSrc	src_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateRequestProto$Builder:setSrc(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateRequestProto$Builder	setSrcBytes	src_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateRequestProto$Builder:setSrcBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateRequestProto$Builder	setClientName	clientName_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateRequestProto$Builder:setClientName(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateRequestProto$Builder	setClientNameBytes	clientName_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateRequestProto$Builder:setClientNameBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateRequestProto$Builder	setCreateFlag	createFlag_	J	int	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateRequestProto$Builder:setCreateFlag(int)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateRequestProto$Builder	setCreateParent	createParent_	J	boolean	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateRequestProto$Builder:setCreateParent(boolean)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateRequestProto$Builder	setReplication	replication_	J	int	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateRequestProto$Builder:setReplication(int)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateRequestProto$Builder	setBlockSize	blockSize_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateRequestProto$Builder:setBlockSize(long)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateRequestProto$Builder	setEcPolicyName	ecPolicyName_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateRequestProto$Builder:setEcPolicyName(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateRequestProto$Builder	setEcPolicyNameBytes	ecPolicyName_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateRequestProto$Builder:setEcPolicyNameBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateRequestProto$Builder	setStoragePolicy	storagePolicy_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateRequestProto$Builder:setStoragePolicy(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateRequestProto$Builder	setStoragePolicyBytes	storagePolicy_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateRequestProto$Builder:setStoragePolicyBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSnapshotResponseProto$Builder	setSnapshotPath	snapshotPath_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSnapshotResponseProto$Builder:setSnapshotPath(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSnapshotResponseProto$Builder	setSnapshotPathBytes	snapshotPath_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSnapshotResponseProto$Builder:setSnapshotPathBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetPermissionRequestProto$Builder	setSrc	src_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetPermissionRequestProto$Builder:setSrc(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetPermissionRequestProto$Builder	setSrcBytes	src_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetPermissionRequestProto$Builder:setSrcBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenewLeaseRequestProto$Builder	setClientName	clientName_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenewLeaseRequestProto$Builder:setClientName(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenewLeaseRequestProto$Builder	setClientNameBytes	clientName_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenewLeaseRequestProto$Builder:setClientNameBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$LocatedBlockProto$Builder	setOffset	offset_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$LocatedBlockProto$Builder:setOffset(long)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$LocatedBlockProto$Builder	setCorrupt	corrupt_	J	boolean	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$LocatedBlockProto$Builder:setCorrupt(boolean)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$LocatedBlockProto$Builder	setBlockIndices	blockIndices_	C	org.apache.hadoop.thirdparty.protobuf.ByteString	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$LocatedBlockProto$Builder:setBlockIndices(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetReplicationResponseProto$Builder	setResult	result_	J	boolean	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetReplicationResponseProto$Builder:setResult(boolean)
org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ChecksumProto$Builder	setBytesPerChecksum	bytesPerChecksum_	J	int	0	org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ChecksumProto$Builder:setBytesPerChecksum(int)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeVolumeInfoProto$Builder	setPath	path_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeVolumeInfoProto$Builder:setPath(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeVolumeInfoProto$Builder	setPathBytes	path_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeVolumeInfoProto$Builder:setPathBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeVolumeInfoProto$Builder	setUsedSpace	usedSpace_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeVolumeInfoProto$Builder:setUsedSpace(long)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeVolumeInfoProto$Builder	setFreeSpace	freeSpace_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeVolumeInfoProto$Builder:setFreeSpace(long)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeVolumeInfoProto$Builder	setReservedSpace	reservedSpace_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeVolumeInfoProto$Builder:setReservedSpace(long)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeVolumeInfoProto$Builder	setReservedSpaceForReplicas	reservedSpaceForReplicas_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeVolumeInfoProto$Builder:setReservedSpaceForReplicas(long)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeVolumeInfoProto$Builder	setNumBlocks	numBlocks_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeVolumeInfoProto$Builder:setNumBlocks(long)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$CorruptFileBlocksProto$Builder	setCookie	cookie_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$CorruptFileBlocksProto$Builder:setCookie(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$CorruptFileBlocksProto$Builder	setCookieBytes	cookie_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$CorruptFileBlocksProto$Builder:setCookieBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$AppendEventProto$Builder	setPath	path_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$AppendEventProto$Builder:setPath(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$AppendEventProto$Builder	setPathBytes	path_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$AppendEventProto$Builder:setPathBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$AppendEventProto$Builder	setNewBlock	newBlock_	J	boolean	0	org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$AppendEventProto$Builder:setNewBlock(boolean)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportListingEntryProto$Builder	setFullpath	fullpath_	C	org.apache.hadoop.thirdparty.protobuf.ByteString	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportListingEntryProto$Builder:setFullpath(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportListingEntryProto$Builder	setDirId	dirId_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportListingEntryProto$Builder:setDirId(long)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportListingEntryProto$Builder	setIsReference	isReference_	J	boolean	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportListingEntryProto$Builder:setIsReference(boolean)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportListingEntryProto$Builder	setTargetPath	targetPath_	C	org.apache.hadoop.thirdparty.protobuf.ByteString	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportListingEntryProto$Builder:setTargetPath(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportListingEntryProto$Builder	setFileId	fileId_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportListingEntryProto$Builder:setFileId(long)
org.apache.hadoop.hdfs.protocol.proto.AclProtos$ModifyAclEntriesRequestProto$Builder	setSrc	src_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.AclProtos$ModifyAclEntriesRequestProto$Builder:setSrc(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.AclProtos$ModifyAclEntriesRequestProto$Builder	setSrcBytes	src_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.AclProtos$ModifyAclEntriesRequestProto$Builder:setSrcBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListOpenFilesResponseProto$Builder	setHasMore	hasMore_	J	boolean	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListOpenFilesResponseProto$Builder:setHasMore(boolean)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListOpenFilesRequestProto$Builder	setId	id_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListOpenFilesRequestProto$Builder:setId(long)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListOpenFilesRequestProto$Builder	setPath	path_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListOpenFilesRequestProto$Builder:setPath(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListOpenFilesRequestProto$Builder	setPathBytes	path_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListOpenFilesRequestProto$Builder:setPathBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsReplicatedBlockStatsResponseProto$Builder	setLowRedundancy	lowRedundancy_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsReplicatedBlockStatsResponseProto$Builder:setLowRedundancy(long)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsReplicatedBlockStatsResponseProto$Builder	setCorruptBlocks	corruptBlocks_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsReplicatedBlockStatsResponseProto$Builder:setCorruptBlocks(long)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsReplicatedBlockStatsResponseProto$Builder	setMissingBlocks	missingBlocks_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsReplicatedBlockStatsResponseProto$Builder:setMissingBlocks(long)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsReplicatedBlockStatsResponseProto$Builder	setMissingReplOneBlocks	missingReplOneBlocks_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsReplicatedBlockStatsResponseProto$Builder:setMissingReplOneBlocks(long)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsReplicatedBlockStatsResponseProto$Builder	setBlocksInFuture	blocksInFuture_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsReplicatedBlockStatsResponseProto$Builder:setBlocksInFuture(long)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsReplicatedBlockStatsResponseProto$Builder	setPendingDeletionBlocks	pendingDeletionBlocks_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsReplicatedBlockStatsResponseProto$Builder:setPendingDeletionBlocks(long)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsReplicatedBlockStatsResponseProto$Builder	setHighestPrioLowRedundancyBlocks	highestPrioLowRedundancyBlocks_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsReplicatedBlockStatsResponseProto$Builder:setHighestPrioLowRedundancyBlocks(long)
org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DeleteBlockPoolRequestProto$Builder	setBlockPool	blockPool_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DeleteBlockPoolRequestProto$Builder:setBlockPool(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DeleteBlockPoolRequestProto$Builder	setBlockPoolBytes	blockPool_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DeleteBlockPoolRequestProto$Builder:setBlockPoolBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DeleteBlockPoolRequestProto$Builder	setForce	force_	J	boolean	0	org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DeleteBlockPoolRequestProto$Builder:setForce(boolean)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MkdirsRequestProto$Builder	setSrc	src_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MkdirsRequestProto$Builder:setSrc(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MkdirsRequestProto$Builder	setSrcBytes	src_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MkdirsRequestProto$Builder:setSrcBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MkdirsRequestProto$Builder	setCreateParent	createParent_	J	boolean	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MkdirsRequestProto$Builder:setCreateParent(boolean)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AppendRequestProto$Builder	setSrc	src_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AppendRequestProto$Builder:setSrc(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AppendRequestProto$Builder	setSrcBytes	src_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AppendRequestProto$Builder:setSrcBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AppendRequestProto$Builder	setClientName	clientName_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AppendRequestProto$Builder:setClientName(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AppendRequestProto$Builder	setClientNameBytes	clientName_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AppendRequestProto$Builder:setClientNameBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AppendRequestProto$Builder	setFlag	flag_	J	int	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AppendRequestProto$Builder:setFlag(int)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollingUpgradeInfoProto$Builder	setStartTime	startTime_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollingUpgradeInfoProto$Builder:setStartTime(long)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollingUpgradeInfoProto$Builder	setFinalizeTime	finalizeTime_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollingUpgradeInfoProto$Builder:setFinalizeTime(long)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollingUpgradeInfoProto$Builder	setCreatedRollbackImages	createdRollbackImages_	J	boolean	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollingUpgradeInfoProto$Builder:setCreatedRollbackImages(boolean)
org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetReplicaVisibleLengthResponseProto$Builder	setLength	length_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetReplicaVisibleLengthResponseProto$Builder:setLength(long)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$RollingUpgradeStatusProto$Builder	setBlockPoolId	blockPoolId_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$RollingUpgradeStatusProto$Builder:setBlockPoolId(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$RollingUpgradeStatusProto$Builder	setBlockPoolIdBytes	blockPoolId_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$RollingUpgradeStatusProto$Builder:setBlockPoolIdBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$RollingUpgradeStatusProto$Builder	setFinalized	finalized_	J	boolean	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$RollingUpgradeStatusProto$Builder:setFinalized(boolean)
org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ReadOpChecksumInfoProto$Builder	setChunkOffset	chunkOffset_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ReadOpChecksumInfoProto$Builder:setChunkOffset(long)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BatchedListingKeyProto$Builder	setChecksum	checksum_	C	org.apache.hadoop.thirdparty.protobuf.ByteString	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BatchedListingKeyProto$Builder:setChecksum(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BatchedListingKeyProto$Builder	setPathIndex	pathIndex_	J	int	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BatchedListingKeyProto$Builder:setPathIndex(int)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BatchedListingKeyProto$Builder	setStartAfter	startAfter_	C	org.apache.hadoop.thirdparty.protobuf.ByteString	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BatchedListingKeyProto$Builder:setStartAfter(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ECSchemaProto$Builder	setCodecName	codecName_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ECSchemaProto$Builder:setCodecName(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ECSchemaProto$Builder	setCodecNameBytes	codecName_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ECSchemaProto$Builder:setCodecNameBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ECSchemaProto$Builder	setDataUnits	dataUnits_	J	int	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ECSchemaProto$Builder:setDataUnits(int)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ECSchemaProto$Builder	setParityUnits	parityUnits_	J	int	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ECSchemaProto$Builder:setParityUnits(int)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CompleteRequestProto$Builder	setSrc	src_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CompleteRequestProto$Builder:setSrc(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CompleteRequestProto$Builder	setSrcBytes	src_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CompleteRequestProto$Builder:setSrcBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CompleteRequestProto$Builder	setClientName	clientName_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CompleteRequestProto$Builder:setClientName(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CompleteRequestProto$Builder	setClientNameBytes	clientName_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CompleteRequestProto$Builder:setClientNameBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CompleteRequestProto$Builder	setFileId	fileId_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CompleteRequestProto$Builder:setFileId(long)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetReplicationRequestProto$Builder	setSrc	src_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetReplicationRequestProto$Builder:setSrc(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetReplicationRequestProto$Builder	setSrcBytes	src_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetReplicationRequestProto$Builder:setSrcBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetReplicationRequestProto$Builder	setReplication	replication_	J	int	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetReplicationRequestProto$Builder:setReplication(int)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SatisfyStoragePolicyRequestProto$Builder	setSrc	src_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SatisfyStoragePolicyRequestProto$Builder:setSrc(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SatisfyStoragePolicyRequestProto$Builder	setSrcBytes	src_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SatisfyStoragePolicyRequestProto$Builder:setSrcBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpWriteBlockProto$Builder	setPipelineSize	pipelineSize_	J	int	0	org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpWriteBlockProto$Builder:setPipelineSize(int)
org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpWriteBlockProto$Builder	setMinBytesRcvd	minBytesRcvd_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpWriteBlockProto$Builder:setMinBytesRcvd(long)
org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpWriteBlockProto$Builder	setMaxBytesRcvd	maxBytesRcvd_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpWriteBlockProto$Builder:setMaxBytesRcvd(long)
org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpWriteBlockProto$Builder	setLatestGenerationStamp	latestGenerationStamp_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpWriteBlockProto$Builder:setLatestGenerationStamp(long)
org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpWriteBlockProto$Builder	setAllowLazyPersist	allowLazyPersist_	J	boolean	0	org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpWriteBlockProto$Builder:setAllowLazyPersist(boolean)
org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpWriteBlockProto$Builder	setPinning	pinning_	J	boolean	0	org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpWriteBlockProto$Builder:setPinning(boolean)
org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpWriteBlockProto$Builder	setStorageId	storageId_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpWriteBlockProto$Builder:setStorageId(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpWriteBlockProto$Builder	setStorageIdBytes	storageId_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpWriteBlockProto$Builder:setStorageIdBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportEntryProto$Builder	setFullpath	fullpath_	C	org.apache.hadoop.thirdparty.protobuf.ByteString	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportEntryProto$Builder:setFullpath(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportEntryProto$Builder	setModificationLabel	modificationLabel_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportEntryProto$Builder:setModificationLabel(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportEntryProto$Builder	setModificationLabelBytes	modificationLabel_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportEntryProto$Builder:setModificationLabelBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportEntryProto$Builder	setTargetPath	targetPath_	C	org.apache.hadoop.thirdparty.protobuf.ByteString	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportEntryProto$Builder:setTargetPath(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLinkTargetRequestProto$Builder	setPath	path_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLinkTargetRequestProto$Builder:setPath(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLinkTargetRequestProto$Builder	setPathBytes	path_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLinkTargetRequestProto$Builder:setPathBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$CancelPlanRequestProto$Builder	setPlanID	planID_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$CancelPlanRequestProto$Builder:setPlanID(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$CancelPlanRequestProto$Builder	setPlanIDBytes	planID_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$CancelPlanRequestProto$Builder:setPlanIDBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCacheDirectiveRequestProto$Builder	setCacheFlags	cacheFlags_	J	int	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCacheDirectiveRequestProto$Builder:setCacheFlags(int)
org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpCustomProto$Builder	setCustomId	customId_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpCustomProto$Builder:setCustomId(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpCustomProto$Builder	setCustomIdBytes	customId_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpCustomProto$Builder:setCustomIdBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ECSchemaOptionEntryProto$Builder	setKey	key_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ECSchemaOptionEntryProto$Builder:setKey(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ECSchemaOptionEntryProto$Builder	setKeyBytes	key_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ECSchemaOptionEntryProto$Builder:setKeyBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ECSchemaOptionEntryProto$Builder	setValue	value_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ECSchemaOptionEntryProto$Builder:setValue(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ECSchemaOptionEntryProto$Builder	setValueBytes	value_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ECSchemaOptionEntryProto$Builder:setValueBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSnapshotRequestProto$Builder	setSnapshotRoot	snapshotRoot_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSnapshotRequestProto$Builder:setSnapshotRoot(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSnapshotRequestProto$Builder	setSnapshotRootBytes	snapshotRoot_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSnapshotRequestProto$Builder:setSnapshotRootBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSnapshotRequestProto$Builder	setSnapshotName	snapshotName_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSnapshotRequestProto$Builder:setSnapshotName(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSnapshotRequestProto$Builder	setSnapshotNameBytes	snapshotName_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSnapshotRequestProto$Builder:setSnapshotNameBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DisallowSnapshotRequestProto$Builder	setSnapshotRoot	snapshotRoot_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DisallowSnapshotRequestProto$Builder:setSnapshotRoot(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DisallowSnapshotRequestProto$Builder	setSnapshotRootBytes	snapshotRoot_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DisallowSnapshotRequestProto$Builder:setSnapshotRootBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$UnlinkEventProto$Builder	setPath	path_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$UnlinkEventProto$Builder:setPath(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$UnlinkEventProto$Builder	setPathBytes	path_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$UnlinkEventProto$Builder:setPathBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$UnlinkEventProto$Builder	setTimestamp	timestamp_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$UnlinkEventProto$Builder:setTimestamp(long)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$Rename2RequestProto$Builder	setSrc	src_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$Rename2RequestProto$Builder:setSrc(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$Rename2RequestProto$Builder	setSrcBytes	src_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$Rename2RequestProto$Builder:setSrcBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$Rename2RequestProto$Builder	setDst	dst_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$Rename2RequestProto$Builder:setDst(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$Rename2RequestProto$Builder	setDstBytes	dst_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$Rename2RequestProto$Builder:setDstBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$Rename2RequestProto$Builder	setOverwriteDest	overwriteDest_	J	boolean	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$Rename2RequestProto$Builder:setOverwriteDest(boolean)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$Rename2RequestProto$Builder	setMoveToTrash	moveToTrash_	J	boolean	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$Rename2RequestProto$Builder:setMoveToTrash(boolean)
org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpBlockGroupChecksumProto$Builder	setRequestedNumBytes	requestedNumBytes_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpBlockGroupChecksumProto$Builder:setRequestedNumBytes(long)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetQuotaUsageRequestProto$Builder	setPath	path_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetQuotaUsageRequestProto$Builder:setPath(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetQuotaUsageRequestProto$Builder	setPathBytes	path_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetQuotaUsageRequestProto$Builder:setPathBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCacheDirectivesResponseProto$Builder	setHasMore	hasMore_	J	boolean	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCacheDirectivesResponseProto$Builder:setHasMore(boolean)
org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitShmIdProto$Builder	setHi	hi_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitShmIdProto$Builder:setHi(long)
org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitShmIdProto$Builder	setLo	lo_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitShmIdProto$Builder:setLo(long)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$QuotaUsageProto$Builder	setFileAndDirectoryCount	fileAndDirectoryCount_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$QuotaUsageProto$Builder:setFileAndDirectoryCount(long)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$QuotaUsageProto$Builder	setQuota	quota_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$QuotaUsageProto$Builder:setQuota(long)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$QuotaUsageProto$Builder	setSpaceConsumed	spaceConsumed_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$QuotaUsageProto$Builder:setSpaceConsumed(long)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$QuotaUsageProto$Builder	setSpaceQuota	spaceQuota_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$QuotaUsageProto$Builder:setSpaceQuota(long)
org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclEntriesRequestProto$Builder	setSrc	src_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclEntriesRequestProto$Builder:setSrc(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclEntriesRequestProto$Builder	setSrcBytes	src_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclEntriesRequestProto$Builder:setSrcBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageTypeQuotaInfoProto$Builder	setQuota	quota_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageTypeQuotaInfoProto$Builder:setQuota(long)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageTypeQuotaInfoProto$Builder	setConsumed	consumed_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageTypeQuotaInfoProto$Builder:setConsumed(long)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdatePipelineRequestProto$Builder	setClientName	clientName_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdatePipelineRequestProto$Builder:setClientName(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdatePipelineRequestProto$Builder	setClientNameBytes	clientName_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdatePipelineRequestProto$Builder:setClientNameBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshottableDirectoryStatusProto$Builder	setSnapshotQuota	snapshotQuota_	J	int	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshottableDirectoryStatusProto$Builder:setSnapshotQuota(int)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshottableDirectoryStatusProto$Builder	setSnapshotNumber	snapshotNumber_	J	int	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshottableDirectoryStatusProto$Builder:setSnapshotNumber(int)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshottableDirectoryStatusProto$Builder	setParentFullpath	parentFullpath_	C	org.apache.hadoop.thirdparty.protobuf.ByteString	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshottableDirectoryStatusProto$Builder:setParentFullpath(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$RemoveErasureCodingPolicyRequestProto$Builder	setEcPolicyName	ecPolicyName_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$RemoveErasureCodingPolicyRequestProto$Builder:setEcPolicyName(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$RemoveErasureCodingPolicyRequestProto$Builder	setEcPolicyNameBytes	ecPolicyName_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$RemoveErasureCodingPolicyRequestProto$Builder:setEcPolicyNameBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ShutdownDatanodeRequestProto$Builder	setForUpgrade	forUpgrade_	J	boolean	0	org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ShutdownDatanodeRequestProto$Builder:setForUpgrade(boolean)
org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$ListXAttrsRequestProto$Builder	setSrc	src_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$ListXAttrsRequestProto$Builder:setSrc(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$ListXAttrsRequestProto$Builder	setSrcBytes	src_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$ListXAttrsRequestProto$Builder:setSrcBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeInfoProto$Builder	setCapacity	capacity_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeInfoProto$Builder:setCapacity(long)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeInfoProto$Builder	setDfsUsed	dfsUsed_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeInfoProto$Builder:setDfsUsed(long)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeInfoProto$Builder	setRemaining	remaining_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeInfoProto$Builder:setRemaining(long)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeInfoProto$Builder	setBlockPoolUsed	blockPoolUsed_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeInfoProto$Builder:setBlockPoolUsed(long)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeInfoProto$Builder	setLastUpdate	lastUpdate_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeInfoProto$Builder:setLastUpdate(long)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeInfoProto$Builder	setXceiverCount	xceiverCount_	J	int	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeInfoProto$Builder:setXceiverCount(int)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeInfoProto$Builder	setLocation	location_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeInfoProto$Builder:setLocation(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeInfoProto$Builder	setLocationBytes	location_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeInfoProto$Builder:setLocationBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeInfoProto$Builder	setNonDfsUsed	nonDfsUsed_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeInfoProto$Builder:setNonDfsUsed(long)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeInfoProto$Builder	setCacheCapacity	cacheCapacity_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeInfoProto$Builder:setCacheCapacity(long)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeInfoProto$Builder	setCacheUsed	cacheUsed_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeInfoProto$Builder:setCacheUsed(long)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeInfoProto$Builder	setLastUpdateMonotonic	lastUpdateMonotonic_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeInfoProto$Builder:setLastUpdateMonotonic(long)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeInfoProto$Builder	setUpgradeDomain	upgradeDomain_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeInfoProto$Builder:setUpgradeDomain(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeInfoProto$Builder	setUpgradeDomainBytes	upgradeDomain_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeInfoProto$Builder:setUpgradeDomainBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeInfoProto$Builder	setLastBlockReportTime	lastBlockReportTime_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeInfoProto$Builder:setLastBlockReportTime(long)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeInfoProto$Builder	setLastBlockReportMonotonic	lastBlockReportMonotonic_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeInfoProto$Builder:setLastBlockReportMonotonic(long)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeInfoProto$Builder	setNumBlocks	numBlocks_	J	int	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeInfoProto$Builder:setNumBlocks(int)
org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusResponseProto$Builder	setStartTime	startTime_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusResponseProto$Builder:setStartTime(long)
org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusResponseProto$Builder	setEndTime	endTime_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusResponseProto$Builder:setEndTime(long)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockStoragePolicyProto$Builder	setPolicyId	policyId_	J	int	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockStoragePolicyProto$Builder:setPolicyId(int)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockStoragePolicyProto$Builder	setName	name_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockStoragePolicyProto$Builder:setName(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockStoragePolicyProto$Builder	setNameBytes	name_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockStoragePolicyProto$Builder:setNameBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitShmResponseProto$Builder	setError	error_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitShmResponseProto$Builder:setError(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitShmResponseProto$Builder	setErrorBytes	error_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitShmResponseProto$Builder:setErrorBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageReportProto$Builder	setStorageUuid	storageUuid_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageReportProto$Builder:setStorageUuid(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageReportProto$Builder	setStorageUuidBytes	storageUuid_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageReportProto$Builder:setStorageUuidBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageReportProto$Builder	setFailed	failed_	J	boolean	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageReportProto$Builder:setFailed(boolean)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageReportProto$Builder	setCapacity	capacity_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageReportProto$Builder:setCapacity(long)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageReportProto$Builder	setDfsUsed	dfsUsed_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageReportProto$Builder:setDfsUsed(long)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageReportProto$Builder	setRemaining	remaining_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageReportProto$Builder:setRemaining(long)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageReportProto$Builder	setBlockPoolUsed	blockPoolUsed_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageReportProto$Builder:setBlockPoolUsed(long)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageReportProto$Builder	setNonDfsUsed	nonDfsUsed_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageReportProto$Builder:setNonDfsUsed(long)
org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$RenameEventProto$Builder	setSrcPath	srcPath_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$RenameEventProto$Builder:setSrcPath(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$RenameEventProto$Builder	setSrcPathBytes	srcPath_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$RenameEventProto$Builder:setSrcPathBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$RenameEventProto$Builder	setDestPath	destPath_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$RenameEventProto$Builder:setDestPath(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$RenameEventProto$Builder	setDestPathBytes	destPath_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$RenameEventProto$Builder:setDestPathBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$RenameEventProto$Builder	setTimestamp	timestamp_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$RenameEventProto$Builder:setTimestamp(long)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$OpenFilesBatchResponseProto$Builder	setId	id_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$OpenFilesBatchResponseProto$Builder:setId(long)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$OpenFilesBatchResponseProto$Builder	setPath	path_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$OpenFilesBatchResponseProto$Builder:setPath(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$OpenFilesBatchResponseProto$Builder	setPathBytes	path_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$OpenFilesBatchResponseProto$Builder:setPathBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$OpenFilesBatchResponseProto$Builder	setClientName	clientName_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$OpenFilesBatchResponseProto$Builder:setClientName(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$OpenFilesBatchResponseProto$Builder	setClientNameBytes	clientName_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$OpenFilesBatchResponseProto$Builder:setClientNameBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$OpenFilesBatchResponseProto$Builder	setClientMachine	clientMachine_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$OpenFilesBatchResponseProto$Builder:setClientMachine(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$OpenFilesBatchResponseProto$Builder	setClientMachineBytes	clientMachine_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$OpenFilesBatchResponseProto$Builder:setClientMachineBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$FileEncryptionInfoProto$Builder	setKey	key_	C	org.apache.hadoop.thirdparty.protobuf.ByteString	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$FileEncryptionInfoProto$Builder:setKey(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$FileEncryptionInfoProto$Builder	setIv	iv_	C	org.apache.hadoop.thirdparty.protobuf.ByteString	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$FileEncryptionInfoProto$Builder:setIv(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$FileEncryptionInfoProto$Builder	setKeyName	keyName_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$FileEncryptionInfoProto$Builder:setKeyName(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$FileEncryptionInfoProto$Builder	setKeyNameBytes	keyName_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$FileEncryptionInfoProto$Builder:setKeyNameBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$FileEncryptionInfoProto$Builder	setEzKeyVersionName	ezKeyVersionName_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$FileEncryptionInfoProto$Builder:setEzKeyVersionName(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$FileEncryptionInfoProto$Builder	setEzKeyVersionNameBytes	ezKeyVersionName_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$FileEncryptionInfoProto$Builder:setEzKeyVersionNameBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DirectoryListingProto$Builder	setRemainingEntries	remainingEntries_	J	int	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DirectoryListingProto$Builder:setRemainingEntries(int)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsFileStatusProto$Builder	setPath	path_	C	org.apache.hadoop.thirdparty.protobuf.ByteString	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsFileStatusProto$Builder:setPath(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsFileStatusProto$Builder	setLength	length_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsFileStatusProto$Builder:setLength(long)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsFileStatusProto$Builder	setOwner	owner_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsFileStatusProto$Builder:setOwner(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsFileStatusProto$Builder	setOwnerBytes	owner_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsFileStatusProto$Builder:setOwnerBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsFileStatusProto$Builder	setGroup	group_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsFileStatusProto$Builder:setGroup(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsFileStatusProto$Builder	setGroupBytes	group_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsFileStatusProto$Builder:setGroupBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsFileStatusProto$Builder	setModificationTime	modificationTime_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsFileStatusProto$Builder:setModificationTime(long)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsFileStatusProto$Builder	setAccessTime	accessTime_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsFileStatusProto$Builder:setAccessTime(long)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsFileStatusProto$Builder	setSymlink	symlink_	C	org.apache.hadoop.thirdparty.protobuf.ByteString	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsFileStatusProto$Builder:setSymlink(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsFileStatusProto$Builder	setBlockReplication	blockReplication_	J	int	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsFileStatusProto$Builder:setBlockReplication(int)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsFileStatusProto$Builder	setBlocksize	blocksize_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsFileStatusProto$Builder:setBlocksize(long)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsFileStatusProto$Builder	setFileId	fileId_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsFileStatusProto$Builder:setFileId(long)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsFileStatusProto$Builder	setChildrenNum	childrenNum_	J	int	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsFileStatusProto$Builder:setChildrenNum(int)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsFileStatusProto$Builder	setStoragePolicy	storagePolicy_	J	int	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsFileStatusProto$Builder:setStoragePolicy(int)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsFileStatusProto$Builder	setFlags	flags_	J	int	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsFileStatusProto$Builder:setFlags(int)
org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$SubmitDiskBalancerPlanRequestProto$Builder	setPlanID	planID_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$SubmitDiskBalancerPlanRequestProto$Builder:setPlanID(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$SubmitDiskBalancerPlanRequestProto$Builder	setPlanIDBytes	planID_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$SubmitDiskBalancerPlanRequestProto$Builder:setPlanIDBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$SubmitDiskBalancerPlanRequestProto$Builder	setPlan	plan_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$SubmitDiskBalancerPlanRequestProto$Builder:setPlan(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$SubmitDiskBalancerPlanRequestProto$Builder	setPlanBytes	plan_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$SubmitDiskBalancerPlanRequestProto$Builder:setPlanBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$SubmitDiskBalancerPlanRequestProto$Builder	setPlanVersion	planVersion_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$SubmitDiskBalancerPlanRequestProto$Builder:setPlanVersion(long)
org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$SubmitDiskBalancerPlanRequestProto$Builder	setIgnoreDateCheck	ignoreDateCheck_	J	boolean	0	org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$SubmitDiskBalancerPlanRequestProto$Builder:setIgnoreDateCheck(boolean)
org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$SubmitDiskBalancerPlanRequestProto$Builder	setPlanFile	planFile_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$SubmitDiskBalancerPlanRequestProto$Builder:setPlanFile(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$SubmitDiskBalancerPlanRequestProto$Builder	setPlanFileBytes	planFile_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$SubmitDiskBalancerPlanRequestProto$Builder:setPlanFileBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$EnableErasureCodingPolicyRequestProto$Builder	setEcPolicyName	ecPolicyName_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$EnableErasureCodingPolicyRequestProto$Builder:setEcPolicyName(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$EnableErasureCodingPolicyRequestProto$Builder	setEcPolicyNameBytes	ecPolicyName_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$EnableErasureCodingPolicyRequestProto$Builder:setEcPolicyNameBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetBatchedListingRequestProto$Builder	setStartAfter	startAfter_	C	org.apache.hadoop.thirdparty.protobuf.ByteString	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetBatchedListingRequestProto$Builder:setStartAfter(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetBatchedListingRequestProto$Builder	setNeedLocation	needLocation_	J	boolean	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetBatchedListingRequestProto$Builder:setNeedLocation(boolean)
org.apache.hadoop.hdfs.protocol.proto.AclProtos$FsPermissionProto$Builder	setPerm	perm_	J	int	0	org.apache.hadoop.hdfs.protocol.proto.AclProtos$FsPermissionProto$Builder:setPerm(int)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameResponseProto$Builder	setResult	result_	J	boolean	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameResponseProto$Builder:setResult(boolean)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ErasureCodingPolicyProto$Builder	setName	name_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ErasureCodingPolicyProto$Builder:setName(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ErasureCodingPolicyProto$Builder	setNameBytes	name_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ErasureCodingPolicyProto$Builder:setNameBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ErasureCodingPolicyProto$Builder	setCellSize	cellSize_	J	int	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ErasureCodingPolicyProto$Builder:setCellSize(int)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ErasureCodingPolicyProto$Builder	setId	id_	J	int	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ErasureCodingPolicyProto$Builder:setId(int)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RecoverLeaseResponseProto$Builder	setResult	result_	J	boolean	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RecoverLeaseResponseProto$Builder:setResult(boolean)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollEditsResponseProto$Builder	setNewSegmentTxId	newSegmentTxId_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollEditsResponseProto$Builder:setNewSegmentTxId(long)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsECBlockGroupStatsResponseProto$Builder	setLowRedundancy	lowRedundancy_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsECBlockGroupStatsResponseProto$Builder:setLowRedundancy(long)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsECBlockGroupStatsResponseProto$Builder	setCorruptBlocks	corruptBlocks_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsECBlockGroupStatsResponseProto$Builder:setCorruptBlocks(long)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsECBlockGroupStatsResponseProto$Builder	setMissingBlocks	missingBlocks_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsECBlockGroupStatsResponseProto$Builder:setMissingBlocks(long)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsECBlockGroupStatsResponseProto$Builder	setBlocksInFuture	blocksInFuture_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsECBlockGroupStatsResponseProto$Builder:setBlocksInFuture(long)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsECBlockGroupStatsResponseProto$Builder	setPendingDeletionBlocks	pendingDeletionBlocks_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsECBlockGroupStatsResponseProto$Builder:setPendingDeletionBlocks(long)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsECBlockGroupStatsResponseProto$Builder	setHighestPrioLowRedundancyBlocks	highestPrioLowRedundancyBlocks_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsECBlockGroupStatsResponseProto$Builder:setHighestPrioLowRedundancyBlocks(long)
org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$DataTransferEncryptorMessageProto$Builder	setPayload	payload_	C	org.apache.hadoop.thirdparty.protobuf.ByteString	0	org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$DataTransferEncryptorMessageProto$Builder:setPayload(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$DataTransferEncryptorMessageProto$Builder	setMessage	message_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$DataTransferEncryptorMessageProto$Builder:setMessage(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$DataTransferEncryptorMessageProto$Builder	setMessageBytes	message_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$DataTransferEncryptorMessageProto$Builder:setMessageBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$DataTransferEncryptorMessageProto$Builder	setAccessTokenError	accessTokenError_	J	boolean	0	org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$DataTransferEncryptorMessageProto$Builder:setAccessTokenError(boolean)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameSnapshotRequestProto$Builder	setSnapshotRoot	snapshotRoot_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameSnapshotRequestProto$Builder:setSnapshotRoot(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameSnapshotRequestProto$Builder	setSnapshotRootBytes	snapshotRoot_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameSnapshotRequestProto$Builder:setSnapshotRootBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameSnapshotRequestProto$Builder	setSnapshotOldName	snapshotOldName_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameSnapshotRequestProto$Builder:setSnapshotOldName(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameSnapshotRequestProto$Builder	setSnapshotOldNameBytes	snapshotOldName_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameSnapshotRequestProto$Builder:setSnapshotOldNameBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameSnapshotRequestProto$Builder	setSnapshotNewName	snapshotNewName_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameSnapshotRequestProto$Builder:setSnapshotNewName(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameSnapshotRequestProto$Builder	setSnapshotNewNameBytes	snapshotNewName_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameSnapshotRequestProto$Builder:setSnapshotNewNameBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBalancerBandwidthResponseProto$Builder	setBandwidth	bandwidth_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBalancerBandwidthResponseProto$Builder:setBandwidth(long)
org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$BlockOpResponseProto$Builder	setFirstBadLink	firstBadLink_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$BlockOpResponseProto$Builder:setFirstBadLink(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$BlockOpResponseProto$Builder	setFirstBadLinkBytes	firstBadLink_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$BlockOpResponseProto$Builder:setFirstBadLinkBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$BlockOpResponseProto$Builder	setMessage	message_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$BlockOpResponseProto$Builder:setMessage(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$BlockOpResponseProto$Builder	setMessageBytes	message_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$BlockOpResponseProto$Builder:setMessageBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$BlockOpResponseProto$Builder	setShortCircuitAccessVersion	shortCircuitAccessVersion_	J	int	0	org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$BlockOpResponseProto$Builder:setShortCircuitAccessVersion(int)
org.apache.hadoop.hdfs.protocol.proto.AclProtos$AclStatusProto$Builder	setOwner	owner_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.AclProtos$AclStatusProto$Builder:setOwner(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.AclProtos$AclStatusProto$Builder	setOwnerBytes	owner_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.AclProtos$AclStatusProto$Builder:setOwnerBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.AclProtos$AclStatusProto$Builder	setGroup	group_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.AclProtos$AclStatusProto$Builder:setGroup(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.AclProtos$AclStatusProto$Builder	setGroupBytes	group_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.AclProtos$AclStatusProto$Builder:setGroupBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.AclProtos$AclStatusProto$Builder	setSticky	sticky_	J	boolean	0	org.apache.hadoop.hdfs.protocol.proto.AclProtos$AclStatusProto$Builder:setSticky(boolean)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$FsServerDefaultsProto$Builder	setBlockSize	blockSize_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$FsServerDefaultsProto$Builder:setBlockSize(long)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$FsServerDefaultsProto$Builder	setBytesPerChecksum	bytesPerChecksum_	J	int	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$FsServerDefaultsProto$Builder:setBytesPerChecksum(int)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$FsServerDefaultsProto$Builder	setWritePacketSize	writePacketSize_	J	int	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$FsServerDefaultsProto$Builder:setWritePacketSize(int)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$FsServerDefaultsProto$Builder	setReplication	replication_	J	int	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$FsServerDefaultsProto$Builder:setReplication(int)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$FsServerDefaultsProto$Builder	setFileBufferSize	fileBufferSize_	J	int	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$FsServerDefaultsProto$Builder:setFileBufferSize(int)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$FsServerDefaultsProto$Builder	setEncryptDataTransfer	encryptDataTransfer_	J	boolean	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$FsServerDefaultsProto$Builder:setEncryptDataTransfer(boolean)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$FsServerDefaultsProto$Builder	setTrashInterval	trashInterval_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$FsServerDefaultsProto$Builder:setTrashInterval(long)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$FsServerDefaultsProto$Builder	setKeyProviderUri	keyProviderUri_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$FsServerDefaultsProto$Builder:setKeyProviderUri(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$FsServerDefaultsProto$Builder	setKeyProviderUriBytes	keyProviderUri_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$FsServerDefaultsProto$Builder:setKeyProviderUriBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$FsServerDefaultsProto$Builder	setPolicyId	policyId_	J	int	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$FsServerDefaultsProto$Builder:setPolicyId(int)
org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBlockLocalPathInfoResponseProto$Builder	setLocalPath	localPath_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBlockLocalPathInfoResponseProto$Builder:setLocalPath(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBlockLocalPathInfoResponseProto$Builder	setLocalPathBytes	localPath_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBlockLocalPathInfoResponseProto$Builder:setLocalPathBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBlockLocalPathInfoResponseProto$Builder	setLocalMetaPath	localMetaPath_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBlockLocalPathInfoResponseProto$Builder:setLocalMetaPath(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBlockLocalPathInfoResponseProto$Builder	setLocalMetaPathBytes	localMetaPath_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBlockLocalPathInfoResponseProto$Builder:setLocalMetaPathBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$CipherOptionProto$Builder	setInKey	inKey_	C	org.apache.hadoop.thirdparty.protobuf.ByteString	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$CipherOptionProto$Builder:setInKey(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$CipherOptionProto$Builder	setInIv	inIv_	C	org.apache.hadoop.thirdparty.protobuf.ByteString	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$CipherOptionProto$Builder:setInIv(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$CipherOptionProto$Builder	setOutKey	outKey_	C	org.apache.hadoop.thirdparty.protobuf.ByteString	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$CipherOptionProto$Builder:setOutKey(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$CipherOptionProto$Builder	setOutIv	outIv_	C	org.apache.hadoop.thirdparty.protobuf.ByteString	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$CipherOptionProto$Builder:setOutIv(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLinkTargetResponseProto$Builder	setTargetPath	targetPath_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLinkTargetResponseProto$Builder:setTargetPath(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLinkTargetResponseProto$Builder	setTargetPathBytes	targetPath_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLinkTargetResponseProto$Builder:setTargetPathBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeIDProto$Builder	setIpAddr	ipAddr_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeIDProto$Builder:setIpAddr(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeIDProto$Builder	setIpAddrBytes	ipAddr_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeIDProto$Builder:setIpAddrBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeIDProto$Builder	setHostName	hostName_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeIDProto$Builder:setHostName(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeIDProto$Builder	setHostNameBytes	hostName_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeIDProto$Builder:setHostNameBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeIDProto$Builder	setDatanodeUuid	datanodeUuid_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeIDProto$Builder:setDatanodeUuid(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeIDProto$Builder	setDatanodeUuidBytes	datanodeUuid_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeIDProto$Builder:setDatanodeUuidBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeIDProto$Builder	setXferPort	xferPort_	J	int	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeIDProto$Builder:setXferPort(int)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeIDProto$Builder	setInfoPort	infoPort_	J	int	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeIDProto$Builder:setInfoPort(int)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeIDProto$Builder	setIpcPort	ipcPort_	J	int	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeIDProto$Builder:setIpcPort(int)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeIDProto$Builder	setInfoSecurePort	infoSecurePort_	J	int	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeIDProto$Builder:setInfoSecurePort(int)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCachePoolsRequestProto$Builder	setPrevPoolName	prevPoolName_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCachePoolsRequestProto$Builder:setPrevPoolName(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCachePoolsRequestProto$Builder	setPrevPoolNameBytes	prevPoolName_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCachePoolsRequestProto$Builder:setPrevPoolNameBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RecoverLeaseRequestProto$Builder	setSrc	src_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RecoverLeaseRequestProto$Builder:setSrc(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RecoverLeaseRequestProto$Builder	setSrcBytes	src_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RecoverLeaseRequestProto$Builder:setSrcBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RecoverLeaseRequestProto$Builder	setClientName	clientName_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RecoverLeaseRequestProto$Builder:setClientName(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RecoverLeaseRequestProto$Builder	setClientNameBytes	clientName_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RecoverLeaseRequestProto$Builder:setClientNameBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DataEncryptionKeyProto$Builder	setKeyId	keyId_	J	int	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DataEncryptionKeyProto$Builder:setKeyId(int)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DataEncryptionKeyProto$Builder	setBlockPoolId	blockPoolId_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DataEncryptionKeyProto$Builder:setBlockPoolId(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DataEncryptionKeyProto$Builder	setBlockPoolIdBytes	blockPoolId_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DataEncryptionKeyProto$Builder:setBlockPoolIdBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DataEncryptionKeyProto$Builder	setNonce	nonce_	C	org.apache.hadoop.thirdparty.protobuf.ByteString	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DataEncryptionKeyProto$Builder:setNonce(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DataEncryptionKeyProto$Builder	setEncryptionKey	encryptionKey_	C	org.apache.hadoop.thirdparty.protobuf.ByteString	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DataEncryptionKeyProto$Builder:setEncryptionKey(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DataEncryptionKeyProto$Builder	setExpiryDate	expiryDate_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DataEncryptionKeyProto$Builder:setExpiryDate(long)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DataEncryptionKeyProto$Builder	setEncryptionAlgorithm	encryptionAlgorithm_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DataEncryptionKeyProto$Builder:setEncryptionAlgorithm(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DataEncryptionKeyProto$Builder	setEncryptionAlgorithmBytes	encryptionAlgorithm_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DataEncryptionKeyProto$Builder:setEncryptionAlgorithmBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpReadBlockProto$Builder	setOffset	offset_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpReadBlockProto$Builder:setOffset(long)
org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpReadBlockProto$Builder	setLen	len_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpReadBlockProto$Builder:setLen(long)
org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpReadBlockProto$Builder	setSendChecksums	sendChecksums_	J	boolean	0	org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpReadBlockProto$Builder:setSendChecksums(boolean)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ReencryptionInfoProto$Builder	setEzKeyVersionName	ezKeyVersionName_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ReencryptionInfoProto$Builder:setEzKeyVersionName(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ReencryptionInfoProto$Builder	setEzKeyVersionNameBytes	ezKeyVersionName_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ReencryptionInfoProto$Builder:setEzKeyVersionNameBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ReencryptionInfoProto$Builder	setSubmissionTime	submissionTime_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ReencryptionInfoProto$Builder:setSubmissionTime(long)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ReencryptionInfoProto$Builder	setCanceled	canceled_	J	boolean	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ReencryptionInfoProto$Builder:setCanceled(boolean)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ReencryptionInfoProto$Builder	setNumReencrypted	numReencrypted_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ReencryptionInfoProto$Builder:setNumReencrypted(long)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ReencryptionInfoProto$Builder	setNumFailures	numFailures_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ReencryptionInfoProto$Builder:setNumFailures(long)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ReencryptionInfoProto$Builder	setCompletionTime	completionTime_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ReencryptionInfoProto$Builder:setCompletionTime(long)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ReencryptionInfoProto$Builder	setLastFile	lastFile_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ReencryptionInfoProto$Builder:setLastFile(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ReencryptionInfoProto$Builder	setLastFileBytes	lastFile_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ReencryptionInfoProto$Builder:setLastFileBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteRequestProto$Builder	setSrc	src_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteRequestProto$Builder:setSrc(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteRequestProto$Builder	setSrcBytes	src_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteRequestProto$Builder:setSrcBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteRequestProto$Builder	setRecursive	recursive_	J	boolean	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteRequestProto$Builder:setRecursive(boolean)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ZoneEncryptionInfoProto$Builder	setKeyName	keyName_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ZoneEncryptionInfoProto$Builder:setKeyName(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ZoneEncryptionInfoProto$Builder	setKeyNameBytes	keyName_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ZoneEncryptionInfoProto$Builder:setKeyNameBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RestoreFailedStorageRequestProto$Builder	setArg	arg_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RestoreFailedStorageRequestProto$Builder:setArg(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RestoreFailedStorageRequestProto$Builder	setArgBytes	arg_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RestoreFailedStorageRequestProto$Builder:setArgBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$IsFileClosedResponseProto$Builder	setResult	result_	J	boolean	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$IsFileClosedResponseProto$Builder:setResult(boolean)
org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ClientOperationHeaderProto$Builder	setClientName	clientName_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ClientOperationHeaderProto$Builder:setClientName(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ClientOperationHeaderProto$Builder	setClientNameBytes	clientName_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ClientOperationHeaderProto$Builder:setClientNameBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ECTopologyVerifierResultProto$Builder	setResultMessage	resultMessage_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ECTopologyVerifierResultProto$Builder:setResultMessage(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ECTopologyVerifierResultProto$Builder	setResultMessageBytes	resultMessage_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ECTopologyVerifierResultProto$Builder:setResultMessageBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ECTopologyVerifierResultProto$Builder	setIsSupported	isSupported_	J	boolean	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ECTopologyVerifierResultProto$Builder:setIsSupported(boolean)
org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ZoneReencryptionStatusProto$Builder	setId	id_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ZoneReencryptionStatusProto$Builder:setId(long)
org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ZoneReencryptionStatusProto$Builder	setPath	path_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ZoneReencryptionStatusProto$Builder:setPath(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ZoneReencryptionStatusProto$Builder	setPathBytes	path_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ZoneReencryptionStatusProto$Builder:setPathBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ZoneReencryptionStatusProto$Builder	setEzKeyVersionName	ezKeyVersionName_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ZoneReencryptionStatusProto$Builder:setEzKeyVersionName(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ZoneReencryptionStatusProto$Builder	setEzKeyVersionNameBytes	ezKeyVersionName_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ZoneReencryptionStatusProto$Builder:setEzKeyVersionNameBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ZoneReencryptionStatusProto$Builder	setSubmissionTime	submissionTime_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ZoneReencryptionStatusProto$Builder:setSubmissionTime(long)
org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ZoneReencryptionStatusProto$Builder	setCanceled	canceled_	J	boolean	0	org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ZoneReencryptionStatusProto$Builder:setCanceled(boolean)
org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ZoneReencryptionStatusProto$Builder	setNumReencrypted	numReencrypted_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ZoneReencryptionStatusProto$Builder:setNumReencrypted(long)
org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ZoneReencryptionStatusProto$Builder	setNumFailures	numFailures_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ZoneReencryptionStatusProto$Builder:setNumFailures(long)
org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ZoneReencryptionStatusProto$Builder	setCompletionTime	completionTime_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ZoneReencryptionStatusProto$Builder:setCompletionTime(long)
org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ZoneReencryptionStatusProto$Builder	setLastFile	lastFile_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ZoneReencryptionStatusProto$Builder:setLastFile(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ZoneReencryptionStatusProto$Builder	setLastFileBytes	lastFile_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ZoneReencryptionStatusProto$Builder:setLastFileBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$PacketHeaderProto$Builder	setOffsetInBlock	offsetInBlock_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$PacketHeaderProto$Builder:setOffsetInBlock(long)
org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$PacketHeaderProto$Builder	setSeqno	seqno_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$PacketHeaderProto$Builder:setSeqno(long)
org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$PacketHeaderProto$Builder	setLastPacketInBlock	lastPacketInBlock_	J	boolean	0	org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$PacketHeaderProto$Builder:setLastPacketInBlock(boolean)
org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$PacketHeaderProto$Builder	setDataLen	dataLen_	J	int	0	org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$PacketHeaderProto$Builder:setDataLen(int)
org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$PacketHeaderProto$Builder	setSyncBlock	syncBlock_	J	boolean	0	org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$PacketHeaderProto$Builder:setSyncBlock(boolean)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportListingProto$Builder	setIsFromEarlier	isFromEarlier_	J	boolean	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportListingProto$Builder:setIsFromEarlier(boolean)
org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$CodecProto$Builder	setCodec	codec_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$CodecProto$Builder:setCodec(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$CodecProto$Builder	setCodecBytes	codec_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$CodecProto$Builder:setCodecBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$CodecProto$Builder	setCoders	coders_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$CodecProto$Builder:setCoders(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$CodecProto$Builder	setCodersBytes	coders_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$CodecProto$Builder:setCodersBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdateBlockForPipelineRequestProto$Builder	setClientName	clientName_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdateBlockForPipelineRequestProto$Builder:setClientName(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdateBlockForPipelineRequestProto$Builder	setClientNameBytes	clientName_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdateBlockForPipelineRequestProto$Builder:setClientNameBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockTokenSecretProto$Builder	setExpiryDate	expiryDate_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockTokenSecretProto$Builder:setExpiryDate(long)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockTokenSecretProto$Builder	setKeyId	keyId_	J	int	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockTokenSecretProto$Builder:setKeyId(int)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockTokenSecretProto$Builder	setUserId	userId_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockTokenSecretProto$Builder:setUserId(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockTokenSecretProto$Builder	setUserIdBytes	userId_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockTokenSecretProto$Builder:setUserIdBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockTokenSecretProto$Builder	setBlockPoolId	blockPoolId_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockTokenSecretProto$Builder:setBlockPoolId(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockTokenSecretProto$Builder	setBlockPoolIdBytes	blockPoolId_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockTokenSecretProto$Builder:setBlockPoolIdBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockTokenSecretProto$Builder	setBlockId	blockId_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockTokenSecretProto$Builder:setBlockId(long)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockTokenSecretProto$Builder	setHandshakeSecret	handshakeSecret_	C	org.apache.hadoop.thirdparty.protobuf.ByteString	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockTokenSecretProto$Builder:setHandshakeSecret(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteResponseProto$Builder	setResult	result_	J	boolean	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteResponseProto$Builder:setResult(boolean)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ProvidedStorageLocationProto$Builder	setPath	path_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ProvidedStorageLocationProto$Builder:setPath(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ProvidedStorageLocationProto$Builder	setPathBytes	path_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ProvidedStorageLocationProto$Builder:setPathBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ProvidedStorageLocationProto$Builder	setOffset	offset_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ProvidedStorageLocationProto$Builder:setOffset(long)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ProvidedStorageLocationProto$Builder	setLength	length_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ProvidedStorageLocationProto$Builder:setLength(long)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ProvidedStorageLocationProto$Builder	setNonce	nonce_	C	org.apache.hadoop.thirdparty.protobuf.ByteString	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ProvidedStorageLocationProto$Builder:setNonce(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ExtendedBlockProto$Builder	setPoolId	poolId_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ExtendedBlockProto$Builder:setPoolId(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ExtendedBlockProto$Builder	setPoolIdBytes	poolId_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ExtendedBlockProto$Builder:setPoolIdBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ExtendedBlockProto$Builder	setBlockId	blockId_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ExtendedBlockProto$Builder:setBlockId(long)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ExtendedBlockProto$Builder	setGenerationStamp	generationStamp_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ExtendedBlockProto$Builder:setGenerationStamp(long)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ExtendedBlockProto$Builder	setNumBytes	numBytes_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ExtendedBlockProto$Builder:setNumBytes(long)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeStorageProto$Builder	setStorageUuid	storageUuid_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeStorageProto$Builder:setStorageUuid(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeStorageProto$Builder	setStorageUuidBytes	storageUuid_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeStorageProto$Builder:setStorageUuidBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$EventsListProto$Builder	setFirstTxid	firstTxid_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$EventsListProto$Builder:setFirstTxid(long)
org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$EventsListProto$Builder	setLastTxid	lastTxid_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$EventsListProto$Builder:setLastTxid(long)
org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$EventsListProto$Builder	setSyncTxid	syncTxid_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$EventsListProto$Builder:setSyncTxid(long)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$IsFileClosedRequestProto$Builder	setSrc	src_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$IsFileClosedRequestProto$Builder:setSrc(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$IsFileClosedRequestProto$Builder	setSrcBytes	src_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$IsFileClosedRequestProto$Builder:setSrcBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ReleaseShortCircuitAccessResponseProto$Builder	setError	error_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ReleaseShortCircuitAccessResponseProto$Builder:setError(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ReleaseShortCircuitAccessResponseProto$Builder	setErrorBytes	error_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ReleaseShortCircuitAccessResponseProto$Builder:setErrorBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLocatedFileInfoRequestProto$Builder	setSrc	src_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLocatedFileInfoRequestProto$Builder:setSrc(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLocatedFileInfoRequestProto$Builder	setSrcBytes	src_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLocatedFileInfoRequestProto$Builder:setSrcBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLocatedFileInfoRequestProto$Builder	setNeedBlockToken	needBlockToken_	J	boolean	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLocatedFileInfoRequestProto$Builder:setNeedBlockToken(boolean)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetStoragePolicyRequestProto$Builder	setSrc	src_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetStoragePolicyRequestProto$Builder:setSrc(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetStoragePolicyRequestProto$Builder	setSrcBytes	src_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetStoragePolicyRequestProto$Builder:setSrcBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetStoragePolicyRequestProto$Builder	setPolicyName	policyName_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetStoragePolicyRequestProto$Builder:setPolicyName(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetStoragePolicyRequestProto$Builder	setPolicyNameBytes	policyName_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetStoragePolicyRequestProto$Builder:setPolicyNameBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$UnsetErasureCodingPolicyRequestProto$Builder	setSrc	src_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$UnsetErasureCodingPolicyRequestProto$Builder:setSrc(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$UnsetErasureCodingPolicyRequestProto$Builder	setSrcBytes	src_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$UnsetErasureCodingPolicyRequestProto$Builder:setSrcBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockProto$Builder	setBlockId	blockId_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockProto$Builder:setBlockId(long)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockProto$Builder	setGenStamp	genStamp_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockProto$Builder:setGenStamp(long)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockProto$Builder	setNumBytes	numBytes_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockProto$Builder:setNumBytes(long)
org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitShmSlotProto$Builder	setSlotIdx	slotIdx_	J	int	0	org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitShmSlotProto$Builder:setSlotIdx(int)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCachePoolsResponseProto$Builder	setHasMore	hasMore_	J	boolean	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCachePoolsResponseProto$Builder:setHasMore(boolean)
org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusConfigChangeProto$Builder	setName	name_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusConfigChangeProto$Builder:setName(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusConfigChangeProto$Builder	setNameBytes	name_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusConfigChangeProto$Builder:setNameBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusConfigChangeProto$Builder	setOldValue	oldValue_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusConfigChangeProto$Builder:setOldValue(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusConfigChangeProto$Builder	setOldValueBytes	oldValue_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusConfigChangeProto$Builder:setOldValueBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusConfigChangeProto$Builder	setNewValue	newValue_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusConfigChangeProto$Builder:setNewValue(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusConfigChangeProto$Builder	setNewValueBytes	newValue_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusConfigChangeProto$Builder:setNewValueBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusConfigChangeProto$Builder	setErrorMessage	errorMessage_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusConfigChangeProto$Builder:setErrorMessage(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusConfigChangeProto$Builder	setErrorMessageBytes	errorMessage_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusConfigChangeProto$Builder:setErrorMessageBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$AddErasureCodingPolicyResponseProto$Builder	setSucceed	succeed_	J	boolean	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$AddErasureCodingPolicyResponseProto$Builder:setSucceed(boolean)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$AddErasureCodingPolicyResponseProto$Builder	setErrorMsg	errorMsg_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$AddErasureCodingPolicyResponseProto$Builder:setErrorMsg(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$AddErasureCodingPolicyResponseProto$Builder	setErrorMsgBytes	errorMsg_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$AddErasureCodingPolicyResponseProto$Builder:setErrorMsgBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportProto$Builder	setSnapshotRoot	snapshotRoot_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportProto$Builder:setSnapshotRoot(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportProto$Builder	setSnapshotRootBytes	snapshotRoot_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportProto$Builder:setSnapshotRootBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportProto$Builder	setFromSnapshot	fromSnapshot_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportProto$Builder:setFromSnapshot(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportProto$Builder	setFromSnapshotBytes	fromSnapshot_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportProto$Builder:setFromSnapshotBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportProto$Builder	setToSnapshot	toSnapshot_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportProto$Builder:setToSnapshot(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportProto$Builder	setToSnapshotBytes	toSnapshot_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportProto$Builder:setToSnapshotBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$QueryPlanStatusResponseProto$Builder	setResult	result_	J	int	0	org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$QueryPlanStatusResponseProto$Builder:setResult(int)
org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$QueryPlanStatusResponseProto$Builder	setPlanID	planID_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$QueryPlanStatusResponseProto$Builder:setPlanID(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$QueryPlanStatusResponseProto$Builder	setPlanIDBytes	planID_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$QueryPlanStatusResponseProto$Builder:setPlanIDBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$QueryPlanStatusResponseProto$Builder	setCurrentStatus	currentStatus_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$QueryPlanStatusResponseProto$Builder:setCurrentStatus(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$QueryPlanStatusResponseProto$Builder	setCurrentStatusBytes	currentStatus_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$QueryPlanStatusResponseProto$Builder:setCurrentStatusBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$QueryPlanStatusResponseProto$Builder	setPlanFile	planFile_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$QueryPlanStatusResponseProto$Builder:setPlanFile(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$QueryPlanStatusResponseProto$Builder	setPlanFileBytes	planFile_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$QueryPlanStatusResponseProto$Builder:setPlanFileBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$DataTransferTraceInfoProto$Builder	setTraceId	traceId_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$DataTransferTraceInfoProto$Builder:setTraceId(long)
org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$DataTransferTraceInfoProto$Builder	setParentId	parentId_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$DataTransferTraceInfoProto$Builder:setParentId(long)
org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$DataTransferTraceInfoProto$Builder	setSpanContext	spanContext_	C	org.apache.hadoop.thirdparty.protobuf.ByteString	0	org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$DataTransferTraceInfoProto$Builder:setSpanContext(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCacheDirectivesRequestProto$Builder	setPrevId	prevId_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCacheDirectivesRequestProto$Builder:setPrevId(long)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCacheDirectiveRequestProto$Builder	setCacheFlags	cacheFlags_	J	int	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCacheDirectiveRequestProto$Builder:setCacheFlags(int)
org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$TruncateEventProto$Builder	setPath	path_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$TruncateEventProto$Builder:setPath(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$TruncateEventProto$Builder	setPathBytes	path_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$TruncateEventProto$Builder:setPathBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$TruncateEventProto$Builder	setFileSize	fileSize_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$TruncateEventProto$Builder:setFileSize(long)
org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$TruncateEventProto$Builder	setTimestamp	timestamp_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$TruncateEventProto$Builder:setTimestamp(long)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$TruncateResponseProto$Builder	setResult	result_	J	boolean	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$TruncateResponseProto$Builder:setResult(boolean)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveInfoProto$Builder	setId	id_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveInfoProto$Builder:setId(long)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveInfoProto$Builder	setPath	path_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveInfoProto$Builder:setPath(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveInfoProto$Builder	setPathBytes	path_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveInfoProto$Builder:setPathBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveInfoProto$Builder	setReplication	replication_	J	int	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveInfoProto$Builder:setReplication(int)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveInfoProto$Builder	setPool	pool_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveInfoProto$Builder:setPool(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveInfoProto$Builder	setPoolBytes	pool_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveInfoProto$Builder:setPoolBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameRequestProto$Builder	setSrc	src_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameRequestProto$Builder:setSrc(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameRequestProto$Builder	setSrcBytes	src_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameRequestProto$Builder:setSrcBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameRequestProto$Builder	setDst	dst_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameRequestProto$Builder:setDst(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameRequestProto$Builder	setDstBytes	dst_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameRequestProto$Builder:setDstBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ReencryptEncryptionZoneRequestProto$Builder	setZone	zone_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ReencryptEncryptionZoneRequestProto$Builder:setZone(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ReencryptEncryptionZoneRequestProto$Builder	setZoneBytes	zone_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ReencryptEncryptionZoneRequestProto$Builder:setZoneBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UnsetStoragePolicyRequestProto$Builder	setSrc	src_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UnsetStoragePolicyRequestProto$Builder:setSrc(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UnsetStoragePolicyRequestProto$Builder	setSrcBytes	src_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UnsetStoragePolicyRequestProto$Builder:setSrcBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotInfoProto$Builder	setSnapshotName	snapshotName_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotInfoProto$Builder:setSnapshotName(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotInfoProto$Builder	setSnapshotNameBytes	snapshotName_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotInfoProto$Builder:setSnapshotNameBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotInfoProto$Builder	setSnapshotRoot	snapshotRoot_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotInfoProto$Builder:setSnapshotRoot(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotInfoProto$Builder	setSnapshotRootBytes	snapshotRoot_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotInfoProto$Builder:setSnapshotRootBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotInfoProto$Builder	setOwner	owner_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotInfoProto$Builder:setOwner(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotInfoProto$Builder	setOwnerBytes	owner_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotInfoProto$Builder:setOwnerBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotInfoProto$Builder	setGroup	group_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotInfoProto$Builder:setGroup(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotInfoProto$Builder	setGroupBytes	group_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotInfoProto$Builder:setGroupBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotInfoProto$Builder	setCreateTime	createTime_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotInfoProto$Builder:setCreateTime(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotInfoProto$Builder	setCreateTimeBytes	createTime_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotInfoProto$Builder:setCreateTimeBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$DisableErasureCodingPolicyRequestProto$Builder	setEcPolicyName	ecPolicyName_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$DisableErasureCodingPolicyRequestProto$Builder:setEcPolicyName(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$DisableErasureCodingPolicyRequestProto$Builder	setEcPolicyNameBytes	ecPolicyName_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$DisableErasureCodingPolicyRequestProto$Builder:setEcPolicyNameBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpgradeStatusResponseProto$Builder	setUpgradeFinalized	upgradeFinalized_	J	boolean	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpgradeStatusResponseProto$Builder:setUpgradeFinalized(boolean)
org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListReencryptionStatusRequestProto$Builder	setId	id_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListReencryptionStatusRequestProto$Builder:setId(long)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RestoreFailedStorageResponseProto$Builder	setResult	result_	J	boolean	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RestoreFailedStorageResponseProto$Builder:setResult(boolean)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetPreferredBlockSizeRequestProto$Builder	setFilename	filename_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetPreferredBlockSizeRequestProto$Builder:setFilename(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetPreferredBlockSizeRequestProto$Builder	setFilenameBytes	filename_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetPreferredBlockSizeRequestProto$Builder:setFilenameBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolInfoProto$Builder	setPoolName	poolName_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolInfoProto$Builder:setPoolName(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolInfoProto$Builder	setPoolNameBytes	poolName_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolInfoProto$Builder:setPoolNameBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolInfoProto$Builder	setOwnerName	ownerName_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolInfoProto$Builder:setOwnerName(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolInfoProto$Builder	setOwnerNameBytes	ownerName_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolInfoProto$Builder:setOwnerNameBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolInfoProto$Builder	setGroupName	groupName_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolInfoProto$Builder:setGroupName(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolInfoProto$Builder	setGroupNameBytes	groupName_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolInfoProto$Builder:setGroupNameBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolInfoProto$Builder	setMode	mode_	J	int	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolInfoProto$Builder:setMode(int)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolInfoProto$Builder	setLimit	limit_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolInfoProto$Builder:setLimit(long)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolInfoProto$Builder	setMaxRelativeExpiry	maxRelativeExpiry_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolInfoProto$Builder:setMaxRelativeExpiry(long)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolInfoProto$Builder	setDefaultReplication	defaultReplication_	J	int	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolInfoProto$Builder:setDefaultReplication(int)
org.apache.hadoop.hdfs.protocol.proto.AclProtos$GetAclStatusRequestProto$Builder	setSrc	src_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.AclProtos$GetAclStatusRequestProto$Builder:setSrc(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.AclProtos$GetAclStatusRequestProto$Builder	setSrcBytes	src_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.AclProtos$GetAclStatusRequestProto$Builder:setSrcBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$SetErasureCodingPolicyRequestProto$Builder	setSrc	src_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$SetErasureCodingPolicyRequestProto$Builder:setSrc(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$SetErasureCodingPolicyRequestProto$Builder	setSrcBytes	src_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$SetErasureCodingPolicyRequestProto$Builder:setSrcBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$SetErasureCodingPolicyRequestProto$Builder	setEcPolicyName	ecPolicyName_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$SetErasureCodingPolicyRequestProto$Builder:setEcPolicyName(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$SetErasureCodingPolicyRequestProto$Builder	setEcPolicyNameBytes	ecPolicyName_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$SetErasureCodingPolicyRequestProto$Builder:setEcPolicyNameBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SaveNamespaceResponseProto$Builder	setSaved	saved_	J	boolean	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SaveNamespaceResponseProto$Builder:setSaved(boolean)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AbandonBlockRequestProto$Builder	setSrc	src_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AbandonBlockRequestProto$Builder:setSrc(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AbandonBlockRequestProto$Builder	setSrcBytes	src_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AbandonBlockRequestProto$Builder:setSrcBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AbandonBlockRequestProto$Builder	setHolder	holder_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AbandonBlockRequestProto$Builder:setHolder(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AbandonBlockRequestProto$Builder	setHolderBytes	holder_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AbandonBlockRequestProto$Builder:setHolderBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AbandonBlockRequestProto$Builder	setFileId	fileId_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AbandonBlockRequestProto$Builder:setFileId(long)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolStatsProto$Builder	setBytesNeeded	bytesNeeded_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolStatsProto$Builder:setBytesNeeded(long)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolStatsProto$Builder	setBytesCached	bytesCached_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolStatsProto$Builder:setBytesCached(long)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolStatsProto$Builder	setBytesOverlimit	bytesOverlimit_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolStatsProto$Builder:setBytesOverlimit(long)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolStatsProto$Builder	setFilesNeeded	filesNeeded_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolStatsProto$Builder:setFilesNeeded(long)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolStatsProto$Builder	setFilesCached	filesCached_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolStatsProto$Builder:setFilesCached(long)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportRequestProto$Builder	setSnapshotRoot	snapshotRoot_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportRequestProto$Builder:setSnapshotRoot(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportRequestProto$Builder	setSnapshotRootBytes	snapshotRoot_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportRequestProto$Builder:setSnapshotRootBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportRequestProto$Builder	setFromSnapshot	fromSnapshot_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportRequestProto$Builder:setFromSnapshot(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportRequestProto$Builder	setFromSnapshotBytes	fromSnapshot_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportRequestProto$Builder:setFromSnapshotBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportRequestProto$Builder	setToSnapshot	toSnapshot_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportRequestProto$Builder:setToSnapshot(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportRequestProto$Builder	setToSnapshotBytes	toSnapshot_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportRequestProto$Builder:setToSnapshotBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$CreateEncryptionZoneRequestProto$Builder	setSrc	src_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$CreateEncryptionZoneRequestProto$Builder:setSrc(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$CreateEncryptionZoneRequestProto$Builder	setSrcBytes	src_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$CreateEncryptionZoneRequestProto$Builder:setSrcBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$CreateEncryptionZoneRequestProto$Builder	setKeyName	keyName_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$CreateEncryptionZoneRequestProto$Builder:setKeyName(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$CreateEncryptionZoneRequestProto$Builder	setKeyNameBytes	keyName_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$CreateEncryptionZoneRequestProto$Builder:setKeyNameBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$EncryptionZoneProto$Builder	setId	id_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$EncryptionZoneProto$Builder:setId(long)
org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$EncryptionZoneProto$Builder	setPath	path_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$EncryptionZoneProto$Builder:setPath(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$EncryptionZoneProto$Builder	setPathBytes	path_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$EncryptionZoneProto$Builder:setPathBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$EncryptionZoneProto$Builder	setKeyName	keyName_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$EncryptionZoneProto$Builder:setKeyName(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$EncryptionZoneProto$Builder	setKeyNameBytes	keyName_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$EncryptionZoneProto$Builder:setKeyNameBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockChecksumOptionsProto$Builder	setStripeLength	stripeLength_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockChecksumOptionsProto$Builder:setStripeLength(long)
org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListEncryptionZonesRequestProto$Builder	setId	id_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListEncryptionZonesRequestProto$Builder:setId(long)
org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DiskBalancerSettingRequestProto$Builder	setKey	key_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DiskBalancerSettingRequestProto$Builder:setKey(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DiskBalancerSettingRequestProto$Builder	setKeyBytes	key_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DiskBalancerSettingRequestProto$Builder:setKeyBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpBlockChecksumResponseProto$Builder	setBytesPerCrc	bytesPerCrc_	J	int	0	org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpBlockChecksumResponseProto$Builder:setBytesPerCrc(int)
org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpBlockChecksumResponseProto$Builder	setCrcPerBlock	crcPerBlock_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpBlockChecksumResponseProto$Builder:setCrcPerBlock(long)
org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpBlockChecksumResponseProto$Builder	setBlockChecksum	blockChecksum_	C	org.apache.hadoop.thirdparty.protobuf.ByteString	0	org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpBlockChecksumResponseProto$Builder:setBlockChecksum(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetListingRequestProto$Builder	setSrc	src_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetListingRequestProto$Builder:setSrc(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetListingRequestProto$Builder	setSrcBytes	src_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetListingRequestProto$Builder:setSrcBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetListingRequestProto$Builder	setStartAfter	startAfter_	C	org.apache.hadoop.thirdparty.protobuf.ByteString	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetListingRequestProto$Builder:setStartAfter(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetListingRequestProto$Builder	setNeedLocation	needLocation_	J	boolean	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetListingRequestProto$Builder:setNeedLocation(boolean)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetCurrentEditLogTxidResponseProto$Builder	setTxid	txid_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetCurrentEditLogTxidResponseProto$Builder:setTxid(long)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeLocalInfoProto$Builder	setSoftwareVersion	softwareVersion_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeLocalInfoProto$Builder:setSoftwareVersion(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeLocalInfoProto$Builder	setSoftwareVersionBytes	softwareVersion_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeLocalInfoProto$Builder:setSoftwareVersionBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeLocalInfoProto$Builder	setConfigVersion	configVersion_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeLocalInfoProto$Builder:setConfigVersion(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeLocalInfoProto$Builder	setConfigVersionBytes	configVersion_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeLocalInfoProto$Builder:setConfigVersionBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeLocalInfoProto$Builder	setUptime	uptime_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeLocalInfoProto$Builder:setUptime(long)
org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitShmRequestProto$Builder	setClientName	clientName_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitShmRequestProto$Builder:setClientName(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitShmRequestProto$Builder	setClientNameBytes	clientName_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitShmRequestProto$Builder:setClientNameBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$BlockECReconstructionInfoProto$Builder	setLiveBlockIndices	liveBlockIndices_	C	org.apache.hadoop.thirdparty.protobuf.ByteString	0	org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$BlockECReconstructionInfoProto$Builder:setLiveBlockIndices(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$BlockECReconstructionInfoProto$Builder	setExcludeReconstructedIndices	excludeReconstructedIndices_	C	org.apache.hadoop.thirdparty.protobuf.ByteString	0	org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$BlockECReconstructionInfoProto$Builder:setExcludeReconstructedIndices(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveStatsProto$Builder	setBytesNeeded	bytesNeeded_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveStatsProto$Builder:setBytesNeeded(long)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveStatsProto$Builder	setBytesCached	bytesCached_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveStatsProto$Builder:setBytesCached(long)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveStatsProto$Builder	setFilesNeeded	filesNeeded_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveStatsProto$Builder:setFilesNeeded(long)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveStatsProto$Builder	setFilesCached	filesCached_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveStatsProto$Builder:setFilesCached(long)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveStatsProto$Builder	setHasExpired	hasExpired_	J	boolean	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveStatsProto$Builder:setHasExpired(boolean)
org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$GetXAttrsRequestProto$Builder	setSrc	src_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$GetXAttrsRequestProto$Builder:setSrc(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$GetXAttrsRequestProto$Builder	setSrcBytes	src_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$GetXAttrsRequestProto$Builder:setSrcBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DiskBalancerSettingResponseProto$Builder	setValue	value_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DiskBalancerSettingResponseProto$Builder:setValue(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DiskBalancerSettingResponseProto$Builder	setValueBytes	value_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DiskBalancerSettingResponseProto$Builder:setValueBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSymlinkRequestProto$Builder	setTarget	target_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSymlinkRequestProto$Builder:setTarget(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSymlinkRequestProto$Builder	setTargetBytes	target_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSymlinkRequestProto$Builder:setTargetBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSymlinkRequestProto$Builder	setLink	link_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSymlinkRequestProto$Builder:setLink(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSymlinkRequestProto$Builder	setLinkBytes	link_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSymlinkRequestProto$Builder:setLinkBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSymlinkRequestProto$Builder	setCreateParent	createParent_	J	boolean	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSymlinkRequestProto$Builder:setCreateParent(boolean)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AllowSnapshotRequestProto$Builder	setSnapshotRoot	snapshotRoot_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AllowSnapshotRequestProto$Builder:setSnapshotRoot(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AllowSnapshotRequestProto$Builder	setSnapshotRootBytes	snapshotRoot_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AllowSnapshotRequestProto$Builder:setSnapshotRootBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetBlockLocationsRequestProto$Builder	setSrc	src_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetBlockLocationsRequestProto$Builder:setSrc(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetBlockLocationsRequestProto$Builder	setSrcBytes	src_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetBlockLocationsRequestProto$Builder:setSrcBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetBlockLocationsRequestProto$Builder	setOffset	offset_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetBlockLocationsRequestProto$Builder:setOffset(long)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetBlockLocationsRequestProto$Builder	setLength	length_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetBlockLocationsRequestProto$Builder:setLength(long)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileInfoRequestProto$Builder	setSrc	src_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileInfoRequestProto$Builder:setSrc(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileInfoRequestProto$Builder	setSrcBytes	src_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileInfoRequestProto$Builder:setSrcBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddBlockRequestProto$Builder	setSrc	src_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddBlockRequestProto$Builder:setSrc(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddBlockRequestProto$Builder	setSrcBytes	src_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddBlockRequestProto$Builder:setSrcBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddBlockRequestProto$Builder	setClientName	clientName_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddBlockRequestProto$Builder:setClientName(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddBlockRequestProto$Builder	setClientNameBytes	clientName_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddBlockRequestProto$Builder:setClientNameBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddBlockRequestProto$Builder	setFileId	fileId_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddBlockRequestProto$Builder:setFileId(long)
org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$HandshakeSecretProto$Builder	setSecret	secret_	C	org.apache.hadoop.thirdparty.protobuf.ByteString	0	org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$HandshakeSecretProto$Builder:setSecret(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$HandshakeSecretProto$Builder	setBpid	bpid_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$HandshakeSecretProto$Builder:setBpid(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$HandshakeSecretProto$Builder	setBpidBytes	bpid_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$HandshakeSecretProto$Builder:setBpidBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCachePoolRequestProto$Builder	setPoolName	poolName_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCachePoolRequestProto$Builder:setPoolName(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCachePoolRequestProto$Builder	setPoolNameBytes	poolName_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCachePoolRequestProto$Builder:setPoolNameBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CheckAccessRequestProto$Builder	setPath	path_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CheckAccessRequestProto$Builder:setPath(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CheckAccessRequestProto$Builder	setPathBytes	path_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CheckAccessRequestProto$Builder:setPathBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetAdditionalDatanodeRequestProto$Builder	setSrc	src_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetAdditionalDatanodeRequestProto$Builder:setSrc(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetAdditionalDatanodeRequestProto$Builder	setSrcBytes	src_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetAdditionalDatanodeRequestProto$Builder:setSrcBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetAdditionalDatanodeRequestProto$Builder	setNumAdditionalNodes	numAdditionalNodes_	J	int	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetAdditionalDatanodeRequestProto$Builder:setNumAdditionalNodes(int)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetAdditionalDatanodeRequestProto$Builder	setClientName	clientName_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetAdditionalDatanodeRequestProto$Builder:setClientName(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetAdditionalDatanodeRequestProto$Builder	setClientNameBytes	clientName_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetAdditionalDatanodeRequestProto$Builder:setClientNameBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetAdditionalDatanodeRequestProto$Builder	setFileId	fileId_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetAdditionalDatanodeRequestProto$Builder:setFileId(long)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ContentSummaryProto$Builder	setLength	length_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ContentSummaryProto$Builder:setLength(long)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ContentSummaryProto$Builder	setFileCount	fileCount_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ContentSummaryProto$Builder:setFileCount(long)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ContentSummaryProto$Builder	setDirectoryCount	directoryCount_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ContentSummaryProto$Builder:setDirectoryCount(long)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ContentSummaryProto$Builder	setQuota	quota_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ContentSummaryProto$Builder:setQuota(long)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ContentSummaryProto$Builder	setSpaceConsumed	spaceConsumed_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ContentSummaryProto$Builder:setSpaceConsumed(long)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ContentSummaryProto$Builder	setSpaceQuota	spaceQuota_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ContentSummaryProto$Builder:setSpaceQuota(long)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ContentSummaryProto$Builder	setSnapshotLength	snapshotLength_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ContentSummaryProto$Builder:setSnapshotLength(long)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ContentSummaryProto$Builder	setSnapshotFileCount	snapshotFileCount_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ContentSummaryProto$Builder:setSnapshotFileCount(long)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ContentSummaryProto$Builder	setSnapshotDirectoryCount	snapshotDirectoryCount_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ContentSummaryProto$Builder:setSnapshotDirectoryCount(long)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ContentSummaryProto$Builder	setSnapshotSpaceConsumed	snapshotSpaceConsumed_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ContentSummaryProto$Builder:setSnapshotSpaceConsumed(long)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ContentSummaryProto$Builder	setErasureCodingPolicy	erasureCodingPolicy_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ContentSummaryProto$Builder:setErasureCodingPolicy(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ContentSummaryProto$Builder	setErasureCodingPolicyBytes	erasureCodingPolicy_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ContentSummaryProto$Builder:setErasureCodingPolicyBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteSnapshotRequestProto$Builder	setSnapshotRoot	snapshotRoot_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteSnapshotRequestProto$Builder:setSnapshotRoot(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteSnapshotRequestProto$Builder	setSnapshotRootBytes	snapshotRoot_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteSnapshotRequestProto$Builder:setSnapshotRootBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteSnapshotRequestProto$Builder	setSnapshotName	snapshotName_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteSnapshotRequestProto$Builder:setSnapshotName(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteSnapshotRequestProto$Builder	setSnapshotNameBytes	snapshotName_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteSnapshotRequestProto$Builder:setSnapshotNameBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.CachePoolStats$Builder	setBytesNeeded	bytesNeeded	J	long	0	org.apache.hadoop.hdfs.protocol.CachePoolStats$Builder:setBytesNeeded(long)
org.apache.hadoop.hdfs.protocol.CachePoolStats$Builder	setBytesCached	bytesCached	J	long	0	org.apache.hadoop.hdfs.protocol.CachePoolStats$Builder:setBytesCached(long)
org.apache.hadoop.hdfs.protocol.CachePoolStats$Builder	setBytesOverlimit	bytesOverlimit	J	long	0	org.apache.hadoop.hdfs.protocol.CachePoolStats$Builder:setBytesOverlimit(long)
org.apache.hadoop.hdfs.protocol.CachePoolStats$Builder	setFilesNeeded	filesNeeded	J	long	0	org.apache.hadoop.hdfs.protocol.CachePoolStats$Builder:setFilesNeeded(long)
org.apache.hadoop.hdfs.protocol.CachePoolStats$Builder	setFilesCached	filesCached	J	long	0	org.apache.hadoop.hdfs.protocol.CachePoolStats$Builder:setFilesCached(long)
org.apache.hadoop.hdfs.protocol.QuotaExceededException	setPathName	pathName	J	java.lang.String	0	org.apache.hadoop.hdfs.protocol.QuotaExceededException:setPathName(java.lang.String)
org.apache.hadoop.hdfs.protocol.datatransfer.TrustedChannelResolver	setConf	conf	C	org.apache.hadoop.conf.Configuration	0	org.apache.hadoop.hdfs.protocol.datatransfer.TrustedChannelResolver:setConf(org.apache.hadoop.conf.Configuration)
org.apache.hadoop.hdfs.protocol.ErasureCodingPolicyInfo	setState	state	C	org.apache.hadoop.hdfs.protocol.ErasureCodingPolicyState	0	org.apache.hadoop.hdfs.protocol.ErasureCodingPolicyInfo:setState(org.apache.hadoop.hdfs.protocol.ErasureCodingPolicyState)
org.apache.hadoop.hdfs.protocol.RollingUpgradeInfo	setCreatedRollbackImages	createdRollbackImages	J	boolean	0	org.apache.hadoop.hdfs.protocol.RollingUpgradeInfo:setCreatedRollbackImages(boolean)
org.apache.hadoop.hdfs.protocol.NSQuotaExceededException	setMessagePrefix	prefix	J	java.lang.String	0	org.apache.hadoop.hdfs.protocol.NSQuotaExceededException:setMessagePrefix(java.lang.String)
org.apache.hadoop.hdfs.protocol.ZoneReencryptionStatus	setState	state	C	org.apache.hadoop.hdfs.protocol.ZoneReencryptionStatus$State	0	org.apache.hadoop.hdfs.protocol.ZoneReencryptionStatus:setState(org.apache.hadoop.hdfs.protocol.ZoneReencryptionStatus$State)
org.apache.hadoop.hdfs.protocol.ZoneReencryptionStatus	setZoneName	zoneName	J	java.lang.String	0	org.apache.hadoop.hdfs.protocol.ZoneReencryptionStatus:setZoneName(java.lang.String)
org.apache.hadoop.hdfs.protocol.DatanodeInfo$DatanodeInfoBuilder	setCapacity	capacity	J	long	0	org.apache.hadoop.hdfs.protocol.DatanodeInfo$DatanodeInfoBuilder:setCapacity(long)
org.apache.hadoop.hdfs.protocol.DatanodeInfo$DatanodeInfoBuilder	setDfsUsed	dfsUsed	J	long	0	org.apache.hadoop.hdfs.protocol.DatanodeInfo$DatanodeInfoBuilder:setDfsUsed(long)
org.apache.hadoop.hdfs.protocol.DatanodeInfo$DatanodeInfoBuilder	setRemaining	remaining	J	long	0	org.apache.hadoop.hdfs.protocol.DatanodeInfo$DatanodeInfoBuilder:setRemaining(long)
org.apache.hadoop.hdfs.protocol.DatanodeInfo$DatanodeInfoBuilder	setBlockPoolUsed	blockPoolUsed	J	long	0	org.apache.hadoop.hdfs.protocol.DatanodeInfo$DatanodeInfoBuilder:setBlockPoolUsed(long)
org.apache.hadoop.hdfs.protocol.DatanodeInfo$DatanodeInfoBuilder	setCacheCapacity	cacheCapacity	J	long	0	org.apache.hadoop.hdfs.protocol.DatanodeInfo$DatanodeInfoBuilder:setCacheCapacity(long)
org.apache.hadoop.hdfs.protocol.DatanodeInfo$DatanodeInfoBuilder	setCacheUsed	cacheUsed	J	long	0	org.apache.hadoop.hdfs.protocol.DatanodeInfo$DatanodeInfoBuilder:setCacheUsed(long)
org.apache.hadoop.hdfs.protocol.DatanodeInfo$DatanodeInfoBuilder	setLastUpdate	lastUpdate	J	long	0	org.apache.hadoop.hdfs.protocol.DatanodeInfo$DatanodeInfoBuilder:setLastUpdate(long)
org.apache.hadoop.hdfs.protocol.DatanodeInfo$DatanodeInfoBuilder	setLastUpdateMonotonic	lastUpdateMonotonic	J	long	0	org.apache.hadoop.hdfs.protocol.DatanodeInfo$DatanodeInfoBuilder:setLastUpdateMonotonic(long)
org.apache.hadoop.hdfs.protocol.DatanodeInfo$DatanodeInfoBuilder	setXceiverCount	xceiverCount	J	int	0	org.apache.hadoop.hdfs.protocol.DatanodeInfo$DatanodeInfoBuilder:setXceiverCount(int)
org.apache.hadoop.hdfs.protocol.DatanodeInfo$DatanodeInfoBuilder	setAdminState	adminState	C	org.apache.hadoop.hdfs.protocol.DatanodeInfo$AdminStates	0	org.apache.hadoop.hdfs.protocol.DatanodeInfo$DatanodeInfoBuilder:setAdminState(org.apache.hadoop.hdfs.protocol.DatanodeInfo$AdminStates)
org.apache.hadoop.hdfs.protocol.DatanodeInfo$DatanodeInfoBuilder	setUpgradeDomain	upgradeDomain	J	java.lang.String	0	org.apache.hadoop.hdfs.protocol.DatanodeInfo$DatanodeInfoBuilder:setUpgradeDomain(java.lang.String)
org.apache.hadoop.hdfs.protocol.DatanodeInfo$DatanodeInfoBuilder	setIpAddr	ipAddr	J	java.lang.String	0	org.apache.hadoop.hdfs.protocol.DatanodeInfo$DatanodeInfoBuilder:setIpAddr(java.lang.String)
org.apache.hadoop.hdfs.protocol.DatanodeInfo$DatanodeInfoBuilder	setHostName	hostName	J	java.lang.String	0	org.apache.hadoop.hdfs.protocol.DatanodeInfo$DatanodeInfoBuilder:setHostName(java.lang.String)
org.apache.hadoop.hdfs.protocol.DatanodeInfo$DatanodeInfoBuilder	setDatanodeUuid	datanodeUuid	J	java.lang.String	0	org.apache.hadoop.hdfs.protocol.DatanodeInfo$DatanodeInfoBuilder:setDatanodeUuid(java.lang.String)
org.apache.hadoop.hdfs.protocol.DatanodeInfo$DatanodeInfoBuilder	setXferPort	xferPort	J	int	0	org.apache.hadoop.hdfs.protocol.DatanodeInfo$DatanodeInfoBuilder:setXferPort(int)
org.apache.hadoop.hdfs.protocol.DatanodeInfo$DatanodeInfoBuilder	setInfoPort	infoPort	J	int	0	org.apache.hadoop.hdfs.protocol.DatanodeInfo$DatanodeInfoBuilder:setInfoPort(int)
org.apache.hadoop.hdfs.protocol.DatanodeInfo$DatanodeInfoBuilder	setInfoSecurePort	infoSecurePort	J	int	0	org.apache.hadoop.hdfs.protocol.DatanodeInfo$DatanodeInfoBuilder:setInfoSecurePort(int)
org.apache.hadoop.hdfs.protocol.DatanodeInfo$DatanodeInfoBuilder	setIpcPort	ipcPort	J	int	0	org.apache.hadoop.hdfs.protocol.DatanodeInfo$DatanodeInfoBuilder:setIpcPort(int)
org.apache.hadoop.hdfs.protocol.DatanodeInfo$DatanodeInfoBuilder	setNetworkLocation	location	J	java.lang.String	0	org.apache.hadoop.hdfs.protocol.DatanodeInfo$DatanodeInfoBuilder:setNetworkLocation(java.lang.String)
org.apache.hadoop.hdfs.protocol.DatanodeInfo$DatanodeInfoBuilder	setNonDfsUsed	nonDfsUsed	J	long	0	org.apache.hadoop.hdfs.protocol.DatanodeInfo$DatanodeInfoBuilder:setNonDfsUsed(long)
org.apache.hadoop.hdfs.protocol.DatanodeInfo$DatanodeInfoBuilder	setLastBlockReportTime	lastBlockReportTime	J	long	0	org.apache.hadoop.hdfs.protocol.DatanodeInfo$DatanodeInfoBuilder:setLastBlockReportTime(long)
org.apache.hadoop.hdfs.protocol.DatanodeInfo$DatanodeInfoBuilder	setLastBlockReportMonotonic	lastBlockReportMonotonic	J	long	0	org.apache.hadoop.hdfs.protocol.DatanodeInfo$DatanodeInfoBuilder:setLastBlockReportMonotonic(long)
org.apache.hadoop.hdfs.protocol.DatanodeInfo$DatanodeInfoBuilder	setNumBlocks	numBlocks	J	int	0	org.apache.hadoop.hdfs.protocol.DatanodeInfo$DatanodeInfoBuilder:setNumBlocks(int)
org.apache.hadoop.hdfs.protocol.DatanodeInfo	setLastUpdateMonotonic	lastUpdateMonotonic	J	long	0	org.apache.hadoop.hdfs.protocol.DatanodeInfo:setLastUpdateMonotonic(long)
org.apache.hadoop.hdfs.protocol.DatanodeInfo	setCapacity	capacity	J	long	0	org.apache.hadoop.hdfs.protocol.DatanodeInfo:setCapacity(long)
org.apache.hadoop.hdfs.protocol.DatanodeInfo	setDfsUsed	dfsUsed	J	long	0	org.apache.hadoop.hdfs.protocol.DatanodeInfo:setDfsUsed(long)
org.apache.hadoop.hdfs.protocol.DatanodeInfo	setNonDfsUsed	nonDfsUsed	J	long	0	org.apache.hadoop.hdfs.protocol.DatanodeInfo:setNonDfsUsed(long)
org.apache.hadoop.hdfs.protocol.DatanodeInfo	setRemaining	remaining	J	long	0	org.apache.hadoop.hdfs.protocol.DatanodeInfo:setRemaining(long)
org.apache.hadoop.hdfs.protocol.DatanodeInfo	setBlockPoolUsed	blockPoolUsed	J	long	0	org.apache.hadoop.hdfs.protocol.DatanodeInfo:setBlockPoolUsed(long)
org.apache.hadoop.hdfs.protocol.DatanodeInfo	setCacheCapacity	cacheCapacity	J	long	0	org.apache.hadoop.hdfs.protocol.DatanodeInfo:setCacheCapacity(long)
org.apache.hadoop.hdfs.protocol.DatanodeInfo	setCacheUsed	cacheUsed	J	long	0	org.apache.hadoop.hdfs.protocol.DatanodeInfo:setCacheUsed(long)
org.apache.hadoop.hdfs.protocol.DatanodeInfo	setLastUpdate	lastUpdate	J	long	0	org.apache.hadoop.hdfs.protocol.DatanodeInfo:setLastUpdate(long)
org.apache.hadoop.hdfs.protocol.DatanodeInfo	setXceiverCount	xceiverCount	J	int	0	org.apache.hadoop.hdfs.protocol.DatanodeInfo:setXceiverCount(int)
org.apache.hadoop.hdfs.protocol.DatanodeInfo	setNumBlocks	numBlocks	J	int	0	org.apache.hadoop.hdfs.protocol.DatanodeInfo:setNumBlocks(int)
org.apache.hadoop.hdfs.protocol.DatanodeInfo	setNetworkLocation	location	J	java.lang.String	0	org.apache.hadoop.hdfs.protocol.DatanodeInfo:setNetworkLocation(java.lang.String)
org.apache.hadoop.hdfs.protocol.DatanodeInfo	setUpgradeDomain	upgradeDomain	J	java.lang.String	0	org.apache.hadoop.hdfs.protocol.DatanodeInfo:setUpgradeDomain(java.lang.String)
org.apache.hadoop.hdfs.protocol.DatanodeInfo	setDependentHostNames	dependentHostNames	GJ	java.util.List	0	org.apache.hadoop.hdfs.protocol.DatanodeInfo:setDependentHostNames(java.util.List)
org.apache.hadoop.hdfs.protocol.DatanodeInfo	setMaintenanceExpireTimeInMS	maintenanceExpireTimeInMS	J	long	0	org.apache.hadoop.hdfs.protocol.DatanodeInfo:setMaintenanceExpireTimeInMS(long)
org.apache.hadoop.hdfs.protocol.DatanodeInfo	setLastBlockReportTime	lastBlockReportTime	J	long	0	org.apache.hadoop.hdfs.protocol.DatanodeInfo:setLastBlockReportTime(long)
org.apache.hadoop.hdfs.protocol.DatanodeInfo	setLastBlockReportMonotonic	lastBlockReportMonotonic	J	long	0	org.apache.hadoop.hdfs.protocol.DatanodeInfo:setLastBlockReportMonotonic(long)
org.apache.hadoop.hdfs.protocol.DatanodeInfo	setAdminState	adminState	C	org.apache.hadoop.hdfs.protocol.DatanodeInfo$AdminStates	0	org.apache.hadoop.hdfs.protocol.DatanodeInfo:setAdminState(org.apache.hadoop.hdfs.protocol.DatanodeInfo$AdminStates)
org.apache.hadoop.hdfs.protocol.DatanodeInfo	setParent	parent	C	org.apache.hadoop.net.Node	0	org.apache.hadoop.hdfs.protocol.DatanodeInfo:setParent(org.apache.hadoop.net.Node)
org.apache.hadoop.hdfs.protocol.DatanodeInfo	setLevel	level	J	int	0	org.apache.hadoop.hdfs.protocol.DatanodeInfo:setLevel(int)
org.apache.hadoop.hdfs.protocol.DatanodeInfo	setSoftwareVersion	softwareVersion	J	java.lang.String	0	org.apache.hadoop.hdfs.protocol.DatanodeInfo:setSoftwareVersion(java.lang.String)
org.apache.hadoop.hdfs.protocol.CachePoolInfo	setOwnerName	ownerName	J	java.lang.String	0	org.apache.hadoop.hdfs.protocol.CachePoolInfo:setOwnerName(java.lang.String)
org.apache.hadoop.hdfs.protocol.CachePoolInfo	setGroupName	groupName	J	java.lang.String	0	org.apache.hadoop.hdfs.protocol.CachePoolInfo:setGroupName(java.lang.String)
org.apache.hadoop.hdfs.protocol.CachePoolInfo	setMode	mode	C	org.apache.hadoop.fs.permission.FsPermission	0	org.apache.hadoop.hdfs.protocol.CachePoolInfo:setMode(org.apache.hadoop.fs.permission.FsPermission)
org.apache.hadoop.hdfs.protocol.CachePoolInfo	setLimit	limit	J	java.lang.Long	0	org.apache.hadoop.hdfs.protocol.CachePoolInfo:setLimit(java.lang.Long)
org.apache.hadoop.hdfs.protocol.CachePoolInfo	setDefaultReplication	defaultReplication	J	java.lang.Short	0	org.apache.hadoop.hdfs.protocol.CachePoolInfo:setDefaultReplication(java.lang.Short)
org.apache.hadoop.hdfs.protocol.CachePoolInfo	setMaxRelativeExpiryMs	maxRelativeExpiryMs	J	java.lang.Long	0	org.apache.hadoop.hdfs.protocol.CachePoolInfo:setMaxRelativeExpiryMs(java.lang.Long)
org.apache.hadoop.hdfs.protocol.LocatedStripedBlock	setBlockTokens	blockTokens	GC	org.apache.hadoop.security.token.Token	1	org.apache.hadoop.hdfs.protocol.LocatedStripedBlock:setBlockTokens(org.apache.hadoop.security.token.Token[])
org.apache.hadoop.hdfs.protocol.DatanodeID	setPeerHostName	peerHostName	J	java.lang.String	0	org.apache.hadoop.hdfs.protocol.DatanodeID:setPeerHostName(java.lang.String)
org.apache.hadoop.hdfs.protocol.CacheDirectiveStats$Builder	setBytesNeeded	bytesNeeded	J	long	0	org.apache.hadoop.hdfs.protocol.CacheDirectiveStats$Builder:setBytesNeeded(long)
org.apache.hadoop.hdfs.protocol.CacheDirectiveStats$Builder	setBytesCached	bytesCached	J	long	0	org.apache.hadoop.hdfs.protocol.CacheDirectiveStats$Builder:setBytesCached(long)
org.apache.hadoop.hdfs.protocol.CacheDirectiveStats$Builder	setFilesNeeded	filesNeeded	J	long	0	org.apache.hadoop.hdfs.protocol.CacheDirectiveStats$Builder:setFilesNeeded(long)
org.apache.hadoop.hdfs.protocol.CacheDirectiveStats$Builder	setFilesCached	filesCached	J	long	0	org.apache.hadoop.hdfs.protocol.CacheDirectiveStats$Builder:setFilesCached(long)
org.apache.hadoop.hdfs.protocol.CacheDirectiveStats$Builder	setHasExpired	hasExpired	J	boolean	0	org.apache.hadoop.hdfs.protocol.CacheDirectiveStats$Builder:setHasExpired(boolean)
org.apache.hadoop.hdfs.protocol.CacheDirectiveInfo$Builder	setId	id	J	java.lang.Long	0	org.apache.hadoop.hdfs.protocol.CacheDirectiveInfo$Builder:setId(java.lang.Long)
org.apache.hadoop.hdfs.protocol.CacheDirectiveInfo$Builder	setPath	path	C	org.apache.hadoop.fs.Path	0	org.apache.hadoop.hdfs.protocol.CacheDirectiveInfo$Builder:setPath(org.apache.hadoop.fs.Path)
org.apache.hadoop.hdfs.protocol.CacheDirectiveInfo$Builder	setReplication	replication	J	java.lang.Short	0	org.apache.hadoop.hdfs.protocol.CacheDirectiveInfo$Builder:setReplication(java.lang.Short)
org.apache.hadoop.hdfs.protocol.CacheDirectiveInfo$Builder	setPool	pool	J	java.lang.String	0	org.apache.hadoop.hdfs.protocol.CacheDirectiveInfo$Builder:setPool(java.lang.String)
org.apache.hadoop.hdfs.protocol.CacheDirectiveInfo$Builder	setExpiration	expiration	C	org.apache.hadoop.hdfs.protocol.CacheDirectiveInfo$Expiration	0	org.apache.hadoop.hdfs.protocol.CacheDirectiveInfo$Builder:setExpiration(org.apache.hadoop.hdfs.protocol.CacheDirectiveInfo$Expiration)
org.apache.hadoop.hdfs.protocol.Block	setBlockId	blockId	J	long	0	org.apache.hadoop.hdfs.protocol.Block:setBlockId(long)
org.apache.hadoop.hdfs.protocol.Block	setNumBytes	numBytes	J	long	0	org.apache.hadoop.hdfs.protocol.Block:setNumBytes(long)
org.apache.hadoop.hdfs.protocol.Block	setGenerationStamp	generationStamp	J	long	0	org.apache.hadoop.hdfs.protocol.Block:setGenerationStamp(long)
org.apache.hadoop.hdfs.protocol.LocatedBlock	setBlockToken	blockToken	GC	org.apache.hadoop.security.token.Token	0	org.apache.hadoop.hdfs.protocol.LocatedBlock:setBlockToken(org.apache.hadoop.security.token.Token)
org.apache.hadoop.hdfs.protocol.LocatedBlock	setStartOffset	offset	J	long	0	org.apache.hadoop.hdfs.protocol.LocatedBlock:setStartOffset(long)
org.apache.hadoop.hdfs.protocol.LocatedBlock	setCorrupt	corrupt	J	boolean	0	org.apache.hadoop.hdfs.protocol.LocatedBlock:setCorrupt(boolean)
org.apache.hadoop.hdfs.protocol.DatanodeAdminProperties	setHostName	hostName	J	java.lang.String	0	org.apache.hadoop.hdfs.protocol.DatanodeAdminProperties:setHostName(java.lang.String)
org.apache.hadoop.hdfs.protocol.DatanodeAdminProperties	setPort	port	J	int	0	org.apache.hadoop.hdfs.protocol.DatanodeAdminProperties:setPort(int)
org.apache.hadoop.hdfs.protocol.DatanodeAdminProperties	setUpgradeDomain	upgradeDomain	J	java.lang.String	0	org.apache.hadoop.hdfs.protocol.DatanodeAdminProperties:setUpgradeDomain(java.lang.String)
org.apache.hadoop.hdfs.protocol.DatanodeAdminProperties	setAdminState	adminState	C	org.apache.hadoop.hdfs.protocol.DatanodeInfo$AdminStates	0	org.apache.hadoop.hdfs.protocol.DatanodeAdminProperties:setAdminState(org.apache.hadoop.hdfs.protocol.DatanodeInfo$AdminStates)
org.apache.hadoop.hdfs.protocol.DatanodeAdminProperties	setMaintenanceExpireTimeInMS	maintenanceExpireTimeInMS	J	long	0	org.apache.hadoop.hdfs.protocol.DatanodeAdminProperties:setMaintenanceExpireTimeInMS(long)
org.apache.hadoop.hdfs.client.BlockReportOptions$Factory	setIncremental	incremental	J	boolean	0	org.apache.hadoop.hdfs.client.BlockReportOptions$Factory:setIncremental(boolean)
org.apache.hadoop.hdfs.client.BlockReportOptions$Factory	setNamenodeAddr	namenodeAddr	J	java.net.InetSocketAddress	0	org.apache.hadoop.hdfs.client.BlockReportOptions$Factory:setNamenodeAddr(java.net.InetSocketAddress)
org.apache.hadoop.hdfs.client.impl.SnapshotDiffReportGenerator$RenameEntry	setSource	sourcePath	J	byte	2	org.apache.hadoop.hdfs.client.impl.SnapshotDiffReportGenerator$RenameEntry:setSource(byte[][])
org.apache.hadoop.hdfs.client.impl.SnapshotDiffReportGenerator$RenameEntry	setTarget	targetPath	J	byte	2	org.apache.hadoop.hdfs.client.impl.SnapshotDiffReportGenerator$RenameEntry:setTarget(byte[][])
org.apache.hadoop.hdfs.client.impl.BlockReaderLocal$Builder	setVerifyChecksum	verifyChecksum	J	boolean	0	org.apache.hadoop.hdfs.client.impl.BlockReaderLocal$Builder:setVerifyChecksum(boolean)
org.apache.hadoop.hdfs.client.impl.BlockReaderLocal$Builder	setFilename	filename	J	java.lang.String	0	org.apache.hadoop.hdfs.client.impl.BlockReaderLocal$Builder:setFilename(java.lang.String)
org.apache.hadoop.hdfs.client.impl.BlockReaderLocal$Builder	setShortCircuitReplica	replica	C	org.apache.hadoop.hdfs.shortcircuit.ShortCircuitReplica	0	org.apache.hadoop.hdfs.client.impl.BlockReaderLocal$Builder:setShortCircuitReplica(org.apache.hadoop.hdfs.shortcircuit.ShortCircuitReplica)
org.apache.hadoop.hdfs.client.impl.BlockReaderLocal$Builder	setStartOffset	dataPos	J	long	0	org.apache.hadoop.hdfs.client.impl.BlockReaderLocal$Builder:setStartOffset(long)
org.apache.hadoop.hdfs.client.impl.BlockReaderLocal$Builder	setBlock	block	C	org.apache.hadoop.hdfs.protocol.ExtendedBlock	0	org.apache.hadoop.hdfs.client.impl.BlockReaderLocal$Builder:setBlock(org.apache.hadoop.hdfs.protocol.ExtendedBlock)
org.apache.hadoop.hdfs.client.impl.BlockReaderLocal$Builder	setStorageType	storageType	C	org.apache.hadoop.fs.StorageType	0	org.apache.hadoop.hdfs.client.impl.BlockReaderLocal$Builder:setStorageType(org.apache.hadoop.fs.StorageType)
org.apache.hadoop.hdfs.client.impl.BlockReaderFactory	setFileName	fileName	J	java.lang.String	0	org.apache.hadoop.hdfs.client.impl.BlockReaderFactory:setFileName(java.lang.String)
org.apache.hadoop.hdfs.client.impl.BlockReaderFactory	setBlock	block	C	org.apache.hadoop.hdfs.protocol.ExtendedBlock	0	org.apache.hadoop.hdfs.client.impl.BlockReaderFactory:setBlock(org.apache.hadoop.hdfs.protocol.ExtendedBlock)
org.apache.hadoop.hdfs.client.impl.BlockReaderFactory	setBlockToken	token	GC	org.apache.hadoop.security.token.Token	0	org.apache.hadoop.hdfs.client.impl.BlockReaderFactory:setBlockToken(org.apache.hadoop.security.token.Token)
org.apache.hadoop.hdfs.client.impl.BlockReaderFactory	setStartOffset	startOffset	J	long	0	org.apache.hadoop.hdfs.client.impl.BlockReaderFactory:setStartOffset(long)
org.apache.hadoop.hdfs.client.impl.BlockReaderFactory	setVerifyChecksum	verifyChecksum	J	boolean	0	org.apache.hadoop.hdfs.client.impl.BlockReaderFactory:setVerifyChecksum(boolean)
org.apache.hadoop.hdfs.client.impl.BlockReaderFactory	setClientName	clientName	J	java.lang.String	0	org.apache.hadoop.hdfs.client.impl.BlockReaderFactory:setClientName(java.lang.String)
org.apache.hadoop.hdfs.client.impl.BlockReaderFactory	setDatanodeInfo	datanode	C	org.apache.hadoop.hdfs.protocol.DatanodeInfo	0	org.apache.hadoop.hdfs.client.impl.BlockReaderFactory:setDatanodeInfo(org.apache.hadoop.hdfs.protocol.DatanodeInfo)
org.apache.hadoop.hdfs.client.impl.BlockReaderFactory	setStorageType	storageType	C	org.apache.hadoop.fs.StorageType	0	org.apache.hadoop.hdfs.client.impl.BlockReaderFactory:setStorageType(org.apache.hadoop.fs.StorageType)
org.apache.hadoop.hdfs.client.impl.BlockReaderFactory	setAllowShortCircuitLocalReads	allowShortCircuitLocalReads	J	boolean	0	org.apache.hadoop.hdfs.client.impl.BlockReaderFactory:setAllowShortCircuitLocalReads(boolean)
org.apache.hadoop.hdfs.client.impl.BlockReaderFactory	setClientCacheContext	clientContext	C	org.apache.hadoop.hdfs.ClientContext	0	org.apache.hadoop.hdfs.client.impl.BlockReaderFactory:setClientCacheContext(org.apache.hadoop.hdfs.ClientContext)
org.apache.hadoop.hdfs.client.impl.BlockReaderFactory	setLength	length	J	long	0	org.apache.hadoop.hdfs.client.impl.BlockReaderFactory:setLength(long)
org.apache.hadoop.hdfs.client.impl.BlockReaderFactory	setCachingStrategy	cachingStrategy	C	org.apache.hadoop.hdfs.server.datanode.CachingStrategy	0	org.apache.hadoop.hdfs.client.impl.BlockReaderFactory:setCachingStrategy(org.apache.hadoop.hdfs.server.datanode.CachingStrategy)
org.apache.hadoop.hdfs.client.impl.BlockReaderFactory	setInetSocketAddress	inetSocketAddress	J	java.net.InetSocketAddress	0	org.apache.hadoop.hdfs.client.impl.BlockReaderFactory:setInetSocketAddress(java.net.InetSocketAddress)
org.apache.hadoop.hdfs.client.impl.BlockReaderFactory	setUserGroupInformation	userGroupInformation	C	org.apache.hadoop.security.UserGroupInformation	0	org.apache.hadoop.hdfs.client.impl.BlockReaderFactory:setUserGroupInformation(org.apache.hadoop.security.UserGroupInformation)
org.apache.hadoop.hdfs.client.impl.BlockReaderFactory	setRemotePeerFactory	remotePeerFactory	C	org.apache.hadoop.hdfs.RemotePeerFactory	0	org.apache.hadoop.hdfs.client.impl.BlockReaderFactory:setRemotePeerFactory(org.apache.hadoop.hdfs.RemotePeerFactory)
org.apache.hadoop.hdfs.client.impl.BlockReaderFactory	setConfiguration	configuration	C	org.apache.hadoop.conf.Configuration	0	org.apache.hadoop.hdfs.client.impl.BlockReaderFactory:setConfiguration(org.apache.hadoop.conf.Configuration)
org.apache.hadoop.hdfs.client.impl.LeaseRenewer	setRenewalTime	renewal	J	long	0	org.apache.hadoop.hdfs.client.impl.LeaseRenewer:setRenewalTime(long)
org.apache.hadoop.hdfs.client.impl.LeaseRenewer	setEmptyTime	emptyTime	J	long	0	org.apache.hadoop.hdfs.client.impl.LeaseRenewer:setEmptyTime(long)
org.apache.hadoop.lib.servlet.ServerWebApp	setAuthority	authority	J	java.net.InetSocketAddress	0	org.apache.hadoop.lib.servlet.ServerWebApp:setAuthority(java.net.InetSocketAddress)
org.apache.hadoop.hdfs.nfs.nfs3.WriteCtx	setDataState	dataState	C	org.apache.hadoop.hdfs.nfs.nfs3.WriteCtx$DataState	0	org.apache.hadoop.hdfs.nfs.nfs3.WriteCtx:setDataState(org.apache.hadoop.hdfs.nfs.nfs3.WriteCtx$DataState)
org.apache.hadoop.hdfs.nfs.nfs3.WriteCtx	setReplied	replied	J	boolean	0	org.apache.hadoop.hdfs.nfs.nfs3.WriteCtx:setReplied(boolean)
org.apache.hadoop.hdfs.nfs.nfs3.OpenFileCtx	setActiveStatusForTest	activeState	J	boolean	0	org.apache.hadoop.hdfs.nfs.nfs3.OpenFileCtx:setActiveStatusForTest(boolean)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$RouterRecordProto$Builder	setDateCreated	dateCreated_	J	long	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$RouterRecordProto$Builder:setDateCreated(long)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$RouterRecordProto$Builder	setDateModified	dateModified_	J	long	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$RouterRecordProto$Builder:setDateModified(long)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$RouterRecordProto$Builder	setAddress	address_	J	java.lang.Object	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$RouterRecordProto$Builder:setAddress(java.lang.String)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$RouterRecordProto$Builder	setAddressBytes	address_	J	java.lang.Object	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$RouterRecordProto$Builder:setAddressBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$RouterRecordProto$Builder	setStatus	status_	J	java.lang.Object	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$RouterRecordProto$Builder:setStatus(java.lang.String)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$RouterRecordProto$Builder	setStatusBytes	status_	J	java.lang.Object	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$RouterRecordProto$Builder:setStatusBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$RouterRecordProto$Builder	setVersion	version_	J	java.lang.Object	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$RouterRecordProto$Builder:setVersion(java.lang.String)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$RouterRecordProto$Builder	setVersionBytes	version_	J	java.lang.Object	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$RouterRecordProto$Builder:setVersionBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$RouterRecordProto$Builder	setCompileInfo	compileInfo_	J	java.lang.Object	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$RouterRecordProto$Builder:setCompileInfo(java.lang.String)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$RouterRecordProto$Builder	setCompileInfoBytes	compileInfo_	J	java.lang.Object	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$RouterRecordProto$Builder:setCompileInfoBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$RouterRecordProto$Builder	setDateStarted	dateStarted_	J	long	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$RouterRecordProto$Builder:setDateStarted(long)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$RouterRecordProto$Builder	setAdminAddress	adminAddress_	J	java.lang.Object	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$RouterRecordProto$Builder:setAdminAddress(java.lang.String)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$RouterRecordProto$Builder	setAdminAddressBytes	adminAddress_	J	java.lang.Object	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$RouterRecordProto$Builder:setAdminAddressBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$GetRouterRegistrationRequestProto$Builder	setRouterId	routerId_	J	java.lang.Object	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$GetRouterRegistrationRequestProto$Builder:setRouterId(java.lang.String)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$GetRouterRegistrationRequestProto$Builder	setRouterIdBytes	routerId_	J	java.lang.Object	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$GetRouterRegistrationRequestProto$Builder:setRouterIdBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$UpdateNamenodeRegistrationResponseProto$Builder	setStatus	status_	J	boolean	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$UpdateNamenodeRegistrationResponseProto$Builder:setStatus(boolean)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$GetMountTableEntriesResponseProto$Builder	setTimestamp	timestamp_	J	long	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$GetMountTableEntriesResponseProto$Builder:setTimestamp(long)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$DisableNameserviceRequestProto$Builder	setNameServiceId	nameServiceId_	J	java.lang.Object	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$DisableNameserviceRequestProto$Builder:setNameServiceId(java.lang.String)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$DisableNameserviceRequestProto$Builder	setNameServiceIdBytes	nameServiceId_	J	java.lang.Object	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$DisableNameserviceRequestProto$Builder:setNameServiceIdBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$GetSafeModeResponseProto$Builder	setIsInSafeMode	isInSafeMode_	J	boolean	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$GetSafeModeResponseProto$Builder:setIsInSafeMode(boolean)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$GetMountTableEntriesRequestProto$Builder	setSrcPath	srcPath_	J	java.lang.Object	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$GetMountTableEntriesRequestProto$Builder:setSrcPath(java.lang.String)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$GetMountTableEntriesRequestProto$Builder	setSrcPathBytes	srcPath_	J	java.lang.Object	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$GetMountTableEntriesRequestProto$Builder:setSrcPathBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$UpdateNamenodeRegistrationRequestProto$Builder	setNameserviceId	nameserviceId_	J	java.lang.Object	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$UpdateNamenodeRegistrationRequestProto$Builder:setNameserviceId(java.lang.String)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$UpdateNamenodeRegistrationRequestProto$Builder	setNameserviceIdBytes	nameserviceId_	J	java.lang.Object	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$UpdateNamenodeRegistrationRequestProto$Builder:setNameserviceIdBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$UpdateNamenodeRegistrationRequestProto$Builder	setNamenodeId	namenodeId_	J	java.lang.Object	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$UpdateNamenodeRegistrationRequestProto$Builder:setNamenodeId(java.lang.String)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$UpdateNamenodeRegistrationRequestProto$Builder	setNamenodeIdBytes	namenodeId_	J	java.lang.Object	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$UpdateNamenodeRegistrationRequestProto$Builder:setNamenodeIdBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$UpdateNamenodeRegistrationRequestProto$Builder	setState	state_	J	java.lang.Object	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$UpdateNamenodeRegistrationRequestProto$Builder:setState(java.lang.String)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$UpdateNamenodeRegistrationRequestProto$Builder	setStateBytes	state_	J	java.lang.Object	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$UpdateNamenodeRegistrationRequestProto$Builder:setStateBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$NamenodeMembershipStatsRecordProto$Builder	setTotalSpace	totalSpace_	J	long	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$NamenodeMembershipStatsRecordProto$Builder:setTotalSpace(long)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$NamenodeMembershipStatsRecordProto$Builder	setAvailableSpace	availableSpace_	J	long	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$NamenodeMembershipStatsRecordProto$Builder:setAvailableSpace(long)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$NamenodeMembershipStatsRecordProto$Builder	setProvidedSpace	providedSpace_	J	long	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$NamenodeMembershipStatsRecordProto$Builder:setProvidedSpace(long)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$NamenodeMembershipStatsRecordProto$Builder	setNumOfFiles	numOfFiles_	J	long	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$NamenodeMembershipStatsRecordProto$Builder:setNumOfFiles(long)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$NamenodeMembershipStatsRecordProto$Builder	setNumOfBlocks	numOfBlocks_	J	long	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$NamenodeMembershipStatsRecordProto$Builder:setNumOfBlocks(long)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$NamenodeMembershipStatsRecordProto$Builder	setNumOfBlocksMissing	numOfBlocksMissing_	J	long	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$NamenodeMembershipStatsRecordProto$Builder:setNumOfBlocksMissing(long)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$NamenodeMembershipStatsRecordProto$Builder	setNumOfBlocksPendingReplication	numOfBlocksPendingReplication_	J	long	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$NamenodeMembershipStatsRecordProto$Builder:setNumOfBlocksPendingReplication(long)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$NamenodeMembershipStatsRecordProto$Builder	setNumOfBlocksUnderReplicated	numOfBlocksUnderReplicated_	J	long	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$NamenodeMembershipStatsRecordProto$Builder:setNumOfBlocksUnderReplicated(long)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$NamenodeMembershipStatsRecordProto$Builder	setNumOfBlocksPendingDeletion	numOfBlocksPendingDeletion_	J	long	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$NamenodeMembershipStatsRecordProto$Builder:setNumOfBlocksPendingDeletion(long)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$NamenodeMembershipStatsRecordProto$Builder	setNumOfActiveDatanodes	numOfActiveDatanodes_	J	int	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$NamenodeMembershipStatsRecordProto$Builder:setNumOfActiveDatanodes(int)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$NamenodeMembershipStatsRecordProto$Builder	setNumOfDeadDatanodes	numOfDeadDatanodes_	J	int	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$NamenodeMembershipStatsRecordProto$Builder:setNumOfDeadDatanodes(int)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$NamenodeMembershipStatsRecordProto$Builder	setNumOfDecommissioningDatanodes	numOfDecommissioningDatanodes_	J	int	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$NamenodeMembershipStatsRecordProto$Builder:setNumOfDecommissioningDatanodes(int)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$NamenodeMembershipStatsRecordProto$Builder	setNumOfDecomActiveDatanodes	numOfDecomActiveDatanodes_	J	int	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$NamenodeMembershipStatsRecordProto$Builder:setNumOfDecomActiveDatanodes(int)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$NamenodeMembershipStatsRecordProto$Builder	setNumOfDecomDeadDatanodes	numOfDecomDeadDatanodes_	J	int	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$NamenodeMembershipStatsRecordProto$Builder:setNumOfDecomDeadDatanodes(int)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$NamenodeMembershipStatsRecordProto$Builder	setNumOfStaleDatanodes	numOfStaleDatanodes_	J	int	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$NamenodeMembershipStatsRecordProto$Builder:setNumOfStaleDatanodes(int)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$NamenodeMembershipStatsRecordProto$Builder	setNumOfInMaintenanceLiveDataNodes	numOfInMaintenanceLiveDataNodes_	J	int	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$NamenodeMembershipStatsRecordProto$Builder:setNumOfInMaintenanceLiveDataNodes(int)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$NamenodeMembershipStatsRecordProto$Builder	setNumOfInMaintenanceDeadDataNodes	numOfInMaintenanceDeadDataNodes_	J	int	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$NamenodeMembershipStatsRecordProto$Builder:setNumOfInMaintenanceDeadDataNodes(int)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$NamenodeMembershipStatsRecordProto$Builder	setNumOfEnteringMaintenanceDataNodes	numOfEnteringMaintenanceDataNodes_	J	int	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$NamenodeMembershipStatsRecordProto$Builder:setNumOfEnteringMaintenanceDataNodes(int)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$StateStoreVersionRecordProto$Builder	setMembershipVersion	membershipVersion_	J	long	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$StateStoreVersionRecordProto$Builder:setMembershipVersion(long)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$StateStoreVersionRecordProto$Builder	setMountTableVersion	mountTableVersion_	J	long	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$StateStoreVersionRecordProto$Builder:setMountTableVersion(long)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$RouterHeartbeatResponseProto$Builder	setStatus	status_	J	boolean	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$RouterHeartbeatResponseProto$Builder:setStatus(boolean)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$RemoteLocationProto$Builder	setNameserviceId	nameserviceId_	J	java.lang.Object	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$RemoteLocationProto$Builder:setNameserviceId(java.lang.String)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$RemoteLocationProto$Builder	setNameserviceIdBytes	nameserviceId_	J	java.lang.Object	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$RemoteLocationProto$Builder:setNameserviceIdBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$RemoteLocationProto$Builder	setPath	path_	J	java.lang.Object	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$RemoteLocationProto$Builder:setPath(java.lang.String)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$RemoteLocationProto$Builder	setPathBytes	path_	J	java.lang.Object	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$RemoteLocationProto$Builder:setPathBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$GetRouterRegistrationsResponseProto$Builder	setTimestamp	timestamp_	J	long	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$GetRouterRegistrationsResponseProto$Builder:setTimestamp(long)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$GetDestinationRequestProto$Builder	setSrcPath	srcPath_	J	java.lang.Object	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$GetDestinationRequestProto$Builder:setSrcPath(java.lang.String)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$GetDestinationRequestProto$Builder	setSrcPathBytes	srcPath_	J	java.lang.Object	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$GetDestinationRequestProto$Builder:setSrcPathBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$LeaveSafeModeResponseProto$Builder	setStatus	status_	J	boolean	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$LeaveSafeModeResponseProto$Builder:setStatus(boolean)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$DisabledNameserviceRecordProto$Builder	setDateCreated	dateCreated_	J	long	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$DisabledNameserviceRecordProto$Builder:setDateCreated(long)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$DisabledNameserviceRecordProto$Builder	setDateModified	dateModified_	J	long	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$DisabledNameserviceRecordProto$Builder:setDateModified(long)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$DisabledNameserviceRecordProto$Builder	setNameServiceId	nameServiceId_	J	java.lang.Object	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$DisabledNameserviceRecordProto$Builder:setNameServiceId(java.lang.String)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$DisabledNameserviceRecordProto$Builder	setNameServiceIdBytes	nameServiceId_	J	java.lang.Object	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$DisabledNameserviceRecordProto$Builder:setNameServiceIdBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$EnableNameserviceRequestProto$Builder	setNameServiceId	nameServiceId_	J	java.lang.Object	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$EnableNameserviceRequestProto$Builder:setNameServiceId(java.lang.String)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$EnableNameserviceRequestProto$Builder	setNameServiceIdBytes	nameServiceId_	J	java.lang.Object	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$EnableNameserviceRequestProto$Builder:setNameServiceIdBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$AddMountTableEntryResponseProto$Builder	setStatus	status_	J	boolean	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$AddMountTableEntryResponseProto$Builder:setStatus(boolean)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$RefreshSuperUserGroupsConfigurationResponseProto$Builder	setStatus	status_	J	boolean	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$RefreshSuperUserGroupsConfigurationResponseProto$Builder:setStatus(boolean)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$EnableNameserviceResponseProto$Builder	setStatus	status_	J	boolean	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$EnableNameserviceResponseProto$Builder:setStatus(boolean)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$RefreshMountTableEntriesResponseProto$Builder	setResult	result_	J	boolean	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$RefreshMountTableEntriesResponseProto$Builder:setResult(boolean)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$EnterSafeModeResponseProto$Builder	setStatus	status_	J	boolean	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$EnterSafeModeResponseProto$Builder:setStatus(boolean)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$RemoveMountTableEntryRequestProto$Builder	setSrcPath	srcPath_	J	java.lang.Object	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$RemoveMountTableEntryRequestProto$Builder:setSrcPath(java.lang.String)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$RemoveMountTableEntryRequestProto$Builder	setSrcPathBytes	srcPath_	J	java.lang.Object	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$RemoveMountTableEntryRequestProto$Builder:setSrcPathBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$DisableNameserviceResponseProto$Builder	setStatus	status_	J	boolean	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$DisableNameserviceResponseProto$Builder:setStatus(boolean)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$FederationNamespaceInfoProto$Builder	setBlockPoolId	blockPoolId_	J	java.lang.Object	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$FederationNamespaceInfoProto$Builder:setBlockPoolId(java.lang.String)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$FederationNamespaceInfoProto$Builder	setBlockPoolIdBytes	blockPoolId_	J	java.lang.Object	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$FederationNamespaceInfoProto$Builder:setBlockPoolIdBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$FederationNamespaceInfoProto$Builder	setClusterId	clusterId_	J	java.lang.Object	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$FederationNamespaceInfoProto$Builder:setClusterId(java.lang.String)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$FederationNamespaceInfoProto$Builder	setClusterIdBytes	clusterId_	J	java.lang.Object	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$FederationNamespaceInfoProto$Builder:setClusterIdBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$FederationNamespaceInfoProto$Builder	setNameserviceId	nameserviceId_	J	java.lang.Object	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$FederationNamespaceInfoProto$Builder:setNameserviceId(java.lang.String)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$FederationNamespaceInfoProto$Builder	setNameserviceIdBytes	nameserviceId_	J	java.lang.Object	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$FederationNamespaceInfoProto$Builder:setNameserviceIdBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$UpdateMountTableEntryResponseProto$Builder	setStatus	status_	J	boolean	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$UpdateMountTableEntryResponseProto$Builder:setStatus(boolean)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$RemoveMountTableEntryResponseProto$Builder	setStatus	status_	J	boolean	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$RemoveMountTableEntryResponseProto$Builder:setStatus(boolean)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$NamenodeHeartbeatResponseProto$Builder	setStatus	status_	J	boolean	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$NamenodeHeartbeatResponseProto$Builder:setStatus(boolean)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$NamenodeMembershipRecordProto$Builder	setDateCreated	dateCreated_	J	long	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$NamenodeMembershipRecordProto$Builder:setDateCreated(long)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$NamenodeMembershipRecordProto$Builder	setDateModified	dateModified_	J	long	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$NamenodeMembershipRecordProto$Builder:setDateModified(long)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$NamenodeMembershipRecordProto$Builder	setLastContact	lastContact_	J	long	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$NamenodeMembershipRecordProto$Builder:setLastContact(long)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$NamenodeMembershipRecordProto$Builder	setRouterId	routerId_	J	java.lang.Object	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$NamenodeMembershipRecordProto$Builder:setRouterId(java.lang.String)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$NamenodeMembershipRecordProto$Builder	setRouterIdBytes	routerId_	J	java.lang.Object	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$NamenodeMembershipRecordProto$Builder:setRouterIdBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$NamenodeMembershipRecordProto$Builder	setNameserviceId	nameserviceId_	J	java.lang.Object	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$NamenodeMembershipRecordProto$Builder:setNameserviceId(java.lang.String)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$NamenodeMembershipRecordProto$Builder	setNameserviceIdBytes	nameserviceId_	J	java.lang.Object	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$NamenodeMembershipRecordProto$Builder:setNameserviceIdBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$NamenodeMembershipRecordProto$Builder	setNamenodeId	namenodeId_	J	java.lang.Object	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$NamenodeMembershipRecordProto$Builder:setNamenodeId(java.lang.String)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$NamenodeMembershipRecordProto$Builder	setNamenodeIdBytes	namenodeId_	J	java.lang.Object	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$NamenodeMembershipRecordProto$Builder:setNamenodeIdBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$NamenodeMembershipRecordProto$Builder	setClusterId	clusterId_	J	java.lang.Object	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$NamenodeMembershipRecordProto$Builder:setClusterId(java.lang.String)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$NamenodeMembershipRecordProto$Builder	setClusterIdBytes	clusterId_	J	java.lang.Object	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$NamenodeMembershipRecordProto$Builder:setClusterIdBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$NamenodeMembershipRecordProto$Builder	setBlockPoolId	blockPoolId_	J	java.lang.Object	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$NamenodeMembershipRecordProto$Builder:setBlockPoolId(java.lang.String)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$NamenodeMembershipRecordProto$Builder	setBlockPoolIdBytes	blockPoolId_	J	java.lang.Object	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$NamenodeMembershipRecordProto$Builder:setBlockPoolIdBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$NamenodeMembershipRecordProto$Builder	setWebAddress	webAddress_	J	java.lang.Object	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$NamenodeMembershipRecordProto$Builder:setWebAddress(java.lang.String)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$NamenodeMembershipRecordProto$Builder	setWebAddressBytes	webAddress_	J	java.lang.Object	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$NamenodeMembershipRecordProto$Builder:setWebAddressBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$NamenodeMembershipRecordProto$Builder	setRpcAddress	rpcAddress_	J	java.lang.Object	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$NamenodeMembershipRecordProto$Builder:setRpcAddress(java.lang.String)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$NamenodeMembershipRecordProto$Builder	setRpcAddressBytes	rpcAddress_	J	java.lang.Object	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$NamenodeMembershipRecordProto$Builder:setRpcAddressBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$NamenodeMembershipRecordProto$Builder	setServiceAddress	serviceAddress_	J	java.lang.Object	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$NamenodeMembershipRecordProto$Builder:setServiceAddress(java.lang.String)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$NamenodeMembershipRecordProto$Builder	setServiceAddressBytes	serviceAddress_	J	java.lang.Object	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$NamenodeMembershipRecordProto$Builder:setServiceAddressBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$NamenodeMembershipRecordProto$Builder	setLifelineAddress	lifelineAddress_	J	java.lang.Object	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$NamenodeMembershipRecordProto$Builder:setLifelineAddress(java.lang.String)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$NamenodeMembershipRecordProto$Builder	setLifelineAddressBytes	lifelineAddress_	J	java.lang.Object	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$NamenodeMembershipRecordProto$Builder:setLifelineAddressBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$NamenodeMembershipRecordProto$Builder	setState	state_	J	java.lang.Object	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$NamenodeMembershipRecordProto$Builder:setState(java.lang.String)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$NamenodeMembershipRecordProto$Builder	setStateBytes	state_	J	java.lang.Object	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$NamenodeMembershipRecordProto$Builder:setStateBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$NamenodeMembershipRecordProto$Builder	setIsSafeMode	isSafeMode_	J	boolean	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$NamenodeMembershipRecordProto$Builder:setIsSafeMode(boolean)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$NamenodeMembershipRecordProto$Builder	setWebScheme	webScheme_	J	java.lang.Object	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$NamenodeMembershipRecordProto$Builder:setWebScheme(java.lang.String)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$NamenodeMembershipRecordProto$Builder	setWebSchemeBytes	webScheme_	J	java.lang.Object	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$NamenodeMembershipRecordProto$Builder:setWebSchemeBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$MountTableRecordProto$Builder	setSrcPath	srcPath_	J	java.lang.Object	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$MountTableRecordProto$Builder:setSrcPath(java.lang.String)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$MountTableRecordProto$Builder	setSrcPathBytes	srcPath_	J	java.lang.Object	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$MountTableRecordProto$Builder:setSrcPathBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$MountTableRecordProto$Builder	setDateCreated	dateCreated_	J	long	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$MountTableRecordProto$Builder:setDateCreated(long)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$MountTableRecordProto$Builder	setDateModified	dateModified_	J	long	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$MountTableRecordProto$Builder:setDateModified(long)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$MountTableRecordProto$Builder	setReadOnly	readOnly_	J	boolean	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$MountTableRecordProto$Builder:setReadOnly(boolean)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$MountTableRecordProto$Builder	setOwnerName	ownerName_	J	java.lang.Object	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$MountTableRecordProto$Builder:setOwnerName(java.lang.String)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$MountTableRecordProto$Builder	setOwnerNameBytes	ownerName_	J	java.lang.Object	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$MountTableRecordProto$Builder:setOwnerNameBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$MountTableRecordProto$Builder	setGroupName	groupName_	J	java.lang.Object	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$MountTableRecordProto$Builder:setGroupName(java.lang.String)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$MountTableRecordProto$Builder	setGroupNameBytes	groupName_	J	java.lang.Object	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$MountTableRecordProto$Builder:setGroupNameBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$MountTableRecordProto$Builder	setMode	mode_	J	int	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$MountTableRecordProto$Builder:setMode(int)
org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$MountTableRecordProto$Builder	setFaultTolerant	faultTolerant_	J	boolean	0	org.apache.hadoop.hdfs.federation.protocol.proto.HdfsServerFederationProtos$MountTableRecordProto$Builder:setFaultTolerant(boolean)
org.apache.hadoop.hdfs.server.federation.resolver.NamenodeStatusReport	setHAServiceState	status	C	org.apache.hadoop.ha.HAServiceProtocol$HAServiceState	0	org.apache.hadoop.hdfs.server.federation.resolver.NamenodeStatusReport:setHAServiceState(org.apache.hadoop.ha.HAServiceProtocol$HAServiceState)
org.apache.hadoop.hdfs.server.federation.resolver.NamenodeStatusReport	setSafeMode	safeMode	J	boolean	0	org.apache.hadoop.hdfs.server.federation.resolver.NamenodeStatusReport:setSafeMode(boolean)
org.apache.hadoop.hdfs.server.federation.resolver.NamenodeStatusReport	setRegistrationValid	registrationValid	J	boolean	0	org.apache.hadoop.hdfs.server.federation.resolver.NamenodeStatusReport:setRegistrationValid(boolean)
org.apache.hadoop.hdfs.server.federation.resolver.MembershipNamenodeResolver	setRouterId	routerId	J	java.lang.String	0	org.apache.hadoop.hdfs.server.federation.resolver.MembershipNamenodeResolver:setRouterId(java.lang.String)
org.apache.hadoop.hdfs.server.federation.resolver.MountTableResolver	setDefaultNameService	defaultNameService	J	java.lang.String	0	org.apache.hadoop.hdfs.server.federation.resolver.MountTableResolver:setDefaultNameService(java.lang.String)
org.apache.hadoop.hdfs.server.federation.resolver.MountTableResolver	setDefaultNSEnable	defaultNSEnable	J	boolean	0	org.apache.hadoop.hdfs.server.federation.resolver.MountTableResolver:setDefaultNSEnable(boolean)
org.apache.hadoop.hdfs.server.federation.resolver.MountTableResolver	setDisabled	disabled	J	boolean	0	org.apache.hadoop.hdfs.server.federation.resolver.MountTableResolver:setDisabled(boolean)
org.apache.hadoop.hdfs.server.federation.router.Router	setAdminServerAddress	adminAddress	J	java.net.InetSocketAddress	0	org.apache.hadoop.hdfs.server.federation.router.Router:setAdminServerAddress(java.net.InetSocketAddress)
org.apache.hadoop.hdfs.server.federation.router.Router	setRouterId	routerId	J	java.lang.String	0	org.apache.hadoop.hdfs.server.federation.router.Router:setRouterId(java.lang.String)
org.apache.hadoop.hdfs.server.federation.router.PeriodicService	setIntervalMs	intervalMs	J	long	0	org.apache.hadoop.hdfs.server.federation.router.PeriodicService:setIntervalMs(long)
org.apache.hadoop.hdfs.server.federation.router.MountTableRefresherThread	setCountDownLatch	countDownLatch	J	java.util.concurrent.CountDownLatch	0	org.apache.hadoop.hdfs.server.federation.router.MountTableRefresherThread:setCountDownLatch(java.util.concurrent.CountDownLatch)
org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreFileBaseImpl	setInitialized	initialized	J	boolean	0	org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreFileBaseImpl:setInitialized(boolean)
org.apache.hadoop.hdfs.server.federation.store.StateStoreService	setIdentifier	identifier	J	java.lang.String	0	org.apache.hadoop.hdfs.server.federation.store.StateStoreService:setIdentifier(java.lang.String)
org.apache.hadoop.hdfs.server.federation.store.MountTableStore	setRefreshService	refreshService	C	org.apache.hadoop.hdfs.server.federation.router.MountTableRefresherService	0	org.apache.hadoop.hdfs.server.federation.store.MountTableStore:setRefreshService(org.apache.hadoop.hdfs.server.federation.router.MountTableRefresherService)
org.apache.hadoop.hdfs.server.federation.store.MountTableStore	setQuotaManager	quotaManager	C	org.apache.hadoop.hdfs.server.federation.router.RouterQuotaManager	0	org.apache.hadoop.hdfs.server.federation.store.MountTableStore:setQuotaManager(org.apache.hadoop.hdfs.server.federation.router.RouterQuotaManager)
org.apache.hadoop.hdfs.qjournal.server.Journal	setTriedJournalSyncerStartedwithnsId	triedJournalSyncerStartedwithnsId	J	boolean	0	org.apache.hadoop.hdfs.qjournal.server.Journal:setTriedJournalSyncerStartedwithnsId(boolean)
org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$NewEpochRequestProto$Builder	setEpoch	epoch_	J	long	0	org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$NewEpochRequestProto$Builder:setEpoch(long)
org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$NewEpochRequestProto$Builder	setNameServiceId	nameServiceId_	J	java.lang.Object	0	org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$NewEpochRequestProto$Builder:setNameServiceId(java.lang.String)
org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$NewEpochRequestProto$Builder	setNameServiceIdBytes	nameServiceId_	J	java.lang.Object	0	org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$NewEpochRequestProto$Builder:setNameServiceIdBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$PrepareRecoveryResponseProto$Builder	setAcceptedInEpoch	acceptedInEpoch_	J	long	0	org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$PrepareRecoveryResponseProto$Builder:setAcceptedInEpoch(long)
org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$PrepareRecoveryResponseProto$Builder	setLastWriterEpoch	lastWriterEpoch_	J	long	0	org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$PrepareRecoveryResponseProto$Builder:setLastWriterEpoch(long)
org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$PrepareRecoveryResponseProto$Builder	setLastCommittedTxId	lastCommittedTxId_	J	long	0	org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$PrepareRecoveryResponseProto$Builder:setLastCommittedTxId(long)
org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$IsFormattedRequestProto$Builder	setNameServiceId	nameServiceId_	J	java.lang.Object	0	org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$IsFormattedRequestProto$Builder:setNameServiceId(java.lang.String)
org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$IsFormattedRequestProto$Builder	setNameServiceIdBytes	nameServiceId_	J	java.lang.Object	0	org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$IsFormattedRequestProto$Builder:setNameServiceIdBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$GetEditLogManifestResponseProto$Builder	setHttpPort	httpPort_	J	int	0	org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$GetEditLogManifestResponseProto$Builder:setHttpPort(int)
org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$GetEditLogManifestResponseProto$Builder	setFromURL	fromURL_	J	java.lang.Object	0	org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$GetEditLogManifestResponseProto$Builder:setFromURL(java.lang.String)
org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$GetEditLogManifestResponseProto$Builder	setFromURLBytes	fromURL_	J	java.lang.Object	0	org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$GetEditLogManifestResponseProto$Builder:setFromURLBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$DiscardSegmentsRequestProto$Builder	setStartTxId	startTxId_	J	long	0	org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$DiscardSegmentsRequestProto$Builder:setStartTxId(long)
org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$DiscardSegmentsRequestProto$Builder	setNameServiceId	nameServiceId_	J	java.lang.Object	0	org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$DiscardSegmentsRequestProto$Builder:setNameServiceId(java.lang.String)
org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$DiscardSegmentsRequestProto$Builder	setNameServiceIdBytes	nameServiceId_	J	java.lang.Object	0	org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$DiscardSegmentsRequestProto$Builder:setNameServiceIdBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$GetJournalCTimeResponseProto$Builder	setResultCTime	resultCTime_	J	long	0	org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$GetJournalCTimeResponseProto$Builder:setResultCTime(long)
org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$GetJournalStateRequestProto$Builder	setNameServiceId	nameServiceId_	J	java.lang.Object	0	org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$GetJournalStateRequestProto$Builder:setNameServiceId(java.lang.String)
org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$GetJournalStateRequestProto$Builder	setNameServiceIdBytes	nameServiceId_	J	java.lang.Object	0	org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$GetJournalStateRequestProto$Builder:setNameServiceIdBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$PersistedRecoveryPaxosData$Builder	setAcceptedInEpoch	acceptedInEpoch_	J	long	0	org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$PersistedRecoveryPaxosData$Builder:setAcceptedInEpoch(long)
org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$FormatRequestProto$Builder	setNameServiceId	nameServiceId_	J	java.lang.Object	0	org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$FormatRequestProto$Builder:setNameServiceId(java.lang.String)
org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$FormatRequestProto$Builder	setNameServiceIdBytes	nameServiceId_	J	java.lang.Object	0	org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$FormatRequestProto$Builder:setNameServiceIdBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$FormatRequestProto$Builder	setForce	force_	J	boolean	0	org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$FormatRequestProto$Builder:setForce(boolean)
org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$CanRollBackRequestProto$Builder	setTargetLayoutVersion	targetLayoutVersion_	J	int	0	org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$CanRollBackRequestProto$Builder:setTargetLayoutVersion(int)
org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$CanRollBackRequestProto$Builder	setNameServiceId	nameServiceId_	J	java.lang.Object	0	org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$CanRollBackRequestProto$Builder:setNameServiceId(java.lang.String)
org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$CanRollBackRequestProto$Builder	setNameServiceIdBytes	nameServiceId_	J	java.lang.Object	0	org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$CanRollBackRequestProto$Builder:setNameServiceIdBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$DoFinalizeRequestProto$Builder	setNameServiceId	nameServiceId_	J	java.lang.Object	0	org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$DoFinalizeRequestProto$Builder:setNameServiceId(java.lang.String)
org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$DoFinalizeRequestProto$Builder	setNameServiceIdBytes	nameServiceId_	J	java.lang.Object	0	org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$DoFinalizeRequestProto$Builder:setNameServiceIdBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$PurgeLogsRequestProto$Builder	setMinTxIdToKeep	minTxIdToKeep_	J	long	0	org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$PurgeLogsRequestProto$Builder:setMinTxIdToKeep(long)
org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$JournalRequestProto$Builder	setFirstTxnId	firstTxnId_	J	long	0	org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$JournalRequestProto$Builder:setFirstTxnId(long)
org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$JournalRequestProto$Builder	setNumTxns	numTxns_	J	int	0	org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$JournalRequestProto$Builder:setNumTxns(int)
org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$JournalRequestProto$Builder	setRecords	records_	C	org.apache.hadoop.thirdparty.protobuf.ByteString	0	org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$JournalRequestProto$Builder:setRecords(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$JournalRequestProto$Builder	setSegmentTxnId	segmentTxnId_	J	long	0	org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$JournalRequestProto$Builder:setSegmentTxnId(long)
org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$JournalRequestProto$Builder	setNameServiceId	nameServiceId_	J	java.lang.Object	0	org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$JournalRequestProto$Builder:setNameServiceId(java.lang.String)
org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$JournalRequestProto$Builder	setNameServiceIdBytes	nameServiceId_	J	java.lang.Object	0	org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$JournalRequestProto$Builder:setNameServiceIdBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$RequestInfoProto$Builder	setEpoch	epoch_	J	long	0	org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$RequestInfoProto$Builder:setEpoch(long)
org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$RequestInfoProto$Builder	setIpcSerialNumber	ipcSerialNumber_	J	long	0	org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$RequestInfoProto$Builder:setIpcSerialNumber(long)
org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$RequestInfoProto$Builder	setCommittedTxId	committedTxId_	J	long	0	org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$RequestInfoProto$Builder:setCommittedTxId(long)
org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$RequestInfoProto$Builder	setNameServiceId	nameServiceId_	J	java.lang.Object	0	org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$RequestInfoProto$Builder:setNameServiceId(java.lang.String)
org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$RequestInfoProto$Builder	setNameServiceIdBytes	nameServiceId_	J	java.lang.Object	0	org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$RequestInfoProto$Builder:setNameServiceIdBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$DoRollbackRequestProto$Builder	setNameserviceId	nameserviceId_	J	java.lang.Object	0	org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$DoRollbackRequestProto$Builder:setNameserviceId(java.lang.String)
org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$DoRollbackRequestProto$Builder	setNameserviceIdBytes	nameserviceId_	J	java.lang.Object	0	org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$DoRollbackRequestProto$Builder:setNameserviceIdBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$SegmentStateProto$Builder	setStartTxId	startTxId_	J	long	0	org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$SegmentStateProto$Builder:setStartTxId(long)
org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$SegmentStateProto$Builder	setEndTxId	endTxId_	J	long	0	org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$SegmentStateProto$Builder:setEndTxId(long)
org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$SegmentStateProto$Builder	setIsInProgress	isInProgress_	J	boolean	0	org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$SegmentStateProto$Builder:setIsInProgress(boolean)
org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$GetEditLogManifestRequestProto$Builder	setSinceTxId	sinceTxId_	J	long	0	org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$GetEditLogManifestRequestProto$Builder:setSinceTxId(long)
org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$GetEditLogManifestRequestProto$Builder	setInProgressOk	inProgressOk_	J	boolean	0	org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$GetEditLogManifestRequestProto$Builder:setInProgressOk(boolean)
org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$GetEditLogManifestRequestProto$Builder	setNameServiceId	nameServiceId_	J	java.lang.Object	0	org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$GetEditLogManifestRequestProto$Builder:setNameServiceId(java.lang.String)
org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$GetEditLogManifestRequestProto$Builder	setNameServiceIdBytes	nameServiceId_	J	java.lang.Object	0	org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$GetEditLogManifestRequestProto$Builder:setNameServiceIdBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$AcceptRecoveryRequestProto$Builder	setFromURL	fromURL_	J	java.lang.Object	0	org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$AcceptRecoveryRequestProto$Builder:setFromURL(java.lang.String)
org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$AcceptRecoveryRequestProto$Builder	setFromURLBytes	fromURL_	J	java.lang.Object	0	org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$AcceptRecoveryRequestProto$Builder:setFromURLBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.qjournal.protocol.RequestInfo	setEpoch	epoch	J	long	0	org.apache.hadoop.hdfs.qjournal.protocol.RequestInfo:setEpoch(long)
org.apache.hadoop.hdfs.qjournal.protocol.RequestInfo	setIpcSerialNumber	ipcSerialNumber	J	long	0	org.apache.hadoop.hdfs.qjournal.protocol.RequestInfo:setIpcSerialNumber(long)
org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$NewEpochResponseProto$Builder	setLastSegmentTxId	lastSegmentTxId_	J	long	0	org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$NewEpochResponseProto$Builder:setLastSegmentTxId(long)
org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$GetJournaledEditsRequestProto$Builder	setSinceTxId	sinceTxId_	J	long	0	org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$GetJournaledEditsRequestProto$Builder:setSinceTxId(long)
org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$GetJournaledEditsRequestProto$Builder	setMaxTxns	maxTxns_	J	int	0	org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$GetJournaledEditsRequestProto$Builder:setMaxTxns(int)
org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$GetJournaledEditsRequestProto$Builder	setNameServiceId	nameServiceId_	J	java.lang.Object	0	org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$GetJournaledEditsRequestProto$Builder:setNameServiceId(java.lang.String)
org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$GetJournaledEditsRequestProto$Builder	setNameServiceIdBytes	nameServiceId_	J	java.lang.Object	0	org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$GetJournaledEditsRequestProto$Builder:setNameServiceIdBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$FinalizeLogSegmentRequestProto$Builder	setStartTxId	startTxId_	J	long	0	org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$FinalizeLogSegmentRequestProto$Builder:setStartTxId(long)
org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$FinalizeLogSegmentRequestProto$Builder	setEndTxId	endTxId_	J	long	0	org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$FinalizeLogSegmentRequestProto$Builder:setEndTxId(long)
org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$GetJournalStateResponseProto$Builder	setLastPromisedEpoch	lastPromisedEpoch_	J	long	0	org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$GetJournalStateResponseProto$Builder:setLastPromisedEpoch(long)
org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$GetJournalStateResponseProto$Builder	setHttpPort	httpPort_	J	int	0	org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$GetJournalStateResponseProto$Builder:setHttpPort(int)
org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$GetJournalStateResponseProto$Builder	setFromURL	fromURL_	J	java.lang.Object	0	org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$GetJournalStateResponseProto$Builder:setFromURL(java.lang.String)
org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$GetJournalStateResponseProto$Builder	setFromURLBytes	fromURL_	J	java.lang.Object	0	org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$GetJournalStateResponseProto$Builder:setFromURLBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$GetJournaledEditsResponseProto$Builder	setTxnCount	txnCount_	J	int	0	org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$GetJournaledEditsResponseProto$Builder:setTxnCount(int)
org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$GetJournaledEditsResponseProto$Builder	setEditLog	editLog_	C	org.apache.hadoop.thirdparty.protobuf.ByteString	0	org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$GetJournaledEditsResponseProto$Builder:setEditLog(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$CanRollBackResponseProto$Builder	setCanRollBack	canRollBack_	J	boolean	0	org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$CanRollBackResponseProto$Builder:setCanRollBack(boolean)
org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$PrepareRecoveryRequestProto$Builder	setSegmentTxId	segmentTxId_	J	long	0	org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$PrepareRecoveryRequestProto$Builder:setSegmentTxId(long)
org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$JournalIdProto$Builder	setIdentifier	identifier_	J	java.lang.Object	0	org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$JournalIdProto$Builder:setIdentifier(java.lang.String)
org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$JournalIdProto$Builder	setIdentifierBytes	identifier_	J	java.lang.Object	0	org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$JournalIdProto$Builder:setIdentifierBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$GetJournalCTimeRequestProto$Builder	setNameServiceId	nameServiceId_	J	java.lang.Object	0	org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$GetJournalCTimeRequestProto$Builder:setNameServiceId(java.lang.String)
org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$GetJournalCTimeRequestProto$Builder	setNameServiceIdBytes	nameServiceId_	J	java.lang.Object	0	org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$GetJournalCTimeRequestProto$Builder:setNameServiceIdBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$IsFormattedResponseProto$Builder	setIsFormatted	isFormatted_	J	boolean	0	org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$IsFormattedResponseProto$Builder:setIsFormatted(boolean)
org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$StartLogSegmentRequestProto$Builder	setTxid	txid_	J	long	0	org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$StartLogSegmentRequestProto$Builder:setTxid(long)
org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$StartLogSegmentRequestProto$Builder	setLayoutVersion	layoutVersion_	J	int	0	org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$StartLogSegmentRequestProto$Builder:setLayoutVersion(int)
org.apache.hadoop.hdfs.qjournal.client.IPCLoggerChannelMetrics	setChannel	ch	C	org.apache.hadoop.hdfs.qjournal.client.IPCLoggerChannel	0	org.apache.hadoop.hdfs.qjournal.client.IPCLoggerChannelMetrics:setChannel(org.apache.hadoop.hdfs.qjournal.client.IPCLoggerChannel)
org.apache.hadoop.hdfs.qjournal.client.IPCLoggerChannel	setEpoch	epoch	J	long	0	org.apache.hadoop.hdfs.qjournal.client.IPCLoggerChannel:setEpoch(long)
org.apache.hadoop.hdfs.qjournal.client.IPCLoggerChannel	setCommittedTxId	committedTxId	J	long	0	org.apache.hadoop.hdfs.qjournal.client.IPCLoggerChannel:setCommittedTxId(long)
org.apache.hadoop.hdfs.tools.JMXGet	setService	service	J	java.lang.String	0	org.apache.hadoop.hdfs.tools.JMXGet:setService(java.lang.String)
org.apache.hadoop.hdfs.tools.JMXGet	setPort	port	J	java.lang.String	0	org.apache.hadoop.hdfs.tools.JMXGet:setPort(java.lang.String)
org.apache.hadoop.hdfs.tools.JMXGet	setServer	server	J	java.lang.String	0	org.apache.hadoop.hdfs.tools.JMXGet:setServer(java.lang.String)
org.apache.hadoop.hdfs.tools.JMXGet	setLocalVMUrl	localVMUrl	J	java.lang.String	0	org.apache.hadoop.hdfs.tools.JMXGet:setLocalVMUrl(java.lang.String)
org.apache.hadoop.hdfs.tools.offlineImageViewer.PBImageCorruptionDetector$OutputEntryBuilder	setCorruption	corruption	C	org.apache.hadoop.hdfs.tools.offlineImageViewer.PBImageCorruption	0	org.apache.hadoop.hdfs.tools.offlineImageViewer.PBImageCorruptionDetector$OutputEntryBuilder:setCorruption(org.apache.hadoop.hdfs.tools.offlineImageViewer.PBImageCorruption)
org.apache.hadoop.hdfs.tools.offlineImageViewer.PBImageCorruptionDetector$OutputEntryBuilder	setParentPath	parentPath	J	java.lang.String	0	org.apache.hadoop.hdfs.tools.offlineImageViewer.PBImageCorruptionDetector$OutputEntryBuilder:setParentPath(java.lang.String)
org.apache.hadoop.hdfs.tools.offlineImageViewer.PBImageCorruptionDetector$OutputEntryBuilder	setParentId	parentId	J	long	0	org.apache.hadoop.hdfs.tools.offlineImageViewer.PBImageCorruptionDetector$OutputEntryBuilder:setParentId(long)
org.apache.hadoop.hdfs.tools.offlineImageViewer.PBImageCorruptionDetector$OutputEntryBuilder	setName	name	J	java.lang.String	0	org.apache.hadoop.hdfs.tools.offlineImageViewer.PBImageCorruptionDetector$OutputEntryBuilder:setName(java.lang.String)
org.apache.hadoop.hdfs.tools.offlineImageViewer.PBImageCorruptionDetector$OutputEntryBuilder	setNodeType	nodeType	J	java.lang.String	0	org.apache.hadoop.hdfs.tools.offlineImageViewer.PBImageCorruptionDetector$OutputEntryBuilder:setNodeType(java.lang.String)
org.apache.hadoop.hdfs.tools.offlineImageViewer.OfflineImageReconstructor$Node	setVal	val	J	java.lang.String	0	org.apache.hadoop.hdfs.tools.offlineImageViewer.OfflineImageReconstructor$Node:setVal(java.lang.String)
org.apache.hadoop.hdfs.tools.offlineImageViewer.PBImageTextWriter$InMemoryMetadataDB$Dir	setParent	parent	C	org.apache.hadoop.hdfs.tools.offlineImageViewer.PBImageTextWriter$InMemoryMetadataDB$Dir	0	org.apache.hadoop.hdfs.tools.offlineImageViewer.PBImageTextWriter$InMemoryMetadataDB$Dir:setParent(org.apache.hadoop.hdfs.tools.offlineImageViewer.PBImageTextWriter$InMemoryMetadataDB$Dir)
org.apache.hadoop.hdfs.tools.offlineImageViewer.PBImageDelimitedTextWriter$OutputEntryBuilder	setPath	path	C	org.apache.hadoop.fs.Path	0	org.apache.hadoop.hdfs.tools.offlineImageViewer.PBImageDelimitedTextWriter$OutputEntryBuilder:setPath(org.apache.hadoop.fs.Path)
org.apache.hadoop.hdfs.tools.offlineImageViewer.PBImageCorruption	setNumberOfCorruption	numOfCorruptChildren	J	int	0	org.apache.hadoop.hdfs.tools.offlineImageViewer.PBImageCorruption:setNumberOfCorruption(int)
org.apache.hadoop.hdfs.server.diskbalancer.command.Command	setClusterURI	clusterURI	J	java.net.URI	0	org.apache.hadoop.hdfs.server.diskbalancer.command.Command:setClusterURI(java.net.URI)
org.apache.hadoop.hdfs.server.diskbalancer.command.Command	setTopNodes	topNodes	J	int	0	org.apache.hadoop.hdfs.server.diskbalancer.command.Command:setTopNodes(int)
org.apache.hadoop.hdfs.server.diskbalancer.command.Command	setCluster	cluster	C	org.apache.hadoop.hdfs.server.diskbalancer.datamodel.DiskBalancerCluster	0	org.apache.hadoop.hdfs.server.diskbalancer.command.Command:setCluster(org.apache.hadoop.hdfs.server.diskbalancer.datamodel.DiskBalancerCluster)
org.apache.hadoop.hdfs.server.diskbalancer.planner.MoveStep	setSourceVolume	sourceVolume	C	org.apache.hadoop.hdfs.server.diskbalancer.datamodel.DiskBalancerVolume	0	org.apache.hadoop.hdfs.server.diskbalancer.planner.MoveStep:setSourceVolume(org.apache.hadoop.hdfs.server.diskbalancer.datamodel.DiskBalancerVolume)
org.apache.hadoop.hdfs.server.diskbalancer.planner.MoveStep	setDestinationVolume	destinationVolume	C	org.apache.hadoop.hdfs.server.diskbalancer.datamodel.DiskBalancerVolume	0	org.apache.hadoop.hdfs.server.diskbalancer.planner.MoveStep:setDestinationVolume(org.apache.hadoop.hdfs.server.diskbalancer.datamodel.DiskBalancerVolume)
org.apache.hadoop.hdfs.server.diskbalancer.planner.MoveStep	setIdealStorage	idealStorage	J	double	0	org.apache.hadoop.hdfs.server.diskbalancer.planner.MoveStep:setIdealStorage(double)
org.apache.hadoop.hdfs.server.diskbalancer.planner.MoveStep	setBytesToMove	bytesToMove	J	long	0	org.apache.hadoop.hdfs.server.diskbalancer.planner.MoveStep:setBytesToMove(long)
org.apache.hadoop.hdfs.server.diskbalancer.planner.MoveStep	setVolumeSetID	volumeSetID	J	java.lang.String	0	org.apache.hadoop.hdfs.server.diskbalancer.planner.MoveStep:setVolumeSetID(java.lang.String)
org.apache.hadoop.hdfs.server.diskbalancer.planner.MoveStep	setMaxDiskErrors	maxDiskErrors	J	long	0	org.apache.hadoop.hdfs.server.diskbalancer.planner.MoveStep:setMaxDiskErrors(long)
org.apache.hadoop.hdfs.server.diskbalancer.planner.MoveStep	setTolerancePercent	tolerancePercent	J	long	0	org.apache.hadoop.hdfs.server.diskbalancer.planner.MoveStep:setTolerancePercent(long)
org.apache.hadoop.hdfs.server.diskbalancer.planner.MoveStep	setBandwidth	bandwidth	J	long	0	org.apache.hadoop.hdfs.server.diskbalancer.planner.MoveStep:setBandwidth(long)
org.apache.hadoop.hdfs.server.diskbalancer.planner.NodePlan	setTimeStamp	timeStamp	J	long	0	org.apache.hadoop.hdfs.server.diskbalancer.planner.NodePlan:setTimeStamp(long)
org.apache.hadoop.hdfs.server.diskbalancer.planner.NodePlan	setNodeName	nodeName	J	java.lang.String	0	org.apache.hadoop.hdfs.server.diskbalancer.planner.NodePlan:setNodeName(java.lang.String)
org.apache.hadoop.hdfs.server.diskbalancer.planner.NodePlan	setVolumeSetPlans	volumeSetPlans	GC	java.util.List	0	org.apache.hadoop.hdfs.server.diskbalancer.planner.NodePlan:setVolumeSetPlans(java.util.List)
org.apache.hadoop.hdfs.server.diskbalancer.planner.NodePlan	setURI	nodeName	J	java.lang.String	0	org.apache.hadoop.hdfs.server.diskbalancer.planner.NodePlan:setURI(java.lang.String)
org.apache.hadoop.hdfs.server.diskbalancer.planner.NodePlan	setPort	port	J	int	0	org.apache.hadoop.hdfs.server.diskbalancer.planner.NodePlan:setPort(int)
org.apache.hadoop.hdfs.server.diskbalancer.planner.NodePlan	setNodeUUID	nodeUUID	J	java.lang.String	0	org.apache.hadoop.hdfs.server.diskbalancer.planner.NodePlan:setNodeUUID(java.lang.String)
org.apache.hadoop.hdfs.server.diskbalancer.datamodel.DiskBalancerVolumeSet	setTransient	isTransient	J	boolean	0	org.apache.hadoop.hdfs.server.diskbalancer.datamodel.DiskBalancerVolumeSet:setTransient(boolean)
org.apache.hadoop.hdfs.server.diskbalancer.datamodel.DiskBalancerVolumeSet	setStorageType	storageType	J	java.lang.String	0	org.apache.hadoop.hdfs.server.diskbalancer.datamodel.DiskBalancerVolumeSet:setStorageType(java.lang.String)
org.apache.hadoop.hdfs.server.diskbalancer.datamodel.DiskBalancerVolumeSet	setSetID	setID	J	java.lang.String	0	org.apache.hadoop.hdfs.server.diskbalancer.datamodel.DiskBalancerVolumeSet:setSetID(java.lang.String)
org.apache.hadoop.hdfs.server.diskbalancer.datamodel.DiskBalancerVolume	setVolumeDataDensity	volumeDataDensity	J	double	0	org.apache.hadoop.hdfs.server.diskbalancer.datamodel.DiskBalancerVolume:setVolumeDataDensity(double)
org.apache.hadoop.hdfs.server.diskbalancer.datamodel.DiskBalancerVolume	setTransient	isTransient	J	boolean	0	org.apache.hadoop.hdfs.server.diskbalancer.datamodel.DiskBalancerVolume:setTransient(boolean)
org.apache.hadoop.hdfs.server.diskbalancer.datamodel.DiskBalancerVolume	setCapacity	capacity	J	long	0	org.apache.hadoop.hdfs.server.diskbalancer.datamodel.DiskBalancerVolume:setCapacity(long)
org.apache.hadoop.hdfs.server.diskbalancer.datamodel.DiskBalancerVolume	setFailed	failed	J	boolean	0	org.apache.hadoop.hdfs.server.diskbalancer.datamodel.DiskBalancerVolume:setFailed(boolean)
org.apache.hadoop.hdfs.server.diskbalancer.datamodel.DiskBalancerVolume	setPath	path	J	java.lang.String	0	org.apache.hadoop.hdfs.server.diskbalancer.datamodel.DiskBalancerVolume:setPath(java.lang.String)
org.apache.hadoop.hdfs.server.diskbalancer.datamodel.DiskBalancerVolume	setReserved	reserved	J	long	0	org.apache.hadoop.hdfs.server.diskbalancer.datamodel.DiskBalancerVolume:setReserved(long)
org.apache.hadoop.hdfs.server.diskbalancer.datamodel.DiskBalancerVolume	setStorageType	storageType	J	java.lang.String	0	org.apache.hadoop.hdfs.server.diskbalancer.datamodel.DiskBalancerVolume:setStorageType(java.lang.String)
org.apache.hadoop.hdfs.server.diskbalancer.datamodel.DiskBalancerVolume	setUuid	uuid	J	java.lang.String	0	org.apache.hadoop.hdfs.server.diskbalancer.datamodel.DiskBalancerVolume:setUuid(java.lang.String)
org.apache.hadoop.hdfs.server.diskbalancer.datamodel.DiskBalancerVolume	setSkip	skip	J	boolean	0	org.apache.hadoop.hdfs.server.diskbalancer.datamodel.DiskBalancerVolume:setSkip(boolean)
org.apache.hadoop.hdfs.server.diskbalancer.datamodel.DiskBalancerVolume	setIsTransient	isTransient	J	boolean	0	org.apache.hadoop.hdfs.server.diskbalancer.datamodel.DiskBalancerVolume:setIsTransient(boolean)
org.apache.hadoop.hdfs.server.diskbalancer.datamodel.DiskBalancerVolume	setReadOnly	isReadOnly	J	boolean	0	org.apache.hadoop.hdfs.server.diskbalancer.datamodel.DiskBalancerVolume:setReadOnly(boolean)
org.apache.hadoop.hdfs.server.diskbalancer.datamodel.DiskBalancerCluster	setNodes	nodes	GC	java.util.List	0	org.apache.hadoop.hdfs.server.diskbalancer.datamodel.DiskBalancerCluster:setNodes(java.util.List)
org.apache.hadoop.hdfs.server.diskbalancer.datamodel.DiskBalancerCluster	setThreshold	threshold	J	float	0	org.apache.hadoop.hdfs.server.diskbalancer.datamodel.DiskBalancerCluster:setThreshold(float)
org.apache.hadoop.hdfs.server.diskbalancer.datamodel.DiskBalancerCluster	setNodesToProcess	nodesToProcess	GC	java.util.List	0	org.apache.hadoop.hdfs.server.diskbalancer.datamodel.DiskBalancerCluster:setNodesToProcess(java.util.List)
org.apache.hadoop.hdfs.server.diskbalancer.datamodel.DiskBalancerCluster	setOutput	outputpath	J	java.lang.String	0	org.apache.hadoop.hdfs.server.diskbalancer.datamodel.DiskBalancerCluster:setOutput(java.lang.String)
org.apache.hadoop.hdfs.server.diskbalancer.datamodel.DiskBalancerDataNode	setDataNodeIP	dataNodeIP	J	java.lang.String	0	org.apache.hadoop.hdfs.server.diskbalancer.datamodel.DiskBalancerDataNode:setDataNodeIP(java.lang.String)
org.apache.hadoop.hdfs.server.diskbalancer.datamodel.DiskBalancerDataNode	setDataNodePort	dataNodePort	J	int	0	org.apache.hadoop.hdfs.server.diskbalancer.datamodel.DiskBalancerDataNode:setDataNodePort(int)
org.apache.hadoop.hdfs.server.diskbalancer.datamodel.DiskBalancerDataNode	setDataNodeName	dataNodeName	J	java.lang.String	0	org.apache.hadoop.hdfs.server.diskbalancer.datamodel.DiskBalancerDataNode:setDataNodeName(java.lang.String)
org.apache.hadoop.hdfs.server.diskbalancer.datamodel.DiskBalancerDataNode	setDataNodeUUID	dataNodeUUID	J	java.lang.String	0	org.apache.hadoop.hdfs.server.diskbalancer.datamodel.DiskBalancerDataNode:setDataNodeUUID(java.lang.String)
org.apache.hadoop.hdfs.server.common.blockaliasmap.impl.TextFileRegionAliasMap	setConf	conf	C	org.apache.hadoop.conf.Configuration	0	org.apache.hadoop.hdfs.server.common.blockaliasmap.impl.TextFileRegionAliasMap:setConf(org.apache.hadoop.conf.Configuration)
org.apache.hadoop.hdfs.server.common.blockaliasmap.impl.LevelDBFileRegionAliasMap$LevelDBOptions	setConf	conf	C	org.apache.hadoop.conf.Configuration	0	org.apache.hadoop.hdfs.server.common.blockaliasmap.impl.LevelDBFileRegionAliasMap$LevelDBOptions:setConf(org.apache.hadoop.conf.Configuration)
org.apache.hadoop.hdfs.server.common.blockaliasmap.impl.LevelDBFileRegionAliasMap	setConf	conf	C	org.apache.hadoop.conf.Configuration	0	org.apache.hadoop.hdfs.server.common.blockaliasmap.impl.LevelDBFileRegionAliasMap:setConf(org.apache.hadoop.conf.Configuration)
org.apache.hadoop.hdfs.server.common.blockaliasmap.impl.InMemoryLevelDBAliasMapClient	setConf	conf	C	org.apache.hadoop.conf.Configuration	0	org.apache.hadoop.hdfs.server.common.blockaliasmap.impl.InMemoryLevelDBAliasMapClient:setConf(org.apache.hadoop.conf.Configuration)
org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory	setStorageUuid	storageUuid	J	java.lang.String	0	org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory:setStorageUuid(java.lang.String)
org.apache.hadoop.hdfs.server.common.StorageInfo	setServiceLayoutVersion	layoutVersion	J	int	0	org.apache.hadoop.hdfs.server.common.StorageInfo:setServiceLayoutVersion(int)
org.apache.hadoop.hdfs.server.mover.Mover$Result	setNoBlockMoved	noBlockMoved	J	boolean	0	org.apache.hadoop.hdfs.server.mover.Mover$Result:setNoBlockMoved(boolean)
org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo	setBlockReportCount	blockReportCount	J	int	0	org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo:setBlockReportCount(int)
org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo	setBlockContentsStale	blockContentsStale	J	boolean	0	org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo:setBlockContentsStale(boolean)
org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo	setState	state	C	org.apache.hadoop.hdfs.server.protocol.DatanodeStorage$State	0	org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo:setState(org.apache.hadoop.hdfs.server.protocol.DatanodeStorage$State)
org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo	setHeartbeatedSinceFailover	heartbeatedSinceFailover	J	boolean	0	org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo:setHeartbeatedSinceFailover(boolean)
org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo	setReplication	replication	J	short	0	org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo:setReplication(short)
org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo	setBlockCollectionId	bcId	J	long	0	org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo:setBlockCollectionId(long)
org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo	setNext	nextLinkedElement	C	org.apache.hadoop.util.LightWeightGSet$LinkedElement	0	org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo:setNext(org.apache.hadoop.util.LightWeightGSet$LinkedElement)
org.apache.hadoop.hdfs.server.blockmanagement.CombinedHostFileManager	setConf	conf	C	org.apache.hadoop.conf.Configuration	0	org.apache.hadoop.hdfs.server.blockmanagement.CombinedHostFileManager:setConf(org.apache.hadoop.conf.Configuration)
org.apache.hadoop.hdfs.server.blockmanagement.BlockReconstructionWork	setTargets	targets	C	org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo	1	org.apache.hadoop.hdfs.server.blockmanagement.BlockReconstructionWork:setTargets(org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo[])
org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor	setAlive	isAlive	J	boolean	0	org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor:setAlive(boolean)
org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor	setNeedKeyUpdate	needKeyUpdate	J	boolean	0	org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor:setNeedKeyUpdate(boolean)
org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor	setDisallowed	disallowed	J	boolean	0	org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor:setDisallowed(boolean)
org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor	setBalancerBandwidth	bandwidth	J	long	0	org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor:setBalancerBandwidth(long)
org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor	setLastCachingDirectiveSentTimeMs	lastCachingDirectiveSentTimeMs	J	long	0	org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor:setLastCachingDirectiveSentTimeMs(long)
org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor	setForceRegistration	forceRegistration	J	boolean	0	org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor:setForceRegistration(boolean)
org.apache.hadoop.hdfs.server.blockmanagement.DatanodeAdminMonitorBase	setNameSystem	namesystem	C	org.apache.hadoop.hdfs.server.namenode.Namesystem	0	org.apache.hadoop.hdfs.server.blockmanagement.DatanodeAdminMonitorBase:setNameSystem(org.apache.hadoop.hdfs.server.namenode.Namesystem)
org.apache.hadoop.hdfs.server.blockmanagement.DatanodeAdminMonitorBase	setBlockManager	blockManager	C	org.apache.hadoop.hdfs.server.blockmanagement.BlockManager	0	org.apache.hadoop.hdfs.server.blockmanagement.DatanodeAdminMonitorBase:setBlockManager(org.apache.hadoop.hdfs.server.blockmanagement.BlockManager)
org.apache.hadoop.hdfs.server.blockmanagement.DatanodeAdminMonitorBase	setDatanodeAdminManager	dnAdmin	C	org.apache.hadoop.hdfs.server.blockmanagement.DatanodeAdminManager	0	org.apache.hadoop.hdfs.server.blockmanagement.DatanodeAdminMonitorBase:setDatanodeAdminManager(org.apache.hadoop.hdfs.server.blockmanagement.DatanodeAdminManager)
org.apache.hadoop.hdfs.server.blockmanagement.DatanodeAdminBackoffMonitor	setPendingRepLimit	pendingRepLimit	J	int	0	org.apache.hadoop.hdfs.server.blockmanagement.DatanodeAdminBackoffMonitor:setPendingRepLimit(int)
org.apache.hadoop.hdfs.server.blockmanagement.DatanodeAdminBackoffMonitor	setBlocksPerLock	blocksPerLock	J	int	0	org.apache.hadoop.hdfs.server.blockmanagement.DatanodeAdminBackoffMonitor:setBlocksPerLock(int)
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager	setBlockPoolId	blockPoolId	J	java.lang.String	0	org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:setBlockPoolId(java.lang.String)
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager	setReplicationStreamsHardLimit	replicationStreamsHardLimit	J	int	0	org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:setReplicationStreamsHardLimit(int)
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager	setBlocksReplWorkMultiplier	blocksReplWorkMultiplier	J	int	0	org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:setBlocksReplWorkMultiplier(int)
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager	setPostponeBlocksFromFuture	shouldPostponeBlocksFromFuture	J	boolean	0	org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:setPostponeBlocksFromFuture(boolean)
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager	setInitializedReplQueues	initializedReplQueues	J	boolean	0	org.apache.hadoop.hdfs.server.blockmanagement.BlockManager:setInitializedReplQueues(boolean)
org.apache.hadoop.hdfs.server.blockmanagement.BlockUnderConstructionFeature	setBlockUCState	blockUCState	C	org.apache.hadoop.hdfs.server.common.HdfsServerConstants$BlockUCState	0	org.apache.hadoop.hdfs.server.blockmanagement.BlockUnderConstructionFeature:setBlockUCState(org.apache.hadoop.hdfs.server.common.HdfsServerConstants$BlockUCState)
org.apache.hadoop.hdfs.server.blockmanagement.BlockUnderConstructionFeature	setTruncateBlock	truncateBlock	C	org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo	0	org.apache.hadoop.hdfs.server.blockmanagement.BlockUnderConstructionFeature:setTruncateBlock(org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo)
org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault	setPreferLocalNode	preferLocalNode	J	boolean	0	org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault:setPreferLocalNode(boolean)
org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault	setExcludeSlowNodesEnabled	excludeSlowNodesEnabled	J	boolean	0	org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault:setExcludeSlowNodesEnabled(boolean)
org.apache.hadoop.hdfs.server.blockmanagement.PendingRecoveryBlocks	setRecoveryTimeoutInterval	recoveryTimeoutInterval	J	long	0	org.apache.hadoop.hdfs.server.blockmanagement.PendingRecoveryBlocks:setRecoveryTimeoutInterval(long)
org.apache.hadoop.hdfs.server.blockmanagement.HostFileManager	setConf	conf	C	org.apache.hadoop.conf.Configuration	0	org.apache.hadoop.hdfs.server.blockmanagement.HostFileManager:setConf(org.apache.hadoop.conf.Configuration)
org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor$LeavingServiceStatus	setStartTime	startTime	J	long	0	org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor$LeavingServiceStatus:setStartTime(long)
org.apache.hadoop.hdfs.server.blockmanagement.SlowDiskTracker	setReportValidityMs	reportValidityMs	J	long	0	org.apache.hadoop.hdfs.server.blockmanagement.SlowDiskTracker:setReportValidityMs(long)
org.apache.hadoop.hdfs.server.blockmanagement.ReplicaUnderConstruction	setState	state	C	org.apache.hadoop.hdfs.server.common.HdfsServerConstants$ReplicaState	0	org.apache.hadoop.hdfs.server.blockmanagement.ReplicaUnderConstruction:setState(org.apache.hadoop.hdfs.server.common.HdfsServerConstants$ReplicaState)
org.apache.hadoop.hdfs.server.blockmanagement.ReplicaUnderConstruction	setChosenAsPrimary	chosenAsPrimary	J	boolean	0	org.apache.hadoop.hdfs.server.blockmanagement.ReplicaUnderConstruction:setChosenAsPrimary(boolean)
org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager	setHeartbeatExpireInterval	heartbeatExpireInterval	J	long	0	org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager:setHeartbeatExpireInterval(long)
org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager	setAvoidSlowDataNodesForReadEnabled	avoidSlowDataNodesForRead	J	boolean	0	org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager:setAvoidSlowDataNodesForReadEnabled(boolean)
org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager	setMaxSlowpeerCollectNodes	maxSlowPeerReportNodes	J	int	0	org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager:setMaxSlowpeerCollectNodes(int)
org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager	setNumStaleNodes	numStaleNodes	J	int	0	org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager:setNumStaleNodes(int)
org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager	setNumStaleStorages	numStaleStorages	J	int	0	org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager:setNumStaleStorages(int)
org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager	setShouldSendCachingCommands	shouldSendCachingCommands	J	boolean	0	org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager:setShouldSendCachingCommands(boolean)
org.apache.hadoop.hdfs.server.blockmanagement.PendingRecoveryBlocks$BlockRecoveryAttempt	setTimeout	timeoutAt	J	long	0	org.apache.hadoop.hdfs.server.blockmanagement.PendingRecoveryBlocks$BlockRecoveryAttempt:setTimeout(long)
org.apache.hadoop.hdfs.server.blockmanagement.BlockIdManager	setLegacyGenerationStampLimit	legacyGenerationStampLimit	J	long	0	org.apache.hadoop.hdfs.server.blockmanagement.BlockIdManager:setLegacyGenerationStampLimit(long)
org.apache.hadoop.hdfs.server.datanode.DNConf	setBlockReportInterval	blockReportInterval	J	long	0	org.apache.hadoop.hdfs.server.datanode.DNConf:setBlockReportInterval(long)
org.apache.hadoop.hdfs.server.datanode.DNConf	setCacheReportInterval	cacheReportInterval	J	long	0	org.apache.hadoop.hdfs.server.datanode.DNConf:setCacheReportInterval(long)
org.apache.hadoop.hdfs.server.datanode.DNConf	setBlockReportSplitThreshold	blockReportSplitThreshold	J	long	0	org.apache.hadoop.hdfs.server.datanode.DNConf:setBlockReportSplitThreshold(long)
org.apache.hadoop.hdfs.server.datanode.DNConf	setPeerStatsEnabled	peerStatsEnabled	J	boolean	0	org.apache.hadoop.hdfs.server.datanode.DNConf:setPeerStatsEnabled(boolean)
org.apache.hadoop.hdfs.server.datanode.metrics.OutlierDetector	setMinNumResources	minNumResources	J	long	0	org.apache.hadoop.hdfs.server.datanode.metrics.OutlierDetector:setMinNumResources(long)
org.apache.hadoop.hdfs.server.datanode.metrics.OutlierDetector	setLowThresholdMs	lowThresholdMs	J	long	0	org.apache.hadoop.hdfs.server.datanode.metrics.OutlierDetector:setLowThresholdMs(long)
org.apache.hadoop.hdfs.server.datanode.metrics.DataNodePeerMetrics	setTestOutliers	testOutlier	GC	java.util.Map	0	org.apache.hadoop.hdfs.server.datanode.metrics.DataNodePeerMetrics:setTestOutliers(java.util.Map)
org.apache.hadoop.hdfs.server.datanode.metrics.DataNodePeerMetrics	setMinOutlierDetectionNodes	minOutlierDetectionNodes	J	long	0	org.apache.hadoop.hdfs.server.datanode.metrics.DataNodePeerMetrics:setMinOutlierDetectionNodes(long)
org.apache.hadoop.hdfs.server.datanode.metrics.DataNodePeerMetrics	setLowThresholdMs	lowThresholdMs	J	long	0	org.apache.hadoop.hdfs.server.datanode.metrics.DataNodePeerMetrics:setLowThresholdMs(long)
org.apache.hadoop.hdfs.server.datanode.metrics.DataNodePeerMetrics	setMinOutlierDetectionSamples	minOutlierDetectionSamples	J	long	0	org.apache.hadoop.hdfs.server.datanode.metrics.DataNodePeerMetrics:setMinOutlierDetectionSamples(long)
org.apache.hadoop.hdfs.server.datanode.metrics.DataNodeDiskMetrics	setLowThresholdMs	lowThresholdMs	J	long	0	org.apache.hadoop.hdfs.server.datanode.metrics.DataNodeDiskMetrics:setLowThresholdMs(long)
org.apache.hadoop.hdfs.server.datanode.metrics.DataNodeDiskMetrics	setMinOutlierDetectionDisks	minOutlierDetectionDisks	J	long	0	org.apache.hadoop.hdfs.server.datanode.metrics.DataNodeDiskMetrics:setMinOutlierDetectionDisks(long)
org.apache.hadoop.hdfs.server.datanode.BlockChecksumHelper$AbstractBlockChecksumComputer	setOutBytes	outBytes	J	byte	1	org.apache.hadoop.hdfs.server.datanode.BlockChecksumHelper$AbstractBlockChecksumComputer:setOutBytes(byte[])
org.apache.hadoop.hdfs.server.datanode.BlockChecksumHelper$AbstractBlockChecksumComputer	setBytesPerCRC	bytesPerCRC	J	int	0	org.apache.hadoop.hdfs.server.datanode.BlockChecksumHelper$AbstractBlockChecksumComputer:setBytesPerCRC(int)
org.apache.hadoop.hdfs.server.datanode.BlockChecksumHelper$AbstractBlockChecksumComputer	setCrcType	crcType	C	org.apache.hadoop.util.DataChecksum$Type	0	org.apache.hadoop.hdfs.server.datanode.BlockChecksumHelper$AbstractBlockChecksumComputer:setCrcType(org.apache.hadoop.util.DataChecksum$Type)
org.apache.hadoop.hdfs.server.datanode.BlockChecksumHelper$AbstractBlockChecksumComputer	setCrcPerBlock	crcPerBlock	J	long	0	org.apache.hadoop.hdfs.server.datanode.BlockChecksumHelper$AbstractBlockChecksumComputer:setCrcPerBlock(long)
org.apache.hadoop.hdfs.server.datanode.BlockChecksumHelper$AbstractBlockChecksumComputer	setChecksumSize	checksumSize	J	int	0	org.apache.hadoop.hdfs.server.datanode.BlockChecksumHelper$AbstractBlockChecksumComputer:setChecksumSize(int)
org.apache.hadoop.hdfs.server.datanode.ProvidedReplica	setPathHandle	pathHandle	C	org.apache.hadoop.fs.PathHandle	0	org.apache.hadoop.hdfs.server.datanode.ProvidedReplica:setPathHandle(org.apache.hadoop.fs.PathHandle)
org.apache.hadoop.hdfs.server.datanode.ReplicaBuilder	setState	state	C	org.apache.hadoop.hdfs.server.common.HdfsServerConstants$ReplicaState	0	org.apache.hadoop.hdfs.server.datanode.ReplicaBuilder:setState(org.apache.hadoop.hdfs.server.common.HdfsServerConstants$ReplicaState)
org.apache.hadoop.hdfs.server.datanode.ReplicaBuilder	setBlockId	blockId	J	long	0	org.apache.hadoop.hdfs.server.datanode.ReplicaBuilder:setBlockId(long)
org.apache.hadoop.hdfs.server.datanode.ReplicaBuilder	setGenerationStamp	genStamp	J	long	0	org.apache.hadoop.hdfs.server.datanode.ReplicaBuilder:setGenerationStamp(long)
org.apache.hadoop.hdfs.server.datanode.ReplicaBuilder	setLength	length	J	long	0	org.apache.hadoop.hdfs.server.datanode.ReplicaBuilder:setLength(long)
org.apache.hadoop.hdfs.server.datanode.ReplicaBuilder	setFsVolume	volume	C	org.apache.hadoop.hdfs.server.datanode.fsdataset.FsVolumeSpi	0	org.apache.hadoop.hdfs.server.datanode.ReplicaBuilder:setFsVolume(org.apache.hadoop.hdfs.server.datanode.fsdataset.FsVolumeSpi)
org.apache.hadoop.hdfs.server.datanode.ReplicaBuilder	setDirectoryToUse	directoryUsed	J	java.io.File	0	org.apache.hadoop.hdfs.server.datanode.ReplicaBuilder:setDirectoryToUse(java.io.File)
org.apache.hadoop.hdfs.server.datanode.ReplicaBuilder	setBytesToReserve	bytesToReserve	J	long	0	org.apache.hadoop.hdfs.server.datanode.ReplicaBuilder:setBytesToReserve(long)
org.apache.hadoop.hdfs.server.datanode.ReplicaBuilder	setWriterThread	writer	J	java.lang.Thread	0	org.apache.hadoop.hdfs.server.datanode.ReplicaBuilder:setWriterThread(java.lang.Thread)
org.apache.hadoop.hdfs.server.datanode.ReplicaBuilder	setRecoveryId	recoveryId	J	long	0	org.apache.hadoop.hdfs.server.datanode.ReplicaBuilder:setRecoveryId(long)
org.apache.hadoop.hdfs.server.datanode.ReplicaBuilder	setBlock	block	C	org.apache.hadoop.hdfs.protocol.Block	0	org.apache.hadoop.hdfs.server.datanode.ReplicaBuilder:setBlock(org.apache.hadoop.hdfs.protocol.Block)
org.apache.hadoop.hdfs.server.datanode.ReplicaBuilder	setURI	uri	J	java.net.URI	0	org.apache.hadoop.hdfs.server.datanode.ReplicaBuilder:setURI(java.net.URI)
org.apache.hadoop.hdfs.server.datanode.ReplicaBuilder	setConf	conf	C	org.apache.hadoop.conf.Configuration	0	org.apache.hadoop.hdfs.server.datanode.ReplicaBuilder:setConf(org.apache.hadoop.conf.Configuration)
org.apache.hadoop.hdfs.server.datanode.ReplicaBuilder	setOffset	offset	J	long	0	org.apache.hadoop.hdfs.server.datanode.ReplicaBuilder:setOffset(long)
org.apache.hadoop.hdfs.server.datanode.ReplicaBuilder	setFileRegion	fileRegion	C	org.apache.hadoop.hdfs.server.common.FileRegion	0	org.apache.hadoop.hdfs.server.datanode.ReplicaBuilder:setFileRegion(org.apache.hadoop.hdfs.server.common.FileRegion)
org.apache.hadoop.hdfs.server.datanode.ReplicaBuilder	setRemoteFS	remoteFS	C	org.apache.hadoop.fs.FileSystem	0	org.apache.hadoop.hdfs.server.datanode.ReplicaBuilder:setRemoteFS(org.apache.hadoop.fs.FileSystem)
org.apache.hadoop.hdfs.server.datanode.ReplicaBuilder	setPathSuffix	pathSuffix	J	java.lang.String	0	org.apache.hadoop.hdfs.server.datanode.ReplicaBuilder:setPathSuffix(java.lang.String)
org.apache.hadoop.hdfs.server.datanode.ReplicaBuilder	setPathPrefix	pathPrefix	C	org.apache.hadoop.fs.Path	0	org.apache.hadoop.hdfs.server.datanode.ReplicaBuilder:setPathPrefix(org.apache.hadoop.fs.Path)
org.apache.hadoop.hdfs.server.datanode.ReplicaBuilder	setPathHandle	pathHandle	C	org.apache.hadoop.fs.PathHandle	0	org.apache.hadoop.hdfs.server.datanode.ReplicaBuilder:setPathHandle(org.apache.hadoop.fs.PathHandle)
org.apache.hadoop.hdfs.server.datanode.ReplicaBuilder	setLastPartialChunkChecksum	lastPartialChunkChecksum	J	byte	1	org.apache.hadoop.hdfs.server.datanode.ReplicaBuilder:setLastPartialChunkChecksum(byte[])
org.apache.hadoop.hdfs.server.datanode.LocalReplicaInPipeline	setBytesAcked	bytesAcked	J	long	0	org.apache.hadoop.hdfs.server.datanode.LocalReplicaInPipeline:setBytesAcked(long)
org.apache.hadoop.hdfs.server.datanode.ReplicaInfo	setVolume	volume	C	org.apache.hadoop.hdfs.server.datanode.fsdataset.FsVolumeSpi	0	org.apache.hadoop.hdfs.server.datanode.ReplicaInfo:setVolume(org.apache.hadoop.hdfs.server.datanode.fsdataset.FsVolumeSpi)
org.apache.hadoop.hdfs.server.datanode.ReplicaInfo	setNext	next	C	org.apache.hadoop.util.LightWeightGSet$LinkedElement	0	org.apache.hadoop.hdfs.server.datanode.ReplicaInfo:setNext(org.apache.hadoop.util.LightWeightGSet$LinkedElement)
org.apache.hadoop.hdfs.server.datanode.DataStorage	setDatanodeUuid	datanodeUuid	J	java.lang.String	0	org.apache.hadoop.hdfs.server.datanode.DataStorage:setDatanodeUuid(java.lang.String)
org.apache.hadoop.hdfs.server.datanode.DataNode	setHeartbeatsDisabledForTests	heartbeatsDisabledForTests	J	boolean	0	org.apache.hadoop.hdfs.server.datanode.DataNode:setHeartbeatsDisabledForTests(boolean)
org.apache.hadoop.hdfs.server.datanode.DataNode	setIBRDisabledForTest	ibrDisabledForTests	J	boolean	0	org.apache.hadoop.hdfs.server.datanode.DataNode:setIBRDisabledForTest(boolean)
org.apache.hadoop.hdfs.server.datanode.DataNode	setCacheReportsDisabledForTest	cacheReportsDisabledForTests	J	boolean	0	org.apache.hadoop.hdfs.server.datanode.DataNode:setCacheReportsDisabledForTest(boolean)
org.apache.hadoop.hdfs.server.datanode.DataNode	setBlockScanner	blockScanner	C	org.apache.hadoop.hdfs.server.datanode.BlockScanner	0	org.apache.hadoop.hdfs.server.datanode.DataNode:setBlockScanner(org.apache.hadoop.hdfs.server.datanode.BlockScanner)
org.apache.hadoop.hdfs.server.datanode.DataXceiverServer	setMaxReconfigureWaitTime	maxReconfigureWaitTime	J	int	0	org.apache.hadoop.hdfs.server.datanode.DataXceiverServer:setMaxReconfigureWaitTime(int)
org.apache.hadoop.hdfs.server.datanode.DataXceiverServer	setMaxXceiverCount	maxXceiverCount	J	int	0	org.apache.hadoop.hdfs.server.datanode.DataXceiverServer:setMaxXceiverCount(int)
org.apache.hadoop.hdfs.server.datanode.FinalizedReplica	setLastPartialChunkChecksum	lastPartialChunkChecksum	J	byte	1	org.apache.hadoop.hdfs.server.datanode.FinalizedReplica:setLastPartialChunkChecksum(byte[])
org.apache.hadoop.hdfs.server.datanode.DirectoryScanner	setRetainDiffs	retainDiffs	J	boolean	0	org.apache.hadoop.hdfs.server.datanode.DirectoryScanner:setRetainDiffs(boolean)
org.apache.hadoop.hdfs.server.datanode.DataXceiver	setCurrentBlockReceiver	blockReceiver	C	org.apache.hadoop.hdfs.server.datanode.BlockReceiver	0	org.apache.hadoop.hdfs.server.datanode.DataXceiver:setCurrentBlockReceiver(org.apache.hadoop.hdfs.server.datanode.BlockReceiver)
org.apache.hadoop.hdfs.server.datanode.VolumeScanner	setConf	conf	C	org.apache.hadoop.hdfs.server.datanode.BlockScanner$Conf	0	org.apache.hadoop.hdfs.server.datanode.VolumeScanner:setConf(org.apache.hadoop.hdfs.server.datanode.BlockScanner$Conf)
org.apache.hadoop.hdfs.server.datanode.BlockScanner	setJoinVolumeScannersTimeOutMs	joinVolumeScannersTimeOutMs	J	long	0	org.apache.hadoop.hdfs.server.datanode.BlockScanner:setJoinVolumeScannersTimeOutMs(long)
org.apache.hadoop.hdfs.server.datanode.checker.DatasetVolumeChecker	setDelegateChecker	delegateChecker	GC	org.apache.hadoop.hdfs.server.datanode.checker.AsyncChecker	0	org.apache.hadoop.hdfs.server.datanode.checker.DatasetVolumeChecker:setDelegateChecker(org.apache.hadoop.hdfs.server.datanode.checker.AsyncChecker)
org.apache.hadoop.hdfs.server.datanode.FSCachingGetSpaceUsed$Builder	setVolume	volume	C	org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsVolumeImpl	0	org.apache.hadoop.hdfs.server.datanode.FSCachingGetSpaceUsed$Builder:setVolume(org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsVolumeImpl)
org.apache.hadoop.hdfs.server.datanode.FSCachingGetSpaceUsed$Builder	setBpid	bpid	J	java.lang.String	0	org.apache.hadoop.hdfs.server.datanode.FSCachingGetSpaceUsed$Builder:setBpid(java.lang.String)
org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsVolumeImplBuilder	setDataset	dataset	C	org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl	0	org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsVolumeImplBuilder:setDataset(org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl)
org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsVolumeImplBuilder	setStorageID	storageID	J	java.lang.String	0	org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsVolumeImplBuilder:setStorageID(java.lang.String)
org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsVolumeImplBuilder	setStorageDirectory	sd	C	org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory	0	org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsVolumeImplBuilder:setStorageDirectory(org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory)
org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsVolumeImplBuilder	setConf	conf	C	org.apache.hadoop.conf.Configuration	0	org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsVolumeImplBuilder:setConf(org.apache.hadoop.conf.Configuration)
org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsVolumeImplBuilder	setFileIoProvider	fileIoProvider	C	org.apache.hadoop.hdfs.server.datanode.FileIoProvider	0	org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsVolumeImplBuilder:setFileIoProvider(org.apache.hadoop.hdfs.server.datanode.FileIoProvider)
org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsVolumeImplBuilder	setUsage	usage	C	org.apache.hadoop.fs.DF	0	org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsVolumeImplBuilder:setUsage(org.apache.hadoop.fs.DF)
org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsVolumeImpl$BlockIteratorImpl	setMaxStalenessMs	maxStalenessMs	J	long	0	org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsVolumeImpl$BlockIteratorImpl:setMaxStalenessMs(long)
org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl	setTimer	timer	C	org.apache.hadoop.util.Timer	0	org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl:setTimer(org.apache.hadoop.util.Timer)
org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.PmemVolumeManager$UsedBytesCount	setMaxBytes	maxBytes	J	long	0	org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.PmemVolumeManager$UsedBytesCount:setMaxBytes(long)
org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.ProvidedVolumeImpl$ProvidedBlockPoolSlice	setFileRegionProvider	aliasMap	GC	org.apache.hadoop.hdfs.server.common.blockaliasmap.BlockAliasMap	0	org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.ProvidedVolumeImpl$ProvidedBlockPoolSlice:setFileRegionProvider(org.apache.hadoop.hdfs.server.common.blockaliasmap.BlockAliasMap)
org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.ReservedSpaceCalculator$Builder	setUsage	usage	C	org.apache.hadoop.fs.DF	0	org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.ReservedSpaceCalculator$Builder:setUsage(org.apache.hadoop.fs.DF)
org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.ReservedSpaceCalculator$Builder	setStorageType	storageType	C	org.apache.hadoop.fs.StorageType	0	org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.ReservedSpaceCalculator$Builder:setStorageType(org.apache.hadoop.fs.StorageType)
org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsVolumeImpl	setCapacityForTesting	configuredCapacity	J	long	0	org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsVolumeImpl:setCapacityForTesting(long)
org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.RamDiskReplicaTracker$RamDiskReplica	setLazyPersistVolume	lazyPersistVolume	C	org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsVolumeImpl	0	org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.RamDiskReplicaTracker$RamDiskReplica:setLazyPersistVolume(org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsVolumeImpl)
org.apache.hadoop.hdfs.server.datanode.BPServiceActor	setNameNode	bpNamenode	C	org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB	0	org.apache.hadoop.hdfs.server.datanode.BPServiceActor:setNameNode(org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB)
org.apache.hadoop.hdfs.server.datanode.VolumeScanner$ScanResultHandler	setup	scanner	C	org.apache.hadoop.hdfs.server.datanode.VolumeScanner	0	org.apache.hadoop.hdfs.server.datanode.VolumeScanner$ScanResultHandler:setup(org.apache.hadoop.hdfs.server.datanode.VolumeScanner)
org.apache.hadoop.hdfs.server.datanode.BPServiceActor$Scheduler	setBlockReportIntervalMs	blockReportIntervalMs	J	long	0	org.apache.hadoop.hdfs.server.datanode.BPServiceActor$Scheduler:setBlockReportIntervalMs(long)
org.apache.hadoop.hdfs.server.datanode.BPServiceActor$Scheduler	setOutliersReportIntervalMs	outliersReportIntervalMs	J	long	0	org.apache.hadoop.hdfs.server.datanode.BPServiceActor$Scheduler:setOutliersReportIntervalMs(long)
org.apache.hadoop.hdfs.server.datanode.erasurecode.StripedReconstructor	setMaxTargetLength	maxTargetLength	J	long	0	org.apache.hadoop.hdfs.server.datanode.erasurecode.StripedReconstructor:setMaxTargetLength(long)
org.apache.hadoop.hdfs.server.namenode.FsImageProto$INodeSection$Builder	setLastInodeId	lastInodeId_	J	long	0	org.apache.hadoop.hdfs.server.namenode.FsImageProto$INodeSection$Builder:setLastInodeId(long)
org.apache.hadoop.hdfs.server.namenode.FsImageProto$INodeSection$Builder	setNumInodes	numInodes_	J	long	0	org.apache.hadoop.hdfs.server.namenode.FsImageProto$INodeSection$Builder:setNumInodes(long)
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$CancelDelegationTokenOp	setDelegationTokenIdentifier	token	C	org.apache.hadoop.hdfs.security.token.delegation.DelegationTokenIdentifier	0	org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$CancelDelegationTokenOp:setDelegationTokenIdentifier(org.apache.hadoop.hdfs.security.token.delegation.DelegationTokenIdentifier)
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$AllowSnapshotOp	setSnapshotRoot	snapshotRoot	J	java.lang.String	0	org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$AllowSnapshotOp:setSnapshotRoot(java.lang.String)
org.apache.hadoop.hdfs.server.namenode.FsImageProto$StringTableSection$Entry$Builder	setId	id_	J	int	0	org.apache.hadoop.hdfs.server.namenode.FsImageProto$StringTableSection$Entry$Builder:setId(int)
org.apache.hadoop.hdfs.server.namenode.FsImageProto$StringTableSection$Entry$Builder	setStr	str_	J	java.lang.Object	0	org.apache.hadoop.hdfs.server.namenode.FsImageProto$StringTableSection$Entry$Builder:setStr(java.lang.String)
org.apache.hadoop.hdfs.server.namenode.FsImageProto$StringTableSection$Entry$Builder	setStrBytes	str_	J	java.lang.Object	0	org.apache.hadoop.hdfs.server.namenode.FsImageProto$StringTableSection$Entry$Builder:setStrBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$GetDelegationTokenOp	setDelegationTokenIdentifier	token	C	org.apache.hadoop.hdfs.security.token.delegation.DelegationTokenIdentifier	0	org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$GetDelegationTokenOp:setDelegationTokenIdentifier(org.apache.hadoop.hdfs.security.token.delegation.DelegationTokenIdentifier)
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$GetDelegationTokenOp	setExpiryTime	expiryTime	J	long	0	org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$GetDelegationTokenOp:setExpiryTime(long)
org.apache.hadoop.hdfs.server.namenode.FsImageProto$INodeDirectorySection$DirEntry$Builder	setParent	parent_	J	long	0	org.apache.hadoop.hdfs.server.namenode.FsImageProto$INodeDirectorySection$DirEntry$Builder:setParent(long)
org.apache.hadoop.hdfs.server.namenode.BackupImage	setNamesystem	namesystem	C	org.apache.hadoop.hdfs.server.namenode.FSNamesystem	0	org.apache.hadoop.hdfs.server.namenode.BackupImage:setNamesystem(org.apache.hadoop.hdfs.server.namenode.FSNamesystem)
org.apache.hadoop.hdfs.server.namenode.FileUnderConstructionFeature	setClientName	clientName	J	java.lang.String	0	org.apache.hadoop.hdfs.server.namenode.FileUnderConstructionFeature:setClientName(java.lang.String)
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$AppendOp	setPath	path	J	java.lang.String	0	org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$AppendOp:setPath(java.lang.String)
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$AppendOp	setClientName	clientName	J	java.lang.String	0	org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$AppendOp:setClientName(java.lang.String)
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$AppendOp	setClientMachine	clientMachine	J	java.lang.String	0	org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$AppendOp:setClientMachine(java.lang.String)
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$AppendOp	setNewBlock	newBlock	J	boolean	0	org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$AppendOp:setNewBlock(boolean)
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$AllocateBlockIdOp	setBlockId	blockId	J	long	0	org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$AllocateBlockIdOp:setBlockId(long)
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$EnableErasureCodingPolicyOp	setErasureCodingPolicy	ecPolicyName	J	java.lang.String	0	org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$EnableErasureCodingPolicyOp:setErasureCodingPolicy(java.lang.String)
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$TimesOp	setPath	path	J	java.lang.String	0	org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$TimesOp:setPath(java.lang.String)
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$TimesOp	setModificationTime	mtime	J	long	0	org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$TimesOp:setModificationTime(long)
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$TimesOp	setAccessTime	atime	J	long	0	org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$TimesOp:setAccessTime(long)
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$ReassignLeaseOp	setLeaseHolder	leaseHolder	J	java.lang.String	0	org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$ReassignLeaseOp:setLeaseHolder(java.lang.String)
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$ReassignLeaseOp	setPath	path	J	java.lang.String	0	org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$ReassignLeaseOp:setPath(java.lang.String)
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$ReassignLeaseOp	setNewHolder	newHolder	J	java.lang.String	0	org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$ReassignLeaseOp:setNewHolder(java.lang.String)
org.apache.hadoop.hdfs.server.namenode.FsImageProto$FileSummary$Builder	setOndiskVersion	ondiskVersion_	J	int	0	org.apache.hadoop.hdfs.server.namenode.FsImageProto$FileSummary$Builder:setOndiskVersion(int)
org.apache.hadoop.hdfs.server.namenode.FsImageProto$FileSummary$Builder	setLayoutVersion	layoutVersion_	J	int	0	org.apache.hadoop.hdfs.server.namenode.FsImageProto$FileSummary$Builder:setLayoutVersion(int)
org.apache.hadoop.hdfs.server.namenode.FsImageProto$FileSummary$Builder	setCodec	codec_	J	java.lang.Object	0	org.apache.hadoop.hdfs.server.namenode.FsImageProto$FileSummary$Builder:setCodec(java.lang.String)
org.apache.hadoop.hdfs.server.namenode.FsImageProto$FileSummary$Builder	setCodecBytes	codec_	J	java.lang.Object	0	org.apache.hadoop.hdfs.server.namenode.FsImageProto$FileSummary$Builder:setCodecBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.server.namenode.FsImageProto$SecretManagerSection$DelegationKey$Builder	setId	id_	J	int	0	org.apache.hadoop.hdfs.server.namenode.FsImageProto$SecretManagerSection$DelegationKey$Builder:setId(int)
org.apache.hadoop.hdfs.server.namenode.FsImageProto$SecretManagerSection$DelegationKey$Builder	setExpiryDate	expiryDate_	J	long	0	org.apache.hadoop.hdfs.server.namenode.FsImageProto$SecretManagerSection$DelegationKey$Builder:setExpiryDate(long)
org.apache.hadoop.hdfs.server.namenode.FsImageProto$SecretManagerSection$DelegationKey$Builder	setKey	key_	C	org.apache.hadoop.thirdparty.protobuf.ByteString	0	org.apache.hadoop.hdfs.server.namenode.FsImageProto$SecretManagerSection$DelegationKey$Builder:setKey(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$RemoveCachePoolOp	setPoolName	poolName	J	java.lang.String	0	org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$RemoveCachePoolOp:setPoolName(java.lang.String)
org.apache.hadoop.hdfs.server.namenode.FsImageProto$INodeSection$INodeSymlink$Builder	setPermission	permission_	J	long	0	org.apache.hadoop.hdfs.server.namenode.FsImageProto$INodeSection$INodeSymlink$Builder:setPermission(long)
org.apache.hadoop.hdfs.server.namenode.FsImageProto$INodeSection$INodeSymlink$Builder	setTarget	target_	C	org.apache.hadoop.thirdparty.protobuf.ByteString	0	org.apache.hadoop.hdfs.server.namenode.FsImageProto$INodeSection$INodeSymlink$Builder:setTarget(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.server.namenode.FsImageProto$INodeSection$INodeSymlink$Builder	setModificationTime	modificationTime_	J	long	0	org.apache.hadoop.hdfs.server.namenode.FsImageProto$INodeSection$INodeSymlink$Builder:setModificationTime(long)
org.apache.hadoop.hdfs.server.namenode.FsImageProto$INodeSection$INodeSymlink$Builder	setAccessTime	accessTime_	J	long	0	org.apache.hadoop.hdfs.server.namenode.FsImageProto$INodeSection$INodeSymlink$Builder:setAccessTime(long)
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$RemoveErasureCodingPolicyOp	setErasureCodingPolicy	ecPolicyName	J	java.lang.String	0	org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$RemoveErasureCodingPolicyOp:setErasureCodingPolicy(java.lang.String)
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$Reader	setMaxOpSize	maxOpSize	J	int	0	org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$Reader:setMaxOpSize(int)
org.apache.hadoop.hdfs.server.namenode.FsImageProto$INodeSection$QuotaByStorageTypeEntryProto$Builder	setQuota	quota_	J	long	0	org.apache.hadoop.hdfs.server.namenode.FsImageProto$INodeSection$QuotaByStorageTypeEntryProto$Builder:setQuota(long)
org.apache.hadoop.hdfs.server.namenode.snapshot.DirectorySnapshottableFeature	setSnapshotQuota	snapshotQuota	J	int	0	org.apache.hadoop.hdfs.server.namenode.snapshot.DirectorySnapshottableFeature:setSnapshotQuota(int)
org.apache.hadoop.hdfs.server.namenode.snapshot.DiffListBySkipList$SkipDiff	setSkipTo	skipTo	C	org.apache.hadoop.hdfs.server.namenode.snapshot.DiffListBySkipList$SkipListNode	0	org.apache.hadoop.hdfs.server.namenode.snapshot.DiffListBySkipList$SkipDiff:setSkipTo(org.apache.hadoop.hdfs.server.namenode.snapshot.DiffListBySkipList$SkipListNode)
org.apache.hadoop.hdfs.server.namenode.snapshot.DiffListBySkipList$SkipDiff	setDiff	diff	C	org.apache.hadoop.hdfs.server.namenode.snapshot.DirectoryWithSnapshotFeature$ChildrenDiff	0	org.apache.hadoop.hdfs.server.namenode.snapshot.DiffListBySkipList$SkipDiff:setDiff(org.apache.hadoop.hdfs.server.namenode.snapshot.DirectoryWithSnapshotFeature$ChildrenDiff)
org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager	setCaptureOpenFiles	captureOpenFiles	J	boolean	0	org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager:setCaptureOpenFiles(boolean)
org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager	setAllowNestedSnapshots	allowNestedSnapshots	J	boolean	0	org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager:setAllowNestedSnapshots(boolean)
org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager	setSnapshotCounter	snapshotCounter	J	int	0	org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager:setSnapshotCounter(int)
org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotDiffListingInfo	setLastIndex	lastIndex	J	int	0	org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotDiffListingInfo:setLastIndex(int)
org.apache.hadoop.hdfs.server.namenode.snapshot.AbstractINodeDiff	setSnapshotId	snapshotId	J	int	0	org.apache.hadoop.hdfs.server.namenode.snapshot.AbstractINodeDiff:setSnapshotId(int)
org.apache.hadoop.hdfs.server.namenode.snapshot.AbstractINodeDiff	setPosterior	posteriorDiff	GC	org.apache.hadoop.hdfs.server.namenode.snapshot.AbstractINodeDiff	0	org.apache.hadoop.hdfs.server.namenode.snapshot.AbstractINodeDiff:setPosterior(org.apache.hadoop.hdfs.server.namenode.snapshot.AbstractINodeDiff)
org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotDiffInfo$RenameEntry	setTarget	targetPath	J	byte	2	org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotDiffInfo$RenameEntry:setTarget(byte[][])
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$RenameOldOp	setSource	src	J	java.lang.String	0	org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$RenameOldOp:setSource(java.lang.String)
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$RenameOldOp	setDestination	dst	J	java.lang.String	0	org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$RenameOldOp:setDestination(java.lang.String)
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$RenameOldOp	setTimestamp	timestamp	J	long	0	org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$RenameOldOp:setTimestamp(long)
org.apache.hadoop.hdfs.server.namenode.FsImageProto$SecretManagerSection$PersistToken$Builder	setVersion	version_	J	int	0	org.apache.hadoop.hdfs.server.namenode.FsImageProto$SecretManagerSection$PersistToken$Builder:setVersion(int)
org.apache.hadoop.hdfs.server.namenode.FsImageProto$SecretManagerSection$PersistToken$Builder	setOwner	owner_	J	java.lang.Object	0	org.apache.hadoop.hdfs.server.namenode.FsImageProto$SecretManagerSection$PersistToken$Builder:setOwner(java.lang.String)
org.apache.hadoop.hdfs.server.namenode.FsImageProto$SecretManagerSection$PersistToken$Builder	setOwnerBytes	owner_	J	java.lang.Object	0	org.apache.hadoop.hdfs.server.namenode.FsImageProto$SecretManagerSection$PersistToken$Builder:setOwnerBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.server.namenode.FsImageProto$SecretManagerSection$PersistToken$Builder	setRenewer	renewer_	J	java.lang.Object	0	org.apache.hadoop.hdfs.server.namenode.FsImageProto$SecretManagerSection$PersistToken$Builder:setRenewer(java.lang.String)
org.apache.hadoop.hdfs.server.namenode.FsImageProto$SecretManagerSection$PersistToken$Builder	setRenewerBytes	renewer_	J	java.lang.Object	0	org.apache.hadoop.hdfs.server.namenode.FsImageProto$SecretManagerSection$PersistToken$Builder:setRenewerBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.server.namenode.FsImageProto$SecretManagerSection$PersistToken$Builder	setRealUser	realUser_	J	java.lang.Object	0	org.apache.hadoop.hdfs.server.namenode.FsImageProto$SecretManagerSection$PersistToken$Builder:setRealUser(java.lang.String)
org.apache.hadoop.hdfs.server.namenode.FsImageProto$SecretManagerSection$PersistToken$Builder	setRealUserBytes	realUser_	J	java.lang.Object	0	org.apache.hadoop.hdfs.server.namenode.FsImageProto$SecretManagerSection$PersistToken$Builder:setRealUserBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.server.namenode.FsImageProto$SecretManagerSection$PersistToken$Builder	setIssueDate	issueDate_	J	long	0	org.apache.hadoop.hdfs.server.namenode.FsImageProto$SecretManagerSection$PersistToken$Builder:setIssueDate(long)
org.apache.hadoop.hdfs.server.namenode.FsImageProto$SecretManagerSection$PersistToken$Builder	setMaxDate	maxDate_	J	long	0	org.apache.hadoop.hdfs.server.namenode.FsImageProto$SecretManagerSection$PersistToken$Builder:setMaxDate(long)
org.apache.hadoop.hdfs.server.namenode.FsImageProto$SecretManagerSection$PersistToken$Builder	setSequenceNumber	sequenceNumber_	J	int	0	org.apache.hadoop.hdfs.server.namenode.FsImageProto$SecretManagerSection$PersistToken$Builder:setSequenceNumber(int)
org.apache.hadoop.hdfs.server.namenode.FsImageProto$SecretManagerSection$PersistToken$Builder	setMasterKeyId	masterKeyId_	J	int	0	org.apache.hadoop.hdfs.server.namenode.FsImageProto$SecretManagerSection$PersistToken$Builder:setMasterKeyId(int)
org.apache.hadoop.hdfs.server.namenode.FsImageProto$SecretManagerSection$PersistToken$Builder	setExpiryDate	expiryDate_	J	long	0	org.apache.hadoop.hdfs.server.namenode.FsImageProto$SecretManagerSection$PersistToken$Builder:setExpiryDate(long)
org.apache.hadoop.hdfs.server.namenode.JournalSet$JournalAndStream	setCurrentStreamForTests	stream	C	org.apache.hadoop.hdfs.server.namenode.EditLogOutputStream	0	org.apache.hadoop.hdfs.server.namenode.JournalSet$JournalAndStream:setCurrentStreamForTests(org.apache.hadoop.hdfs.server.namenode.EditLogOutputStream)
org.apache.hadoop.hdfs.server.namenode.JournalSet$JournalAndStream	setJournalForTests	journal	C	org.apache.hadoop.hdfs.server.namenode.JournalManager	0	org.apache.hadoop.hdfs.server.namenode.JournalSet$JournalAndStream:setJournalForTests(org.apache.hadoop.hdfs.server.namenode.JournalManager)
org.apache.hadoop.hdfs.server.namenode.JournalSet$JournalAndStream	setDisabled	disabled	J	boolean	0	org.apache.hadoop.hdfs.server.namenode.JournalSet$JournalAndStream:setDisabled(boolean)
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$SetPermissionsOp	setSource	src	J	java.lang.String	0	org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$SetPermissionsOp:setSource(java.lang.String)
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$SetPermissionsOp	setPermissions	permissions	C	org.apache.hadoop.fs.permission.FsPermission	0	org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$SetPermissionsOp:setPermissions(org.apache.hadoop.fs.permission.FsPermission)
org.apache.hadoop.hdfs.server.namenode.FsImageProto$NameSystemSection$Builder	setNamespaceId	namespaceId_	J	int	0	org.apache.hadoop.hdfs.server.namenode.FsImageProto$NameSystemSection$Builder:setNamespaceId(int)
org.apache.hadoop.hdfs.server.namenode.FsImageProto$NameSystemSection$Builder	setGenstampV1	genstampV1_	J	long	0	org.apache.hadoop.hdfs.server.namenode.FsImageProto$NameSystemSection$Builder:setGenstampV1(long)
org.apache.hadoop.hdfs.server.namenode.FsImageProto$NameSystemSection$Builder	setGenstampV2	genstampV2_	J	long	0	org.apache.hadoop.hdfs.server.namenode.FsImageProto$NameSystemSection$Builder:setGenstampV2(long)
org.apache.hadoop.hdfs.server.namenode.FsImageProto$NameSystemSection$Builder	setGenstampV1Limit	genstampV1Limit_	J	long	0	org.apache.hadoop.hdfs.server.namenode.FsImageProto$NameSystemSection$Builder:setGenstampV1Limit(long)
org.apache.hadoop.hdfs.server.namenode.FsImageProto$NameSystemSection$Builder	setLastAllocatedBlockId	lastAllocatedBlockId_	J	long	0	org.apache.hadoop.hdfs.server.namenode.FsImageProto$NameSystemSection$Builder:setLastAllocatedBlockId(long)
org.apache.hadoop.hdfs.server.namenode.FsImageProto$NameSystemSection$Builder	setTransactionId	transactionId_	J	long	0	org.apache.hadoop.hdfs.server.namenode.FsImageProto$NameSystemSection$Builder:setTransactionId(long)
org.apache.hadoop.hdfs.server.namenode.FsImageProto$NameSystemSection$Builder	setRollingUpgradeStartTime	rollingUpgradeStartTime_	J	long	0	org.apache.hadoop.hdfs.server.namenode.FsImageProto$NameSystemSection$Builder:setRollingUpgradeStartTime(long)
org.apache.hadoop.hdfs.server.namenode.FsImageProto$NameSystemSection$Builder	setLastAllocatedStripedBlockId	lastAllocatedStripedBlockId_	J	long	0	org.apache.hadoop.hdfs.server.namenode.FsImageProto$NameSystemSection$Builder:setLastAllocatedStripedBlockId(long)
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$ModifyCacheDirectiveInfoOp	setDirective	directive	C	org.apache.hadoop.hdfs.protocol.CacheDirectiveInfo	0	org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$ModifyCacheDirectiveInfoOp:setDirective(org.apache.hadoop.hdfs.protocol.CacheDirectiveInfo)
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$SetOwnerOp	setSource	src	J	java.lang.String	0	org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$SetOwnerOp:setSource(java.lang.String)
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$SetOwnerOp	setUser	username	J	java.lang.String	0	org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$SetOwnerOp:setUser(java.lang.String)
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$SetOwnerOp	setGroup	groupname	J	java.lang.String	0	org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$SetOwnerOp:setGroup(java.lang.String)
org.apache.hadoop.hdfs.server.namenode.FsImageProto$INodeReferenceSection$INodeReference$Builder	setReferredId	referredId_	J	long	0	org.apache.hadoop.hdfs.server.namenode.FsImageProto$INodeReferenceSection$INodeReference$Builder:setReferredId(long)
org.apache.hadoop.hdfs.server.namenode.FsImageProto$INodeReferenceSection$INodeReference$Builder	setName	name_	C	org.apache.hadoop.thirdparty.protobuf.ByteString	0	org.apache.hadoop.hdfs.server.namenode.FsImageProto$INodeReferenceSection$INodeReference$Builder:setName(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.server.namenode.FsImageProto$INodeReferenceSection$INodeReference$Builder	setDstSnapshotId	dstSnapshotId_	J	int	0	org.apache.hadoop.hdfs.server.namenode.FsImageProto$INodeReferenceSection$INodeReference$Builder:setDstSnapshotId(int)
org.apache.hadoop.hdfs.server.namenode.FsImageProto$INodeReferenceSection$INodeReference$Builder	setLastSnapshotId	lastSnapshotId_	J	int	0	org.apache.hadoop.hdfs.server.namenode.FsImageProto$INodeReferenceSection$INodeReference$Builder:setLastSnapshotId(int)
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$RenameOp	setSource	src	J	java.lang.String	0	org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$RenameOp:setSource(java.lang.String)
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$RenameOp	setDestination	dst	J	java.lang.String	0	org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$RenameOp:setDestination(java.lang.String)
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$RenameOp	setTimestamp	timestamp	J	long	0	org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$RenameOp:setTimestamp(long)
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$RenameOp	setOptions	options	C	org.apache.hadoop.fs.Options$Rename	1	org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$RenameOp:setOptions(org.apache.hadoop.fs.Options$Rename[])
org.apache.hadoop.hdfs.server.namenode.NNStorage	setRestoreFailedStorage	restoreFailedStorage	J	boolean	0	org.apache.hadoop.hdfs.server.namenode.NNStorage:setRestoreFailedStorage(boolean)
org.apache.hadoop.hdfs.server.namenode.NNStorage	setDisablePreUpgradableLayoutCheck	disablePreUpgradableLayoutCheck	J	boolean	0	org.apache.hadoop.hdfs.server.namenode.NNStorage:setDisablePreUpgradableLayoutCheck(boolean)
org.apache.hadoop.hdfs.server.namenode.NNStorage	setBlockPoolID	blockpoolID	J	java.lang.String	0	org.apache.hadoop.hdfs.server.namenode.NNStorage:setBlockPoolID(java.lang.String)
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$UpdateBlocksOp	setPath	path	J	java.lang.String	0	org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$UpdateBlocksOp:setPath(java.lang.String)
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$UpdateBlocksOp	setBlocks	blocks	C	org.apache.hadoop.hdfs.protocol.Block	1	org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$UpdateBlocksOp:setBlocks(org.apache.hadoop.hdfs.protocol.Block[])
org.apache.hadoop.hdfs.server.namenode.ReencryptionUpdater$FileEdekInfo	setEdek	edek	C	org.apache.hadoop.crypto.key.KeyProviderCryptoExtension$EncryptedKeyVersion	0	org.apache.hadoop.hdfs.server.namenode.ReencryptionUpdater$FileEdekInfo:setEdek(org.apache.hadoop.crypto.key.KeyProviderCryptoExtension$EncryptedKeyVersion)
org.apache.hadoop.hdfs.server.namenode.FsImageProto$SnapshotSection$Builder	setSnapshotCounter	snapshotCounter_	J	int	0	org.apache.hadoop.hdfs.server.namenode.FsImageProto$SnapshotSection$Builder:setSnapshotCounter(int)
org.apache.hadoop.hdfs.server.namenode.FsImageProto$SnapshotSection$Builder	setNumSnapshots	numSnapshots_	J	int	0	org.apache.hadoop.hdfs.server.namenode.FsImageProto$SnapshotSection$Builder:setNumSnapshots(int)
org.apache.hadoop.hdfs.server.namenode.FSEditLog	setJournalSetForTesting	journalSet	C	org.apache.hadoop.hdfs.server.namenode.JournalSet	0	org.apache.hadoop.hdfs.server.namenode.FSEditLog:setJournalSetForTesting(org.apache.hadoop.hdfs.server.namenode.JournalSet)
org.apache.hadoop.hdfs.server.namenode.FSEditLog	setMetricsForTests	metrics	C	org.apache.hadoop.hdfs.server.namenode.metrics.NameNodeMetrics	0	org.apache.hadoop.hdfs.server.namenode.FSEditLog:setMetricsForTests(org.apache.hadoop.hdfs.server.namenode.metrics.NameNodeMetrics)
org.apache.hadoop.hdfs.server.namenode.INodeAttributeProvider$AuthorizationContext	setFsOwner	fsOwner	J	java.lang.String	0	org.apache.hadoop.hdfs.server.namenode.INodeAttributeProvider$AuthorizationContext:setFsOwner(java.lang.String)
org.apache.hadoop.hdfs.server.namenode.INodeAttributeProvider$AuthorizationContext	setSupergroup	supergroup	J	java.lang.String	0	org.apache.hadoop.hdfs.server.namenode.INodeAttributeProvider$AuthorizationContext:setSupergroup(java.lang.String)
org.apache.hadoop.hdfs.server.namenode.INodeAttributeProvider$AuthorizationContext	setCallerUgi	callerUgi	C	org.apache.hadoop.security.UserGroupInformation	0	org.apache.hadoop.hdfs.server.namenode.INodeAttributeProvider$AuthorizationContext:setCallerUgi(org.apache.hadoop.security.UserGroupInformation)
org.apache.hadoop.hdfs.server.namenode.INodeAttributeProvider$AuthorizationContext	setInodeAttrs	inodeAttrs	C	org.apache.hadoop.hdfs.server.namenode.INodeAttributes	1	org.apache.hadoop.hdfs.server.namenode.INodeAttributeProvider$AuthorizationContext:setInodeAttrs(org.apache.hadoop.hdfs.server.namenode.INodeAttributes[])
org.apache.hadoop.hdfs.server.namenode.INodeAttributeProvider$AuthorizationContext	setInodes	inodes	C	org.apache.hadoop.hdfs.server.namenode.INode	1	org.apache.hadoop.hdfs.server.namenode.INodeAttributeProvider$AuthorizationContext:setInodes(org.apache.hadoop.hdfs.server.namenode.INode[])
org.apache.hadoop.hdfs.server.namenode.INodeAttributeProvider$AuthorizationContext	setPathByNameArr	pathByNameArr	J	byte	2	org.apache.hadoop.hdfs.server.namenode.INodeAttributeProvider$AuthorizationContext:setPathByNameArr(byte[][])
org.apache.hadoop.hdfs.server.namenode.INodeAttributeProvider$AuthorizationContext	setSnapshotId	snapshotId	J	int	0	org.apache.hadoop.hdfs.server.namenode.INodeAttributeProvider$AuthorizationContext:setSnapshotId(int)
org.apache.hadoop.hdfs.server.namenode.INodeAttributeProvider$AuthorizationContext	setPath	path	J	java.lang.String	0	org.apache.hadoop.hdfs.server.namenode.INodeAttributeProvider$AuthorizationContext:setPath(java.lang.String)
org.apache.hadoop.hdfs.server.namenode.INodeAttributeProvider$AuthorizationContext	setAncestorIndex	ancestorIndex	J	int	0	org.apache.hadoop.hdfs.server.namenode.INodeAttributeProvider$AuthorizationContext:setAncestorIndex(int)
org.apache.hadoop.hdfs.server.namenode.INodeAttributeProvider$AuthorizationContext	setDoCheckOwner	doCheckOwner	J	boolean	0	org.apache.hadoop.hdfs.server.namenode.INodeAttributeProvider$AuthorizationContext:setDoCheckOwner(boolean)
org.apache.hadoop.hdfs.server.namenode.INodeAttributeProvider$AuthorizationContext	setAncestorAccess	ancestorAccess	C	org.apache.hadoop.fs.permission.FsAction	0	org.apache.hadoop.hdfs.server.namenode.INodeAttributeProvider$AuthorizationContext:setAncestorAccess(org.apache.hadoop.fs.permission.FsAction)
org.apache.hadoop.hdfs.server.namenode.INodeAttributeProvider$AuthorizationContext	setParentAccess	parentAccess	C	org.apache.hadoop.fs.permission.FsAction	0	org.apache.hadoop.hdfs.server.namenode.INodeAttributeProvider$AuthorizationContext:setParentAccess(org.apache.hadoop.fs.permission.FsAction)
org.apache.hadoop.hdfs.server.namenode.INodeAttributeProvider$AuthorizationContext	setAccess	access	C	org.apache.hadoop.fs.permission.FsAction	0	org.apache.hadoop.hdfs.server.namenode.INodeAttributeProvider$AuthorizationContext:setAccess(org.apache.hadoop.fs.permission.FsAction)
org.apache.hadoop.hdfs.server.namenode.INodeAttributeProvider$AuthorizationContext	setSubAccess	subAccess	C	org.apache.hadoop.fs.permission.FsAction	0	org.apache.hadoop.hdfs.server.namenode.INodeAttributeProvider$AuthorizationContext:setSubAccess(org.apache.hadoop.fs.permission.FsAction)
org.apache.hadoop.hdfs.server.namenode.INodeAttributeProvider$AuthorizationContext	setIgnoreEmptyDir	ignoreEmptyDir	J	boolean	0	org.apache.hadoop.hdfs.server.namenode.INodeAttributeProvider$AuthorizationContext:setIgnoreEmptyDir(boolean)
org.apache.hadoop.hdfs.server.namenode.INodeAttributeProvider$AuthorizationContext	setOperationName	operationName	J	java.lang.String	0	org.apache.hadoop.hdfs.server.namenode.INodeAttributeProvider$AuthorizationContext:setOperationName(java.lang.String)
org.apache.hadoop.hdfs.server.namenode.INodeAttributeProvider$AuthorizationContext	setCallerContext	callerContext	C	org.apache.hadoop.ipc.CallerContext	0	org.apache.hadoop.hdfs.server.namenode.INodeAttributeProvider$AuthorizationContext:setCallerContext(org.apache.hadoop.ipc.CallerContext)
org.apache.hadoop.hdfs.server.namenode.StoragePolicySummary$StorageTypeAllocation	setActualStoragePolicy	actualStoragePolicy	C	org.apache.hadoop.hdfs.protocol.BlockStoragePolicy	0	org.apache.hadoop.hdfs.server.namenode.StoragePolicySummary$StorageTypeAllocation:setActualStoragePolicy(org.apache.hadoop.hdfs.protocol.BlockStoragePolicy)
org.apache.hadoop.hdfs.server.namenode.EditLogFileOutputStream	setFileChannelForTesting	fc	J	java.nio.channels.FileChannel	0	org.apache.hadoop.hdfs.server.namenode.EditLogFileOutputStream:setFileChannelForTesting(java.nio.channels.FileChannel)
org.apache.hadoop.hdfs.server.namenode.FsImageProto$INodeSection$FileUnderConstructionFeature$Builder	setClientName	clientName_	J	java.lang.Object	0	org.apache.hadoop.hdfs.server.namenode.FsImageProto$INodeSection$FileUnderConstructionFeature$Builder:setClientName(java.lang.String)
org.apache.hadoop.hdfs.server.namenode.FsImageProto$INodeSection$FileUnderConstructionFeature$Builder	setClientNameBytes	clientName_	J	java.lang.Object	0	org.apache.hadoop.hdfs.server.namenode.FsImageProto$INodeSection$FileUnderConstructionFeature$Builder:setClientNameBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.server.namenode.FsImageProto$INodeSection$FileUnderConstructionFeature$Builder	setClientMachine	clientMachine_	J	java.lang.Object	0	org.apache.hadoop.hdfs.server.namenode.FsImageProto$INodeSection$FileUnderConstructionFeature$Builder:setClientMachine(java.lang.String)
org.apache.hadoop.hdfs.server.namenode.FsImageProto$INodeSection$FileUnderConstructionFeature$Builder	setClientMachineBytes	clientMachine_	J	java.lang.Object	0	org.apache.hadoop.hdfs.server.namenode.FsImageProto$INodeSection$FileUnderConstructionFeature$Builder:setClientMachineBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.server.namenode.CachePool	setOwnerName	ownerName	J	java.lang.String	0	org.apache.hadoop.hdfs.server.namenode.CachePool:setOwnerName(java.lang.String)
org.apache.hadoop.hdfs.server.namenode.CachePool	setGroupName	groupName	J	java.lang.String	0	org.apache.hadoop.hdfs.server.namenode.CachePool:setGroupName(java.lang.String)
org.apache.hadoop.hdfs.server.namenode.CachePool	setMode	mode	C	org.apache.hadoop.fs.permission.FsPermission	0	org.apache.hadoop.hdfs.server.namenode.CachePool:setMode(org.apache.hadoop.fs.permission.FsPermission)
org.apache.hadoop.hdfs.server.namenode.CachePool	setLimit	limit	J	long	0	org.apache.hadoop.hdfs.server.namenode.CachePool:setLimit(long)
org.apache.hadoop.hdfs.server.namenode.CachePool	setDefaultReplication	defaultReplication	J	short	0	org.apache.hadoop.hdfs.server.namenode.CachePool:setDefaultReplication(short)
org.apache.hadoop.hdfs.server.namenode.CachePool	setMaxRelativeExpiryMs	maxRelativeExpiryMs	J	long	0	org.apache.hadoop.hdfs.server.namenode.CachePool:setMaxRelativeExpiryMs(long)
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$ModifyCachePoolOp	setInfo	info	C	org.apache.hadoop.hdfs.protocol.CachePoolInfo	0	org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$ModifyCachePoolOp:setInfo(org.apache.hadoop.hdfs.protocol.CachePoolInfo)
org.apache.hadoop.hdfs.server.namenode.FsImageProto$SnapshotDiffSection$DiffEntry$Builder	setInodeId	inodeId_	J	long	0	org.apache.hadoop.hdfs.server.namenode.FsImageProto$SnapshotDiffSection$DiffEntry$Builder:setInodeId(long)
org.apache.hadoop.hdfs.server.namenode.FsImageProto$SnapshotDiffSection$DiffEntry$Builder	setNumOfDiff	numOfDiff_	J	int	0	org.apache.hadoop.hdfs.server.namenode.FsImageProto$SnapshotDiffSection$DiffEntry$Builder:setNumOfDiff(int)
org.apache.hadoop.hdfs.server.namenode.FsImageProto$INodeSection$XAttrCompactProto$Builder	setName	name_	J	int	0	org.apache.hadoop.hdfs.server.namenode.FsImageProto$INodeSection$XAttrCompactProto$Builder:setName(int)
org.apache.hadoop.hdfs.server.namenode.FsImageProto$INodeSection$XAttrCompactProto$Builder	setValue	value_	C	org.apache.hadoop.thirdparty.protobuf.ByteString	0	org.apache.hadoop.hdfs.server.namenode.FsImageProto$INodeSection$XAttrCompactProto$Builder:setValue(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$UpdateMasterKeyOp	setDelegationKey	key	C	org.apache.hadoop.security.token.delegation.DelegationKey	0	org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$UpdateMasterKeyOp:setDelegationKey(org.apache.hadoop.security.token.delegation.DelegationKey)
org.apache.hadoop.hdfs.server.namenode.FsImageProto$INodeSection$INodeFile$Builder	setReplication	replication_	J	int	0	org.apache.hadoop.hdfs.server.namenode.FsImageProto$INodeSection$INodeFile$Builder:setReplication(int)
org.apache.hadoop.hdfs.server.namenode.FsImageProto$INodeSection$INodeFile$Builder	setModificationTime	modificationTime_	J	long	0	org.apache.hadoop.hdfs.server.namenode.FsImageProto$INodeSection$INodeFile$Builder:setModificationTime(long)
org.apache.hadoop.hdfs.server.namenode.FsImageProto$INodeSection$INodeFile$Builder	setAccessTime	accessTime_	J	long	0	org.apache.hadoop.hdfs.server.namenode.FsImageProto$INodeSection$INodeFile$Builder:setAccessTime(long)
org.apache.hadoop.hdfs.server.namenode.FsImageProto$INodeSection$INodeFile$Builder	setPreferredBlockSize	preferredBlockSize_	J	long	0	org.apache.hadoop.hdfs.server.namenode.FsImageProto$INodeSection$INodeFile$Builder:setPreferredBlockSize(long)
org.apache.hadoop.hdfs.server.namenode.FsImageProto$INodeSection$INodeFile$Builder	setPermission	permission_	J	long	0	org.apache.hadoop.hdfs.server.namenode.FsImageProto$INodeSection$INodeFile$Builder:setPermission(long)
org.apache.hadoop.hdfs.server.namenode.FsImageProto$INodeSection$INodeFile$Builder	setStoragePolicyID	storagePolicyID_	J	int	0	org.apache.hadoop.hdfs.server.namenode.FsImageProto$INodeSection$INodeFile$Builder:setStoragePolicyID(int)
org.apache.hadoop.hdfs.server.namenode.FsImageProto$INodeSection$INodeFile$Builder	setErasureCodingPolicyID	erasureCodingPolicyID_	J	int	0	org.apache.hadoop.hdfs.server.namenode.FsImageProto$INodeSection$INodeFile$Builder:setErasureCodingPolicyID(int)
org.apache.hadoop.hdfs.server.namenode.FsImageProto$SnapshotDiffSection$CreatedListEntry$Builder	setName	name_	C	org.apache.hadoop.thirdparty.protobuf.ByteString	0	org.apache.hadoop.hdfs.server.namenode.FsImageProto$SnapshotDiffSection$CreatedListEntry$Builder:setName(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.server.namenode.EditLogOutputStream	setCurrentLogVersion	currentLogVersion	J	int	0	org.apache.hadoop.hdfs.server.namenode.EditLogOutputStream:setCurrentLogVersion(int)
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$SetReplicationOp	setPath	path	J	java.lang.String	0	org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$SetReplicationOp:setPath(java.lang.String)
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$SetReplicationOp	setReplication	replication	J	short	0	org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$SetReplicationOp:setReplication(short)
org.apache.hadoop.hdfs.server.namenode.FileJournalManager	setOutputBufferCapacity	outputBufferCapacity	J	int	0	org.apache.hadoop.hdfs.server.namenode.FileJournalManager:setOutputBufferCapacity(int)
org.apache.hadoop.hdfs.server.namenode.FileJournalManager	setLastReadableTxId	lastReadableTxId	J	long	0	org.apache.hadoop.hdfs.server.namenode.FileJournalManager:setLastReadableTxId(long)
org.apache.hadoop.hdfs.server.namenode.FsImageProto$INodeSection$INode$Builder	setId	id_	J	long	0	org.apache.hadoop.hdfs.server.namenode.FsImageProto$INodeSection$INode$Builder:setId(long)
org.apache.hadoop.hdfs.server.namenode.FsImageProto$INodeSection$INode$Builder	setName	name_	C	org.apache.hadoop.thirdparty.protobuf.ByteString	0	org.apache.hadoop.hdfs.server.namenode.FsImageProto$INodeSection$INode$Builder:setName(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.server.namenode.INode	setParent	parent	C	org.apache.hadoop.hdfs.server.namenode.INode	0	org.apache.hadoop.hdfs.server.namenode.INode:setParent(org.apache.hadoop.hdfs.server.namenode.INodeDirectory)
org.apache.hadoop.hdfs.server.namenode.INode	setParentReference	parent	C	org.apache.hadoop.hdfs.server.namenode.INode	0	org.apache.hadoop.hdfs.server.namenode.INode:setParentReference(org.apache.hadoop.hdfs.server.namenode.INodeReference)
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$SetStoragePolicyOp	setPath	path	J	java.lang.String	0	org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$SetStoragePolicyOp:setPath(java.lang.String)
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$SetStoragePolicyOp	setPolicyId	policyId	J	byte	0	org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$SetStoragePolicyOp:setPolicyId(byte)
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp	setTransactionId	txid	J	long	0	org.apache.hadoop.hdfs.server.namenode.FSEditLogOp:setTransactionId(long)
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp	setRpcClientId	rpcClientId	J	byte	1	org.apache.hadoop.hdfs.server.namenode.FSEditLogOp:setRpcClientId(byte[])
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp	setRpcCallId	rpcCallId	J	int	0	org.apache.hadoop.hdfs.server.namenode.FSEditLogOp:setRpcCallId(int)
org.apache.hadoop.hdfs.server.namenode.FSNamesystem	setImageLoaded	imageLoaded	J	boolean	0	org.apache.hadoop.hdfs.server.namenode.FSNamesystem:setImageLoaded(boolean)
org.apache.hadoop.hdfs.server.namenode.FSNamesystem	setBlockManagerForTesting	blockManager	C	org.apache.hadoop.hdfs.server.blockmanagement.BlockManager	0	org.apache.hadoop.hdfs.server.namenode.FSNamesystem:setBlockManagerForTesting(org.apache.hadoop.hdfs.server.blockmanagement.BlockManager)
org.apache.hadoop.hdfs.server.namenode.FSNamesystem	setFSDirectory	dir	C	org.apache.hadoop.hdfs.server.namenode.FSDirectory	0	org.apache.hadoop.hdfs.server.namenode.FSNamesystem:setFSDirectory(org.apache.hadoop.hdfs.server.namenode.FSDirectory)
org.apache.hadoop.hdfs.server.namenode.FSNamesystem	setEditLogTailerForTests	editLogTailer	C	org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer	0	org.apache.hadoop.hdfs.server.namenode.FSNamesystem:setEditLogTailerForTests(org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer)
org.apache.hadoop.hdfs.server.namenode.FSNamesystem	setNNResourceChecker	nnResourceChecker	C	org.apache.hadoop.hdfs.server.namenode.NameNodeResourceChecker	0	org.apache.hadoop.hdfs.server.namenode.FSNamesystem:setNNResourceChecker(org.apache.hadoop.hdfs.server.namenode.NameNodeResourceChecker)
org.apache.hadoop.hdfs.server.namenode.FSNamesystem	setNeedRollbackFsImage	needRollbackFsImage	J	boolean	0	org.apache.hadoop.hdfs.server.namenode.FSNamesystem:setNeedRollbackFsImage(boolean)
org.apache.hadoop.hdfs.server.namenode.FsImageProto$SnapshotDiffSection$DirectoryDiff$Builder	setSnapshotId	snapshotId_	J	int	0	org.apache.hadoop.hdfs.server.namenode.FsImageProto$SnapshotDiffSection$DirectoryDiff$Builder:setSnapshotId(int)
org.apache.hadoop.hdfs.server.namenode.FsImageProto$SnapshotDiffSection$DirectoryDiff$Builder	setChildrenSize	childrenSize_	J	int	0	org.apache.hadoop.hdfs.server.namenode.FsImageProto$SnapshotDiffSection$DirectoryDiff$Builder:setChildrenSize(int)
org.apache.hadoop.hdfs.server.namenode.FsImageProto$SnapshotDiffSection$DirectoryDiff$Builder	setIsSnapshotRoot	isSnapshotRoot_	J	boolean	0	org.apache.hadoop.hdfs.server.namenode.FsImageProto$SnapshotDiffSection$DirectoryDiff$Builder:setIsSnapshotRoot(boolean)
org.apache.hadoop.hdfs.server.namenode.FsImageProto$SnapshotDiffSection$DirectoryDiff$Builder	setName	name_	C	org.apache.hadoop.thirdparty.protobuf.ByteString	0	org.apache.hadoop.hdfs.server.namenode.FsImageProto$SnapshotDiffSection$DirectoryDiff$Builder:setName(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.server.namenode.FsImageProto$SnapshotDiffSection$DirectoryDiff$Builder	setCreatedListSize	createdListSize_	J	int	0	org.apache.hadoop.hdfs.server.namenode.FsImageProto$SnapshotDiffSection$DirectoryDiff$Builder:setCreatedListSize(int)
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$DeleteOp	setPath	path	J	java.lang.String	0	org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$DeleteOp:setPath(java.lang.String)
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$DeleteOp	setTimestamp	timestamp	J	long	0	org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$DeleteOp:setTimestamp(long)
org.apache.hadoop.hdfs.server.namenode.FsImageProto$INodeSection$INodeDirectory$Builder	setModificationTime	modificationTime_	J	long	0	org.apache.hadoop.hdfs.server.namenode.FsImageProto$INodeSection$INodeDirectory$Builder:setModificationTime(long)
org.apache.hadoop.hdfs.server.namenode.FsImageProto$INodeSection$INodeDirectory$Builder	setNsQuota	nsQuota_	J	long	0	org.apache.hadoop.hdfs.server.namenode.FsImageProto$INodeSection$INodeDirectory$Builder:setNsQuota(long)
org.apache.hadoop.hdfs.server.namenode.FsImageProto$INodeSection$INodeDirectory$Builder	setDsQuota	dsQuota_	J	long	0	org.apache.hadoop.hdfs.server.namenode.FsImageProto$INodeSection$INodeDirectory$Builder:setDsQuota(long)
org.apache.hadoop.hdfs.server.namenode.FsImageProto$INodeSection$INodeDirectory$Builder	setPermission	permission_	J	long	0	org.apache.hadoop.hdfs.server.namenode.FsImageProto$INodeSection$INodeDirectory$Builder:setPermission(long)
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$TruncateOp	setPath	src	J	java.lang.String	0	org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$TruncateOp:setPath(java.lang.String)
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$TruncateOp	setClientName	clientName	J	java.lang.String	0	org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$TruncateOp:setClientName(java.lang.String)
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$TruncateOp	setClientMachine	clientMachine	J	java.lang.String	0	org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$TruncateOp:setClientMachine(java.lang.String)
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$TruncateOp	setNewLength	newLength	J	long	0	org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$TruncateOp:setNewLength(long)
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$TruncateOp	setTimestamp	timestamp	J	long	0	org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$TruncateOp:setTimestamp(long)
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$TruncateOp	setTruncateBlock	truncateBlock	C	org.apache.hadoop.hdfs.protocol.Block	0	org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$TruncateOp:setTruncateBlock(org.apache.hadoop.hdfs.protocol.Block)
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$SetQuotaOp	setSource	src	J	java.lang.String	0	org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$SetQuotaOp:setSource(java.lang.String)
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$SetQuotaOp	setNSQuota	nsQuota	J	long	0	org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$SetQuotaOp:setNSQuota(long)
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$SetQuotaOp	setDSQuota	dsQuota	J	long	0	org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$SetQuotaOp:setDSQuota(long)
org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode	setFSImage	checkpointImage	C	org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage	0	org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode:setFSImage(org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage)
org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode	setNameNode	namenode	C	org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol	0	org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode:setNameNode(org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol)
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$DisableErasureCodingPolicyOp	setErasureCodingPolicy	ecPolicyName	J	java.lang.String	0	org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$DisableErasureCodingPolicyOp:setErasureCodingPolicy(java.lang.String)
org.apache.hadoop.hdfs.server.namenode.CheckpointSignature	setBlockpoolID	blockpoolID	J	java.lang.String	0	org.apache.hadoop.hdfs.server.namenode.CheckpointSignature:setBlockpoolID(java.lang.String)
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$ConcatDeleteOp	setTarget	trg	J	java.lang.String	0	org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$ConcatDeleteOp:setTarget(java.lang.String)
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$ConcatDeleteOp	setSources	srcs	J	java.lang.String	1	org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$ConcatDeleteOp:setSources(java.lang.String[])
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$ConcatDeleteOp	setTimestamp	timestamp	J	long	0	org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$ConcatDeleteOp:setTimestamp(long)
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$SetGenstampV1Op	setGenerationStamp	genStampV1	J	long	0	org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$SetGenstampV1Op:setGenerationStamp(long)
org.apache.hadoop.hdfs.server.namenode.MetaRecoveryContext	setForce	force	J	int	0	org.apache.hadoop.hdfs.server.namenode.MetaRecoveryContext:setForce(int)
org.apache.hadoop.hdfs.server.namenode.EditLogFileInputStream	setMaxOpSize	maxOpSize	J	int	0	org.apache.hadoop.hdfs.server.namenode.EditLogFileInputStream:setMaxOpSize(int)
org.apache.hadoop.hdfs.server.namenode.FsImageProto$FileSummary$Section$Builder	setName	name_	J	java.lang.Object	0	org.apache.hadoop.hdfs.server.namenode.FsImageProto$FileSummary$Section$Builder:setName(java.lang.String)
org.apache.hadoop.hdfs.server.namenode.FsImageProto$FileSummary$Section$Builder	setNameBytes	name_	J	java.lang.Object	0	org.apache.hadoop.hdfs.server.namenode.FsImageProto$FileSummary$Section$Builder:setNameBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.server.namenode.FsImageProto$FileSummary$Section$Builder	setLength	length_	J	long	0	org.apache.hadoop.hdfs.server.namenode.FsImageProto$FileSummary$Section$Builder:setLength(long)
org.apache.hadoop.hdfs.server.namenode.FsImageProto$FileSummary$Section$Builder	setOffset	offset_	J	long	0	org.apache.hadoop.hdfs.server.namenode.FsImageProto$FileSummary$Section$Builder:setOffset(long)
org.apache.hadoop.hdfs.server.namenode.FsImageProto$FilesUnderConstructionSection$FileUnderConstructionEntry$Builder	setInodeId	inodeId_	J	long	0	org.apache.hadoop.hdfs.server.namenode.FsImageProto$FilesUnderConstructionSection$FileUnderConstructionEntry$Builder:setInodeId(long)
org.apache.hadoop.hdfs.server.namenode.FsImageProto$FilesUnderConstructionSection$FileUnderConstructionEntry$Builder	setFullPath	fullPath_	J	java.lang.Object	0	org.apache.hadoop.hdfs.server.namenode.FsImageProto$FilesUnderConstructionSection$FileUnderConstructionEntry$Builder:setFullPath(java.lang.String)
org.apache.hadoop.hdfs.server.namenode.FsImageProto$FilesUnderConstructionSection$FileUnderConstructionEntry$Builder	setFullPathBytes	fullPath_	J	java.lang.Object	0	org.apache.hadoop.hdfs.server.namenode.FsImageProto$FilesUnderConstructionSection$FileUnderConstructionEntry$Builder:setFullPathBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.server.namenode.FsImageProto$SnapshotDiffSection$FileDiff$Builder	setSnapshotId	snapshotId_	J	int	0	org.apache.hadoop.hdfs.server.namenode.FsImageProto$SnapshotDiffSection$FileDiff$Builder:setSnapshotId(int)
org.apache.hadoop.hdfs.server.namenode.FsImageProto$SnapshotDiffSection$FileDiff$Builder	setFileSize	fileSize_	J	long	0	org.apache.hadoop.hdfs.server.namenode.FsImageProto$SnapshotDiffSection$FileDiff$Builder:setFileSize(long)
org.apache.hadoop.hdfs.server.namenode.FsImageProto$SnapshotDiffSection$FileDiff$Builder	setName	name_	C	org.apache.hadoop.thirdparty.protobuf.ByteString	0	org.apache.hadoop.hdfs.server.namenode.FsImageProto$SnapshotDiffSection$FileDiff$Builder:setName(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.server.namenode.INodeFile	setBlocks	blocks	C	org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo	1	org.apache.hadoop.hdfs.server.namenode.INodeFile:setBlocks(org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo[])
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$RemoveCacheDirectiveInfoOp	setId	id	J	long	0	org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$RemoveCacheDirectiveInfoOp:setId(long)
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$RenewDelegationTokenOp	setDelegationTokenIdentifier	token	C	org.apache.hadoop.hdfs.security.token.delegation.DelegationTokenIdentifier	0	org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$RenewDelegationTokenOp:setDelegationTokenIdentifier(org.apache.hadoop.hdfs.security.token.delegation.DelegationTokenIdentifier)
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$RenewDelegationTokenOp	setExpiryTime	expiryTime	J	long	0	org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$RenewDelegationTokenOp:setExpiryTime(long)
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$RollingUpgradeOp	setTime	time	J	long	0	org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$RollingUpgradeOp:setTime(long)
org.apache.hadoop.hdfs.server.namenode.FsImageProto$StringTableSection$Builder	setNumEntry	numEntry_	J	int	0	org.apache.hadoop.hdfs.server.namenode.FsImageProto$StringTableSection$Builder:setNumEntry(int)
org.apache.hadoop.hdfs.server.namenode.FsImageProto$StringTableSection$Builder	setMaskBits	maskBits_	J	int	0	org.apache.hadoop.hdfs.server.namenode.FsImageProto$StringTableSection$Builder:setMaskBits(int)
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$DisallowSnapshotOp	setSnapshotRoot	snapshotRoot	J	java.lang.String	0	org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$DisallowSnapshotOp:setSnapshotRoot(java.lang.String)
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$CreateSnapshotOp	setSnapshotName	snapshotName	J	java.lang.String	0	org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$CreateSnapshotOp:setSnapshotName(java.lang.String)
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$CreateSnapshotOp	setSnapshotRoot	snapshotRoot	J	java.lang.String	0	org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$CreateSnapshotOp:setSnapshotRoot(java.lang.String)
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$CreateSnapshotOp	setSnapshotMTime	mtime	J	long	0	org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$CreateSnapshotOp:setSnapshotMTime(long)
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$AddErasureCodingPolicyOp	setErasureCodingPolicy	ecPolicy	C	org.apache.hadoop.hdfs.protocol.ErasureCodingPolicy	0	org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$AddErasureCodingPolicyOp:setErasureCodingPolicy(org.apache.hadoop.hdfs.protocol.ErasureCodingPolicy)
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$RenameSnapshotOp	setSnapshotOldName	snapshotOldName	J	java.lang.String	0	org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$RenameSnapshotOp:setSnapshotOldName(java.lang.String)
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$RenameSnapshotOp	setSnapshotNewName	snapshotNewName	J	java.lang.String	0	org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$RenameSnapshotOp:setSnapshotNewName(java.lang.String)
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$RenameSnapshotOp	setSnapshotRoot	snapshotRoot	J	java.lang.String	0	org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$RenameSnapshotOp:setSnapshotRoot(java.lang.String)
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$RenameSnapshotOp	setSnapshotMTime	mtime	J	long	0	org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$RenameSnapshotOp:setSnapshotMTime(long)
org.apache.hadoop.hdfs.server.namenode.INodeWithAdditionalFields	setNext	next	C	org.apache.hadoop.util.LightWeightGSet$LinkedElement	0	org.apache.hadoop.hdfs.server.namenode.INodeWithAdditionalFields:setNext(org.apache.hadoop.util.LightWeightGSet$LinkedElement)
org.apache.hadoop.hdfs.server.namenode.INodeWithAdditionalFields	setLocalName	name	J	byte	1	org.apache.hadoop.hdfs.server.namenode.INodeWithAdditionalFields:setLocalName(byte[])
org.apache.hadoop.hdfs.server.namenode.INodeWithAdditionalFields	setModificationTime	modificationTime	J	long	0	org.apache.hadoop.hdfs.server.namenode.INodeWithAdditionalFields:setModificationTime(long)
org.apache.hadoop.hdfs.server.namenode.INodeWithAdditionalFields	setAccessTime	accessTime	J	long	0	org.apache.hadoop.hdfs.server.namenode.INodeWithAdditionalFields:setAccessTime(long)
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$AddBlockOp	setPath	path	J	java.lang.String	0	org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$AddBlockOp:setPath(java.lang.String)
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$AddBlockOp	setPenultimateBlock	penultimateBlock	C	org.apache.hadoop.hdfs.protocol.Block	0	org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$AddBlockOp:setPenultimateBlock(org.apache.hadoop.hdfs.protocol.Block)
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$AddBlockOp	setLastBlock	lastBlock	C	org.apache.hadoop.hdfs.protocol.Block	0	org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$AddBlockOp:setLastBlock(org.apache.hadoop.hdfs.protocol.Block)
org.apache.hadoop.hdfs.server.namenode.FSDirectory	setPosixAclInheritanceEnabled	posixAclInheritanceEnabled	J	boolean	0	org.apache.hadoop.hdfs.server.namenode.FSDirectory:setPosixAclInheritanceEnabled(boolean)
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$DeleteSnapshotOp	setSnapshotName	snapshotName	J	java.lang.String	0	org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$DeleteSnapshotOp:setSnapshotName(java.lang.String)
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$DeleteSnapshotOp	setSnapshotRoot	snapshotRoot	J	java.lang.String	0	org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$DeleteSnapshotOp:setSnapshotRoot(java.lang.String)
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$DeleteSnapshotOp	setSnapshotMTime	mtime	J	long	0	org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$DeleteSnapshotOp:setSnapshotMTime(long)
org.apache.hadoop.hdfs.server.namenode.FsImageProto$SecretManagerSection$Builder	setCurrentId	currentId_	J	int	0	org.apache.hadoop.hdfs.server.namenode.FsImageProto$SecretManagerSection$Builder:setCurrentId(int)
org.apache.hadoop.hdfs.server.namenode.FsImageProto$SecretManagerSection$Builder	setTokenSequenceNumber	tokenSequenceNumber_	J	int	0	org.apache.hadoop.hdfs.server.namenode.FsImageProto$SecretManagerSection$Builder:setTokenSequenceNumber(int)
org.apache.hadoop.hdfs.server.namenode.FsImageProto$SecretManagerSection$Builder	setNumKeys	numKeys_	J	int	0	org.apache.hadoop.hdfs.server.namenode.FsImageProto$SecretManagerSection$Builder:setNumKeys(int)
org.apache.hadoop.hdfs.server.namenode.FsImageProto$SecretManagerSection$Builder	setNumTokens	numTokens_	J	int	0	org.apache.hadoop.hdfs.server.namenode.FsImageProto$SecretManagerSection$Builder:setNumTokens(int)
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$SetQuotaByStorageTypeOp	setSource	src	J	java.lang.String	0	org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$SetQuotaByStorageTypeOp:setSource(java.lang.String)
org.apache.hadoop.hdfs.server.namenode.QuotaByStorageTypeEntry$Builder	setStorageType	type	C	org.apache.hadoop.fs.StorageType	0	org.apache.hadoop.hdfs.server.namenode.QuotaByStorageTypeEntry$Builder:setStorageType(org.apache.hadoop.fs.StorageType)
org.apache.hadoop.hdfs.server.namenode.QuotaByStorageTypeEntry$Builder	setQuota	quota	J	long	0	org.apache.hadoop.hdfs.server.namenode.QuotaByStorageTypeEntry$Builder:setQuota(long)
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$SymlinkOp	setId	inodeId	J	long	0	org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$SymlinkOp:setId(long)
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$SymlinkOp	setPath	path	J	java.lang.String	0	org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$SymlinkOp:setPath(java.lang.String)
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$SymlinkOp	setValue	value	J	java.lang.String	0	org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$SymlinkOp:setValue(java.lang.String)
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$SymlinkOp	setModificationTime	mtime	J	long	0	org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$SymlinkOp:setModificationTime(long)
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$SymlinkOp	setAccessTime	atime	J	long	0	org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$SymlinkOp:setAccessTime(long)
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$SymlinkOp	setPermissionStatus	permissionStatus	C	org.apache.hadoop.fs.permission.PermissionStatus	0	org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$SymlinkOp:setPermissionStatus(org.apache.hadoop.fs.permission.PermissionStatus)
org.apache.hadoop.hdfs.server.namenode.FsImageProto$SnapshotSection$Snapshot$Builder	setSnapshotId	snapshotId_	J	int	0	org.apache.hadoop.hdfs.server.namenode.FsImageProto$SnapshotSection$Snapshot$Builder:setSnapshotId(int)
org.apache.hadoop.hdfs.server.namenode.CachedBlock	setNext	nextElement	C	org.apache.hadoop.util.LightWeightGSet$LinkedElement	0	org.apache.hadoop.hdfs.server.namenode.CachedBlock:setNext(org.apache.hadoop.util.LightWeightGSet$LinkedElement)
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$AddCloseOp	setInodeId	inodeId	J	long	0	org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$AddCloseOp:setInodeId(long)
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$AddCloseOp	setPath	path	J	java.lang.String	0	org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$AddCloseOp:setPath(java.lang.String)
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$AddCloseOp	setReplication	replication	J	short	0	org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$AddCloseOp:setReplication(short)
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$AddCloseOp	setModificationTime	mtime	J	long	0	org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$AddCloseOp:setModificationTime(long)
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$AddCloseOp	setAccessTime	atime	J	long	0	org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$AddCloseOp:setAccessTime(long)
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$AddCloseOp	setBlockSize	blockSize	J	long	0	org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$AddCloseOp:setBlockSize(long)
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$AddCloseOp	setBlocks	blocks	C	org.apache.hadoop.hdfs.protocol.Block	1	org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$AddCloseOp:setBlocks(org.apache.hadoop.hdfs.protocol.Block[])
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$AddCloseOp	setPermissionStatus	permissions	C	org.apache.hadoop.fs.permission.PermissionStatus	0	org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$AddCloseOp:setPermissionStatus(org.apache.hadoop.fs.permission.PermissionStatus)
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$AddCloseOp	setAclEntries	aclEntries	GC	java.util.List	0	org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$AddCloseOp:setAclEntries(java.util.List)
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$AddCloseOp	setXAttrs	xAttrs	GC	java.util.List	0	org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$AddCloseOp:setXAttrs(java.util.List)
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$AddCloseOp	setClientName	clientName	J	java.lang.String	0	org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$AddCloseOp:setClientName(java.lang.String)
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$AddCloseOp	setClientMachine	clientMachine	J	java.lang.String	0	org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$AddCloseOp:setClientMachine(java.lang.String)
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$AddCloseOp	setOverwrite	overwrite	J	boolean	0	org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$AddCloseOp:setOverwrite(boolean)
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$AddCloseOp	setStoragePolicyId	storagePolicyId	J	byte	0	org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$AddCloseOp:setStoragePolicyId(byte)
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$AddCloseOp	setErasureCodingPolicyId	erasureCodingPolicyId	J	byte	0	org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$AddCloseOp:setErasureCodingPolicyId(byte)
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$SetGenstampV2Op	setGenerationStamp	genStampV2	J	long	0	org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$SetGenstampV2Op:setGenerationStamp(long)
org.apache.hadoop.hdfs.server.namenode.NameNodeResourceChecker	setVolumes	volumes	GC	java.util.Map	0	org.apache.hadoop.hdfs.server.namenode.NameNodeResourceChecker:setVolumes(java.util.Map)
org.apache.hadoop.hdfs.server.namenode.NameNodeResourceChecker	setMinimumReduntdantVolumes	minimumRedundantVolumes	J	int	0	org.apache.hadoop.hdfs.server.namenode.NameNodeResourceChecker:setMinimumReduntdantVolumes(int)
org.apache.hadoop.hdfs.server.namenode.ha.proto.HAZKInfoProtos$ActiveNodeInfo$Builder	setNameserviceId	nameserviceId_	J	java.lang.Object	0	org.apache.hadoop.hdfs.server.namenode.ha.proto.HAZKInfoProtos$ActiveNodeInfo$Builder:setNameserviceId(java.lang.String)
org.apache.hadoop.hdfs.server.namenode.ha.proto.HAZKInfoProtos$ActiveNodeInfo$Builder	setNameserviceIdBytes	nameserviceId_	J	java.lang.Object	0	org.apache.hadoop.hdfs.server.namenode.ha.proto.HAZKInfoProtos$ActiveNodeInfo$Builder:setNameserviceIdBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.server.namenode.ha.proto.HAZKInfoProtos$ActiveNodeInfo$Builder	setNamenodeId	namenodeId_	J	java.lang.Object	0	org.apache.hadoop.hdfs.server.namenode.ha.proto.HAZKInfoProtos$ActiveNodeInfo$Builder:setNamenodeId(java.lang.String)
org.apache.hadoop.hdfs.server.namenode.ha.proto.HAZKInfoProtos$ActiveNodeInfo$Builder	setNamenodeIdBytes	namenodeId_	J	java.lang.Object	0	org.apache.hadoop.hdfs.server.namenode.ha.proto.HAZKInfoProtos$ActiveNodeInfo$Builder:setNamenodeIdBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.server.namenode.ha.proto.HAZKInfoProtos$ActiveNodeInfo$Builder	setHostname	hostname_	J	java.lang.Object	0	org.apache.hadoop.hdfs.server.namenode.ha.proto.HAZKInfoProtos$ActiveNodeInfo$Builder:setHostname(java.lang.String)
org.apache.hadoop.hdfs.server.namenode.ha.proto.HAZKInfoProtos$ActiveNodeInfo$Builder	setHostnameBytes	hostname_	J	java.lang.Object	0	org.apache.hadoop.hdfs.server.namenode.ha.proto.HAZKInfoProtos$ActiveNodeInfo$Builder:setHostnameBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.server.namenode.ha.proto.HAZKInfoProtos$ActiveNodeInfo$Builder	setPort	port_	J	int	0	org.apache.hadoop.hdfs.server.namenode.ha.proto.HAZKInfoProtos$ActiveNodeInfo$Builder:setPort(int)
org.apache.hadoop.hdfs.server.namenode.ha.proto.HAZKInfoProtos$ActiveNodeInfo$Builder	setZkfcPort	zkfcPort_	J	int	0	org.apache.hadoop.hdfs.server.namenode.ha.proto.HAZKInfoProtos$ActiveNodeInfo$Builder:setZkfcPort(int)
org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread	setShouldRun	shouldRun	J	boolean	0	org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread:setShouldRun(boolean)
org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer	setEditLog	editLog	C	org.apache.hadoop.hdfs.server.namenode.FSEditLog	0	org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer:setEditLog(org.apache.hadoop.hdfs.server.namenode.FSEditLog)
org.apache.hadoop.hdfs.server.namenode.ha.StandbyCheckpointer$CheckpointerThread	setShouldRun	shouldRun	J	boolean	0	org.apache.hadoop.hdfs.server.namenode.ha.StandbyCheckpointer$CheckpointerThread:setShouldRun(boolean)
org.apache.hadoop.hdfs.server.namenode.ha.RemoteNameNodeInfo	setIpcAddress	ipcAddress	J	java.net.InetSocketAddress	0	org.apache.hadoop.hdfs.server.namenode.ha.RemoteNameNodeInfo:setIpcAddress(java.net.InetSocketAddress)
org.apache.hadoop.hdfs.server.namenode.ha.StandbyCheckpointer$CheckpointReceiverEntry	setLastUploadTime	lastUploadTime	J	long	0	org.apache.hadoop.hdfs.server.namenode.ha.StandbyCheckpointer$CheckpointReceiverEntry:setLastUploadTime(long)
org.apache.hadoop.hdfs.server.namenode.ha.StandbyCheckpointer$CheckpointReceiverEntry	setIsPrimary	isPrimary	J	boolean	0	org.apache.hadoop.hdfs.server.namenode.ha.StandbyCheckpointer$CheckpointReceiverEntry:setIsPrimary(boolean)
org.apache.hadoop.hdfs.server.namenode.ha.BootstrapStandby	setConf	conf	C	org.apache.hadoop.conf.Configuration	0	org.apache.hadoop.hdfs.server.namenode.ha.BootstrapStandby:setConf(org.apache.hadoop.conf.Configuration)
org.apache.hadoop.hdfs.server.namenode.ha.NameNodeHAProxyFactory	setAlignmentContext	alignmentContext	C	org.apache.hadoop.ipc.AlignmentContext	0	org.apache.hadoop.hdfs.server.namenode.ha.NameNodeHAProxyFactory:setAlignmentContext(org.apache.hadoop.ipc.AlignmentContext)
org.apache.hadoop.hdfs.server.namenode.QuotaCounts	setTypeSpaces	tsCounts	GC	org.apache.hadoop.hdfs.util.EnumCounters	0	org.apache.hadoop.hdfs.server.namenode.QuotaCounts:setTypeSpaces(org.apache.hadoop.hdfs.util.EnumCounters)
org.apache.hadoop.hdfs.server.namenode.FsImageProto$CacheManagerSection$Builder	setNextDirectiveId	nextDirectiveId_	J	long	0	org.apache.hadoop.hdfs.server.namenode.FsImageProto$CacheManagerSection$Builder:setNextDirectiveId(long)
org.apache.hadoop.hdfs.server.namenode.FsImageProto$CacheManagerSection$Builder	setNumPools	numPools_	J	int	0	org.apache.hadoop.hdfs.server.namenode.FsImageProto$CacheManagerSection$Builder:setNumPools(int)
org.apache.hadoop.hdfs.server.namenode.FsImageProto$CacheManagerSection$Builder	setNumDirectives	numDirectives_	J	int	0	org.apache.hadoop.hdfs.server.namenode.FsImageProto$CacheManagerSection$Builder:setNumDirectives(int)
org.apache.hadoop.hdfs.server.namenode.DefaultAuditLogger	setCallerContextEnabled	isCallerContextEnabled	J	boolean	0	org.apache.hadoop.hdfs.server.namenode.DefaultAuditLogger:setCallerContextEnabled(boolean)
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$MkdirOp	setInodeId	inodeId	J	long	0	org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$MkdirOp:setInodeId(long)
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$MkdirOp	setPath	path	J	java.lang.String	0	org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$MkdirOp:setPath(java.lang.String)
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$MkdirOp	setTimestamp	timestamp	J	long	0	org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$MkdirOp:setTimestamp(long)
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$MkdirOp	setPermissionStatus	permissions	C	org.apache.hadoop.fs.permission.PermissionStatus	0	org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$MkdirOp:setPermissionStatus(org.apache.hadoop.fs.permission.PermissionStatus)
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$MkdirOp	setAclEntries	aclEntries	GC	java.util.List	0	org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$MkdirOp:setAclEntries(java.util.List)
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$MkdirOp	setXAttrs	xAttrs	GC	java.util.List	0	org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$MkdirOp:setXAttrs(java.util.List)
org.apache.hadoop.hdfs.server.balancer.Dispatcher$Allocator	setLotSize	lotSize	J	int	0	org.apache.hadoop.hdfs.server.balancer.Dispatcher$Allocator:setLotSize(int)
org.apache.hadoop.hdfs.server.balancer.Dispatcher$DBlockStriped	setIndices	indices	J	byte	1	org.apache.hadoop.hdfs.server.balancer.Dispatcher$DBlockStriped:setIndices(byte[])
org.apache.hadoop.hdfs.server.balancer.BalancerParameters$Builder	setBalancingPolicy	policy	C	org.apache.hadoop.hdfs.server.balancer.BalancingPolicy	0	org.apache.hadoop.hdfs.server.balancer.BalancerParameters$Builder:setBalancingPolicy(org.apache.hadoop.hdfs.server.balancer.BalancingPolicy)
org.apache.hadoop.hdfs.server.balancer.BalancerParameters$Builder	setThreshold	threshold	J	double	0	org.apache.hadoop.hdfs.server.balancer.BalancerParameters$Builder:setThreshold(double)
org.apache.hadoop.hdfs.server.balancer.BalancerParameters$Builder	setMaxIdleIteration	maxIdleIteration	J	int	0	org.apache.hadoop.hdfs.server.balancer.BalancerParameters$Builder:setMaxIdleIteration(int)
org.apache.hadoop.hdfs.server.balancer.BalancerParameters$Builder	setExcludedNodes	excludedNodes	GJ	java.util.Set	0	org.apache.hadoop.hdfs.server.balancer.BalancerParameters$Builder:setExcludedNodes(java.util.Set)
org.apache.hadoop.hdfs.server.balancer.BalancerParameters$Builder	setIncludedNodes	includedNodes	GJ	java.util.Set	0	org.apache.hadoop.hdfs.server.balancer.BalancerParameters$Builder:setIncludedNodes(java.util.Set)
org.apache.hadoop.hdfs.server.balancer.BalancerParameters$Builder	setSourceNodes	sourceNodes	GJ	java.util.Set	0	org.apache.hadoop.hdfs.server.balancer.BalancerParameters$Builder:setSourceNodes(java.util.Set)
org.apache.hadoop.hdfs.server.balancer.BalancerParameters$Builder	setBlockpools	blockpools	GJ	java.util.Set	0	org.apache.hadoop.hdfs.server.balancer.BalancerParameters$Builder:setBlockpools(java.util.Set)
org.apache.hadoop.hdfs.server.balancer.BalancerParameters$Builder	setRunDuringUpgrade	runDuringUpgrade	J	boolean	0	org.apache.hadoop.hdfs.server.balancer.BalancerParameters$Builder:setRunDuringUpgrade(boolean)
org.apache.hadoop.hdfs.server.balancer.BalancerParameters$Builder	setRunAsService	runAsService	J	boolean	0	org.apache.hadoop.hdfs.server.balancer.BalancerParameters$Builder:setRunAsService(boolean)
org.apache.hadoop.hdfs.server.protocol.ReceivedDeletedBlockInfo	setBlock	block	C	org.apache.hadoop.hdfs.protocol.Block	0	org.apache.hadoop.hdfs.server.protocol.ReceivedDeletedBlockInfo:setBlock(org.apache.hadoop.hdfs.protocol.Block)
org.apache.hadoop.hdfs.server.protocol.ReceivedDeletedBlockInfo	setDelHints	delHints	J	java.lang.String	0	org.apache.hadoop.hdfs.server.protocol.ReceivedDeletedBlockInfo:setDelHints(java.lang.String)
org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration	setExportedKeys	exportedKeys	C	org.apache.hadoop.hdfs.security.token.block.ExportedBlockKeys	0	org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration:setExportedKeys(org.apache.hadoop.hdfs.security.token.block.ExportedBlockKeys)
org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration	setNamespaceInfo	nsInfo	C	org.apache.hadoop.hdfs.server.protocol.NamespaceInfo	0	org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration:setNamespaceInfo(org.apache.hadoop.hdfs.server.protocol.NamespaceInfo)
org.apache.hadoop.hdfs.server.protocol.NamespaceInfo	setCapabilities	capabilities	J	long	0	org.apache.hadoop.hdfs.server.protocol.NamespaceInfo:setCapabilities(long)
org.apache.hadoop.hdfs.server.protocol.NamespaceInfo	setState	state	C	org.apache.hadoop.ha.HAServiceProtocol$HAServiceState	0	org.apache.hadoop.hdfs.server.protocol.NamespaceInfo:setState(org.apache.hadoop.ha.HAServiceProtocol$HAServiceState)
org.apache.hadoop.hdfs.server.protocol.NamespaceInfo	setBlockPoolID	blockPoolID	J	java.lang.String	0	org.apache.hadoop.hdfs.server.protocol.NamespaceInfo:setBlockPoolID(java.lang.String)
org.apache.hadoop.hdfs.server.aliasmap.InMemoryAliasMap	setConf	conf	C	org.apache.hadoop.conf.Configuration	0	org.apache.hadoop.hdfs.server.aliasmap.InMemoryAliasMap:setConf(org.apache.hadoop.conf.Configuration)
org.apache.hadoop.hdfs.server.aliasmap.InMemoryLevelDBAliasMapServer	setConf	conf	C	org.apache.hadoop.conf.Configuration	0	org.apache.hadoop.hdfs.server.aliasmap.InMemoryLevelDBAliasMapServer:setConf(org.apache.hadoop.conf.Configuration)
org.apache.hadoop.hdfs.security.token.block.BlockTokenSecretManager	setBlockPoolId	blockPoolId	J	java.lang.String	0	org.apache.hadoop.hdfs.security.token.block.BlockTokenSecretManager:setBlockPoolId(java.lang.String)
org.apache.hadoop.hdfs.security.token.block.BlockTokenSecretManager	setTokenLifetime	tokenLifetime	J	long	0	org.apache.hadoop.hdfs.security.token.block.BlockTokenSecretManager:setTokenLifetime(long)
org.apache.hadoop.hdfs.security.token.block.BlockTokenSecretManager	setKeyUpdateIntervalForTesting	keyUpdateInterval	J	long	0	org.apache.hadoop.hdfs.security.token.block.BlockTokenSecretManager:setKeyUpdateIntervalForTesting(long)
org.apache.hadoop.hdfs.util.PersistentLongFile	set	value	J	long	0	org.apache.hadoop.hdfs.util.PersistentLongFile:set(long)
org.apache.hadoop.hdfs.util.XMLUtils$Stanza	setValue	value	J	java.lang.String	0	org.apache.hadoop.hdfs.util.XMLUtils$Stanza:setValue(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$BlockIdCommandProto$Builder	setBlockPoolId	blockPoolId_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$BlockIdCommandProto$Builder:setBlockPoolId(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$BlockIdCommandProto$Builder	setBlockPoolIdBytes	blockPoolId_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$BlockIdCommandProto$Builder:setBlockPoolIdBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$BlockReceivedAndDeletedRequestProto$Builder	setBlockPoolId	blockPoolId_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$BlockReceivedAndDeletedRequestProto$Builder:setBlockPoolId(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$BlockReceivedAndDeletedRequestProto$Builder	setBlockPoolIdBytes	blockPoolId_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$BlockReceivedAndDeletedRequestProto$Builder:setBlockPoolIdBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$HeartbeatRequestProto$Builder	setXmitsInProgress	xmitsInProgress_	J	int	0	org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$HeartbeatRequestProto$Builder:setXmitsInProgress(int)
org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$HeartbeatRequestProto$Builder	setXceiverCount	xceiverCount_	J	int	0	org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$HeartbeatRequestProto$Builder:setXceiverCount(int)
org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$HeartbeatRequestProto$Builder	setFailedVolumes	failedVolumes_	J	int	0	org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$HeartbeatRequestProto$Builder:setFailedVolumes(int)
org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$HeartbeatRequestProto$Builder	setCacheCapacity	cacheCapacity_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$HeartbeatRequestProto$Builder:setCacheCapacity(long)
org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$HeartbeatRequestProto$Builder	setCacheUsed	cacheUsed_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$HeartbeatRequestProto$Builder:setCacheUsed(long)
org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$HeartbeatRequestProto$Builder	setRequestFullBlockReportLease	requestFullBlockReportLease_	J	boolean	0	org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$HeartbeatRequestProto$Builder:setRequestFullBlockReportLease(boolean)
org.apache.hadoop.hdfs.protocol.proto.AliasMapProtocolProtos$BlockPoolResponseProto$Builder	setBlockPoolId	blockPoolId_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.AliasMapProtocolProtos$BlockPoolResponseProto$Builder:setBlockPoolId(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.AliasMapProtocolProtos$BlockPoolResponseProto$Builder	setBlockPoolIdBytes	blockPoolId_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.AliasMapProtocolProtos$BlockPoolResponseProto$Builder:setBlockPoolIdBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$GetEditLogManifestRequestProto$Builder	setSinceTxId	sinceTxId_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$GetEditLogManifestRequestProto$Builder:setSinceTxId(long)
org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos$NNHAStatusHeartbeatProto$Builder	setTxid	txid_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos$NNHAStatusHeartbeatProto$Builder:setTxid(long)
org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$BlockReportContextProto$Builder	setTotalRpcs	totalRpcs_	J	int	0	org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$BlockReportContextProto$Builder:setTotalRpcs(int)
org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$BlockReportContextProto$Builder	setCurRpc	curRpc_	J	int	0	org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$BlockReportContextProto$Builder:setCurRpc(int)
org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$BlockReportContextProto$Builder	setId	id_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$BlockReportContextProto$Builder:setId(long)
org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$BlockReportContextProto$Builder	setLeaseId	leaseId_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$BlockReportContextProto$Builder:setLeaseId(long)
org.apache.hadoop.hdfs.protocol.proto.JournalProtocolProtos$JournalInfoProto$Builder	setClusterID	clusterID_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.JournalProtocolProtos$JournalInfoProto$Builder:setClusterID(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.JournalProtocolProtos$JournalInfoProto$Builder	setClusterIDBytes	clusterID_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.JournalProtocolProtos$JournalInfoProto$Builder:setClusterIDBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.JournalProtocolProtos$JournalInfoProto$Builder	setLayoutVersion	layoutVersion_	J	int	0	org.apache.hadoop.hdfs.protocol.proto.JournalProtocolProtos$JournalInfoProto$Builder:setLayoutVersion(int)
org.apache.hadoop.hdfs.protocol.proto.JournalProtocolProtos$JournalInfoProto$Builder	setNamespaceID	namespaceID_	J	int	0	org.apache.hadoop.hdfs.protocol.proto.JournalProtocolProtos$JournalInfoProto$Builder:setNamespaceID(int)
org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos$RecoveringBlockProto$Builder	setNewGenStamp	newGenStamp_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos$RecoveringBlockProto$Builder:setNewGenStamp(long)
org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos$RecoveringBlockProto$Builder	setBlockIndices	blockIndices_	C	org.apache.hadoop.thirdparty.protobuf.ByteString	0	org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos$RecoveringBlockProto$Builder:setBlockIndices(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$GetFilePathRequestProto$Builder	setFileId	fileId_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$GetFilePathRequestProto$Builder:setFileId(long)
org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos$CheckpointSignatureProto$Builder	setBlockPoolId	blockPoolId_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos$CheckpointSignatureProto$Builder:setBlockPoolId(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos$CheckpointSignatureProto$Builder	setBlockPoolIdBytes	blockPoolId_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos$CheckpointSignatureProto$Builder:setBlockPoolIdBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos$CheckpointSignatureProto$Builder	setMostRecentCheckpointTxId	mostRecentCheckpointTxId_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos$CheckpointSignatureProto$Builder:setMostRecentCheckpointTxId(long)
org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos$CheckpointSignatureProto$Builder	setCurSegmentTxId	curSegmentTxId_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos$CheckpointSignatureProto$Builder:setCurSegmentTxId(long)
org.apache.hadoop.hdfs.protocol.proto.JournalProtocolProtos$FenceRequestProto$Builder	setEpoch	epoch_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.JournalProtocolProtos$FenceRequestProto$Builder:setEpoch(long)
org.apache.hadoop.hdfs.protocol.proto.JournalProtocolProtos$FenceRequestProto$Builder	setFencerInfo	fencerInfo_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.JournalProtocolProtos$FenceRequestProto$Builder:setFencerInfo(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.JournalProtocolProtos$FenceRequestProto$Builder	setFencerInfoBytes	fencerInfo_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.JournalProtocolProtos$FenceRequestProto$Builder:setFencerInfoBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$FinalizeCommandProto$Builder	setBlockPoolId	blockPoolId_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$FinalizeCommandProto$Builder:setBlockPoolId(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$FinalizeCommandProto$Builder	setBlockPoolIdBytes	blockPoolId_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$FinalizeCommandProto$Builder:setBlockPoolIdBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.JournalProtocolProtos$FenceResponseProto$Builder	setPreviousEpoch	previousEpoch_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.JournalProtocolProtos$FenceResponseProto$Builder:setPreviousEpoch(long)
org.apache.hadoop.hdfs.protocol.proto.JournalProtocolProtos$FenceResponseProto$Builder	setLastTransactionId	lastTransactionId_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.JournalProtocolProtos$FenceResponseProto$Builder:setLastTransactionId(long)
org.apache.hadoop.hdfs.protocol.proto.JournalProtocolProtos$FenceResponseProto$Builder	setInSync	inSync_	J	boolean	0	org.apache.hadoop.hdfs.protocol.proto.JournalProtocolProtos$FenceResponseProto$Builder:setInSync(boolean)
org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$SlowPeerReportProto$Builder	setDataNodeId	dataNodeId_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$SlowPeerReportProto$Builder:setDataNodeId(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$SlowPeerReportProto$Builder	setDataNodeIdBytes	dataNodeId_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$SlowPeerReportProto$Builder:setDataNodeIdBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$SlowPeerReportProto$Builder	setAggregateLatency	aggregateLatency_	J	double	0	org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$SlowPeerReportProto$Builder:setAggregateLatency(double)
org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$SlowPeerReportProto$Builder	setMedian	median_	J	double	0	org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$SlowPeerReportProto$Builder:setMedian(double)
org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$SlowPeerReportProto$Builder	setMad	mad_	J	double	0	org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$SlowPeerReportProto$Builder:setMad(double)
org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$SlowPeerReportProto$Builder	setUpperLimitLatency	upperLimitLatency_	J	double	0	org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$SlowPeerReportProto$Builder:setUpperLimitLatency(double)
org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos$BlockWithLocationsProto$Builder	setIndices	indices_	C	org.apache.hadoop.thirdparty.protobuf.ByteString	0	org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos$BlockWithLocationsProto$Builder:setIndices(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos$BlockWithLocationsProto$Builder	setDataBlockNum	dataBlockNum_	J	int	0	org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos$BlockWithLocationsProto$Builder:setDataBlockNum(int)
org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos$BlockWithLocationsProto$Builder	setCellSize	cellSize_	J	int	0	org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos$BlockWithLocationsProto$Builder:setCellSize(int)
org.apache.hadoop.hdfs.protocol.proto.InterDatanodeProtocolProtos$UpdateReplicaUnderRecoveryRequestProto$Builder	setRecoveryId	recoveryId_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.InterDatanodeProtocolProtos$UpdateReplicaUnderRecoveryRequestProto$Builder:setRecoveryId(long)
org.apache.hadoop.hdfs.protocol.proto.InterDatanodeProtocolProtos$UpdateReplicaUnderRecoveryRequestProto$Builder	setNewLength	newLength_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.InterDatanodeProtocolProtos$UpdateReplicaUnderRecoveryRequestProto$Builder:setNewLength(long)
org.apache.hadoop.hdfs.protocol.proto.InterDatanodeProtocolProtos$UpdateReplicaUnderRecoveryRequestProto$Builder	setNewBlockId	newBlockId_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.InterDatanodeProtocolProtos$UpdateReplicaUnderRecoveryRequestProto$Builder:setNewBlockId(long)
org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$HeartbeatResponseProto$Builder	setFullBlockReportLeaseId	fullBlockReportLeaseId_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$HeartbeatResponseProto$Builder:setFullBlockReportLeaseId(long)
org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$GetNextSPSPathResponseProto$Builder	setSpsPath	spsPath_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$GetNextSPSPathResponseProto$Builder:setSpsPath(long)
org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$GetFilePathResponseProto$Builder	setSrcPath	srcPath_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$GetFilePathResponseProto$Builder:setSrcPath(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$GetFilePathResponseProto$Builder	setSrcPathBytes	srcPath_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$GetFilePathResponseProto$Builder:setSrcPathBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$BalancerBandwidthCommandProto$Builder	setBandwidth	bandwidth_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$BalancerBandwidthCommandProto$Builder:setBandwidth(long)
org.apache.hadoop.hdfs.protocol.proto.JournalProtocolProtos$StartLogSegmentRequestProto$Builder	setTxid	txid_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.JournalProtocolProtos$StartLogSegmentRequestProto$Builder:setTxid(long)
org.apache.hadoop.hdfs.protocol.proto.JournalProtocolProtos$StartLogSegmentRequestProto$Builder	setEpoch	epoch_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.JournalProtocolProtos$StartLogSegmentRequestProto$Builder:setEpoch(long)
org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos$NamenodeCommandProto$Builder	setAction	action_	J	int	0	org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos$NamenodeCommandProto$Builder:setAction(int)
org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$StorageReceivedDeletedBlocksProto$Builder	setStorageUuid	storageUuid_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$StorageReceivedDeletedBlocksProto$Builder:setStorageUuid(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$StorageReceivedDeletedBlocksProto$Builder	setStorageUuidBytes	storageUuid_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$StorageReceivedDeletedBlocksProto$Builder:setStorageUuidBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos$ExportedBlockKeysProto$Builder	setIsBlockTokenEnabled	isBlockTokenEnabled_	J	boolean	0	org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos$ExportedBlockKeysProto$Builder:setIsBlockTokenEnabled(boolean)
org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos$ExportedBlockKeysProto$Builder	setKeyUpdateInterval	keyUpdateInterval_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos$ExportedBlockKeysProto$Builder:setKeyUpdateInterval(long)
org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos$ExportedBlockKeysProto$Builder	setTokenLifeTime	tokenLifeTime_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos$ExportedBlockKeysProto$Builder:setTokenLifeTime(long)
org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$ErrorReportRequestProto$Builder	setErrorCode	errorCode_	J	int	0	org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$ErrorReportRequestProto$Builder:setErrorCode(int)
org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$ErrorReportRequestProto$Builder	setMsg	msg_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$ErrorReportRequestProto$Builder:setMsg(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$ErrorReportRequestProto$Builder	setMsgBytes	msg_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$ErrorReportRequestProto$Builder:setMsgBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$CacheReportRequestProto$Builder	setBlockPoolId	blockPoolId_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$CacheReportRequestProto$Builder:setBlockPoolId(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$CacheReportRequestProto$Builder	setBlockPoolIdBytes	blockPoolId_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$CacheReportRequestProto$Builder:setBlockPoolIdBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.EditLogProtos$AclEditLogProto$Builder	setSrc	src_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.EditLogProtos$AclEditLogProto$Builder:setSrc(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.EditLogProtos$AclEditLogProto$Builder	setSrcBytes	src_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.EditLogProtos$AclEditLogProto$Builder:setSrcBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.InterDatanodeProtocolProtos$InitReplicaRecoveryResponseProto$Builder	setReplicaFound	replicaFound_	J	boolean	0	org.apache.hadoop.hdfs.protocol.proto.InterDatanodeProtocolProtos$InitReplicaRecoveryResponseProto$Builder:setReplicaFound(boolean)
org.apache.hadoop.hdfs.protocol.proto.EditLogProtos$XAttrEditLogProto$Builder	setSrc	src_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.EditLogProtos$XAttrEditLogProto$Builder:setSrc(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.EditLogProtos$XAttrEditLogProto$Builder	setSrcBytes	src_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.EditLogProtos$XAttrEditLogProto$Builder:setSrcBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos$CheckpointCommandProto$Builder	setNeedToReturnImage	needToReturnImage_	J	boolean	0	org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos$CheckpointCommandProto$Builder:setNeedToReturnImage(boolean)
org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$BlockCommandProto$Builder	setBlockPoolId	blockPoolId_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$BlockCommandProto$Builder:setBlockPoolId(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$BlockCommandProto$Builder	setBlockPoolIdBytes	blockPoolId_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$BlockCommandProto$Builder:setBlockPoolIdBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$CommitBlockSynchronizationRequestProto$Builder	setNewGenStamp	newGenStamp_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$CommitBlockSynchronizationRequestProto$Builder:setNewGenStamp(long)
org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$CommitBlockSynchronizationRequestProto$Builder	setNewLength	newLength_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$CommitBlockSynchronizationRequestProto$Builder:setNewLength(long)
org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$CommitBlockSynchronizationRequestProto$Builder	setCloseFile	closeFile_	J	boolean	0	org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$CommitBlockSynchronizationRequestProto$Builder:setCloseFile(boolean)
org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$CommitBlockSynchronizationRequestProto$Builder	setDeleteBlock	deleteBlock_	J	boolean	0	org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$CommitBlockSynchronizationRequestProto$Builder:setDeleteBlock(boolean)
org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$SlowDiskReportProto$Builder	setBasePath	basePath_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$SlowDiskReportProto$Builder:setBasePath(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$SlowDiskReportProto$Builder	setBasePathBytes	basePath_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$SlowDiskReportProto$Builder:setBasePathBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$SlowDiskReportProto$Builder	setMeanMetadataOpLatency	meanMetadataOpLatency_	J	double	0	org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$SlowDiskReportProto$Builder:setMeanMetadataOpLatency(double)
org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$SlowDiskReportProto$Builder	setMeanReadIoLatency	meanReadIoLatency_	J	double	0	org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$SlowDiskReportProto$Builder:setMeanReadIoLatency(double)
org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$SlowDiskReportProto$Builder	setMeanWriteIoLatency	meanWriteIoLatency_	J	double	0	org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$SlowDiskReportProto$Builder:setMeanWriteIoLatency(double)
org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$ReceivedDeletedBlockInfoProto$Builder	setDeleteHint	deleteHint_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$ReceivedDeletedBlockInfoProto$Builder:setDeleteHint(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$ReceivedDeletedBlockInfoProto$Builder	setDeleteHintBytes	deleteHint_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$ReceivedDeletedBlockInfoProto$Builder:setDeleteHintBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos$RemoteEditLogProto$Builder	setStartTxId	startTxId_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos$RemoteEditLogProto$Builder:setStartTxId(long)
org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos$RemoteEditLogProto$Builder	setEndTxId	endTxId_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos$RemoteEditLogProto$Builder:setEndTxId(long)
org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos$RemoteEditLogProto$Builder	setIsInProgress	isInProgress_	J	boolean	0	org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos$RemoteEditLogProto$Builder:setIsInProgress(boolean)
org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$GetMostRecentCheckpointTxIdResponseProto$Builder	setTxId	txId_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$GetMostRecentCheckpointTxIdResponseProto$Builder:setTxId(long)
org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$VolumeFailureSummaryProto$Builder	setLastVolumeFailureDate	lastVolumeFailureDate_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$VolumeFailureSummaryProto$Builder:setLastVolumeFailureDate(long)
org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$VolumeFailureSummaryProto$Builder	setEstimatedCapacityLostTotal	estimatedCapacityLostTotal_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$VolumeFailureSummaryProto$Builder:setEstimatedCapacityLostTotal(long)
org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$ErrorReportRequestProto$Builder	setErrorCode	errorCode_	J	int	0	org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$ErrorReportRequestProto$Builder:setErrorCode(int)
org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$ErrorReportRequestProto$Builder	setMsg	msg_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$ErrorReportRequestProto$Builder:setMsg(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$ErrorReportRequestProto$Builder	setMsgBytes	msg_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$ErrorReportRequestProto$Builder:setMsgBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.InterDatanodeProtocolProtos$UpdateReplicaUnderRecoveryResponseProto$Builder	setStorageUuid	storageUuid_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.InterDatanodeProtocolProtos$UpdateReplicaUnderRecoveryResponseProto$Builder:setStorageUuid(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.InterDatanodeProtocolProtos$UpdateReplicaUnderRecoveryResponseProto$Builder	setStorageUuidBytes	storageUuid_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.InterDatanodeProtocolProtos$UpdateReplicaUnderRecoveryResponseProto$Builder:setStorageUuidBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$IsUpgradeFinalizedResponseProto$Builder	setIsUpgradeFinalized	isUpgradeFinalized_	J	boolean	0	org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$IsUpgradeFinalizedResponseProto$Builder:setIsUpgradeFinalized(boolean)
org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos$RemoteEditLogManifestProto$Builder	setCommittedTxnId	committedTxnId_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos$RemoteEditLogManifestProto$Builder:setCommittedTxnId(long)
org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$DatanodeRegistrationProto$Builder	setSoftwareVersion	softwareVersion_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$DatanodeRegistrationProto$Builder:setSoftwareVersion(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$DatanodeRegistrationProto$Builder	setSoftwareVersionBytes	softwareVersion_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$DatanodeRegistrationProto$Builder:setSoftwareVersionBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos$NamespaceInfoProto$Builder	setBuildVersion	buildVersion_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos$NamespaceInfoProto$Builder:setBuildVersion(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos$NamespaceInfoProto$Builder	setBuildVersionBytes	buildVersion_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos$NamespaceInfoProto$Builder:setBuildVersionBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos$NamespaceInfoProto$Builder	setUnused	unused_	J	int	0	org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos$NamespaceInfoProto$Builder:setUnused(int)
org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos$NamespaceInfoProto$Builder	setBlockPoolID	blockPoolID_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos$NamespaceInfoProto$Builder:setBlockPoolID(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos$NamespaceInfoProto$Builder	setBlockPoolIDBytes	blockPoolID_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos$NamespaceInfoProto$Builder:setBlockPoolIDBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos$NamespaceInfoProto$Builder	setSoftwareVersion	softwareVersion_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos$NamespaceInfoProto$Builder:setSoftwareVersion(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos$NamespaceInfoProto$Builder	setSoftwareVersionBytes	softwareVersion_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos$NamespaceInfoProto$Builder:setSoftwareVersionBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos$NamespaceInfoProto$Builder	setCapabilities	capabilities_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos$NamespaceInfoProto$Builder:setCapabilities(long)
org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$GetTransactionIdResponseProto$Builder	setTxId	txId_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$GetTransactionIdResponseProto$Builder:setTxId(long)
org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos$BlockKeyProto$Builder	setKeyId	keyId_	J	int	0	org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos$BlockKeyProto$Builder:setKeyId(int)
org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos$BlockKeyProto$Builder	setExpiryDate	expiryDate_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos$BlockKeyProto$Builder:setExpiryDate(long)
org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos$BlockKeyProto$Builder	setKeyBytes	keyBytes_	C	org.apache.hadoop.thirdparty.protobuf.ByteString	0	org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos$BlockKeyProto$Builder:setKeyBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$StorageBlockReportProto$Builder	setNumberOfBlocks	numberOfBlocks_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$StorageBlockReportProto$Builder:setNumberOfBlocks(long)
org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$IsRollingUpgradeResponseProto$Builder	setIsRollingUpgrade	isRollingUpgrade_	J	boolean	0	org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$IsRollingUpgradeResponseProto$Builder:setIsRollingUpgrade(boolean)
org.apache.hadoop.hdfs.protocol.proto.JournalProtocolProtos$JournalRequestProto$Builder	setFirstTxnId	firstTxnId_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.JournalProtocolProtos$JournalRequestProto$Builder:setFirstTxnId(long)
org.apache.hadoop.hdfs.protocol.proto.JournalProtocolProtos$JournalRequestProto$Builder	setNumTxns	numTxns_	J	int	0	org.apache.hadoop.hdfs.protocol.proto.JournalProtocolProtos$JournalRequestProto$Builder:setNumTxns(int)
org.apache.hadoop.hdfs.protocol.proto.JournalProtocolProtos$JournalRequestProto$Builder	setRecords	records_	C	org.apache.hadoop.thirdparty.protobuf.ByteString	0	org.apache.hadoop.hdfs.protocol.proto.JournalProtocolProtos$JournalRequestProto$Builder:setRecords(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.JournalProtocolProtos$JournalRequestProto$Builder	setEpoch	epoch_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.JournalProtocolProtos$JournalRequestProto$Builder:setEpoch(long)
org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos$NamenodeRegistrationProto$Builder	setRpcAddress	rpcAddress_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos$NamenodeRegistrationProto$Builder:setRpcAddress(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos$NamenodeRegistrationProto$Builder	setRpcAddressBytes	rpcAddress_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos$NamenodeRegistrationProto$Builder:setRpcAddressBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos$NamenodeRegistrationProto$Builder	setHttpAddress	httpAddress_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos$NamenodeRegistrationProto$Builder:setHttpAddress(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos$NamenodeRegistrationProto$Builder	setHttpAddressBytes	httpAddress_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos$NamenodeRegistrationProto$Builder:setHttpAddressBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos$StorageInfoProto$Builder	setLayoutVersion	layoutVersion_	J	int	0	org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos$StorageInfoProto$Builder:setLayoutVersion(int)
org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos$StorageInfoProto$Builder	setNamespceID	namespceID_	J	int	0	org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos$StorageInfoProto$Builder:setNamespceID(int)
org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos$StorageInfoProto$Builder	setClusterID	clusterID_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos$StorageInfoProto$Builder:setClusterID(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos$StorageInfoProto$Builder	setClusterIDBytes	clusterID_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos$StorageInfoProto$Builder:setClusterIDBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos$StorageInfoProto$Builder	setCTime	cTime_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos$StorageInfoProto$Builder:setCTime(long)
org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$BlockReportRequestProto$Builder	setBlockPoolId	blockPoolId_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$BlockReportRequestProto$Builder:setBlockPoolId(java.lang.String)
org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$BlockReportRequestProto$Builder	setBlockPoolIdBytes	blockPoolId_	J	java.lang.Object	0	org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$BlockReportRequestProto$Builder:setBlockPoolIdBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$GetBlocksRequestProto$Builder	setSize	size_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$GetBlocksRequestProto$Builder:setSize(long)
org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$GetBlocksRequestProto$Builder	setMinBlockSize	minBlockSize_	J	long	0	org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$GetBlocksRequestProto$Builder:setMinBlockSize(long)
org.apache.hadoop.hdfs.protocol.BlockListAsLongs$BlockReportReplica	setState	state	C	org.apache.hadoop.hdfs.server.common.HdfsServerConstants$ReplicaState	0	org.apache.hadoop.hdfs.protocol.BlockListAsLongs$BlockReportReplica:setState(org.apache.hadoop.hdfs.server.common.HdfsServerConstants$ReplicaState)
org.apache.hadoop.mapred.YarnOutputFiles	setConf	conf	C	org.apache.hadoop.mapred.JobConf	0	org.apache.hadoop.mapred.YarnOutputFiles:setConf(org.apache.hadoop.conf.Configuration)
org.apache.hadoop.mapred.LocalContainerLauncher	setEncryptedSpillKey	encryptedSpillKey	J	byte	1	org.apache.hadoop.mapred.LocalContainerLauncher:setEncryptedSpillKey(byte[])
org.apache.hadoop.mapreduce.v2.app.speculate.DefaultSpeculator$TaskAttemptHistoryStatistics	setEstimatedRunTime	estimatedRunTime	J	long	0	org.apache.hadoop.mapreduce.v2.app.speculate.DefaultSpeculator$TaskAttemptHistoryStatistics:setEstimatedRunTime(long)
org.apache.hadoop.mapreduce.v2.app.speculate.DefaultSpeculator$TaskAttemptHistoryStatistics	setProgress	progress	J	float	0	org.apache.hadoop.mapreduce.v2.app.speculate.DefaultSpeculator$TaskAttemptHistoryStatistics:setProgress(float)
org.apache.hadoop.mapreduce.v2.app.TaskHeartbeatHandler$ReportTime	setLastProgress	lastProgress	J	long	0	org.apache.hadoop.mapreduce.v2.app.TaskHeartbeatHandler$ReportTime:setLastProgress(long)
org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator	setIsReduceStarted	reduceStarted	J	boolean	0	org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator:setIsReduceStarted(boolean)
org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator	setReduceResourceRequest	reduceResourceRequest	C	org.apache.hadoop.yarn.api.records.Resource	0	org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator:setReduceResourceRequest(org.apache.hadoop.yarn.api.records.Resource)
org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator	setMapResourceRequest	mapResourceRequest	C	org.apache.hadoop.yarn.api.records.Resource	0	org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator:setMapResourceRequest(org.apache.hadoop.yarn.api.records.Resource)
org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator	setShouldUnregister	shouldUnregister	J	boolean	0	org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator:setShouldUnregister(boolean)
org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator	setSignalled	isSignalled	J	boolean	0	org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator:setSignalled(boolean)
org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator$ScheduledRequests	setNumOpportunisticMapsPercent	numOpportunisticMapsPercent	J	int	0	org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator$ScheduledRequests:setNumOpportunisticMapsPercent(int)
org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl	setLocality	locality	C	org.apache.hadoop.mapreduce.v2.api.records.Locality	0	org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl:setLocality(org.apache.hadoop.mapreduce.v2.api.records.Locality)
org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl	setAvataar	avataar	C	org.apache.hadoop.mapreduce.v2.api.records.Avataar	0	org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl:setAvataar(org.apache.hadoop.mapreduce.v2.api.records.Avataar)
org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl	setTaskFailFast	failFast	J	boolean	0	org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl:setTaskFailFast(boolean)
org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl	setRescheduleNextAttempt	rescheduleNextAttempt	J	boolean	0	org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl:setRescheduleNextAttempt(boolean)
org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl	setQueueName	queueName	J	java.lang.String	0	org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl:setQueueName(java.lang.String)
org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl	setJobPriority	jobPriority	C	org.apache.hadoop.yarn.api.records.Priority	0	org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl:setJobPriority(org.apache.hadoop.yarn.api.records.Priority)
org.apache.hadoop.mapreduce.v2.app.MRAppMaster$RunningAppContext	setHistoryUrl	historyUrl	J	java.lang.String	0	org.apache.hadoop.mapreduce.v2.app.MRAppMaster$RunningAppContext:setHistoryUrl(java.lang.String)
org.apache.hadoop.mapreduce.v2.app.ClusterInfo	setMaxContainerCapability	maxContainerCapability	C	org.apache.hadoop.yarn.api.records.Resource	0	org.apache.hadoop.mapreduce.v2.app.ClusterInfo:setMaxContainerCapability(org.apache.hadoop.yarn.api.records.Resource)
org.apache.hadoop.mapreduce.v2.app.webapp.App	setJob	job	C	org.apache.hadoop.mapreduce.v2.app.job.Job	0	org.apache.hadoop.mapreduce.v2.app.webapp.App:setJob(org.apache.hadoop.mapreduce.v2.app.job.Job)
org.apache.hadoop.mapreduce.v2.app.webapp.App	setTask	task	C	org.apache.hadoop.mapreduce.v2.app.job.Task	0	org.apache.hadoop.mapreduce.v2.app.webapp.App:setTask(org.apache.hadoop.mapreduce.v2.app.job.Task)
org.apache.hadoop.mapreduce.v2.app.webapp.dao.JobTaskAttemptState	setState	state	J	java.lang.String	0	org.apache.hadoop.mapreduce.v2.app.webapp.dao.JobTaskAttemptState:setState(java.lang.String)
org.apache.hadoop.mapreduce.jobhistory.JobSummary	setJobId	jobId	C	org.apache.hadoop.mapreduce.v2.api.records.JobId	0	org.apache.hadoop.mapreduce.jobhistory.JobSummary:setJobId(org.apache.hadoop.mapreduce.v2.api.records.JobId)
org.apache.hadoop.mapreduce.jobhistory.JobSummary	setJobSubmitTime	jobSubmitTime	J	long	0	org.apache.hadoop.mapreduce.jobhistory.JobSummary:setJobSubmitTime(long)
org.apache.hadoop.mapreduce.jobhistory.JobSummary	setJobLaunchTime	jobLaunchTime	J	long	0	org.apache.hadoop.mapreduce.jobhistory.JobSummary:setJobLaunchTime(long)
org.apache.hadoop.mapreduce.jobhistory.JobSummary	setFirstMapTaskLaunchTime	firstMapTaskLaunchTime	J	long	0	org.apache.hadoop.mapreduce.jobhistory.JobSummary:setFirstMapTaskLaunchTime(long)
org.apache.hadoop.mapreduce.jobhistory.JobSummary	setFirstReduceTaskLaunchTime	firstReduceTaskLaunchTime	J	long	0	org.apache.hadoop.mapreduce.jobhistory.JobSummary:setFirstReduceTaskLaunchTime(long)
org.apache.hadoop.mapreduce.jobhistory.JobSummary	setJobFinishTime	jobFinishTime	J	long	0	org.apache.hadoop.mapreduce.jobhistory.JobSummary:setJobFinishTime(long)
org.apache.hadoop.mapreduce.jobhistory.JobSummary	setNumSucceededMaps	numSucceededMaps	J	int	0	org.apache.hadoop.mapreduce.jobhistory.JobSummary:setNumSucceededMaps(int)
org.apache.hadoop.mapreduce.jobhistory.JobSummary	setNumFailedMaps	numFailedMaps	J	int	0	org.apache.hadoop.mapreduce.jobhistory.JobSummary:setNumFailedMaps(int)
org.apache.hadoop.mapreduce.jobhistory.JobSummary	setNumKilledMaps	numKilledMaps	J	int	0	org.apache.hadoop.mapreduce.jobhistory.JobSummary:setNumKilledMaps(int)
org.apache.hadoop.mapreduce.jobhistory.JobSummary	setNumKilledReduces	numKilledReduces	J	int	0	org.apache.hadoop.mapreduce.jobhistory.JobSummary:setNumKilledReduces(int)
org.apache.hadoop.mapreduce.jobhistory.JobSummary	setResourcesPerMap	resourcesPerMap	J	int	0	org.apache.hadoop.mapreduce.jobhistory.JobSummary:setResourcesPerMap(int)
org.apache.hadoop.mapreduce.jobhistory.JobSummary	setNumSucceededReduces	numSucceededReduces	J	int	0	org.apache.hadoop.mapreduce.jobhistory.JobSummary:setNumSucceededReduces(int)
org.apache.hadoop.mapreduce.jobhistory.JobSummary	setNumFailedReduces	numFailedReduces	J	int	0	org.apache.hadoop.mapreduce.jobhistory.JobSummary:setNumFailedReduces(int)
org.apache.hadoop.mapreduce.jobhistory.JobSummary	setResourcesPerReduce	resourcesPerReduce	J	int	0	org.apache.hadoop.mapreduce.jobhistory.JobSummary:setResourcesPerReduce(int)
org.apache.hadoop.mapreduce.jobhistory.JobSummary	setUser	user	J	java.lang.String	0	org.apache.hadoop.mapreduce.jobhistory.JobSummary:setUser(java.lang.String)
org.apache.hadoop.mapreduce.jobhistory.JobSummary	setQueue	queue	J	java.lang.String	0	org.apache.hadoop.mapreduce.jobhistory.JobSummary:setQueue(java.lang.String)
org.apache.hadoop.mapreduce.jobhistory.JobSummary	setJobStatus	jobStatus	J	java.lang.String	0	org.apache.hadoop.mapreduce.jobhistory.JobSummary:setJobStatus(java.lang.String)
org.apache.hadoop.mapreduce.jobhistory.JobSummary	setMapSlotSeconds	mapSlotSeconds	J	long	0	org.apache.hadoop.mapreduce.jobhistory.JobSummary:setMapSlotSeconds(long)
org.apache.hadoop.mapreduce.jobhistory.JobSummary	setReduceSlotSeconds	reduceSlotSeconds	J	long	0	org.apache.hadoop.mapreduce.jobhistory.JobSummary:setReduceSlotSeconds(long)
org.apache.hadoop.mapreduce.jobhistory.JobSummary	setJobName	jobName	J	java.lang.String	0	org.apache.hadoop.mapreduce.jobhistory.JobSummary:setJobName(java.lang.String)
org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler	setForcejobCompletion	forceJobCompletion	J	boolean	0	org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler:setForcejobCompletion(boolean)
org.apache.hadoop.mapreduce.v2.proto.MRProtos$JobIdProto$Builder	setId	id_	J	int	0	org.apache.hadoop.mapreduce.v2.proto.MRProtos$JobIdProto$Builder:setId(int)
org.apache.hadoop.mapreduce.v2.proto.MRProtos$TaskAttemptIdProto$Builder	setId	id_	J	int	0	org.apache.hadoop.mapreduce.v2.proto.MRProtos$TaskAttemptIdProto$Builder:setId(int)
org.apache.hadoop.mapreduce.v2.proto.MRProtos$CounterGroupProto$Builder	setName	name_	J	java.lang.Object	0	org.apache.hadoop.mapreduce.v2.proto.MRProtos$CounterGroupProto$Builder:setName(java.lang.String)
org.apache.hadoop.mapreduce.v2.proto.MRProtos$CounterGroupProto$Builder	setNameBytes	name_	J	java.lang.Object	0	org.apache.hadoop.mapreduce.v2.proto.MRProtos$CounterGroupProto$Builder:setNameBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.mapreduce.v2.proto.MRProtos$CounterGroupProto$Builder	setDisplayName	displayName_	J	java.lang.Object	0	org.apache.hadoop.mapreduce.v2.proto.MRProtos$CounterGroupProto$Builder:setDisplayName(java.lang.String)
org.apache.hadoop.mapreduce.v2.proto.MRProtos$CounterGroupProto$Builder	setDisplayNameBytes	displayName_	J	java.lang.Object	0	org.apache.hadoop.mapreduce.v2.proto.MRProtos$CounterGroupProto$Builder:setDisplayNameBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.mapreduce.v2.proto.MRProtos$TaskReportProto$Builder	setProgress	progress_	J	float	0	org.apache.hadoop.mapreduce.v2.proto.MRProtos$TaskReportProto$Builder:setProgress(float)
org.apache.hadoop.mapreduce.v2.proto.MRProtos$TaskReportProto$Builder	setStartTime	startTime_	J	long	0	org.apache.hadoop.mapreduce.v2.proto.MRProtos$TaskReportProto$Builder:setStartTime(long)
org.apache.hadoop.mapreduce.v2.proto.MRProtos$TaskReportProto$Builder	setFinishTime	finishTime_	J	long	0	org.apache.hadoop.mapreduce.v2.proto.MRProtos$TaskReportProto$Builder:setFinishTime(long)
org.apache.hadoop.mapreduce.v2.proto.MRProtos$JobReportProto$Builder	setMapProgress	mapProgress_	J	float	0	org.apache.hadoop.mapreduce.v2.proto.MRProtos$JobReportProto$Builder:setMapProgress(float)
org.apache.hadoop.mapreduce.v2.proto.MRProtos$JobReportProto$Builder	setReduceProgress	reduceProgress_	J	float	0	org.apache.hadoop.mapreduce.v2.proto.MRProtos$JobReportProto$Builder:setReduceProgress(float)
org.apache.hadoop.mapreduce.v2.proto.MRProtos$JobReportProto$Builder	setCleanupProgress	cleanupProgress_	J	float	0	org.apache.hadoop.mapreduce.v2.proto.MRProtos$JobReportProto$Builder:setCleanupProgress(float)
org.apache.hadoop.mapreduce.v2.proto.MRProtos$JobReportProto$Builder	setSetupProgress	setupProgress_	J	float	0	org.apache.hadoop.mapreduce.v2.proto.MRProtos$JobReportProto$Builder:setSetupProgress(float)
org.apache.hadoop.mapreduce.v2.proto.MRProtos$JobReportProto$Builder	setStartTime	startTime_	J	long	0	org.apache.hadoop.mapreduce.v2.proto.MRProtos$JobReportProto$Builder:setStartTime(long)
org.apache.hadoop.mapreduce.v2.proto.MRProtos$JobReportProto$Builder	setFinishTime	finishTime_	J	long	0	org.apache.hadoop.mapreduce.v2.proto.MRProtos$JobReportProto$Builder:setFinishTime(long)
org.apache.hadoop.mapreduce.v2.proto.MRProtos$JobReportProto$Builder	setUser	user_	J	java.lang.Object	0	org.apache.hadoop.mapreduce.v2.proto.MRProtos$JobReportProto$Builder:setUser(java.lang.String)
org.apache.hadoop.mapreduce.v2.proto.MRProtos$JobReportProto$Builder	setUserBytes	user_	J	java.lang.Object	0	org.apache.hadoop.mapreduce.v2.proto.MRProtos$JobReportProto$Builder:setUserBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.mapreduce.v2.proto.MRProtos$JobReportProto$Builder	setJobName	jobName_	J	java.lang.Object	0	org.apache.hadoop.mapreduce.v2.proto.MRProtos$JobReportProto$Builder:setJobName(java.lang.String)
org.apache.hadoop.mapreduce.v2.proto.MRProtos$JobReportProto$Builder	setJobNameBytes	jobName_	J	java.lang.Object	0	org.apache.hadoop.mapreduce.v2.proto.MRProtos$JobReportProto$Builder:setJobNameBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.mapreduce.v2.proto.MRProtos$JobReportProto$Builder	setTrackingUrl	trackingUrl_	J	java.lang.Object	0	org.apache.hadoop.mapreduce.v2.proto.MRProtos$JobReportProto$Builder:setTrackingUrl(java.lang.String)
org.apache.hadoop.mapreduce.v2.proto.MRProtos$JobReportProto$Builder	setTrackingUrlBytes	trackingUrl_	J	java.lang.Object	0	org.apache.hadoop.mapreduce.v2.proto.MRProtos$JobReportProto$Builder:setTrackingUrlBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.mapreduce.v2.proto.MRProtos$JobReportProto$Builder	setDiagnostics	diagnostics_	J	java.lang.Object	0	org.apache.hadoop.mapreduce.v2.proto.MRProtos$JobReportProto$Builder:setDiagnostics(java.lang.String)
org.apache.hadoop.mapreduce.v2.proto.MRProtos$JobReportProto$Builder	setDiagnosticsBytes	diagnostics_	J	java.lang.Object	0	org.apache.hadoop.mapreduce.v2.proto.MRProtos$JobReportProto$Builder:setDiagnosticsBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.mapreduce.v2.proto.MRProtos$JobReportProto$Builder	setJobFile	jobFile_	J	java.lang.Object	0	org.apache.hadoop.mapreduce.v2.proto.MRProtos$JobReportProto$Builder:setJobFile(java.lang.String)
org.apache.hadoop.mapreduce.v2.proto.MRProtos$JobReportProto$Builder	setJobFileBytes	jobFile_	J	java.lang.Object	0	org.apache.hadoop.mapreduce.v2.proto.MRProtos$JobReportProto$Builder:setJobFileBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.mapreduce.v2.proto.MRProtos$JobReportProto$Builder	setSubmitTime	submitTime_	J	long	0	org.apache.hadoop.mapreduce.v2.proto.MRProtos$JobReportProto$Builder:setSubmitTime(long)
org.apache.hadoop.mapreduce.v2.proto.MRProtos$JobReportProto$Builder	setIsUber	isUber_	J	boolean	0	org.apache.hadoop.mapreduce.v2.proto.MRProtos$JobReportProto$Builder:setIsUber(boolean)
org.apache.hadoop.mapreduce.v2.proto.MRProtos$JobReportProto$Builder	setHistoryFile	historyFile_	J	java.lang.Object	0	org.apache.hadoop.mapreduce.v2.proto.MRProtos$JobReportProto$Builder:setHistoryFile(java.lang.String)
org.apache.hadoop.mapreduce.v2.proto.MRProtos$JobReportProto$Builder	setHistoryFileBytes	historyFile_	J	java.lang.Object	0	org.apache.hadoop.mapreduce.v2.proto.MRProtos$JobReportProto$Builder:setHistoryFileBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.mapreduce.v2.proto.MRProtos$CounterProto$Builder	setName	name_	J	java.lang.Object	0	org.apache.hadoop.mapreduce.v2.proto.MRProtos$CounterProto$Builder:setName(java.lang.String)
org.apache.hadoop.mapreduce.v2.proto.MRProtos$CounterProto$Builder	setNameBytes	name_	J	java.lang.Object	0	org.apache.hadoop.mapreduce.v2.proto.MRProtos$CounterProto$Builder:setNameBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.mapreduce.v2.proto.MRProtos$CounterProto$Builder	setDisplayName	displayName_	J	java.lang.Object	0	org.apache.hadoop.mapreduce.v2.proto.MRProtos$CounterProto$Builder:setDisplayName(java.lang.String)
org.apache.hadoop.mapreduce.v2.proto.MRProtos$CounterProto$Builder	setDisplayNameBytes	displayName_	J	java.lang.Object	0	org.apache.hadoop.mapreduce.v2.proto.MRProtos$CounterProto$Builder:setDisplayNameBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.mapreduce.v2.proto.MRProtos$CounterProto$Builder	setValue	value_	J	long	0	org.apache.hadoop.mapreduce.v2.proto.MRProtos$CounterProto$Builder:setValue(long)
org.apache.hadoop.mapreduce.v2.proto.MRProtos$TaskIdProto$Builder	setId	id_	J	int	0	org.apache.hadoop.mapreduce.v2.proto.MRProtos$TaskIdProto$Builder:setId(int)
org.apache.hadoop.mapreduce.v2.proto.MRProtos$StringCounterMapProto$Builder	setKey	key_	J	java.lang.Object	0	org.apache.hadoop.mapreduce.v2.proto.MRProtos$StringCounterMapProto$Builder:setKey(java.lang.String)
org.apache.hadoop.mapreduce.v2.proto.MRProtos$StringCounterMapProto$Builder	setKeyBytes	key_	J	java.lang.Object	0	org.apache.hadoop.mapreduce.v2.proto.MRProtos$StringCounterMapProto$Builder:setKeyBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.mapreduce.v2.proto.MRProtos$StringCounterGroupMapProto$Builder	setKey	key_	J	java.lang.Object	0	org.apache.hadoop.mapreduce.v2.proto.MRProtos$StringCounterGroupMapProto$Builder:setKey(java.lang.String)
org.apache.hadoop.mapreduce.v2.proto.MRProtos$StringCounterGroupMapProto$Builder	setKeyBytes	key_	J	java.lang.Object	0	org.apache.hadoop.mapreduce.v2.proto.MRProtos$StringCounterGroupMapProto$Builder:setKeyBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.mapreduce.v2.proto.MRProtos$TaskAttemptCompletionEventProto$Builder	setMapOutputServerAddress	mapOutputServerAddress_	J	java.lang.Object	0	org.apache.hadoop.mapreduce.v2.proto.MRProtos$TaskAttemptCompletionEventProto$Builder:setMapOutputServerAddress(java.lang.String)
org.apache.hadoop.mapreduce.v2.proto.MRProtos$TaskAttemptCompletionEventProto$Builder	setMapOutputServerAddressBytes	mapOutputServerAddress_	J	java.lang.Object	0	org.apache.hadoop.mapreduce.v2.proto.MRProtos$TaskAttemptCompletionEventProto$Builder:setMapOutputServerAddressBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.mapreduce.v2.proto.MRProtos$TaskAttemptCompletionEventProto$Builder	setAttemptRunTime	attemptRunTime_	J	int	0	org.apache.hadoop.mapreduce.v2.proto.MRProtos$TaskAttemptCompletionEventProto$Builder:setAttemptRunTime(int)
org.apache.hadoop.mapreduce.v2.proto.MRProtos$TaskAttemptCompletionEventProto$Builder	setEventId	eventId_	J	int	0	org.apache.hadoop.mapreduce.v2.proto.MRProtos$TaskAttemptCompletionEventProto$Builder:setEventId(int)
org.apache.hadoop.mapreduce.v2.proto.MRProtos$TaskAttemptReportProto$Builder	setProgress	progress_	J	float	0	org.apache.hadoop.mapreduce.v2.proto.MRProtos$TaskAttemptReportProto$Builder:setProgress(float)
org.apache.hadoop.mapreduce.v2.proto.MRProtos$TaskAttemptReportProto$Builder	setStartTime	startTime_	J	long	0	org.apache.hadoop.mapreduce.v2.proto.MRProtos$TaskAttemptReportProto$Builder:setStartTime(long)
org.apache.hadoop.mapreduce.v2.proto.MRProtos$TaskAttemptReportProto$Builder	setFinishTime	finishTime_	J	long	0	org.apache.hadoop.mapreduce.v2.proto.MRProtos$TaskAttemptReportProto$Builder:setFinishTime(long)
org.apache.hadoop.mapreduce.v2.proto.MRProtos$TaskAttemptReportProto$Builder	setDiagnosticInfo	diagnosticInfo_	J	java.lang.Object	0	org.apache.hadoop.mapreduce.v2.proto.MRProtos$TaskAttemptReportProto$Builder:setDiagnosticInfo(java.lang.String)
org.apache.hadoop.mapreduce.v2.proto.MRProtos$TaskAttemptReportProto$Builder	setDiagnosticInfoBytes	diagnosticInfo_	J	java.lang.Object	0	org.apache.hadoop.mapreduce.v2.proto.MRProtos$TaskAttemptReportProto$Builder:setDiagnosticInfoBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.mapreduce.v2.proto.MRProtos$TaskAttemptReportProto$Builder	setStateString	stateString_	J	java.lang.Object	0	org.apache.hadoop.mapreduce.v2.proto.MRProtos$TaskAttemptReportProto$Builder:setStateString(java.lang.String)
org.apache.hadoop.mapreduce.v2.proto.MRProtos$TaskAttemptReportProto$Builder	setStateStringBytes	stateString_	J	java.lang.Object	0	org.apache.hadoop.mapreduce.v2.proto.MRProtos$TaskAttemptReportProto$Builder:setStateStringBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.mapreduce.v2.proto.MRProtos$TaskAttemptReportProto$Builder	setShuffleFinishTime	shuffleFinishTime_	J	long	0	org.apache.hadoop.mapreduce.v2.proto.MRProtos$TaskAttemptReportProto$Builder:setShuffleFinishTime(long)
org.apache.hadoop.mapreduce.v2.proto.MRProtos$TaskAttemptReportProto$Builder	setSortFinishTime	sortFinishTime_	J	long	0	org.apache.hadoop.mapreduce.v2.proto.MRProtos$TaskAttemptReportProto$Builder:setSortFinishTime(long)
org.apache.hadoop.mapreduce.v2.proto.MRProtos$TaskAttemptReportProto$Builder	setNodeManagerHost	nodeManagerHost_	J	java.lang.Object	0	org.apache.hadoop.mapreduce.v2.proto.MRProtos$TaskAttemptReportProto$Builder:setNodeManagerHost(java.lang.String)
org.apache.hadoop.mapreduce.v2.proto.MRProtos$TaskAttemptReportProto$Builder	setNodeManagerHostBytes	nodeManagerHost_	J	java.lang.Object	0	org.apache.hadoop.mapreduce.v2.proto.MRProtos$TaskAttemptReportProto$Builder:setNodeManagerHostBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.mapreduce.v2.proto.MRProtos$TaskAttemptReportProto$Builder	setNodeManagerPort	nodeManagerPort_	J	int	0	org.apache.hadoop.mapreduce.v2.proto.MRProtos$TaskAttemptReportProto$Builder:setNodeManagerPort(int)
org.apache.hadoop.mapreduce.v2.proto.MRProtos$TaskAttemptReportProto$Builder	setNodeManagerHttpPort	nodeManagerHttpPort_	J	int	0	org.apache.hadoop.mapreduce.v2.proto.MRProtos$TaskAttemptReportProto$Builder:setNodeManagerHttpPort(int)
org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos$GetTaskAttemptCompletionEventsRequestProto$Builder	setFromEventId	fromEventId_	J	int	0	org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos$GetTaskAttemptCompletionEventsRequestProto$Builder:setFromEventId(int)
org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos$GetTaskAttemptCompletionEventsRequestProto$Builder	setMaxEvents	maxEvents_	J	int	0	org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos$GetTaskAttemptCompletionEventsRequestProto$Builder:setMaxEvents(int)
org.apache.hadoop.mapreduce.v2.proto.MRProtos$AMInfoProto$Builder	setStartTime	startTime_	J	long	0	org.apache.hadoop.mapreduce.v2.proto.MRProtos$AMInfoProto$Builder:setStartTime(long)
org.apache.hadoop.mapreduce.v2.proto.MRProtos$AMInfoProto$Builder	setNodeManagerHost	nodeManagerHost_	J	java.lang.Object	0	org.apache.hadoop.mapreduce.v2.proto.MRProtos$AMInfoProto$Builder:setNodeManagerHost(java.lang.String)
org.apache.hadoop.mapreduce.v2.proto.MRProtos$AMInfoProto$Builder	setNodeManagerHostBytes	nodeManagerHost_	J	java.lang.Object	0	org.apache.hadoop.mapreduce.v2.proto.MRProtos$AMInfoProto$Builder:setNodeManagerHostBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.mapreduce.v2.proto.MRProtos$AMInfoProto$Builder	setNodeManagerPort	nodeManagerPort_	J	int	0	org.apache.hadoop.mapreduce.v2.proto.MRProtos$AMInfoProto$Builder:setNodeManagerPort(int)
org.apache.hadoop.mapreduce.v2.proto.MRProtos$AMInfoProto$Builder	setNodeManagerHttpPort	nodeManagerHttpPort_	J	int	0	org.apache.hadoop.mapreduce.v2.proto.MRProtos$AMInfoProto$Builder:setNodeManagerHttpPort(int)
org.apache.hadoop.mapreduce.v2.api.protocolrecords.impl.pb.KillTaskAttemptRequestPBImpl	setTaskAttemptId	taskAttemptId	C	org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId	0	org.apache.hadoop.mapreduce.v2.api.protocolrecords.impl.pb.KillTaskAttemptRequestPBImpl:setTaskAttemptId(org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId)
org.apache.hadoop.mapreduce.v2.api.protocolrecords.impl.pb.GetDiagnosticsRequestPBImpl	setTaskAttemptId	taskAttemptId	C	org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId	0	org.apache.hadoop.mapreduce.v2.api.protocolrecords.impl.pb.GetDiagnosticsRequestPBImpl:setTaskAttemptId(org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId)
org.apache.hadoop.mapreduce.v2.api.protocolrecords.impl.pb.GetTaskReportResponsePBImpl	setTaskReport	taskReport	C	org.apache.hadoop.mapreduce.v2.api.records.TaskReport	0	org.apache.hadoop.mapreduce.v2.api.protocolrecords.impl.pb.GetTaskReportResponsePBImpl:setTaskReport(org.apache.hadoop.mapreduce.v2.api.records.TaskReport)
org.apache.hadoop.mapreduce.v2.api.protocolrecords.impl.pb.GetTaskAttemptReportRequestPBImpl	setTaskAttemptId	taskAttemptId	C	org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId	0	org.apache.hadoop.mapreduce.v2.api.protocolrecords.impl.pb.GetTaskAttemptReportRequestPBImpl:setTaskAttemptId(org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId)
org.apache.hadoop.mapreduce.v2.api.protocolrecords.impl.pb.GetTaskAttemptReportResponsePBImpl	setTaskAttemptReport	taskAttemptReport	C	org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptReport	0	org.apache.hadoop.mapreduce.v2.api.protocolrecords.impl.pb.GetTaskAttemptReportResponsePBImpl:setTaskAttemptReport(org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptReport)
org.apache.hadoop.mapreduce.v2.api.protocolrecords.impl.pb.GetTaskReportRequestPBImpl	setTaskId	taskId	C	org.apache.hadoop.mapreduce.v2.api.records.TaskId	0	org.apache.hadoop.mapreduce.v2.api.protocolrecords.impl.pb.GetTaskReportRequestPBImpl:setTaskId(org.apache.hadoop.mapreduce.v2.api.records.TaskId)
org.apache.hadoop.mapreduce.v2.api.protocolrecords.impl.pb.FailTaskAttemptRequestPBImpl	setTaskAttemptId	taskAttemptId	C	org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId	0	org.apache.hadoop.mapreduce.v2.api.protocolrecords.impl.pb.FailTaskAttemptRequestPBImpl:setTaskAttemptId(org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId)
org.apache.hadoop.mapreduce.v2.api.protocolrecords.impl.pb.RenewDelegationTokenRequestPBImpl	setDelegationToken	token	C	org.apache.hadoop.yarn.api.records.Token	0	org.apache.hadoop.mapreduce.v2.api.protocolrecords.impl.pb.RenewDelegationTokenRequestPBImpl:setDelegationToken(org.apache.hadoop.yarn.api.records.Token)
org.apache.hadoop.mapreduce.v2.api.protocolrecords.impl.pb.GetDelegationTokenRequestPBImpl	setRenewer	renewer	J	java.lang.String	0	org.apache.hadoop.mapreduce.v2.api.protocolrecords.impl.pb.GetDelegationTokenRequestPBImpl:setRenewer(java.lang.String)
org.apache.hadoop.mapreduce.v2.api.protocolrecords.impl.pb.KillTaskRequestPBImpl	setTaskId	taskId	C	org.apache.hadoop.mapreduce.v2.api.records.TaskId	0	org.apache.hadoop.mapreduce.v2.api.protocolrecords.impl.pb.KillTaskRequestPBImpl:setTaskId(org.apache.hadoop.mapreduce.v2.api.records.TaskId)
org.apache.hadoop.mapreduce.v2.api.protocolrecords.impl.pb.GetTaskAttemptCompletionEventsRequestPBImpl	setJobId	jobId	C	org.apache.hadoop.mapreduce.v2.api.records.JobId	0	org.apache.hadoop.mapreduce.v2.api.protocolrecords.impl.pb.GetTaskAttemptCompletionEventsRequestPBImpl:setJobId(org.apache.hadoop.mapreduce.v2.api.records.JobId)
org.apache.hadoop.mapreduce.v2.api.protocolrecords.impl.pb.GetJobReportResponsePBImpl	setJobReport	jobReport	C	org.apache.hadoop.mapreduce.v2.api.records.JobReport	0	org.apache.hadoop.mapreduce.v2.api.protocolrecords.impl.pb.GetJobReportResponsePBImpl:setJobReport(org.apache.hadoop.mapreduce.v2.api.records.JobReport)
org.apache.hadoop.mapreduce.v2.api.protocolrecords.impl.pb.KillJobRequestPBImpl	setJobId	jobId	C	org.apache.hadoop.mapreduce.v2.api.records.JobId	0	org.apache.hadoop.mapreduce.v2.api.protocolrecords.impl.pb.KillJobRequestPBImpl:setJobId(org.apache.hadoop.mapreduce.v2.api.records.JobId)
org.apache.hadoop.mapreduce.v2.api.protocolrecords.impl.pb.GetJobReportRequestPBImpl	setJobId	jobId	C	org.apache.hadoop.mapreduce.v2.api.records.JobId	0	org.apache.hadoop.mapreduce.v2.api.protocolrecords.impl.pb.GetJobReportRequestPBImpl:setJobId(org.apache.hadoop.mapreduce.v2.api.records.JobId)
org.apache.hadoop.mapreduce.v2.api.protocolrecords.impl.pb.GetCountersResponsePBImpl	setCounters	counters	C	org.apache.hadoop.mapreduce.v2.api.records.Counters	0	org.apache.hadoop.mapreduce.v2.api.protocolrecords.impl.pb.GetCountersResponsePBImpl:setCounters(org.apache.hadoop.mapreduce.v2.api.records.Counters)
org.apache.hadoop.mapreduce.v2.api.protocolrecords.impl.pb.GetCountersRequestPBImpl	setJobId	jobId	C	org.apache.hadoop.mapreduce.v2.api.records.JobId	0	org.apache.hadoop.mapreduce.v2.api.protocolrecords.impl.pb.GetCountersRequestPBImpl:setJobId(org.apache.hadoop.mapreduce.v2.api.records.JobId)
org.apache.hadoop.mapreduce.v2.api.protocolrecords.impl.pb.GetTaskReportsRequestPBImpl	setJobId	jobId	C	org.apache.hadoop.mapreduce.v2.api.records.JobId	0	org.apache.hadoop.mapreduce.v2.api.protocolrecords.impl.pb.GetTaskReportsRequestPBImpl:setJobId(org.apache.hadoop.mapreduce.v2.api.records.JobId)
org.apache.hadoop.mapreduce.v2.api.protocolrecords.impl.pb.GetDelegationTokenResponsePBImpl	setDelegationToken	mrToken	C	org.apache.hadoop.yarn.api.records.Token	0	org.apache.hadoop.mapreduce.v2.api.protocolrecords.impl.pb.GetDelegationTokenResponsePBImpl:setDelegationToken(org.apache.hadoop.yarn.api.records.Token)
org.apache.hadoop.mapreduce.v2.api.protocolrecords.impl.pb.CancelDelegationTokenRequestPBImpl	setDelegationToken	token	C	org.apache.hadoop.yarn.api.records.Token	0	org.apache.hadoop.mapreduce.v2.api.protocolrecords.impl.pb.CancelDelegationTokenRequestPBImpl:setDelegationToken(org.apache.hadoop.yarn.api.records.Token)
org.apache.hadoop.mapreduce.v2.api.records.impl.pb.TaskAttemptIdPBImpl	setTaskId	taskId	C	org.apache.hadoop.mapreduce.v2.api.records.TaskId	0	org.apache.hadoop.mapreduce.v2.api.records.impl.pb.TaskAttemptIdPBImpl:setTaskId(org.apache.hadoop.mapreduce.v2.api.records.TaskId)
org.apache.hadoop.mapreduce.v2.api.records.impl.pb.TaskAttemptReportPBImpl	setCounters	counters	C	org.apache.hadoop.mapreduce.v2.api.records.Counters	0	org.apache.hadoop.mapreduce.v2.api.records.impl.pb.TaskAttemptReportPBImpl:setCounters(org.apache.hadoop.mapreduce.v2.api.records.Counters)
org.apache.hadoop.mapreduce.v2.api.records.impl.pb.TaskAttemptReportPBImpl	setRawCounters	rawCounters	C	org.apache.hadoop.mapreduce.Counters	0	org.apache.hadoop.mapreduce.v2.api.records.impl.pb.TaskAttemptReportPBImpl:setRawCounters(org.apache.hadoop.mapreduce.Counters)
org.apache.hadoop.mapreduce.v2.api.records.impl.pb.TaskAttemptReportPBImpl	setTaskAttemptId	taskAttemptId	C	org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId	0	org.apache.hadoop.mapreduce.v2.api.records.impl.pb.TaskAttemptReportPBImpl:setTaskAttemptId(org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId)
org.apache.hadoop.mapreduce.v2.api.records.impl.pb.TaskAttemptReportPBImpl	setContainerId	containerId	C	org.apache.hadoop.yarn.api.records.ContainerId	0	org.apache.hadoop.mapreduce.v2.api.records.impl.pb.TaskAttemptReportPBImpl:setContainerId(org.apache.hadoop.yarn.api.records.ContainerId)
org.apache.hadoop.mapreduce.v2.api.records.impl.pb.TaskReportPBImpl	setCounters	counters	C	org.apache.hadoop.mapreduce.v2.api.records.Counters	0	org.apache.hadoop.mapreduce.v2.api.records.impl.pb.TaskReportPBImpl:setCounters(org.apache.hadoop.mapreduce.v2.api.records.Counters)
org.apache.hadoop.mapreduce.v2.api.records.impl.pb.TaskReportPBImpl	setRawCounters	rawCounters	C	org.apache.hadoop.mapreduce.Counters	0	org.apache.hadoop.mapreduce.v2.api.records.impl.pb.TaskReportPBImpl:setRawCounters(org.apache.hadoop.mapreduce.Counters)
org.apache.hadoop.mapreduce.v2.api.records.impl.pb.TaskReportPBImpl	setTaskId	taskId	C	org.apache.hadoop.mapreduce.v2.api.records.TaskId	0	org.apache.hadoop.mapreduce.v2.api.records.impl.pb.TaskReportPBImpl:setTaskId(org.apache.hadoop.mapreduce.v2.api.records.TaskId)
org.apache.hadoop.mapreduce.v2.api.records.impl.pb.TaskReportPBImpl	setStatus	status	J	java.lang.String	0	org.apache.hadoop.mapreduce.v2.api.records.impl.pb.TaskReportPBImpl:setStatus(java.lang.String)
org.apache.hadoop.mapreduce.v2.api.records.impl.pb.TaskReportPBImpl	setSuccessfulAttempt	successfulAttemptId	C	org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId	0	org.apache.hadoop.mapreduce.v2.api.records.impl.pb.TaskReportPBImpl:setSuccessfulAttempt(org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId)
org.apache.hadoop.mapreduce.v2.api.records.impl.pb.JobReportPBImpl	setJobId	jobId	C	org.apache.hadoop.mapreduce.v2.api.records.JobId	0	org.apache.hadoop.mapreduce.v2.api.records.impl.pb.JobReportPBImpl:setJobId(org.apache.hadoop.mapreduce.v2.api.records.JobId)
org.apache.hadoop.mapreduce.v2.api.records.impl.pb.JobReportPBImpl	setJobPriority	jobPriority	C	org.apache.hadoop.yarn.api.records.Priority	0	org.apache.hadoop.mapreduce.v2.api.records.impl.pb.JobReportPBImpl:setJobPriority(org.apache.hadoop.yarn.api.records.Priority)
org.apache.hadoop.mapreduce.v2.api.records.impl.pb.AMInfoPBImpl	setAppAttemptId	appAttemptId	C	org.apache.hadoop.yarn.api.records.ApplicationAttemptId	0	org.apache.hadoop.mapreduce.v2.api.records.impl.pb.AMInfoPBImpl:setAppAttemptId(org.apache.hadoop.yarn.api.records.ApplicationAttemptId)
org.apache.hadoop.mapreduce.v2.api.records.impl.pb.AMInfoPBImpl	setContainerId	containerId	C	org.apache.hadoop.yarn.api.records.ContainerId	0	org.apache.hadoop.mapreduce.v2.api.records.impl.pb.AMInfoPBImpl:setContainerId(org.apache.hadoop.yarn.api.records.ContainerId)
org.apache.hadoop.mapreduce.v2.api.records.impl.pb.JobIdPBImpl	setAppId	applicationId	C	org.apache.hadoop.yarn.api.records.ApplicationId	0	org.apache.hadoop.mapreduce.v2.api.records.impl.pb.JobIdPBImpl:setAppId(org.apache.hadoop.yarn.api.records.ApplicationId)
org.apache.hadoop.mapreduce.v2.api.records.impl.pb.TaskAttemptCompletionEventPBImpl	setAttemptId	taskAttemptId	C	org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId	0	org.apache.hadoop.mapreduce.v2.api.records.impl.pb.TaskAttemptCompletionEventPBImpl:setAttemptId(org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId)
org.apache.hadoop.mapreduce.v2.api.records.impl.pb.TaskIdPBImpl	setJobId	jobId	C	org.apache.hadoop.mapreduce.v2.api.records.JobId	0	org.apache.hadoop.mapreduce.v2.api.records.impl.pb.TaskIdPBImpl:setJobId(org.apache.hadoop.mapreduce.v2.api.records.JobId)
org.apache.hadoop.mapreduce.v2.util.LocalResourceBuilder	setConf	conf	C	org.apache.hadoop.conf.Configuration	0	org.apache.hadoop.mapreduce.v2.util.LocalResourceBuilder:setConf(org.apache.hadoop.conf.Configuration)
org.apache.hadoop.mapreduce.v2.util.LocalResourceBuilder	setType	type	C	org.apache.hadoop.yarn.api.records.LocalResourceType	0	org.apache.hadoop.mapreduce.v2.util.LocalResourceBuilder:setType(org.apache.hadoop.yarn.api.records.LocalResourceType)
org.apache.hadoop.mapreduce.v2.util.LocalResourceBuilder	setUris	uris	J	java.net.URI	1	org.apache.hadoop.mapreduce.v2.util.LocalResourceBuilder:setUris(java.net.URI[])
org.apache.hadoop.mapreduce.v2.util.LocalResourceBuilder	setTimestamps	timestamps	J	long	1	org.apache.hadoop.mapreduce.v2.util.LocalResourceBuilder:setTimestamps(long[])
org.apache.hadoop.mapreduce.v2.util.LocalResourceBuilder	setSizes	sizes	J	long	1	org.apache.hadoop.mapreduce.v2.util.LocalResourceBuilder:setSizes(long[])
org.apache.hadoop.mapreduce.v2.util.LocalResourceBuilder	setVisibilities	visibilities	J	boolean	1	org.apache.hadoop.mapreduce.v2.util.LocalResourceBuilder:setVisibilities(boolean[])
org.apache.hadoop.mapreduce.v2.util.LocalResourceBuilder	setSharedCacheUploadPolicies	sharedCacheUploadPolicies	GJ	java.util.Map	0	org.apache.hadoop.mapreduce.v2.util.LocalResourceBuilder:setSharedCacheUploadPolicies(java.util.Map)
org.apache.hadoop.mapreduce.v2.jobhistory.JobIndexInfo	setSubmitTime	submitTime	J	long	0	org.apache.hadoop.mapreduce.v2.jobhistory.JobIndexInfo:setSubmitTime(long)
org.apache.hadoop.mapreduce.v2.jobhistory.JobIndexInfo	setFinishTime	finishTime	J	long	0	org.apache.hadoop.mapreduce.v2.jobhistory.JobIndexInfo:setFinishTime(long)
org.apache.hadoop.mapreduce.v2.jobhistory.JobIndexInfo	setUser	user	J	java.lang.String	0	org.apache.hadoop.mapreduce.v2.jobhistory.JobIndexInfo:setUser(java.lang.String)
org.apache.hadoop.mapreduce.v2.jobhistory.JobIndexInfo	setQueueName	queueName	J	java.lang.String	0	org.apache.hadoop.mapreduce.v2.jobhistory.JobIndexInfo:setQueueName(java.lang.String)
org.apache.hadoop.mapreduce.v2.jobhistory.JobIndexInfo	setJobName	jobName	J	java.lang.String	0	org.apache.hadoop.mapreduce.v2.jobhistory.JobIndexInfo:setJobName(java.lang.String)
org.apache.hadoop.mapreduce.v2.jobhistory.JobIndexInfo	setJobId	jobId	C	org.apache.hadoop.mapreduce.v2.api.records.JobId	0	org.apache.hadoop.mapreduce.v2.jobhistory.JobIndexInfo:setJobId(org.apache.hadoop.mapreduce.v2.api.records.JobId)
org.apache.hadoop.mapreduce.v2.jobhistory.JobIndexInfo	setNumMaps	numMaps	J	int	0	org.apache.hadoop.mapreduce.v2.jobhistory.JobIndexInfo:setNumMaps(int)
org.apache.hadoop.mapreduce.v2.jobhistory.JobIndexInfo	setNumReduces	numReduces	J	int	0	org.apache.hadoop.mapreduce.v2.jobhistory.JobIndexInfo:setNumReduces(int)
org.apache.hadoop.mapreduce.v2.jobhistory.JobIndexInfo	setJobStatus	jobStatus	J	java.lang.String	0	org.apache.hadoop.mapreduce.v2.jobhistory.JobIndexInfo:setJobStatus(java.lang.String)
org.apache.hadoop.mapreduce.v2.jobhistory.JobIndexInfo	setJobStartTime	jobStartTime	J	long	0	org.apache.hadoop.mapreduce.v2.jobhistory.JobIndexInfo:setJobStartTime(long)
org.apache.hadoop.mapred.MapTaskStatus	setMapFinishTime	mapFinishTime	J	long	0	org.apache.hadoop.mapred.MapTaskStatus:setMapFinishTime(long)
org.apache.hadoop.mapred.Task	setJobFile	jobFile	J	java.lang.String	0	org.apache.hadoop.mapred.Task:setJobFile(java.lang.String)
org.apache.hadoop.mapred.Task	setJobTokenSecret	tokenSecret	J	javax.crypto.SecretKey	0	org.apache.hadoop.mapred.Task:setJobTokenSecret(javax.crypto.SecretKey)
org.apache.hadoop.mapred.Task	setEncryptedSpillKey	encryptedSpillKey	J	byte	1	org.apache.hadoop.mapred.Task:setEncryptedSpillKey(byte[])
org.apache.hadoop.mapred.Task	setShuffleSecret	shuffleSecret	J	javax.crypto.SecretKey	0	org.apache.hadoop.mapred.Task:setShuffleSecret(javax.crypto.SecretKey)
org.apache.hadoop.mapred.Task	setWriteSkipRecs	writeSkipRecs	J	boolean	0	org.apache.hadoop.mapred.Task:setWriteSkipRecs(boolean)
org.apache.hadoop.mapred.Task	setSkipRanges	skipRanges	C	org.apache.hadoop.mapred.SortedRanges	0	org.apache.hadoop.mapred.Task:setSkipRanges(org.apache.hadoop.mapred.SortedRanges)
org.apache.hadoop.mapred.Task	setSkipping	skipping	J	boolean	0	org.apache.hadoop.mapred.Task:setSkipping(boolean)
org.apache.hadoop.mapred.Task	setJobCleanupTaskState	jobRunStateForCleanup	C	org.apache.hadoop.mapreduce.JobStatus$State	0	org.apache.hadoop.mapred.Task:setJobCleanupTaskState(org.apache.hadoop.mapreduce.JobStatus$State)
org.apache.hadoop.mapred.Task	setUser	user	J	java.lang.String	0	org.apache.hadoop.mapred.Task:setUser(java.lang.String)
org.apache.hadoop.mapred.Task	setExtraData	extraData	C	org.apache.hadoop.io.BytesWritable	0	org.apache.hadoop.mapred.Task:setExtraData(org.apache.hadoop.io.BytesWritable)
org.apache.hadoop.mapred.FileInputFormat	setMinSplitSize	minSplitSize	J	long	0	org.apache.hadoop.mapred.FileInputFormat:setMinSplitSize(long)
org.apache.hadoop.mapred.Queue	setName	name	J	java.lang.String	0	org.apache.hadoop.mapred.Queue:setName(java.lang.String)
org.apache.hadoop.mapred.Queue	setAcls	acls	GC	java.util.Map	0	org.apache.hadoop.mapred.Queue:setAcls(java.util.Map)
org.apache.hadoop.mapred.Queue	setState	state	C	org.apache.hadoop.mapreduce.QueueState	0	org.apache.hadoop.mapred.Queue:setState(org.apache.hadoop.mapreduce.QueueState)
org.apache.hadoop.mapred.Queue	setSchedulingInfo	schedulingInfo	J	java.lang.Object	0	org.apache.hadoop.mapred.Queue:setSchedulingInfo(java.lang.Object)
org.apache.hadoop.mapred.Queue	setProperties	props	J	java.util.Properties	0	org.apache.hadoop.mapred.Queue:setProperties(java.util.Properties)
org.apache.hadoop.mapred.JobClient	setTaskOutputFilter	taskOutputFilter	C	org.apache.hadoop.mapred.JobClient$TaskStatusFilter	0	org.apache.hadoop.mapred.JobClient:setTaskOutputFilter(org.apache.hadoop.mapred.JobClient$TaskStatusFilter)
org.apache.hadoop.mapred.Task$TaskReporter	setInputSplit	split	C	org.apache.hadoop.mapred.InputSplit	0	org.apache.hadoop.mapred.Task$TaskReporter:setInputSplit(org.apache.hadoop.mapred.InputSplit)
org.apache.hadoop.mapred.ReduceTask	setLocalMapFiles	localMapFiles	GC	java.util.Map	0	org.apache.hadoop.mapred.ReduceTask:setLocalMapFiles(java.util.Map)
org.apache.hadoop.mapred.QueueConfigurationParser	setAclsEnabled	aclsEnabled	J	boolean	0	org.apache.hadoop.mapred.QueueConfigurationParser:setAclsEnabled(boolean)
org.apache.hadoop.mapred.QueueConfigurationParser	setRoot	root	C	org.apache.hadoop.mapred.Queue	0	org.apache.hadoop.mapred.QueueConfigurationParser:setRoot(org.apache.hadoop.mapred.Queue)
org.apache.hadoop.mapred.ReduceTaskStatus	setShuffleFinishTime	shuffleFinishTime	J	long	0	org.apache.hadoop.mapred.ReduceTaskStatus:setShuffleFinishTime(long)
org.apache.hadoop.mapred.JobConf	setCredentials	credentials	C	org.apache.hadoop.security.Credentials	0	org.apache.hadoop.mapred.JobConf:setCredentials(org.apache.hadoop.security.Credentials)
org.apache.hadoop.mapred.lib.TaggedInputSplit	setConf	conf	C	org.apache.hadoop.conf.Configuration	0	org.apache.hadoop.mapred.lib.TaggedInputSplit:setConf(org.apache.hadoop.conf.Configuration)
org.apache.hadoop.mapred.lib.MultipleOutputs	setRecordWriters	recordWriters	GC	java.util.Map	0	org.apache.hadoop.mapred.lib.MultipleOutputs:setRecordWriters(java.util.Map)
org.apache.hadoop.mapred.Task$CombineOutputCollector	setWriter	writer	GC	org.apache.hadoop.mapred.IFile$Writer	0	org.apache.hadoop.mapred.Task$CombineOutputCollector:setWriter(org.apache.hadoop.mapred.IFile$Writer)
org.apache.hadoop.mapred.MapOutputFile	setConf	conf	C	org.apache.hadoop.conf.Configuration	0	org.apache.hadoop.mapred.MapOutputFile:setConf(org.apache.hadoop.conf.Configuration)
org.apache.hadoop.mapred.join.Parser$Node	setID	id	J	int	0	org.apache.hadoop.mapred.join.Parser$Node:setID(int)
org.apache.hadoop.mapred.join.Parser$Node	setKeyComparator	cmpcl	GC	java.lang.Class	0	org.apache.hadoop.mapred.join.Parser$Node:setKeyComparator(java.lang.Class)
org.apache.hadoop.mapred.join.CompositeRecordReader	setConf	conf	C	org.apache.hadoop.conf.Configuration	0	org.apache.hadoop.mapred.join.CompositeRecordReader:setConf(org.apache.hadoop.conf.Configuration)
org.apache.hadoop.mapred.join.WrappedRecordReader	setConf	conf	C	org.apache.hadoop.conf.Configuration	0	org.apache.hadoop.mapred.join.WrappedRecordReader:setConf(org.apache.hadoop.conf.Configuration)
org.apache.hadoop.mapred.TaskLogAppender	setTaskId	taskId	J	java.lang.String	0	org.apache.hadoop.mapred.TaskLogAppender:setTaskId(java.lang.String)
org.apache.hadoop.mapred.TaskStatus	setProgress	progress	J	float	0	org.apache.hadoop.mapred.TaskStatus:setProgress(float)
org.apache.hadoop.mapred.TaskStatus	setTaskTracker	taskTracker	J	java.lang.String	0	org.apache.hadoop.mapred.TaskStatus:setTaskTracker(java.lang.String)
org.apache.hadoop.mapred.TaskStatus	setRunState	runState	C	org.apache.hadoop.mapred.TaskStatus$State	0	org.apache.hadoop.mapred.TaskStatus:setRunState(org.apache.hadoop.mapred.TaskStatus$State)
org.apache.hadoop.mapred.TaskStatus	setNextRecordRange	nextRecordRange	C	org.apache.hadoop.mapred.SortedRanges$Range	0	org.apache.hadoop.mapred.TaskStatus:setNextRecordRange(org.apache.hadoop.mapred.SortedRanges$Range)
org.apache.hadoop.mapred.TaskStatus	setIncludeAllCounters	includeAllCounters	J	boolean	0	org.apache.hadoop.mapred.TaskStatus:setIncludeAllCounters(boolean)
org.apache.hadoop.mapred.TaskStatus	setCounters	counters	C	org.apache.hadoop.mapred.Counters	0	org.apache.hadoop.mapred.TaskStatus:setCounters(org.apache.hadoop.mapred.Counters)
org.apache.hadoop.mapred.TaskStatus	setOutputSize	outputSize	J	long	0	org.apache.hadoop.mapred.TaskStatus:setOutputSize(long)
org.apache.hadoop.mapred.AMFeedback	setTaskFound	taskFound	J	boolean	0	org.apache.hadoop.mapred.AMFeedback:setTaskFound(boolean)
org.apache.hadoop.mapred.AMFeedback	setPreemption	preemption	J	boolean	0	org.apache.hadoop.mapred.AMFeedback:setPreemption(boolean)
org.apache.hadoop.mapred.BasicTypeSorterBase	setProgressable	reporter	C	org.apache.hadoop.util.Progressable	0	org.apache.hadoop.mapred.BasicTypeSorterBase:setProgressable(org.apache.hadoop.util.Progressable)
org.apache.hadoop.mapred.BasicTypeSorterBase	setInputBuffer	keyValBuffer	C	org.apache.hadoop.io.OutputBuffer	0	org.apache.hadoop.mapred.BasicTypeSorterBase:setInputBuffer(org.apache.hadoop.io.OutputBuffer)
org.apache.hadoop.mapred.ClusterStatus$BlackListInfo	setTrackerName	trackerName	J	java.lang.String	0	org.apache.hadoop.mapred.ClusterStatus$BlackListInfo:setTrackerName(java.lang.String)
org.apache.hadoop.mapred.ClusterStatus$BlackListInfo	setReasonForBlackListing	reasonForBlackListing	J	java.lang.String	0	org.apache.hadoop.mapred.ClusterStatus$BlackListInfo:setReasonForBlackListing(java.lang.String)
org.apache.hadoop.mapred.ClusterStatus$BlackListInfo	setBlackListReport	blackListReport	J	java.lang.String	0	org.apache.hadoop.mapred.ClusterStatus$BlackListInfo:setBlackListReport(java.lang.String)
org.apache.hadoop.mapreduce.counters.FrameworkCounterGroup$FrameworkCounter	setValue	value	J	long	0	org.apache.hadoop.mapreduce.counters.FrameworkCounterGroup$FrameworkCounter:setValue(long)
org.apache.hadoop.mapreduce.counters.AbstractCounters	setWriteAllCounters	writeAllCounters	J	boolean	0	org.apache.hadoop.mapreduce.counters.AbstractCounters:setWriteAllCounters(boolean)
org.apache.hadoop.mapreduce.counters.FileSystemCounterGroup$FSCounter	setValue	value	J	long	0	org.apache.hadoop.mapreduce.counters.FileSystemCounterGroup$FSCounter:setValue(long)
org.apache.hadoop.mapreduce.counters.GenericCounter	setDisplayName	displayName	J	java.lang.String	0	org.apache.hadoop.mapreduce.counters.GenericCounter:setDisplayName(java.lang.String)
org.apache.hadoop.mapreduce.counters.GenericCounter	setValue	value	J	long	0	org.apache.hadoop.mapreduce.counters.GenericCounter:setValue(long)
org.apache.hadoop.mapreduce.counters.AbstractCounterGroup	setDisplayName	displayName	J	java.lang.String	0	org.apache.hadoop.mapreduce.counters.AbstractCounterGroup:setDisplayName(java.lang.String)
org.apache.hadoop.mapreduce.counters.FrameworkCounterGroup	setDisplayName	displayName	J	java.lang.String	0	org.apache.hadoop.mapreduce.counters.FrameworkCounterGroup:setDisplayName(java.lang.String)
org.apache.hadoop.mapreduce.counters.FileSystemCounterGroup	setDisplayName	displayName	J	java.lang.String	0	org.apache.hadoop.mapreduce.counters.FileSystemCounterGroup:setDisplayName(java.lang.String)
org.apache.hadoop.mapreduce.v2.LogParams	setContainerId	containerId	J	java.lang.String	0	org.apache.hadoop.mapreduce.v2.LogParams:setContainerId(java.lang.String)
org.apache.hadoop.mapreduce.v2.LogParams	setApplicationId	applicationId	J	java.lang.String	0	org.apache.hadoop.mapreduce.v2.LogParams:setApplicationId(java.lang.String)
org.apache.hadoop.mapreduce.v2.LogParams	setNodeId	nodeId	J	java.lang.String	0	org.apache.hadoop.mapreduce.v2.LogParams:setNodeId(java.lang.String)
org.apache.hadoop.mapreduce.TaskCompletionEvent	setTaskRunTime	taskRunTime	J	int	0	org.apache.hadoop.mapreduce.TaskCompletionEvent:setTaskRunTime(int)
org.apache.hadoop.mapreduce.TaskCompletionEvent	setEventId	eventId	J	int	0	org.apache.hadoop.mapreduce.TaskCompletionEvent:setEventId(int)
org.apache.hadoop.mapreduce.TaskCompletionEvent	setTaskAttemptId	taskId	C	org.apache.hadoop.mapreduce.TaskAttemptID	0	org.apache.hadoop.mapreduce.TaskCompletionEvent:setTaskAttemptId(org.apache.hadoop.mapreduce.TaskAttemptID)
org.apache.hadoop.mapreduce.TaskCompletionEvent	setTaskStatus	status	C	org.apache.hadoop.mapreduce.TaskCompletionEvent$Status	0	org.apache.hadoop.mapreduce.TaskCompletionEvent:setTaskStatus(org.apache.hadoop.mapreduce.TaskCompletionEvent$Status)
org.apache.hadoop.mapreduce.TaskCompletionEvent	setTaskTrackerHttp	taskTrackerHttp	J	java.lang.String	0	org.apache.hadoop.mapreduce.TaskCompletionEvent:setTaskTrackerHttp(java.lang.String)
org.apache.hadoop.mapreduce.TaskReport	setFinishTime	finishTime	J	long	0	org.apache.hadoop.mapreduce.TaskReport:setFinishTime(long)
org.apache.hadoop.mapreduce.TaskReport	setStartTime	startTime	J	long	0	org.apache.hadoop.mapreduce.TaskReport:setStartTime(long)
org.apache.hadoop.mapreduce.TaskReport	setSuccessfulAttemptId	successfulAttempt	C	org.apache.hadoop.mapreduce.TaskAttemptID	0	org.apache.hadoop.mapreduce.TaskReport:setSuccessfulAttemptId(org.apache.hadoop.mapreduce.TaskAttemptID)
org.apache.hadoop.mapreduce.TaskReport	setRunningTaskAttemptIds	runningAttempts	GC	java.util.Collection	0	org.apache.hadoop.mapreduce.TaskReport:setRunningTaskAttemptIds(java.util.Collection)
org.apache.hadoop.mapreduce.QueueAclsInfo	setQueueName	queueName	J	java.lang.String	0	org.apache.hadoop.mapreduce.QueueAclsInfo:setQueueName(java.lang.String)
org.apache.hadoop.mapreduce.task.TaskAttemptContextImpl	setStatusString	status	J	java.lang.String	0	org.apache.hadoop.mapreduce.task.TaskAttemptContextImpl:setStatusString(java.lang.String)
org.apache.hadoop.mapreduce.task.JobContextImpl	setJobID	jobId	C	org.apache.hadoop.mapreduce.JobID	0	org.apache.hadoop.mapreduce.task.JobContextImpl:setJobID(org.apache.hadoop.mapreduce.JobID)
org.apache.hadoop.mapreduce.QueueInfo	setQueueName	queueName	J	java.lang.String	0	org.apache.hadoop.mapreduce.QueueInfo:setQueueName(java.lang.String)
org.apache.hadoop.mapreduce.QueueInfo	setSchedulingInfo	schedulingInfo	J	java.lang.String	0	org.apache.hadoop.mapreduce.QueueInfo:setSchedulingInfo(java.lang.String)
org.apache.hadoop.mapreduce.QueueInfo	setState	queueState	C	org.apache.hadoop.mapreduce.QueueState	0	org.apache.hadoop.mapreduce.QueueInfo:setState(org.apache.hadoop.mapreduce.QueueState)
org.apache.hadoop.mapreduce.QueueInfo	setJobStatuses	stats	C	org.apache.hadoop.mapreduce.JobStatus	1	org.apache.hadoop.mapreduce.QueueInfo:setJobStatuses(org.apache.hadoop.mapreduce.JobStatus[])
org.apache.hadoop.mapreduce.QueueInfo	setQueueChildren	children	GC	java.util.List	0	org.apache.hadoop.mapreduce.QueueInfo:setQueueChildren(java.util.List)
org.apache.hadoop.mapreduce.QueueInfo	setProperties	props	J	java.util.Properties	0	org.apache.hadoop.mapreduce.QueueInfo:setProperties(java.util.Properties)
org.apache.hadoop.mapreduce.JobStatus	setPriority	priority	C	org.apache.hadoop.mapreduce.JobPriority	0	org.apache.hadoop.mapreduce.JobStatus:setPriority(org.apache.hadoop.mapreduce.JobPriority)
org.apache.hadoop.mapreduce.JobStatus	setFinishTime	finishTime	J	long	0	org.apache.hadoop.mapreduce.JobStatus:setFinishTime(long)
org.apache.hadoop.mapreduce.JobStatus	setHistoryFile	historyFile	J	java.lang.String	0	org.apache.hadoop.mapreduce.JobStatus:setHistoryFile(java.lang.String)
org.apache.hadoop.mapreduce.JobStatus	setTrackingUrl	trackingUrl	J	java.lang.String	0	org.apache.hadoop.mapreduce.JobStatus:setTrackingUrl(java.lang.String)
org.apache.hadoop.mapreduce.JobStatus	setState	runState	C	org.apache.hadoop.mapreduce.JobStatus$State	0	org.apache.hadoop.mapreduce.JobStatus:setState(org.apache.hadoop.mapreduce.JobStatus$State)
org.apache.hadoop.mapreduce.JobStatus	setStartTime	startTime	J	long	0	org.apache.hadoop.mapreduce.JobStatus:setStartTime(long)
org.apache.hadoop.mapreduce.JobStatus	setUsername	user	J	java.lang.String	0	org.apache.hadoop.mapreduce.JobStatus:setUsername(java.lang.String)
org.apache.hadoop.mapreduce.JobStatus	setSchedulingInfo	schedulingInfo	J	java.lang.String	0	org.apache.hadoop.mapreduce.JobStatus:setSchedulingInfo(java.lang.String)
org.apache.hadoop.mapreduce.JobStatus	setJobACLs	jobACLs	GC	java.util.Map	0	org.apache.hadoop.mapreduce.JobStatus:setJobACLs(java.util.Map)
org.apache.hadoop.mapreduce.JobStatus	setQueue	queue	J	java.lang.String	0	org.apache.hadoop.mapreduce.JobStatus:setQueue(java.lang.String)
org.apache.hadoop.mapreduce.JobStatus	setFailureInfo	failureInfo	J	java.lang.String	0	org.apache.hadoop.mapreduce.JobStatus:setFailureInfo(java.lang.String)
org.apache.hadoop.mapreduce.JobStatus	setNumUsedSlots	numUsedSlots	J	int	0	org.apache.hadoop.mapreduce.JobStatus:setNumUsedSlots(int)
org.apache.hadoop.mapreduce.JobStatus	setNumReservedSlots	numReservedSlots	J	int	0	org.apache.hadoop.mapreduce.JobStatus:setNumReservedSlots(int)
org.apache.hadoop.mapreduce.JobStatus	setUsedMem	usedMem	J	int	0	org.apache.hadoop.mapreduce.JobStatus:setUsedMem(int)
org.apache.hadoop.mapreduce.JobStatus	setReservedMem	reservedMem	J	int	0	org.apache.hadoop.mapreduce.JobStatus:setReservedMem(int)
org.apache.hadoop.mapreduce.JobStatus	setNeededMem	neededMem	J	int	0	org.apache.hadoop.mapreduce.JobStatus:setNeededMem(int)
org.apache.hadoop.mapreduce.JobStatus	setUber	isUber	J	boolean	0	org.apache.hadoop.mapreduce.JobStatus:setUber(boolean)
org.apache.hadoop.mapreduce.split.JobSplit$SplitMetaInfo	setInputDataLocations	locations	J	java.lang.String	1	org.apache.hadoop.mapreduce.split.JobSplit$SplitMetaInfo:setInputDataLocations(java.lang.String[])
org.apache.hadoop.mapreduce.split.JobSplit$SplitMetaInfo	setInputDataLength	inputDataLength	J	long	0	org.apache.hadoop.mapreduce.split.JobSplit$SplitMetaInfo:setInputDataLength(long)
org.apache.hadoop.mapreduce.Job	setCluster	cluster	C	org.apache.hadoop.mapreduce.Cluster	0	org.apache.hadoop.mapreduce.Job:setCluster(org.apache.hadoop.mapreduce.Cluster)
org.apache.hadoop.mapreduce.Job	setReservationId	reservationId	C	org.apache.hadoop.yarn.api.records.ReservationId	0	org.apache.hadoop.mapreduce.Job:setReservationId(org.apache.hadoop.yarn.api.records.ReservationId)
org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob	setJobID	controlID	J	java.lang.String	0	org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob:setJobID(java.lang.String)
org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob	setJob	job	C	org.apache.hadoop.mapreduce.Job	0	org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob:setJob(org.apache.hadoop.mapreduce.Job)
org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob	setJobState	state	C	org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob$State	0	org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob:setJobState(org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob$State)
org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob	setMessage	message	J	java.lang.String	0	org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob:setMessage(java.lang.String)
org.apache.hadoop.mapreduce.lib.db.DBRecordReader	setStatement	statement	J	java.sql.PreparedStatement	0	org.apache.hadoop.mapreduce.lib.db.DBRecordReader:setStatement(java.sql.PreparedStatement)
org.apache.hadoop.mapreduce.lib.partition.BinaryPartitioner	setConf	conf	C	org.apache.hadoop.conf.Configuration	0	org.apache.hadoop.mapreduce.lib.partition.BinaryPartitioner:setConf(org.apache.hadoop.conf.Configuration)
org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregatorBaseDescriptor$MyEntry	setValue	val	C	org.apache.hadoop.io.Text	0	org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregatorBaseDescriptor$MyEntry:setValue(org.apache.hadoop.io.Text)
org.apache.hadoop.mapreduce.lib.output.committer.manifest.ManifestCommitter	setSuccessReport	successReport	C	org.apache.hadoop.mapreduce.lib.output.committer.manifest.files.ManifestSuccessData	0	org.apache.hadoop.mapreduce.lib.output.committer.manifest.ManifestCommitter:setSuccessReport(org.apache.hadoop.mapreduce.lib.output.committer.manifest.files.ManifestSuccessData)
org.apache.hadoop.mapreduce.lib.output.committer.manifest.files.TaskManifest	setType	type	J	java.lang.String	0	org.apache.hadoop.mapreduce.lib.output.committer.manifest.files.TaskManifest:setType(java.lang.String)
org.apache.hadoop.mapreduce.lib.output.committer.manifest.files.TaskManifest	setVersion	version	J	int	0	org.apache.hadoop.mapreduce.lib.output.committer.manifest.files.TaskManifest:setVersion(int)
org.apache.hadoop.mapreduce.lib.output.committer.manifest.files.TaskManifest	setIOStatistics	iostatistics	C	org.apache.hadoop.fs.statistics.IOStatisticsSnapshot	0	org.apache.hadoop.mapreduce.lib.output.committer.manifest.files.TaskManifest:setIOStatistics(org.apache.hadoop.fs.statistics.IOStatisticsSnapshot)
org.apache.hadoop.mapreduce.lib.output.committer.manifest.files.TaskManifest	setJobId	jobId	J	java.lang.String	0	org.apache.hadoop.mapreduce.lib.output.committer.manifest.files.TaskManifest:setJobId(java.lang.String)
org.apache.hadoop.mapreduce.lib.output.committer.manifest.files.TaskManifest	setJobAttemptNumber	jobAttemptNumber	J	int	0	org.apache.hadoop.mapreduce.lib.output.committer.manifest.files.TaskManifest:setJobAttemptNumber(int)
org.apache.hadoop.mapreduce.lib.output.committer.manifest.files.TaskManifest	setTaskID	taskID	J	java.lang.String	0	org.apache.hadoop.mapreduce.lib.output.committer.manifest.files.TaskManifest:setTaskID(java.lang.String)
org.apache.hadoop.mapreduce.lib.output.committer.manifest.files.TaskManifest	setTaskAttemptID	taskAttemptID	J	java.lang.String	0	org.apache.hadoop.mapreduce.lib.output.committer.manifest.files.TaskManifest:setTaskAttemptID(java.lang.String)
org.apache.hadoop.mapreduce.lib.output.committer.manifest.files.TaskManifest	setTaskAttemptDir	taskAttemptDir	J	java.lang.String	0	org.apache.hadoop.mapreduce.lib.output.committer.manifest.files.TaskManifest:setTaskAttemptDir(java.lang.String)
org.apache.hadoop.mapreduce.lib.output.committer.manifest.files.FileEntry	setSource	source	J	java.lang.String	0	org.apache.hadoop.mapreduce.lib.output.committer.manifest.files.FileEntry:setSource(java.lang.String)
org.apache.hadoop.mapreduce.lib.output.committer.manifest.files.FileEntry	setDest	dest	J	java.lang.String	0	org.apache.hadoop.mapreduce.lib.output.committer.manifest.files.FileEntry:setDest(java.lang.String)
org.apache.hadoop.mapreduce.lib.output.committer.manifest.files.FileEntry	setSize	size	J	long	0	org.apache.hadoop.mapreduce.lib.output.committer.manifest.files.FileEntry:setSize(long)
org.apache.hadoop.mapreduce.lib.output.committer.manifest.files.FileEntry	setEtag	etag	J	java.lang.String	0	org.apache.hadoop.mapreduce.lib.output.committer.manifest.files.FileEntry:setEtag(java.lang.String)
org.apache.hadoop.mapreduce.lib.output.committer.manifest.files.DirEntry	setDir	dir	J	java.lang.String	0	org.apache.hadoop.mapreduce.lib.output.committer.manifest.files.DirEntry:setDir(java.lang.String)
org.apache.hadoop.mapreduce.lib.output.committer.manifest.files.DirEntry	setType	type	J	int	0	org.apache.hadoop.mapreduce.lib.output.committer.manifest.files.DirEntry:setType(int)
org.apache.hadoop.mapreduce.lib.output.committer.manifest.files.DirEntry	setLevel	level	J	int	0	org.apache.hadoop.mapreduce.lib.output.committer.manifest.files.DirEntry:setLevel(int)
org.apache.hadoop.mapreduce.lib.output.committer.manifest.files.ManifestSuccessData	setName	name	J	java.lang.String	0	org.apache.hadoop.mapreduce.lib.output.committer.manifest.files.ManifestSuccessData:setName(java.lang.String)
org.apache.hadoop.mapreduce.lib.output.committer.manifest.files.ManifestSuccessData	setTimestamp	timestamp	J	long	0	org.apache.hadoop.mapreduce.lib.output.committer.manifest.files.ManifestSuccessData:setTimestamp(long)
org.apache.hadoop.mapreduce.lib.output.committer.manifest.files.ManifestSuccessData	setDate	date	J	java.lang.String	0	org.apache.hadoop.mapreduce.lib.output.committer.manifest.files.ManifestSuccessData:setDate(java.lang.String)
org.apache.hadoop.mapreduce.lib.output.committer.manifest.files.ManifestSuccessData	setHostname	hostname	J	java.lang.String	0	org.apache.hadoop.mapreduce.lib.output.committer.manifest.files.ManifestSuccessData:setHostname(java.lang.String)
org.apache.hadoop.mapreduce.lib.output.committer.manifest.files.ManifestSuccessData	setCommitter	committer	J	java.lang.String	0	org.apache.hadoop.mapreduce.lib.output.committer.manifest.files.ManifestSuccessData:setCommitter(java.lang.String)
org.apache.hadoop.mapreduce.lib.output.committer.manifest.files.ManifestSuccessData	setDescription	description	J	java.lang.String	0	org.apache.hadoop.mapreduce.lib.output.committer.manifest.files.ManifestSuccessData:setDescription(java.lang.String)
org.apache.hadoop.mapreduce.lib.output.committer.manifest.files.ManifestSuccessData	setMetrics	metrics	GJ	java.util.TreeMap	0	org.apache.hadoop.mapreduce.lib.output.committer.manifest.files.ManifestSuccessData:setMetrics(java.util.TreeMap)
org.apache.hadoop.mapreduce.lib.output.committer.manifest.files.ManifestSuccessData	setFilenames	filenames	GJ	java.util.ArrayList	0	org.apache.hadoop.mapreduce.lib.output.committer.manifest.files.ManifestSuccessData:setFilenames(java.util.ArrayList)
org.apache.hadoop.mapreduce.lib.output.committer.manifest.files.ManifestSuccessData	setDiagnostics	diagnostics	GJ	java.util.TreeMap	0	org.apache.hadoop.mapreduce.lib.output.committer.manifest.files.ManifestSuccessData:setDiagnostics(java.util.TreeMap)
org.apache.hadoop.mapreduce.lib.output.committer.manifest.files.ManifestSuccessData	setJobId	jobId	J	java.lang.String	0	org.apache.hadoop.mapreduce.lib.output.committer.manifest.files.ManifestSuccessData:setJobId(java.lang.String)
org.apache.hadoop.mapreduce.lib.output.committer.manifest.files.ManifestSuccessData	setJobIdSource	jobIdSource	J	java.lang.String	0	org.apache.hadoop.mapreduce.lib.output.committer.manifest.files.ManifestSuccessData:setJobIdSource(java.lang.String)
org.apache.hadoop.mapreduce.lib.output.committer.manifest.files.ManifestSuccessData	setIOStatistics	iostatistics	C	org.apache.hadoop.fs.statistics.IOStatisticsSnapshot	0	org.apache.hadoop.mapreduce.lib.output.committer.manifest.files.ManifestSuccessData:setIOStatistics(org.apache.hadoop.fs.statistics.IOStatisticsSnapshot)
org.apache.hadoop.mapreduce.lib.output.committer.manifest.files.ManifestSuccessData	setSuccess	success	J	boolean	0	org.apache.hadoop.mapreduce.lib.output.committer.manifest.files.ManifestSuccessData:setSuccess(boolean)
org.apache.hadoop.mapreduce.lib.output.committer.manifest.files.ManifestSuccessData	setState	state	J	java.lang.String	0	org.apache.hadoop.mapreduce.lib.output.committer.manifest.files.ManifestSuccessData:setState(java.lang.String)
org.apache.hadoop.mapreduce.lib.output.MultipleOutputs	setRecordWriters	recordWriters	GC	java.util.Map	0	org.apache.hadoop.mapreduce.lib.output.MultipleOutputs:setRecordWriters(java.util.Map)
org.apache.hadoop.mapreduce.lib.join.Parser$Node	setID	id	J	int	0	org.apache.hadoop.mapreduce.lib.join.Parser$Node:setID(int)
org.apache.hadoop.mapreduce.lib.join.Parser$Node	setKeyComparator	cmpcl	GC	java.lang.Class	0	org.apache.hadoop.mapreduce.lib.join.Parser$Node:setKeyComparator(java.lang.Class)
org.apache.hadoop.mapreduce.lib.join.CompositeRecordReader	setConf	conf	C	org.apache.hadoop.conf.Configuration	0	org.apache.hadoop.mapreduce.lib.join.CompositeRecordReader:setConf(org.apache.hadoop.conf.Configuration)
org.apache.hadoop.mapreduce.lib.input.TaggedInputSplit	setConf	conf	C	org.apache.hadoop.conf.Configuration	0	org.apache.hadoop.mapreduce.lib.input.TaggedInputSplit:setConf(org.apache.hadoop.conf.Configuration)
org.apache.hadoop.mapreduce.lib.input.CombineFileInputFormat	setMaxSplitSize	maxSplitSize	J	long	0	org.apache.hadoop.mapreduce.lib.input.CombineFileInputFormat:setMaxSplitSize(long)
org.apache.hadoop.mapreduce.lib.input.CombineFileInputFormat	setMinSplitSizeNode	minSplitSizeNode	J	long	0	org.apache.hadoop.mapreduce.lib.input.CombineFileInputFormat:setMinSplitSizeNode(long)
org.apache.hadoop.mapreduce.lib.input.CombineFileInputFormat	setMinSplitSizeRack	minSplitSizeRack	J	long	0	org.apache.hadoop.mapreduce.lib.input.CombineFileInputFormat:setMinSplitSizeRack(long)
org.apache.hadoop.mapreduce.lib.chain.Chain	setIfUnsetThrowable	throwable	J	java.lang.Throwable	0	org.apache.hadoop.mapreduce.lib.chain.Chain:setIfUnsetThrowable(java.lang.Throwable)
org.apache.hadoop.mapreduce.jobhistory.TaskFailed$Builder	setTaskid	taskid	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.TaskFailed$Builder:setTaskid(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.TaskFailed$Builder	setTaskType	taskType	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.TaskFailed$Builder:setTaskType(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.TaskFailed$Builder	setFinishTime	finishTime	J	long	0	org.apache.hadoop.mapreduce.jobhistory.TaskFailed$Builder:setFinishTime(long)
org.apache.hadoop.mapreduce.jobhistory.TaskFailed$Builder	setError	error	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.TaskFailed$Builder:setError(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.TaskFailed$Builder	setFailedDueToAttempt	failedDueToAttempt	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.TaskFailed$Builder:setFailedDueToAttempt(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.TaskFailed$Builder	setStatus	status	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.TaskFailed$Builder:setStatus(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.TaskFailed$Builder	setCounters	counters	C	org.apache.hadoop.mapreduce.jobhistory.JhCounters	0	org.apache.hadoop.mapreduce.jobhistory.TaskFailed$Builder:setCounters(org.apache.hadoop.mapreduce.jobhistory.JhCounters)
org.apache.hadoop.mapreduce.jobhistory.TaskStarted	setTaskid	taskid	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.TaskStarted:setTaskid(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.TaskStarted	setTaskType	taskType	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.TaskStarted:setTaskType(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.TaskStarted	setSplitLocations	splitLocations	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.TaskStarted:setSplitLocations(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.JobInfoChange$Builder	setJobid	jobid	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.JobInfoChange$Builder:setJobid(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.JobInfoChange$Builder	setSubmitTime	submitTime	J	long	0	org.apache.hadoop.mapreduce.jobhistory.JobInfoChange$Builder:setSubmitTime(long)
org.apache.hadoop.mapreduce.jobhistory.JobInfoChange$Builder	setLaunchTime	launchTime	J	long	0	org.apache.hadoop.mapreduce.jobhistory.JobInfoChange$Builder:setLaunchTime(long)
org.apache.hadoop.mapreduce.jobhistory.JobQueueChange$Builder	setJobid	jobid	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.JobQueueChange$Builder:setJobid(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.JobQueueChange$Builder	setJobQueueName	jobQueueName	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.JobQueueChange$Builder:setJobQueueName(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.TaskUpdated$Builder	setTaskid	taskid	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.TaskUpdated$Builder:setTaskid(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.TaskUpdated$Builder	setFinishTime	finishTime	J	long	0	org.apache.hadoop.mapreduce.jobhistory.TaskUpdated$Builder:setFinishTime(long)
org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished$Builder	setTaskid	taskid	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished$Builder:setTaskid(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished$Builder	setAttemptId	attemptId	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished$Builder:setAttemptId(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished$Builder	setTaskType	taskType	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished$Builder:setTaskType(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished$Builder	setTaskStatus	taskStatus	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished$Builder:setTaskStatus(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished$Builder	setMapFinishTime	mapFinishTime	J	long	0	org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished$Builder:setMapFinishTime(long)
org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished$Builder	setFinishTime	finishTime	J	long	0	org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished$Builder:setFinishTime(long)
org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished$Builder	setHostname	hostname	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished$Builder:setHostname(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished$Builder	setPort	port	J	int	0	org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished$Builder:setPort(int)
org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished$Builder	setRackname	rackname	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished$Builder:setRackname(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished$Builder	setState	state	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished$Builder:setState(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished$Builder	setCounters	counters	C	org.apache.hadoop.mapreduce.jobhistory.JhCounters	0	org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished$Builder:setCounters(org.apache.hadoop.mapreduce.jobhistory.JhCounters)
org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished$Builder	setClockSplits	clockSplits	GJ	java.util.List	0	org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished$Builder:setClockSplits(java.util.List)
org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished$Builder	setCpuUsages	cpuUsages	GJ	java.util.List	0	org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished$Builder:setCpuUsages(java.util.List)
org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished$Builder	setVMemKbytes	vMemKbytes	GJ	java.util.List	0	org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished$Builder:setVMemKbytes(java.util.List)
org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished$Builder	setPhysMemKbytes	physMemKbytes	GJ	java.util.List	0	org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished$Builder:setPhysMemKbytes(java.util.List)
org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished	setTaskid	taskid	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished:setTaskid(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished	setAttemptId	attemptId	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished:setAttemptId(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished	setTaskType	taskType	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished:setTaskType(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished	setTaskStatus	taskStatus	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished:setTaskStatus(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished	setHostname	hostname	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished:setHostname(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished	setRackname	rackname	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished:setRackname(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished	setState	state	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished:setState(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished	setCounters	counters	C	org.apache.hadoop.mapreduce.jobhistory.JhCounters	0	org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished:setCounters(org.apache.hadoop.mapreduce.jobhistory.JhCounters)
org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished	setClockSplits	clockSplits	GJ	java.util.List	0	org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished:setClockSplits(java.util.List)
org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished	setCpuUsages	cpuUsages	GJ	java.util.List	0	org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished:setCpuUsages(java.util.List)
org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished	setVMemKbytes	vMemKbytes	GJ	java.util.List	0	org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished:setVMemKbytes(java.util.List)
org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished	setPhysMemKbytes	physMemKbytes	GJ	java.util.List	0	org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished:setPhysMemKbytes(java.util.List)
org.apache.hadoop.mapreduce.jobhistory.Event$Builder	setType	type	C	org.apache.hadoop.mapreduce.jobhistory.EventType	0	org.apache.hadoop.mapreduce.jobhistory.Event$Builder:setType(org.apache.hadoop.mapreduce.jobhistory.EventType)
org.apache.hadoop.mapreduce.jobhistory.Event$Builder	setEvent	event	J	java.lang.Object	0	org.apache.hadoop.mapreduce.jobhistory.Event$Builder:setEvent(java.lang.Object)
org.apache.hadoop.mapreduce.jobhistory.JobInited$Builder	setJobid	jobid	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.JobInited$Builder:setJobid(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.JobInited$Builder	setLaunchTime	launchTime	J	long	0	org.apache.hadoop.mapreduce.jobhistory.JobInited$Builder:setLaunchTime(long)
org.apache.hadoop.mapreduce.jobhistory.JobInited$Builder	setTotalMaps	totalMaps	J	int	0	org.apache.hadoop.mapreduce.jobhistory.JobInited$Builder:setTotalMaps(int)
org.apache.hadoop.mapreduce.jobhistory.JobInited$Builder	setTotalReduces	totalReduces	J	int	0	org.apache.hadoop.mapreduce.jobhistory.JobInited$Builder:setTotalReduces(int)
org.apache.hadoop.mapreduce.jobhistory.JobInited$Builder	setJobStatus	jobStatus	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.JobInited$Builder:setJobStatus(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.JobInited$Builder	setUberized	uberized	J	boolean	0	org.apache.hadoop.mapreduce.jobhistory.JobInited$Builder:setUberized(boolean)
org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished$Builder	setTaskid	taskid	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished$Builder:setTaskid(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished$Builder	setAttemptId	attemptId	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished$Builder:setAttemptId(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished$Builder	setTaskType	taskType	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished$Builder:setTaskType(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished$Builder	setTaskStatus	taskStatus	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished$Builder:setTaskStatus(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished$Builder	setShuffleFinishTime	shuffleFinishTime	J	long	0	org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished$Builder:setShuffleFinishTime(long)
org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished$Builder	setSortFinishTime	sortFinishTime	J	long	0	org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished$Builder:setSortFinishTime(long)
org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished$Builder	setFinishTime	finishTime	J	long	0	org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished$Builder:setFinishTime(long)
org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished$Builder	setHostname	hostname	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished$Builder:setHostname(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished$Builder	setPort	port	J	int	0	org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished$Builder:setPort(int)
org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished$Builder	setRackname	rackname	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished$Builder:setRackname(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished$Builder	setState	state	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished$Builder:setState(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished$Builder	setCounters	counters	C	org.apache.hadoop.mapreduce.jobhistory.JhCounters	0	org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished$Builder:setCounters(org.apache.hadoop.mapreduce.jobhistory.JhCounters)
org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished$Builder	setClockSplits	clockSplits	GJ	java.util.List	0	org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished$Builder:setClockSplits(java.util.List)
org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished$Builder	setCpuUsages	cpuUsages	GJ	java.util.List	0	org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished$Builder:setCpuUsages(java.util.List)
org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished$Builder	setVMemKbytes	vMemKbytes	GJ	java.util.List	0	org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished$Builder:setVMemKbytes(java.util.List)
org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished$Builder	setPhysMemKbytes	physMemKbytes	GJ	java.util.List	0	org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished$Builder:setPhysMemKbytes(java.util.List)
org.apache.hadoop.mapreduce.jobhistory.TaskFinished	setTaskid	taskid	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.TaskFinished:setTaskid(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.TaskFinished	setTaskType	taskType	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.TaskFinished:setTaskType(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.TaskFinished	setStatus	status	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.TaskFinished:setStatus(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.TaskFinished	setCounters	counters	C	org.apache.hadoop.mapreduce.jobhistory.JhCounters	0	org.apache.hadoop.mapreduce.jobhistory.TaskFinished:setCounters(org.apache.hadoop.mapreduce.jobhistory.JhCounters)
org.apache.hadoop.mapreduce.jobhistory.TaskFinished	setSuccessfulAttemptId	successfulAttemptId	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.TaskFinished:setSuccessfulAttemptId(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.JhCounterGroup	setName	name	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.JhCounterGroup:setName(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.JhCounterGroup	setDisplayName	displayName	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.JhCounterGroup:setDisplayName(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.JhCounterGroup	setCounts	counts	GC	java.util.List	0	org.apache.hadoop.mapreduce.jobhistory.JhCounterGroup:setCounts(java.util.List)
org.apache.hadoop.mapreduce.jobhistory.JobPriorityChange$Builder	setJobid	jobid	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.JobPriorityChange$Builder:setJobid(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.JobPriorityChange$Builder	setPriority	priority	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.JobPriorityChange$Builder:setPriority(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletionEvent	setDatum	datum	C	org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion	0	org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletionEvent:setDatum(java.lang.Object)
org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished	setTaskid	taskid	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished:setTaskid(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished	setAttemptId	attemptId	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished:setAttemptId(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished	setTaskType	taskType	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished:setTaskType(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished	setTaskStatus	taskStatus	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished:setTaskStatus(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished	setHostname	hostname	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished:setHostname(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished	setRackname	rackname	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished:setRackname(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished	setState	state	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished:setState(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished	setCounters	counters	C	org.apache.hadoop.mapreduce.jobhistory.JhCounters	0	org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished:setCounters(org.apache.hadoop.mapreduce.jobhistory.JhCounters)
org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished	setClockSplits	clockSplits	GJ	java.util.List	0	org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished:setClockSplits(java.util.List)
org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished	setCpuUsages	cpuUsages	GJ	java.util.List	0	org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished:setCpuUsages(java.util.List)
org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished	setVMemKbytes	vMemKbytes	GJ	java.util.List	0	org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished:setVMemKbytes(java.util.List)
org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished	setPhysMemKbytes	physMemKbytes	GJ	java.util.List	0	org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished:setPhysMemKbytes(java.util.List)
org.apache.hadoop.mapreduce.jobhistory.TaskFailed	setTaskid	taskid	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.TaskFailed:setTaskid(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.TaskFailed	setTaskType	taskType	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.TaskFailed:setTaskType(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.TaskFailed	setError	error	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.TaskFailed:setError(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.TaskFailed	setFailedDueToAttempt	failedDueToAttempt	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.TaskFailed:setFailedDueToAttempt(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.TaskFailed	setStatus	status	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.TaskFailed:setStatus(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.TaskFailed	setCounters	counters	C	org.apache.hadoop.mapreduce.jobhistory.JhCounters	0	org.apache.hadoop.mapreduce.jobhistory.TaskFailed:setCounters(org.apache.hadoop.mapreduce.jobhistory.JhCounters)
org.apache.hadoop.mapreduce.jobhistory.JhCounters$Builder	setName	name	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.JhCounters$Builder:setName(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.JhCounters$Builder	setGroups	groups	GC	java.util.List	0	org.apache.hadoop.mapreduce.jobhistory.JhCounters$Builder:setGroups(java.util.List)
org.apache.hadoop.mapreduce.jobhistory.AMStartedEvent	setDatum	datum	C	org.apache.hadoop.mapreduce.jobhistory.AMStarted	0	org.apache.hadoop.mapreduce.jobhistory.AMStartedEvent:setDatum(java.lang.Object)
org.apache.hadoop.mapreduce.jobhistory.AMStarted	setApplicationAttemptId	applicationAttemptId	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.AMStarted:setApplicationAttemptId(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.AMStarted	setContainerId	containerId	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.AMStarted:setContainerId(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.AMStarted	setNodeManagerHost	nodeManagerHost	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.AMStarted:setNodeManagerHost(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted$Builder	setTaskid	taskid	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted$Builder:setTaskid(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted$Builder	setTaskType	taskType	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted$Builder:setTaskType(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted$Builder	setAttemptId	attemptId	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted$Builder:setAttemptId(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted$Builder	setStartTime	startTime	J	long	0	org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted$Builder:setStartTime(long)
org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted$Builder	setTrackerName	trackerName	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted$Builder:setTrackerName(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted$Builder	setHttpPort	httpPort	J	int	0	org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted$Builder:setHttpPort(int)
org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted$Builder	setShufflePort	shufflePort	J	int	0	org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted$Builder:setShufflePort(int)
org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted$Builder	setContainerId	containerId	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted$Builder:setContainerId(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted$Builder	setLocality	locality	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted$Builder:setLocality(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted$Builder	setAvataar	avataar	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted$Builder:setAvataar(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.Event	setType	type	C	org.apache.hadoop.mapreduce.jobhistory.EventType	0	org.apache.hadoop.mapreduce.jobhistory.Event:setType(org.apache.hadoop.mapreduce.jobhistory.EventType)
org.apache.hadoop.mapreduce.jobhistory.Event	setEvent	event	J	java.lang.Object	0	org.apache.hadoop.mapreduce.jobhistory.Event:setEvent(java.lang.Object)
org.apache.hadoop.mapreduce.jobhistory.JobSubmittedEvent	setDatum	datum	C	org.apache.hadoop.mapreduce.jobhistory.JobSubmitted	0	org.apache.hadoop.mapreduce.jobhistory.JobSubmittedEvent:setDatum(java.lang.Object)
org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished$Builder	setTaskid	taskid	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished$Builder:setTaskid(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished$Builder	setAttemptId	attemptId	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished$Builder:setAttemptId(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished$Builder	setTaskType	taskType	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished$Builder:setTaskType(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished$Builder	setTaskStatus	taskStatus	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished$Builder:setTaskStatus(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished$Builder	setFinishTime	finishTime	J	long	0	org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished$Builder:setFinishTime(long)
org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished$Builder	setRackname	rackname	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished$Builder:setRackname(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished$Builder	setHostname	hostname	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished$Builder:setHostname(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished$Builder	setState	state	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished$Builder:setState(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished$Builder	setCounters	counters	C	org.apache.hadoop.mapreduce.jobhistory.JhCounters	0	org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished$Builder:setCounters(org.apache.hadoop.mapreduce.jobhistory.JhCounters)
org.apache.hadoop.mapreduce.jobhistory.JobInitedEvent	setDatum	datum	C	org.apache.hadoop.mapreduce.jobhistory.JobInited	0	org.apache.hadoop.mapreduce.jobhistory.JobInitedEvent:setDatum(java.lang.Object)
org.apache.hadoop.mapreduce.jobhistory.JobFinished	setJobid	jobid	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.JobFinished:setJobid(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.JobFinished	setTotalCounters	totalCounters	C	org.apache.hadoop.mapreduce.jobhistory.JhCounters	0	org.apache.hadoop.mapreduce.jobhistory.JobFinished:setTotalCounters(org.apache.hadoop.mapreduce.jobhistory.JhCounters)
org.apache.hadoop.mapreduce.jobhistory.JobFinished	setMapCounters	mapCounters	C	org.apache.hadoop.mapreduce.jobhistory.JhCounters	0	org.apache.hadoop.mapreduce.jobhistory.JobFinished:setMapCounters(org.apache.hadoop.mapreduce.jobhistory.JhCounters)
org.apache.hadoop.mapreduce.jobhistory.JobFinished	setReduceCounters	reduceCounters	C	org.apache.hadoop.mapreduce.jobhistory.JhCounters	0	org.apache.hadoop.mapreduce.jobhistory.JobFinished:setReduceCounters(org.apache.hadoop.mapreduce.jobhistory.JhCounters)
org.apache.hadoop.mapreduce.jobhistory.JobSubmitted$Builder	setJobid	jobid	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.JobSubmitted$Builder:setJobid(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.JobSubmitted$Builder	setJobName	jobName	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.JobSubmitted$Builder:setJobName(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.JobSubmitted$Builder	setUserName	userName	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.JobSubmitted$Builder:setUserName(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.JobSubmitted$Builder	setSubmitTime	submitTime	J	long	0	org.apache.hadoop.mapreduce.jobhistory.JobSubmitted$Builder:setSubmitTime(long)
org.apache.hadoop.mapreduce.jobhistory.JobSubmitted$Builder	setJobConfPath	jobConfPath	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.JobSubmitted$Builder:setJobConfPath(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.JobSubmitted$Builder	setAcls	acls	GJ	java.util.Map	0	org.apache.hadoop.mapreduce.jobhistory.JobSubmitted$Builder:setAcls(java.util.Map)
org.apache.hadoop.mapreduce.jobhistory.JobSubmitted$Builder	setJobQueueName	jobQueueName	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.JobSubmitted$Builder:setJobQueueName(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.JobSubmitted$Builder	setWorkflowId	workflowId	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.JobSubmitted$Builder:setWorkflowId(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.JobSubmitted$Builder	setWorkflowName	workflowName	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.JobSubmitted$Builder:setWorkflowName(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.JobSubmitted$Builder	setWorkflowNodeName	workflowNodeName	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.JobSubmitted$Builder:setWorkflowNodeName(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.JobSubmitted$Builder	setWorkflowAdjacencies	workflowAdjacencies	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.JobSubmitted$Builder:setWorkflowAdjacencies(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.JobSubmitted$Builder	setWorkflowTags	workflowTags	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.JobSubmitted$Builder:setWorkflowTags(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.JobStatusChanged	setJobid	jobid	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.JobStatusChanged:setJobid(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.JobStatusChanged	setJobStatus	jobStatus	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.JobStatusChanged:setJobStatus(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.TaskUpdatedEvent	setDatum	datum	C	org.apache.hadoop.mapreduce.jobhistory.TaskUpdated	0	org.apache.hadoop.mapreduce.jobhistory.TaskUpdatedEvent:setDatum(java.lang.Object)
org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion	setJobid	jobid	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion:setJobid(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion	setJobStatus	jobStatus	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion:setJobStatus(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion	setDiagnostics	diagnostics	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion:setDiagnostics(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.JhCounter$Builder	setName	name	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.JhCounter$Builder:setName(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.JhCounter$Builder	setDisplayName	displayName	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.JhCounter$Builder:setDisplayName(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.JhCounter$Builder	setValue	value	J	long	0	org.apache.hadoop.mapreduce.jobhistory.JhCounter$Builder:setValue(long)
org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion	setTaskid	taskid	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion:setTaskid(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion	setTaskType	taskType	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion:setTaskType(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion	setAttemptId	attemptId	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion:setAttemptId(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion	setHostname	hostname	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion:setHostname(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion	setRackname	rackname	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion:setRackname(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion	setStatus	status	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion:setStatus(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion	setError	error	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion:setError(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion	setCounters	counters	C	org.apache.hadoop.mapreduce.jobhistory.JhCounters	0	org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion:setCounters(org.apache.hadoop.mapreduce.jobhistory.JhCounters)
org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion	setClockSplits	clockSplits	GJ	java.util.List	0	org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion:setClockSplits(java.util.List)
org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion	setCpuUsages	cpuUsages	GJ	java.util.List	0	org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion:setCpuUsages(java.util.List)
org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion	setVMemKbytes	vMemKbytes	GJ	java.util.List	0	org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion:setVMemKbytes(java.util.List)
org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion	setPhysMemKbytes	physMemKbytes	GJ	java.util.List	0	org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion:setPhysMemKbytes(java.util.List)
org.apache.hadoop.mapreduce.jobhistory.JobPriorityChangeEvent	setDatum	datum	C	org.apache.hadoop.mapreduce.jobhistory.JobPriorityChange	0	org.apache.hadoop.mapreduce.jobhistory.JobPriorityChangeEvent:setDatum(java.lang.Object)
org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion$Builder	setJobid	jobid	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion$Builder:setJobid(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion$Builder	setFinishTime	finishTime	J	long	0	org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion$Builder:setFinishTime(long)
org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion$Builder	setFinishedMaps	finishedMaps	J	int	0	org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion$Builder:setFinishedMaps(int)
org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion$Builder	setFinishedReduces	finishedReduces	J	int	0	org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion$Builder:setFinishedReduces(int)
org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion$Builder	setJobStatus	jobStatus	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion$Builder:setJobStatus(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion$Builder	setDiagnostics	diagnostics	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion$Builder:setDiagnostics(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion$Builder	setFailedMaps	failedMaps	J	int	0	org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion$Builder:setFailedMaps(int)
org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion$Builder	setFailedReduces	failedReduces	J	int	0	org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion$Builder:setFailedReduces(int)
org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion$Builder	setKilledMaps	killedMaps	J	int	0	org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion$Builder:setKilledMaps(int)
org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion$Builder	setKilledReduces	killedReduces	J	int	0	org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion$Builder:setKilledReduces(int)
org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion$Builder	setTaskid	taskid	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion$Builder:setTaskid(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion$Builder	setTaskType	taskType	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion$Builder:setTaskType(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion$Builder	setAttemptId	attemptId	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion$Builder:setAttemptId(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion$Builder	setFinishTime	finishTime	J	long	0	org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion$Builder:setFinishTime(long)
org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion$Builder	setHostname	hostname	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion$Builder:setHostname(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion$Builder	setPort	port	J	int	0	org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion$Builder:setPort(int)
org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion$Builder	setRackname	rackname	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion$Builder:setRackname(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion$Builder	setStatus	status	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion$Builder:setStatus(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion$Builder	setError	error	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion$Builder:setError(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion$Builder	setCounters	counters	C	org.apache.hadoop.mapreduce.jobhistory.JhCounters	0	org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion$Builder:setCounters(org.apache.hadoop.mapreduce.jobhistory.JhCounters)
org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion$Builder	setClockSplits	clockSplits	GJ	java.util.List	0	org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion$Builder:setClockSplits(java.util.List)
org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion$Builder	setCpuUsages	cpuUsages	GJ	java.util.List	0	org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion$Builder:setCpuUsages(java.util.List)
org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion$Builder	setVMemKbytes	vMemKbytes	GJ	java.util.List	0	org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion$Builder:setVMemKbytes(java.util.List)
org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion$Builder	setPhysMemKbytes	physMemKbytes	GJ	java.util.List	0	org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion$Builder:setPhysMemKbytes(java.util.List)
org.apache.hadoop.mapreduce.jobhistory.JhCounters	setName	name	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.JhCounters:setName(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.JhCounters	setGroups	groups	GC	java.util.List	0	org.apache.hadoop.mapreduce.jobhistory.JhCounters:setGroups(java.util.List)
org.apache.hadoop.mapreduce.jobhistory.JobInfoChange	setJobid	jobid	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.JobInfoChange:setJobid(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.JobStatusChanged$Builder	setJobid	jobid	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.JobStatusChanged$Builder:setJobid(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.JobStatusChanged$Builder	setJobStatus	jobStatus	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.JobStatusChanged$Builder:setJobStatus(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted	setTaskid	taskid	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted:setTaskid(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted	setTaskType	taskType	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted:setTaskType(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted	setAttemptId	attemptId	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted:setAttemptId(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted	setTrackerName	trackerName	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted:setTrackerName(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted	setContainerId	containerId	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted:setContainerId(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted	setLocality	locality	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted:setLocality(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted	setAvataar	avataar	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted:setAvataar(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStartedEvent	setDatum	datum	C	org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted	0	org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStartedEvent:setDatum(java.lang.Object)
org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished	setTaskid	taskid	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished:setTaskid(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished	setAttemptId	attemptId	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished:setAttemptId(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished	setTaskType	taskType	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished:setTaskType(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished	setTaskStatus	taskStatus	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished:setTaskStatus(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished	setRackname	rackname	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished:setRackname(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished	setHostname	hostname	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished:setHostname(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished	setState	state	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished:setState(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished	setCounters	counters	C	org.apache.hadoop.mapreduce.jobhistory.JhCounters	0	org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished:setCounters(org.apache.hadoop.mapreduce.jobhistory.JhCounters)
org.apache.hadoop.mapreduce.jobhistory.JobQueueChange	setJobid	jobid	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.JobQueueChange:setJobid(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.JobQueueChange	setJobQueueName	jobQueueName	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.JobQueueChange:setJobQueueName(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.JobFinished$Builder	setJobid	jobid	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.JobFinished$Builder:setJobid(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.JobFinished$Builder	setFinishTime	finishTime	J	long	0	org.apache.hadoop.mapreduce.jobhistory.JobFinished$Builder:setFinishTime(long)
org.apache.hadoop.mapreduce.jobhistory.JobFinished$Builder	setFinishedMaps	finishedMaps	J	int	0	org.apache.hadoop.mapreduce.jobhistory.JobFinished$Builder:setFinishedMaps(int)
org.apache.hadoop.mapreduce.jobhistory.JobFinished$Builder	setFinishedReduces	finishedReduces	J	int	0	org.apache.hadoop.mapreduce.jobhistory.JobFinished$Builder:setFinishedReduces(int)
org.apache.hadoop.mapreduce.jobhistory.JobFinished$Builder	setFailedMaps	failedMaps	J	int	0	org.apache.hadoop.mapreduce.jobhistory.JobFinished$Builder:setFailedMaps(int)
org.apache.hadoop.mapreduce.jobhistory.JobFinished$Builder	setFailedReduces	failedReduces	J	int	0	org.apache.hadoop.mapreduce.jobhistory.JobFinished$Builder:setFailedReduces(int)
org.apache.hadoop.mapreduce.jobhistory.JobFinished$Builder	setTotalCounters	totalCounters	C	org.apache.hadoop.mapreduce.jobhistory.JhCounters	0	org.apache.hadoop.mapreduce.jobhistory.JobFinished$Builder:setTotalCounters(org.apache.hadoop.mapreduce.jobhistory.JhCounters)
org.apache.hadoop.mapreduce.jobhistory.JobFinished$Builder	setMapCounters	mapCounters	C	org.apache.hadoop.mapreduce.jobhistory.JhCounters	0	org.apache.hadoop.mapreduce.jobhistory.JobFinished$Builder:setMapCounters(org.apache.hadoop.mapreduce.jobhistory.JhCounters)
org.apache.hadoop.mapreduce.jobhistory.JobFinished$Builder	setReduceCounters	reduceCounters	C	org.apache.hadoop.mapreduce.jobhistory.JhCounters	0	org.apache.hadoop.mapreduce.jobhistory.JobFinished$Builder:setReduceCounters(org.apache.hadoop.mapreduce.jobhistory.JhCounters)
org.apache.hadoop.mapreduce.jobhistory.JobFinished$Builder	setKilledMaps	killedMaps	J	int	0	org.apache.hadoop.mapreduce.jobhistory.JobFinished$Builder:setKilledMaps(int)
org.apache.hadoop.mapreduce.jobhistory.JobFinished$Builder	setKilledReduces	killedReduces	J	int	0	org.apache.hadoop.mapreduce.jobhistory.JobFinished$Builder:setKilledReduces(int)
org.apache.hadoop.mapreduce.jobhistory.JobStatusChangedEvent	setDatum	datum	C	org.apache.hadoop.mapreduce.jobhistory.JobStatusChanged	0	org.apache.hadoop.mapreduce.jobhistory.JobStatusChangedEvent:setDatum(java.lang.Object)
org.apache.hadoop.mapreduce.jobhistory.JhCounter	setName	name	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.JhCounter:setName(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.JhCounter	setDisplayName	displayName	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.JhCounter:setDisplayName(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.JobInited	setJobid	jobid	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.JobInited:setJobid(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.JobInited	setJobStatus	jobStatus	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.JobInited:setJobStatus(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.JobSubmitted	setJobid	jobid	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.JobSubmitted:setJobid(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.JobSubmitted	setJobName	jobName	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.JobSubmitted:setJobName(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.JobSubmitted	setUserName	userName	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.JobSubmitted:setUserName(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.JobSubmitted	setJobConfPath	jobConfPath	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.JobSubmitted:setJobConfPath(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.JobSubmitted	setAcls	acls	GJ	java.util.Map	0	org.apache.hadoop.mapreduce.jobhistory.JobSubmitted:setAcls(java.util.Map)
org.apache.hadoop.mapreduce.jobhistory.JobSubmitted	setJobQueueName	jobQueueName	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.JobSubmitted:setJobQueueName(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.JobSubmitted	setWorkflowId	workflowId	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.JobSubmitted:setWorkflowId(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.JobSubmitted	setWorkflowName	workflowName	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.JobSubmitted:setWorkflowName(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.JobSubmitted	setWorkflowNodeName	workflowNodeName	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.JobSubmitted:setWorkflowNodeName(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.JobSubmitted	setWorkflowAdjacencies	workflowAdjacencies	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.JobSubmitted:setWorkflowAdjacencies(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.JobSubmitted	setWorkflowTags	workflowTags	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.JobSubmitted:setWorkflowTags(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.AMStarted$Builder	setApplicationAttemptId	applicationAttemptId	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.AMStarted$Builder:setApplicationAttemptId(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.AMStarted$Builder	setStartTime	startTime	J	long	0	org.apache.hadoop.mapreduce.jobhistory.AMStarted$Builder:setStartTime(long)
org.apache.hadoop.mapreduce.jobhistory.AMStarted$Builder	setContainerId	containerId	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.AMStarted$Builder:setContainerId(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.AMStarted$Builder	setNodeManagerHost	nodeManagerHost	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.AMStarted$Builder:setNodeManagerHost(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.AMStarted$Builder	setNodeManagerPort	nodeManagerPort	J	int	0	org.apache.hadoop.mapreduce.jobhistory.AMStarted$Builder:setNodeManagerPort(int)
org.apache.hadoop.mapreduce.jobhistory.AMStarted$Builder	setNodeManagerHttpPort	nodeManagerHttpPort	J	int	0	org.apache.hadoop.mapreduce.jobhistory.AMStarted$Builder:setNodeManagerHttpPort(int)
org.apache.hadoop.mapreduce.jobhistory.JobQueueChangeEvent	setDatum	datum	C	org.apache.hadoop.mapreduce.jobhistory.JobQueueChange	0	org.apache.hadoop.mapreduce.jobhistory.JobQueueChangeEvent:setDatum(java.lang.Object)
org.apache.hadoop.mapreduce.jobhistory.TaskStarted$Builder	setTaskid	taskid	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.TaskStarted$Builder:setTaskid(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.TaskStarted$Builder	setTaskType	taskType	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.TaskStarted$Builder:setTaskType(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.TaskStarted$Builder	setStartTime	startTime	J	long	0	org.apache.hadoop.mapreduce.jobhistory.TaskStarted$Builder:setStartTime(long)
org.apache.hadoop.mapreduce.jobhistory.TaskStarted$Builder	setSplitLocations	splitLocations	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.TaskStarted$Builder:setSplitLocations(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.TaskUpdated	setTaskid	taskid	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.TaskUpdated:setTaskid(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.JhCounterGroup$Builder	setName	name	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.JhCounterGroup$Builder:setName(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.JhCounterGroup$Builder	setDisplayName	displayName	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.JhCounterGroup$Builder:setDisplayName(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.JhCounterGroup$Builder	setCounts	counts	GC	java.util.List	0	org.apache.hadoop.mapreduce.jobhistory.JhCounterGroup$Builder:setCounts(java.util.List)
org.apache.hadoop.mapreduce.jobhistory.JobPriorityChange	setJobid	jobid	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.JobPriorityChange:setJobid(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.JobPriorityChange	setPriority	priority	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.JobPriorityChange:setPriority(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.TaskStartedEvent	setDatum	datum	C	org.apache.hadoop.mapreduce.jobhistory.TaskStarted	0	org.apache.hadoop.mapreduce.jobhistory.TaskStartedEvent:setDatum(java.lang.Object)
org.apache.hadoop.mapreduce.jobhistory.JobInfoChangeEvent	setDatum	datum	C	org.apache.hadoop.mapreduce.jobhistory.JobInfoChange	0	org.apache.hadoop.mapreduce.jobhistory.JobInfoChangeEvent:setDatum(java.lang.Object)
org.apache.hadoop.mapreduce.jobhistory.TaskFinished$Builder	setTaskid	taskid	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.TaskFinished$Builder:setTaskid(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.TaskFinished$Builder	setTaskType	taskType	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.TaskFinished$Builder:setTaskType(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.TaskFinished$Builder	setFinishTime	finishTime	J	long	0	org.apache.hadoop.mapreduce.jobhistory.TaskFinished$Builder:setFinishTime(long)
org.apache.hadoop.mapreduce.jobhistory.TaskFinished$Builder	setStatus	status	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.TaskFinished$Builder:setStatus(java.lang.CharSequence)
org.apache.hadoop.mapreduce.jobhistory.TaskFinished$Builder	setCounters	counters	C	org.apache.hadoop.mapreduce.jobhistory.JhCounters	0	org.apache.hadoop.mapreduce.jobhistory.TaskFinished$Builder:setCounters(org.apache.hadoop.mapreduce.jobhistory.JhCounters)
org.apache.hadoop.mapreduce.jobhistory.TaskFinished$Builder	setSuccessfulAttemptId	successfulAttemptId	J	java.lang.CharSequence	0	org.apache.hadoop.mapreduce.jobhistory.TaskFinished$Builder:setSuccessfulAttemptId(java.lang.CharSequence)
org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager	setMaxHistoryAge	maxHistoryAge	J	long	0	org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager:setMaxHistoryAge(long)
org.apache.hadoop.mapreduce.v2.hs.server.HSAdminServer	setLoginUGI	loginUGI	C	org.apache.hadoop.security.UserGroupInformation	0	org.apache.hadoop.mapreduce.v2.hs.server.HSAdminServer:setLoginUGI(org.apache.hadoop.security.UserGroupInformation)
org.apache.hadoop.mapreduce.v2.hs.webapp.HsWebServices	setResponse	response	J	javax.servlet.http.HttpServletResponse	0	org.apache.hadoop.mapreduce.v2.hs.webapp.HsWebServices:setResponse(javax.servlet.http.HttpServletResponse)
org.apache.hadoop.mapreduce.v2.hs.webapp.HsWebServices	setLogServlet	logServlet	C	org.apache.hadoop.yarn.server.webapp.LogServlet	0	org.apache.hadoop.mapreduce.v2.hs.webapp.HsWebServices:setLogServlet(org.apache.hadoop.yarn.server.webapp.LogServlet)
org.apache.hadoop.mapreduce.v2.hs.CachedHistoryStorage	setHistoryFileManager	hsManager	C	org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager	0	org.apache.hadoop.mapreduce.v2.hs.CachedHistoryStorage:setHistoryFileManager(org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager)
org.apache.hadoop.mapred.YARNRunner	setResourceMgrDelegate	resMgrDelegate	C	org.apache.hadoop.mapred.ResourceMgrDelegate	0	org.apache.hadoop.mapred.YARNRunner:setResourceMgrDelegate(org.apache.hadoop.mapred.ResourceMgrDelegate)
org.apache.hadoop.mapred.nativetask.TaskContext	setInputKeyClass	iKClass	GC	java.lang.Class	0	org.apache.hadoop.mapred.nativetask.TaskContext:setInputKeyClass(java.lang.Class)
org.apache.hadoop.mapred.nativetask.TaskContext	setInputValueClass	iVClass	GC	java.lang.Class	0	org.apache.hadoop.mapred.nativetask.TaskContext:setInputValueClass(java.lang.Class)
org.apache.hadoop.mapred.nativetask.TaskContext	setOutputKeyClass	oKClass	GC	java.lang.Class	0	org.apache.hadoop.mapred.nativetask.TaskContext:setOutputKeyClass(java.lang.Class)
org.apache.hadoop.mapred.nativetask.TaskContext	setOutputValueClass	oVClass	GC	java.lang.Class	0	org.apache.hadoop.mapred.nativetask.TaskContext:setOutputValueClass(java.lang.Class)
org.apache.hadoop.mapred.nativetask.NativeBatchProcessor	setCommandDispatcher	commandDispatcher	C	org.apache.hadoop.mapred.nativetask.CommandDispatcher	0	org.apache.hadoop.mapred.nativetask.NativeBatchProcessor:setCommandDispatcher(org.apache.hadoop.mapred.nativetask.CommandDispatcher)
org.apache.hadoop.mapred.nativetask.NativeBatchProcessor	setDataReceiver	dataReceiver	C	org.apache.hadoop.mapred.nativetask.DataReceiver	0	org.apache.hadoop.mapred.nativetask.NativeBatchProcessor:setDataReceiver(org.apache.hadoop.mapred.nativetask.DataReceiver)
org.apache.hadoop.mapred.nativetask.util.ReadWriteBuffer	setReadPoint	_readPoint	J	int	0	org.apache.hadoop.mapred.nativetask.util.ReadWriteBuffer:setReadPoint(int)
org.apache.hadoop.mapred.nativetask.util.ReadWriteBuffer	setWritePoint	_writePoint	J	int	0	org.apache.hadoop.mapred.nativetask.util.ReadWriteBuffer:setWritePoint(int)
org.apache.hadoop.mapred.proto.ShuffleHandlerRecoveryProtos$JobShuffleInfoProto$Builder	setUser	user_	J	java.lang.Object	0	org.apache.hadoop.mapred.proto.ShuffleHandlerRecoveryProtos$JobShuffleInfoProto$Builder:setUser(java.lang.String)
org.apache.hadoop.mapred.proto.ShuffleHandlerRecoveryProtos$JobShuffleInfoProto$Builder	setUserBytes	user_	J	java.lang.Object	0	org.apache.hadoop.mapred.proto.ShuffleHandlerRecoveryProtos$JobShuffleInfoProto$Builder:setUserBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.mapred.ShuffleHandler$TimeoutHandler	setEnabledTimeout	enabledTimeout	J	boolean	0	org.apache.hadoop.mapred.ShuffleHandler$TimeoutHandler:setEnabledTimeout(boolean)
org.apache.hadoop.mapred.ShuffleHandler$Shuffle	setPort	port	J	int	0	org.apache.hadoop.mapred.ShuffleHandler$Shuffle:setPort(int)
org.apache.hadoop.mapred.uploader.FrameworkUploader	setConf	conf	C	org.apache.hadoop.conf.Configuration	0	org.apache.hadoop.mapred.uploader.FrameworkUploader:setConf(org.apache.hadoop.conf.Configuration)
org.apache.hadoop.examples.dancing.Pentomino	setPrinter	printer	GC	org.apache.hadoop.examples.dancing.DancingLinks$SolutionAcceptor	0	org.apache.hadoop.examples.dancing.Pentomino:setPrinter(org.apache.hadoop.examples.dancing.DancingLinks$SolutionAcceptor)
org.apache.hadoop.examples.terasort.Unsigned16	set	lo8	J	long	0	org.apache.hadoop.examples.terasort.Unsigned16:set(long)
org.apache.hadoop.examples.terasort.TeraSort$SimplePartitioner	setConf	conf	C	org.apache.hadoop.conf.Configuration	0	org.apache.hadoop.examples.terasort.TeraSort$SimplePartitioner:setConf(org.apache.hadoop.conf.Configuration)
org.apache.hadoop.examples.pi.DistSum	setParameters	parameters	C	org.apache.hadoop.examples.pi.DistSum$Parameters	0	org.apache.hadoop.examples.pi.DistSum:setParameters(org.apache.hadoop.examples.pi.DistSum$Parameters)
org.apache.hadoop.fs.aliyun.oss.AliyunOSSFileSystem	setWorkingDirectory	workingDir	C	org.apache.hadoop.fs.Path	0	org.apache.hadoop.fs.aliyun.oss.AliyunOSSFileSystem:setWorkingDirectory(org.apache.hadoop.fs.Path)
org.apache.hadoop.fs.aliyun.oss.ReadBuffer	setStatus	status	C	org.apache.hadoop.fs.aliyun.oss.ReadBuffer$STATUS	0	org.apache.hadoop.fs.aliyun.oss.ReadBuffer:setStatus(org.apache.hadoop.fs.aliyun.oss.ReadBuffer$STATUS)
org.apache.hadoop.fs.aliyun.oss.AliyunCredentialsProvider	setCredentials	credentials	C	com.aliyun.oss.common.auth.Credentials	0	org.apache.hadoop.fs.aliyun.oss.AliyunCredentialsProvider:setCredentials(com.aliyun.oss.common.auth.Credentials)
org.apache.hadoop.fs.aliyun.oss.AliyunOSSCopyFileContext	setCopyFailure	copyFailure	J	boolean	0	org.apache.hadoop.fs.aliyun.oss.AliyunOSSCopyFileContext:setCopyFailure(boolean)
org.apache.hadoop.tools.HadoopArchiveLogs$AppInfo	setAppId	appId	J	java.lang.String	0	org.apache.hadoop.tools.HadoopArchiveLogs$AppInfo:setAppId(java.lang.String)
org.apache.hadoop.tools.HadoopArchiveLogs$AppInfo	setRemoteRootLogDir	remoteRootLogDir	C	org.apache.hadoop.fs.Path	0	org.apache.hadoop.tools.HadoopArchiveLogs$AppInfo:setRemoteRootLogDir(org.apache.hadoop.fs.Path)
org.apache.hadoop.tools.HadoopArchiveLogs$AppInfo	setSuffix	suffix	J	java.lang.String	0	org.apache.hadoop.tools.HadoopArchiveLogs$AppInfo:setSuffix(java.lang.String)
org.apache.hadoop.tools.HadoopArchiveLogs$AppInfo	setWorkingDir	workingDir	C	org.apache.hadoop.fs.Path	0	org.apache.hadoop.tools.HadoopArchiveLogs$AppInfo:setWorkingDir(org.apache.hadoop.fs.Path)
org.apache.hadoop.tools.HadoopArchiveLogs$AppInfo	setUser	user	J	java.lang.String	0	org.apache.hadoop.tools.HadoopArchiveLogs$AppInfo:setUser(java.lang.String)
org.apache.hadoop.tools.HadoopArchiveLogs$AppInfo	setFinishTime	finishTime	J	long	0	org.apache.hadoop.tools.HadoopArchiveLogs$AppInfo:setFinishTime(long)
org.apache.hadoop.tools.HadoopArchiveLogs	setConf	conf	C	org.apache.hadoop.mapred.JobConf	0	org.apache.hadoop.tools.HadoopArchiveLogs:setConf(org.apache.hadoop.conf.Configuration)
org.apache.hadoop.tools.HadoopArchiveLogsRunner	setConf	conf	C	org.apache.hadoop.mapred.JobConf	0	org.apache.hadoop.tools.HadoopArchiveLogsRunner:setConf(org.apache.hadoop.conf.Configuration)
org.apache.hadoop.tools.HadoopArchives$FileStatusDir	setChildren	children	C	org.apache.hadoop.fs.FileStatus	1	org.apache.hadoop.tools.HadoopArchives$FileStatusDir:setChildren(org.apache.hadoop.fs.FileStatus[])
org.apache.hadoop.fs.s3a.S3AFileStatus	setIsEmptyDirectory	isEmptyDirectory	C	org.apache.hadoop.fs.s3a.Tristate	0	org.apache.hadoop.fs.s3a.S3AFileStatus:setIsEmptyDirectory(org.apache.hadoop.fs.s3a.Tristate)
org.apache.hadoop.fs.s3a.S3AFileStatus	setVersionId	versionId	J	java.lang.String	0	org.apache.hadoop.fs.s3a.S3AFileStatus:setVersionId(java.lang.String)
org.apache.hadoop.fs.s3a.tools.MarkerTool	setVerbose	verbose	J	boolean	0	org.apache.hadoop.fs.s3a.tools.MarkerTool:setVerbose(boolean)
org.apache.hadoop.fs.s3a.FailureInjectionPolicy	setFailureLimit	failureLimit	J	int	0	org.apache.hadoop.fs.s3a.FailureInjectionPolicy:setFailureLimit(int)
org.apache.hadoop.fs.s3a.FailureInjectionPolicy	setThrottleProbability	throttleProbability	J	float	0	org.apache.hadoop.fs.s3a.FailureInjectionPolicy:setThrottleProbability(float)
org.apache.hadoop.fs.s3a.prefetch.S3ARemoteInputStream	setInputPolicy	inputPolicy	C	org.apache.hadoop.fs.s3a.S3AInputPolicy	0	org.apache.hadoop.fs.s3a.prefetch.S3ARemoteInputStream:setInputPolicy(org.apache.hadoop.fs.s3a.S3AInputPolicy)
org.apache.hadoop.fs.s3a.commit.AbstractS3ACommitter	setOutputPath	outputPath	C	org.apache.hadoop.fs.Path	0	org.apache.hadoop.fs.s3a.commit.AbstractS3ACommitter:setOutputPath(org.apache.hadoop.fs.Path)
org.apache.hadoop.fs.s3a.commit.AbstractS3ACommitter	setWorkPath	workPath	C	org.apache.hadoop.fs.Path	0	org.apache.hadoop.fs.s3a.commit.AbstractS3ACommitter:setWorkPath(org.apache.hadoop.fs.Path)
org.apache.hadoop.fs.s3a.commit.AbstractS3ACommitter	setConf	conf	C	org.apache.hadoop.conf.Configuration	0	org.apache.hadoop.fs.s3a.commit.AbstractS3ACommitter:setConf(org.apache.hadoop.conf.Configuration)
org.apache.hadoop.fs.s3a.commit.AbstractS3ACommitter	setDestFS	destFS	C	org.apache.hadoop.fs.FileSystem	0	org.apache.hadoop.fs.s3a.commit.AbstractS3ACommitter:setDestFS(org.apache.hadoop.fs.FileSystem)
org.apache.hadoop.fs.s3a.commit.files.SuccessData	setName	name	J	java.lang.String	0	org.apache.hadoop.fs.s3a.commit.files.SuccessData:setName(java.lang.String)
org.apache.hadoop.fs.s3a.commit.files.SuccessData	setTimestamp	timestamp	J	long	0	org.apache.hadoop.fs.s3a.commit.files.SuccessData:setTimestamp(long)
org.apache.hadoop.fs.s3a.commit.files.SuccessData	setDate	date	J	java.lang.String	0	org.apache.hadoop.fs.s3a.commit.files.SuccessData:setDate(java.lang.String)
org.apache.hadoop.fs.s3a.commit.files.SuccessData	setHostname	hostname	J	java.lang.String	0	org.apache.hadoop.fs.s3a.commit.files.SuccessData:setHostname(java.lang.String)
org.apache.hadoop.fs.s3a.commit.files.SuccessData	setCommitter	committer	J	java.lang.String	0	org.apache.hadoop.fs.s3a.commit.files.SuccessData:setCommitter(java.lang.String)
org.apache.hadoop.fs.s3a.commit.files.SuccessData	setDescription	description	J	java.lang.String	0	org.apache.hadoop.fs.s3a.commit.files.SuccessData:setDescription(java.lang.String)
org.apache.hadoop.fs.s3a.commit.files.SuccessData	setMetrics	metrics	GJ	java.util.Map	0	org.apache.hadoop.fs.s3a.commit.files.SuccessData:setMetrics(java.util.Map)
org.apache.hadoop.fs.s3a.commit.files.SuccessData	setFilenames	filenames	GJ	java.util.List	0	org.apache.hadoop.fs.s3a.commit.files.SuccessData:setFilenames(java.util.List)
org.apache.hadoop.fs.s3a.commit.files.SuccessData	setDiagnostics	diagnostics	GJ	java.util.Map	0	org.apache.hadoop.fs.s3a.commit.files.SuccessData:setDiagnostics(java.util.Map)
org.apache.hadoop.fs.s3a.commit.files.SuccessData	setJobId	jobId	J	java.lang.String	0	org.apache.hadoop.fs.s3a.commit.files.SuccessData:setJobId(java.lang.String)
org.apache.hadoop.fs.s3a.commit.files.SuccessData	setJobIdSource	jobIdSource	J	java.lang.String	0	org.apache.hadoop.fs.s3a.commit.files.SuccessData:setJobIdSource(java.lang.String)
org.apache.hadoop.fs.s3a.commit.files.SuccessData	setIOStatistics	iostatistics	C	org.apache.hadoop.fs.statistics.IOStatisticsSnapshot	0	org.apache.hadoop.fs.s3a.commit.files.SuccessData:setIOStatistics(org.apache.hadoop.fs.statistics.IOStatisticsSnapshot)
org.apache.hadoop.fs.s3a.commit.files.SuccessData	setSuccess	success	J	boolean	0	org.apache.hadoop.fs.s3a.commit.files.SuccessData:setSuccess(boolean)
org.apache.hadoop.fs.s3a.commit.files.SuccessData	setState	state	J	java.lang.String	0	org.apache.hadoop.fs.s3a.commit.files.SuccessData:setState(java.lang.String)
org.apache.hadoop.fs.s3a.commit.files.PendingSet	setVersion	version	J	int	0	org.apache.hadoop.fs.s3a.commit.files.PendingSet:setVersion(int)
org.apache.hadoop.fs.s3a.commit.files.PendingSet	setCommits	commits	GC	java.util.List	0	org.apache.hadoop.fs.s3a.commit.files.PendingSet:setCommits(java.util.List)
org.apache.hadoop.fs.s3a.commit.files.PendingSet	setJobId	jobId	J	java.lang.String	0	org.apache.hadoop.fs.s3a.commit.files.PendingSet:setJobId(java.lang.String)
org.apache.hadoop.fs.s3a.commit.files.PendingSet	setIOStatistics	iostats	C	org.apache.hadoop.fs.statistics.IOStatisticsSnapshot	0	org.apache.hadoop.fs.s3a.commit.files.PendingSet:setIOStatistics(org.apache.hadoop.fs.statistics.IOStatisticsSnapshot)
org.apache.hadoop.fs.s3a.commit.files.SinglePendingCommit	setVersion	version	J	int	0	org.apache.hadoop.fs.s3a.commit.files.SinglePendingCommit:setVersion(int)
org.apache.hadoop.fs.s3a.commit.files.SinglePendingCommit	setFilename	filename	J	java.lang.String	0	org.apache.hadoop.fs.s3a.commit.files.SinglePendingCommit:setFilename(java.lang.String)
org.apache.hadoop.fs.s3a.commit.files.SinglePendingCommit	setUri	uri	J	java.lang.String	0	org.apache.hadoop.fs.s3a.commit.files.SinglePendingCommit:setUri(java.lang.String)
org.apache.hadoop.fs.s3a.commit.files.SinglePendingCommit	setUploadId	uploadId	J	java.lang.String	0	org.apache.hadoop.fs.s3a.commit.files.SinglePendingCommit:setUploadId(java.lang.String)
org.apache.hadoop.fs.s3a.commit.files.SinglePendingCommit	setBucket	bucket	J	java.lang.String	0	org.apache.hadoop.fs.s3a.commit.files.SinglePendingCommit:setBucket(java.lang.String)
org.apache.hadoop.fs.s3a.commit.files.SinglePendingCommit	setDestinationKey	destinationKey	J	java.lang.String	0	org.apache.hadoop.fs.s3a.commit.files.SinglePendingCommit:setDestinationKey(java.lang.String)
org.apache.hadoop.fs.s3a.commit.files.SinglePendingCommit	setCreated	created	J	long	0	org.apache.hadoop.fs.s3a.commit.files.SinglePendingCommit:setCreated(long)
org.apache.hadoop.fs.s3a.commit.files.SinglePendingCommit	setSaved	saved	J	long	0	org.apache.hadoop.fs.s3a.commit.files.SinglePendingCommit:setSaved(long)
org.apache.hadoop.fs.s3a.commit.files.SinglePendingCommit	setDate	date	J	java.lang.String	0	org.apache.hadoop.fs.s3a.commit.files.SinglePendingCommit:setDate(java.lang.String)
org.apache.hadoop.fs.s3a.commit.files.SinglePendingCommit	setJobId	jobId	J	java.lang.String	0	org.apache.hadoop.fs.s3a.commit.files.SinglePendingCommit:setJobId(java.lang.String)
org.apache.hadoop.fs.s3a.commit.files.SinglePendingCommit	setTaskId	taskId	J	java.lang.String	0	org.apache.hadoop.fs.s3a.commit.files.SinglePendingCommit:setTaskId(java.lang.String)
org.apache.hadoop.fs.s3a.commit.files.SinglePendingCommit	setText	text	J	java.lang.String	0	org.apache.hadoop.fs.s3a.commit.files.SinglePendingCommit:setText(java.lang.String)
org.apache.hadoop.fs.s3a.commit.files.SinglePendingCommit	setEtags	etags	GJ	java.util.List	0	org.apache.hadoop.fs.s3a.commit.files.SinglePendingCommit:setEtags(java.util.List)
org.apache.hadoop.fs.s3a.commit.files.SinglePendingCommit	setExtraData	extraData	GJ	java.util.Map	0	org.apache.hadoop.fs.s3a.commit.files.SinglePendingCommit:setExtraData(java.util.Map)
org.apache.hadoop.fs.s3a.commit.files.SinglePendingCommit	setLength	length	J	long	0	org.apache.hadoop.fs.s3a.commit.files.SinglePendingCommit:setLength(long)
org.apache.hadoop.fs.s3a.commit.files.SinglePendingCommit	setIOStatistics	iostats	C	org.apache.hadoop.fs.statistics.IOStatisticsSnapshot	0	org.apache.hadoop.fs.s3a.commit.files.SinglePendingCommit:setIOStatistics(org.apache.hadoop.fs.statistics.IOStatisticsSnapshot)
org.apache.hadoop.fs.s3a.auth.MarshalledCredentials	setExpiration	expiration	J	long	0	org.apache.hadoop.fs.s3a.auth.MarshalledCredentials:setExpiration(long)
org.apache.hadoop.fs.s3a.auth.MarshalledCredentials	setRoleARN	roleARN	J	java.lang.String	0	org.apache.hadoop.fs.s3a.auth.MarshalledCredentials:setRoleARN(java.lang.String)
org.apache.hadoop.fs.s3a.auth.MarshalledCredentials	setAccessKey	accessKey	J	java.lang.String	0	org.apache.hadoop.fs.s3a.auth.MarshalledCredentials:setAccessKey(java.lang.String)
org.apache.hadoop.fs.s3a.auth.MarshalledCredentials	setSecretKey	secretKey	J	java.lang.String	0	org.apache.hadoop.fs.s3a.auth.MarshalledCredentials:setSecretKey(java.lang.String)
org.apache.hadoop.fs.s3a.auth.MarshalledCredentials	setSessionToken	sessionToken	J	java.lang.String	0	org.apache.hadoop.fs.s3a.auth.MarshalledCredentials:setSessionToken(java.lang.String)
org.apache.hadoop.fs.s3a.auth.delegation.SessionTokenBinding	setExpirationDateTime	expirationDateTime	GJ	java.util.Optional	0	org.apache.hadoop.fs.s3a.auth.delegation.SessionTokenBinding:setExpirationDateTime(java.util.Optional)
org.apache.hadoop.fs.s3a.auth.delegation.SessionTokenBinding	setTokenIdentifier	tokenIdentifier	GC	java.util.Optional	0	org.apache.hadoop.fs.s3a.auth.delegation.SessionTokenBinding:setTokenIdentifier(java.util.Optional)
org.apache.hadoop.fs.s3a.auth.delegation.AbstractS3ATokenIdentifier	setOrigin	origin	J	java.lang.String	0	org.apache.hadoop.fs.s3a.auth.delegation.AbstractS3ATokenIdentifier:setOrigin(java.lang.String)
org.apache.hadoop.fs.s3a.statistics.impl.AbstractS3AStatisticsSource	setIOStatistics	ioStatistics	C	org.apache.hadoop.fs.statistics.impl.IOStatisticsStore	0	org.apache.hadoop.fs.s3a.statistics.impl.AbstractS3AStatisticsSource:setIOStatistics(org.apache.hadoop.fs.statistics.impl.IOStatisticsStore)
org.apache.hadoop.fs.s3a.S3AFileSystem	setEncryptionSecrets	encryptionSecrets	C	org.apache.hadoop.fs.s3a.auth.delegation.EncryptionSecrets	0	org.apache.hadoop.fs.s3a.S3AFileSystem:setEncryptionSecrets(org.apache.hadoop.fs.s3a.auth.delegation.EncryptionSecrets)
org.apache.hadoop.fs.s3a.S3AFileSystem	setAmazonS3Client	s3	C	com.amazonaws.services.s3.AmazonS3	0	org.apache.hadoop.fs.s3a.S3AFileSystem:setAmazonS3Client(com.amazonaws.services.s3.AmazonS3)
org.apache.hadoop.fs.s3a.S3AFileSystem	setBucket	bucket	J	java.lang.String	0	org.apache.hadoop.fs.s3a.S3AFileSystem:setBucket(java.lang.String)
org.apache.hadoop.fs.s3a.S3AFileSystem	setWorkingDirectory	workingDir	C	org.apache.hadoop.fs.Path	0	org.apache.hadoop.fs.s3a.S3AFileSystem:setWorkingDirectory(org.apache.hadoop.fs.Path)
org.apache.hadoop.fs.s3a.impl.RequestFactoryImpl	setEncryptionSecrets	encryptionSecrets	C	org.apache.hadoop.fs.s3a.auth.delegation.EncryptionSecrets	0	org.apache.hadoop.fs.s3a.impl.RequestFactoryImpl:setEncryptionSecrets(org.apache.hadoop.fs.s3a.auth.delegation.EncryptionSecrets)
org.apache.hadoop.fs.s3a.impl.StoreContextBuilder	setFsURI	fsURI	J	java.net.URI	0	org.apache.hadoop.fs.s3a.impl.StoreContextBuilder:setFsURI(java.net.URI)
org.apache.hadoop.fs.s3a.impl.StoreContextBuilder	setBucket	bucket	J	java.lang.String	0	org.apache.hadoop.fs.s3a.impl.StoreContextBuilder:setBucket(java.lang.String)
org.apache.hadoop.fs.s3a.impl.StoreContextBuilder	setConfiguration	configuration	C	org.apache.hadoop.conf.Configuration	0	org.apache.hadoop.fs.s3a.impl.StoreContextBuilder:setConfiguration(org.apache.hadoop.conf.Configuration)
org.apache.hadoop.fs.s3a.impl.StoreContextBuilder	setUsername	username	J	java.lang.String	0	org.apache.hadoop.fs.s3a.impl.StoreContextBuilder:setUsername(java.lang.String)
org.apache.hadoop.fs.s3a.impl.StoreContextBuilder	setOwner	owner	C	org.apache.hadoop.security.UserGroupInformation	0	org.apache.hadoop.fs.s3a.impl.StoreContextBuilder:setOwner(org.apache.hadoop.security.UserGroupInformation)
org.apache.hadoop.fs.s3a.impl.StoreContextBuilder	setExecutor	executor	J	java.util.concurrent.ExecutorService	0	org.apache.hadoop.fs.s3a.impl.StoreContextBuilder:setExecutor(java.util.concurrent.ExecutorService)
org.apache.hadoop.fs.s3a.impl.StoreContextBuilder	setExecutorCapacity	executorCapacity	J	int	0	org.apache.hadoop.fs.s3a.impl.StoreContextBuilder:setExecutorCapacity(int)
org.apache.hadoop.fs.s3a.impl.StoreContextBuilder	setInvoker	invoker	C	org.apache.hadoop.fs.s3a.Invoker	0	org.apache.hadoop.fs.s3a.impl.StoreContextBuilder:setInvoker(org.apache.hadoop.fs.s3a.Invoker)
org.apache.hadoop.fs.s3a.impl.StoreContextBuilder	setInstrumentation	instrumentation	C	org.apache.hadoop.fs.s3a.statistics.S3AStatisticsContext	0	org.apache.hadoop.fs.s3a.impl.StoreContextBuilder:setInstrumentation(org.apache.hadoop.fs.s3a.statistics.S3AStatisticsContext)
org.apache.hadoop.fs.s3a.impl.StoreContextBuilder	setStorageStatistics	storageStatistics	C	org.apache.hadoop.fs.s3a.S3AStorageStatistics	0	org.apache.hadoop.fs.s3a.impl.StoreContextBuilder:setStorageStatistics(org.apache.hadoop.fs.s3a.S3AStorageStatistics)
org.apache.hadoop.fs.s3a.impl.StoreContextBuilder	setInputPolicy	inputPolicy	C	org.apache.hadoop.fs.s3a.S3AInputPolicy	0	org.apache.hadoop.fs.s3a.impl.StoreContextBuilder:setInputPolicy(org.apache.hadoop.fs.s3a.S3AInputPolicy)
org.apache.hadoop.fs.s3a.impl.StoreContextBuilder	setChangeDetectionPolicy	changeDetectionPolicy	C	org.apache.hadoop.fs.s3a.impl.ChangeDetectionPolicy	0	org.apache.hadoop.fs.s3a.impl.StoreContextBuilder:setChangeDetectionPolicy(org.apache.hadoop.fs.s3a.impl.ChangeDetectionPolicy)
org.apache.hadoop.fs.s3a.impl.StoreContextBuilder	setMultiObjectDeleteEnabled	multiObjectDeleteEnabled	J	boolean	0	org.apache.hadoop.fs.s3a.impl.StoreContextBuilder:setMultiObjectDeleteEnabled(boolean)
org.apache.hadoop.fs.s3a.impl.StoreContextBuilder	setUseListV1	useListV1	J	boolean	0	org.apache.hadoop.fs.s3a.impl.StoreContextBuilder:setUseListV1(boolean)
org.apache.hadoop.fs.s3a.impl.StoreContextBuilder	setContextAccessors	contextAccessors	C	org.apache.hadoop.fs.s3a.impl.ContextAccessors	0	org.apache.hadoop.fs.s3a.impl.StoreContextBuilder:setContextAccessors(org.apache.hadoop.fs.s3a.impl.ContextAccessors)
org.apache.hadoop.fs.s3a.impl.StoreContextBuilder	setAuditor	auditor	GC	org.apache.hadoop.fs.store.audit.AuditSpanSource	0	org.apache.hadoop.fs.s3a.impl.StoreContextBuilder:setAuditor(org.apache.hadoop.fs.store.audit.AuditSpanSource)
org.apache.hadoop.fs.s3a.impl.StoreContextBuilder	setEnableCSE	isCSEEnabled	J	boolean	0	org.apache.hadoop.fs.s3a.impl.StoreContextBuilder:setEnableCSE(boolean)
org.apache.hadoop.fs.s3a.S3AInputStream	setInputPolicy	inputPolicy	C	org.apache.hadoop.fs.s3a.S3AInputPolicy	0	org.apache.hadoop.fs.s3a.S3AInputStream:setInputPolicy(org.apache.hadoop.fs.s3a.S3AInputPolicy)
org.apache.hadoop.fs.s3a.VectoredIOContext	setMinSeekForVectoredReads	minSeekForVectorReads	J	int	0	org.apache.hadoop.fs.s3a.VectoredIOContext:setMinSeekForVectoredReads(int)
org.apache.hadoop.fs.s3a.VectoredIOContext	setMaxReadSizeForVectoredReads	maxReadSizeForVectorReads	J	int	0	org.apache.hadoop.fs.s3a.VectoredIOContext:setMaxReadSizeForVectoredReads(int)
org.apache.hadoop.fs.s3a.audit.impl.LoggingAuditor	setLastHeader	lastHeader	J	java.lang.String	0	org.apache.hadoop.fs.s3a.audit.impl.LoggingAuditor:setLastHeader(java.lang.String)
org.apache.hadoop.fs.s3a.audit.impl.ActiveAuditManagerS3A	setUnbondedSpan	unbondedSpan	C	org.apache.hadoop.fs.s3a.audit.impl.ActiveAuditManagerS3A$WrappingAuditSpan	0	org.apache.hadoop.fs.s3a.audit.impl.ActiveAuditManagerS3A:setUnbondedSpan(org.apache.hadoop.fs.s3a.audit.impl.ActiveAuditManagerS3A$WrappingAuditSpan)
org.apache.hadoop.fs.adl.AdlFileSystem	setWorkingDirectory	workingDirectory	C	org.apache.hadoop.fs.Path	0	org.apache.hadoop.fs.adl.AdlFileSystem:setWorkingDirectory(org.apache.hadoop.fs.Path)
org.apache.hadoop.fs.azure.RemoteSASKeyGenerationResponse	setResponseCode	responseCode	J	int	0	org.apache.hadoop.fs.azure.RemoteSASKeyGenerationResponse:setResponseCode(int)
org.apache.hadoop.fs.azure.RemoteSASKeyGenerationResponse	setResponseMessage	responseMessage	J	java.lang.String	0	org.apache.hadoop.fs.azure.RemoteSASKeyGenerationResponse:setResponseMessage(java.lang.String)
org.apache.hadoop.fs.azure.RemoteSASKeyGenerationResponse	setSasKey	sasKey	J	java.lang.String	0	org.apache.hadoop.fs.azure.RemoteSASKeyGenerationResponse:setSasKey(java.lang.String)
org.apache.hadoop.fs.azure.NativeAzureFileSystem$NativeAzureFsOutputStream	setKey	key	J	java.lang.String	0	org.apache.hadoop.fs.azure.NativeAzureFileSystem$NativeAzureFsOutputStream:setKey(java.lang.String)
org.apache.hadoop.fs.azure.NativeAzureFileSystem$NativeAzureFsOutputStream	setEncodedKey	keyEncoded	J	java.lang.String	0	org.apache.hadoop.fs.azure.NativeAzureFileSystem$NativeAzureFsOutputStream:setEncodedKey(java.lang.String)
org.apache.hadoop.fs.azure.AzureNativeFileSystemStore	setAzureStorageInteractionLayer	storageInteractionLayer	C	org.apache.hadoop.fs.azure.StorageInterface	0	org.apache.hadoop.fs.azure.AzureNativeFileSystemStore:setAzureStorageInteractionLayer(org.apache.hadoop.fs.azure.StorageInterface)
org.apache.hadoop.fs.azure.StorageInterfaceImpl	setRetryPolicyFactory	retryPolicyFactory	C	com.microsoft.azure.storage.RetryPolicyFactory	0	org.apache.hadoop.fs.azure.StorageInterfaceImpl:setRetryPolicyFactory(com.microsoft.azure.storage.RetryPolicyFactory)
org.apache.hadoop.fs.azure.StorageInterfaceImpl	setTimeoutInMs	timeoutIntervalInMs	J	int	0	org.apache.hadoop.fs.azure.StorageInterfaceImpl:setTimeoutInMs(int)
org.apache.hadoop.fs.azure.NativeAzureFileSystem	setWorkingDirectory	workingDir	C	org.apache.hadoop.fs.Path	0	org.apache.hadoop.fs.azure.NativeAzureFileSystem:setWorkingDirectory(org.apache.hadoop.fs.Path)
org.apache.hadoop.fs.azure.SecureWasbRemoteCallHelper	setDelegationToken	delegationToken	GC	org.apache.hadoop.security.token.Token	0	org.apache.hadoop.fs.azure.SecureWasbRemoteCallHelper:setDelegationToken(org.apache.hadoop.security.token.Token)
org.apache.hadoop.fs.azure.SecureStorageInterfaceImpl	setTimeoutInMs	timeoutIntervalInMs	J	int	0	org.apache.hadoop.fs.azure.SecureStorageInterfaceImpl:setTimeoutInMs(int)
org.apache.hadoop.fs.azure.SecureStorageInterfaceImpl	setRetryPolicyFactory	retryPolicy	C	com.microsoft.azure.storage.RetryPolicyFactory	0	org.apache.hadoop.fs.azure.SecureStorageInterfaceImpl:setRetryPolicyFactory(com.microsoft.azure.storage.RetryPolicyFactory)
org.apache.hadoop.fs.azure.SecureStorageInterfaceImpl	setStorageAccountName	storageAccount	J	java.lang.String	0	org.apache.hadoop.fs.azure.SecureStorageInterfaceImpl:setStorageAccountName(java.lang.String)
org.apache.hadoop.fs.azure.WasbFsck	setMockFileSystemForTesting	mockFileSystemForTesting	C	org.apache.hadoop.fs.FileSystem	0	org.apache.hadoop.fs.azure.WasbFsck:setMockFileSystemForTesting(org.apache.hadoop.fs.FileSystem)
org.apache.hadoop.fs.azure.RemoteWasbAuthorizerResponse	setResponseCode	responseCode	J	int	0	org.apache.hadoop.fs.azure.RemoteWasbAuthorizerResponse:setResponseCode(int)
org.apache.hadoop.fs.azure.RemoteWasbAuthorizerResponse	setAuthorizationResult	authorizationResult	J	boolean	0	org.apache.hadoop.fs.azure.RemoteWasbAuthorizerResponse:setAuthorizationResult(boolean)
org.apache.hadoop.fs.azure.RemoteWasbAuthorizerResponse	setResponseMessage	responseMessage	J	java.lang.String	0	org.apache.hadoop.fs.azure.RemoteWasbAuthorizerResponse:setResponseMessage(java.lang.String)
org.apache.hadoop.fs.azure.BlockBlobAppendStream	setCompactionBlockCount	activateCompactionBlockCount	J	int	0	org.apache.hadoop.fs.azure.BlockBlobAppendStream:setCompactionBlockCount(int)
org.apache.hadoop.fs.azurebfs.oauth2.QueryParams	setApiVersion	apiVersion	J	java.lang.String	0	org.apache.hadoop.fs.azurebfs.oauth2.QueryParams:setApiVersion(java.lang.String)
org.apache.hadoop.fs.azurebfs.oauth2.AzureADToken	setAccessToken	accessToken	J	java.lang.String	0	org.apache.hadoop.fs.azurebfs.oauth2.AzureADToken:setAccessToken(java.lang.String)
org.apache.hadoop.fs.azurebfs.contracts.services.AppendRequestParameters	setExpectHeaderEnabled	isExpectHeaderEnabled	J	boolean	0	org.apache.hadoop.fs.azurebfs.contracts.services.AppendRequestParameters:setExpectHeaderEnabled(boolean)
org.apache.hadoop.fs.azurebfs.services.AbfsOperationMetrics	setEndTime	endTime	J	long	0	org.apache.hadoop.fs.azurebfs.services.AbfsOperationMetrics:setEndTime(long)
org.apache.hadoop.fs.azurebfs.services.ReadBuffer	setStream	stream	C	org.apache.hadoop.fs.azurebfs.services.AbfsInputStream	0	org.apache.hadoop.fs.azurebfs.services.ReadBuffer:setStream(org.apache.hadoop.fs.azurebfs.services.AbfsInputStream)
org.apache.hadoop.fs.azurebfs.services.ReadBuffer	setTracingContext	tracingContext	C	org.apache.hadoop.fs.azurebfs.utils.TracingContext	0	org.apache.hadoop.fs.azurebfs.services.ReadBuffer:setTracingContext(org.apache.hadoop.fs.azurebfs.utils.TracingContext)
org.apache.hadoop.fs.azurebfs.services.ReadBuffer	setOffset	offset	J	long	0	org.apache.hadoop.fs.azurebfs.services.ReadBuffer:setOffset(long)
org.apache.hadoop.fs.azurebfs.services.ReadBuffer	setLength	length	J	int	0	org.apache.hadoop.fs.azurebfs.services.ReadBuffer:setLength(int)
org.apache.hadoop.fs.azurebfs.services.ReadBuffer	setRequestedLength	requestedLength	J	int	0	org.apache.hadoop.fs.azurebfs.services.ReadBuffer:setRequestedLength(int)
org.apache.hadoop.fs.azurebfs.services.ReadBuffer	setBuffer	buffer	J	byte	1	org.apache.hadoop.fs.azurebfs.services.ReadBuffer:setBuffer(byte[])
org.apache.hadoop.fs.azurebfs.services.ReadBuffer	setBufferindex	bufferindex	J	int	0	org.apache.hadoop.fs.azurebfs.services.ReadBuffer:setBufferindex(int)
org.apache.hadoop.fs.azurebfs.services.ReadBuffer	setErrException	errException	J	java.io.IOException	0	org.apache.hadoop.fs.azurebfs.services.ReadBuffer:setErrException(java.io.IOException)
org.apache.hadoop.fs.azurebfs.services.ReadBuffer	setStatus	status	C	org.apache.hadoop.fs.azurebfs.contracts.services.ReadBufferStatus	0	org.apache.hadoop.fs.azurebfs.services.ReadBuffer:setStatus(org.apache.hadoop.fs.azurebfs.contracts.services.ReadBufferStatus)
org.apache.hadoop.fs.azurebfs.services.ReadBuffer	setLatch	latch	J	java.util.concurrent.CountDownLatch	0	org.apache.hadoop.fs.azurebfs.services.ReadBuffer:setLatch(java.util.concurrent.CountDownLatch)
org.apache.hadoop.fs.azurebfs.services.ReadBuffer	setTimeStamp	timeStamp	J	long	0	org.apache.hadoop.fs.azurebfs.services.ReadBuffer:setTimeStamp(long)
org.apache.hadoop.fs.azurebfs.services.ReadBuffer	setFirstByteConsumed	isFirstByteConsumed	J	boolean	0	org.apache.hadoop.fs.azurebfs.services.ReadBuffer:setFirstByteConsumed(boolean)
org.apache.hadoop.fs.azurebfs.services.ReadBuffer	setLastByteConsumed	isLastByteConsumed	J	boolean	0	org.apache.hadoop.fs.azurebfs.services.ReadBuffer:setLastByteConsumed(boolean)
org.apache.hadoop.fs.azurebfs.services.ReadBuffer	setAnyByteConsumed	isAnyByteConsumed	J	boolean	0	org.apache.hadoop.fs.azurebfs.services.ReadBuffer:setAnyByteConsumed(boolean)
org.apache.hadoop.fs.azurebfs.services.AbfsInputStream	setCachedSasToken	cachedSasToken	C	org.apache.hadoop.fs.azurebfs.utils.CachedSASToken	0	org.apache.hadoop.fs.azurebfs.services.AbfsInputStream:setCachedSasToken(org.apache.hadoop.fs.azurebfs.utils.CachedSASToken)
org.apache.hadoop.fs.azurebfs.services.AbfsUriQueryBuilder	setSASToken	sasToken	J	java.lang.String	0	org.apache.hadoop.fs.azurebfs.services.AbfsUriQueryBuilder:setSASToken(java.lang.String)
org.apache.hadoop.fs.azurebfs.utils.TracingContext	setStreamID	streamID	J	java.lang.String	0	org.apache.hadoop.fs.azurebfs.utils.TracingContext:setStreamID(java.lang.String)
org.apache.hadoop.fs.azurebfs.utils.TracingContext	setOperation	opType	C	org.apache.hadoop.fs.azurebfs.constants.FSOperationType	0	org.apache.hadoop.fs.azurebfs.utils.TracingContext:setOperation(org.apache.hadoop.fs.azurebfs.constants.FSOperationType)
org.apache.hadoop.fs.azurebfs.utils.TracingContext	setRetryCount	retryCount	J	int	0	org.apache.hadoop.fs.azurebfs.utils.TracingContext:setRetryCount(int)
org.apache.hadoop.fs.azurebfs.utils.TracingContext	setListener	listener	C	org.apache.hadoop.fs.azurebfs.utils.Listener	0	org.apache.hadoop.fs.azurebfs.utils.TracingContext:setListener(org.apache.hadoop.fs.azurebfs.utils.Listener)
org.apache.hadoop.fs.azurebfs.AzureBlobFileSystemStore	setClient	client	C	org.apache.hadoop.fs.azurebfs.services.AbfsClient	0	org.apache.hadoop.fs.azurebfs.AzureBlobFileSystemStore:setClient(org.apache.hadoop.fs.azurebfs.services.AbfsClient)
org.apache.hadoop.fs.azurebfs.AzureBlobFileSystemStore	setNamespaceEnabled	isNamespaceEnabled	C	org.apache.hadoop.fs.azurebfs.enums.Trilean	0	org.apache.hadoop.fs.azurebfs.AzureBlobFileSystemStore:setNamespaceEnabled(org.apache.hadoop.fs.azurebfs.enums.Trilean)
org.apache.hadoop.fs.azurebfs.AbfsConfiguration	setReadAheadEnabled	enabledReadAhead	J	boolean	0	org.apache.hadoop.fs.azurebfs.AbfsConfiguration:setReadAheadEnabled(boolean)
org.apache.hadoop.fs.azurebfs.AbfsConfiguration	setReadBufferSize	readBufferSize	J	int	0	org.apache.hadoop.fs.azurebfs.AbfsConfiguration:setReadBufferSize(int)
org.apache.hadoop.fs.azurebfs.AbfsConfiguration	setWriteBufferSize	writeBufferSize	J	int	0	org.apache.hadoop.fs.azurebfs.AbfsConfiguration:setWriteBufferSize(int)
org.apache.hadoop.fs.azurebfs.AbfsConfiguration	setEnableFlush	enableFlush	J	boolean	0	org.apache.hadoop.fs.azurebfs.AbfsConfiguration:setEnableFlush(boolean)
org.apache.hadoop.fs.azurebfs.AbfsConfiguration	setDisableOutputStreamFlush	disableOutputStreamFlush	J	boolean	0	org.apache.hadoop.fs.azurebfs.AbfsConfiguration:setDisableOutputStreamFlush(boolean)
org.apache.hadoop.fs.azurebfs.AbfsConfiguration	setListMaxResults	listMaxResults	J	int	0	org.apache.hadoop.fs.azurebfs.AbfsConfiguration:setListMaxResults(int)
org.apache.hadoop.fs.azurebfs.AbfsConfiguration	setMaxIoRetries	maxIoRetries	J	int	0	org.apache.hadoop.fs.azurebfs.AbfsConfiguration:setMaxIoRetries(int)
org.apache.hadoop.fs.azurebfs.AbfsConfiguration	setMaxBackoffIntervalMilliseconds	maxBackoffInterval	J	int	0	org.apache.hadoop.fs.azurebfs.AbfsConfiguration:setMaxBackoffIntervalMilliseconds(int)
org.apache.hadoop.fs.azurebfs.AbfsConfiguration	setIsNamespaceEnabledAccount	isNamespaceEnabledAccount	J	java.lang.String	0	org.apache.hadoop.fs.azurebfs.AbfsConfiguration:setIsNamespaceEnabledAccount(java.lang.String)
org.apache.hadoop.fs.azurebfs.AbfsConfiguration	setReadSmallFilesCompletely	readSmallFilesCompletely	J	boolean	0	org.apache.hadoop.fs.azurebfs.AbfsConfiguration:setReadSmallFilesCompletely(boolean)
org.apache.hadoop.fs.azurebfs.AbfsConfiguration	setOptimizeFooterRead	optimizeFooterRead	J	boolean	0	org.apache.hadoop.fs.azurebfs.AbfsConfiguration:setOptimizeFooterRead(boolean)
org.apache.hadoop.fs.azurebfs.AbfsConfiguration	setEnableAbfsListIterator	enableAbfsListIterator	J	boolean	0	org.apache.hadoop.fs.azurebfs.AbfsConfiguration:setEnableAbfsListIterator(boolean)
org.apache.hadoop.fs.azurebfs.AbfsConfiguration	setRenameResilience	renameResilience	J	boolean	0	org.apache.hadoop.fs.azurebfs.AbfsConfiguration:setRenameResilience(boolean)
org.apache.hadoop.fs.azurebfs.AzureBlobFileSystem	setWorkingDirectory	workingDir	C	org.apache.hadoop.fs.Path	0	org.apache.hadoop.fs.azurebfs.AzureBlobFileSystem:setWorkingDirectory(org.apache.hadoop.fs.Path)
org.apache.hadoop.contrib.utils.join.TaggedMapOutput	setTag	tag	C	org.apache.hadoop.io.Text	0	org.apache.hadoop.contrib.utils.join.TaggedMapOutput:setTag(org.apache.hadoop.io.Text)
org.apache.hadoop.tools.DistCpContext	setSourcePaths	sourcePaths	GC	java.util.List	0	org.apache.hadoop.tools.DistCpContext:setSourcePaths(java.util.List)
org.apache.hadoop.tools.DistCpContext	setPreserveRawXattrs	preserveRawXattrs	J	boolean	0	org.apache.hadoop.tools.DistCpContext:setPreserveRawXattrs(boolean)
org.apache.hadoop.tools.DistCpContext	setTargetPathExists	targetPathExists	J	boolean	0	org.apache.hadoop.tools.DistCpContext:setTargetPathExists(boolean)
org.apache.hadoop.tools.DiffInfo	setSource	source	C	org.apache.hadoop.fs.Path	0	org.apache.hadoop.tools.DiffInfo:setSource(org.apache.hadoop.fs.Path)
org.apache.hadoop.tools.DiffInfo	setTarget	target	C	org.apache.hadoop.fs.Path	0	org.apache.hadoop.tools.DiffInfo:setTarget(org.apache.hadoop.fs.Path)
org.apache.hadoop.tools.DiffInfo	setType	type	C	org.apache.hadoop.hdfs.protocol.SnapshotDiffReport$DiffType	0	org.apache.hadoop.tools.DiffInfo:setType(org.apache.hadoop.hdfs.protocol.SnapshotDiffReport$DiffType)
org.apache.hadoop.tools.DiffInfo	setTmp	tmp	C	org.apache.hadoop.fs.Path	0	org.apache.hadoop.tools.DiffInfo:setTmp(org.apache.hadoop.fs.Path)
org.apache.hadoop.tools.RegexCopyFilter	setFilters	filters	GJ	java.util.List	0	org.apache.hadoop.tools.RegexCopyFilter:setFilters(java.util.List)
org.apache.hadoop.tools.CopyListing	setCredentials	credentials	C	org.apache.hadoop.security.Credentials	0	org.apache.hadoop.tools.CopyListing:setCredentials(org.apache.hadoop.security.Credentials)
org.apache.hadoop.tools.DistCpSync	setCopyFilter	copyFilter	C	org.apache.hadoop.tools.CopyFilter	0	org.apache.hadoop.tools.DistCpSync:setCopyFilter(org.apache.hadoop.tools.CopyFilter)
org.apache.hadoop.tools.util.RetriableCommand	setRetryPolicy	retryPolicy	C	org.apache.hadoop.io.retry.RetryPolicy	0	org.apache.hadoop.tools.util.RetriableCommand:setRetryPolicy(org.apache.hadoop.io.retry.RetryPolicy)
org.apache.hadoop.tools.CopyListingFileStatus	setAclEntries	aclEntries	GC	java.util.List	0	org.apache.hadoop.tools.CopyListingFileStatus:setAclEntries(java.util.List)
org.apache.hadoop.tools.CopyListingFileStatus	setXAttrs	xAttrs	GJ	java.util.Map	0	org.apache.hadoop.tools.CopyListingFileStatus:setXAttrs(java.util.Map)
org.apache.hadoop.tools.CopyListingFileStatus	setChunkOffset	chunkOffset	J	long	0	org.apache.hadoop.tools.CopyListingFileStatus:setChunkOffset(long)
org.apache.hadoop.tools.CopyListingFileStatus	setChunkLength	chunkLength	J	long	0	org.apache.hadoop.tools.CopyListingFileStatus:setChunkLength(long)
org.apache.hadoop.tools.DistTool	setConf	jobconf	C	org.apache.hadoop.mapred.JobConf	0	org.apache.hadoop.tools.DistTool:setConf(org.apache.hadoop.conf.Configuration)
org.apache.hadoop.hdfs.server.namenode.FixedBlockResolver	setConf	conf	C	org.apache.hadoop.conf.Configuration	0	org.apache.hadoop.hdfs.server.namenode.FixedBlockResolver:setConf(org.apache.hadoop.conf.Configuration)
org.apache.hadoop.hdfs.server.namenode.FileSystemImage	setConf	conf	C	org.apache.hadoop.conf.Configuration	0	org.apache.hadoop.hdfs.server.namenode.FileSystemImage:setConf(org.apache.hadoop.conf.Configuration)
org.apache.hadoop.mapred.gridmix.GridmixKey$Spec	setResourceUsageSpecification	metrics	C	org.apache.hadoop.tools.rumen.ResourceUsageMetrics	0	org.apache.hadoop.mapred.gridmix.GridmixKey$Spec:setResourceUsageSpecification(org.apache.hadoop.tools.rumen.ResourceUsageMetrics)
org.apache.hadoop.mapred.gridmix.Statistics$ClusterStats	setClusterMetric	status	C	org.apache.hadoop.mapred.ClusterStatus	0	org.apache.hadoop.mapred.gridmix.Statistics$ClusterStats:setClusterMetric(org.apache.hadoop.mapred.ClusterStatus)
org.apache.hadoop.mapred.gridmix.LoadJob$ResourceUsageMatcherRunner$BoostingProgress	setBoostValue	boostValue	J	float	0	org.apache.hadoop.mapred.gridmix.LoadJob$ResourceUsageMatcherRunner$BoostingProgress:setBoostValue(float)
org.apache.hadoop.mapred.gridmix.GridmixRecord	setSeed	seed	J	long	0	org.apache.hadoop.mapred.gridmix.GridmixRecord:setSeed(long)
org.apache.hadoop.mapred.gridmix.GridmixKey	setPartition	partition	J	int	0	org.apache.hadoop.mapred.gridmix.GridmixKey:setPartition(int)
org.apache.hadoop.metrics2.sink.KafkaSink	setProducer	producer	GJ	org.apache.kafka.clients.producer.Producer	0	org.apache.hadoop.metrics2.sink.KafkaSink:setProducer(org.apache.kafka.clients.producer.Producer)
org.apache.hadoop.resourceestimator.common.api.RecurrenceId	setPipelineId	pipelineId	J	java.lang.String	0	org.apache.hadoop.resourceestimator.common.api.RecurrenceId:setPipelineId(java.lang.String)
org.apache.hadoop.resourceestimator.common.api.RecurrenceId	setRunId	runId	J	java.lang.String	0	org.apache.hadoop.resourceestimator.common.api.RecurrenceId:setRunId(java.lang.String)
org.apache.hadoop.resourceestimator.common.api.ResourceSkyline	setJobId	jobId	J	java.lang.String	0	org.apache.hadoop.resourceestimator.common.api.ResourceSkyline:setJobId(java.lang.String)
org.apache.hadoop.resourceestimator.common.api.ResourceSkyline	setJobInputDataSize	jobInputDataSize	J	double	0	org.apache.hadoop.resourceestimator.common.api.ResourceSkyline:setJobInputDataSize(double)
org.apache.hadoop.resourceestimator.common.api.ResourceSkyline	setJobSubmissionTime	jobSubmissionTime	J	long	0	org.apache.hadoop.resourceestimator.common.api.ResourceSkyline:setJobSubmissionTime(long)
org.apache.hadoop.resourceestimator.common.api.ResourceSkyline	setJobFinishTime	jobFinishTime	J	long	0	org.apache.hadoop.resourceestimator.common.api.ResourceSkyline:setJobFinishTime(long)
org.apache.hadoop.resourceestimator.common.api.ResourceSkyline	setContainerSpec	containerSpec	C	org.apache.hadoop.yarn.api.records.Resource	0	org.apache.hadoop.resourceestimator.common.api.ResourceSkyline:setContainerSpec(org.apache.hadoop.yarn.api.records.Resource)
org.apache.hadoop.resourceestimator.common.api.ResourceSkyline	setSkylineList	skylineList	C	org.apache.hadoop.yarn.server.resourcemanager.reservation.RLESparseResourceAllocation	0	org.apache.hadoop.resourceestimator.common.api.ResourceSkyline:setSkylineList(org.apache.hadoop.yarn.server.resourcemanager.reservation.RLESparseResourceAllocation)
org.apache.hadoop.resourceestimator.translator.api.JobMetaData	setRecurrenceId	recurrenceId	C	org.apache.hadoop.resourceestimator.common.api.RecurrenceId	0	org.apache.hadoop.resourceestimator.translator.api.JobMetaData:setRecurrenceId(org.apache.hadoop.resourceestimator.common.api.RecurrenceId)
org.apache.hadoop.resourceestimator.translator.impl.LogParserUtil	setLogParser	logParser	C	org.apache.hadoop.resourceestimator.translator.api.LogParser	0	org.apache.hadoop.resourceestimator.translator.impl.LogParserUtil:setLogParser(org.apache.hadoop.resourceestimator.translator.api.LogParser)
org.apache.hadoop.tools.rumen.LoggedSingleRelativeRanking	setRelativeRanking	relativeRanking	J	double	0	org.apache.hadoop.tools.rumen.LoggedSingleRelativeRanking:setRelativeRanking(double)
org.apache.hadoop.tools.rumen.LoggedSingleRelativeRanking	setDatum	datum	J	long	0	org.apache.hadoop.tools.rumen.LoggedSingleRelativeRanking:setDatum(long)
org.apache.hadoop.tools.rumen.state.StatePool	setStates	pool	GC	java.util.HashMap	0	org.apache.hadoop.tools.rumen.state.StatePool:setStates(java.util.HashMap)
org.apache.hadoop.tools.rumen.state.StatePool$StatePair	setClassName	className	J	java.lang.String	0	org.apache.hadoop.tools.rumen.state.StatePool$StatePair:setClassName(java.lang.String)
org.apache.hadoop.tools.rumen.state.StatePool$StatePair	setState	state	C	org.apache.hadoop.tools.rumen.state.State	0	org.apache.hadoop.tools.rumen.state.StatePool$StatePair:setState(org.apache.hadoop.tools.rumen.state.State)
org.apache.hadoop.tools.rumen.LoggedTask	setInputBytes	inputBytes	J	long	0	org.apache.hadoop.tools.rumen.LoggedTask:setInputBytes(long)
org.apache.hadoop.tools.rumen.LoggedTask	setInputRecords	inputRecords	J	long	0	org.apache.hadoop.tools.rumen.LoggedTask:setInputRecords(long)
org.apache.hadoop.tools.rumen.LoggedTask	setOutputBytes	outputBytes	J	long	0	org.apache.hadoop.tools.rumen.LoggedTask:setOutputBytes(long)
org.apache.hadoop.tools.rumen.LoggedTask	setOutputRecords	outputRecords	J	long	0	org.apache.hadoop.tools.rumen.LoggedTask:setOutputRecords(long)
org.apache.hadoop.tools.rumen.LoggedTask	setStartTime	startTime	J	long	0	org.apache.hadoop.tools.rumen.LoggedTask:setStartTime(long)
org.apache.hadoop.tools.rumen.LoggedTask	setFinishTime	finishTime	J	long	0	org.apache.hadoop.tools.rumen.LoggedTask:setFinishTime(long)
org.apache.hadoop.tools.rumen.LoggedTask	setAttempts	attempts	GC	java.util.List	0	org.apache.hadoop.tools.rumen.LoggedTask:setAttempts(java.util.List)
org.apache.hadoop.tools.rumen.LoggedTask	setPreferredLocations	preferredLocations	GC	java.util.List	0	org.apache.hadoop.tools.rumen.LoggedTask:setPreferredLocations(java.util.List)
org.apache.hadoop.tools.rumen.LoggedTask	setTaskStatus	taskStatus	C	org.apache.hadoop.tools.rumen.Pre21JobHistoryConstants$Values	0	org.apache.hadoop.tools.rumen.LoggedTask:setTaskStatus(org.apache.hadoop.tools.rumen.Pre21JobHistoryConstants$Values)
org.apache.hadoop.tools.rumen.LoggedTask	setTaskType	taskType	C	org.apache.hadoop.tools.rumen.Pre21JobHistoryConstants$Values	0	org.apache.hadoop.tools.rumen.LoggedTask:setTaskType(org.apache.hadoop.tools.rumen.Pre21JobHistoryConstants$Values)
org.apache.hadoop.tools.rumen.anonymization.WordList	setName	name	J	java.lang.String	0	org.apache.hadoop.tools.rumen.anonymization.WordList:setName(java.lang.String)
org.apache.hadoop.tools.rumen.anonymization.WordList	setWords	list	GJ	java.util.Map	0	org.apache.hadoop.tools.rumen.anonymization.WordList:setWords(java.util.Map)
org.apache.hadoop.tools.rumen.LoggedJob	setPriority	priority	C	org.apache.hadoop.tools.rumen.LoggedJob$JobPriority	0	org.apache.hadoop.tools.rumen.LoggedJob:setPriority(org.apache.hadoop.tools.rumen.LoggedJob$JobPriority)
org.apache.hadoop.tools.rumen.LoggedJob	setComputonsPerMapInputByte	computonsPerMapInputByte	J	long	0	org.apache.hadoop.tools.rumen.LoggedJob:setComputonsPerMapInputByte(long)
org.apache.hadoop.tools.rumen.LoggedJob	setComputonsPerMapOutputByte	computonsPerMapOutputByte	J	long	0	org.apache.hadoop.tools.rumen.LoggedJob:setComputonsPerMapOutputByte(long)
org.apache.hadoop.tools.rumen.LoggedJob	setComputonsPerReduceInputByte	computonsPerReduceInputByte	J	long	0	org.apache.hadoop.tools.rumen.LoggedJob:setComputonsPerReduceInputByte(long)
org.apache.hadoop.tools.rumen.LoggedJob	setComputonsPerReduceOutputByte	computonsPerReduceOutputByte	J	long	0	org.apache.hadoop.tools.rumen.LoggedJob:setComputonsPerReduceOutputByte(long)
org.apache.hadoop.tools.rumen.LoggedJob	setSubmitTime	submitTime	J	long	0	org.apache.hadoop.tools.rumen.LoggedJob:setSubmitTime(long)
org.apache.hadoop.tools.rumen.LoggedJob	setLaunchTime	launchTime	J	long	0	org.apache.hadoop.tools.rumen.LoggedJob:setLaunchTime(long)
org.apache.hadoop.tools.rumen.LoggedJob	setFinishTime	finishTime	J	long	0	org.apache.hadoop.tools.rumen.LoggedJob:setFinishTime(long)
org.apache.hadoop.tools.rumen.LoggedJob	setHeapMegabytes	heapMegabytes	J	int	0	org.apache.hadoop.tools.rumen.LoggedJob:setHeapMegabytes(int)
org.apache.hadoop.tools.rumen.LoggedJob	setTotalMaps	totalMaps	J	int	0	org.apache.hadoop.tools.rumen.LoggedJob:setTotalMaps(int)
org.apache.hadoop.tools.rumen.LoggedJob	setTotalReduces	totalReduces	J	int	0	org.apache.hadoop.tools.rumen.LoggedJob:setTotalReduces(int)
org.apache.hadoop.tools.rumen.LoggedJob	setOutcome	outcome	C	org.apache.hadoop.tools.rumen.Pre21JobHistoryConstants$Values	0	org.apache.hadoop.tools.rumen.LoggedJob:setOutcome(org.apache.hadoop.tools.rumen.Pre21JobHistoryConstants$Values)
org.apache.hadoop.tools.rumen.LoggedJob	setJobtype	jobtype	C	org.apache.hadoop.tools.rumen.LoggedJob$JobType	0	org.apache.hadoop.tools.rumen.LoggedJob:setJobtype(org.apache.hadoop.tools.rumen.LoggedJob$JobType)
org.apache.hadoop.tools.rumen.LoggedJob	setDirectDependantJobs	directDependantJobs	GJ	java.util.List	0	org.apache.hadoop.tools.rumen.LoggedJob:setDirectDependantJobs(java.util.List)
org.apache.hadoop.tools.rumen.LoggedJob	setMapTasks	mapTasks	GC	java.util.List	0	org.apache.hadoop.tools.rumen.LoggedJob:setMapTasks(java.util.List)
org.apache.hadoop.tools.rumen.LoggedJob	setReduceTasks	reduceTasks	GC	java.util.List	0	org.apache.hadoop.tools.rumen.LoggedJob:setReduceTasks(java.util.List)
org.apache.hadoop.tools.rumen.LoggedJob	setOtherTasks	otherTasks	GC	java.util.List	0	org.apache.hadoop.tools.rumen.LoggedJob:setOtherTasks(java.util.List)
org.apache.hadoop.tools.rumen.LoggedJob	setSuccessfulMapAttemptCDFs	successfulMapAttemptCDFs	GC	java.util.ArrayList	0	org.apache.hadoop.tools.rumen.LoggedJob:setSuccessfulMapAttemptCDFs(java.util.ArrayList)
org.apache.hadoop.tools.rumen.LoggedJob	setFailedMapAttemptCDFs	failedMapAttemptCDFs	GC	java.util.ArrayList	0	org.apache.hadoop.tools.rumen.LoggedJob:setFailedMapAttemptCDFs(java.util.ArrayList)
org.apache.hadoop.tools.rumen.LoggedJob	setSuccessfulReduceAttemptCDF	successfulReduceAttemptCDF	C	org.apache.hadoop.tools.rumen.LoggedDiscreteCDF	0	org.apache.hadoop.tools.rumen.LoggedJob:setSuccessfulReduceAttemptCDF(org.apache.hadoop.tools.rumen.LoggedDiscreteCDF)
org.apache.hadoop.tools.rumen.LoggedJob	setFailedReduceAttemptCDF	failedReduceAttemptCDF	C	org.apache.hadoop.tools.rumen.LoggedDiscreteCDF	0	org.apache.hadoop.tools.rumen.LoggedJob:setFailedReduceAttemptCDF(org.apache.hadoop.tools.rumen.LoggedDiscreteCDF)
org.apache.hadoop.tools.rumen.LoggedJob	setMapperTriesToSucceed	mapperTriesToSucceed	J	double	1	org.apache.hadoop.tools.rumen.LoggedJob:setMapperTriesToSucceed(double[])
org.apache.hadoop.tools.rumen.LoggedJob	setFailedMapperFraction	failedMapperFraction	J	double	0	org.apache.hadoop.tools.rumen.LoggedJob:setFailedMapperFraction(double)
org.apache.hadoop.tools.rumen.LoggedJob	setRelativeTime	relativeTime	J	long	0	org.apache.hadoop.tools.rumen.LoggedJob:setRelativeTime(long)
org.apache.hadoop.tools.rumen.LoggedJob	setClusterMapMB	clusterMapMB	J	int	0	org.apache.hadoop.tools.rumen.LoggedJob:setClusterMapMB(int)
org.apache.hadoop.tools.rumen.LoggedJob	setClusterReduceMB	clusterReduceMB	J	int	0	org.apache.hadoop.tools.rumen.LoggedJob:setClusterReduceMB(int)
org.apache.hadoop.tools.rumen.LoggedJob	setJobMapMB	jobMapMB	J	int	0	org.apache.hadoop.tools.rumen.LoggedJob:setJobMapMB(int)
org.apache.hadoop.tools.rumen.LoggedJob	setJobReduceMB	jobReduceMB	J	int	0	org.apache.hadoop.tools.rumen.LoggedJob:setJobReduceMB(int)
org.apache.hadoop.tools.rumen.datatypes.NodeName$NodeNameState	setRackNameState	rackNameState	C	org.apache.hadoop.tools.rumen.anonymization.WordList	0	org.apache.hadoop.tools.rumen.datatypes.NodeName$NodeNameState:setRackNameState(org.apache.hadoop.tools.rumen.anonymization.WordList)
org.apache.hadoop.tools.rumen.datatypes.NodeName$NodeNameState	setHostNameState	hostNameState	C	org.apache.hadoop.tools.rumen.anonymization.WordList	0	org.apache.hadoop.tools.rumen.datatypes.NodeName$NodeNameState:setHostNameState(org.apache.hadoop.tools.rumen.anonymization.WordList)
org.apache.hadoop.tools.rumen.datatypes.FileName$FileNameState	setDirectoryState	dirState	C	org.apache.hadoop.tools.rumen.anonymization.WordList	0	org.apache.hadoop.tools.rumen.datatypes.FileName$FileNameState:setDirectoryState(org.apache.hadoop.tools.rumen.anonymization.WordList)
org.apache.hadoop.tools.rumen.datatypes.FileName$FileNameState	setFileNameState	fileNameState	C	org.apache.hadoop.tools.rumen.anonymization.WordList	0	org.apache.hadoop.tools.rumen.datatypes.FileName$FileNameState:setFileNameState(org.apache.hadoop.tools.rumen.anonymization.WordList)
org.apache.hadoop.tools.rumen.ResourceUsageMetrics	setCumulativeCpuUsage	cumulativeCpuUsage	J	long	0	org.apache.hadoop.tools.rumen.ResourceUsageMetrics:setCumulativeCpuUsage(long)
org.apache.hadoop.tools.rumen.ResourceUsageMetrics	setVirtualMemoryUsage	virtualMemoryUsage	J	long	0	org.apache.hadoop.tools.rumen.ResourceUsageMetrics:setVirtualMemoryUsage(long)
org.apache.hadoop.tools.rumen.ResourceUsageMetrics	setPhysicalMemoryUsage	physicalMemoryUsage	J	long	0	org.apache.hadoop.tools.rumen.ResourceUsageMetrics:setPhysicalMemoryUsage(long)
org.apache.hadoop.tools.rumen.ResourceUsageMetrics	setHeapUsage	heapUsage	J	long	0	org.apache.hadoop.tools.rumen.ResourceUsageMetrics:setHeapUsage(long)
org.apache.hadoop.tools.rumen.LoggedDiscreteCDF	setMinimum	minimum	J	long	0	org.apache.hadoop.tools.rumen.LoggedDiscreteCDF:setMinimum(long)
org.apache.hadoop.tools.rumen.LoggedDiscreteCDF	setRankings	rankings	GC	java.util.List	0	org.apache.hadoop.tools.rumen.LoggedDiscreteCDF:setRankings(java.util.List)
org.apache.hadoop.tools.rumen.LoggedDiscreteCDF	setMaximum	maximum	J	long	0	org.apache.hadoop.tools.rumen.LoggedDiscreteCDF:setMaximum(long)
org.apache.hadoop.tools.rumen.LoggedDiscreteCDF	setNumberValues	numberValues	J	long	0	org.apache.hadoop.tools.rumen.LoggedDiscreteCDF:setNumberValues(long)
org.apache.hadoop.tools.rumen.LoggedTaskAttempt	setClockSplits	clockSplits	GJ	java.util.List	0	org.apache.hadoop.tools.rumen.LoggedTaskAttempt:setClockSplits(java.util.List)
org.apache.hadoop.tools.rumen.LoggedTaskAttempt	setCpuUsages	cpuUsages	GJ	java.util.List	0	org.apache.hadoop.tools.rumen.LoggedTaskAttempt:setCpuUsages(java.util.List)
org.apache.hadoop.tools.rumen.LoggedTaskAttempt	setVMemKbytes	vMemKbytes	GJ	java.util.List	0	org.apache.hadoop.tools.rumen.LoggedTaskAttempt:setVMemKbytes(java.util.List)
org.apache.hadoop.tools.rumen.LoggedTaskAttempt	setPhysMemKbytes	physMemKbytes	GJ	java.util.List	0	org.apache.hadoop.tools.rumen.LoggedTaskAttempt:setPhysMemKbytes(java.util.List)
org.apache.hadoop.tools.rumen.LoggedTaskAttempt	setShuffleFinished	shuffleFinished	J	long	0	org.apache.hadoop.tools.rumen.LoggedTaskAttempt:setShuffleFinished(long)
org.apache.hadoop.tools.rumen.LoggedTaskAttempt	setSortFinished	sortFinished	J	long	0	org.apache.hadoop.tools.rumen.LoggedTaskAttempt:setSortFinished(long)
org.apache.hadoop.tools.rumen.LoggedTaskAttempt	setResult	result	C	org.apache.hadoop.tools.rumen.Pre21JobHistoryConstants$Values	0	org.apache.hadoop.tools.rumen.LoggedTaskAttempt:setResult(org.apache.hadoop.tools.rumen.Pre21JobHistoryConstants$Values)
org.apache.hadoop.tools.rumen.LoggedTaskAttempt	setStartTime	startTime	J	long	0	org.apache.hadoop.tools.rumen.LoggedTaskAttempt:setStartTime(long)
org.apache.hadoop.tools.rumen.LoggedTaskAttempt	setFinishTime	finishTime	J	long	0	org.apache.hadoop.tools.rumen.LoggedTaskAttempt:setFinishTime(long)
org.apache.hadoop.tools.rumen.LoggedTaskAttempt	setHdfsBytesRead	hdfsBytesRead	J	long	0	org.apache.hadoop.tools.rumen.LoggedTaskAttempt:setHdfsBytesRead(long)
org.apache.hadoop.tools.rumen.LoggedTaskAttempt	setHdfsBytesWritten	hdfsBytesWritten	J	long	0	org.apache.hadoop.tools.rumen.LoggedTaskAttempt:setHdfsBytesWritten(long)
org.apache.hadoop.tools.rumen.LoggedTaskAttempt	setFileBytesRead	fileBytesRead	J	long	0	org.apache.hadoop.tools.rumen.LoggedTaskAttempt:setFileBytesRead(long)
org.apache.hadoop.tools.rumen.LoggedTaskAttempt	setFileBytesWritten	fileBytesWritten	J	long	0	org.apache.hadoop.tools.rumen.LoggedTaskAttempt:setFileBytesWritten(long)
org.apache.hadoop.tools.rumen.LoggedTaskAttempt	setMapInputRecords	mapInputRecords	J	long	0	org.apache.hadoop.tools.rumen.LoggedTaskAttempt:setMapInputRecords(long)
org.apache.hadoop.tools.rumen.LoggedTaskAttempt	setMapOutputBytes	mapOutputBytes	J	long	0	org.apache.hadoop.tools.rumen.LoggedTaskAttempt:setMapOutputBytes(long)
org.apache.hadoop.tools.rumen.LoggedTaskAttempt	setMapOutputRecords	mapOutputRecords	J	long	0	org.apache.hadoop.tools.rumen.LoggedTaskAttempt:setMapOutputRecords(long)
org.apache.hadoop.tools.rumen.LoggedTaskAttempt	setCombineInputRecords	combineInputRecords	J	long	0	org.apache.hadoop.tools.rumen.LoggedTaskAttempt:setCombineInputRecords(long)
org.apache.hadoop.tools.rumen.LoggedTaskAttempt	setReduceInputGroups	reduceInputGroups	J	long	0	org.apache.hadoop.tools.rumen.LoggedTaskAttempt:setReduceInputGroups(long)
org.apache.hadoop.tools.rumen.LoggedTaskAttempt	setReduceInputRecords	reduceInputRecords	J	long	0	org.apache.hadoop.tools.rumen.LoggedTaskAttempt:setReduceInputRecords(long)
org.apache.hadoop.tools.rumen.LoggedTaskAttempt	setReduceShuffleBytes	reduceShuffleBytes	J	long	0	org.apache.hadoop.tools.rumen.LoggedTaskAttempt:setReduceShuffleBytes(long)
org.apache.hadoop.tools.rumen.LoggedTaskAttempt	setReduceOutputRecords	reduceOutputRecords	J	long	0	org.apache.hadoop.tools.rumen.LoggedTaskAttempt:setReduceOutputRecords(long)
org.apache.hadoop.tools.rumen.LoggedTaskAttempt	setSpilledRecords	spilledRecords	J	long	0	org.apache.hadoop.tools.rumen.LoggedTaskAttempt:setSpilledRecords(long)
org.apache.hadoop.tools.rumen.LoggedTaskAttempt	setLocation	location	C	org.apache.hadoop.tools.rumen.LoggedLocation	0	org.apache.hadoop.tools.rumen.LoggedTaskAttempt:setLocation(org.apache.hadoop.tools.rumen.LoggedLocation)
org.apache.hadoop.tools.rumen.LoggedTaskAttempt	setMapInputBytes	mapInputBytes	J	long	0	org.apache.hadoop.tools.rumen.LoggedTaskAttempt:setMapInputBytes(long)
org.apache.hadoop.tools.rumen.LoggedTaskAttempt	setResourceUsageMetrics	metrics	C	org.apache.hadoop.tools.rumen.ResourceUsageMetrics	0	org.apache.hadoop.tools.rumen.LoggedTaskAttempt:setResourceUsageMetrics(org.apache.hadoop.tools.rumen.ResourceUsageMetrics)
org.apache.hadoop.tools.rumen.LoggedNetworkTopology	setChildren	children	GC	java.util.List	0	org.apache.hadoop.tools.rumen.LoggedNetworkTopology:setChildren(java.util.List)
org.apache.hadoop.yarn.sls.SLSRunner$NodeDetails	setHostname	hostname	J	java.lang.String	0	org.apache.hadoop.yarn.sls.SLSRunner$NodeDetails:setHostname(java.lang.String)
org.apache.hadoop.yarn.sls.SLSRunner$NodeDetails	setNodeResource	nodeResource	C	org.apache.hadoop.yarn.api.records.Resource	0	org.apache.hadoop.yarn.sls.SLSRunner$NodeDetails:setNodeResource(org.apache.hadoop.yarn.api.records.Resource)
org.apache.hadoop.yarn.sls.SLSRunner$NodeDetails	setLabels	labels	GC	java.util.Set	0	org.apache.hadoop.yarn.sls.SLSRunner$NodeDetails:setLabels(java.util.Set)
org.apache.hadoop.yarn.sls.scheduler.TaskRunner	setQueueSize	threadPoolSize	J	int	0	org.apache.hadoop.yarn.sls.scheduler.TaskRunner:setQueueSize(int)
org.apache.hadoop.yarn.sls.scheduler.ContainerSimulator	setPriority	priority	J	int	0	org.apache.hadoop.yarn.sls.scheduler.ContainerSimulator:setPriority(int)
org.apache.hadoop.yarn.sls.scheduler.SchedulerMetrics	setRunning	running	J	boolean	0	org.apache.hadoop.yarn.sls.scheduler.SchedulerMetrics:setRunning(boolean)
org.apache.hadoop.yarn.sls.scheduler.Tracker	setQueueSet	queueSet	GJ	java.util.Set	0	org.apache.hadoop.yarn.sls.scheduler.Tracker:setQueueSet(java.util.Set)
org.apache.hadoop.yarn.sls.scheduler.Tracker	setTrackedAppSet	trackedAppSet	GJ	java.util.Set	0	org.apache.hadoop.yarn.sls.scheduler.Tracker:setTrackedAppSet(java.util.Set)
org.apache.hadoop.yarn.sls.scheduler.TaskRunner$Task	setQueue	queue	GC	java.util.Queue	0	org.apache.hadoop.yarn.sls.scheduler.TaskRunner$Task:setQueue(java.util.Queue)
org.apache.hadoop.yarn.sls.scheduler.TaskRunner$Task	setEndTime	endTime	J	long	0	org.apache.hadoop.yarn.sls.scheduler.TaskRunner$Task:setEndTime(long)
org.apache.hadoop.yarn.sls.appmaster.AMSimulator	setReservationRequest	reservationRequest	C	org.apache.hadoop.yarn.api.protocolrecords.ReservationSubmissionRequest	0	org.apache.hadoop.yarn.sls.appmaster.AMSimulator:setReservationRequest(org.apache.hadoop.yarn.api.protocolrecords.ReservationSubmissionRequest)
org.apache.hadoop.record.BinaryRecordOutput	setDataOutput	out	J	java.io.DataOutput	0	org.apache.hadoop.record.BinaryRecordOutput:setDataOutput(java.io.DataOutput)
org.apache.hadoop.record.BinaryRecordInput	setDataInput	in	J	java.io.DataInput	0	org.apache.hadoop.record.BinaryRecordInput:setDataInput(java.io.DataInput)
org.apache.hadoop.record.Buffer	set	bytes	J	byte	1	org.apache.hadoop.record.Buffer:set(byte[])
org.apache.hadoop.streaming.DumpTypedBytes	setConf	conf	C	org.apache.hadoop.conf.Configuration	0	org.apache.hadoop.streaming.DumpTypedBytes:setConf(org.apache.hadoop.conf.Configuration)
org.apache.hadoop.streaming.LoadTypedBytes	setConf	conf	C	org.apache.hadoop.conf.Configuration	0	org.apache.hadoop.streaming.LoadTypedBytes:setConf(org.apache.hadoop.conf.Configuration)
org.apache.hadoop.streaming.PipeMapRed$MRErrorThread	setReporter	reporter	C	org.apache.hadoop.mapred.Reporter	0	org.apache.hadoop.streaming.PipeMapRed$MRErrorThread:setReporter(org.apache.hadoop.mapred.Reporter)
org.apache.hadoop.streaming.io.IdentifierResolver	setInputWriterClass	inputWriterClass	GC	java.lang.Class	0	org.apache.hadoop.streaming.io.IdentifierResolver:setInputWriterClass(java.lang.Class)
org.apache.hadoop.streaming.io.IdentifierResolver	setOutputReaderClass	outputReaderClass	GC	java.lang.Class	0	org.apache.hadoop.streaming.io.IdentifierResolver:setOutputReaderClass(java.lang.Class)
org.apache.hadoop.streaming.io.IdentifierResolver	setOutputKeyClass	outputKeyClass	J	java.lang.Class	0	org.apache.hadoop.streaming.io.IdentifierResolver:setOutputKeyClass(java.lang.Class)
org.apache.hadoop.streaming.io.IdentifierResolver	setOutputValueClass	outputValueClass	J	java.lang.Class	0	org.apache.hadoop.streaming.io.IdentifierResolver:setOutputValueClass(java.lang.Class)
org.apache.hadoop.streaming.JarBuilder	setVerbose	verbose	J	boolean	0	org.apache.hadoop.streaming.JarBuilder:setVerbose(boolean)
org.apache.hadoop.streaming.StreamJob	setConf	config_	C	org.apache.hadoop.conf.Configuration	0	org.apache.hadoop.streaming.StreamJob:setConf(org.apache.hadoop.conf.Configuration)
org.apache.hadoop.typedbytes.TypedBytesWritableOutput	setTypedBytesOutput	out	C	org.apache.hadoop.typedbytes.TypedBytesOutput	0	org.apache.hadoop.typedbytes.TypedBytesWritableOutput:setTypedBytesOutput(org.apache.hadoop.typedbytes.TypedBytesOutput)
org.apache.hadoop.typedbytes.TypedBytesOutput	setDataOutput	out	J	java.io.DataOutput	0	org.apache.hadoop.typedbytes.TypedBytesOutput:setDataOutput(java.io.DataOutput)
org.apache.hadoop.typedbytes.TypedBytesInput	setDataInput	in	J	java.io.DataInput	0	org.apache.hadoop.typedbytes.TypedBytesInput:setDataInput(java.io.DataInput)
org.apache.hadoop.typedbytes.TypedBytesRecordOutput	setTypedBytesOutput	out	C	org.apache.hadoop.typedbytes.TypedBytesOutput	0	org.apache.hadoop.typedbytes.TypedBytesRecordOutput:setTypedBytesOutput(org.apache.hadoop.typedbytes.TypedBytesOutput)
org.apache.hadoop.typedbytes.TypedBytesWritableInput	setTypedBytesInput	in	C	org.apache.hadoop.typedbytes.TypedBytesInput	0	org.apache.hadoop.typedbytes.TypedBytesWritableInput:setTypedBytesInput(org.apache.hadoop.typedbytes.TypedBytesInput)
org.apache.hadoop.typedbytes.TypedBytesWritableInput	setConf	conf	C	org.apache.hadoop.conf.Configuration	0	org.apache.hadoop.typedbytes.TypedBytesWritableInput:setConf(org.apache.hadoop.conf.Configuration)
org.apache.hadoop.typedbytes.TypedBytesRecordInput	setTypedBytesInput	in	C	org.apache.hadoop.typedbytes.TypedBytesInput	0	org.apache.hadoop.typedbytes.TypedBytesRecordInput:setTypedBytesInput(org.apache.hadoop.typedbytes.TypedBytesInput)
org.apache.hadoop.yarn.api.resource.PlacementConstraint$TimedPlacementConstraint	setConstraint	constraint	C	org.apache.hadoop.yarn.api.resource.PlacementConstraint$AbstractConstraint	0	org.apache.hadoop.yarn.api.resource.PlacementConstraint$TimedPlacementConstraint:setConstraint(org.apache.hadoop.yarn.api.resource.PlacementConstraint$AbstractConstraint)
org.apache.hadoop.yarn.api.records.ResourceInformation	setName	name	J	java.lang.String	0	org.apache.hadoop.yarn.api.records.ResourceInformation:setName(java.lang.String)
org.apache.hadoop.yarn.api.records.ResourceInformation	setUnitsWithoutValidation	units	J	java.lang.String	0	org.apache.hadoop.yarn.api.records.ResourceInformation:setUnitsWithoutValidation(java.lang.String)
org.apache.hadoop.yarn.api.records.ResourceInformation	setResourceType	resourceType	C	org.apache.hadoop.yarn.api.protocolrecords.ResourceTypes	0	org.apache.hadoop.yarn.api.records.ResourceInformation:setResourceType(org.apache.hadoop.yarn.api.protocolrecords.ResourceTypes)
org.apache.hadoop.yarn.api.records.ResourceInformation	setValue	value	J	long	0	org.apache.hadoop.yarn.api.records.ResourceInformation:setValue(long)
org.apache.hadoop.yarn.api.records.ResourceInformation	setMinimumAllocation	minimumAllocation	J	long	0	org.apache.hadoop.yarn.api.records.ResourceInformation:setMinimumAllocation(long)
org.apache.hadoop.yarn.api.records.ResourceInformation	setMaximumAllocation	maximumAllocation	J	long	0	org.apache.hadoop.yarn.api.records.ResourceInformation:setMaximumAllocation(long)
org.apache.hadoop.yarn.api.records.ResourceInformation	setAttributes	attributes	GJ	java.util.Map	0	org.apache.hadoop.yarn.api.records.ResourceInformation:setAttributes(java.util.Map)
org.apache.hadoop.yarn.api.records.ResourceInformation	setTags	tags	GJ	java.util.Set	0	org.apache.hadoop.yarn.api.records.ResourceInformation:setTags(java.util.Set)
org.apache.hadoop.yarn.api.records.ResourceUtilization	setCustomResources	customResources	GJ	java.util.Map	0	org.apache.hadoop.yarn.api.records.ResourceUtilization:setCustomResources(java.util.Map)
org.apache.hadoop.yarn.api.records.timelineservice.TimelineEvent	setId	id	J	java.lang.String	0	org.apache.hadoop.yarn.api.records.timelineservice.TimelineEvent:setId(java.lang.String)
org.apache.hadoop.yarn.api.records.timelineservice.TimelineEvent	setTimestamp	timestamp	J	long	0	org.apache.hadoop.yarn.api.records.timelineservice.TimelineEvent:setTimestamp(long)
org.apache.hadoop.yarn.api.records.timelineservice.TimelineEntities	setEntities	entities	GC	java.util.List	0	org.apache.hadoop.yarn.api.records.timelineservice.TimelineEntities:setEntities(java.util.List)
org.apache.hadoop.yarn.api.records.timelineservice.TimelineDomain	setId	id	J	java.lang.String	0	org.apache.hadoop.yarn.api.records.timelineservice.TimelineDomain:setId(java.lang.String)
org.apache.hadoop.yarn.api.records.timelineservice.TimelineDomain	setDescription	description	J	java.lang.String	0	org.apache.hadoop.yarn.api.records.timelineservice.TimelineDomain:setDescription(java.lang.String)
org.apache.hadoop.yarn.api.records.timelineservice.TimelineDomain	setOwner	owner	J	java.lang.String	0	org.apache.hadoop.yarn.api.records.timelineservice.TimelineDomain:setOwner(java.lang.String)
org.apache.hadoop.yarn.api.records.timelineservice.TimelineDomain	setReaders	readers	J	java.lang.String	0	org.apache.hadoop.yarn.api.records.timelineservice.TimelineDomain:setReaders(java.lang.String)
org.apache.hadoop.yarn.api.records.timelineservice.TimelineDomain	setWriters	writers	J	java.lang.String	0	org.apache.hadoop.yarn.api.records.timelineservice.TimelineDomain:setWriters(java.lang.String)
org.apache.hadoop.yarn.api.records.timelineservice.TimelineDomain	setCreatedTime	createdTime	J	java.lang.Long	0	org.apache.hadoop.yarn.api.records.timelineservice.TimelineDomain:setCreatedTime(java.lang.Long)
org.apache.hadoop.yarn.api.records.timelineservice.TimelineDomain	setModifiedTime	modifiedTime	J	java.lang.Long	0	org.apache.hadoop.yarn.api.records.timelineservice.TimelineDomain:setModifiedTime(java.lang.Long)
org.apache.hadoop.yarn.api.records.timelineservice.TimelineMetric	setType	type	C	org.apache.hadoop.yarn.api.records.timelineservice.TimelineMetric$Type	0	org.apache.hadoop.yarn.api.records.timelineservice.TimelineMetric:setType(org.apache.hadoop.yarn.api.records.timelineservice.TimelineMetric$Type)
org.apache.hadoop.yarn.api.records.timelineservice.TimelineMetric	setId	id	J	java.lang.String	0	org.apache.hadoop.yarn.api.records.timelineservice.TimelineMetric:setId(java.lang.String)
org.apache.hadoop.yarn.api.records.timelineservice.TimelineMetric	setRealtimeAggregationOp	realtimeAggregationOp	C	org.apache.hadoop.yarn.api.records.timelineservice.TimelineMetricOperation	0	org.apache.hadoop.yarn.api.records.timelineservice.TimelineMetric:setRealtimeAggregationOp(org.apache.hadoop.yarn.api.records.timelineservice.TimelineMetricOperation)
org.apache.hadoop.yarn.api.records.timelineservice.TimelineWriteResponse$TimelineWriteError	setEntityId	entityId	J	java.lang.String	0	org.apache.hadoop.yarn.api.records.timelineservice.TimelineWriteResponse$TimelineWriteError:setEntityId(java.lang.String)
org.apache.hadoop.yarn.api.records.timelineservice.TimelineWriteResponse$TimelineWriteError	setEntityType	entityType	J	java.lang.String	0	org.apache.hadoop.yarn.api.records.timelineservice.TimelineWriteResponse$TimelineWriteError:setEntityType(java.lang.String)
org.apache.hadoop.yarn.api.records.timelineservice.TimelineWriteResponse$TimelineWriteError	setErrorCode	errorCode	J	int	0	org.apache.hadoop.yarn.api.records.timelineservice.TimelineWriteResponse$TimelineWriteError:setErrorCode(int)
org.apache.hadoop.yarn.api.records.timelineservice.TimelineEntity	setIdentifier	identifier	C	org.apache.hadoop.yarn.api.records.timelineservice.TimelineEntity$Identifier	0	org.apache.hadoop.yarn.api.records.timelineservice.TimelineEntity:setIdentifier(org.apache.hadoop.yarn.api.records.timelineservice.TimelineEntity$Identifier)
org.apache.hadoop.yarn.api.records.timelineservice.TimelineEntity	setMetrics	metrics	GC	java.util.Set	0	org.apache.hadoop.yarn.api.records.timelineservice.TimelineEntity:setMetrics(java.util.Set)
org.apache.hadoop.yarn.api.records.timelineservice.TimelineEntity	setEvents	events	GC	java.util.NavigableSet	0	org.apache.hadoop.yarn.api.records.timelineservice.TimelineEntity:setEvents(java.util.NavigableSet)
org.apache.hadoop.yarn.api.records.timelineservice.TimelineEntity	setCreatedTime	createdTime	J	java.lang.Long	0	org.apache.hadoop.yarn.api.records.timelineservice.TimelineEntity:setCreatedTime(java.lang.Long)
org.apache.hadoop.yarn.api.records.timelineservice.TimelineEntity	setIdPrefix	idPrefix	J	long	0	org.apache.hadoop.yarn.api.records.timelineservice.TimelineEntity:setIdPrefix(long)
org.apache.hadoop.yarn.api.records.timelineservice.TimelineEntity$Identifier	setType	type	J	java.lang.String	0	org.apache.hadoop.yarn.api.records.timelineservice.TimelineEntity$Identifier:setType(java.lang.String)
org.apache.hadoop.yarn.api.records.timelineservice.TimelineEntity$Identifier	setId	id	J	java.lang.String	0	org.apache.hadoop.yarn.api.records.timelineservice.TimelineEntity$Identifier:setId(java.lang.String)
org.apache.hadoop.yarn.api.records.timeline.TimelineEvent	setTimestamp	timestamp	J	long	0	org.apache.hadoop.yarn.api.records.timeline.TimelineEvent:setTimestamp(long)
org.apache.hadoop.yarn.api.records.timeline.TimelineEvent	setEventType	eventType	J	java.lang.String	0	org.apache.hadoop.yarn.api.records.timeline.TimelineEvent:setEventType(java.lang.String)
org.apache.hadoop.yarn.api.records.timeline.TimelineEvents$EventsOfOneEntity	setEntityId	entityId	J	java.lang.String	0	org.apache.hadoop.yarn.api.records.timeline.TimelineEvents$EventsOfOneEntity:setEntityId(java.lang.String)
org.apache.hadoop.yarn.api.records.timeline.TimelineEvents$EventsOfOneEntity	setEntityType	entityType	J	java.lang.String	0	org.apache.hadoop.yarn.api.records.timeline.TimelineEvents$EventsOfOneEntity:setEntityType(java.lang.String)
org.apache.hadoop.yarn.api.records.timeline.TimelineEvents$EventsOfOneEntity	setEvents	events	GC	java.util.List	0	org.apache.hadoop.yarn.api.records.timeline.TimelineEvents$EventsOfOneEntity:setEvents(java.util.List)
org.apache.hadoop.yarn.api.records.timeline.TimelinePutResponse$TimelinePutError	setEntityId	entityId	J	java.lang.String	0	org.apache.hadoop.yarn.api.records.timeline.TimelinePutResponse$TimelinePutError:setEntityId(java.lang.String)
org.apache.hadoop.yarn.api.records.timeline.TimelinePutResponse$TimelinePutError	setEntityType	entityType	J	java.lang.String	0	org.apache.hadoop.yarn.api.records.timeline.TimelinePutResponse$TimelinePutError:setEntityType(java.lang.String)
org.apache.hadoop.yarn.api.records.timeline.TimelinePutResponse$TimelinePutError	setErrorCode	errorCode	J	int	0	org.apache.hadoop.yarn.api.records.timeline.TimelinePutResponse$TimelinePutError:setErrorCode(int)
org.apache.hadoop.yarn.api.records.timeline.TimelineEntityGroupId	setApplicationId	applicationId	C	org.apache.hadoop.yarn.api.records.ApplicationId	0	org.apache.hadoop.yarn.api.records.timeline.TimelineEntityGroupId:setApplicationId(org.apache.hadoop.yarn.api.records.ApplicationId)
org.apache.hadoop.yarn.api.records.timeline.TimelineEntityGroupId	setTimelineEntityGroupId	id	J	java.lang.String	0	org.apache.hadoop.yarn.api.records.timeline.TimelineEntityGroupId:setTimelineEntityGroupId(java.lang.String)
org.apache.hadoop.yarn.api.records.timeline.TimelineEntities	setEntities	entities	GC	java.util.List	0	org.apache.hadoop.yarn.api.records.timeline.TimelineEntities:setEntities(java.util.List)
org.apache.hadoop.yarn.api.records.timeline.TimelineAbout	setAbout	about	J	java.lang.String	0	org.apache.hadoop.yarn.api.records.timeline.TimelineAbout:setAbout(java.lang.String)
org.apache.hadoop.yarn.api.records.timeline.TimelineAbout	setTimelineServiceVersion	timelineServiceVersion	J	java.lang.String	0	org.apache.hadoop.yarn.api.records.timeline.TimelineAbout:setTimelineServiceVersion(java.lang.String)
org.apache.hadoop.yarn.api.records.timeline.TimelineAbout	setTimelineServiceBuildVersion	timelineServiceBuildVersion	J	java.lang.String	0	org.apache.hadoop.yarn.api.records.timeline.TimelineAbout:setTimelineServiceBuildVersion(java.lang.String)
org.apache.hadoop.yarn.api.records.timeline.TimelineAbout	setTimelineServiceVersionBuiltOn	timelineServiceVersionBuiltOn	J	java.lang.String	0	org.apache.hadoop.yarn.api.records.timeline.TimelineAbout:setTimelineServiceVersionBuiltOn(java.lang.String)
org.apache.hadoop.yarn.api.records.timeline.TimelineAbout	setHadoopVersion	hadoopVersion	J	java.lang.String	0	org.apache.hadoop.yarn.api.records.timeline.TimelineAbout:setHadoopVersion(java.lang.String)
org.apache.hadoop.yarn.api.records.timeline.TimelineAbout	setHadoopBuildVersion	hadoopBuildVersion	J	java.lang.String	0	org.apache.hadoop.yarn.api.records.timeline.TimelineAbout:setHadoopBuildVersion(java.lang.String)
org.apache.hadoop.yarn.api.records.timeline.TimelineAbout	setHadoopVersionBuiltOn	hadoopVersionBuiltOn	J	java.lang.String	0	org.apache.hadoop.yarn.api.records.timeline.TimelineAbout:setHadoopVersionBuiltOn(java.lang.String)
org.apache.hadoop.yarn.api.records.timeline.TimelineDelegationTokenResponse	setType	type	J	java.lang.String	0	org.apache.hadoop.yarn.api.records.timeline.TimelineDelegationTokenResponse:setType(java.lang.String)
org.apache.hadoop.yarn.api.records.timeline.TimelineDelegationTokenResponse	setContent	content	J	java.lang.Object	0	org.apache.hadoop.yarn.api.records.timeline.TimelineDelegationTokenResponse:setContent(java.lang.Object)
org.apache.hadoop.yarn.api.records.timeline.TimelineDomain	setId	id	J	java.lang.String	0	org.apache.hadoop.yarn.api.records.timeline.TimelineDomain:setId(java.lang.String)
org.apache.hadoop.yarn.api.records.timeline.TimelineDomain	setDescription	description	J	java.lang.String	0	org.apache.hadoop.yarn.api.records.timeline.TimelineDomain:setDescription(java.lang.String)
org.apache.hadoop.yarn.api.records.timeline.TimelineDomain	setOwner	owner	J	java.lang.String	0	org.apache.hadoop.yarn.api.records.timeline.TimelineDomain:setOwner(java.lang.String)
org.apache.hadoop.yarn.api.records.timeline.TimelineDomain	setReaders	readers	J	java.lang.String	0	org.apache.hadoop.yarn.api.records.timeline.TimelineDomain:setReaders(java.lang.String)
org.apache.hadoop.yarn.api.records.timeline.TimelineDomain	setWriters	writers	J	java.lang.String	0	org.apache.hadoop.yarn.api.records.timeline.TimelineDomain:setWriters(java.lang.String)
org.apache.hadoop.yarn.api.records.timeline.TimelineDomain	setCreatedTime	createdTime	J	java.lang.Long	0	org.apache.hadoop.yarn.api.records.timeline.TimelineDomain:setCreatedTime(java.lang.Long)
org.apache.hadoop.yarn.api.records.timeline.TimelineDomain	setModifiedTime	modifiedTime	J	java.lang.Long	0	org.apache.hadoop.yarn.api.records.timeline.TimelineDomain:setModifiedTime(java.lang.Long)
org.apache.hadoop.yarn.api.records.timeline.TimelineDomains	setDomains	domains	GC	java.util.List	0	org.apache.hadoop.yarn.api.records.timeline.TimelineDomains:setDomains(java.util.List)
org.apache.hadoop.yarn.api.records.timeline.TimelineEntity	setEntityType	entityType	J	java.lang.String	0	org.apache.hadoop.yarn.api.records.timeline.TimelineEntity:setEntityType(java.lang.String)
org.apache.hadoop.yarn.api.records.timeline.TimelineEntity	setEntityId	entityId	J	java.lang.String	0	org.apache.hadoop.yarn.api.records.timeline.TimelineEntity:setEntityId(java.lang.String)
org.apache.hadoop.yarn.api.records.timeline.TimelineEntity	setStartTime	startTime	J	java.lang.Long	0	org.apache.hadoop.yarn.api.records.timeline.TimelineEntity:setStartTime(java.lang.Long)
org.apache.hadoop.yarn.api.records.timeline.TimelineEntity	setEvents	events	GC	java.util.List	0	org.apache.hadoop.yarn.api.records.timeline.TimelineEntity:setEvents(java.util.List)
org.apache.hadoop.yarn.api.records.timeline.TimelineEntity	setDomainId	domainId	J	java.lang.String	0	org.apache.hadoop.yarn.api.records.timeline.TimelineEntity:setDomainId(java.lang.String)
org.apache.hadoop.yarn.api.records.timeline.TimelineHealth	setHealthStatus	healthStatus	C	org.apache.hadoop.yarn.api.records.timeline.TimelineHealth$TimelineHealthStatus	0	org.apache.hadoop.yarn.api.records.timeline.TimelineHealth:setHealthStatus(org.apache.hadoop.yarn.api.records.timeline.TimelineHealth$TimelineHealthStatus)
org.apache.hadoop.yarn.api.records.timeline.TimelineHealth	setDiagnosticsInfo	diagnosticsInfo	J	java.lang.String	0	org.apache.hadoop.yarn.api.records.timeline.TimelineHealth:setDiagnosticsInfo(java.lang.String)
org.apache.hadoop.yarn.proto.YarnProtos$ApplicationACLMapProto$Builder	setAcl	acl_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$ApplicationACLMapProto$Builder:setAcl(java.lang.String)
org.apache.hadoop.yarn.proto.YarnProtos$ApplicationACLMapProto$Builder	setAclBytes	acl_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$ApplicationACLMapProto$Builder:setAclBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnServiceProtos$GetApplicationsRequestProto$Builder	setLimit	limit_	J	long	0	org.apache.hadoop.yarn.proto.YarnServiceProtos$GetApplicationsRequestProto$Builder:setLimit(long)
org.apache.hadoop.yarn.proto.YarnServiceProtos$GetApplicationsRequestProto$Builder	setStartBegin	startBegin_	J	long	0	org.apache.hadoop.yarn.proto.YarnServiceProtos$GetApplicationsRequestProto$Builder:setStartBegin(long)
org.apache.hadoop.yarn.proto.YarnServiceProtos$GetApplicationsRequestProto$Builder	setStartEnd	startEnd_	J	long	0	org.apache.hadoop.yarn.proto.YarnServiceProtos$GetApplicationsRequestProto$Builder:setStartEnd(long)
org.apache.hadoop.yarn.proto.YarnServiceProtos$GetApplicationsRequestProto$Builder	setFinishBegin	finishBegin_	J	long	0	org.apache.hadoop.yarn.proto.YarnServiceProtos$GetApplicationsRequestProto$Builder:setFinishBegin(long)
org.apache.hadoop.yarn.proto.YarnServiceProtos$GetApplicationsRequestProto$Builder	setFinishEnd	finishEnd_	J	long	0	org.apache.hadoop.yarn.proto.YarnServiceProtos$GetApplicationsRequestProto$Builder:setFinishEnd(long)
org.apache.hadoop.yarn.proto.YarnServiceProtos$GetApplicationsRequestProto$Builder	setName	name_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServiceProtos$GetApplicationsRequestProto$Builder:setName(java.lang.String)
org.apache.hadoop.yarn.proto.YarnServiceProtos$GetApplicationsRequestProto$Builder	setNameBytes	name_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServiceProtos$GetApplicationsRequestProto$Builder:setNameBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnProtos$ApplicationTimeoutProto$Builder	setExpireTime	expireTime_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$ApplicationTimeoutProto$Builder:setExpireTime(java.lang.String)
org.apache.hadoop.yarn.proto.YarnProtos$ApplicationTimeoutProto$Builder	setExpireTimeBytes	expireTime_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$ApplicationTimeoutProto$Builder:setExpireTimeBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnProtos$ApplicationTimeoutProto$Builder	setRemainingTime	remainingTime_	J	long	0	org.apache.hadoop.yarn.proto.YarnProtos$ApplicationTimeoutProto$Builder:setRemainingTime(long)
org.apache.hadoop.yarn.proto.YarnServiceProtos$FinishApplicationMasterResponseProto$Builder	setIsUnregistered	isUnregistered_	J	boolean	0	org.apache.hadoop.yarn.proto.YarnServiceProtos$FinishApplicationMasterResponseProto$Builder:setIsUnregistered(boolean)
org.apache.hadoop.yarn.proto.YarnProtos$TimedPlacementConstraintProto$Builder	setSchedulingDelay	schedulingDelay_	J	long	0	org.apache.hadoop.yarn.proto.YarnProtos$TimedPlacementConstraintProto$Builder:setSchedulingDelay(long)
org.apache.hadoop.yarn.proto.YarnProtos$ResourceOptionProto$Builder	setOverCommitTimeout	overCommitTimeout_	J	int	0	org.apache.hadoop.yarn.proto.YarnProtos$ResourceOptionProto$Builder:setOverCommitTimeout(int)
org.apache.hadoop.yarn.proto.YarnProtos$SchedulingRequestProto$Builder	setAllocationRequestId	allocationRequestId_	J	long	0	org.apache.hadoop.yarn.proto.YarnProtos$SchedulingRequestProto$Builder:setAllocationRequestId(long)
org.apache.hadoop.yarn.proto.YarnProtos$ResourceProfileEntry$Builder	setName	name_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$ResourceProfileEntry$Builder:setName(java.lang.String)
org.apache.hadoop.yarn.proto.YarnProtos$ResourceProfileEntry$Builder	setNameBytes	name_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$ResourceProfileEntry$Builder:setNameBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnProtos$ReservationAllocationStateProto$Builder	setStartTime	startTime_	J	long	0	org.apache.hadoop.yarn.proto.YarnProtos$ReservationAllocationStateProto$Builder:setStartTime(long)
org.apache.hadoop.yarn.proto.YarnProtos$ReservationAllocationStateProto$Builder	setEndTime	endTime_	J	long	0	org.apache.hadoop.yarn.proto.YarnProtos$ReservationAllocationStateProto$Builder:setEndTime(long)
org.apache.hadoop.yarn.proto.YarnProtos$ReservationAllocationStateProto$Builder	setUser	user_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$ReservationAllocationStateProto$Builder:setUser(java.lang.String)
org.apache.hadoop.yarn.proto.YarnProtos$ReservationAllocationStateProto$Builder	setUserBytes	user_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$ReservationAllocationStateProto$Builder:setUserBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnProtos$ReservationAllocationStateProto$Builder	setContainsGangs	containsGangs_	J	boolean	0	org.apache.hadoop.yarn.proto.YarnProtos$ReservationAllocationStateProto$Builder:setContainsGangs(boolean)
org.apache.hadoop.yarn.proto.YarnProtos$ReservationAllocationStateProto$Builder	setAcceptanceTime	acceptanceTime_	J	long	0	org.apache.hadoop.yarn.proto.YarnProtos$ReservationAllocationStateProto$Builder:setAcceptanceTime(long)
org.apache.hadoop.yarn.proto.YarnServerResourceManagerServiceProtos$NodesToAttributesMappingRequestProto$Builder	setFailOnUnknownNodes	failOnUnknownNodes_	J	boolean	0	org.apache.hadoop.yarn.proto.YarnServerResourceManagerServiceProtos$NodesToAttributesMappingRequestProto$Builder:setFailOnUnknownNodes(boolean)
org.apache.hadoop.yarn.proto.YarnProtos$StringStringMapProto$Builder	setKey	key_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$StringStringMapProto$Builder:setKey(java.lang.String)
org.apache.hadoop.yarn.proto.YarnProtos$StringStringMapProto$Builder	setKeyBytes	key_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$StringStringMapProto$Builder:setKeyBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnProtos$StringStringMapProto$Builder	setValue	value_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$StringStringMapProto$Builder:setValue(java.lang.String)
org.apache.hadoop.yarn.proto.YarnProtos$StringStringMapProto$Builder	setValueBytes	value_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$StringStringMapProto$Builder:setValueBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnServerResourceManagerServiceProtos$ReplaceLabelsOnNodeRequestProto$Builder	setFailOnUnknownNodes	failOnUnknownNodes_	J	boolean	0	org.apache.hadoop.yarn.proto.YarnServerResourceManagerServiceProtos$ReplaceLabelsOnNodeRequestProto$Builder:setFailOnUnknownNodes(boolean)
org.apache.hadoop.yarn.proto.YarnServerResourceManagerServiceProtos$RefreshNodesRequestProto$Builder	setDecommissionTimeout	decommissionTimeout_	J	int	0	org.apache.hadoop.yarn.proto.YarnServerResourceManagerServiceProtos$RefreshNodesRequestProto$Builder:setDecommissionTimeout(int)
org.apache.hadoop.yarn.proto.CsiAdaptorProtos$NodeUnpublishVolumeRequest$Builder	setVolumeId	volumeId_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.CsiAdaptorProtos$NodeUnpublishVolumeRequest$Builder:setVolumeId(java.lang.String)
org.apache.hadoop.yarn.proto.CsiAdaptorProtos$NodeUnpublishVolumeRequest$Builder	setVolumeIdBytes	volumeId_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.CsiAdaptorProtos$NodeUnpublishVolumeRequest$Builder:setVolumeIdBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.CsiAdaptorProtos$NodeUnpublishVolumeRequest$Builder	setTargetPath	targetPath_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.CsiAdaptorProtos$NodeUnpublishVolumeRequest$Builder:setTargetPath(java.lang.String)
org.apache.hadoop.yarn.proto.CsiAdaptorProtos$NodeUnpublishVolumeRequest$Builder	setTargetPathBytes	targetPath_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.CsiAdaptorProtos$NodeUnpublishVolumeRequest$Builder:setTargetPathBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnProtos$ApplicationSubmissionContextProto$Builder	setApplicationName	applicationName_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$ApplicationSubmissionContextProto$Builder:setApplicationName(java.lang.String)
org.apache.hadoop.yarn.proto.YarnProtos$ApplicationSubmissionContextProto$Builder	setApplicationNameBytes	applicationName_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$ApplicationSubmissionContextProto$Builder:setApplicationNameBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnProtos$ApplicationSubmissionContextProto$Builder	setQueue	queue_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$ApplicationSubmissionContextProto$Builder:setQueue(java.lang.String)
org.apache.hadoop.yarn.proto.YarnProtos$ApplicationSubmissionContextProto$Builder	setQueueBytes	queue_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$ApplicationSubmissionContextProto$Builder:setQueueBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnProtos$ApplicationSubmissionContextProto$Builder	setCancelTokensWhenComplete	cancelTokensWhenComplete_	J	boolean	0	org.apache.hadoop.yarn.proto.YarnProtos$ApplicationSubmissionContextProto$Builder:setCancelTokensWhenComplete(boolean)
org.apache.hadoop.yarn.proto.YarnProtos$ApplicationSubmissionContextProto$Builder	setUnmanagedAm	unmanagedAm_	J	boolean	0	org.apache.hadoop.yarn.proto.YarnProtos$ApplicationSubmissionContextProto$Builder:setUnmanagedAm(boolean)
org.apache.hadoop.yarn.proto.YarnProtos$ApplicationSubmissionContextProto$Builder	setMaxAppAttempts	maxAppAttempts_	J	int	0	org.apache.hadoop.yarn.proto.YarnProtos$ApplicationSubmissionContextProto$Builder:setMaxAppAttempts(int)
org.apache.hadoop.yarn.proto.YarnProtos$ApplicationSubmissionContextProto$Builder	setApplicationType	applicationType_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$ApplicationSubmissionContextProto$Builder:setApplicationType(java.lang.String)
org.apache.hadoop.yarn.proto.YarnProtos$ApplicationSubmissionContextProto$Builder	setApplicationTypeBytes	applicationType_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$ApplicationSubmissionContextProto$Builder:setApplicationTypeBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnProtos$ApplicationSubmissionContextProto$Builder	setKeepContainersAcrossApplicationAttempts	keepContainersAcrossApplicationAttempts_	J	boolean	0	org.apache.hadoop.yarn.proto.YarnProtos$ApplicationSubmissionContextProto$Builder:setKeepContainersAcrossApplicationAttempts(boolean)
org.apache.hadoop.yarn.proto.YarnProtos$ApplicationSubmissionContextProto$Builder	setAttemptFailuresValidityInterval	attemptFailuresValidityInterval_	J	long	0	org.apache.hadoop.yarn.proto.YarnProtos$ApplicationSubmissionContextProto$Builder:setAttemptFailuresValidityInterval(long)
org.apache.hadoop.yarn.proto.YarnProtos$ApplicationSubmissionContextProto$Builder	setNodeLabelExpression	nodeLabelExpression_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$ApplicationSubmissionContextProto$Builder:setNodeLabelExpression(java.lang.String)
org.apache.hadoop.yarn.proto.YarnProtos$ApplicationSubmissionContextProto$Builder	setNodeLabelExpressionBytes	nodeLabelExpression_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$ApplicationSubmissionContextProto$Builder:setNodeLabelExpressionBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnProtos$ContainerStatusProto$Builder	setDiagnostics	diagnostics_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$ContainerStatusProto$Builder:setDiagnostics(java.lang.String)
org.apache.hadoop.yarn.proto.YarnProtos$ContainerStatusProto$Builder	setDiagnosticsBytes	diagnostics_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$ContainerStatusProto$Builder:setDiagnosticsBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnProtos$ContainerStatusProto$Builder	setExitStatus	exitStatus_	J	int	0	org.apache.hadoop.yarn.proto.YarnProtos$ContainerStatusProto$Builder:setExitStatus(int)
org.apache.hadoop.yarn.proto.YarnProtos$ApplicationUpdateTimeoutMapProto$Builder	setExpireTime	expireTime_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$ApplicationUpdateTimeoutMapProto$Builder:setExpireTime(java.lang.String)
org.apache.hadoop.yarn.proto.YarnProtos$ApplicationUpdateTimeoutMapProto$Builder	setExpireTimeBytes	expireTime_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$ApplicationUpdateTimeoutMapProto$Builder:setExpireTimeBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.CsiAdaptorProtos$GetPluginInfoResponse$Builder	setName	name_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.CsiAdaptorProtos$GetPluginInfoResponse$Builder:setName(java.lang.String)
org.apache.hadoop.yarn.proto.CsiAdaptorProtos$GetPluginInfoResponse$Builder	setNameBytes	name_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.CsiAdaptorProtos$GetPluginInfoResponse$Builder:setNameBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.CsiAdaptorProtos$GetPluginInfoResponse$Builder	setVendorVersion	vendorVersion_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.CsiAdaptorProtos$GetPluginInfoResponse$Builder:setVendorVersion(java.lang.String)
org.apache.hadoop.yarn.proto.CsiAdaptorProtos$GetPluginInfoResponse$Builder	setVendorVersionBytes	vendorVersion_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.CsiAdaptorProtos$GetPluginInfoResponse$Builder:setVendorVersionBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.ApplicationHistoryServerProtos$ApplicationFinishDataProto$Builder	setFinishTime	finishTime_	J	long	0	org.apache.hadoop.yarn.proto.ApplicationHistoryServerProtos$ApplicationFinishDataProto$Builder:setFinishTime(long)
org.apache.hadoop.yarn.proto.ApplicationHistoryServerProtos$ApplicationFinishDataProto$Builder	setDiagnosticsInfo	diagnosticsInfo_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.ApplicationHistoryServerProtos$ApplicationFinishDataProto$Builder:setDiagnosticsInfo(java.lang.String)
org.apache.hadoop.yarn.proto.ApplicationHistoryServerProtos$ApplicationFinishDataProto$Builder	setDiagnosticsInfoBytes	diagnosticsInfo_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.ApplicationHistoryServerProtos$ApplicationFinishDataProto$Builder:setDiagnosticsInfoBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnProtos$ContainerIdProto$Builder	setId	id_	J	long	0	org.apache.hadoop.yarn.proto.YarnProtos$ContainerIdProto$Builder:setId(long)
org.apache.hadoop.yarn.proto.YarnProtos$ApplicationReportProto$Builder	setUser	user_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$ApplicationReportProto$Builder:setUser(java.lang.String)
org.apache.hadoop.yarn.proto.YarnProtos$ApplicationReportProto$Builder	setUserBytes	user_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$ApplicationReportProto$Builder:setUserBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnProtos$ApplicationReportProto$Builder	setQueue	queue_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$ApplicationReportProto$Builder:setQueue(java.lang.String)
org.apache.hadoop.yarn.proto.YarnProtos$ApplicationReportProto$Builder	setQueueBytes	queue_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$ApplicationReportProto$Builder:setQueueBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnProtos$ApplicationReportProto$Builder	setName	name_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$ApplicationReportProto$Builder:setName(java.lang.String)
org.apache.hadoop.yarn.proto.YarnProtos$ApplicationReportProto$Builder	setNameBytes	name_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$ApplicationReportProto$Builder:setNameBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnProtos$ApplicationReportProto$Builder	setHost	host_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$ApplicationReportProto$Builder:setHost(java.lang.String)
org.apache.hadoop.yarn.proto.YarnProtos$ApplicationReportProto$Builder	setHostBytes	host_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$ApplicationReportProto$Builder:setHostBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnProtos$ApplicationReportProto$Builder	setRpcPort	rpcPort_	J	int	0	org.apache.hadoop.yarn.proto.YarnProtos$ApplicationReportProto$Builder:setRpcPort(int)
org.apache.hadoop.yarn.proto.YarnProtos$ApplicationReportProto$Builder	setTrackingUrl	trackingUrl_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$ApplicationReportProto$Builder:setTrackingUrl(java.lang.String)
org.apache.hadoop.yarn.proto.YarnProtos$ApplicationReportProto$Builder	setTrackingUrlBytes	trackingUrl_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$ApplicationReportProto$Builder:setTrackingUrlBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnProtos$ApplicationReportProto$Builder	setDiagnostics	diagnostics_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$ApplicationReportProto$Builder:setDiagnostics(java.lang.String)
org.apache.hadoop.yarn.proto.YarnProtos$ApplicationReportProto$Builder	setDiagnosticsBytes	diagnostics_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$ApplicationReportProto$Builder:setDiagnosticsBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnProtos$ApplicationReportProto$Builder	setStartTime	startTime_	J	long	0	org.apache.hadoop.yarn.proto.YarnProtos$ApplicationReportProto$Builder:setStartTime(long)
org.apache.hadoop.yarn.proto.YarnProtos$ApplicationReportProto$Builder	setFinishTime	finishTime_	J	long	0	org.apache.hadoop.yarn.proto.YarnProtos$ApplicationReportProto$Builder:setFinishTime(long)
org.apache.hadoop.yarn.proto.YarnProtos$ApplicationReportProto$Builder	setOriginalTrackingUrl	originalTrackingUrl_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$ApplicationReportProto$Builder:setOriginalTrackingUrl(java.lang.String)
org.apache.hadoop.yarn.proto.YarnProtos$ApplicationReportProto$Builder	setOriginalTrackingUrlBytes	originalTrackingUrl_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$ApplicationReportProto$Builder:setOriginalTrackingUrlBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnProtos$ApplicationReportProto$Builder	setProgress	progress_	J	float	0	org.apache.hadoop.yarn.proto.YarnProtos$ApplicationReportProto$Builder:setProgress(float)
org.apache.hadoop.yarn.proto.YarnProtos$ApplicationReportProto$Builder	setApplicationType	applicationType_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$ApplicationReportProto$Builder:setApplicationType(java.lang.String)
org.apache.hadoop.yarn.proto.YarnProtos$ApplicationReportProto$Builder	setApplicationTypeBytes	applicationType_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$ApplicationReportProto$Builder:setApplicationTypeBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnProtos$ApplicationReportProto$Builder	setUnmanagedApplication	unmanagedApplication_	J	boolean	0	org.apache.hadoop.yarn.proto.YarnProtos$ApplicationReportProto$Builder:setUnmanagedApplication(boolean)
org.apache.hadoop.yarn.proto.YarnProtos$ApplicationReportProto$Builder	setAppNodeLabelExpression	appNodeLabelExpression_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$ApplicationReportProto$Builder:setAppNodeLabelExpression(java.lang.String)
org.apache.hadoop.yarn.proto.YarnProtos$ApplicationReportProto$Builder	setAppNodeLabelExpressionBytes	appNodeLabelExpression_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$ApplicationReportProto$Builder:setAppNodeLabelExpressionBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnProtos$ApplicationReportProto$Builder	setAmNodeLabelExpression	amNodeLabelExpression_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$ApplicationReportProto$Builder:setAmNodeLabelExpression(java.lang.String)
org.apache.hadoop.yarn.proto.YarnProtos$ApplicationReportProto$Builder	setAmNodeLabelExpressionBytes	amNodeLabelExpression_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$ApplicationReportProto$Builder:setAmNodeLabelExpressionBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnProtos$ApplicationReportProto$Builder	setLaunchTime	launchTime_	J	long	0	org.apache.hadoop.yarn.proto.YarnProtos$ApplicationReportProto$Builder:setLaunchTime(long)
org.apache.hadoop.yarn.proto.YarnProtos$ApplicationReportProto$Builder	setSubmitTime	submitTime_	J	long	0	org.apache.hadoop.yarn.proto.YarnProtos$ApplicationReportProto$Builder:setSubmitTime(long)
org.apache.hadoop.yarn.proto.YarnProtos$ContainerReportProto$Builder	setCreationTime	creationTime_	J	long	0	org.apache.hadoop.yarn.proto.YarnProtos$ContainerReportProto$Builder:setCreationTime(long)
org.apache.hadoop.yarn.proto.YarnProtos$ContainerReportProto$Builder	setFinishTime	finishTime_	J	long	0	org.apache.hadoop.yarn.proto.YarnProtos$ContainerReportProto$Builder:setFinishTime(long)
org.apache.hadoop.yarn.proto.YarnProtos$ContainerReportProto$Builder	setDiagnosticsInfo	diagnosticsInfo_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$ContainerReportProto$Builder:setDiagnosticsInfo(java.lang.String)
org.apache.hadoop.yarn.proto.YarnProtos$ContainerReportProto$Builder	setDiagnosticsInfoBytes	diagnosticsInfo_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$ContainerReportProto$Builder:setDiagnosticsInfoBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnProtos$ContainerReportProto$Builder	setLogUrl	logUrl_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$ContainerReportProto$Builder:setLogUrl(java.lang.String)
org.apache.hadoop.yarn.proto.YarnProtos$ContainerReportProto$Builder	setLogUrlBytes	logUrl_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$ContainerReportProto$Builder:setLogUrlBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnProtos$ContainerReportProto$Builder	setContainerExitStatus	containerExitStatus_	J	int	0	org.apache.hadoop.yarn.proto.YarnProtos$ContainerReportProto$Builder:setContainerExitStatus(int)
org.apache.hadoop.yarn.proto.YarnProtos$ContainerReportProto$Builder	setNodeHttpAddress	nodeHttpAddress_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$ContainerReportProto$Builder:setNodeHttpAddress(java.lang.String)
org.apache.hadoop.yarn.proto.YarnProtos$ContainerReportProto$Builder	setNodeHttpAddressBytes	nodeHttpAddress_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$ContainerReportProto$Builder:setNodeHttpAddressBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnProtos$ContainerReportProto$Builder	setExposedPorts	exposedPorts_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$ContainerReportProto$Builder:setExposedPorts(java.lang.String)
org.apache.hadoop.yarn.proto.YarnProtos$ContainerReportProto$Builder	setExposedPortsBytes	exposedPorts_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$ContainerReportProto$Builder:setExposedPortsBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnProtos$NodeAttributeKeyProto$Builder	setAttributePrefix	attributePrefix_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$NodeAttributeKeyProto$Builder:setAttributePrefix(java.lang.String)
org.apache.hadoop.yarn.proto.YarnProtos$NodeAttributeKeyProto$Builder	setAttributePrefixBytes	attributePrefix_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$NodeAttributeKeyProto$Builder:setAttributePrefixBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnProtos$NodeAttributeKeyProto$Builder	setAttributeName	attributeName_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$NodeAttributeKeyProto$Builder:setAttributeName(java.lang.String)
org.apache.hadoop.yarn.proto.YarnProtos$NodeAttributeKeyProto$Builder	setAttributeNameBytes	attributeName_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$NodeAttributeKeyProto$Builder:setAttributeNameBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.ApplicationHistoryServerProtos$ApplicationAttemptStartDataProto$Builder	setHost	host_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.ApplicationHistoryServerProtos$ApplicationAttemptStartDataProto$Builder:setHost(java.lang.String)
org.apache.hadoop.yarn.proto.ApplicationHistoryServerProtos$ApplicationAttemptStartDataProto$Builder	setHostBytes	host_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.ApplicationHistoryServerProtos$ApplicationAttemptStartDataProto$Builder:setHostBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.ApplicationHistoryServerProtos$ApplicationAttemptStartDataProto$Builder	setRpcPort	rpcPort_	J	int	0	org.apache.hadoop.yarn.proto.ApplicationHistoryServerProtos$ApplicationAttemptStartDataProto$Builder:setRpcPort(int)
org.apache.hadoop.yarn.proto.YarnProtos$NodeToAttributesProto$Builder	setNode	node_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$NodeToAttributesProto$Builder:setNode(java.lang.String)
org.apache.hadoop.yarn.proto.YarnProtos$NodeToAttributesProto$Builder	setNodeBytes	node_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$NodeToAttributesProto$Builder:setNodeBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnProtos$StringLocalResourceMapProto$Builder	setKey	key_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$StringLocalResourceMapProto$Builder:setKey(java.lang.String)
org.apache.hadoop.yarn.proto.YarnProtos$StringLocalResourceMapProto$Builder	setKeyBytes	key_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$StringLocalResourceMapProto$Builder:setKeyBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnProtos$ResourceRequestProto$Builder	setResourceName	resourceName_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$ResourceRequestProto$Builder:setResourceName(java.lang.String)
org.apache.hadoop.yarn.proto.YarnProtos$ResourceRequestProto$Builder	setResourceNameBytes	resourceName_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$ResourceRequestProto$Builder:setResourceNameBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnProtos$ResourceRequestProto$Builder	setNumContainers	numContainers_	J	int	0	org.apache.hadoop.yarn.proto.YarnProtos$ResourceRequestProto$Builder:setNumContainers(int)
org.apache.hadoop.yarn.proto.YarnProtos$ResourceRequestProto$Builder	setRelaxLocality	relaxLocality_	J	boolean	0	org.apache.hadoop.yarn.proto.YarnProtos$ResourceRequestProto$Builder:setRelaxLocality(boolean)
org.apache.hadoop.yarn.proto.YarnProtos$ResourceRequestProto$Builder	setNodeLabelExpression	nodeLabelExpression_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$ResourceRequestProto$Builder:setNodeLabelExpression(java.lang.String)
org.apache.hadoop.yarn.proto.YarnProtos$ResourceRequestProto$Builder	setNodeLabelExpressionBytes	nodeLabelExpression_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$ResourceRequestProto$Builder:setNodeLabelExpressionBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnProtos$ResourceRequestProto$Builder	setAllocationRequestId	allocationRequestId_	J	long	0	org.apache.hadoop.yarn.proto.YarnProtos$ResourceRequestProto$Builder:setAllocationRequestId(long)
org.apache.hadoop.yarn.proto.YarnServiceProtos$KillApplicationResponseProto$Builder	setIsKillCompleted	isKillCompleted_	J	boolean	0	org.apache.hadoop.yarn.proto.YarnServiceProtos$KillApplicationResponseProto$Builder:setIsKillCompleted(boolean)
org.apache.hadoop.yarn.proto.YarnProtos$QueueConfigurationsProto$Builder	setCapacity	capacity_	J	float	0	org.apache.hadoop.yarn.proto.YarnProtos$QueueConfigurationsProto$Builder:setCapacity(float)
org.apache.hadoop.yarn.proto.YarnProtos$QueueConfigurationsProto$Builder	setAbsoluteCapacity	absoluteCapacity_	J	float	0	org.apache.hadoop.yarn.proto.YarnProtos$QueueConfigurationsProto$Builder:setAbsoluteCapacity(float)
org.apache.hadoop.yarn.proto.YarnProtos$QueueConfigurationsProto$Builder	setMaxCapacity	maxCapacity_	J	float	0	org.apache.hadoop.yarn.proto.YarnProtos$QueueConfigurationsProto$Builder:setMaxCapacity(float)
org.apache.hadoop.yarn.proto.YarnProtos$QueueConfigurationsProto$Builder	setAbsoluteMaxCapacity	absoluteMaxCapacity_	J	float	0	org.apache.hadoop.yarn.proto.YarnProtos$QueueConfigurationsProto$Builder:setAbsoluteMaxCapacity(float)
org.apache.hadoop.yarn.proto.YarnProtos$QueueConfigurationsProto$Builder	setMaxAMPercentage	maxAMPercentage_	J	float	0	org.apache.hadoop.yarn.proto.YarnProtos$QueueConfigurationsProto$Builder:setMaxAMPercentage(float)
org.apache.hadoop.yarn.proto.CsiAdaptorProtos$ValidateVolumeCapabilitiesRequest$Builder	setVolumeId	volumeId_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.CsiAdaptorProtos$ValidateVolumeCapabilitiesRequest$Builder:setVolumeId(java.lang.String)
org.apache.hadoop.yarn.proto.CsiAdaptorProtos$ValidateVolumeCapabilitiesRequest$Builder	setVolumeIdBytes	volumeId_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.CsiAdaptorProtos$ValidateVolumeCapabilitiesRequest$Builder:setVolumeIdBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnServiceProtos$RegisterApplicationMasterRequestProto$Builder	setHost	host_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServiceProtos$RegisterApplicationMasterRequestProto$Builder:setHost(java.lang.String)
org.apache.hadoop.yarn.proto.YarnServiceProtos$RegisterApplicationMasterRequestProto$Builder	setHostBytes	host_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServiceProtos$RegisterApplicationMasterRequestProto$Builder:setHostBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnServiceProtos$RegisterApplicationMasterRequestProto$Builder	setRpcPort	rpcPort_	J	int	0	org.apache.hadoop.yarn.proto.YarnServiceProtos$RegisterApplicationMasterRequestProto$Builder:setRpcPort(int)
org.apache.hadoop.yarn.proto.YarnServiceProtos$RegisterApplicationMasterRequestProto$Builder	setTrackingUrl	trackingUrl_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServiceProtos$RegisterApplicationMasterRequestProto$Builder:setTrackingUrl(java.lang.String)
org.apache.hadoop.yarn.proto.YarnServiceProtos$RegisterApplicationMasterRequestProto$Builder	setTrackingUrlBytes	trackingUrl_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServiceProtos$RegisterApplicationMasterRequestProto$Builder:setTrackingUrlBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnServiceProtos$RunSharedCacheCleanerTaskResponseProto$Builder	setAccepted	accepted_	J	boolean	0	org.apache.hadoop.yarn.proto.YarnServiceProtos$RunSharedCacheCleanerTaskResponseProto$Builder:setAccepted(boolean)
org.apache.hadoop.yarn.proto.ApplicationHistoryServerProtos$ContainerHistoryDataProto$Builder	setStartTime	startTime_	J	long	0	org.apache.hadoop.yarn.proto.ApplicationHistoryServerProtos$ContainerHistoryDataProto$Builder:setStartTime(long)
org.apache.hadoop.yarn.proto.ApplicationHistoryServerProtos$ContainerHistoryDataProto$Builder	setFinishTime	finishTime_	J	long	0	org.apache.hadoop.yarn.proto.ApplicationHistoryServerProtos$ContainerHistoryDataProto$Builder:setFinishTime(long)
org.apache.hadoop.yarn.proto.ApplicationHistoryServerProtos$ContainerHistoryDataProto$Builder	setDiagnosticsInfo	diagnosticsInfo_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.ApplicationHistoryServerProtos$ContainerHistoryDataProto$Builder:setDiagnosticsInfo(java.lang.String)
org.apache.hadoop.yarn.proto.ApplicationHistoryServerProtos$ContainerHistoryDataProto$Builder	setDiagnosticsInfoBytes	diagnosticsInfo_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.ApplicationHistoryServerProtos$ContainerHistoryDataProto$Builder:setDiagnosticsInfoBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.ApplicationHistoryServerProtos$ContainerHistoryDataProto$Builder	setContainerExitStatus	containerExitStatus_	J	int	0	org.apache.hadoop.yarn.proto.ApplicationHistoryServerProtos$ContainerHistoryDataProto$Builder:setContainerExitStatus(int)
org.apache.hadoop.yarn.proto.YarnProtos$SimplePlacementConstraintProto$Builder	setScope	scope_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$SimplePlacementConstraintProto$Builder:setScope(java.lang.String)
org.apache.hadoop.yarn.proto.YarnProtos$SimplePlacementConstraintProto$Builder	setScopeBytes	scope_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$SimplePlacementConstraintProto$Builder:setScopeBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnProtos$SimplePlacementConstraintProto$Builder	setMinCardinality	minCardinality_	J	int	0	org.apache.hadoop.yarn.proto.YarnProtos$SimplePlacementConstraintProto$Builder:setMinCardinality(int)
org.apache.hadoop.yarn.proto.YarnProtos$SimplePlacementConstraintProto$Builder	setMaxCardinality	maxCardinality_	J	int	0	org.apache.hadoop.yarn.proto.YarnProtos$SimplePlacementConstraintProto$Builder:setMaxCardinality(int)
org.apache.hadoop.yarn.proto.YarnProtos$LabelsToNodeIdsProto$Builder	setNodeLabels	nodeLabels_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$LabelsToNodeIdsProto$Builder:setNodeLabels(java.lang.String)
org.apache.hadoop.yarn.proto.YarnProtos$LabelsToNodeIdsProto$Builder	setNodeLabelsBytes	nodeLabels_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$LabelsToNodeIdsProto$Builder:setNodeLabelsBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnProtos$ResourceInformationProto$Builder	setKey	key_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$ResourceInformationProto$Builder:setKey(java.lang.String)
org.apache.hadoop.yarn.proto.YarnProtos$ResourceInformationProto$Builder	setKeyBytes	key_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$ResourceInformationProto$Builder:setKeyBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnProtos$ResourceInformationProto$Builder	setValue	value_	J	long	0	org.apache.hadoop.yarn.proto.YarnProtos$ResourceInformationProto$Builder:setValue(long)
org.apache.hadoop.yarn.proto.YarnProtos$ResourceInformationProto$Builder	setUnits	units_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$ResourceInformationProto$Builder:setUnits(java.lang.String)
org.apache.hadoop.yarn.proto.YarnProtos$ResourceInformationProto$Builder	setUnitsBytes	units_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$ResourceInformationProto$Builder:setUnitsBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnProtos$ContainerProto$Builder	setNodeHttpAddress	nodeHttpAddress_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$ContainerProto$Builder:setNodeHttpAddress(java.lang.String)
org.apache.hadoop.yarn.proto.YarnProtos$ContainerProto$Builder	setNodeHttpAddressBytes	nodeHttpAddress_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$ContainerProto$Builder:setNodeHttpAddressBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnProtos$ContainerProto$Builder	setAllocationRequestId	allocationRequestId_	J	long	0	org.apache.hadoop.yarn.proto.YarnProtos$ContainerProto$Builder:setAllocationRequestId(long)
org.apache.hadoop.yarn.proto.YarnProtos$ContainerProto$Builder	setVersion	version_	J	int	0	org.apache.hadoop.yarn.proto.YarnProtos$ContainerProto$Builder:setVersion(int)
org.apache.hadoop.yarn.proto.YarnProtos$ContainerProto$Builder	setExposedPorts	exposedPorts_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$ContainerProto$Builder:setExposedPorts(java.lang.String)
org.apache.hadoop.yarn.proto.YarnProtos$ContainerProto$Builder	setExposedPortsBytes	exposedPorts_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$ContainerProto$Builder:setExposedPortsBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnServerResourceManagerServiceProtos$ActiveRMInfoProto$Builder	setClusterId	clusterId_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServerResourceManagerServiceProtos$ActiveRMInfoProto$Builder:setClusterId(java.lang.String)
org.apache.hadoop.yarn.proto.YarnServerResourceManagerServiceProtos$ActiveRMInfoProto$Builder	setClusterIdBytes	clusterId_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServerResourceManagerServiceProtos$ActiveRMInfoProto$Builder:setClusterIdBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnServerResourceManagerServiceProtos$ActiveRMInfoProto$Builder	setRmId	rmId_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServerResourceManagerServiceProtos$ActiveRMInfoProto$Builder:setRmId(java.lang.String)
org.apache.hadoop.yarn.proto.YarnServerResourceManagerServiceProtos$ActiveRMInfoProto$Builder	setRmIdBytes	rmId_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServerResourceManagerServiceProtos$ActiveRMInfoProto$Builder:setRmIdBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnProtos$ResourceTypeInfoProto$Builder	setName	name_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$ResourceTypeInfoProto$Builder:setName(java.lang.String)
org.apache.hadoop.yarn.proto.YarnProtos$ResourceTypeInfoProto$Builder	setNameBytes	name_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$ResourceTypeInfoProto$Builder:setNameBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnProtos$ResourceTypeInfoProto$Builder	setUnits	units_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$ResourceTypeInfoProto$Builder:setUnits(java.lang.String)
org.apache.hadoop.yarn.proto.YarnProtos$ResourceTypeInfoProto$Builder	setUnitsBytes	units_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$ResourceTypeInfoProto$Builder:setUnitsBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnProtos$QueueInfoProto$Builder	setQueueName	queueName_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$QueueInfoProto$Builder:setQueueName(java.lang.String)
org.apache.hadoop.yarn.proto.YarnProtos$QueueInfoProto$Builder	setQueueNameBytes	queueName_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$QueueInfoProto$Builder:setQueueNameBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnProtos$QueueInfoProto$Builder	setCapacity	capacity_	J	float	0	org.apache.hadoop.yarn.proto.YarnProtos$QueueInfoProto$Builder:setCapacity(float)
org.apache.hadoop.yarn.proto.YarnProtos$QueueInfoProto$Builder	setMaximumCapacity	maximumCapacity_	J	float	0	org.apache.hadoop.yarn.proto.YarnProtos$QueueInfoProto$Builder:setMaximumCapacity(float)
org.apache.hadoop.yarn.proto.YarnProtos$QueueInfoProto$Builder	setCurrentCapacity	currentCapacity_	J	float	0	org.apache.hadoop.yarn.proto.YarnProtos$QueueInfoProto$Builder:setCurrentCapacity(float)
org.apache.hadoop.yarn.proto.YarnProtos$QueueInfoProto$Builder	setDefaultNodeLabelExpression	defaultNodeLabelExpression_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$QueueInfoProto$Builder:setDefaultNodeLabelExpression(java.lang.String)
org.apache.hadoop.yarn.proto.YarnProtos$QueueInfoProto$Builder	setDefaultNodeLabelExpressionBytes	defaultNodeLabelExpression_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$QueueInfoProto$Builder:setDefaultNodeLabelExpressionBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnProtos$QueueInfoProto$Builder	setPreemptionDisabled	preemptionDisabled_	J	boolean	0	org.apache.hadoop.yarn.proto.YarnProtos$QueueInfoProto$Builder:setPreemptionDisabled(boolean)
org.apache.hadoop.yarn.proto.YarnProtos$QueueInfoProto$Builder	setIntraQueuePreemptionDisabled	intraQueuePreemptionDisabled_	J	boolean	0	org.apache.hadoop.yarn.proto.YarnProtos$QueueInfoProto$Builder:setIntraQueuePreemptionDisabled(boolean)
org.apache.hadoop.yarn.proto.YarnProtos$ExecutionTypeRequestProto$Builder	setEnforceExecutionType	enforceExecutionType_	J	boolean	0	org.apache.hadoop.yarn.proto.YarnProtos$ExecutionTypeRequestProto$Builder:setEnforceExecutionType(boolean)
org.apache.hadoop.yarn.proto.YarnProtos$ApplicationAttemptIdProto$Builder	setAttemptId	attemptId_	J	int	0	org.apache.hadoop.yarn.proto.YarnProtos$ApplicationAttemptIdProto$Builder:setAttemptId(int)
org.apache.hadoop.yarn.proto.YarnProtos$NodeLabelProto$Builder	setName	name_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$NodeLabelProto$Builder:setName(java.lang.String)
org.apache.hadoop.yarn.proto.YarnProtos$NodeLabelProto$Builder	setNameBytes	name_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$NodeLabelProto$Builder:setNameBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnProtos$NodeLabelProto$Builder	setIsExclusive	isExclusive_	J	boolean	0	org.apache.hadoop.yarn.proto.YarnProtos$NodeLabelProto$Builder:setIsExclusive(boolean)
org.apache.hadoop.yarn.proto.ApplicationHistoryServerProtos$ContainerStartDataProto$Builder	setStartTime	startTime_	J	long	0	org.apache.hadoop.yarn.proto.ApplicationHistoryServerProtos$ContainerStartDataProto$Builder:setStartTime(long)
org.apache.hadoop.yarn.proto.YarnProtos$ReservationRequestProto$Builder	setNumContainers	numContainers_	J	int	0	org.apache.hadoop.yarn.proto.YarnProtos$ReservationRequestProto$Builder:setNumContainers(int)
org.apache.hadoop.yarn.proto.YarnProtos$ReservationRequestProto$Builder	setConcurrency	concurrency_	J	int	0	org.apache.hadoop.yarn.proto.YarnProtos$ReservationRequestProto$Builder:setConcurrency(int)
org.apache.hadoop.yarn.proto.YarnProtos$ReservationRequestProto$Builder	setDuration	duration_	J	long	0	org.apache.hadoop.yarn.proto.YarnProtos$ReservationRequestProto$Builder:setDuration(long)
org.apache.hadoop.yarn.proto.YarnProtos$StringBytesMapProto$Builder	setKey	key_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$StringBytesMapProto$Builder:setKey(java.lang.String)
org.apache.hadoop.yarn.proto.YarnProtos$StringBytesMapProto$Builder	setKeyBytes	key_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$StringBytesMapProto$Builder:setKeyBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnProtos$StringBytesMapProto$Builder	setValue	value_	C	org.apache.hadoop.thirdparty.protobuf.ByteString	0	org.apache.hadoop.yarn.proto.YarnProtos$StringBytesMapProto$Builder:setValue(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnProtos$YarnClusterMetricsProto$Builder	setNumNodeManagers	numNodeManagers_	J	int	0	org.apache.hadoop.yarn.proto.YarnProtos$YarnClusterMetricsProto$Builder:setNumNodeManagers(int)
org.apache.hadoop.yarn.proto.YarnProtos$YarnClusterMetricsProto$Builder	setNumDecommissionedNms	numDecommissionedNms_	J	int	0	org.apache.hadoop.yarn.proto.YarnProtos$YarnClusterMetricsProto$Builder:setNumDecommissionedNms(int)
org.apache.hadoop.yarn.proto.YarnProtos$YarnClusterMetricsProto$Builder	setNumActiveNms	numActiveNms_	J	int	0	org.apache.hadoop.yarn.proto.YarnProtos$YarnClusterMetricsProto$Builder:setNumActiveNms(int)
org.apache.hadoop.yarn.proto.YarnProtos$YarnClusterMetricsProto$Builder	setNumLostNms	numLostNms_	J	int	0	org.apache.hadoop.yarn.proto.YarnProtos$YarnClusterMetricsProto$Builder:setNumLostNms(int)
org.apache.hadoop.yarn.proto.YarnProtos$YarnClusterMetricsProto$Builder	setNumUnhealthyNms	numUnhealthyNms_	J	int	0	org.apache.hadoop.yarn.proto.YarnProtos$YarnClusterMetricsProto$Builder:setNumUnhealthyNms(int)
org.apache.hadoop.yarn.proto.YarnProtos$YarnClusterMetricsProto$Builder	setNumRebootedNms	numRebootedNms_	J	int	0	org.apache.hadoop.yarn.proto.YarnProtos$YarnClusterMetricsProto$Builder:setNumRebootedNms(int)
org.apache.hadoop.yarn.proto.YarnProtos$YarnClusterMetricsProto$Builder	setNumDecommissioningNms	numDecommissioningNms_	J	int	0	org.apache.hadoop.yarn.proto.YarnProtos$YarnClusterMetricsProto$Builder:setNumDecommissioningNms(int)
org.apache.hadoop.yarn.proto.YarnProtos$YarnClusterMetricsProto$Builder	setNumShutdownNms	numShutdownNms_	J	int	0	org.apache.hadoop.yarn.proto.YarnProtos$YarnClusterMetricsProto$Builder:setNumShutdownNms(int)
org.apache.hadoop.yarn.proto.YarnProtos$CollectorInfoProto$Builder	setCollectorAddr	collectorAddr_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$CollectorInfoProto$Builder:setCollectorAddr(java.lang.String)
org.apache.hadoop.yarn.proto.YarnProtos$CollectorInfoProto$Builder	setCollectorAddrBytes	collectorAddr_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$CollectorInfoProto$Builder:setCollectorAddrBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnProtos$URLProto$Builder	setScheme	scheme_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$URLProto$Builder:setScheme(java.lang.String)
org.apache.hadoop.yarn.proto.YarnProtos$URLProto$Builder	setSchemeBytes	scheme_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$URLProto$Builder:setSchemeBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnProtos$URLProto$Builder	setHost	host_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$URLProto$Builder:setHost(java.lang.String)
org.apache.hadoop.yarn.proto.YarnProtos$URLProto$Builder	setHostBytes	host_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$URLProto$Builder:setHostBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnProtos$URLProto$Builder	setPort	port_	J	int	0	org.apache.hadoop.yarn.proto.YarnProtos$URLProto$Builder:setPort(int)
org.apache.hadoop.yarn.proto.YarnProtos$URLProto$Builder	setFile	file_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$URLProto$Builder:setFile(java.lang.String)
org.apache.hadoop.yarn.proto.YarnProtos$URLProto$Builder	setFileBytes	file_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$URLProto$Builder:setFileBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnProtos$URLProto$Builder	setUserInfo	userInfo_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$URLProto$Builder:setUserInfo(java.lang.String)
org.apache.hadoop.yarn.proto.YarnProtos$URLProto$Builder	setUserInfoBytes	userInfo_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$URLProto$Builder:setUserInfoBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnProtos$ReservationIdProto$Builder	setId	id_	J	long	0	org.apache.hadoop.yarn.proto.YarnProtos$ReservationIdProto$Builder:setId(long)
org.apache.hadoop.yarn.proto.YarnProtos$ReservationIdProto$Builder	setClusterTimestamp	clusterTimestamp_	J	long	0	org.apache.hadoop.yarn.proto.YarnProtos$ReservationIdProto$Builder:setClusterTimestamp(long)
org.apache.hadoop.yarn.proto.YarnServiceProtos$KillApplicationRequestProto$Builder	setDiagnostics	diagnostics_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServiceProtos$KillApplicationRequestProto$Builder:setDiagnostics(java.lang.String)
org.apache.hadoop.yarn.proto.YarnServiceProtos$KillApplicationRequestProto$Builder	setDiagnosticsBytes	diagnostics_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServiceProtos$KillApplicationRequestProto$Builder:setDiagnosticsBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnServiceProtos$ReleaseSharedCacheResourceRequestProto$Builder	setResourceKey	resourceKey_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServiceProtos$ReleaseSharedCacheResourceRequestProto$Builder:setResourceKey(java.lang.String)
org.apache.hadoop.yarn.proto.YarnServiceProtos$ReleaseSharedCacheResourceRequestProto$Builder	setResourceKeyBytes	resourceKey_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServiceProtos$ReleaseSharedCacheResourceRequestProto$Builder:setResourceKeyBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnServiceProtos$GetResourceProfileRequestProto$Builder	setProfile	profile_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServiceProtos$GetResourceProfileRequestProto$Builder:setProfile(java.lang.String)
org.apache.hadoop.yarn.proto.YarnServiceProtos$GetResourceProfileRequestProto$Builder	setProfileBytes	profile_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServiceProtos$GetResourceProfileRequestProto$Builder:setProfileBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnServiceProtos$FinishApplicationMasterRequestProto$Builder	setDiagnostics	diagnostics_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServiceProtos$FinishApplicationMasterRequestProto$Builder:setDiagnostics(java.lang.String)
org.apache.hadoop.yarn.proto.YarnServiceProtos$FinishApplicationMasterRequestProto$Builder	setDiagnosticsBytes	diagnostics_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServiceProtos$FinishApplicationMasterRequestProto$Builder:setDiagnosticsBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnServiceProtos$FinishApplicationMasterRequestProto$Builder	setTrackingUrl	trackingUrl_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServiceProtos$FinishApplicationMasterRequestProto$Builder:setTrackingUrl(java.lang.String)
org.apache.hadoop.yarn.proto.YarnServiceProtos$FinishApplicationMasterRequestProto$Builder	setTrackingUrlBytes	trackingUrl_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServiceProtos$FinishApplicationMasterRequestProto$Builder:setTrackingUrlBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.ApplicationHistoryServerProtos$ApplicationAttemptFinishDataProto$Builder	setTrackingUrl	trackingUrl_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.ApplicationHistoryServerProtos$ApplicationAttemptFinishDataProto$Builder:setTrackingUrl(java.lang.String)
org.apache.hadoop.yarn.proto.ApplicationHistoryServerProtos$ApplicationAttemptFinishDataProto$Builder	setTrackingUrlBytes	trackingUrl_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.ApplicationHistoryServerProtos$ApplicationAttemptFinishDataProto$Builder:setTrackingUrlBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.ApplicationHistoryServerProtos$ApplicationAttemptFinishDataProto$Builder	setDiagnosticsInfo	diagnosticsInfo_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.ApplicationHistoryServerProtos$ApplicationAttemptFinishDataProto$Builder:setDiagnosticsInfo(java.lang.String)
org.apache.hadoop.yarn.proto.ApplicationHistoryServerProtos$ApplicationAttemptFinishDataProto$Builder	setDiagnosticsInfoBytes	diagnosticsInfo_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.ApplicationHistoryServerProtos$ApplicationAttemptFinishDataProto$Builder:setDiagnosticsInfoBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnServiceProtos$UseSharedCacheResourceRequestProto$Builder	setResourceKey	resourceKey_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServiceProtos$UseSharedCacheResourceRequestProto$Builder:setResourceKey(java.lang.String)
org.apache.hadoop.yarn.proto.YarnServiceProtos$UseSharedCacheResourceRequestProto$Builder	setResourceKeyBytes	resourceKey_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServiceProtos$UseSharedCacheResourceRequestProto$Builder:setResourceKeyBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnServiceProtos$LocalizationStatusProto$Builder	setResourceKey	resourceKey_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServiceProtos$LocalizationStatusProto$Builder:setResourceKey(java.lang.String)
org.apache.hadoop.yarn.proto.YarnServiceProtos$LocalizationStatusProto$Builder	setResourceKeyBytes	resourceKey_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServiceProtos$LocalizationStatusProto$Builder:setResourceKeyBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnServiceProtos$LocalizationStatusProto$Builder	setDiagnostics	diagnostics_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServiceProtos$LocalizationStatusProto$Builder:setDiagnostics(java.lang.String)
org.apache.hadoop.yarn.proto.YarnServiceProtos$LocalizationStatusProto$Builder	setDiagnosticsBytes	diagnostics_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServiceProtos$LocalizationStatusProto$Builder:setDiagnosticsBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnServiceProtos$UpdateContainerErrorProto$Builder	setReason	reason_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServiceProtos$UpdateContainerErrorProto$Builder:setReason(java.lang.String)
org.apache.hadoop.yarn.proto.YarnServiceProtos$UpdateContainerErrorProto$Builder	setReasonBytes	reason_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServiceProtos$UpdateContainerErrorProto$Builder:setReasonBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnServiceProtos$UpdateContainerErrorProto$Builder	setCurrentContainerVersion	currentContainerVersion_	J	int	0	org.apache.hadoop.yarn.proto.YarnServiceProtos$UpdateContainerErrorProto$Builder:setCurrentContainerVersion(int)
org.apache.hadoop.yarn.proto.YarnProtos$PlacementConstraintTargetProto$Builder	setTargetKey	targetKey_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$PlacementConstraintTargetProto$Builder:setTargetKey(java.lang.String)
org.apache.hadoop.yarn.proto.YarnProtos$PlacementConstraintTargetProto$Builder	setTargetKeyBytes	targetKey_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$PlacementConstraintTargetProto$Builder:setTargetKeyBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnProtos$ContainerLaunchContextProto$Builder	setTokens	tokens_	C	org.apache.hadoop.thirdparty.protobuf.ByteString	0	org.apache.hadoop.yarn.proto.YarnProtos$ContainerLaunchContextProto$Builder:setTokens(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnProtos$ContainerLaunchContextProto$Builder	setTokensConf	tokensConf_	C	org.apache.hadoop.thirdparty.protobuf.ByteString	0	org.apache.hadoop.yarn.proto.YarnProtos$ContainerLaunchContextProto$Builder:setTokensConf(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnProtos$SerializedExceptionProto$Builder	setMessage	message_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$SerializedExceptionProto$Builder:setMessage(java.lang.String)
org.apache.hadoop.yarn.proto.YarnProtos$SerializedExceptionProto$Builder	setMessageBytes	message_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$SerializedExceptionProto$Builder:setMessageBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnProtos$SerializedExceptionProto$Builder	setTrace	trace_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$SerializedExceptionProto$Builder:setTrace(java.lang.String)
org.apache.hadoop.yarn.proto.YarnProtos$SerializedExceptionProto$Builder	setTraceBytes	trace_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$SerializedExceptionProto$Builder:setTraceBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnProtos$SerializedExceptionProto$Builder	setClassName	className_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$SerializedExceptionProto$Builder:setClassName(java.lang.String)
org.apache.hadoop.yarn.proto.YarnProtos$SerializedExceptionProto$Builder	setClassNameBytes	className_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$SerializedExceptionProto$Builder:setClassNameBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnProtos$StringLongMapProto$Builder	setKey	key_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$StringLongMapProto$Builder:setKey(java.lang.String)
org.apache.hadoop.yarn.proto.YarnProtos$StringLongMapProto$Builder	setKeyBytes	key_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$StringLongMapProto$Builder:setKeyBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnProtos$StringLongMapProto$Builder	setValue	value_	J	long	0	org.apache.hadoop.yarn.proto.YarnProtos$StringLongMapProto$Builder:setValue(long)
org.apache.hadoop.yarn.proto.YarnServiceProtos$RegisterApplicationMasterResponseProto$Builder	setClientToAmTokenMasterKey	clientToAmTokenMasterKey_	C	org.apache.hadoop.thirdparty.protobuf.ByteString	0	org.apache.hadoop.yarn.proto.YarnServiceProtos$RegisterApplicationMasterResponseProto$Builder:setClientToAmTokenMasterKey(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnServiceProtos$RegisterApplicationMasterResponseProto$Builder	setQueue	queue_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServiceProtos$RegisterApplicationMasterResponseProto$Builder:setQueue(java.lang.String)
org.apache.hadoop.yarn.proto.YarnServiceProtos$RegisterApplicationMasterResponseProto$Builder	setQueueBytes	queue_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServiceProtos$RegisterApplicationMasterResponseProto$Builder:setQueueBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnProtos$ApplicationResourceUsageReportProto$Builder	setNumUsedContainers	numUsedContainers_	J	int	0	org.apache.hadoop.yarn.proto.YarnProtos$ApplicationResourceUsageReportProto$Builder:setNumUsedContainers(int)
org.apache.hadoop.yarn.proto.YarnProtos$ApplicationResourceUsageReportProto$Builder	setNumReservedContainers	numReservedContainers_	J	int	0	org.apache.hadoop.yarn.proto.YarnProtos$ApplicationResourceUsageReportProto$Builder:setNumReservedContainers(int)
org.apache.hadoop.yarn.proto.YarnProtos$ApplicationResourceUsageReportProto$Builder	setMemorySeconds	memorySeconds_	J	long	0	org.apache.hadoop.yarn.proto.YarnProtos$ApplicationResourceUsageReportProto$Builder:setMemorySeconds(long)
org.apache.hadoop.yarn.proto.YarnProtos$ApplicationResourceUsageReportProto$Builder	setVcoreSeconds	vcoreSeconds_	J	long	0	org.apache.hadoop.yarn.proto.YarnProtos$ApplicationResourceUsageReportProto$Builder:setVcoreSeconds(long)
org.apache.hadoop.yarn.proto.YarnProtos$ApplicationResourceUsageReportProto$Builder	setQueueUsagePercentage	queueUsagePercentage_	J	float	0	org.apache.hadoop.yarn.proto.YarnProtos$ApplicationResourceUsageReportProto$Builder:setQueueUsagePercentage(float)
org.apache.hadoop.yarn.proto.YarnProtos$ApplicationResourceUsageReportProto$Builder	setClusterUsagePercentage	clusterUsagePercentage_	J	float	0	org.apache.hadoop.yarn.proto.YarnProtos$ApplicationResourceUsageReportProto$Builder:setClusterUsagePercentage(float)
org.apache.hadoop.yarn.proto.YarnProtos$ApplicationResourceUsageReportProto$Builder	setPreemptedMemorySeconds	preemptedMemorySeconds_	J	long	0	org.apache.hadoop.yarn.proto.YarnProtos$ApplicationResourceUsageReportProto$Builder:setPreemptedMemorySeconds(long)
org.apache.hadoop.yarn.proto.YarnProtos$ApplicationResourceUsageReportProto$Builder	setPreemptedVcoreSeconds	preemptedVcoreSeconds_	J	long	0	org.apache.hadoop.yarn.proto.YarnProtos$ApplicationResourceUsageReportProto$Builder:setPreemptedVcoreSeconds(long)
org.apache.hadoop.yarn.proto.ApplicationHistoryServerProtos$ApplicationStartDataProto$Builder	setApplicationName	applicationName_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.ApplicationHistoryServerProtos$ApplicationStartDataProto$Builder:setApplicationName(java.lang.String)
org.apache.hadoop.yarn.proto.ApplicationHistoryServerProtos$ApplicationStartDataProto$Builder	setApplicationNameBytes	applicationName_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.ApplicationHistoryServerProtos$ApplicationStartDataProto$Builder:setApplicationNameBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.ApplicationHistoryServerProtos$ApplicationStartDataProto$Builder	setApplicationType	applicationType_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.ApplicationHistoryServerProtos$ApplicationStartDataProto$Builder:setApplicationType(java.lang.String)
org.apache.hadoop.yarn.proto.ApplicationHistoryServerProtos$ApplicationStartDataProto$Builder	setApplicationTypeBytes	applicationType_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.ApplicationHistoryServerProtos$ApplicationStartDataProto$Builder:setApplicationTypeBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.ApplicationHistoryServerProtos$ApplicationStartDataProto$Builder	setUser	user_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.ApplicationHistoryServerProtos$ApplicationStartDataProto$Builder:setUser(java.lang.String)
org.apache.hadoop.yarn.proto.ApplicationHistoryServerProtos$ApplicationStartDataProto$Builder	setUserBytes	user_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.ApplicationHistoryServerProtos$ApplicationStartDataProto$Builder:setUserBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.ApplicationHistoryServerProtos$ApplicationStartDataProto$Builder	setQueue	queue_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.ApplicationHistoryServerProtos$ApplicationStartDataProto$Builder:setQueue(java.lang.String)
org.apache.hadoop.yarn.proto.ApplicationHistoryServerProtos$ApplicationStartDataProto$Builder	setQueueBytes	queue_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.ApplicationHistoryServerProtos$ApplicationStartDataProto$Builder:setQueueBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.ApplicationHistoryServerProtos$ApplicationStartDataProto$Builder	setSubmitTime	submitTime_	J	long	0	org.apache.hadoop.yarn.proto.ApplicationHistoryServerProtos$ApplicationStartDataProto$Builder:setSubmitTime(long)
org.apache.hadoop.yarn.proto.ApplicationHistoryServerProtos$ApplicationStartDataProto$Builder	setStartTime	startTime_	J	long	0	org.apache.hadoop.yarn.proto.ApplicationHistoryServerProtos$ApplicationStartDataProto$Builder:setStartTime(long)
org.apache.hadoop.yarn.proto.YarnProtos$ReservationDefinitionProto$Builder	setArrival	arrival_	J	long	0	org.apache.hadoop.yarn.proto.YarnProtos$ReservationDefinitionProto$Builder:setArrival(long)
org.apache.hadoop.yarn.proto.YarnProtos$ReservationDefinitionProto$Builder	setDeadline	deadline_	J	long	0	org.apache.hadoop.yarn.proto.YarnProtos$ReservationDefinitionProto$Builder:setDeadline(long)
org.apache.hadoop.yarn.proto.YarnProtos$ReservationDefinitionProto$Builder	setReservationName	reservationName_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$ReservationDefinitionProto$Builder:setReservationName(java.lang.String)
org.apache.hadoop.yarn.proto.YarnProtos$ReservationDefinitionProto$Builder	setReservationNameBytes	reservationName_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$ReservationDefinitionProto$Builder:setReservationNameBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnProtos$ReservationDefinitionProto$Builder	setRecurrenceExpression	recurrenceExpression_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$ReservationDefinitionProto$Builder:setRecurrenceExpression(java.lang.String)
org.apache.hadoop.yarn.proto.YarnProtos$ReservationDefinitionProto$Builder	setRecurrenceExpressionBytes	recurrenceExpression_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$ReservationDefinitionProto$Builder:setRecurrenceExpressionBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnProtos$QueueUserACLInfoProto$Builder	setQueueName	queueName_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$QueueUserACLInfoProto$Builder:setQueueName(java.lang.String)
org.apache.hadoop.yarn.proto.YarnProtos$QueueUserACLInfoProto$Builder	setQueueNameBytes	queueName_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$QueueUserACLInfoProto$Builder:setQueueNameBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnServiceProtos$ReservationSubmissionRequestProto$Builder	setQueue	queue_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServiceProtos$ReservationSubmissionRequestProto$Builder:setQueue(java.lang.String)
org.apache.hadoop.yarn.proto.YarnServiceProtos$ReservationSubmissionRequestProto$Builder	setQueueBytes	queue_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServiceProtos$ReservationSubmissionRequestProto$Builder:setQueueBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnServiceProtos$AllocateResponseProto$Builder	setResponseId	responseId_	J	int	0	org.apache.hadoop.yarn.proto.YarnServiceProtos$AllocateResponseProto$Builder:setResponseId(int)
org.apache.hadoop.yarn.proto.YarnServiceProtos$AllocateResponseProto$Builder	setNumClusterNodes	numClusterNodes_	J	int	0	org.apache.hadoop.yarn.proto.YarnServiceProtos$AllocateResponseProto$Builder:setNumClusterNodes(int)
org.apache.hadoop.yarn.proto.YarnProtos$ResourceUtilizationProto$Builder	setPmem	pmem_	J	int	0	org.apache.hadoop.yarn.proto.YarnProtos$ResourceUtilizationProto$Builder:setPmem(int)
org.apache.hadoop.yarn.proto.YarnProtos$ResourceUtilizationProto$Builder	setVmem	vmem_	J	int	0	org.apache.hadoop.yarn.proto.YarnProtos$ResourceUtilizationProto$Builder:setVmem(int)
org.apache.hadoop.yarn.proto.YarnProtos$ResourceUtilizationProto$Builder	setCpu	cpu_	J	float	0	org.apache.hadoop.yarn.proto.YarnProtos$ResourceUtilizationProto$Builder:setCpu(float)
org.apache.hadoop.yarn.proto.YarnServiceProtos$GetQueueInfoRequestProto$Builder	setQueueName	queueName_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServiceProtos$GetQueueInfoRequestProto$Builder:setQueueName(java.lang.String)
org.apache.hadoop.yarn.proto.YarnServiceProtos$GetQueueInfoRequestProto$Builder	setQueueNameBytes	queueName_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServiceProtos$GetQueueInfoRequestProto$Builder:setQueueNameBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnServiceProtos$GetQueueInfoRequestProto$Builder	setIncludeApplications	includeApplications_	J	boolean	0	org.apache.hadoop.yarn.proto.YarnServiceProtos$GetQueueInfoRequestProto$Builder:setIncludeApplications(boolean)
org.apache.hadoop.yarn.proto.YarnServiceProtos$GetQueueInfoRequestProto$Builder	setIncludeChildQueues	includeChildQueues_	J	boolean	0	org.apache.hadoop.yarn.proto.YarnServiceProtos$GetQueueInfoRequestProto$Builder:setIncludeChildQueues(boolean)
org.apache.hadoop.yarn.proto.YarnServiceProtos$GetQueueInfoRequestProto$Builder	setRecursive	recursive_	J	boolean	0	org.apache.hadoop.yarn.proto.YarnServiceProtos$GetQueueInfoRequestProto$Builder:setRecursive(boolean)
org.apache.hadoop.yarn.proto.CsiAdaptorProtos$NodePublishVolumeRequest$Builder	setVolumeId	volumeId_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.CsiAdaptorProtos$NodePublishVolumeRequest$Builder:setVolumeId(java.lang.String)
org.apache.hadoop.yarn.proto.CsiAdaptorProtos$NodePublishVolumeRequest$Builder	setVolumeIdBytes	volumeId_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.CsiAdaptorProtos$NodePublishVolumeRequest$Builder:setVolumeIdBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.CsiAdaptorProtos$NodePublishVolumeRequest$Builder	setStagingTargetPath	stagingTargetPath_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.CsiAdaptorProtos$NodePublishVolumeRequest$Builder:setStagingTargetPath(java.lang.String)
org.apache.hadoop.yarn.proto.CsiAdaptorProtos$NodePublishVolumeRequest$Builder	setStagingTargetPathBytes	stagingTargetPath_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.CsiAdaptorProtos$NodePublishVolumeRequest$Builder:setStagingTargetPathBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.CsiAdaptorProtos$NodePublishVolumeRequest$Builder	setTargetPath	targetPath_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.CsiAdaptorProtos$NodePublishVolumeRequest$Builder:setTargetPath(java.lang.String)
org.apache.hadoop.yarn.proto.CsiAdaptorProtos$NodePublishVolumeRequest$Builder	setTargetPathBytes	targetPath_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.CsiAdaptorProtos$NodePublishVolumeRequest$Builder:setTargetPathBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.CsiAdaptorProtos$NodePublishVolumeRequest$Builder	setReadonly	readonly_	J	boolean	0	org.apache.hadoop.yarn.proto.CsiAdaptorProtos$NodePublishVolumeRequest$Builder:setReadonly(boolean)
org.apache.hadoop.yarn.proto.YarnProtos$LocalResourceProto$Builder	setSize	size_	J	long	0	org.apache.hadoop.yarn.proto.YarnProtos$LocalResourceProto$Builder:setSize(long)
org.apache.hadoop.yarn.proto.YarnProtos$LocalResourceProto$Builder	setTimestamp	timestamp_	J	long	0	org.apache.hadoop.yarn.proto.YarnProtos$LocalResourceProto$Builder:setTimestamp(long)
org.apache.hadoop.yarn.proto.YarnProtos$LocalResourceProto$Builder	setPattern	pattern_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$LocalResourceProto$Builder:setPattern(java.lang.String)
org.apache.hadoop.yarn.proto.YarnProtos$LocalResourceProto$Builder	setPatternBytes	pattern_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$LocalResourceProto$Builder:setPatternBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnProtos$LocalResourceProto$Builder	setShouldBeUploadedToSharedCache	shouldBeUploadedToSharedCache_	J	boolean	0	org.apache.hadoop.yarn.proto.YarnProtos$LocalResourceProto$Builder:setShouldBeUploadedToSharedCache(boolean)
org.apache.hadoop.yarn.proto.YarnProtos$ApplicationIdProto$Builder	setId	id_	J	int	0	org.apache.hadoop.yarn.proto.YarnProtos$ApplicationIdProto$Builder:setId(int)
org.apache.hadoop.yarn.proto.YarnProtos$ApplicationIdProto$Builder	setClusterTimestamp	clusterTimestamp_	J	long	0	org.apache.hadoop.yarn.proto.YarnProtos$ApplicationIdProto$Builder:setClusterTimestamp(long)
org.apache.hadoop.yarn.proto.CsiAdaptorProtos$ValidateVolumeCapabilitiesResponse$Builder	setSupported	supported_	J	boolean	0	org.apache.hadoop.yarn.proto.CsiAdaptorProtos$ValidateVolumeCapabilitiesResponse$Builder:setSupported(boolean)
org.apache.hadoop.yarn.proto.CsiAdaptorProtos$ValidateVolumeCapabilitiesResponse$Builder	setMessage	message_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.CsiAdaptorProtos$ValidateVolumeCapabilitiesResponse$Builder:setMessage(java.lang.String)
org.apache.hadoop.yarn.proto.CsiAdaptorProtos$ValidateVolumeCapabilitiesResponse$Builder	setMessageBytes	message_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.CsiAdaptorProtos$ValidateVolumeCapabilitiesResponse$Builder:setMessageBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.ApplicationHistoryServerProtos$ContainerFinishDataProto$Builder	setFinishTime	finishTime_	J	long	0	org.apache.hadoop.yarn.proto.ApplicationHistoryServerProtos$ContainerFinishDataProto$Builder:setFinishTime(long)
org.apache.hadoop.yarn.proto.ApplicationHistoryServerProtos$ContainerFinishDataProto$Builder	setDiagnosticsInfo	diagnosticsInfo_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.ApplicationHistoryServerProtos$ContainerFinishDataProto$Builder:setDiagnosticsInfo(java.lang.String)
org.apache.hadoop.yarn.proto.ApplicationHistoryServerProtos$ContainerFinishDataProto$Builder	setDiagnosticsInfoBytes	diagnosticsInfo_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.ApplicationHistoryServerProtos$ContainerFinishDataProto$Builder:setDiagnosticsInfoBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.ApplicationHistoryServerProtos$ContainerFinishDataProto$Builder	setContainerExitStatus	containerExitStatus_	J	int	0	org.apache.hadoop.yarn.proto.ApplicationHistoryServerProtos$ContainerFinishDataProto$Builder:setContainerExitStatus(int)
org.apache.hadoop.yarn.proto.ApplicationHistoryServerProtos$ApplicationHistoryDataProto$Builder	setApplicationName	applicationName_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.ApplicationHistoryServerProtos$ApplicationHistoryDataProto$Builder:setApplicationName(java.lang.String)
org.apache.hadoop.yarn.proto.ApplicationHistoryServerProtos$ApplicationHistoryDataProto$Builder	setApplicationNameBytes	applicationName_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.ApplicationHistoryServerProtos$ApplicationHistoryDataProto$Builder:setApplicationNameBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.ApplicationHistoryServerProtos$ApplicationHistoryDataProto$Builder	setApplicationType	applicationType_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.ApplicationHistoryServerProtos$ApplicationHistoryDataProto$Builder:setApplicationType(java.lang.String)
org.apache.hadoop.yarn.proto.ApplicationHistoryServerProtos$ApplicationHistoryDataProto$Builder	setApplicationTypeBytes	applicationType_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.ApplicationHistoryServerProtos$ApplicationHistoryDataProto$Builder:setApplicationTypeBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.ApplicationHistoryServerProtos$ApplicationHistoryDataProto$Builder	setUser	user_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.ApplicationHistoryServerProtos$ApplicationHistoryDataProto$Builder:setUser(java.lang.String)
org.apache.hadoop.yarn.proto.ApplicationHistoryServerProtos$ApplicationHistoryDataProto$Builder	setUserBytes	user_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.ApplicationHistoryServerProtos$ApplicationHistoryDataProto$Builder:setUserBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.ApplicationHistoryServerProtos$ApplicationHistoryDataProto$Builder	setQueue	queue_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.ApplicationHistoryServerProtos$ApplicationHistoryDataProto$Builder:setQueue(java.lang.String)
org.apache.hadoop.yarn.proto.ApplicationHistoryServerProtos$ApplicationHistoryDataProto$Builder	setQueueBytes	queue_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.ApplicationHistoryServerProtos$ApplicationHistoryDataProto$Builder:setQueueBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.ApplicationHistoryServerProtos$ApplicationHistoryDataProto$Builder	setSubmitTime	submitTime_	J	long	0	org.apache.hadoop.yarn.proto.ApplicationHistoryServerProtos$ApplicationHistoryDataProto$Builder:setSubmitTime(long)
org.apache.hadoop.yarn.proto.ApplicationHistoryServerProtos$ApplicationHistoryDataProto$Builder	setStartTime	startTime_	J	long	0	org.apache.hadoop.yarn.proto.ApplicationHistoryServerProtos$ApplicationHistoryDataProto$Builder:setStartTime(long)
org.apache.hadoop.yarn.proto.ApplicationHistoryServerProtos$ApplicationHistoryDataProto$Builder	setFinishTime	finishTime_	J	long	0	org.apache.hadoop.yarn.proto.ApplicationHistoryServerProtos$ApplicationHistoryDataProto$Builder:setFinishTime(long)
org.apache.hadoop.yarn.proto.ApplicationHistoryServerProtos$ApplicationHistoryDataProto$Builder	setDiagnosticsInfo	diagnosticsInfo_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.ApplicationHistoryServerProtos$ApplicationHistoryDataProto$Builder:setDiagnosticsInfo(java.lang.String)
org.apache.hadoop.yarn.proto.ApplicationHistoryServerProtos$ApplicationHistoryDataProto$Builder	setDiagnosticsInfoBytes	diagnosticsInfo_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.ApplicationHistoryServerProtos$ApplicationHistoryDataProto$Builder:setDiagnosticsInfoBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnServiceProtos$ReservationListRequestProto$Builder	setQueue	queue_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServiceProtos$ReservationListRequestProto$Builder:setQueue(java.lang.String)
org.apache.hadoop.yarn.proto.YarnServiceProtos$ReservationListRequestProto$Builder	setQueueBytes	queue_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServiceProtos$ReservationListRequestProto$Builder:setQueueBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnServiceProtos$ReservationListRequestProto$Builder	setReservationId	reservationId_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServiceProtos$ReservationListRequestProto$Builder:setReservationId(java.lang.String)
org.apache.hadoop.yarn.proto.YarnServiceProtos$ReservationListRequestProto$Builder	setReservationIdBytes	reservationId_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServiceProtos$ReservationListRequestProto$Builder:setReservationIdBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnServiceProtos$ReservationListRequestProto$Builder	setStartTime	startTime_	J	long	0	org.apache.hadoop.yarn.proto.YarnServiceProtos$ReservationListRequestProto$Builder:setStartTime(long)
org.apache.hadoop.yarn.proto.YarnServiceProtos$ReservationListRequestProto$Builder	setEndTime	endTime_	J	long	0	org.apache.hadoop.yarn.proto.YarnServiceProtos$ReservationListRequestProto$Builder:setEndTime(long)
org.apache.hadoop.yarn.proto.YarnServiceProtos$ReservationListRequestProto$Builder	setIncludeResourceAllocations	includeResourceAllocations_	J	boolean	0	org.apache.hadoop.yarn.proto.YarnServiceProtos$ReservationListRequestProto$Builder:setIncludeResourceAllocations(boolean)
org.apache.hadoop.yarn.proto.YarnServiceProtos$UseSharedCacheResourceResponseProto$Builder	setPath	path_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServiceProtos$UseSharedCacheResourceResponseProto$Builder:setPath(java.lang.String)
org.apache.hadoop.yarn.proto.YarnServiceProtos$UseSharedCacheResourceResponseProto$Builder	setPathBytes	path_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServiceProtos$UseSharedCacheResourceResponseProto$Builder:setPathBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnProtos$QueueConfigurationsMapProto$Builder	setPartitionName	partitionName_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$QueueConfigurationsMapProto$Builder:setPartitionName(java.lang.String)
org.apache.hadoop.yarn.proto.YarnProtos$QueueConfigurationsMapProto$Builder	setPartitionNameBytes	partitionName_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$QueueConfigurationsMapProto$Builder:setPartitionNameBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnProtos$ResourceProto$Builder	setMemory	memory_	J	long	0	org.apache.hadoop.yarn.proto.YarnProtos$ResourceProto$Builder:setMemory(long)
org.apache.hadoop.yarn.proto.YarnProtos$ResourceProto$Builder	setVirtualCores	virtualCores_	J	int	0	org.apache.hadoop.yarn.proto.YarnProtos$ResourceProto$Builder:setVirtualCores(int)
org.apache.hadoop.yarn.proto.YarnServiceProtos$MoveApplicationAcrossQueuesRequestProto$Builder	setTargetQueue	targetQueue_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServiceProtos$MoveApplicationAcrossQueuesRequestProto$Builder:setTargetQueue(java.lang.String)
org.apache.hadoop.yarn.proto.YarnServiceProtos$MoveApplicationAcrossQueuesRequestProto$Builder	setTargetQueueBytes	targetQueue_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServiceProtos$MoveApplicationAcrossQueuesRequestProto$Builder:setTargetQueueBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnServerResourceManagerServiceProtos$GetGroupsForUserRequestProto$Builder	setUser	user_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServerResourceManagerServiceProtos$GetGroupsForUserRequestProto$Builder:setUser(java.lang.String)
org.apache.hadoop.yarn.proto.YarnServerResourceManagerServiceProtos$GetGroupsForUserRequestProto$Builder	setUserBytes	user_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServerResourceManagerServiceProtos$GetGroupsForUserRequestProto$Builder:setUserBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnServiceProtos$AllocateRequestProto$Builder	setResponseId	responseId_	J	int	0	org.apache.hadoop.yarn.proto.YarnServiceProtos$AllocateRequestProto$Builder:setResponseId(int)
org.apache.hadoop.yarn.proto.YarnServiceProtos$AllocateRequestProto$Builder	setProgress	progress_	J	float	0	org.apache.hadoop.yarn.proto.YarnServiceProtos$AllocateRequestProto$Builder:setProgress(float)
org.apache.hadoop.yarn.proto.YarnServiceProtos$AllocateRequestProto$Builder	setTrackingUrl	trackingUrl_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServiceProtos$AllocateRequestProto$Builder:setTrackingUrl(java.lang.String)
org.apache.hadoop.yarn.proto.YarnServiceProtos$AllocateRequestProto$Builder	setTrackingUrlBytes	trackingUrl_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServiceProtos$AllocateRequestProto$Builder:setTrackingUrlBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnServiceProtos$UpdateContainerRequestProto$Builder	setContainerVersion	containerVersion_	J	int	0	org.apache.hadoop.yarn.proto.YarnServiceProtos$UpdateContainerRequestProto$Builder:setContainerVersion(int)
org.apache.hadoop.yarn.proto.YarnProtos$StringFloatMapProto$Builder	setKey	key_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$StringFloatMapProto$Builder:setKey(java.lang.String)
org.apache.hadoop.yarn.proto.YarnProtos$StringFloatMapProto$Builder	setKeyBytes	key_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$StringFloatMapProto$Builder:setKeyBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnProtos$StringFloatMapProto$Builder	setValue	value_	J	float	0	org.apache.hadoop.yarn.proto.YarnProtos$StringFloatMapProto$Builder:setValue(float)
org.apache.hadoop.yarn.proto.YarnProtos$NodeToAttributeValueProto$Builder	setHostname	hostname_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$NodeToAttributeValueProto$Builder:setHostname(java.lang.String)
org.apache.hadoop.yarn.proto.YarnProtos$NodeToAttributeValueProto$Builder	setHostnameBytes	hostname_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$NodeToAttributeValueProto$Builder:setHostnameBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnProtos$NodeToAttributeValueProto$Builder	setAttributeValue	attributeValue_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$NodeToAttributeValueProto$Builder:setAttributeValue(java.lang.String)
org.apache.hadoop.yarn.proto.YarnProtos$NodeToAttributeValueProto$Builder	setAttributeValueBytes	attributeValue_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$NodeToAttributeValueProto$Builder:setAttributeValueBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnProtos$ResourceAllocationRequestProto$Builder	setStartTime	startTime_	J	long	0	org.apache.hadoop.yarn.proto.YarnProtos$ResourceAllocationRequestProto$Builder:setStartTime(long)
org.apache.hadoop.yarn.proto.YarnProtos$ResourceAllocationRequestProto$Builder	setEndTime	endTime_	J	long	0	org.apache.hadoop.yarn.proto.YarnProtos$ResourceAllocationRequestProto$Builder:setEndTime(long)
org.apache.hadoop.yarn.proto.YarnProtos$ContainerRetryContextProto$Builder	setMaxRetries	maxRetries_	J	int	0	org.apache.hadoop.yarn.proto.YarnProtos$ContainerRetryContextProto$Builder:setMaxRetries(int)
org.apache.hadoop.yarn.proto.YarnProtos$ContainerRetryContextProto$Builder	setRetryInterval	retryInterval_	J	int	0	org.apache.hadoop.yarn.proto.YarnProtos$ContainerRetryContextProto$Builder:setRetryInterval(int)
org.apache.hadoop.yarn.proto.YarnProtos$ContainerRetryContextProto$Builder	setFailuresValidityInterval	failuresValidityInterval_	J	long	0	org.apache.hadoop.yarn.proto.YarnProtos$ContainerRetryContextProto$Builder:setFailuresValidityInterval(long)
org.apache.hadoop.yarn.proto.YarnServiceProtos$ReInitializeContainerRequestProto$Builder	setAutoCommit	autoCommit_	J	boolean	0	org.apache.hadoop.yarn.proto.YarnServiceProtos$ReInitializeContainerRequestProto$Builder:setAutoCommit(boolean)
org.apache.hadoop.yarn.proto.YarnProtos$ApplicationAttemptReportProto$Builder	setHost	host_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$ApplicationAttemptReportProto$Builder:setHost(java.lang.String)
org.apache.hadoop.yarn.proto.YarnProtos$ApplicationAttemptReportProto$Builder	setHostBytes	host_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$ApplicationAttemptReportProto$Builder:setHostBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnProtos$ApplicationAttemptReportProto$Builder	setRpcPort	rpcPort_	J	int	0	org.apache.hadoop.yarn.proto.YarnProtos$ApplicationAttemptReportProto$Builder:setRpcPort(int)
org.apache.hadoop.yarn.proto.YarnProtos$ApplicationAttemptReportProto$Builder	setTrackingUrl	trackingUrl_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$ApplicationAttemptReportProto$Builder:setTrackingUrl(java.lang.String)
org.apache.hadoop.yarn.proto.YarnProtos$ApplicationAttemptReportProto$Builder	setTrackingUrlBytes	trackingUrl_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$ApplicationAttemptReportProto$Builder:setTrackingUrlBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnProtos$ApplicationAttemptReportProto$Builder	setDiagnostics	diagnostics_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$ApplicationAttemptReportProto$Builder:setDiagnostics(java.lang.String)
org.apache.hadoop.yarn.proto.YarnProtos$ApplicationAttemptReportProto$Builder	setDiagnosticsBytes	diagnostics_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$ApplicationAttemptReportProto$Builder:setDiagnosticsBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnProtos$ApplicationAttemptReportProto$Builder	setOriginalTrackingUrl	originalTrackingUrl_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$ApplicationAttemptReportProto$Builder:setOriginalTrackingUrl(java.lang.String)
org.apache.hadoop.yarn.proto.YarnProtos$ApplicationAttemptReportProto$Builder	setOriginalTrackingUrlBytes	originalTrackingUrl_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$ApplicationAttemptReportProto$Builder:setOriginalTrackingUrlBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnProtos$ApplicationAttemptReportProto$Builder	setStartTime	startTime_	J	long	0	org.apache.hadoop.yarn.proto.YarnProtos$ApplicationAttemptReportProto$Builder:setStartTime(long)
org.apache.hadoop.yarn.proto.YarnProtos$ApplicationAttemptReportProto$Builder	setFinishTime	finishTime_	J	long	0	org.apache.hadoop.yarn.proto.YarnProtos$ApplicationAttemptReportProto$Builder:setFinishTime(long)
org.apache.hadoop.yarn.proto.YarnProtos$NodeIdProto$Builder	setHost	host_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$NodeIdProto$Builder:setHost(java.lang.String)
org.apache.hadoop.yarn.proto.YarnProtos$NodeIdProto$Builder	setHostBytes	host_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$NodeIdProto$Builder:setHostBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnProtos$NodeIdProto$Builder	setPort	port_	J	int	0	org.apache.hadoop.yarn.proto.YarnProtos$NodeIdProto$Builder:setPort(int)
org.apache.hadoop.yarn.proto.YarnProtos$ResourceSizingProto$Builder	setNumAllocations	numAllocations_	J	int	0	org.apache.hadoop.yarn.proto.YarnProtos$ResourceSizingProto$Builder:setNumAllocations(int)
org.apache.hadoop.yarn.proto.YarnProtos$NodeAttributeProto$Builder	setAttributeValue	attributeValue_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$NodeAttributeProto$Builder:setAttributeValue(java.lang.String)
org.apache.hadoop.yarn.proto.YarnProtos$NodeAttributeProto$Builder	setAttributeValueBytes	attributeValue_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$NodeAttributeProto$Builder:setAttributeValueBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnProtos$NodeReportProto$Builder	setHttpAddress	httpAddress_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$NodeReportProto$Builder:setHttpAddress(java.lang.String)
org.apache.hadoop.yarn.proto.YarnProtos$NodeReportProto$Builder	setHttpAddressBytes	httpAddress_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$NodeReportProto$Builder:setHttpAddressBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnProtos$NodeReportProto$Builder	setRackName	rackName_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$NodeReportProto$Builder:setRackName(java.lang.String)
org.apache.hadoop.yarn.proto.YarnProtos$NodeReportProto$Builder	setRackNameBytes	rackName_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$NodeReportProto$Builder:setRackNameBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnProtos$NodeReportProto$Builder	setNumContainers	numContainers_	J	int	0	org.apache.hadoop.yarn.proto.YarnProtos$NodeReportProto$Builder:setNumContainers(int)
org.apache.hadoop.yarn.proto.YarnProtos$NodeReportProto$Builder	setHealthReport	healthReport_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$NodeReportProto$Builder:setHealthReport(java.lang.String)
org.apache.hadoop.yarn.proto.YarnProtos$NodeReportProto$Builder	setHealthReportBytes	healthReport_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$NodeReportProto$Builder:setHealthReportBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnProtos$NodeReportProto$Builder	setLastHealthReportTime	lastHealthReportTime_	J	long	0	org.apache.hadoop.yarn.proto.YarnProtos$NodeReportProto$Builder:setLastHealthReportTime(long)
org.apache.hadoop.yarn.proto.YarnProtos$NodeReportProto$Builder	setDecommissioningTimeout	decommissioningTimeout_	J	int	0	org.apache.hadoop.yarn.proto.YarnProtos$NodeReportProto$Builder:setDecommissioningTimeout(int)
org.apache.hadoop.yarn.proto.YarnProtos$LogAggregationContextProto$Builder	setIncludePattern	includePattern_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$LogAggregationContextProto$Builder:setIncludePattern(java.lang.String)
org.apache.hadoop.yarn.proto.YarnProtos$LogAggregationContextProto$Builder	setIncludePatternBytes	includePattern_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$LogAggregationContextProto$Builder:setIncludePatternBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnProtos$LogAggregationContextProto$Builder	setExcludePattern	excludePattern_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$LogAggregationContextProto$Builder:setExcludePattern(java.lang.String)
org.apache.hadoop.yarn.proto.YarnProtos$LogAggregationContextProto$Builder	setExcludePatternBytes	excludePattern_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$LogAggregationContextProto$Builder:setExcludePatternBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnProtos$LogAggregationContextProto$Builder	setRolledLogsIncludePattern	rolledLogsIncludePattern_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$LogAggregationContextProto$Builder:setRolledLogsIncludePattern(java.lang.String)
org.apache.hadoop.yarn.proto.YarnProtos$LogAggregationContextProto$Builder	setRolledLogsIncludePatternBytes	rolledLogsIncludePattern_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$LogAggregationContextProto$Builder:setRolledLogsIncludePatternBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnProtos$LogAggregationContextProto$Builder	setRolledLogsExcludePattern	rolledLogsExcludePattern_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$LogAggregationContextProto$Builder:setRolledLogsExcludePattern(java.lang.String)
org.apache.hadoop.yarn.proto.YarnProtos$LogAggregationContextProto$Builder	setRolledLogsExcludePatternBytes	rolledLogsExcludePattern_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$LogAggregationContextProto$Builder:setRolledLogsExcludePatternBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnProtos$LogAggregationContextProto$Builder	setLogAggregationPolicyClassName	logAggregationPolicyClassName_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$LogAggregationContextProto$Builder:setLogAggregationPolicyClassName(java.lang.String)
org.apache.hadoop.yarn.proto.YarnProtos$LogAggregationContextProto$Builder	setLogAggregationPolicyClassNameBytes	logAggregationPolicyClassName_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$LogAggregationContextProto$Builder:setLogAggregationPolicyClassNameBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnProtos$LogAggregationContextProto$Builder	setLogAggregationPolicyParameters	logAggregationPolicyParameters_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$LogAggregationContextProto$Builder:setLogAggregationPolicyParameters(java.lang.String)
org.apache.hadoop.yarn.proto.YarnProtos$LogAggregationContextProto$Builder	setLogAggregationPolicyParametersBytes	logAggregationPolicyParameters_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnProtos$LogAggregationContextProto$Builder:setLogAggregationPolicyParametersBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnProtos$QueueStatisticsProto$Builder	setNumAppsSubmitted	numAppsSubmitted_	J	long	0	org.apache.hadoop.yarn.proto.YarnProtos$QueueStatisticsProto$Builder:setNumAppsSubmitted(long)
org.apache.hadoop.yarn.proto.YarnProtos$QueueStatisticsProto$Builder	setNumAppsRunning	numAppsRunning_	J	long	0	org.apache.hadoop.yarn.proto.YarnProtos$QueueStatisticsProto$Builder:setNumAppsRunning(long)
org.apache.hadoop.yarn.proto.YarnProtos$QueueStatisticsProto$Builder	setNumAppsPending	numAppsPending_	J	long	0	org.apache.hadoop.yarn.proto.YarnProtos$QueueStatisticsProto$Builder:setNumAppsPending(long)
org.apache.hadoop.yarn.proto.YarnProtos$QueueStatisticsProto$Builder	setNumAppsCompleted	numAppsCompleted_	J	long	0	org.apache.hadoop.yarn.proto.YarnProtos$QueueStatisticsProto$Builder:setNumAppsCompleted(long)
org.apache.hadoop.yarn.proto.YarnProtos$QueueStatisticsProto$Builder	setNumAppsKilled	numAppsKilled_	J	long	0	org.apache.hadoop.yarn.proto.YarnProtos$QueueStatisticsProto$Builder:setNumAppsKilled(long)
org.apache.hadoop.yarn.proto.YarnProtos$QueueStatisticsProto$Builder	setNumAppsFailed	numAppsFailed_	J	long	0	org.apache.hadoop.yarn.proto.YarnProtos$QueueStatisticsProto$Builder:setNumAppsFailed(long)
org.apache.hadoop.yarn.proto.YarnProtos$QueueStatisticsProto$Builder	setNumActiveUsers	numActiveUsers_	J	long	0	org.apache.hadoop.yarn.proto.YarnProtos$QueueStatisticsProto$Builder:setNumActiveUsers(long)
org.apache.hadoop.yarn.proto.YarnProtos$QueueStatisticsProto$Builder	setAvailableMemoryMB	availableMemoryMB_	J	long	0	org.apache.hadoop.yarn.proto.YarnProtos$QueueStatisticsProto$Builder:setAvailableMemoryMB(long)
org.apache.hadoop.yarn.proto.YarnProtos$QueueStatisticsProto$Builder	setAllocatedMemoryMB	allocatedMemoryMB_	J	long	0	org.apache.hadoop.yarn.proto.YarnProtos$QueueStatisticsProto$Builder:setAllocatedMemoryMB(long)
org.apache.hadoop.yarn.proto.YarnProtos$QueueStatisticsProto$Builder	setPendingMemoryMB	pendingMemoryMB_	J	long	0	org.apache.hadoop.yarn.proto.YarnProtos$QueueStatisticsProto$Builder:setPendingMemoryMB(long)
org.apache.hadoop.yarn.proto.YarnProtos$QueueStatisticsProto$Builder	setReservedMemoryMB	reservedMemoryMB_	J	long	0	org.apache.hadoop.yarn.proto.YarnProtos$QueueStatisticsProto$Builder:setReservedMemoryMB(long)
org.apache.hadoop.yarn.proto.YarnProtos$QueueStatisticsProto$Builder	setAvailableVCores	availableVCores_	J	long	0	org.apache.hadoop.yarn.proto.YarnProtos$QueueStatisticsProto$Builder:setAvailableVCores(long)
org.apache.hadoop.yarn.proto.YarnProtos$QueueStatisticsProto$Builder	setAllocatedVCores	allocatedVCores_	J	long	0	org.apache.hadoop.yarn.proto.YarnProtos$QueueStatisticsProto$Builder:setAllocatedVCores(long)
org.apache.hadoop.yarn.proto.YarnProtos$QueueStatisticsProto$Builder	setPendingVCores	pendingVCores_	J	long	0	org.apache.hadoop.yarn.proto.YarnProtos$QueueStatisticsProto$Builder:setPendingVCores(long)
org.apache.hadoop.yarn.proto.YarnProtos$QueueStatisticsProto$Builder	setReservedVCores	reservedVCores_	J	long	0	org.apache.hadoop.yarn.proto.YarnProtos$QueueStatisticsProto$Builder:setReservedVCores(long)
org.apache.hadoop.yarn.proto.YarnProtos$QueueStatisticsProto$Builder	setAllocatedContainers	allocatedContainers_	J	long	0	org.apache.hadoop.yarn.proto.YarnProtos$QueueStatisticsProto$Builder:setAllocatedContainers(long)
org.apache.hadoop.yarn.proto.YarnProtos$QueueStatisticsProto$Builder	setPendingContainers	pendingContainers_	J	long	0	org.apache.hadoop.yarn.proto.YarnProtos$QueueStatisticsProto$Builder:setPendingContainers(long)
org.apache.hadoop.yarn.proto.YarnProtos$QueueStatisticsProto$Builder	setReservedContainers	reservedContainers_	J	long	0	org.apache.hadoop.yarn.proto.YarnProtos$QueueStatisticsProto$Builder:setReservedContainers(long)
org.apache.hadoop.yarn.proto.ApplicationHistoryServerProtos$ApplicationAttemptHistoryDataProto$Builder	setHost	host_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.ApplicationHistoryServerProtos$ApplicationAttemptHistoryDataProto$Builder:setHost(java.lang.String)
org.apache.hadoop.yarn.proto.ApplicationHistoryServerProtos$ApplicationAttemptHistoryDataProto$Builder	setHostBytes	host_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.ApplicationHistoryServerProtos$ApplicationAttemptHistoryDataProto$Builder:setHostBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.ApplicationHistoryServerProtos$ApplicationAttemptHistoryDataProto$Builder	setRpcPort	rpcPort_	J	int	0	org.apache.hadoop.yarn.proto.ApplicationHistoryServerProtos$ApplicationAttemptHistoryDataProto$Builder:setRpcPort(int)
org.apache.hadoop.yarn.proto.ApplicationHistoryServerProtos$ApplicationAttemptHistoryDataProto$Builder	setTrackingUrl	trackingUrl_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.ApplicationHistoryServerProtos$ApplicationAttemptHistoryDataProto$Builder:setTrackingUrl(java.lang.String)
org.apache.hadoop.yarn.proto.ApplicationHistoryServerProtos$ApplicationAttemptHistoryDataProto$Builder	setTrackingUrlBytes	trackingUrl_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.ApplicationHistoryServerProtos$ApplicationAttemptHistoryDataProto$Builder:setTrackingUrlBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.ApplicationHistoryServerProtos$ApplicationAttemptHistoryDataProto$Builder	setDiagnosticsInfo	diagnosticsInfo_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.ApplicationHistoryServerProtos$ApplicationAttemptHistoryDataProto$Builder:setDiagnosticsInfo(java.lang.String)
org.apache.hadoop.yarn.proto.ApplicationHistoryServerProtos$ApplicationAttemptHistoryDataProto$Builder	setDiagnosticsInfoBytes	diagnosticsInfo_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.ApplicationHistoryServerProtos$ApplicationAttemptHistoryDataProto$Builder:setDiagnosticsInfoBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnProtos$PriorityProto$Builder	setPriority	priority_	J	int	0	org.apache.hadoop.yarn.proto.YarnProtos$PriorityProto$Builder:setPriority(int)
org.apache.hadoop.yarn.proto.YarnProtos$ApplicationTimeoutMapProto$Builder	setTimeout	timeout_	J	long	0	org.apache.hadoop.yarn.proto.YarnProtos$ApplicationTimeoutMapProto$Builder:setTimeout(long)
org.apache.hadoop.yarn.server.api.AuxiliaryService	setRecoveryPath	recoveryPath	C	org.apache.hadoop.fs.Path	0	org.apache.hadoop.yarn.server.api.AuxiliaryService:setRecoveryPath(org.apache.hadoop.fs.Path)
org.apache.hadoop.yarn.server.api.AuxiliaryService	setAuxiliaryLocalPathHandler	auxiliaryLocalPathHandler	C	org.apache.hadoop.yarn.server.api.AuxiliaryLocalPathHandler	0	org.apache.hadoop.yarn.server.api.AuxiliaryService:setAuxiliaryLocalPathHandler(org.apache.hadoop.yarn.server.api.AuxiliaryLocalPathHandler)
org.apache.hadoop.yarn.appcatalog.model.AppDetails	setImage	image	J	java.lang.String	0	org.apache.hadoop.yarn.appcatalog.model.AppDetails:setImage(java.lang.String)
org.apache.hadoop.yarn.appcatalog.model.AppDetails	setVersion	version	J	java.lang.String	0	org.apache.hadoop.yarn.appcatalog.model.AppDetails:setVersion(java.lang.String)
org.apache.hadoop.yarn.appcatalog.model.AppDetails	setPorts	ports	J	java.lang.String	1	org.apache.hadoop.yarn.appcatalog.model.AppDetails:setPorts(java.lang.String[])
org.apache.hadoop.yarn.appcatalog.model.AppDetails	setVolumes	volumes	J	java.lang.String	1	org.apache.hadoop.yarn.appcatalog.model.AppDetails:setVolumes(java.lang.String[])
org.apache.hadoop.yarn.appcatalog.model.AppDetails	setEnv	env	J	java.lang.String	1	org.apache.hadoop.yarn.appcatalog.model.AppDetails:setEnv(java.lang.String[])
org.apache.hadoop.yarn.appcatalog.model.AppEntry	setId	id	J	java.lang.String	0	org.apache.hadoop.yarn.appcatalog.model.AppEntry:setId(java.lang.String)
org.apache.hadoop.yarn.appcatalog.model.AppEntry	setName	name	J	java.lang.String	0	org.apache.hadoop.yarn.appcatalog.model.AppEntry:setName(java.lang.String)
org.apache.hadoop.yarn.appcatalog.model.AppEntry	setApp	app	J	java.lang.String	0	org.apache.hadoop.yarn.appcatalog.model.AppEntry:setApp(java.lang.String)
org.apache.hadoop.yarn.appcatalog.model.AppEntry	setYarnfile	yarnfile	C	org.apache.hadoop.yarn.service.api.records.Service	0	org.apache.hadoop.yarn.appcatalog.model.AppEntry:setYarnfile(org.apache.hadoop.yarn.service.api.records.Service)
org.apache.hadoop.yarn.appcatalog.model.AppStoreEntry	setOrg	org	J	java.lang.String	0	org.apache.hadoop.yarn.appcatalog.model.AppStoreEntry:setOrg(java.lang.String)
org.apache.hadoop.yarn.appcatalog.model.AppStoreEntry	setName	name	J	java.lang.String	0	org.apache.hadoop.yarn.appcatalog.model.AppStoreEntry:setName(java.lang.String)
org.apache.hadoop.yarn.appcatalog.model.AppStoreEntry	setDesc	desc	J	java.lang.String	0	org.apache.hadoop.yarn.appcatalog.model.AppStoreEntry:setDesc(java.lang.String)
org.apache.hadoop.yarn.appcatalog.model.AppStoreEntry	setLike	like	J	long	0	org.apache.hadoop.yarn.appcatalog.model.AppStoreEntry:setLike(long)
org.apache.hadoop.yarn.appcatalog.model.AppStoreEntry	setDownload	download	J	long	0	org.apache.hadoop.yarn.appcatalog.model.AppStoreEntry:setDownload(long)
org.apache.hadoop.yarn.appcatalog.model.AppStoreEntry	setId	id	J	java.lang.String	0	org.apache.hadoop.yarn.appcatalog.model.AppStoreEntry:setId(java.lang.String)
org.apache.hadoop.yarn.appcatalog.model.AppStoreEntry	setApp	app	C	org.apache.hadoop.yarn.service.api.records.Service	0	org.apache.hadoop.yarn.appcatalog.model.AppStoreEntry:setApp(org.apache.hadoop.yarn.service.api.records.Service)
org.apache.hadoop.yarn.appcatalog.model.AppStoreEntry	setIcon	icon	J	java.lang.String	0	org.apache.hadoop.yarn.appcatalog.model.AppStoreEntry:setIcon(java.lang.String)
org.apache.hadoop.yarn.appcatalog.model.Application	setOrganization	organization	J	java.lang.String	0	org.apache.hadoop.yarn.appcatalog.model.Application:setOrganization(java.lang.String)
org.apache.hadoop.yarn.appcatalog.model.Application	setDescription	description	J	java.lang.String	0	org.apache.hadoop.yarn.appcatalog.model.Application:setDescription(java.lang.String)
org.apache.hadoop.yarn.appcatalog.model.Application	setIcon	icon	J	java.lang.String	0	org.apache.hadoop.yarn.appcatalog.model.Application:setIcon(java.lang.String)
org.apache.hadoop.yarn.applications.distributedshell.ApplicationMaster	setAmRMClient	amRMClient	C	org.apache.hadoop.yarn.client.api.async.AMRMClientAsync	0	org.apache.hadoop.yarn.applications.distributedshell.ApplicationMaster:setAmRMClient(org.apache.hadoop.yarn.client.api.async.AMRMClientAsync)
org.apache.hadoop.yarn.applications.distributedshell.PlacementSpec	setNumContainers	numContainers	J	int	0	org.apache.hadoop.yarn.applications.distributedshell.PlacementSpec:setNumContainers(int)
org.apache.hadoop.applications.mawo.server.common.AbstractTask	setEnvironment	environment	GJ	java.util.Map	0	org.apache.hadoop.applications.mawo.server.common.AbstractTask:setEnvironment(java.util.Map)
org.apache.hadoop.applications.mawo.server.common.AbstractTask	setTaskCmd	taskCmd	J	java.lang.String	0	org.apache.hadoop.applications.mawo.server.common.AbstractTask:setTaskCmd(java.lang.String)
org.apache.hadoop.applications.mawo.server.common.AbstractTask	setTaskId	taskID	C	org.apache.hadoop.applications.mawo.server.common.TaskId	0	org.apache.hadoop.applications.mawo.server.common.AbstractTask:setTaskId(org.apache.hadoop.applications.mawo.server.common.TaskId)
org.apache.hadoop.applications.mawo.server.common.AbstractTask	setTaskType	taskType	C	org.apache.hadoop.applications.mawo.server.common.TaskType	0	org.apache.hadoop.applications.mawo.server.common.AbstractTask:setTaskType(org.apache.hadoop.applications.mawo.server.common.TaskType)
org.apache.hadoop.applications.mawo.server.common.AbstractTask	setTimeout	timeout	J	long	0	org.apache.hadoop.applications.mawo.server.common.AbstractTask:setTimeout(long)
org.apache.hadoop.applications.mawo.server.common.TaskStatus	setRunState	runState	C	org.apache.hadoop.applications.mawo.server.common.TaskStatus$State	0	org.apache.hadoop.applications.mawo.server.common.TaskStatus:setRunState(org.apache.hadoop.applications.mawo.server.common.TaskStatus$State)
org.apache.hadoop.applications.mawo.server.common.TaskStatus	setExitCode	exitCode	J	int	0	org.apache.hadoop.applications.mawo.server.common.TaskStatus:setExitCode(int)
org.apache.hadoop.applications.mawo.server.common.TaskStatus	setTaskCMD	taskCMD	J	java.lang.String	0	org.apache.hadoop.applications.mawo.server.common.TaskStatus:setTaskCMD(java.lang.String)
org.apache.hadoop.applications.mawo.server.common.TaskStatus	setTaskType	taskType	J	java.lang.String	0	org.apache.hadoop.applications.mawo.server.common.TaskStatus:setTaskType(java.lang.String)
org.apache.hadoop.applications.mawo.server.common.TaskStatus	setTaskId	taskId	C	org.apache.hadoop.applications.mawo.server.common.TaskId	0	org.apache.hadoop.applications.mawo.server.common.TaskStatus:setTaskId(org.apache.hadoop.applications.mawo.server.common.TaskId)
org.apache.hadoop.applications.mawo.server.common.TaskStatus	setStartTime	startTime	J	long	0	org.apache.hadoop.applications.mawo.server.common.TaskStatus:setStartTime(long)
org.apache.hadoop.applications.mawo.server.common.TaskStatus	setEndTime	endTime	J	long	0	org.apache.hadoop.applications.mawo.server.common.TaskStatus:setEndTime(long)
org.apache.hadoop.applications.mawo.server.common.TaskStatus	setWorkerId	workerId	C	org.apache.hadoop.applications.mawo.server.worker.WorkerId	0	org.apache.hadoop.applications.mawo.server.common.TaskStatus:setWorkerId(org.apache.hadoop.applications.mawo.server.worker.WorkerId)
org.apache.hadoop.applications.mawo.server.worker.WorkerId	setHostname	hostname	C	org.apache.hadoop.io.Text	0	org.apache.hadoop.applications.mawo.server.worker.WorkerId:setHostname(org.apache.hadoop.io.Text)
org.apache.hadoop.yarn.service.webapp.ApiServer	setServiceClient	serviceClientUnitTest	C	org.apache.hadoop.yarn.service.client.ServiceClient	0	org.apache.hadoop.yarn.service.webapp.ApiServer:setServiceClient(org.apache.hadoop.yarn.service.client.ServiceClient)
org.apache.hadoop.yarn.proto.ClientAMProtocol$GetCompInstancesResponseProto$Builder	setCompInstances	compInstances_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.ClientAMProtocol$GetCompInstancesResponseProto$Builder:setCompInstances(java.lang.String)
org.apache.hadoop.yarn.proto.ClientAMProtocol$GetCompInstancesResponseProto$Builder	setCompInstancesBytes	compInstances_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.ClientAMProtocol$GetCompInstancesResponseProto$Builder:setCompInstancesBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.ClientAMProtocol$ComponentCountProto$Builder	setName	name_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.ClientAMProtocol$ComponentCountProto$Builder:setName(java.lang.String)
org.apache.hadoop.yarn.proto.ClientAMProtocol$ComponentCountProto$Builder	setNameBytes	name_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.ClientAMProtocol$ComponentCountProto$Builder:setNameBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.ClientAMProtocol$ComponentCountProto$Builder	setNumberOfContainers	numberOfContainers_	J	long	0	org.apache.hadoop.yarn.proto.ClientAMProtocol$ComponentCountProto$Builder:setNumberOfContainers(long)
org.apache.hadoop.yarn.proto.ClientAMProtocol$UpgradeServiceRequestProto$Builder	setVersion	version_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.ClientAMProtocol$UpgradeServiceRequestProto$Builder:setVersion(java.lang.String)
org.apache.hadoop.yarn.proto.ClientAMProtocol$UpgradeServiceRequestProto$Builder	setVersionBytes	version_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.ClientAMProtocol$UpgradeServiceRequestProto$Builder:setVersionBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.ClientAMProtocol$UpgradeServiceRequestProto$Builder	setAutoFinalize	autoFinalize_	J	boolean	0	org.apache.hadoop.yarn.proto.ClientAMProtocol$UpgradeServiceRequestProto$Builder:setAutoFinalize(boolean)
org.apache.hadoop.yarn.proto.ClientAMProtocol$UpgradeServiceRequestProto$Builder	setExpressUpgrade	expressUpgrade_	J	boolean	0	org.apache.hadoop.yarn.proto.ClientAMProtocol$UpgradeServiceRequestProto$Builder:setExpressUpgrade(boolean)
org.apache.hadoop.yarn.proto.ClientAMProtocol$GetCompInstancesRequestProto$Builder	setVersion	version_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.ClientAMProtocol$GetCompInstancesRequestProto$Builder:setVersion(java.lang.String)
org.apache.hadoop.yarn.proto.ClientAMProtocol$GetCompInstancesRequestProto$Builder	setVersionBytes	version_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.ClientAMProtocol$GetCompInstancesRequestProto$Builder:setVersionBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.ClientAMProtocol$GetStatusResponseProto$Builder	setStatus	status_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.ClientAMProtocol$GetStatusResponseProto$Builder:setStatus(java.lang.String)
org.apache.hadoop.yarn.proto.ClientAMProtocol$GetStatusResponseProto$Builder	setStatusBytes	status_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.ClientAMProtocol$GetStatusResponseProto$Builder:setStatusBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.ClientAMProtocol$UpgradeServiceResponseProto$Builder	setError	error_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.ClientAMProtocol$UpgradeServiceResponseProto$Builder:setError(java.lang.String)
org.apache.hadoop.yarn.proto.ClientAMProtocol$UpgradeServiceResponseProto$Builder	setErrorBytes	error_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.ClientAMProtocol$UpgradeServiceResponseProto$Builder:setErrorBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.service.ServiceEvent	setVersion	version	J	java.lang.String	0	org.apache.hadoop.yarn.service.ServiceEvent:setVersion(java.lang.String)
org.apache.hadoop.yarn.service.ServiceEvent	setAutoFinalize	autoFinalize	J	boolean	0	org.apache.hadoop.yarn.service.ServiceEvent:setAutoFinalize(boolean)
org.apache.hadoop.yarn.service.ServiceEvent	setExpressUpgrade	expressUpgrade	J	boolean	0	org.apache.hadoop.yarn.service.ServiceEvent:setExpressUpgrade(boolean)
org.apache.hadoop.yarn.service.ServiceEvent	setCompsToUpgrade	compsToUpgrade	GC	java.util.List	0	org.apache.hadoop.yarn.service.ServiceEvent:setCompsToUpgrade(java.util.List)
org.apache.hadoop.yarn.service.registry.YarnRegistryViewForProviders	setSelfRegistration	selfRegistration	C	org.apache.hadoop.registry.client.types.ServiceRecord	0	org.apache.hadoop.yarn.service.registry.YarnRegistryViewForProviders:setSelfRegistration(org.apache.hadoop.registry.client.types.ServiceRecord)
org.apache.hadoop.yarn.service.api.records.Artifact	setId	id	J	java.lang.String	0	org.apache.hadoop.yarn.service.api.records.Artifact:setId(java.lang.String)
org.apache.hadoop.yarn.service.api.records.Artifact	setType	type	C	org.apache.hadoop.yarn.service.api.records.Artifact$TypeEnum	0	org.apache.hadoop.yarn.service.api.records.Artifact:setType(org.apache.hadoop.yarn.service.api.records.Artifact$TypeEnum)
org.apache.hadoop.yarn.service.api.records.Artifact	setUri	uri	J	java.lang.String	0	org.apache.hadoop.yarn.service.api.records.Artifact:setUri(java.lang.String)
org.apache.hadoop.yarn.service.api.records.PlacementConstraint	setName	name	J	java.lang.String	0	org.apache.hadoop.yarn.service.api.records.PlacementConstraint:setName(java.lang.String)
org.apache.hadoop.yarn.service.api.records.PlacementConstraint	setType	type	C	org.apache.hadoop.yarn.service.api.records.PlacementType	0	org.apache.hadoop.yarn.service.api.records.PlacementConstraint:setType(org.apache.hadoop.yarn.service.api.records.PlacementType)
org.apache.hadoop.yarn.service.api.records.PlacementConstraint	setScope	scope	C	org.apache.hadoop.yarn.service.api.records.PlacementScope	0	org.apache.hadoop.yarn.service.api.records.PlacementConstraint:setScope(org.apache.hadoop.yarn.service.api.records.PlacementScope)
org.apache.hadoop.yarn.service.api.records.PlacementConstraint	setTargetTags	targetTags	GJ	java.util.List	0	org.apache.hadoop.yarn.service.api.records.PlacementConstraint:setTargetTags(java.util.List)
org.apache.hadoop.yarn.service.api.records.PlacementConstraint	setNodeAttributes	nodeAttributes	GJ	java.util.Map	0	org.apache.hadoop.yarn.service.api.records.PlacementConstraint:setNodeAttributes(java.util.Map)
org.apache.hadoop.yarn.service.api.records.PlacementConstraint	setNodePartitions	nodePartitions	GJ	java.util.List	0	org.apache.hadoop.yarn.service.api.records.PlacementConstraint:setNodePartitions(java.util.List)
org.apache.hadoop.yarn.service.api.records.PlacementConstraint	setMinCardinality	minCardinality	J	java.lang.Long	0	org.apache.hadoop.yarn.service.api.records.PlacementConstraint:setMinCardinality(java.lang.Long)
org.apache.hadoop.yarn.service.api.records.PlacementConstraint	setMaxCardinality	maxCardinality	J	java.lang.Long	0	org.apache.hadoop.yarn.service.api.records.PlacementConstraint:setMaxCardinality(java.lang.Long)
org.apache.hadoop.yarn.service.api.records.ResourceInformation	setValue	value	J	java.lang.Long	0	org.apache.hadoop.yarn.service.api.records.ResourceInformation:setValue(java.lang.Long)
org.apache.hadoop.yarn.service.api.records.ResourceInformation	setUnit	unit	J	java.lang.String	0	org.apache.hadoop.yarn.service.api.records.ResourceInformation:setUnit(java.lang.String)
org.apache.hadoop.yarn.service.api.records.ConfigFile	setType	type	C	org.apache.hadoop.yarn.service.api.records.ConfigFile$TypeEnum	0	org.apache.hadoop.yarn.service.api.records.ConfigFile:setType(org.apache.hadoop.yarn.service.api.records.ConfigFile$TypeEnum)
org.apache.hadoop.yarn.service.api.records.ConfigFile	setDestFile	destFile	J	java.lang.String	0	org.apache.hadoop.yarn.service.api.records.ConfigFile:setDestFile(java.lang.String)
org.apache.hadoop.yarn.service.api.records.ConfigFile	setSrcFile	srcFile	J	java.lang.String	0	org.apache.hadoop.yarn.service.api.records.ConfigFile:setSrcFile(java.lang.String)
org.apache.hadoop.yarn.service.api.records.ConfigFile	setVisibility	visibility	C	org.apache.hadoop.yarn.api.records.LocalResourceVisibility	0	org.apache.hadoop.yarn.service.api.records.ConfigFile:setVisibility(org.apache.hadoop.yarn.api.records.LocalResourceVisibility)
org.apache.hadoop.yarn.service.api.records.ConfigFile	setProperties	properties	GJ	java.util.Map	0	org.apache.hadoop.yarn.service.api.records.ConfigFile:setProperties(java.util.Map)
org.apache.hadoop.yarn.service.api.records.ServiceStatus	setDiagnostics	diagnostics	J	java.lang.String	0	org.apache.hadoop.yarn.service.api.records.ServiceStatus:setDiagnostics(java.lang.String)
org.apache.hadoop.yarn.service.api.records.ServiceStatus	setState	state	C	org.apache.hadoop.yarn.service.api.records.ServiceState	0	org.apache.hadoop.yarn.service.api.records.ServiceStatus:setState(org.apache.hadoop.yarn.service.api.records.ServiceState)
org.apache.hadoop.yarn.service.api.records.ServiceStatus	setCode	code	J	java.lang.Integer	0	org.apache.hadoop.yarn.service.api.records.ServiceStatus:setCode(java.lang.Integer)
org.apache.hadoop.yarn.service.api.records.Container	setId	id	J	java.lang.String	0	org.apache.hadoop.yarn.service.api.records.Container:setId(java.lang.String)
org.apache.hadoop.yarn.service.api.records.Container	setLaunchTime	launchTime	J	java.util.Date	0	org.apache.hadoop.yarn.service.api.records.Container:setLaunchTime(java.util.Date)
org.apache.hadoop.yarn.service.api.records.Container	setIp	ip	J	java.lang.String	0	org.apache.hadoop.yarn.service.api.records.Container:setIp(java.lang.String)
org.apache.hadoop.yarn.service.api.records.Container	setHostname	hostname	J	java.lang.String	0	org.apache.hadoop.yarn.service.api.records.Container:setHostname(java.lang.String)
org.apache.hadoop.yarn.service.api.records.Container	setBareHost	bareHost	J	java.lang.String	0	org.apache.hadoop.yarn.service.api.records.Container:setBareHost(java.lang.String)
org.apache.hadoop.yarn.service.api.records.Container	setState	state	C	org.apache.hadoop.yarn.service.api.records.ContainerState	0	org.apache.hadoop.yarn.service.api.records.Container:setState(org.apache.hadoop.yarn.service.api.records.ContainerState)
org.apache.hadoop.yarn.service.api.records.Container	setComponentInstanceName	componentInstanceName	J	java.lang.String	0	org.apache.hadoop.yarn.service.api.records.Container:setComponentInstanceName(java.lang.String)
org.apache.hadoop.yarn.service.api.records.Container	setResource	resource	C	org.apache.hadoop.yarn.service.api.records.Resource	0	org.apache.hadoop.yarn.service.api.records.Container:setResource(org.apache.hadoop.yarn.service.api.records.Resource)
org.apache.hadoop.yarn.service.api.records.Container	setArtifact	artifact	C	org.apache.hadoop.yarn.service.api.records.Artifact	0	org.apache.hadoop.yarn.service.api.records.Container:setArtifact(org.apache.hadoop.yarn.service.api.records.Artifact)
org.apache.hadoop.yarn.service.api.records.Container	setPrivilegedContainer	privilegedContainer	J	java.lang.Boolean	0	org.apache.hadoop.yarn.service.api.records.Container:setPrivilegedContainer(java.lang.Boolean)
org.apache.hadoop.yarn.service.api.records.Container	setExposedPorts	exposedPorts	GJ	java.util.Map	0	org.apache.hadoop.yarn.service.api.records.Container:setExposedPorts(java.util.Map)
org.apache.hadoop.yarn.service.api.records.Container	setLocalizationStatuses	localizationStatuses	GC	java.util.List	0	org.apache.hadoop.yarn.service.api.records.Container:setLocalizationStatuses(java.util.List)
org.apache.hadoop.yarn.service.api.records.Service	setName	name	J	java.lang.String	0	org.apache.hadoop.yarn.service.api.records.Service:setName(java.lang.String)
org.apache.hadoop.yarn.service.api.records.Service	setId	id	J	java.lang.String	0	org.apache.hadoop.yarn.service.api.records.Service:setId(java.lang.String)
org.apache.hadoop.yarn.service.api.records.Service	setVersion	version	J	java.lang.String	0	org.apache.hadoop.yarn.service.api.records.Service:setVersion(java.lang.String)
org.apache.hadoop.yarn.service.api.records.Service	setDescription	description	J	java.lang.String	0	org.apache.hadoop.yarn.service.api.records.Service:setDescription(java.lang.String)
org.apache.hadoop.yarn.service.api.records.Service	setArtifact	artifact	C	org.apache.hadoop.yarn.service.api.records.Artifact	0	org.apache.hadoop.yarn.service.api.records.Service:setArtifact(org.apache.hadoop.yarn.service.api.records.Artifact)
org.apache.hadoop.yarn.service.api.records.Service	setResource	resource	C	org.apache.hadoop.yarn.service.api.records.Resource	0	org.apache.hadoop.yarn.service.api.records.Service:setResource(org.apache.hadoop.yarn.service.api.records.Resource)
org.apache.hadoop.yarn.service.api.records.Service	setLaunchTime	launchTime	J	java.util.Date	0	org.apache.hadoop.yarn.service.api.records.Service:setLaunchTime(java.util.Date)
org.apache.hadoop.yarn.service.api.records.Service	setNumberOfRunningContainers	numberOfRunningContainers	J	java.lang.Long	0	org.apache.hadoop.yarn.service.api.records.Service:setNumberOfRunningContainers(java.lang.Long)
org.apache.hadoop.yarn.service.api.records.Service	setLifetime	lifetime	J	java.lang.Long	0	org.apache.hadoop.yarn.service.api.records.Service:setLifetime(java.lang.Long)
org.apache.hadoop.yarn.service.api.records.Service	setComponents	components	GC	java.util.List	0	org.apache.hadoop.yarn.service.api.records.Service:setComponents(java.util.List)
org.apache.hadoop.yarn.service.api.records.Service	setConfiguration	configuration	C	org.apache.hadoop.yarn.service.api.records.Configuration	0	org.apache.hadoop.yarn.service.api.records.Service:setConfiguration(org.apache.hadoop.yarn.service.api.records.Configuration)
org.apache.hadoop.yarn.service.api.records.Service	setState	state	C	org.apache.hadoop.yarn.service.api.records.ServiceState	0	org.apache.hadoop.yarn.service.api.records.Service:setState(org.apache.hadoop.yarn.service.api.records.ServiceState)
org.apache.hadoop.yarn.service.api.records.Service	setQuicklinks	quicklinks	GJ	java.util.Map	0	org.apache.hadoop.yarn.service.api.records.Service:setQuicklinks(java.util.Map)
org.apache.hadoop.yarn.service.api.records.Service	setQueue	queue	J	java.lang.String	0	org.apache.hadoop.yarn.service.api.records.Service:setQueue(java.lang.String)
org.apache.hadoop.yarn.service.api.records.Service	setDependencies	dependencies	GJ	java.util.List	0	org.apache.hadoop.yarn.service.api.records.Service:setDependencies(java.util.List)
org.apache.hadoop.yarn.service.api.records.Service	setKerberosPrincipal	kerberosPrincipal	C	org.apache.hadoop.yarn.service.api.records.KerberosPrincipal	0	org.apache.hadoop.yarn.service.api.records.Service:setKerberosPrincipal(org.apache.hadoop.yarn.service.api.records.KerberosPrincipal)
org.apache.hadoop.yarn.service.api.records.Service	setDockerClientConfig	dockerClientConfig	J	java.lang.String	0	org.apache.hadoop.yarn.service.api.records.Service:setDockerClientConfig(java.lang.String)
org.apache.hadoop.yarn.service.api.records.Resource	setProfile	profile	J	java.lang.String	0	org.apache.hadoop.yarn.service.api.records.Resource:setProfile(java.lang.String)
org.apache.hadoop.yarn.service.api.records.Resource	setCpus	cpus	J	java.lang.Integer	0	org.apache.hadoop.yarn.service.api.records.Resource:setCpus(java.lang.Integer)
org.apache.hadoop.yarn.service.api.records.Resource	setMemory	memory	J	java.lang.String	0	org.apache.hadoop.yarn.service.api.records.Resource:setMemory(java.lang.String)
org.apache.hadoop.yarn.service.api.records.Resource	setResourceInformations	additional	GC	java.util.Map	0	org.apache.hadoop.yarn.service.api.records.Resource:setResourceInformations(java.util.Map)
org.apache.hadoop.yarn.service.api.records.PlacementPolicy	setConstraints	constraints	GC	java.util.List	0	org.apache.hadoop.yarn.service.api.records.PlacementPolicy:setConstraints(java.util.List)
org.apache.hadoop.yarn.service.api.records.Configuration	setProperties	properties	GJ	java.util.Map	0	org.apache.hadoop.yarn.service.api.records.Configuration:setProperties(java.util.Map)
org.apache.hadoop.yarn.service.api.records.Configuration	setEnv	env	GJ	java.util.Map	0	org.apache.hadoop.yarn.service.api.records.Configuration:setEnv(java.util.Map)
org.apache.hadoop.yarn.service.api.records.Configuration	setFiles	files	GC	java.util.List	0	org.apache.hadoop.yarn.service.api.records.Configuration:setFiles(java.util.List)
org.apache.hadoop.yarn.service.api.records.Error	setCode	code	J	java.lang.Integer	0	org.apache.hadoop.yarn.service.api.records.Error:setCode(java.lang.Integer)
org.apache.hadoop.yarn.service.api.records.Error	setMessage	message	J	java.lang.String	0	org.apache.hadoop.yarn.service.api.records.Error:setMessage(java.lang.String)
org.apache.hadoop.yarn.service.api.records.Error	setFields	fields	J	java.lang.String	0	org.apache.hadoop.yarn.service.api.records.Error:setFields(java.lang.String)
org.apache.hadoop.yarn.service.api.records.KerberosPrincipal	setPrincipalName	principalName	J	java.lang.String	0	org.apache.hadoop.yarn.service.api.records.KerberosPrincipal:setPrincipalName(java.lang.String)
org.apache.hadoop.yarn.service.api.records.KerberosPrincipal	setKeytab	keytab	J	java.lang.String	0	org.apache.hadoop.yarn.service.api.records.KerberosPrincipal:setKeytab(java.lang.String)
org.apache.hadoop.yarn.service.api.records.ReadinessCheck	setType	type	C	org.apache.hadoop.yarn.service.api.records.ReadinessCheck$TypeEnum	0	org.apache.hadoop.yarn.service.api.records.ReadinessCheck:setType(org.apache.hadoop.yarn.service.api.records.ReadinessCheck$TypeEnum)
org.apache.hadoop.yarn.service.api.records.ReadinessCheck	setProperties	properties	GJ	java.util.Map	0	org.apache.hadoop.yarn.service.api.records.ReadinessCheck:setProperties(java.util.Map)
org.apache.hadoop.yarn.service.api.records.ReadinessCheck	setArtifact	artifact	C	org.apache.hadoop.yarn.service.api.records.Artifact	0	org.apache.hadoop.yarn.service.api.records.ReadinessCheck:setArtifact(org.apache.hadoop.yarn.service.api.records.Artifact)
org.apache.hadoop.yarn.service.api.records.ComponentContainers	setComponentName	componentName	J	java.lang.String	0	org.apache.hadoop.yarn.service.api.records.ComponentContainers:setComponentName(java.lang.String)
org.apache.hadoop.yarn.service.api.records.ComponentContainers	setContainers	containers	GC	java.util.List	0	org.apache.hadoop.yarn.service.api.records.ComponentContainers:setContainers(java.util.List)
org.apache.hadoop.yarn.service.api.records.LocalizationStatus	setDestFile	destFile	J	java.lang.String	0	org.apache.hadoop.yarn.service.api.records.LocalizationStatus:setDestFile(java.lang.String)
org.apache.hadoop.yarn.service.api.records.LocalizationStatus	setState	state	C	org.apache.hadoop.yarn.api.records.LocalizationState	0	org.apache.hadoop.yarn.service.api.records.LocalizationStatus:setState(org.apache.hadoop.yarn.api.records.LocalizationState)
org.apache.hadoop.yarn.service.api.records.LocalizationStatus	setDiagnostics	diagnostics	J	java.lang.String	0	org.apache.hadoop.yarn.service.api.records.LocalizationStatus:setDiagnostics(java.lang.String)
org.apache.hadoop.yarn.service.api.records.Component	setRestartPolicy	restartPolicy	C	org.apache.hadoop.yarn.service.api.records.Component$RestartPolicyEnum	0	org.apache.hadoop.yarn.service.api.records.Component:setRestartPolicy(org.apache.hadoop.yarn.service.api.records.Component$RestartPolicyEnum)
org.apache.hadoop.yarn.service.api.records.Component	setName	name	J	java.lang.String	0	org.apache.hadoop.yarn.service.api.records.Component:setName(java.lang.String)
org.apache.hadoop.yarn.service.api.records.Component	setDependencies	dependencies	GJ	java.util.List	0	org.apache.hadoop.yarn.service.api.records.Component:setDependencies(java.util.List)
org.apache.hadoop.yarn.service.api.records.Component	setReadinessCheck	readinessCheck	C	org.apache.hadoop.yarn.service.api.records.ReadinessCheck	0	org.apache.hadoop.yarn.service.api.records.Component:setReadinessCheck(org.apache.hadoop.yarn.service.api.records.ReadinessCheck)
org.apache.hadoop.yarn.service.api.records.Component	setArtifact	artifact	C	org.apache.hadoop.yarn.service.api.records.Artifact	0	org.apache.hadoop.yarn.service.api.records.Component:setArtifact(org.apache.hadoop.yarn.service.api.records.Artifact)
org.apache.hadoop.yarn.service.api.records.Component	setLaunchCommand	launchCommand	J	java.lang.String	0	org.apache.hadoop.yarn.service.api.records.Component:setLaunchCommand(java.lang.String)
org.apache.hadoop.yarn.service.api.records.Component	setResource	resource	C	org.apache.hadoop.yarn.service.api.records.Resource	0	org.apache.hadoop.yarn.service.api.records.Component:setResource(org.apache.hadoop.yarn.service.api.records.Resource)
org.apache.hadoop.yarn.service.api.records.Component	setNumberOfContainers	numberOfContainers	J	java.lang.Long	0	org.apache.hadoop.yarn.service.api.records.Component:setNumberOfContainers(java.lang.Long)
org.apache.hadoop.yarn.service.api.records.Component	setDecommissionedInstances	decommissionedInstances	GJ	java.util.List	0	org.apache.hadoop.yarn.service.api.records.Component:setDecommissionedInstances(java.util.List)
org.apache.hadoop.yarn.service.api.records.Component	setContainers	containers	GC	java.util.List	0	org.apache.hadoop.yarn.service.api.records.Component:setContainers(java.util.List)
org.apache.hadoop.yarn.service.api.records.Component	setRunPrivilegedContainer	runPrivilegedContainer	J	java.lang.Boolean	0	org.apache.hadoop.yarn.service.api.records.Component:setRunPrivilegedContainer(java.lang.Boolean)
org.apache.hadoop.yarn.service.api.records.Component	setPlacementPolicy	placementPolicy	C	org.apache.hadoop.yarn.service.api.records.PlacementPolicy	0	org.apache.hadoop.yarn.service.api.records.Component:setPlacementPolicy(org.apache.hadoop.yarn.service.api.records.PlacementPolicy)
org.apache.hadoop.yarn.service.api.records.Component	setConfiguration	configuration	C	org.apache.hadoop.yarn.service.api.records.Configuration	0	org.apache.hadoop.yarn.service.api.records.Component:setConfiguration(org.apache.hadoop.yarn.service.api.records.Configuration)
org.apache.hadoop.yarn.service.api.records.Component	setQuicklinks	quicklinks	GJ	java.util.List	0	org.apache.hadoop.yarn.service.api.records.Component:setQuicklinks(java.util.List)
org.apache.hadoop.yarn.service.api.records.Component	setState	state	C	org.apache.hadoop.yarn.service.api.records.ComponentState	0	org.apache.hadoop.yarn.service.api.records.Component:setState(org.apache.hadoop.yarn.service.api.records.ComponentState)
org.apache.hadoop.yarn.service.api.records.BaseResource	setUri	uri	J	java.lang.String	0	org.apache.hadoop.yarn.service.api.records.BaseResource:setUri(java.lang.String)
org.apache.hadoop.yarn.service.utils.SliderFileSystem	setAppDir	appDir	C	org.apache.hadoop.fs.Path	0	org.apache.hadoop.yarn.service.utils.SliderFileSystem:setAppDir(org.apache.hadoop.fs.Path)
org.apache.hadoop.yarn.service.utils.PublishedConfiguration	setUpdated	updated	J	long	0	org.apache.hadoop.yarn.service.utils.PublishedConfiguration:setUpdated(long)
org.apache.hadoop.yarn.service.monitor.probe.ProbeStatus	setTimestamp	timestamp	J	long	0	org.apache.hadoop.yarn.service.monitor.probe.ProbeStatus:setTimestamp(long)
org.apache.hadoop.yarn.service.monitor.probe.ProbeStatus	setMessage	message	J	java.lang.String	0	org.apache.hadoop.yarn.service.monitor.probe.ProbeStatus:setMessage(java.lang.String)
org.apache.hadoop.yarn.service.monitor.probe.ProbeStatus	setThrown	thrown	J	java.lang.Throwable	0	org.apache.hadoop.yarn.service.monitor.probe.ProbeStatus:setThrown(java.lang.Throwable)
org.apache.hadoop.yarn.service.monitor.probe.Probe	setName	name	J	java.lang.String	0	org.apache.hadoop.yarn.service.monitor.probe.Probe:setName(java.lang.String)
org.apache.hadoop.yarn.service.containerlaunch.AbstractLauncher	setYarnDockerMode	yarnDockerMode	J	boolean	0	org.apache.hadoop.yarn.service.containerlaunch.AbstractLauncher:setYarnDockerMode(boolean)
org.apache.hadoop.yarn.service.containerlaunch.AbstractLauncher	setDockerImage	dockerImage	J	java.lang.String	0	org.apache.hadoop.yarn.service.containerlaunch.AbstractLauncher:setDockerImage(java.lang.String)
org.apache.hadoop.yarn.service.containerlaunch.AbstractLauncher	setDockerNetwork	dockerNetwork	J	java.lang.String	0	org.apache.hadoop.yarn.service.containerlaunch.AbstractLauncher:setDockerNetwork(java.lang.String)
org.apache.hadoop.yarn.service.containerlaunch.AbstractLauncher	setDockerHostname	dockerHostname	J	java.lang.String	0	org.apache.hadoop.yarn.service.containerlaunch.AbstractLauncher:setDockerHostname(java.lang.String)
org.apache.hadoop.yarn.service.containerlaunch.AbstractLauncher	setRunPrivilegedContainer	runPrivilegedContainer	J	boolean	0	org.apache.hadoop.yarn.service.containerlaunch.AbstractLauncher:setRunPrivilegedContainer(boolean)
org.apache.hadoop.yarn.service.containerlaunch.ContainerLaunchService$ComponentLaunchContext	setArtifact	artifact	C	org.apache.hadoop.yarn.service.api.records.Artifact	0	org.apache.hadoop.yarn.service.containerlaunch.ContainerLaunchService$ComponentLaunchContext:setArtifact(org.apache.hadoop.yarn.service.api.records.Artifact)
org.apache.hadoop.yarn.service.containerlaunch.ContainerLaunchService$ComponentLaunchContext	setConfiguration	configuration	C	org.apache.hadoop.yarn.service.api.records.Configuration	0	org.apache.hadoop.yarn.service.containerlaunch.ContainerLaunchService$ComponentLaunchContext:setConfiguration(org.apache.hadoop.yarn.service.api.records.Configuration)
org.apache.hadoop.yarn.service.containerlaunch.ContainerLaunchService$ComponentLaunchContext	setLaunchCommand	launchCommand	J	java.lang.String	0	org.apache.hadoop.yarn.service.containerlaunch.ContainerLaunchService$ComponentLaunchContext:setLaunchCommand(java.lang.String)
org.apache.hadoop.yarn.service.containerlaunch.ContainerLaunchService$ComponentLaunchContext	setRunPrivilegedContainer	runPrivilegedContainer	J	boolean	0	org.apache.hadoop.yarn.service.containerlaunch.ContainerLaunchService$ComponentLaunchContext:setRunPrivilegedContainer(boolean)
org.apache.hadoop.yarn.service.ServiceScheduler	setGracefulStop	finalApplicationStatus	C	org.apache.hadoop.yarn.api.records.FinalApplicationStatus	0	org.apache.hadoop.yarn.service.ServiceScheduler:setGracefulStop(org.apache.hadoop.yarn.api.records.FinalApplicationStatus)
org.apache.hadoop.yarn.service.ServiceContext	setServiceManager	serviceManager	C	org.apache.hadoop.yarn.service.ServiceManager	0	org.apache.hadoop.yarn.service.ServiceContext:setServiceManager(org.apache.hadoop.yarn.service.ServiceManager)
org.apache.hadoop.yarn.service.client.ServiceClient	setFileSystem	fs	C	org.apache.hadoop.yarn.service.utils.SliderFileSystem	0	org.apache.hadoop.yarn.service.client.ServiceClient:setFileSystem(org.apache.hadoop.yarn.service.utils.SliderFileSystem)
org.apache.hadoop.yarn.service.client.ServiceClient	setYarnClient	yarnClient	C	org.apache.hadoop.yarn.client.api.YarnClient	0	org.apache.hadoop.yarn.service.client.ServiceClient:setYarnClient(org.apache.hadoop.yarn.client.api.YarnClient)
org.apache.hadoop.yarn.service.component.instance.ComponentInstance	setContainer	container	C	org.apache.hadoop.yarn.api.records.Container	0	org.apache.hadoop.yarn.service.component.instance.ComponentInstance:setContainer(org.apache.hadoop.yarn.api.records.Container)
org.apache.hadoop.yarn.service.component.instance.ComponentInstance	setCompInstanceDir	compInstanceDir	C	org.apache.hadoop.fs.Path	0	org.apache.hadoop.yarn.service.component.instance.ComponentInstance:setCompInstanceDir(org.apache.hadoop.fs.Path)
org.apache.hadoop.yarn.service.component.instance.ComponentInstanceEvent	setStatus	status	C	org.apache.hadoop.yarn.api.records.ContainerStatus	0	org.apache.hadoop.yarn.service.component.instance.ComponentInstanceEvent:setStatus(org.apache.hadoop.yarn.api.records.ContainerStatus)
org.apache.hadoop.yarn.service.component.instance.ComponentInstanceId	setContainerId	containerId	C	org.apache.hadoop.yarn.api.records.ContainerId	0	org.apache.hadoop.yarn.service.component.instance.ComponentInstanceId:setContainerId(org.apache.hadoop.yarn.api.records.ContainerId)
org.apache.hadoop.yarn.service.component.ComponentEvent	setContainerId	containerId	C	org.apache.hadoop.yarn.api.records.ContainerId	0	org.apache.hadoop.yarn.service.component.ComponentEvent:setContainerId(org.apache.hadoop.yarn.api.records.ContainerId)
org.apache.hadoop.yarn.service.component.ComponentEvent	setDesired	desired	J	long	0	org.apache.hadoop.yarn.service.component.ComponentEvent:setDesired(long)
org.apache.hadoop.yarn.service.component.ComponentEvent	setContainer	container	C	org.apache.hadoop.yarn.api.records.Container	0	org.apache.hadoop.yarn.service.component.ComponentEvent:setContainer(org.apache.hadoop.yarn.api.records.Container)
org.apache.hadoop.yarn.service.component.ComponentEvent	setInstance	instance	C	org.apache.hadoop.yarn.service.component.instance.ComponentInstance	0	org.apache.hadoop.yarn.service.component.ComponentEvent:setInstance(org.apache.hadoop.yarn.service.component.instance.ComponentInstance)
org.apache.hadoop.yarn.service.component.ComponentEvent	setInstanceName	instanceName	J	java.lang.String	0	org.apache.hadoop.yarn.service.component.ComponentEvent:setInstanceName(java.lang.String)
org.apache.hadoop.yarn.service.component.ComponentEvent	setStatus	status	C	org.apache.hadoop.yarn.api.records.ContainerStatus	0	org.apache.hadoop.yarn.service.component.ComponentEvent:setStatus(org.apache.hadoop.yarn.api.records.ContainerStatus)
org.apache.hadoop.yarn.service.component.ComponentEvent	setTargetSpec	targetSpec	C	org.apache.hadoop.yarn.service.api.records.Component	0	org.apache.hadoop.yarn.service.component.ComponentEvent:setTargetSpec(org.apache.hadoop.yarn.service.api.records.Component)
org.apache.hadoop.yarn.service.component.ComponentEvent	setUpgradeVersion	upgradeVersion	J	java.lang.String	0	org.apache.hadoop.yarn.service.component.ComponentEvent:setUpgradeVersion(java.lang.String)
org.apache.hadoop.yarn.service.component.Component	setHealthThresholdMonitorEnabled	healthThresholdMonitorEnabled	J	boolean	0	org.apache.hadoop.yarn.service.component.Component:setHealthThresholdMonitorEnabled(boolean)
org.apache.hadoop.yarn.client.api.NMClient	setNMTokenCache	nmTokenCache	C	org.apache.hadoop.yarn.client.api.NMTokenCache	0	org.apache.hadoop.yarn.client.api.NMClient:setNMTokenCache(org.apache.hadoop.yarn.client.api.NMTokenCache)
org.apache.hadoop.yarn.client.api.AMRMClient	setNMTokenCache	nmTokenCache	C	org.apache.hadoop.yarn.client.api.NMTokenCache	0	org.apache.hadoop.yarn.client.api.AMRMClient:setNMTokenCache(org.apache.hadoop.yarn.client.api.NMTokenCache)
org.apache.hadoop.yarn.client.api.async.NMClientAsync	setClient	client	C	org.apache.hadoop.yarn.client.api.NMClient	0	org.apache.hadoop.yarn.client.api.async.NMClientAsync:setClient(org.apache.hadoop.yarn.client.api.NMClient)
org.apache.hadoop.yarn.client.api.async.NMClientAsync	setCallbackHandler	callbackHandler	C	org.apache.hadoop.yarn.client.api.async.NMClientAsync$CallbackHandler	0	org.apache.hadoop.yarn.client.api.async.NMClientAsync:setCallbackHandler(org.apache.hadoop.yarn.client.api.async.NMClientAsync$CallbackHandler)
org.apache.hadoop.yarn.client.api.impl.AHSv2ClientImpl	setReaderClient	readerClient	C	org.apache.hadoop.yarn.client.api.TimelineReaderClient	0	org.apache.hadoop.yarn.client.api.impl.AHSv2ClientImpl:setReaderClient(org.apache.hadoop.yarn.client.api.TimelineReaderClient)
org.apache.hadoop.yarn.client.api.impl.YarnClientImpl	setRMClient	rmClient	C	org.apache.hadoop.yarn.api.ApplicationClientProtocol	0	org.apache.hadoop.yarn.client.api.impl.YarnClientImpl:setRMClient(org.apache.hadoop.yarn.api.ApplicationClientProtocol)
org.apache.hadoop.yarn.client.cli.NodeAttributesCLI	setErrOut	errOut	J	java.io.PrintStream	0	org.apache.hadoop.yarn.client.cli.NodeAttributesCLI:setErrOut(java.io.PrintStream)
org.apache.hadoop.yarn.client.cli.YarnCLI	setSysOutPrintStream	sysout	J	java.io.PrintStream	0	org.apache.hadoop.yarn.client.cli.YarnCLI:setSysOutPrintStream(java.io.PrintStream)
org.apache.hadoop.yarn.client.cli.YarnCLI	setSysErrPrintStream	syserr	J	java.io.PrintStream	0	org.apache.hadoop.yarn.client.cli.YarnCLI:setSysErrPrintStream(java.io.PrintStream)
org.apache.hadoop.yarn.client.cli.YarnCLI	setClient	client	C	org.apache.hadoop.yarn.client.api.YarnClient	0	org.apache.hadoop.yarn.client.cli.YarnCLI:setClient(org.apache.hadoop.yarn.client.api.YarnClient)
org.apache.hadoop.yarn.client.cli.NodeAttributesCLI$ClientCommandHandler	setSysOut	sysOut	J	java.io.PrintStream	0	org.apache.hadoop.yarn.client.cli.NodeAttributesCLI$ClientCommandHandler:setSysOut(java.io.PrintStream)
org.apache.hadoop.yarn.proto.YarnSecurityTokenProtos$ClientToAMTokenIdentifierProto$Builder	setClientName	clientName_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnSecurityTokenProtos$ClientToAMTokenIdentifierProto$Builder:setClientName(java.lang.String)
org.apache.hadoop.yarn.proto.YarnSecurityTokenProtos$ClientToAMTokenIdentifierProto$Builder	setClientNameBytes	clientName_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnSecurityTokenProtos$ClientToAMTokenIdentifierProto$Builder:setClientNameBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnSecurityTokenProtos$YARNDelegationTokenIdentifierProto$Builder	setOwner	owner_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnSecurityTokenProtos$YARNDelegationTokenIdentifierProto$Builder:setOwner(java.lang.String)
org.apache.hadoop.yarn.proto.YarnSecurityTokenProtos$YARNDelegationTokenIdentifierProto$Builder	setOwnerBytes	owner_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnSecurityTokenProtos$YARNDelegationTokenIdentifierProto$Builder:setOwnerBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnSecurityTokenProtos$YARNDelegationTokenIdentifierProto$Builder	setRenewer	renewer_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnSecurityTokenProtos$YARNDelegationTokenIdentifierProto$Builder:setRenewer(java.lang.String)
org.apache.hadoop.yarn.proto.YarnSecurityTokenProtos$YARNDelegationTokenIdentifierProto$Builder	setRenewerBytes	renewer_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnSecurityTokenProtos$YARNDelegationTokenIdentifierProto$Builder:setRenewerBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnSecurityTokenProtos$YARNDelegationTokenIdentifierProto$Builder	setRealUser	realUser_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnSecurityTokenProtos$YARNDelegationTokenIdentifierProto$Builder:setRealUser(java.lang.String)
org.apache.hadoop.yarn.proto.YarnSecurityTokenProtos$YARNDelegationTokenIdentifierProto$Builder	setRealUserBytes	realUser_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnSecurityTokenProtos$YARNDelegationTokenIdentifierProto$Builder:setRealUserBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnSecurityTokenProtos$YARNDelegationTokenIdentifierProto$Builder	setIssueDate	issueDate_	J	long	0	org.apache.hadoop.yarn.proto.YarnSecurityTokenProtos$YARNDelegationTokenIdentifierProto$Builder:setIssueDate(long)
org.apache.hadoop.yarn.proto.YarnSecurityTokenProtos$YARNDelegationTokenIdentifierProto$Builder	setMaxDate	maxDate_	J	long	0	org.apache.hadoop.yarn.proto.YarnSecurityTokenProtos$YARNDelegationTokenIdentifierProto$Builder:setMaxDate(long)
org.apache.hadoop.yarn.proto.YarnSecurityTokenProtos$YARNDelegationTokenIdentifierProto$Builder	setSequenceNumber	sequenceNumber_	J	int	0	org.apache.hadoop.yarn.proto.YarnSecurityTokenProtos$YARNDelegationTokenIdentifierProto$Builder:setSequenceNumber(int)
org.apache.hadoop.yarn.proto.YarnSecurityTokenProtos$YARNDelegationTokenIdentifierProto$Builder	setMasterKeyId	masterKeyId_	J	int	0	org.apache.hadoop.yarn.proto.YarnSecurityTokenProtos$YARNDelegationTokenIdentifierProto$Builder:setMasterKeyId(int)
org.apache.hadoop.yarn.proto.YarnSecurityTokenProtos$AMRMTokenIdentifierProto$Builder	setKeyId	keyId_	J	int	0	org.apache.hadoop.yarn.proto.YarnSecurityTokenProtos$AMRMTokenIdentifierProto$Builder:setKeyId(int)
org.apache.hadoop.yarn.proto.YarnSecurityTokenProtos$ContainerTokenIdentifierProto$Builder	setNmHostAddr	nmHostAddr_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnSecurityTokenProtos$ContainerTokenIdentifierProto$Builder:setNmHostAddr(java.lang.String)
org.apache.hadoop.yarn.proto.YarnSecurityTokenProtos$ContainerTokenIdentifierProto$Builder	setNmHostAddrBytes	nmHostAddr_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnSecurityTokenProtos$ContainerTokenIdentifierProto$Builder:setNmHostAddrBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnSecurityTokenProtos$ContainerTokenIdentifierProto$Builder	setAppSubmitter	appSubmitter_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnSecurityTokenProtos$ContainerTokenIdentifierProto$Builder:setAppSubmitter(java.lang.String)
org.apache.hadoop.yarn.proto.YarnSecurityTokenProtos$ContainerTokenIdentifierProto$Builder	setAppSubmitterBytes	appSubmitter_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnSecurityTokenProtos$ContainerTokenIdentifierProto$Builder:setAppSubmitterBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnSecurityTokenProtos$ContainerTokenIdentifierProto$Builder	setExpiryTimeStamp	expiryTimeStamp_	J	long	0	org.apache.hadoop.yarn.proto.YarnSecurityTokenProtos$ContainerTokenIdentifierProto$Builder:setExpiryTimeStamp(long)
org.apache.hadoop.yarn.proto.YarnSecurityTokenProtos$ContainerTokenIdentifierProto$Builder	setMasterKeyId	masterKeyId_	J	int	0	org.apache.hadoop.yarn.proto.YarnSecurityTokenProtos$ContainerTokenIdentifierProto$Builder:setMasterKeyId(int)
org.apache.hadoop.yarn.proto.YarnSecurityTokenProtos$ContainerTokenIdentifierProto$Builder	setRmIdentifier	rmIdentifier_	J	long	0	org.apache.hadoop.yarn.proto.YarnSecurityTokenProtos$ContainerTokenIdentifierProto$Builder:setRmIdentifier(long)
org.apache.hadoop.yarn.proto.YarnSecurityTokenProtos$ContainerTokenIdentifierProto$Builder	setCreationTime	creationTime_	J	long	0	org.apache.hadoop.yarn.proto.YarnSecurityTokenProtos$ContainerTokenIdentifierProto$Builder:setCreationTime(long)
org.apache.hadoop.yarn.proto.YarnSecurityTokenProtos$ContainerTokenIdentifierProto$Builder	setNodeLabelExpression	nodeLabelExpression_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnSecurityTokenProtos$ContainerTokenIdentifierProto$Builder:setNodeLabelExpression(java.lang.String)
org.apache.hadoop.yarn.proto.YarnSecurityTokenProtos$ContainerTokenIdentifierProto$Builder	setNodeLabelExpressionBytes	nodeLabelExpression_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnSecurityTokenProtos$ContainerTokenIdentifierProto$Builder:setNodeLabelExpressionBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnSecurityTokenProtos$ContainerTokenIdentifierProto$Builder	setVersion	version_	J	int	0	org.apache.hadoop.yarn.proto.YarnSecurityTokenProtos$ContainerTokenIdentifierProto$Builder:setVersion(int)
org.apache.hadoop.yarn.proto.YarnSecurityTokenProtos$ContainerTokenIdentifierProto$Builder	setAllocationRequestId	allocationRequestId_	J	long	0	org.apache.hadoop.yarn.proto.YarnSecurityTokenProtos$ContainerTokenIdentifierProto$Builder:setAllocationRequestId(long)
org.apache.hadoop.yarn.proto.YarnSecurityTokenProtos$NMTokenIdentifierProto$Builder	setAppSubmitter	appSubmitter_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnSecurityTokenProtos$NMTokenIdentifierProto$Builder:setAppSubmitter(java.lang.String)
org.apache.hadoop.yarn.proto.YarnSecurityTokenProtos$NMTokenIdentifierProto$Builder	setAppSubmitterBytes	appSubmitter_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnSecurityTokenProtos$NMTokenIdentifierProto$Builder:setAppSubmitterBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnSecurityTokenProtos$NMTokenIdentifierProto$Builder	setKeyId	keyId_	J	int	0	org.apache.hadoop.yarn.proto.YarnSecurityTokenProtos$NMTokenIdentifierProto$Builder:setKeyId(int)
org.apache.hadoop.yarn.proto.YarnSecurityTokenProtos$DockerCredentialTokenIdentifierProto$Builder	setRegistryUrl	registryUrl_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnSecurityTokenProtos$DockerCredentialTokenIdentifierProto$Builder:setRegistryUrl(java.lang.String)
org.apache.hadoop.yarn.proto.YarnSecurityTokenProtos$DockerCredentialTokenIdentifierProto$Builder	setRegistryUrlBytes	registryUrl_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnSecurityTokenProtos$DockerCredentialTokenIdentifierProto$Builder:setRegistryUrlBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnSecurityTokenProtos$DockerCredentialTokenIdentifierProto$Builder	setApplicationId	applicationId_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnSecurityTokenProtos$DockerCredentialTokenIdentifierProto$Builder:setApplicationId(java.lang.String)
org.apache.hadoop.yarn.proto.YarnSecurityTokenProtos$DockerCredentialTokenIdentifierProto$Builder	setApplicationIdBytes	applicationId_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnSecurityTokenProtos$DockerCredentialTokenIdentifierProto$Builder:setApplicationIdBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.nodelabels.RMNodeLabel	setIsExclusive	exclusive	J	boolean	0	org.apache.hadoop.yarn.nodelabels.RMNodeLabel:setIsExclusive(boolean)
org.apache.hadoop.yarn.nodelabels.CommonNodeLabelsManager	setInitNodeLabelStoreInProgress	initNodeLabelStoreInProgress	J	boolean	0	org.apache.hadoop.yarn.nodelabels.CommonNodeLabelsManager:setInitNodeLabelStoreInProgress(boolean)
org.apache.hadoop.yarn.nodelabels.RMNodeAttribute	setAttribute	attribute	C	org.apache.hadoop.yarn.api.records.NodeAttribute	0	org.apache.hadoop.yarn.nodelabels.RMNodeAttribute:setAttribute(org.apache.hadoop.yarn.api.records.NodeAttribute)
org.apache.hadoop.yarn.nodelabels.store.AbstractFSNodeStore	setFs	fs	C	org.apache.hadoop.fs.FileSystem	0	org.apache.hadoop.yarn.nodelabels.store.AbstractFSNodeStore:setFs(org.apache.hadoop.fs.FileSystem)
org.apache.hadoop.yarn.nodelabels.store.op.RemoveNodeToAttributeLogOp	setAttributes	attributes	GC	java.util.List	0	org.apache.hadoop.yarn.nodelabels.store.op.RemoveNodeToAttributeLogOp:setAttributes(java.util.List)
org.apache.hadoop.yarn.nodelabels.store.op.AddClusterLabelOp	setLabels	labels	GC	java.util.List	0	org.apache.hadoop.yarn.nodelabels.store.op.AddClusterLabelOp:setLabels(java.util.List)
org.apache.hadoop.yarn.nodelabels.store.op.RemoveClusterLabelOp	setLabels	labels	GJ	java.util.Collection	0	org.apache.hadoop.yarn.nodelabels.store.op.RemoveClusterLabelOp:setLabels(java.util.Collection)
org.apache.hadoop.yarn.nodelabels.store.op.AddNodeToAttributeLogOp	setAttributes	attributes	GC	java.util.List	0	org.apache.hadoop.yarn.nodelabels.store.op.AddNodeToAttributeLogOp:setAttributes(java.util.List)
org.apache.hadoop.yarn.nodelabels.store.op.NodeToLabelOp	setNodeToLabels	nodeToLabels	GC	java.util.Map	0	org.apache.hadoop.yarn.nodelabels.store.op.NodeToLabelOp:setNodeToLabels(java.util.Map)
org.apache.hadoop.yarn.nodelabels.store.op.ReplaceNodeToAttributeLogOp	setAttributes	attributes	GC	java.util.List	0	org.apache.hadoop.yarn.nodelabels.store.op.ReplaceNodeToAttributeLogOp:setAttributes(java.util.List)
org.apache.hadoop.yarn.metrics.GenericEventTypeMetrics$EventTypeMetricsBuilder	setEnumClass	enumClass	GC	java.lang.Class	0	org.apache.hadoop.yarn.metrics.GenericEventTypeMetrics$EventTypeMetricsBuilder:setEnumClass(java.lang.Class)
org.apache.hadoop.yarn.metrics.GenericEventTypeMetrics$EventTypeMetricsBuilder	setEnums	enums	GC	java.lang.Enum	1	org.apache.hadoop.yarn.metrics.GenericEventTypeMetrics$EventTypeMetricsBuilder:setEnums(java.lang.Enum[])
org.apache.hadoop.yarn.metrics.GenericEventTypeMetrics$EventTypeMetricsBuilder	setInfo	info	C	org.apache.hadoop.metrics2.MetricsInfo	0	org.apache.hadoop.yarn.metrics.GenericEventTypeMetrics$EventTypeMetricsBuilder:setInfo(org.apache.hadoop.metrics2.MetricsInfo)
org.apache.hadoop.yarn.metrics.GenericEventTypeMetrics$EventTypeMetricsBuilder	setMs	ms	C	org.apache.hadoop.metrics2.MetricsSystem	0	org.apache.hadoop.yarn.metrics.GenericEventTypeMetrics$EventTypeMetricsBuilder:setMs(org.apache.hadoop.metrics2.MetricsSystem)
org.apache.hadoop.yarn.event.EventDispatcher	setMetrics	metrics	C	org.apache.hadoop.yarn.metrics.EventTypeMetrics	0	org.apache.hadoop.yarn.event.EventDispatcher:setMetrics(org.apache.hadoop.yarn.metrics.EventTypeMetrics)
org.apache.hadoop.yarn.server.api.protocolrecords.impl.pb.RemoveFromClusterNodeLabelsRequestPBImpl	setNodeLabels	labels	GJ	java.util.Set	0	org.apache.hadoop.yarn.server.api.protocolrecords.impl.pb.RemoveFromClusterNodeLabelsRequestPBImpl:setNodeLabels(java.util.Set)
org.apache.hadoop.yarn.server.api.protocolrecords.impl.pb.RefreshNodesRequestPBImpl	setDecommissionType	decommissionType	C	org.apache.hadoop.yarn.api.records.DecommissionType	0	org.apache.hadoop.yarn.server.api.protocolrecords.impl.pb.RefreshNodesRequestPBImpl:setDecommissionType(org.apache.hadoop.yarn.api.records.DecommissionType)
org.apache.hadoop.yarn.server.api.protocolrecords.impl.pb.CheckForDecommissioningNodesResponsePBImpl	setDecommissioningNodes	decommissioningNodes	GC	java.util.Set	0	org.apache.hadoop.yarn.server.api.protocolrecords.impl.pb.CheckForDecommissioningNodesResponsePBImpl:setDecommissioningNodes(java.util.Set)
org.apache.hadoop.yarn.api.protocolrecords.impl.pb.GetNodesToAttributesRequestPBImpl	setHostNames	hostNames	GJ	java.util.Set	0	org.apache.hadoop.yarn.api.protocolrecords.impl.pb.GetNodesToAttributesRequestPBImpl:setHostNames(java.util.Set)
org.apache.hadoop.yarn.api.protocolrecords.impl.pb.StartContainerRequestPBImpl	setContainerLaunchContext	containerLaunchContext	C	org.apache.hadoop.yarn.api.records.ContainerLaunchContext	0	org.apache.hadoop.yarn.api.protocolrecords.impl.pb.StartContainerRequestPBImpl:setContainerLaunchContext(org.apache.hadoop.yarn.api.records.ContainerLaunchContext)
org.apache.hadoop.yarn.api.protocolrecords.impl.pb.StartContainerRequestPBImpl	setContainerToken	containerToken	C	org.apache.hadoop.yarn.api.records.Token	0	org.apache.hadoop.yarn.api.protocolrecords.impl.pb.StartContainerRequestPBImpl:setContainerToken(org.apache.hadoop.yarn.api.records.Token)
org.apache.hadoop.yarn.api.protocolrecords.impl.pb.SubmitApplicationRequestPBImpl	setApplicationSubmissionContext	applicationSubmissionContext	C	org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext	0	org.apache.hadoop.yarn.api.protocolrecords.impl.pb.SubmitApplicationRequestPBImpl:setApplicationSubmissionContext(org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext)
org.apache.hadoop.yarn.api.protocolrecords.impl.pb.GetApplicationAttemptReportResponsePBImpl	setApplicationAttemptReport	applicationAttemptReport	C	org.apache.hadoop.yarn.api.records.ApplicationAttemptReport	0	org.apache.hadoop.yarn.api.protocolrecords.impl.pb.GetApplicationAttemptReportResponsePBImpl:setApplicationAttemptReport(org.apache.hadoop.yarn.api.records.ApplicationAttemptReport)
org.apache.hadoop.yarn.api.protocolrecords.impl.pb.GetAllResourceTypeInfoResponsePBImpl	setResourceTypeInfo	resourceTypeInfo	GC	java.util.List	0	org.apache.hadoop.yarn.api.protocolrecords.impl.pb.GetAllResourceTypeInfoResponsePBImpl:setResourceTypeInfo(java.util.List)
org.apache.hadoop.yarn.api.protocolrecords.impl.pb.GetClusterNodesResponsePBImpl	setNodeReports	nodeManagerInfoList	GC	java.util.List	0	org.apache.hadoop.yarn.api.protocolrecords.impl.pb.GetClusterNodesResponsePBImpl:setNodeReports(java.util.List)
org.apache.hadoop.yarn.api.protocolrecords.impl.pb.RegisterApplicationMasterResponsePBImpl	setMaximumResourceCapability	maximumResourceCapability	C	org.apache.hadoop.yarn.api.records.Resource	0	org.apache.hadoop.yarn.api.protocolrecords.impl.pb.RegisterApplicationMasterResponsePBImpl:setMaximumResourceCapability(org.apache.hadoop.yarn.api.records.Resource)
org.apache.hadoop.yarn.api.protocolrecords.impl.pb.RegisterApplicationMasterResponsePBImpl	setResourceTypes	resourceTypeInfo	GC	java.util.List	0	org.apache.hadoop.yarn.api.protocolrecords.impl.pb.RegisterApplicationMasterResponsePBImpl:setResourceTypes(java.util.List)
org.apache.hadoop.yarn.api.protocolrecords.impl.pb.GetNewApplicationResponsePBImpl	setApplicationId	applicationId	C	org.apache.hadoop.yarn.api.records.ApplicationId	0	org.apache.hadoop.yarn.api.protocolrecords.impl.pb.GetNewApplicationResponsePBImpl:setApplicationId(org.apache.hadoop.yarn.api.records.ApplicationId)
org.apache.hadoop.yarn.api.protocolrecords.impl.pb.GetNewApplicationResponsePBImpl	setMaximumResourceCapability	maximumResourceCapability	C	org.apache.hadoop.yarn.api.records.Resource	0	org.apache.hadoop.yarn.api.protocolrecords.impl.pb.GetNewApplicationResponsePBImpl:setMaximumResourceCapability(org.apache.hadoop.yarn.api.records.Resource)
org.apache.hadoop.yarn.api.protocolrecords.impl.pb.GetLabelsToNodesRequestPBImpl	setNodeLabels	nodeLabels	GJ	java.util.Set	0	org.apache.hadoop.yarn.api.protocolrecords.impl.pb.GetLabelsToNodesRequestPBImpl:setNodeLabels(java.util.Set)
org.apache.hadoop.yarn.api.protocolrecords.impl.pb.StartContainersResponsePBImpl	setSuccessfullyStartedContainers	succeededContainers	GC	java.util.List	0	org.apache.hadoop.yarn.api.protocolrecords.impl.pb.StartContainersResponsePBImpl:setSuccessfullyStartedContainers(java.util.List)
org.apache.hadoop.yarn.api.protocolrecords.impl.pb.StartContainersResponsePBImpl	setFailedRequests	failedContainers	GC	java.util.Map	0	org.apache.hadoop.yarn.api.protocolrecords.impl.pb.StartContainersResponsePBImpl:setFailedRequests(java.util.Map)
org.apache.hadoop.yarn.api.protocolrecords.impl.pb.StopContainersRequestPBImpl	setContainerIds	containerIds	GC	java.util.List	0	org.apache.hadoop.yarn.api.protocolrecords.impl.pb.StopContainersRequestPBImpl:setContainerIds(java.util.List)
org.apache.hadoop.yarn.api.protocolrecords.impl.pb.GetResourceProfileRequestPBImpl	setProfileName	profile	J	java.lang.String	0	org.apache.hadoop.yarn.api.protocolrecords.impl.pb.GetResourceProfileRequestPBImpl:setProfileName(java.lang.String)
org.apache.hadoop.yarn.api.protocolrecords.impl.pb.StartContainersRequestPBImpl	setStartContainerRequests	requests	GC	java.util.List	0	org.apache.hadoop.yarn.api.protocolrecords.impl.pb.StartContainersRequestPBImpl:setStartContainerRequests(java.util.List)
org.apache.hadoop.yarn.api.protocolrecords.impl.pb.GetContainerStatusesResponsePBImpl	setContainerStatuses	containerStatuses	GC	java.util.List	0	org.apache.hadoop.yarn.api.protocolrecords.impl.pb.GetContainerStatusesResponsePBImpl:setContainerStatuses(java.util.List)
org.apache.hadoop.yarn.api.protocolrecords.impl.pb.GetContainerStatusesResponsePBImpl	setFailedRequests	failedRequests	GC	java.util.Map	0	org.apache.hadoop.yarn.api.protocolrecords.impl.pb.GetContainerStatusesResponsePBImpl:setFailedRequests(java.util.Map)
org.apache.hadoop.yarn.api.protocolrecords.impl.pb.AllocateResponsePBImpl	setAvailableResources	limit	C	org.apache.hadoop.yarn.api.records.Resource	0	org.apache.hadoop.yarn.api.protocolrecords.impl.pb.AllocateResponsePBImpl:setAvailableResources(org.apache.hadoop.yarn.api.records.Resource)
org.apache.hadoop.yarn.api.protocolrecords.impl.pb.AllocateResponsePBImpl	setPreemptionMessage	preempt	C	org.apache.hadoop.yarn.api.records.PreemptionMessage	0	org.apache.hadoop.yarn.api.protocolrecords.impl.pb.AllocateResponsePBImpl:setPreemptionMessage(org.apache.hadoop.yarn.api.records.PreemptionMessage)
org.apache.hadoop.yarn.api.protocolrecords.impl.pb.AllocateResponsePBImpl	setAMRMToken	amrmToken	C	org.apache.hadoop.yarn.api.records.Token	0	org.apache.hadoop.yarn.api.protocolrecords.impl.pb.AllocateResponsePBImpl:setAMRMToken(org.apache.hadoop.yarn.api.records.Token)
org.apache.hadoop.yarn.api.protocolrecords.impl.pb.AllocateResponsePBImpl	setCollectorInfo	collectorInfo	C	org.apache.hadoop.yarn.api.records.CollectorInfo	0	org.apache.hadoop.yarn.api.protocolrecords.impl.pb.AllocateResponsePBImpl:setCollectorInfo(org.apache.hadoop.yarn.api.records.CollectorInfo)
org.apache.hadoop.yarn.api.protocolrecords.impl.pb.AllocateResponsePBImpl	setApplicationPriority	appPriority	C	org.apache.hadoop.yarn.api.records.Priority	0	org.apache.hadoop.yarn.api.protocolrecords.impl.pb.AllocateResponsePBImpl:setApplicationPriority(org.apache.hadoop.yarn.api.records.Priority)
org.apache.hadoop.yarn.api.protocolrecords.impl.pb.ReleaseSharedCacheResourceRequestPBImpl	setAppId	applicationId	C	org.apache.hadoop.yarn.api.records.ApplicationId	0	org.apache.hadoop.yarn.api.protocolrecords.impl.pb.ReleaseSharedCacheResourceRequestPBImpl:setAppId(org.apache.hadoop.yarn.api.records.ApplicationId)
org.apache.hadoop.yarn.api.protocolrecords.impl.pb.GetContainerReportResponsePBImpl	setContainerReport	containerReport	C	org.apache.hadoop.yarn.api.records.ContainerReport	0	org.apache.hadoop.yarn.api.protocolrecords.impl.pb.GetContainerReportResponsePBImpl:setContainerReport(org.apache.hadoop.yarn.api.records.ContainerReport)
org.apache.hadoop.yarn.api.protocolrecords.impl.pb.GetNewReservationResponsePBImpl	setReservationId	reservationId	C	org.apache.hadoop.yarn.api.records.ReservationId	0	org.apache.hadoop.yarn.api.protocolrecords.impl.pb.GetNewReservationResponsePBImpl:setReservationId(org.apache.hadoop.yarn.api.records.ReservationId)
org.apache.hadoop.yarn.api.protocolrecords.impl.pb.IncreaseContainersResourceResponsePBImpl	setSuccessfullyIncreasedContainers	succeededRequests	GC	java.util.List	0	org.apache.hadoop.yarn.api.protocolrecords.impl.pb.IncreaseContainersResourceResponsePBImpl:setSuccessfullyIncreasedContainers(java.util.List)
org.apache.hadoop.yarn.api.protocolrecords.impl.pb.IncreaseContainersResourceResponsePBImpl	setFailedRequests	failedRequests	GC	java.util.Map	0	org.apache.hadoop.yarn.api.protocolrecords.impl.pb.IncreaseContainersResourceResponsePBImpl:setFailedRequests(java.util.Map)
org.apache.hadoop.yarn.api.protocolrecords.impl.pb.ReservationDeleteRequestPBImpl	setReservationId	reservationId	C	org.apache.hadoop.yarn.api.records.ReservationId	0	org.apache.hadoop.yarn.api.protocolrecords.impl.pb.ReservationDeleteRequestPBImpl:setReservationId(org.apache.hadoop.yarn.api.records.ReservationId)
org.apache.hadoop.yarn.api.protocolrecords.impl.pb.MoveApplicationAcrossQueuesRequestPBImpl	setApplicationId	applicationId	C	org.apache.hadoop.yarn.api.records.ApplicationId	0	org.apache.hadoop.yarn.api.protocolrecords.impl.pb.MoveApplicationAcrossQueuesRequestPBImpl:setApplicationId(org.apache.hadoop.yarn.api.records.ApplicationId)
org.apache.hadoop.yarn.api.protocolrecords.impl.pb.MoveApplicationAcrossQueuesRequestPBImpl	setTargetQueue	targetQueue	J	java.lang.String	0	org.apache.hadoop.yarn.api.protocolrecords.impl.pb.MoveApplicationAcrossQueuesRequestPBImpl:setTargetQueue(java.lang.String)
org.apache.hadoop.yarn.api.protocolrecords.impl.pb.UpdateApplicationPriorityRequestPBImpl	setApplicationPriority	applicationPriority	C	org.apache.hadoop.yarn.api.records.Priority	0	org.apache.hadoop.yarn.api.protocolrecords.impl.pb.UpdateApplicationPriorityRequestPBImpl:setApplicationPriority(org.apache.hadoop.yarn.api.records.Priority)
org.apache.hadoop.yarn.api.protocolrecords.impl.pb.UpdateApplicationPriorityRequestPBImpl	setApplicationId	applicationId	C	org.apache.hadoop.yarn.api.records.ApplicationId	0	org.apache.hadoop.yarn.api.protocolrecords.impl.pb.UpdateApplicationPriorityRequestPBImpl:setApplicationId(org.apache.hadoop.yarn.api.records.ApplicationId)
org.apache.hadoop.yarn.api.protocolrecords.impl.pb.GetLocalizationStatusesRequestPBImpl	setContainerIds	containerIds	GC	java.util.List	0	org.apache.hadoop.yarn.api.protocolrecords.impl.pb.GetLocalizationStatusesRequestPBImpl:setContainerIds(java.util.List)
org.apache.hadoop.yarn.api.protocolrecords.impl.pb.GetApplicationAttemptReportRequestPBImpl	setApplicationAttemptId	applicationAttemptId	C	org.apache.hadoop.yarn.api.records.ApplicationAttemptId	0	org.apache.hadoop.yarn.api.protocolrecords.impl.pb.GetApplicationAttemptReportRequestPBImpl:setApplicationAttemptId(org.apache.hadoop.yarn.api.records.ApplicationAttemptId)
org.apache.hadoop.yarn.api.protocolrecords.impl.pb.GetContainerReportRequestPBImpl	setContainerId	containerId	C	org.apache.hadoop.yarn.api.records.ContainerId	0	org.apache.hadoop.yarn.api.protocolrecords.impl.pb.GetContainerReportRequestPBImpl:setContainerId(org.apache.hadoop.yarn.api.records.ContainerId)
org.apache.hadoop.yarn.api.protocolrecords.impl.pb.ReservationSubmissionRequestPBImpl	setReservationDefinition	reservationDefinition	C	org.apache.hadoop.yarn.api.records.ReservationDefinition	0	org.apache.hadoop.yarn.api.protocolrecords.impl.pb.ReservationSubmissionRequestPBImpl:setReservationDefinition(org.apache.hadoop.yarn.api.records.ReservationDefinition)
org.apache.hadoop.yarn.api.protocolrecords.impl.pb.ResourceLocalizationRequestPBImpl	setContainerId	containerId	C	org.apache.hadoop.yarn.api.records.ContainerId	0	org.apache.hadoop.yarn.api.protocolrecords.impl.pb.ResourceLocalizationRequestPBImpl:setContainerId(org.apache.hadoop.yarn.api.records.ContainerId)
org.apache.hadoop.yarn.api.protocolrecords.impl.pb.ResourceLocalizationRequestPBImpl	setLocalResources	localResources	GC	java.util.Map	0	org.apache.hadoop.yarn.api.protocolrecords.impl.pb.ResourceLocalizationRequestPBImpl:setLocalResources(java.util.Map)
org.apache.hadoop.yarn.api.protocolrecords.impl.pb.FailApplicationAttemptRequestPBImpl	setApplicationAttemptId	applicationAttemptId	C	org.apache.hadoop.yarn.api.records.ApplicationAttemptId	0	org.apache.hadoop.yarn.api.protocolrecords.impl.pb.FailApplicationAttemptRequestPBImpl:setApplicationAttemptId(org.apache.hadoop.yarn.api.records.ApplicationAttemptId)
org.apache.hadoop.yarn.api.protocolrecords.impl.pb.RegisterApplicationMasterRequestPBImpl	setPlacementConstraints	placementConstraints	GC	java.util.Map	0	org.apache.hadoop.yarn.api.protocolrecords.impl.pb.RegisterApplicationMasterRequestPBImpl:setPlacementConstraints(java.util.Map)
org.apache.hadoop.yarn.api.protocolrecords.impl.pb.UpdateApplicationTimeoutsRequestPBImpl	setApplicationId	applicationId	C	org.apache.hadoop.yarn.api.records.ApplicationId	0	org.apache.hadoop.yarn.api.protocolrecords.impl.pb.UpdateApplicationTimeoutsRequestPBImpl:setApplicationId(org.apache.hadoop.yarn.api.records.ApplicationId)
org.apache.hadoop.yarn.api.protocolrecords.impl.pb.GetContainersRequestPBImpl	setApplicationAttemptId	applicationAttemptId	C	org.apache.hadoop.yarn.api.records.ApplicationAttemptId	0	org.apache.hadoop.yarn.api.protocolrecords.impl.pb.GetContainersRequestPBImpl:setApplicationAttemptId(org.apache.hadoop.yarn.api.records.ApplicationAttemptId)
org.apache.hadoop.yarn.api.protocolrecords.impl.pb.GetContainerStatusesRequestPBImpl	setContainerIds	containerIds	GC	java.util.List	0	org.apache.hadoop.yarn.api.protocolrecords.impl.pb.GetContainerStatusesRequestPBImpl:setContainerIds(java.util.List)
org.apache.hadoop.yarn.api.protocolrecords.impl.pb.ContainerUpdateRequestPBImpl	setContainersToUpdate	containersToUpdate	GC	java.util.List	0	org.apache.hadoop.yarn.api.protocolrecords.impl.pb.ContainerUpdateRequestPBImpl:setContainersToUpdate(java.util.List)
org.apache.hadoop.yarn.api.protocolrecords.impl.pb.RenewDelegationTokenRequestPBImpl	setDelegationToken	token	C	org.apache.hadoop.yarn.api.records.Token	0	org.apache.hadoop.yarn.api.protocolrecords.impl.pb.RenewDelegationTokenRequestPBImpl:setDelegationToken(org.apache.hadoop.yarn.api.records.Token)
org.apache.hadoop.yarn.api.protocolrecords.impl.pb.IncreaseContainersResourceRequestPBImpl	setContainersToIncrease	containersToIncrease	GC	java.util.List	0	org.apache.hadoop.yarn.api.protocolrecords.impl.pb.IncreaseContainersResourceRequestPBImpl:setContainersToIncrease(java.util.List)
org.apache.hadoop.yarn.api.protocolrecords.impl.pb.GetDelegationTokenRequestPBImpl	setRenewer	renewer	J	java.lang.String	0	org.apache.hadoop.yarn.api.protocolrecords.impl.pb.GetDelegationTokenRequestPBImpl:setRenewer(java.lang.String)
org.apache.hadoop.yarn.api.protocolrecords.impl.pb.GetResourceProfileResponsePBImpl	setResource	resource	C	org.apache.hadoop.yarn.api.records.Resource	0	org.apache.hadoop.yarn.api.protocolrecords.impl.pb.GetResourceProfileResponsePBImpl:setResource(org.apache.hadoop.yarn.api.records.Resource)
org.apache.hadoop.yarn.api.protocolrecords.impl.pb.GetClusterMetricsResponsePBImpl	setClusterMetrics	yarnClusterMetrics	C	org.apache.hadoop.yarn.api.records.YarnClusterMetrics	0	org.apache.hadoop.yarn.api.protocolrecords.impl.pb.GetClusterMetricsResponsePBImpl:setClusterMetrics(org.apache.hadoop.yarn.api.records.YarnClusterMetrics)
org.apache.hadoop.yarn.api.protocolrecords.impl.pb.GetApplicationAttemptsRequestPBImpl	setApplicationId	applicationId	C	org.apache.hadoop.yarn.api.records.ApplicationId	0	org.apache.hadoop.yarn.api.protocolrecords.impl.pb.GetApplicationAttemptsRequestPBImpl:setApplicationId(org.apache.hadoop.yarn.api.records.ApplicationId)
org.apache.hadoop.yarn.api.protocolrecords.impl.pb.AllocateRequestPBImpl	setResourceBlacklistRequest	blacklistRequest	C	org.apache.hadoop.yarn.api.records.ResourceBlacklistRequest	0	org.apache.hadoop.yarn.api.protocolrecords.impl.pb.AllocateRequestPBImpl:setResourceBlacklistRequest(org.apache.hadoop.yarn.api.records.ResourceBlacklistRequest)
org.apache.hadoop.yarn.api.protocolrecords.impl.pb.AllocateRequestPBImpl	setTrackingUrl	trackingUrl	J	java.lang.String	0	org.apache.hadoop.yarn.api.protocolrecords.impl.pb.AllocateRequestPBImpl:setTrackingUrl(java.lang.String)
org.apache.hadoop.yarn.api.protocolrecords.impl.pb.GetApplicationsRequestPBImpl	setApplicationTypes	applicationTypes	GJ	java.util.Set	0	org.apache.hadoop.yarn.api.protocolrecords.impl.pb.GetApplicationsRequestPBImpl:setApplicationTypes(java.util.Set)
org.apache.hadoop.yarn.api.protocolrecords.impl.pb.GetApplicationsRequestPBImpl	setScope	scope	C	org.apache.hadoop.yarn.api.protocolrecords.ApplicationsRequestScope	0	org.apache.hadoop.yarn.api.protocolrecords.impl.pb.GetApplicationsRequestPBImpl:setScope(org.apache.hadoop.yarn.api.protocolrecords.ApplicationsRequestScope)
org.apache.hadoop.yarn.api.protocolrecords.impl.pb.GetApplicationsRequestPBImpl	setApplicationStates	applicationStates	GC	java.util.EnumSet	0	org.apache.hadoop.yarn.api.protocolrecords.impl.pb.GetApplicationsRequestPBImpl:setApplicationStates(java.util.EnumSet)
org.apache.hadoop.yarn.api.protocolrecords.impl.pb.GetApplicationsRequestPBImpl	setUsers	users	GJ	java.util.Set	0	org.apache.hadoop.yarn.api.protocolrecords.impl.pb.GetApplicationsRequestPBImpl:setUsers(java.util.Set)
org.apache.hadoop.yarn.api.protocolrecords.impl.pb.GetApplicationsRequestPBImpl	setQueues	queues	GJ	java.util.Set	0	org.apache.hadoop.yarn.api.protocolrecords.impl.pb.GetApplicationsRequestPBImpl:setQueues(java.util.Set)
org.apache.hadoop.yarn.api.protocolrecords.impl.pb.GetApplicationsRequestPBImpl	setLimit	limit	J	long	0	org.apache.hadoop.yarn.api.protocolrecords.impl.pb.GetApplicationsRequestPBImpl:setLimit(long)
org.apache.hadoop.yarn.api.protocolrecords.impl.pb.GetApplicationsRequestPBImpl	setStartRange	start	GJ	org.apache.commons.lang3.Range	0	org.apache.hadoop.yarn.api.protocolrecords.impl.pb.GetApplicationsRequestPBImpl:setStartRange(org.apache.commons.lang3.Range)
org.apache.hadoop.yarn.api.protocolrecords.impl.pb.GetApplicationsRequestPBImpl	setFinishRange	finish	GJ	org.apache.commons.lang3.Range	0	org.apache.hadoop.yarn.api.protocolrecords.impl.pb.GetApplicationsRequestPBImpl:setFinishRange(org.apache.commons.lang3.Range)
org.apache.hadoop.yarn.api.protocolrecords.impl.pb.GetApplicationsRequestPBImpl	setName	name	J	java.lang.String	0	org.apache.hadoop.yarn.api.protocolrecords.impl.pb.GetApplicationsRequestPBImpl:setName(java.lang.String)
org.apache.hadoop.yarn.api.protocolrecords.impl.pb.ReservationListResponsePBImpl	setReservationAllocationState	reservations	GC	java.util.List	0	org.apache.hadoop.yarn.api.protocolrecords.impl.pb.ReservationListResponsePBImpl:setReservationAllocationState(java.util.List)
org.apache.hadoop.yarn.api.protocolrecords.impl.pb.SignalContainerRequestPBImpl	setContainerId	containerId	C	org.apache.hadoop.yarn.api.records.ContainerId	0	org.apache.hadoop.yarn.api.protocolrecords.impl.pb.SignalContainerRequestPBImpl:setContainerId(org.apache.hadoop.yarn.api.records.ContainerId)
org.apache.hadoop.yarn.api.protocolrecords.impl.pb.SignalContainerRequestPBImpl	setCommand	command	C	org.apache.hadoop.yarn.api.records.SignalContainerCommand	0	org.apache.hadoop.yarn.api.protocolrecords.impl.pb.SignalContainerRequestPBImpl:setCommand(org.apache.hadoop.yarn.api.records.SignalContainerCommand)
org.apache.hadoop.yarn.api.protocolrecords.impl.pb.UpdateApplicationPriorityResponsePBImpl	setApplicationPriority	updatedAppPriority	C	org.apache.hadoop.yarn.api.records.Priority	0	org.apache.hadoop.yarn.api.protocolrecords.impl.pb.UpdateApplicationPriorityResponsePBImpl:setApplicationPriority(org.apache.hadoop.yarn.api.records.Priority)
org.apache.hadoop.yarn.api.protocolrecords.impl.pb.GetApplicationReportResponsePBImpl	setApplicationReport	applicationReport	C	org.apache.hadoop.yarn.api.records.ApplicationReport	0	org.apache.hadoop.yarn.api.protocolrecords.impl.pb.GetApplicationReportResponsePBImpl:setApplicationReport(org.apache.hadoop.yarn.api.records.ApplicationReport)
org.apache.hadoop.yarn.api.protocolrecords.impl.pb.UseSharedCacheResourceRequestPBImpl	setAppId	applicationId	C	org.apache.hadoop.yarn.api.records.ApplicationId	0	org.apache.hadoop.yarn.api.protocolrecords.impl.pb.UseSharedCacheResourceRequestPBImpl:setAppId(org.apache.hadoop.yarn.api.records.ApplicationId)
org.apache.hadoop.yarn.api.protocolrecords.impl.pb.ReservationUpdateRequestPBImpl	setReservationDefinition	reservationDefinition	C	org.apache.hadoop.yarn.api.records.ReservationDefinition	0	org.apache.hadoop.yarn.api.protocolrecords.impl.pb.ReservationUpdateRequestPBImpl:setReservationDefinition(org.apache.hadoop.yarn.api.records.ReservationDefinition)
org.apache.hadoop.yarn.api.protocolrecords.impl.pb.ReservationUpdateRequestPBImpl	setReservationId	reservationId	C	org.apache.hadoop.yarn.api.records.ReservationId	0	org.apache.hadoop.yarn.api.protocolrecords.impl.pb.ReservationUpdateRequestPBImpl:setReservationId(org.apache.hadoop.yarn.api.records.ReservationId)
org.apache.hadoop.yarn.api.protocolrecords.impl.pb.KillApplicationRequestPBImpl	setApplicationId	applicationId	C	org.apache.hadoop.yarn.api.records.ApplicationId	0	org.apache.hadoop.yarn.api.protocolrecords.impl.pb.KillApplicationRequestPBImpl:setApplicationId(org.apache.hadoop.yarn.api.records.ApplicationId)
org.apache.hadoop.yarn.api.protocolrecords.impl.pb.GetLocalizationStatusesResponsePBImpl	setLocalizationStatuses	localizationStatuses	GC	java.util.Map	0	org.apache.hadoop.yarn.api.protocolrecords.impl.pb.GetLocalizationStatusesResponsePBImpl:setLocalizationStatuses(java.util.Map)
org.apache.hadoop.yarn.api.protocolrecords.impl.pb.GetLocalizationStatusesResponsePBImpl	setFailedRequests	failedRequests	GC	java.util.Map	0	org.apache.hadoop.yarn.api.protocolrecords.impl.pb.GetLocalizationStatusesResponsePBImpl:setFailedRequests(java.util.Map)
org.apache.hadoop.yarn.api.protocolrecords.impl.pb.ContainerUpdateResponsePBImpl	setSuccessfullyUpdatedContainers	succeededRequests	GC	java.util.List	0	org.apache.hadoop.yarn.api.protocolrecords.impl.pb.ContainerUpdateResponsePBImpl:setSuccessfullyUpdatedContainers(java.util.List)
org.apache.hadoop.yarn.api.protocolrecords.impl.pb.ContainerUpdateResponsePBImpl	setFailedRequests	failedRequests	GC	java.util.Map	0	org.apache.hadoop.yarn.api.protocolrecords.impl.pb.ContainerUpdateResponsePBImpl:setFailedRequests(java.util.Map)
org.apache.hadoop.yarn.api.protocolrecords.impl.pb.GetQueueUserAclsInfoResponsePBImpl	setUserAclsInfoList	queueUserAclsInfoList	GC	java.util.List	0	org.apache.hadoop.yarn.api.protocolrecords.impl.pb.GetQueueUserAclsInfoResponsePBImpl:setUserAclsInfoList(java.util.List)
org.apache.hadoop.yarn.api.protocolrecords.impl.pb.GetApplicationsResponsePBImpl	setApplicationList	applicationList	GC	java.util.List	0	org.apache.hadoop.yarn.api.protocolrecords.impl.pb.GetApplicationsResponsePBImpl:setApplicationList(java.util.List)
org.apache.hadoop.yarn.api.protocolrecords.impl.pb.ReInitializeContainerRequestPBImpl	setContainerId	containerId	C	org.apache.hadoop.yarn.api.records.ContainerId	0	org.apache.hadoop.yarn.api.protocolrecords.impl.pb.ReInitializeContainerRequestPBImpl:setContainerId(org.apache.hadoop.yarn.api.records.ContainerId)
org.apache.hadoop.yarn.api.protocolrecords.impl.pb.ReInitializeContainerRequestPBImpl	setContainerLaunchContext	containerLaunchContext	C	org.apache.hadoop.yarn.api.records.ContainerLaunchContext	0	org.apache.hadoop.yarn.api.protocolrecords.impl.pb.ReInitializeContainerRequestPBImpl:setContainerLaunchContext(org.apache.hadoop.yarn.api.records.ContainerLaunchContext)
org.apache.hadoop.yarn.api.protocolrecords.impl.pb.StopContainersResponsePBImpl	setSuccessfullyStoppedContainers	succeededRequests	GC	java.util.List	0	org.apache.hadoop.yarn.api.protocolrecords.impl.pb.StopContainersResponsePBImpl:setSuccessfullyStoppedContainers(java.util.List)
org.apache.hadoop.yarn.api.protocolrecords.impl.pb.StopContainersResponsePBImpl	setFailedRequests	failedRequests	GC	java.util.Map	0	org.apache.hadoop.yarn.api.protocolrecords.impl.pb.StopContainersResponsePBImpl:setFailedRequests(java.util.Map)
org.apache.hadoop.yarn.api.protocolrecords.impl.pb.GetAttributesToNodesRequestPBImpl	setNodeAttributes	nodeAttributes	GC	java.util.Set	0	org.apache.hadoop.yarn.api.protocolrecords.impl.pb.GetAttributesToNodesRequestPBImpl:setNodeAttributes(java.util.Set)
org.apache.hadoop.yarn.api.protocolrecords.impl.pb.GetDelegationTokenResponsePBImpl	setRMDelegationToken	appToken	C	org.apache.hadoop.yarn.api.records.Token	0	org.apache.hadoop.yarn.api.protocolrecords.impl.pb.GetDelegationTokenResponsePBImpl:setRMDelegationToken(org.apache.hadoop.yarn.api.records.Token)
org.apache.hadoop.yarn.api.protocolrecords.impl.pb.CancelDelegationTokenRequestPBImpl	setDelegationToken	token	C	org.apache.hadoop.yarn.api.records.Token	0	org.apache.hadoop.yarn.api.protocolrecords.impl.pb.CancelDelegationTokenRequestPBImpl:setDelegationToken(org.apache.hadoop.yarn.api.records.Token)
org.apache.hadoop.yarn.api.protocolrecords.impl.pb.GetContainersResponsePBImpl	setContainerList	containerList	GC	java.util.List	0	org.apache.hadoop.yarn.api.protocolrecords.impl.pb.GetContainersResponsePBImpl:setContainerList(java.util.List)
org.apache.hadoop.yarn.api.protocolrecords.impl.pb.GetQueueInfoResponsePBImpl	setQueueInfo	queueInfo	C	org.apache.hadoop.yarn.api.records.QueueInfo	0	org.apache.hadoop.yarn.api.protocolrecords.impl.pb.GetQueueInfoResponsePBImpl:setQueueInfo(org.apache.hadoop.yarn.api.records.QueueInfo)
org.apache.hadoop.yarn.api.protocolrecords.impl.pb.GetApplicationAttemptsResponsePBImpl	setApplicationAttemptList	applicationAttemptList	GC	java.util.List	0	org.apache.hadoop.yarn.api.protocolrecords.impl.pb.GetApplicationAttemptsResponsePBImpl:setApplicationAttemptList(java.util.List)
org.apache.hadoop.yarn.api.protocolrecords.impl.pb.GetApplicationReportRequestPBImpl	setApplicationId	applicationId	C	org.apache.hadoop.yarn.api.records.ApplicationId	0	org.apache.hadoop.yarn.api.protocolrecords.impl.pb.GetApplicationReportRequestPBImpl:setApplicationId(org.apache.hadoop.yarn.api.records.ApplicationId)
org.apache.hadoop.yarn.api.records.impl.pb.QueueUserACLInfoPBImpl	setUserAcls	userAclsList	GC	java.util.List	0	org.apache.hadoop.yarn.api.records.impl.pb.QueueUserACLInfoPBImpl:setUserAcls(java.util.List)
org.apache.hadoop.yarn.api.records.impl.pb.PreemptionContractPBImpl	setContainers	containers	GC	java.util.Set	0	org.apache.hadoop.yarn.api.records.impl.pb.PreemptionContractPBImpl:setContainers(java.util.Set)
org.apache.hadoop.yarn.api.records.impl.pb.PreemptionContractPBImpl	setResourceRequest	resources	GC	java.util.List	0	org.apache.hadoop.yarn.api.records.impl.pb.PreemptionContractPBImpl:setResourceRequest(java.util.List)
org.apache.hadoop.yarn.api.records.impl.pb.LocalizationStatusPBImpl	setResourceKey	resourceKey	J	java.lang.String	0	org.apache.hadoop.yarn.api.records.impl.pb.LocalizationStatusPBImpl:setResourceKey(java.lang.String)
org.apache.hadoop.yarn.api.records.impl.pb.LocalizationStatusPBImpl	setLocalizationState	localizationState	C	org.apache.hadoop.yarn.api.records.LocalizationState	0	org.apache.hadoop.yarn.api.records.impl.pb.LocalizationStatusPBImpl:setLocalizationState(org.apache.hadoop.yarn.api.records.LocalizationState)
org.apache.hadoop.yarn.api.records.impl.pb.LocalizationStatusPBImpl	setDiagnostics	diagnostics	J	java.lang.String	0	org.apache.hadoop.yarn.api.records.impl.pb.LocalizationStatusPBImpl:setDiagnostics(java.lang.String)
org.apache.hadoop.yarn.api.records.impl.pb.CollectorInfoPBImpl	setCollectorAddr	collectorAddr	J	java.lang.String	0	org.apache.hadoop.yarn.api.records.impl.pb.CollectorInfoPBImpl:setCollectorAddr(java.lang.String)
org.apache.hadoop.yarn.api.records.impl.pb.CollectorInfoPBImpl	setCollectorToken	collectorToken	C	org.apache.hadoop.yarn.api.records.Token	0	org.apache.hadoop.yarn.api.records.impl.pb.CollectorInfoPBImpl:setCollectorToken(org.apache.hadoop.yarn.api.records.Token)
org.apache.hadoop.yarn.api.records.impl.pb.PreemptionResourceRequestPBImpl	setResourceRequest	rr	C	org.apache.hadoop.yarn.api.records.ResourceRequest	0	org.apache.hadoop.yarn.api.records.impl.pb.PreemptionResourceRequestPBImpl:setResourceRequest(org.apache.hadoop.yarn.api.records.ResourceRequest)
org.apache.hadoop.yarn.api.records.impl.pb.StrictPreemptionContractPBImpl	setContainers	containers	GC	java.util.Set	0	org.apache.hadoop.yarn.api.records.impl.pb.StrictPreemptionContractPBImpl:setContainers(java.util.Set)
org.apache.hadoop.yarn.api.records.impl.pb.ApplicationAttemptIdPBImpl	setApplicationId	applicationId	C	org.apache.hadoop.yarn.api.records.ApplicationId	0	org.apache.hadoop.yarn.api.records.impl.pb.ApplicationAttemptIdPBImpl:setApplicationId(org.apache.hadoop.yarn.api.records.ApplicationId)
org.apache.hadoop.yarn.api.records.impl.pb.TokenPBImpl	setIdentifier	identifier	J	java.nio.ByteBuffer	0	org.apache.hadoop.yarn.api.records.impl.pb.TokenPBImpl:setIdentifier(java.nio.ByteBuffer)
org.apache.hadoop.yarn.api.records.impl.pb.TokenPBImpl	setPassword	password	J	java.nio.ByteBuffer	0	org.apache.hadoop.yarn.api.records.impl.pb.TokenPBImpl:setPassword(java.nio.ByteBuffer)
org.apache.hadoop.yarn.api.records.impl.pb.ResourceAllocationRequestPBImpl	setCapability	capability	C	org.apache.hadoop.yarn.api.records.Resource	0	org.apache.hadoop.yarn.api.records.impl.pb.ResourceAllocationRequestPBImpl:setCapability(org.apache.hadoop.yarn.api.records.Resource)
org.apache.hadoop.yarn.api.records.impl.pb.ContainerStatusPBImpl	setContainerId	containerId	C	org.apache.hadoop.yarn.api.records.ContainerId	0	org.apache.hadoop.yarn.api.records.impl.pb.ContainerStatusPBImpl:setContainerId(org.apache.hadoop.yarn.api.records.ContainerId)
org.apache.hadoop.yarn.api.records.impl.pb.UpdatedContainerPBImpl	setContainer	container	C	org.apache.hadoop.yarn.api.records.Container	0	org.apache.hadoop.yarn.api.records.impl.pb.UpdatedContainerPBImpl:setContainer(org.apache.hadoop.yarn.api.records.Container)
org.apache.hadoop.yarn.api.records.impl.pb.ApplicationReportPBImpl	setApplicationId	applicationId	C	org.apache.hadoop.yarn.api.records.ApplicationId	0	org.apache.hadoop.yarn.api.records.impl.pb.ApplicationReportPBImpl:setApplicationId(org.apache.hadoop.yarn.api.records.ApplicationId)
org.apache.hadoop.yarn.api.records.impl.pb.ApplicationReportPBImpl	setCurrentApplicationAttemptId	currentApplicationAttemptId	C	org.apache.hadoop.yarn.api.records.ApplicationAttemptId	0	org.apache.hadoop.yarn.api.records.impl.pb.ApplicationReportPBImpl:setCurrentApplicationAttemptId(org.apache.hadoop.yarn.api.records.ApplicationAttemptId)
org.apache.hadoop.yarn.api.records.impl.pb.ApplicationReportPBImpl	setClientToAMToken	clientToAMToken	C	org.apache.hadoop.yarn.api.records.Token	0	org.apache.hadoop.yarn.api.records.impl.pb.ApplicationReportPBImpl:setClientToAMToken(org.apache.hadoop.yarn.api.records.Token)
org.apache.hadoop.yarn.api.records.impl.pb.ApplicationReportPBImpl	setApplicationTags	applicationTags	GJ	java.util.Set	0	org.apache.hadoop.yarn.api.records.impl.pb.ApplicationReportPBImpl:setApplicationTags(java.util.Set)
org.apache.hadoop.yarn.api.records.impl.pb.ApplicationReportPBImpl	setAMRMToken	amRmToken	C	org.apache.hadoop.yarn.api.records.Token	0	org.apache.hadoop.yarn.api.records.impl.pb.ApplicationReportPBImpl:setAMRMToken(org.apache.hadoop.yarn.api.records.Token)
org.apache.hadoop.yarn.api.records.impl.pb.ApplicationReportPBImpl	setPriority	priority	C	org.apache.hadoop.yarn.api.records.Priority	0	org.apache.hadoop.yarn.api.records.impl.pb.ApplicationReportPBImpl:setPriority(org.apache.hadoop.yarn.api.records.Priority)
org.apache.hadoop.yarn.api.records.impl.pb.ResourceSizingPBImpl	setResources	resources	C	org.apache.hadoop.yarn.api.records.Resource	0	org.apache.hadoop.yarn.api.records.impl.pb.ResourceSizingPBImpl:setResources(org.apache.hadoop.yarn.api.records.Resource)
org.apache.hadoop.yarn.api.records.impl.pb.UpdateContainerErrorPBImpl	setReason	reason	J	java.lang.String	0	org.apache.hadoop.yarn.api.records.impl.pb.UpdateContainerErrorPBImpl:setReason(java.lang.String)
org.apache.hadoop.yarn.api.records.impl.pb.UpdateContainerErrorPBImpl	setUpdateContainerRequest	updateRequest	C	org.apache.hadoop.yarn.api.records.UpdateContainerRequest	0	org.apache.hadoop.yarn.api.records.impl.pb.UpdateContainerErrorPBImpl:setUpdateContainerRequest(org.apache.hadoop.yarn.api.records.UpdateContainerRequest)
org.apache.hadoop.yarn.api.records.impl.pb.NodeReportPBImpl	setNodeId	nodeId	C	org.apache.hadoop.yarn.api.records.NodeId	0	org.apache.hadoop.yarn.api.records.impl.pb.NodeReportPBImpl:setNodeId(org.apache.hadoop.yarn.api.records.NodeId)
org.apache.hadoop.yarn.api.records.impl.pb.NodeReportPBImpl	setCapability	capability	C	org.apache.hadoop.yarn.api.records.Resource	0	org.apache.hadoop.yarn.api.records.impl.pb.NodeReportPBImpl:setCapability(org.apache.hadoop.yarn.api.records.Resource)
org.apache.hadoop.yarn.api.records.impl.pb.NodeReportPBImpl	setUsed	used	C	org.apache.hadoop.yarn.api.records.Resource	0	org.apache.hadoop.yarn.api.records.impl.pb.NodeReportPBImpl:setUsed(org.apache.hadoop.yarn.api.records.Resource)
org.apache.hadoop.yarn.api.records.impl.pb.NodeReportPBImpl	setNodeLabels	labels	GJ	java.util.Set	0	org.apache.hadoop.yarn.api.records.impl.pb.NodeReportPBImpl:setNodeLabels(java.util.Set)
org.apache.hadoop.yarn.api.records.impl.pb.NodeReportPBImpl	setAggregatedContainersUtilization	containersUtilization	C	org.apache.hadoop.yarn.api.records.ResourceUtilization	0	org.apache.hadoop.yarn.api.records.impl.pb.NodeReportPBImpl:setAggregatedContainersUtilization(org.apache.hadoop.yarn.api.records.ResourceUtilization)
org.apache.hadoop.yarn.api.records.impl.pb.NodeReportPBImpl	setNodeUtilization	nodeUtilization	C	org.apache.hadoop.yarn.api.records.ResourceUtilization	0	org.apache.hadoop.yarn.api.records.impl.pb.NodeReportPBImpl:setNodeUtilization(org.apache.hadoop.yarn.api.records.ResourceUtilization)
org.apache.hadoop.yarn.api.records.impl.pb.NodeReportPBImpl	setNodeAttributes	nodeAttributes	GC	java.util.Set	0	org.apache.hadoop.yarn.api.records.impl.pb.NodeReportPBImpl:setNodeAttributes(java.util.Set)
org.apache.hadoop.yarn.api.records.impl.pb.ContainerRetryContextPBImpl	setErrorCodes	errorCodes	GJ	java.util.Set	0	org.apache.hadoop.yarn.api.records.impl.pb.ContainerRetryContextPBImpl:setErrorCodes(java.util.Set)
org.apache.hadoop.yarn.api.records.impl.pb.SchedulingRequestPBImpl	setPriority	priority	C	org.apache.hadoop.yarn.api.records.Priority	0	org.apache.hadoop.yarn.api.records.impl.pb.SchedulingRequestPBImpl:setPriority(org.apache.hadoop.yarn.api.records.Priority)
org.apache.hadoop.yarn.api.records.impl.pb.SchedulingRequestPBImpl	setExecutionType	executionType	C	org.apache.hadoop.yarn.api.records.ExecutionTypeRequest	0	org.apache.hadoop.yarn.api.records.impl.pb.SchedulingRequestPBImpl:setExecutionType(org.apache.hadoop.yarn.api.records.ExecutionTypeRequest)
org.apache.hadoop.yarn.api.records.impl.pb.SchedulingRequestPBImpl	setAllocationTags	allocationTags	GJ	java.util.Set	0	org.apache.hadoop.yarn.api.records.impl.pb.SchedulingRequestPBImpl:setAllocationTags(java.util.Set)
org.apache.hadoop.yarn.api.records.impl.pb.SchedulingRequestPBImpl	setResourceSizing	resourceSizing	C	org.apache.hadoop.yarn.api.records.ResourceSizing	0	org.apache.hadoop.yarn.api.records.impl.pb.SchedulingRequestPBImpl:setResourceSizing(org.apache.hadoop.yarn.api.records.ResourceSizing)
org.apache.hadoop.yarn.api.records.impl.pb.SchedulingRequestPBImpl	setPlacementConstraint	placementConstraint	C	org.apache.hadoop.yarn.api.resource.PlacementConstraint	0	org.apache.hadoop.yarn.api.records.impl.pb.SchedulingRequestPBImpl:setPlacementConstraint(org.apache.hadoop.yarn.api.resource.PlacementConstraint)
org.apache.hadoop.yarn.api.records.impl.pb.ResourceRequestPBImpl	setPriority	priority	C	org.apache.hadoop.yarn.api.records.Priority	0	org.apache.hadoop.yarn.api.records.impl.pb.ResourceRequestPBImpl:setPriority(org.apache.hadoop.yarn.api.records.Priority)
org.apache.hadoop.yarn.api.records.impl.pb.ResourceRequestPBImpl	setExecutionTypeRequest	executionTypeRequest	C	org.apache.hadoop.yarn.api.records.ExecutionTypeRequest	0	org.apache.hadoop.yarn.api.records.impl.pb.ResourceRequestPBImpl:setExecutionTypeRequest(org.apache.hadoop.yarn.api.records.ExecutionTypeRequest)
org.apache.hadoop.yarn.api.records.impl.pb.ResourceRequestPBImpl	setCapability	capability	C	org.apache.hadoop.yarn.api.records.Resource	0	org.apache.hadoop.yarn.api.records.impl.pb.ResourceRequestPBImpl:setCapability(org.apache.hadoop.yarn.api.records.Resource)
org.apache.hadoop.yarn.api.records.impl.pb.ContainerPBImpl	setNodeId	nodeId	C	org.apache.hadoop.yarn.api.records.NodeId	0	org.apache.hadoop.yarn.api.records.impl.pb.ContainerPBImpl:setNodeId(org.apache.hadoop.yarn.api.records.NodeId)
org.apache.hadoop.yarn.api.records.impl.pb.ContainerPBImpl	setId	containerId	C	org.apache.hadoop.yarn.api.records.ContainerId	0	org.apache.hadoop.yarn.api.records.impl.pb.ContainerPBImpl:setId(org.apache.hadoop.yarn.api.records.ContainerId)
org.apache.hadoop.yarn.api.records.impl.pb.ContainerPBImpl	setResource	resource	C	org.apache.hadoop.yarn.api.records.Resource	0	org.apache.hadoop.yarn.api.records.impl.pb.ContainerPBImpl:setResource(org.apache.hadoop.yarn.api.records.Resource)
org.apache.hadoop.yarn.api.records.impl.pb.ContainerPBImpl	setExposedPorts	exposedPorts	GJ	java.util.Map	0	org.apache.hadoop.yarn.api.records.impl.pb.ContainerPBImpl:setExposedPorts(java.util.Map)
org.apache.hadoop.yarn.api.records.impl.pb.ContainerPBImpl	setPriority	priority	C	org.apache.hadoop.yarn.api.records.Priority	0	org.apache.hadoop.yarn.api.records.impl.pb.ContainerPBImpl:setPriority(org.apache.hadoop.yarn.api.records.Priority)
org.apache.hadoop.yarn.api.records.impl.pb.ContainerPBImpl	setContainerToken	containerToken	C	org.apache.hadoop.yarn.api.records.Token	0	org.apache.hadoop.yarn.api.records.impl.pb.ContainerPBImpl:setContainerToken(org.apache.hadoop.yarn.api.records.Token)
org.apache.hadoop.yarn.api.records.impl.pb.ContainerPBImpl	setAllocationTags	allocationTags	GJ	java.util.Set	0	org.apache.hadoop.yarn.api.records.impl.pb.ContainerPBImpl:setAllocationTags(java.util.Set)
org.apache.hadoop.yarn.api.records.impl.pb.ApplicationAttemptReportPBImpl	setApplicationAttemptId	ApplicationAttemptId	C	org.apache.hadoop.yarn.api.records.ApplicationAttemptId	0	org.apache.hadoop.yarn.api.records.impl.pb.ApplicationAttemptReportPBImpl:setApplicationAttemptId(org.apache.hadoop.yarn.api.records.ApplicationAttemptId)
org.apache.hadoop.yarn.api.records.impl.pb.ApplicationAttemptReportPBImpl	setAMContainerId	amContainerId	C	org.apache.hadoop.yarn.api.records.ContainerId	0	org.apache.hadoop.yarn.api.records.impl.pb.ApplicationAttemptReportPBImpl:setAMContainerId(org.apache.hadoop.yarn.api.records.ContainerId)
org.apache.hadoop.yarn.api.records.impl.pb.QueueInfoPBImpl	setApplications	applicationsList	GC	java.util.List	0	org.apache.hadoop.yarn.api.records.impl.pb.QueueInfoPBImpl:setApplications(java.util.List)
org.apache.hadoop.yarn.api.records.impl.pb.QueueInfoPBImpl	setChildQueues	childQueuesList	GC	java.util.List	0	org.apache.hadoop.yarn.api.records.impl.pb.QueueInfoPBImpl:setChildQueues(java.util.List)
org.apache.hadoop.yarn.api.records.impl.pb.QueueInfoPBImpl	setAccessibleNodeLabels	accessibleNodeLabels	GJ	java.util.Set	0	org.apache.hadoop.yarn.api.records.impl.pb.QueueInfoPBImpl:setAccessibleNodeLabels(java.util.Set)
org.apache.hadoop.yarn.api.records.impl.pb.ReservationRequestPBImpl	setCapability	capability	C	org.apache.hadoop.yarn.api.records.Resource	0	org.apache.hadoop.yarn.api.records.impl.pb.ReservationRequestPBImpl:setCapability(org.apache.hadoop.yarn.api.records.Resource)
org.apache.hadoop.yarn.api.records.impl.pb.ApplicationSubmissionContextPBImpl	setPriority	priority	C	org.apache.hadoop.yarn.api.records.Priority	0	org.apache.hadoop.yarn.api.records.impl.pb.ApplicationSubmissionContextPBImpl:setPriority(org.apache.hadoop.yarn.api.records.Priority)
org.apache.hadoop.yarn.api.records.impl.pb.ApplicationSubmissionContextPBImpl	setApplicationId	applicationId	C	org.apache.hadoop.yarn.api.records.ApplicationId	0	org.apache.hadoop.yarn.api.records.impl.pb.ApplicationSubmissionContextPBImpl:setApplicationId(org.apache.hadoop.yarn.api.records.ApplicationId)
org.apache.hadoop.yarn.api.records.impl.pb.ApplicationSubmissionContextPBImpl	setAMContainerSpec	amContainer	C	org.apache.hadoop.yarn.api.records.ContainerLaunchContext	0	org.apache.hadoop.yarn.api.records.impl.pb.ApplicationSubmissionContextPBImpl:setAMContainerSpec(org.apache.hadoop.yarn.api.records.ContainerLaunchContext)
org.apache.hadoop.yarn.api.records.impl.pb.ApplicationSubmissionContextPBImpl	setResource	resource	C	org.apache.hadoop.yarn.api.records.Resource	0	org.apache.hadoop.yarn.api.records.impl.pb.ApplicationSubmissionContextPBImpl:setResource(org.apache.hadoop.yarn.api.records.Resource)
org.apache.hadoop.yarn.api.records.impl.pb.ApplicationSubmissionContextPBImpl	setReservationID	reservationId	C	org.apache.hadoop.yarn.api.records.ReservationId	0	org.apache.hadoop.yarn.api.records.impl.pb.ApplicationSubmissionContextPBImpl:setReservationID(org.apache.hadoop.yarn.api.records.ReservationId)
org.apache.hadoop.yarn.api.records.impl.pb.ApplicationSubmissionContextPBImpl	setAMContainerResourceRequests	amResourceRequests	GC	java.util.List	0	org.apache.hadoop.yarn.api.records.impl.pb.ApplicationSubmissionContextPBImpl:setAMContainerResourceRequests(java.util.List)
org.apache.hadoop.yarn.api.records.impl.pb.ApplicationSubmissionContextPBImpl	setLogAggregationContext	logAggregationContext	C	org.apache.hadoop.yarn.api.records.LogAggregationContext	0	org.apache.hadoop.yarn.api.records.impl.pb.ApplicationSubmissionContextPBImpl:setLogAggregationContext(org.apache.hadoop.yarn.api.records.LogAggregationContext)
org.apache.hadoop.yarn.api.records.impl.pb.ResourceTypeInfoPBImpl	setName	name	J	java.lang.String	0	org.apache.hadoop.yarn.api.records.impl.pb.ResourceTypeInfoPBImpl:setName(java.lang.String)
org.apache.hadoop.yarn.api.records.impl.pb.ResourceTypeInfoPBImpl	setDefaultUnit	defaultUnit	J	java.lang.String	0	org.apache.hadoop.yarn.api.records.impl.pb.ResourceTypeInfoPBImpl:setDefaultUnit(java.lang.String)
org.apache.hadoop.yarn.api.records.impl.pb.ResourceTypeInfoPBImpl	setResourceType	resourceTypes	C	org.apache.hadoop.yarn.api.protocolrecords.ResourceTypes	0	org.apache.hadoop.yarn.api.records.impl.pb.ResourceTypeInfoPBImpl:setResourceType(org.apache.hadoop.yarn.api.protocolrecords.ResourceTypes)
org.apache.hadoop.yarn.api.records.impl.pb.ContainerReportPBImpl	setAllocatedResource	resource	C	org.apache.hadoop.yarn.api.records.Resource	0	org.apache.hadoop.yarn.api.records.impl.pb.ContainerReportPBImpl:setAllocatedResource(org.apache.hadoop.yarn.api.records.Resource)
org.apache.hadoop.yarn.api.records.impl.pb.ContainerReportPBImpl	setAssignedNode	nodeId	C	org.apache.hadoop.yarn.api.records.NodeId	0	org.apache.hadoop.yarn.api.records.impl.pb.ContainerReportPBImpl:setAssignedNode(org.apache.hadoop.yarn.api.records.NodeId)
org.apache.hadoop.yarn.api.records.impl.pb.ContainerReportPBImpl	setContainerId	containerId	C	org.apache.hadoop.yarn.api.records.ContainerId	0	org.apache.hadoop.yarn.api.records.impl.pb.ContainerReportPBImpl:setContainerId(org.apache.hadoop.yarn.api.records.ContainerId)
org.apache.hadoop.yarn.api.records.impl.pb.ContainerReportPBImpl	setPriority	priority	C	org.apache.hadoop.yarn.api.records.Priority	0	org.apache.hadoop.yarn.api.records.impl.pb.ContainerReportPBImpl:setPriority(org.apache.hadoop.yarn.api.records.Priority)
org.apache.hadoop.yarn.api.records.impl.pb.ContainerLaunchContextPBImpl	setTokens	tokens	J	java.nio.ByteBuffer	0	org.apache.hadoop.yarn.api.records.impl.pb.ContainerLaunchContextPBImpl:setTokens(java.nio.ByteBuffer)
org.apache.hadoop.yarn.api.records.impl.pb.ContainerLaunchContextPBImpl	setTokensConf	tokensConf	J	java.nio.ByteBuffer	0	org.apache.hadoop.yarn.api.records.impl.pb.ContainerLaunchContextPBImpl:setTokensConf(java.nio.ByteBuffer)
org.apache.hadoop.yarn.api.records.impl.pb.ContainerLaunchContextPBImpl	setContainerRetryContext	containerRetryContext	C	org.apache.hadoop.yarn.api.records.ContainerRetryContext	0	org.apache.hadoop.yarn.api.records.impl.pb.ContainerLaunchContextPBImpl:setContainerRetryContext(org.apache.hadoop.yarn.api.records.ContainerRetryContext)
org.apache.hadoop.yarn.api.records.impl.pb.LocalResourcePBImpl	setResource	url	C	org.apache.hadoop.yarn.api.records.URL	0	org.apache.hadoop.yarn.api.records.impl.pb.LocalResourcePBImpl:setResource(org.apache.hadoop.yarn.api.records.URL)
org.apache.hadoop.yarn.api.records.impl.pb.RejectedSchedulingRequestPBImpl	setRequest	request	C	org.apache.hadoop.yarn.api.records.SchedulingRequest	0	org.apache.hadoop.yarn.api.records.impl.pb.RejectedSchedulingRequestPBImpl:setRequest(org.apache.hadoop.yarn.api.records.SchedulingRequest)
org.apache.hadoop.yarn.api.records.impl.pb.ReservationDefinitionPBImpl	setReservationRequests	reservationReqs	C	org.apache.hadoop.yarn.api.records.ReservationRequests	0	org.apache.hadoop.yarn.api.records.impl.pb.ReservationDefinitionPBImpl:setReservationRequests(org.apache.hadoop.yarn.api.records.ReservationRequests)
org.apache.hadoop.yarn.api.records.impl.pb.ReservationDefinitionPBImpl	setPriority	priority	C	org.apache.hadoop.yarn.api.records.Priority	0	org.apache.hadoop.yarn.api.records.impl.pb.ReservationDefinitionPBImpl:setPriority(org.apache.hadoop.yarn.api.records.Priority)
org.apache.hadoop.yarn.api.records.impl.pb.UpdateContainerRequestPBImpl	setContainerId	existingContainerId	C	org.apache.hadoop.yarn.api.records.ContainerId	0	org.apache.hadoop.yarn.api.records.impl.pb.UpdateContainerRequestPBImpl:setContainerId(org.apache.hadoop.yarn.api.records.ContainerId)
org.apache.hadoop.yarn.api.records.impl.pb.UpdateContainerRequestPBImpl	setCapability	targetCapability	C	org.apache.hadoop.yarn.api.records.Resource	0	org.apache.hadoop.yarn.api.records.impl.pb.UpdateContainerRequestPBImpl:setCapability(org.apache.hadoop.yarn.api.records.Resource)
org.apache.hadoop.yarn.api.records.impl.pb.QueueConfigurationsPBImpl	setEffectiveMinCapacity	effMinResource	C	org.apache.hadoop.yarn.api.records.Resource	0	org.apache.hadoop.yarn.api.records.impl.pb.QueueConfigurationsPBImpl:setEffectiveMinCapacity(org.apache.hadoop.yarn.api.records.Resource)
org.apache.hadoop.yarn.api.records.impl.pb.QueueConfigurationsPBImpl	setEffectiveMaxCapacity	effMaxResource	C	org.apache.hadoop.yarn.api.records.Resource	0	org.apache.hadoop.yarn.api.records.impl.pb.QueueConfigurationsPBImpl:setEffectiveMaxCapacity(org.apache.hadoop.yarn.api.records.Resource)
org.apache.hadoop.yarn.api.records.impl.pb.QueueConfigurationsPBImpl	setConfiguredMinCapacity	configuredMinResource	C	org.apache.hadoop.yarn.api.records.Resource	0	org.apache.hadoop.yarn.api.records.impl.pb.QueueConfigurationsPBImpl:setConfiguredMinCapacity(org.apache.hadoop.yarn.api.records.Resource)
org.apache.hadoop.yarn.api.records.impl.pb.QueueConfigurationsPBImpl	setConfiguredMaxCapacity	configuredMaxResource	C	org.apache.hadoop.yarn.api.records.Resource	0	org.apache.hadoop.yarn.api.records.impl.pb.QueueConfigurationsPBImpl:setConfiguredMaxCapacity(org.apache.hadoop.yarn.api.records.Resource)
org.apache.hadoop.yarn.api.records.impl.pb.ApplicationResourceUsageReportPBImpl	setUsedResources	usedResources	C	org.apache.hadoop.yarn.api.records.Resource	0	org.apache.hadoop.yarn.api.records.impl.pb.ApplicationResourceUsageReportPBImpl:setUsedResources(org.apache.hadoop.yarn.api.records.Resource)
org.apache.hadoop.yarn.api.records.impl.pb.ApplicationResourceUsageReportPBImpl	setReservedResources	reservedResources	C	org.apache.hadoop.yarn.api.records.Resource	0	org.apache.hadoop.yarn.api.records.impl.pb.ApplicationResourceUsageReportPBImpl:setReservedResources(org.apache.hadoop.yarn.api.records.Resource)
org.apache.hadoop.yarn.api.records.impl.pb.ApplicationResourceUsageReportPBImpl	setNeededResources	neededResources	C	org.apache.hadoop.yarn.api.records.Resource	0	org.apache.hadoop.yarn.api.records.impl.pb.ApplicationResourceUsageReportPBImpl:setNeededResources(org.apache.hadoop.yarn.api.records.Resource)
org.apache.hadoop.yarn.api.records.impl.pb.PreemptionContainerPBImpl	setId	id	C	org.apache.hadoop.yarn.api.records.ContainerId	0	org.apache.hadoop.yarn.api.records.impl.pb.PreemptionContainerPBImpl:setId(org.apache.hadoop.yarn.api.records.ContainerId)
org.apache.hadoop.yarn.api.records.impl.pb.ContainerIdPBImpl	setApplicationAttemptId	applicationAttemptId	C	org.apache.hadoop.yarn.api.records.ApplicationAttemptId	0	org.apache.hadoop.yarn.api.records.impl.pb.ContainerIdPBImpl:setApplicationAttemptId(org.apache.hadoop.yarn.api.records.ApplicationAttemptId)
org.apache.hadoop.yarn.api.records.impl.pb.ReservationRequestsPBImpl	setReservationResources	reservationRequests	GC	java.util.List	0	org.apache.hadoop.yarn.api.records.impl.pb.ReservationRequestsPBImpl:setReservationResources(java.util.List)
org.apache.hadoop.yarn.api.records.impl.pb.PreemptionMessagePBImpl	setStrictContract	strict	C	org.apache.hadoop.yarn.api.records.StrictPreemptionContract	0	org.apache.hadoop.yarn.api.records.impl.pb.PreemptionMessagePBImpl:setStrictContract(org.apache.hadoop.yarn.api.records.StrictPreemptionContract)
org.apache.hadoop.yarn.api.records.impl.pb.PreemptionMessagePBImpl	setContract	contract	C	org.apache.hadoop.yarn.api.records.PreemptionContract	0	org.apache.hadoop.yarn.api.records.impl.pb.PreemptionMessagePBImpl:setContract(org.apache.hadoop.yarn.api.records.PreemptionContract)
org.apache.hadoop.yarn.api.records.impl.pb.ReservationAllocationStatePBImpl	setResourceAllocationRequests	resourceAllocations	GC	java.util.List	0	org.apache.hadoop.yarn.api.records.impl.pb.ReservationAllocationStatePBImpl:setResourceAllocationRequests(java.util.List)
org.apache.hadoop.yarn.api.records.impl.pb.ReservationAllocationStatePBImpl	setReservationId	reservationId	C	org.apache.hadoop.yarn.api.records.ReservationId	0	org.apache.hadoop.yarn.api.records.impl.pb.ReservationAllocationStatePBImpl:setReservationId(org.apache.hadoop.yarn.api.records.ReservationId)
org.apache.hadoop.yarn.api.records.impl.pb.ReservationAllocationStatePBImpl	setReservationDefinition	reservationDefinition	C	org.apache.hadoop.yarn.api.records.ReservationDefinition	0	org.apache.hadoop.yarn.api.records.impl.pb.ReservationAllocationStatePBImpl:setReservationDefinition(org.apache.hadoop.yarn.api.records.ReservationDefinition)
org.apache.hadoop.yarn.api.records.impl.pb.NMTokenPBImpl	setNodeId	nodeId	C	org.apache.hadoop.yarn.api.records.NodeId	0	org.apache.hadoop.yarn.api.records.impl.pb.NMTokenPBImpl:setNodeId(org.apache.hadoop.yarn.api.records.NodeId)
org.apache.hadoop.yarn.api.records.impl.pb.NMTokenPBImpl	setToken	token	C	org.apache.hadoop.yarn.api.records.Token	0	org.apache.hadoop.yarn.api.records.impl.pb.NMTokenPBImpl:setToken(org.apache.hadoop.yarn.api.records.Token)
org.apache.hadoop.yarn.ContainerRollingLogAppender	setContainerLogDir	containerLogDir	J	java.lang.String	0	org.apache.hadoop.yarn.ContainerRollingLogAppender:setContainerLogDir(java.lang.String)
org.apache.hadoop.yarn.ContainerRollingLogAppender	setContainerLogFile	containerLogFile	J	java.lang.String	0	org.apache.hadoop.yarn.ContainerRollingLogAppender:setContainerLogFile(java.lang.String)
org.apache.hadoop.yarn.webapp.hamlet.HamletImpl	setWasInline	wasInline	J	boolean	0	org.apache.hadoop.yarn.webapp.hamlet.HamletImpl:setWasInline(boolean)
org.apache.hadoop.yarn.webapp.hamlet2.HamletImpl	setWasInline	wasInline	J	boolean	0	org.apache.hadoop.yarn.webapp.hamlet2.HamletImpl:setWasInline(boolean)
org.apache.hadoop.yarn.webapp.WebApp	setHttpServer	httpServer	C	org.apache.hadoop.http.HttpServer2	0	org.apache.hadoop.yarn.webapp.WebApp:setHttpServer(org.apache.hadoop.http.HttpServer2)
org.apache.hadoop.yarn.webapp.WebApp	setConf	conf	C	org.apache.hadoop.conf.Configuration	0	org.apache.hadoop.yarn.webapp.WebApp:setConf(org.apache.hadoop.conf.Configuration)
org.apache.hadoop.yarn.webapp.WebApp	setName	name	J	java.lang.String	0	org.apache.hadoop.yarn.webapp.WebApp:setName(java.lang.String)
org.apache.hadoop.yarn.webapp.WebApp	setRedirectPath	redirectPath	J	java.lang.String	0	org.apache.hadoop.yarn.webapp.WebApp:setRedirectPath(java.lang.String)
org.apache.hadoop.yarn.webapp.WebApp	setWebServices	wsName	J	java.lang.String	0	org.apache.hadoop.yarn.webapp.WebApp:setWebServices(java.lang.String)
org.apache.hadoop.yarn.webapp.WebApp	setGuiceFilter	guiceFilter	C	com.google.inject.servlet.GuiceFilter	0	org.apache.hadoop.yarn.webapp.WebApp:setGuiceFilter(com.google.inject.servlet.GuiceFilter)
org.apache.hadoop.yarn.webapp.Router	setHostClass	hostClass	GC	java.lang.Class	0	org.apache.hadoop.yarn.webapp.Router:setHostClass(java.lang.Class)
org.apache.hadoop.yarn.webapp.dao.SchedConfUpdateInfo	setAddQueueInfo	addQueueInfo	GC	java.util.ArrayList	0	org.apache.hadoop.yarn.webapp.dao.SchedConfUpdateInfo:setAddQueueInfo(java.util.ArrayList)
org.apache.hadoop.yarn.webapp.dao.SchedConfUpdateInfo	setRemoveQueueInfo	removeQueueInfo	GJ	java.util.ArrayList	0	org.apache.hadoop.yarn.webapp.dao.SchedConfUpdateInfo:setRemoveQueueInfo(java.util.ArrayList)
org.apache.hadoop.yarn.webapp.dao.SchedConfUpdateInfo	setUpdateQueueInfo	updateQueueInfo	GC	java.util.ArrayList	0	org.apache.hadoop.yarn.webapp.dao.SchedConfUpdateInfo:setUpdateQueueInfo(java.util.ArrayList)
org.apache.hadoop.yarn.webapp.dao.SchedConfUpdateInfo	setGlobalParams	global	GJ	java.util.HashMap	0	org.apache.hadoop.yarn.webapp.dao.SchedConfUpdateInfo:setGlobalParams(java.util.HashMap)
org.apache.hadoop.yarn.webapp.Controller$RequestContext	setStatus	status	J	int	0	org.apache.hadoop.yarn.webapp.Controller$RequestContext:setStatus(int)
org.apache.hadoop.yarn.webapp.Controller$RequestContext	setRendered	rendered	J	boolean	0	org.apache.hadoop.yarn.webapp.Controller$RequestContext:setRendered(boolean)
org.apache.hadoop.yarn.webapp.Dispatcher	setDevMode	devMode	J	boolean	0	org.apache.hadoop.yarn.webapp.Dispatcher:setDevMode(boolean)
org.apache.hadoop.yarn.logaggregation.ContainerLogFileInfo	setFileName	fileName	J	java.lang.String	0	org.apache.hadoop.yarn.logaggregation.ContainerLogFileInfo:setFileName(java.lang.String)
org.apache.hadoop.yarn.logaggregation.ContainerLogFileInfo	setFileSize	fileSize	J	java.lang.String	0	org.apache.hadoop.yarn.logaggregation.ContainerLogFileInfo:setFileSize(java.lang.String)
org.apache.hadoop.yarn.logaggregation.ContainerLogFileInfo	setLastModifiedTime	lastModifiedTime	J	java.lang.String	0	org.apache.hadoop.yarn.logaggregation.ContainerLogFileInfo:setLastModifiedTime(java.lang.String)
org.apache.hadoop.yarn.logaggregation.filecontroller.LogAggregationHtmlBlock$BlockParameters	setAppId	appId	C	org.apache.hadoop.yarn.api.records.ApplicationId	0	org.apache.hadoop.yarn.logaggregation.filecontroller.LogAggregationHtmlBlock$BlockParameters:setAppId(org.apache.hadoop.yarn.api.records.ApplicationId)
org.apache.hadoop.yarn.logaggregation.filecontroller.LogAggregationHtmlBlock$BlockParameters	setContainerId	containerId	C	org.apache.hadoop.yarn.api.records.ContainerId	0	org.apache.hadoop.yarn.logaggregation.filecontroller.LogAggregationHtmlBlock$BlockParameters:setContainerId(org.apache.hadoop.yarn.api.records.ContainerId)
org.apache.hadoop.yarn.logaggregation.filecontroller.LogAggregationHtmlBlock$BlockParameters	setNodeId	nodeId	C	org.apache.hadoop.yarn.api.records.NodeId	0	org.apache.hadoop.yarn.logaggregation.filecontroller.LogAggregationHtmlBlock$BlockParameters:setNodeId(org.apache.hadoop.yarn.api.records.NodeId)
org.apache.hadoop.yarn.logaggregation.filecontroller.LogAggregationHtmlBlock$BlockParameters	setAppOwner	appOwner	J	java.lang.String	0	org.apache.hadoop.yarn.logaggregation.filecontroller.LogAggregationHtmlBlock$BlockParameters:setAppOwner(java.lang.String)
org.apache.hadoop.yarn.logaggregation.filecontroller.LogAggregationHtmlBlock$BlockParameters	setStartIndex	start	J	long	0	org.apache.hadoop.yarn.logaggregation.filecontroller.LogAggregationHtmlBlock$BlockParameters:setStartIndex(long)
org.apache.hadoop.yarn.logaggregation.filecontroller.LogAggregationHtmlBlock$BlockParameters	setEndIndex	end	J	long	0	org.apache.hadoop.yarn.logaggregation.filecontroller.LogAggregationHtmlBlock$BlockParameters:setEndIndex(long)
org.apache.hadoop.yarn.logaggregation.filecontroller.LogAggregationHtmlBlock$BlockParameters	setLogEntity	logEntity	J	java.lang.String	0	org.apache.hadoop.yarn.logaggregation.filecontroller.LogAggregationHtmlBlock$BlockParameters:setLogEntity(java.lang.String)
org.apache.hadoop.yarn.logaggregation.filecontroller.LogAggregationHtmlBlock$BlockParameters	setStartTime	startTime	J	long	0	org.apache.hadoop.yarn.logaggregation.filecontroller.LogAggregationHtmlBlock$BlockParameters:setStartTime(long)
org.apache.hadoop.yarn.logaggregation.filecontroller.LogAggregationHtmlBlock$BlockParameters	setEndTime	endTime	J	long	0	org.apache.hadoop.yarn.logaggregation.filecontroller.LogAggregationHtmlBlock$BlockParameters:setEndTime(long)
org.apache.hadoop.yarn.logaggregation.filecontroller.ifile.LogAggregationIndexedFileController$IndexedLogsMeta	setVersion	version	J	int	0	org.apache.hadoop.yarn.logaggregation.filecontroller.ifile.LogAggregationIndexedFileController$IndexedLogsMeta:setVersion(int)
org.apache.hadoop.yarn.logaggregation.filecontroller.ifile.LogAggregationIndexedFileController$IndexedLogsMeta	setUser	user	J	java.lang.String	0	org.apache.hadoop.yarn.logaggregation.filecontroller.ifile.LogAggregationIndexedFileController$IndexedLogsMeta:setUser(java.lang.String)
org.apache.hadoop.yarn.logaggregation.filecontroller.ifile.LogAggregationIndexedFileController$IndexedLogsMeta	setAcls	acls	GC	java.util.Map	0	org.apache.hadoop.yarn.logaggregation.filecontroller.ifile.LogAggregationIndexedFileController$IndexedLogsMeta:setAcls(java.util.Map)
org.apache.hadoop.yarn.logaggregation.filecontroller.ifile.LogAggregationIndexedFileController$IndexedLogsMeta	setCompressName	compressName	J	java.lang.String	0	org.apache.hadoop.yarn.logaggregation.filecontroller.ifile.LogAggregationIndexedFileController$IndexedLogsMeta:setCompressName(java.lang.String)
org.apache.hadoop.yarn.logaggregation.filecontroller.ifile.LogAggregationIndexedFileController$IndexedLogsMeta	setNodeId	nodeId	J	java.lang.String	0	org.apache.hadoop.yarn.logaggregation.filecontroller.ifile.LogAggregationIndexedFileController$IndexedLogsMeta:setNodeId(java.lang.String)
org.apache.hadoop.yarn.logaggregation.filecontroller.ifile.LogAggregationIndexedFileController$IndexedFileLogMeta	setFileName	fileName	J	java.lang.String	0	org.apache.hadoop.yarn.logaggregation.filecontroller.ifile.LogAggregationIndexedFileController$IndexedFileLogMeta:setFileName(java.lang.String)
org.apache.hadoop.yarn.logaggregation.filecontroller.ifile.LogAggregationIndexedFileController$IndexedFileLogMeta	setFileSize	fileSize	J	long	0	org.apache.hadoop.yarn.logaggregation.filecontroller.ifile.LogAggregationIndexedFileController$IndexedFileLogMeta:setFileSize(long)
org.apache.hadoop.yarn.logaggregation.filecontroller.ifile.LogAggregationIndexedFileController$IndexedFileLogMeta	setFileCompressedSize	fileCompressedSize	J	long	0	org.apache.hadoop.yarn.logaggregation.filecontroller.ifile.LogAggregationIndexedFileController$IndexedFileLogMeta:setFileCompressedSize(long)
org.apache.hadoop.yarn.logaggregation.filecontroller.ifile.LogAggregationIndexedFileController$IndexedFileLogMeta	setLastModifiedTime	lastModifiedTime	J	long	0	org.apache.hadoop.yarn.logaggregation.filecontroller.ifile.LogAggregationIndexedFileController$IndexedFileLogMeta:setLastModifiedTime(long)
org.apache.hadoop.yarn.logaggregation.filecontroller.ifile.LogAggregationIndexedFileController$IndexedFileLogMeta	setStartIndex	startIndex	J	long	0	org.apache.hadoop.yarn.logaggregation.filecontroller.ifile.LogAggregationIndexedFileController$IndexedFileLogMeta:setStartIndex(long)
org.apache.hadoop.yarn.logaggregation.filecontroller.ifile.LogAggregationIndexedFileController$IndexedFileLogMeta	setContainerId	containerId	J	java.lang.String	0	org.apache.hadoop.yarn.logaggregation.filecontroller.ifile.LogAggregationIndexedFileController$IndexedFileLogMeta:setContainerId(java.lang.String)
org.apache.hadoop.yarn.logaggregation.filecontroller.ifile.LogAggregationIndexedFileController$IndexedPerAggregationLogMeta	setRemoteNodeFile	remoteNodeLogFileName	J	java.lang.String	0	org.apache.hadoop.yarn.logaggregation.filecontroller.ifile.LogAggregationIndexedFileController$IndexedPerAggregationLogMeta:setRemoteNodeFile(java.lang.String)
org.apache.hadoop.yarn.logaggregation.filecontroller.ifile.LogAggregationIndexedFileController$IndexedPerAggregationLogMeta	setUploadTimeStamp	uploadTimeStamp	J	long	0	org.apache.hadoop.yarn.logaggregation.filecontroller.ifile.LogAggregationIndexedFileController$IndexedPerAggregationLogMeta:setUploadTimeStamp(long)
org.apache.hadoop.yarn.logaggregation.filecontroller.tfile.LogAggregationTFileController$TFileLogReader	setLogReader	logReader	C	org.apache.hadoop.yarn.logaggregation.AggregatedLogFormat$LogReader	0	org.apache.hadoop.yarn.logaggregation.filecontroller.tfile.LogAggregationTFileController$TFileLogReader:setLogReader(org.apache.hadoop.yarn.logaggregation.AggregatedLogFormat$LogReader)
org.apache.hadoop.yarn.logaggregation.filecontroller.tfile.LogAggregationTFileController$TFileLogReader	setAggregatedLogPath	aggregatedLogPath	C	org.apache.hadoop.fs.Path	0	org.apache.hadoop.yarn.logaggregation.filecontroller.tfile.LogAggregationTFileController$TFileLogReader:setAggregatedLogPath(org.apache.hadoop.fs.Path)
org.apache.hadoop.yarn.logaggregation.filecontroller.LogAggregationFileControllerContext	setUploadedLogsInThisCycle	uploadedLogsInThisCycle	J	boolean	0	org.apache.hadoop.yarn.logaggregation.filecontroller.LogAggregationFileControllerContext:setUploadedLogsInThisCycle(boolean)
org.apache.hadoop.yarn.logaggregation.filecontroller.LogAggregationFileControllerContext	setLogUploadTimeStamp	logUploadedTimeStamp	J	long	0	org.apache.hadoop.yarn.logaggregation.filecontroller.LogAggregationFileControllerContext:setLogUploadTimeStamp(long)
org.apache.hadoop.yarn.logaggregation.LogCLIHelpers	setConf	conf	C	org.apache.hadoop.conf.Configuration	0	org.apache.hadoop.yarn.logaggregation.LogCLIHelpers:setConf(org.apache.hadoop.conf.Configuration)
org.apache.hadoop.yarn.logaggregation.ContainerLogsRequest	setAppId	appId	C	org.apache.hadoop.yarn.api.records.ApplicationId	0	org.apache.hadoop.yarn.logaggregation.ContainerLogsRequest:setAppId(org.apache.hadoop.yarn.api.records.ApplicationId)
org.apache.hadoop.yarn.logaggregation.ContainerLogsRequest	setAppAttemptId	appAttemptId	C	org.apache.hadoop.yarn.api.records.ApplicationAttemptId	0	org.apache.hadoop.yarn.logaggregation.ContainerLogsRequest:setAppAttemptId(org.apache.hadoop.yarn.api.records.ApplicationAttemptId)
org.apache.hadoop.yarn.logaggregation.ContainerLogsRequest	setContainerId	containerId	J	java.lang.String	0	org.apache.hadoop.yarn.logaggregation.ContainerLogsRequest:setContainerId(java.lang.String)
org.apache.hadoop.yarn.logaggregation.ContainerLogsRequest	setNodeId	nodeId	J	java.lang.String	0	org.apache.hadoop.yarn.logaggregation.ContainerLogsRequest:setNodeId(java.lang.String)
org.apache.hadoop.yarn.logaggregation.ContainerLogsRequest	setAppOwner	appOwner	J	java.lang.String	0	org.apache.hadoop.yarn.logaggregation.ContainerLogsRequest:setAppOwner(java.lang.String)
org.apache.hadoop.yarn.logaggregation.ContainerLogsRequest	setNodeHttpAddress	nodeHttpAddress	J	java.lang.String	0	org.apache.hadoop.yarn.logaggregation.ContainerLogsRequest:setNodeHttpAddress(java.lang.String)
org.apache.hadoop.yarn.logaggregation.ContainerLogsRequest	setAppFinished	appFinished	J	boolean	0	org.apache.hadoop.yarn.logaggregation.ContainerLogsRequest:setAppFinished(boolean)
org.apache.hadoop.yarn.logaggregation.ContainerLogsRequest	setOutputLocalDir	outputLocalDir	J	java.lang.String	0	org.apache.hadoop.yarn.logaggregation.ContainerLogsRequest:setOutputLocalDir(java.lang.String)
org.apache.hadoop.yarn.logaggregation.ContainerLogsRequest	setLogTypes	logTypes	GJ	java.util.Set	0	org.apache.hadoop.yarn.logaggregation.ContainerLogsRequest:setLogTypes(java.util.Set)
org.apache.hadoop.yarn.logaggregation.ContainerLogsRequest	setBytes	bytes	J	long	0	org.apache.hadoop.yarn.logaggregation.ContainerLogsRequest:setBytes(long)
org.apache.hadoop.yarn.logaggregation.ContainerLogsRequest	setContainerState	containerState	C	org.apache.hadoop.yarn.api.records.ContainerState	0	org.apache.hadoop.yarn.logaggregation.ContainerLogsRequest:setContainerState(org.apache.hadoop.yarn.api.records.ContainerState)
org.apache.hadoop.yarn.ContainerLogAppender	setContainerLogDir	containerLogDir	J	java.lang.String	0	org.apache.hadoop.yarn.ContainerLogAppender:setContainerLogDir(java.lang.String)
org.apache.hadoop.yarn.ContainerLogAppender	setContainerLogFile	containerLogFile	J	java.lang.String	0	org.apache.hadoop.yarn.ContainerLogAppender:setContainerLogFile(java.lang.String)
org.apache.hadoop.yarn.util.Log4jWarningErrorMetricsAppender	setCleanupInterval	cleanupInterval	J	long	0	org.apache.hadoop.yarn.util.Log4jWarningErrorMetricsAppender:setCleanupInterval(long)
org.apache.hadoop.yarn.util.Log4jWarningErrorMetricsAppender	setMessageAgeLimitSeconds	messageAgeLimitSeconds	J	long	0	org.apache.hadoop.yarn.util.Log4jWarningErrorMetricsAppender:setMessageAgeLimitSeconds(long)
org.apache.hadoop.yarn.util.Log4jWarningErrorMetricsAppender	setMaxUniqueMessages	maxUniqueMessages	J	int	0	org.apache.hadoop.yarn.util.Log4jWarningErrorMetricsAppender:setMaxUniqueMessages(int)
org.apache.hadoop.yarn.util.AbstractLivelinessMonitor	setMonitorInterval	monitorInterval	J	long	0	org.apache.hadoop.yarn.util.AbstractLivelinessMonitor:setMonitorInterval(long)
org.apache.hadoop.yarn.util.AbstractLivelinessMonitor	setResetTimeOnStart	resetTimerOnStart	J	boolean	0	org.apache.hadoop.yarn.util.AbstractLivelinessMonitor:setResetTimeOnStart(boolean)
org.apache.hadoop.yarn.util.ProcfsBasedProcessTree$ProcessSmapMemoryInfo	setPermission	permission	J	java.lang.String	0	org.apache.hadoop.yarn.util.ProcfsBasedProcessTree$ProcessSmapMemoryInfo:setPermission(java.lang.String)
org.apache.hadoop.yarn.client.api.impl.TimelineClientImpl	setTimelineWriter	timelineWriter	C	org.apache.hadoop.yarn.client.api.impl.TimelineWriter	0	org.apache.hadoop.yarn.client.api.impl.TimelineClientImpl:setTimelineWriter(org.apache.hadoop.yarn.client.api.impl.TimelineWriter)
csi.v0.Csi$ValidateVolumeCapabilitiesRequest$Builder	setVolumeId	volumeId_	J	java.lang.Object	0	csi.v0.Csi$ValidateVolumeCapabilitiesRequest$Builder:setVolumeId(java.lang.String)
csi.v0.Csi$ValidateVolumeCapabilitiesRequest$Builder	setVolumeIdBytes	volumeId_	J	java.lang.Object	0	csi.v0.Csi$ValidateVolumeCapabilitiesRequest$Builder:setVolumeIdBytes(com.google.protobuf.ByteString)
csi.v0.Csi$GetCapacityResponse$Builder	setAvailableCapacity	availableCapacity_	J	long	0	csi.v0.Csi$GetCapacityResponse$Builder:setAvailableCapacity(long)
csi.v0.Csi$ValidateVolumeCapabilitiesResponse$Builder	setSupported	supported_	J	boolean	0	csi.v0.Csi$ValidateVolumeCapabilitiesResponse$Builder:setSupported(boolean)
csi.v0.Csi$ValidateVolumeCapabilitiesResponse$Builder	setMessage	message_	J	java.lang.Object	0	csi.v0.Csi$ValidateVolumeCapabilitiesResponse$Builder:setMessage(java.lang.String)
csi.v0.Csi$ValidateVolumeCapabilitiesResponse$Builder	setMessageBytes	message_	J	java.lang.Object	0	csi.v0.Csi$ValidateVolumeCapabilitiesResponse$Builder:setMessageBytes(com.google.protobuf.ByteString)
csi.v0.Csi$Snapshot$Builder	setSizeBytes	sizeBytes_	J	long	0	csi.v0.Csi$Snapshot$Builder:setSizeBytes(long)
csi.v0.Csi$Snapshot$Builder	setId	id_	J	java.lang.Object	0	csi.v0.Csi$Snapshot$Builder:setId(java.lang.String)
csi.v0.Csi$Snapshot$Builder	setIdBytes	id_	J	java.lang.Object	0	csi.v0.Csi$Snapshot$Builder:setIdBytes(com.google.protobuf.ByteString)
csi.v0.Csi$Snapshot$Builder	setSourceVolumeId	sourceVolumeId_	J	java.lang.Object	0	csi.v0.Csi$Snapshot$Builder:setSourceVolumeId(java.lang.String)
csi.v0.Csi$Snapshot$Builder	setSourceVolumeIdBytes	sourceVolumeId_	J	java.lang.Object	0	csi.v0.Csi$Snapshot$Builder:setSourceVolumeIdBytes(com.google.protobuf.ByteString)
csi.v0.Csi$Snapshot$Builder	setCreatedAt	createdAt_	J	long	0	csi.v0.Csi$Snapshot$Builder:setCreatedAt(long)
csi.v0.Csi$SnapshotStatus$Builder	setTypeValue	type_	J	int	0	csi.v0.Csi$SnapshotStatus$Builder:setTypeValue(int)
csi.v0.Csi$SnapshotStatus$Builder	setDetails	details_	J	java.lang.Object	0	csi.v0.Csi$SnapshotStatus$Builder:setDetails(java.lang.String)
csi.v0.Csi$SnapshotStatus$Builder	setDetailsBytes	details_	J	java.lang.Object	0	csi.v0.Csi$SnapshotStatus$Builder:setDetailsBytes(com.google.protobuf.ByteString)
csi.v0.Csi$ControllerPublishVolumeRequest$Builder	setVolumeId	volumeId_	J	java.lang.Object	0	csi.v0.Csi$ControllerPublishVolumeRequest$Builder:setVolumeId(java.lang.String)
csi.v0.Csi$ControllerPublishVolumeRequest$Builder	setVolumeIdBytes	volumeId_	J	java.lang.Object	0	csi.v0.Csi$ControllerPublishVolumeRequest$Builder:setVolumeIdBytes(com.google.protobuf.ByteString)
csi.v0.Csi$ControllerPublishVolumeRequest$Builder	setNodeId	nodeId_	J	java.lang.Object	0	csi.v0.Csi$ControllerPublishVolumeRequest$Builder:setNodeId(java.lang.String)
csi.v0.Csi$ControllerPublishVolumeRequest$Builder	setNodeIdBytes	nodeId_	J	java.lang.Object	0	csi.v0.Csi$ControllerPublishVolumeRequest$Builder:setNodeIdBytes(com.google.protobuf.ByteString)
csi.v0.Csi$ControllerPublishVolumeRequest$Builder	setReadonly	readonly_	J	boolean	0	csi.v0.Csi$ControllerPublishVolumeRequest$Builder:setReadonly(boolean)
csi.v0.Csi$ListVolumesRequest$Builder	setMaxEntries	maxEntries_	J	int	0	csi.v0.Csi$ListVolumesRequest$Builder:setMaxEntries(int)
csi.v0.Csi$ListVolumesRequest$Builder	setStartingToken	startingToken_	J	java.lang.Object	0	csi.v0.Csi$ListVolumesRequest$Builder:setStartingToken(java.lang.String)
csi.v0.Csi$ListVolumesRequest$Builder	setStartingTokenBytes	startingToken_	J	java.lang.Object	0	csi.v0.Csi$ListVolumesRequest$Builder:setStartingTokenBytes(com.google.protobuf.ByteString)
csi.v0.Csi$VolumeCapability$MountVolume$Builder	setFsType	fsType_	J	java.lang.Object	0	csi.v0.Csi$VolumeCapability$MountVolume$Builder:setFsType(java.lang.String)
csi.v0.Csi$VolumeCapability$MountVolume$Builder	setFsTypeBytes	fsType_	J	java.lang.Object	0	csi.v0.Csi$VolumeCapability$MountVolume$Builder:setFsTypeBytes(com.google.protobuf.ByteString)
csi.v0.Csi$ListSnapshotsResponse$Builder	setNextToken	nextToken_	J	java.lang.Object	0	csi.v0.Csi$ListSnapshotsResponse$Builder:setNextToken(java.lang.String)
csi.v0.Csi$ListSnapshotsResponse$Builder	setNextTokenBytes	nextToken_	J	java.lang.Object	0	csi.v0.Csi$ListSnapshotsResponse$Builder:setNextTokenBytes(com.google.protobuf.ByteString)
csi.v0.Csi$ListVolumesResponse$Builder	setNextToken	nextToken_	J	java.lang.Object	0	csi.v0.Csi$ListVolumesResponse$Builder:setNextToken(java.lang.String)
csi.v0.Csi$ListVolumesResponse$Builder	setNextTokenBytes	nextToken_	J	java.lang.Object	0	csi.v0.Csi$ListVolumesResponse$Builder:setNextTokenBytes(com.google.protobuf.ByteString)
csi.v0.Csi$NodeStageVolumeRequest$Builder	setVolumeId	volumeId_	J	java.lang.Object	0	csi.v0.Csi$NodeStageVolumeRequest$Builder:setVolumeId(java.lang.String)
csi.v0.Csi$NodeStageVolumeRequest$Builder	setVolumeIdBytes	volumeId_	J	java.lang.Object	0	csi.v0.Csi$NodeStageVolumeRequest$Builder:setVolumeIdBytes(com.google.protobuf.ByteString)
csi.v0.Csi$NodeStageVolumeRequest$Builder	setStagingTargetPath	stagingTargetPath_	J	java.lang.Object	0	csi.v0.Csi$NodeStageVolumeRequest$Builder:setStagingTargetPath(java.lang.String)
csi.v0.Csi$NodeStageVolumeRequest$Builder	setStagingTargetPathBytes	stagingTargetPath_	J	java.lang.Object	0	csi.v0.Csi$NodeStageVolumeRequest$Builder:setStagingTargetPathBytes(com.google.protobuf.ByteString)
csi.v0.Csi$CapacityRange$Builder	setRequiredBytes	requiredBytes_	J	long	0	csi.v0.Csi$CapacityRange$Builder:setRequiredBytes(long)
csi.v0.Csi$CapacityRange$Builder	setLimitBytes	limitBytes_	J	long	0	csi.v0.Csi$CapacityRange$Builder:setLimitBytes(long)
csi.v0.Csi$CreateVolumeRequest$Builder	setName	name_	J	java.lang.Object	0	csi.v0.Csi$CreateVolumeRequest$Builder:setName(java.lang.String)
csi.v0.Csi$CreateVolumeRequest$Builder	setNameBytes	name_	J	java.lang.Object	0	csi.v0.Csi$CreateVolumeRequest$Builder:setNameBytes(com.google.protobuf.ByteString)
csi.v0.Csi$PluginCapability$Service$Builder	setTypeValue	type_	J	int	0	csi.v0.Csi$PluginCapability$Service$Builder:setTypeValue(int)
csi.v0.Csi$Volume$Builder	setCapacityBytes	capacityBytes_	J	long	0	csi.v0.Csi$Volume$Builder:setCapacityBytes(long)
csi.v0.Csi$Volume$Builder	setId	id_	J	java.lang.Object	0	csi.v0.Csi$Volume$Builder:setId(java.lang.String)
csi.v0.Csi$Volume$Builder	setIdBytes	id_	J	java.lang.Object	0	csi.v0.Csi$Volume$Builder:setIdBytes(com.google.protobuf.ByteString)
csi.v0.Csi$NodeServiceCapability$RPC$Builder	setTypeValue	type_	J	int	0	csi.v0.Csi$NodeServiceCapability$RPC$Builder:setTypeValue(int)
csi.v0.Csi$NodeUnstageVolumeRequest$Builder	setVolumeId	volumeId_	J	java.lang.Object	0	csi.v0.Csi$NodeUnstageVolumeRequest$Builder:setVolumeId(java.lang.String)
csi.v0.Csi$NodeUnstageVolumeRequest$Builder	setVolumeIdBytes	volumeId_	J	java.lang.Object	0	csi.v0.Csi$NodeUnstageVolumeRequest$Builder:setVolumeIdBytes(com.google.protobuf.ByteString)
csi.v0.Csi$NodeUnstageVolumeRequest$Builder	setStagingTargetPath	stagingTargetPath_	J	java.lang.Object	0	csi.v0.Csi$NodeUnstageVolumeRequest$Builder:setStagingTargetPath(java.lang.String)
csi.v0.Csi$NodeUnstageVolumeRequest$Builder	setStagingTargetPathBytes	stagingTargetPath_	J	java.lang.Object	0	csi.v0.Csi$NodeUnstageVolumeRequest$Builder:setStagingTargetPathBytes(com.google.protobuf.ByteString)
csi.v0.Csi$ControllerServiceCapability$RPC$Builder	setTypeValue	type_	J	int	0	csi.v0.Csi$ControllerServiceCapability$RPC$Builder:setTypeValue(int)
csi.v0.Csi$NodeGetIdResponse$Builder	setNodeId	nodeId_	J	java.lang.Object	0	csi.v0.Csi$NodeGetIdResponse$Builder:setNodeId(java.lang.String)
csi.v0.Csi$NodeGetIdResponse$Builder	setNodeIdBytes	nodeId_	J	java.lang.Object	0	csi.v0.Csi$NodeGetIdResponse$Builder:setNodeIdBytes(com.google.protobuf.ByteString)
csi.v0.Csi$NodeGetInfoResponse$Builder	setNodeId	nodeId_	J	java.lang.Object	0	csi.v0.Csi$NodeGetInfoResponse$Builder:setNodeId(java.lang.String)
csi.v0.Csi$NodeGetInfoResponse$Builder	setNodeIdBytes	nodeId_	J	java.lang.Object	0	csi.v0.Csi$NodeGetInfoResponse$Builder:setNodeIdBytes(com.google.protobuf.ByteString)
csi.v0.Csi$NodeGetInfoResponse$Builder	setMaxVolumesPerNode	maxVolumesPerNode_	J	long	0	csi.v0.Csi$NodeGetInfoResponse$Builder:setMaxVolumesPerNode(long)
csi.v0.Csi$VolumeCapability$AccessMode$Builder	setModeValue	mode_	J	int	0	csi.v0.Csi$VolumeCapability$AccessMode$Builder:setModeValue(int)
csi.v0.Csi$GetPluginInfoResponse$Builder	setName	name_	J	java.lang.Object	0	csi.v0.Csi$GetPluginInfoResponse$Builder:setName(java.lang.String)
csi.v0.Csi$GetPluginInfoResponse$Builder	setNameBytes	name_	J	java.lang.Object	0	csi.v0.Csi$GetPluginInfoResponse$Builder:setNameBytes(com.google.protobuf.ByteString)
csi.v0.Csi$GetPluginInfoResponse$Builder	setVendorVersion	vendorVersion_	J	java.lang.Object	0	csi.v0.Csi$GetPluginInfoResponse$Builder:setVendorVersion(java.lang.String)
csi.v0.Csi$GetPluginInfoResponse$Builder	setVendorVersionBytes	vendorVersion_	J	java.lang.Object	0	csi.v0.Csi$GetPluginInfoResponse$Builder:setVendorVersionBytes(com.google.protobuf.ByteString)
csi.v0.Csi$NodePublishVolumeRequest$Builder	setVolumeId	volumeId_	J	java.lang.Object	0	csi.v0.Csi$NodePublishVolumeRequest$Builder:setVolumeId(java.lang.String)
csi.v0.Csi$NodePublishVolumeRequest$Builder	setVolumeIdBytes	volumeId_	J	java.lang.Object	0	csi.v0.Csi$NodePublishVolumeRequest$Builder:setVolumeIdBytes(com.google.protobuf.ByteString)
csi.v0.Csi$NodePublishVolumeRequest$Builder	setStagingTargetPath	stagingTargetPath_	J	java.lang.Object	0	csi.v0.Csi$NodePublishVolumeRequest$Builder:setStagingTargetPath(java.lang.String)
csi.v0.Csi$NodePublishVolumeRequest$Builder	setStagingTargetPathBytes	stagingTargetPath_	J	java.lang.Object	0	csi.v0.Csi$NodePublishVolumeRequest$Builder:setStagingTargetPathBytes(com.google.protobuf.ByteString)
csi.v0.Csi$NodePublishVolumeRequest$Builder	setTargetPath	targetPath_	J	java.lang.Object	0	csi.v0.Csi$NodePublishVolumeRequest$Builder:setTargetPath(java.lang.String)
csi.v0.Csi$NodePublishVolumeRequest$Builder	setTargetPathBytes	targetPath_	J	java.lang.Object	0	csi.v0.Csi$NodePublishVolumeRequest$Builder:setTargetPathBytes(com.google.protobuf.ByteString)
csi.v0.Csi$NodePublishVolumeRequest$Builder	setReadonly	readonly_	J	boolean	0	csi.v0.Csi$NodePublishVolumeRequest$Builder:setReadonly(boolean)
csi.v0.Csi$DeleteVolumeRequest$Builder	setVolumeId	volumeId_	J	java.lang.Object	0	csi.v0.Csi$DeleteVolumeRequest$Builder:setVolumeId(java.lang.String)
csi.v0.Csi$DeleteVolumeRequest$Builder	setVolumeIdBytes	volumeId_	J	java.lang.Object	0	csi.v0.Csi$DeleteVolumeRequest$Builder:setVolumeIdBytes(com.google.protobuf.ByteString)
csi.v0.Csi$NodeUnpublishVolumeRequest$Builder	setVolumeId	volumeId_	J	java.lang.Object	0	csi.v0.Csi$NodeUnpublishVolumeRequest$Builder:setVolumeId(java.lang.String)
csi.v0.Csi$NodeUnpublishVolumeRequest$Builder	setVolumeIdBytes	volumeId_	J	java.lang.Object	0	csi.v0.Csi$NodeUnpublishVolumeRequest$Builder:setVolumeIdBytes(com.google.protobuf.ByteString)
csi.v0.Csi$NodeUnpublishVolumeRequest$Builder	setTargetPath	targetPath_	J	java.lang.Object	0	csi.v0.Csi$NodeUnpublishVolumeRequest$Builder:setTargetPath(java.lang.String)
csi.v0.Csi$NodeUnpublishVolumeRequest$Builder	setTargetPathBytes	targetPath_	J	java.lang.Object	0	csi.v0.Csi$NodeUnpublishVolumeRequest$Builder:setTargetPathBytes(com.google.protobuf.ByteString)
csi.v0.Csi$DeleteSnapshotRequest$Builder	setSnapshotId	snapshotId_	J	java.lang.Object	0	csi.v0.Csi$DeleteSnapshotRequest$Builder:setSnapshotId(java.lang.String)
csi.v0.Csi$DeleteSnapshotRequest$Builder	setSnapshotIdBytes	snapshotId_	J	java.lang.Object	0	csi.v0.Csi$DeleteSnapshotRequest$Builder:setSnapshotIdBytes(com.google.protobuf.ByteString)
csi.v0.Csi$ControllerUnpublishVolumeRequest$Builder	setVolumeId	volumeId_	J	java.lang.Object	0	csi.v0.Csi$ControllerUnpublishVolumeRequest$Builder:setVolumeId(java.lang.String)
csi.v0.Csi$ControllerUnpublishVolumeRequest$Builder	setVolumeIdBytes	volumeId_	J	java.lang.Object	0	csi.v0.Csi$ControllerUnpublishVolumeRequest$Builder:setVolumeIdBytes(com.google.protobuf.ByteString)
csi.v0.Csi$ControllerUnpublishVolumeRequest$Builder	setNodeId	nodeId_	J	java.lang.Object	0	csi.v0.Csi$ControllerUnpublishVolumeRequest$Builder:setNodeId(java.lang.String)
csi.v0.Csi$ControllerUnpublishVolumeRequest$Builder	setNodeIdBytes	nodeId_	J	java.lang.Object	0	csi.v0.Csi$ControllerUnpublishVolumeRequest$Builder:setNodeIdBytes(com.google.protobuf.ByteString)
csi.v0.Csi$CreateSnapshotRequest$Builder	setSourceVolumeId	sourceVolumeId_	J	java.lang.Object	0	csi.v0.Csi$CreateSnapshotRequest$Builder:setSourceVolumeId(java.lang.String)
csi.v0.Csi$CreateSnapshotRequest$Builder	setSourceVolumeIdBytes	sourceVolumeId_	J	java.lang.Object	0	csi.v0.Csi$CreateSnapshotRequest$Builder:setSourceVolumeIdBytes(com.google.protobuf.ByteString)
csi.v0.Csi$CreateSnapshotRequest$Builder	setName	name_	J	java.lang.Object	0	csi.v0.Csi$CreateSnapshotRequest$Builder:setName(java.lang.String)
csi.v0.Csi$CreateSnapshotRequest$Builder	setNameBytes	name_	J	java.lang.Object	0	csi.v0.Csi$CreateSnapshotRequest$Builder:setNameBytes(com.google.protobuf.ByteString)
csi.v0.Csi$ListSnapshotsRequest$Builder	setMaxEntries	maxEntries_	J	int	0	csi.v0.Csi$ListSnapshotsRequest$Builder:setMaxEntries(int)
csi.v0.Csi$ListSnapshotsRequest$Builder	setStartingToken	startingToken_	J	java.lang.Object	0	csi.v0.Csi$ListSnapshotsRequest$Builder:setStartingToken(java.lang.String)
csi.v0.Csi$ListSnapshotsRequest$Builder	setStartingTokenBytes	startingToken_	J	java.lang.Object	0	csi.v0.Csi$ListSnapshotsRequest$Builder:setStartingTokenBytes(com.google.protobuf.ByteString)
csi.v0.Csi$ListSnapshotsRequest$Builder	setSourceVolumeId	sourceVolumeId_	J	java.lang.Object	0	csi.v0.Csi$ListSnapshotsRequest$Builder:setSourceVolumeId(java.lang.String)
csi.v0.Csi$ListSnapshotsRequest$Builder	setSourceVolumeIdBytes	sourceVolumeId_	J	java.lang.Object	0	csi.v0.Csi$ListSnapshotsRequest$Builder:setSourceVolumeIdBytes(com.google.protobuf.ByteString)
csi.v0.Csi$ListSnapshotsRequest$Builder	setSnapshotId	snapshotId_	J	java.lang.Object	0	csi.v0.Csi$ListSnapshotsRequest$Builder:setSnapshotId(java.lang.String)
csi.v0.Csi$ListSnapshotsRequest$Builder	setSnapshotIdBytes	snapshotId_	J	java.lang.Object	0	csi.v0.Csi$ListSnapshotsRequest$Builder:setSnapshotIdBytes(com.google.protobuf.ByteString)
csi.v0.Csi$VolumeContentSource$SnapshotSource$Builder	setId	id_	J	java.lang.Object	0	csi.v0.Csi$VolumeContentSource$SnapshotSource$Builder:setId(java.lang.String)
csi.v0.Csi$VolumeContentSource$SnapshotSource$Builder	setIdBytes	id_	J	java.lang.Object	0	csi.v0.Csi$VolumeContentSource$SnapshotSource$Builder:setIdBytes(com.google.protobuf.ByteString)
org.apache.hadoop.yarn.csi.client.CsiGrpcClient$GrpcClientBuilder	setDomainSocketAddress	socket	J	java.net.SocketAddress	0	org.apache.hadoop.yarn.csi.client.CsiGrpcClient$GrpcClientBuilder:setDomainSocketAddress(java.net.SocketAddress)
org.apache.hadoop.yarn.proto.YarnServerTimelineServerRecoveryProtos$TimelineDelegationTokenIdentifierDataProto$Builder	setRenewDate	renewDate_	J	long	0	org.apache.hadoop.yarn.proto.YarnServerTimelineServerRecoveryProtos$TimelineDelegationTokenIdentifierDataProto$Builder:setRenewDate(long)
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationHistoryData	setApplicationId	applicationId	C	org.apache.hadoop.yarn.api.records.ApplicationId	0	org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationHistoryData:setApplicationId(org.apache.hadoop.yarn.api.records.ApplicationId)
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationHistoryData	setApplicationName	applicationName	J	java.lang.String	0	org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationHistoryData:setApplicationName(java.lang.String)
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationHistoryData	setApplicationType	applicationType	J	java.lang.String	0	org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationHistoryData:setApplicationType(java.lang.String)
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationHistoryData	setUser	user	J	java.lang.String	0	org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationHistoryData:setUser(java.lang.String)
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationHistoryData	setQueue	queue	J	java.lang.String	0	org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationHistoryData:setQueue(java.lang.String)
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationHistoryData	setSubmitTime	submitTime	J	long	0	org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationHistoryData:setSubmitTime(long)
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationHistoryData	setStartTime	startTime	J	long	0	org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationHistoryData:setStartTime(long)
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationHistoryData	setFinishTime	finishTime	J	long	0	org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationHistoryData:setFinishTime(long)
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationHistoryData	setDiagnosticsInfo	diagnosticsInfo	J	java.lang.String	0	org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationHistoryData:setDiagnosticsInfo(java.lang.String)
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationHistoryData	setFinalApplicationStatus	finalApplicationStatus	C	org.apache.hadoop.yarn.api.records.FinalApplicationStatus	0	org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationHistoryData:setFinalApplicationStatus(org.apache.hadoop.yarn.api.records.FinalApplicationStatus)
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationHistoryData	setYarnApplicationState	yarnApplicationState	C	org.apache.hadoop.yarn.api.records.YarnApplicationState	0	org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationHistoryData:setYarnApplicationState(org.apache.hadoop.yarn.api.records.YarnApplicationState)
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ContainerHistoryData	setContainerId	containerId	C	org.apache.hadoop.yarn.api.records.ContainerId	0	org.apache.hadoop.yarn.server.applicationhistoryservice.records.ContainerHistoryData:setContainerId(org.apache.hadoop.yarn.api.records.ContainerId)
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ContainerHistoryData	setAllocatedResource	allocatedResource	C	org.apache.hadoop.yarn.api.records.Resource	0	org.apache.hadoop.yarn.server.applicationhistoryservice.records.ContainerHistoryData:setAllocatedResource(org.apache.hadoop.yarn.api.records.Resource)
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ContainerHistoryData	setAssignedNode	assignedNode	C	org.apache.hadoop.yarn.api.records.NodeId	0	org.apache.hadoop.yarn.server.applicationhistoryservice.records.ContainerHistoryData:setAssignedNode(org.apache.hadoop.yarn.api.records.NodeId)
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ContainerHistoryData	setPriority	priority	C	org.apache.hadoop.yarn.api.records.Priority	0	org.apache.hadoop.yarn.server.applicationhistoryservice.records.ContainerHistoryData:setPriority(org.apache.hadoop.yarn.api.records.Priority)
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ContainerHistoryData	setStartTime	startTime	J	long	0	org.apache.hadoop.yarn.server.applicationhistoryservice.records.ContainerHistoryData:setStartTime(long)
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ContainerHistoryData	setFinishTime	finishTime	J	long	0	org.apache.hadoop.yarn.server.applicationhistoryservice.records.ContainerHistoryData:setFinishTime(long)
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ContainerHistoryData	setDiagnosticsInfo	diagnosticsInfo	J	java.lang.String	0	org.apache.hadoop.yarn.server.applicationhistoryservice.records.ContainerHistoryData:setDiagnosticsInfo(java.lang.String)
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ContainerHistoryData	setContainerExitStatus	containerExitStatus	J	int	0	org.apache.hadoop.yarn.server.applicationhistoryservice.records.ContainerHistoryData:setContainerExitStatus(int)
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ContainerHistoryData	setContainerState	containerState	C	org.apache.hadoop.yarn.api.records.ContainerState	0	org.apache.hadoop.yarn.server.applicationhistoryservice.records.ContainerHistoryData:setContainerState(org.apache.hadoop.yarn.api.records.ContainerState)
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ContainerHistoryData	setExposedPorts	exposedPorts	GJ	java.util.Map	0	org.apache.hadoop.yarn.server.applicationhistoryservice.records.ContainerHistoryData:setExposedPorts(java.util.Map)
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationAttemptHistoryData	setApplicationAttemptId	applicationAttemptId	C	org.apache.hadoop.yarn.api.records.ApplicationAttemptId	0	org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationAttemptHistoryData:setApplicationAttemptId(org.apache.hadoop.yarn.api.records.ApplicationAttemptId)
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationAttemptHistoryData	setHost	host	J	java.lang.String	0	org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationAttemptHistoryData:setHost(java.lang.String)
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationAttemptHistoryData	setRPCPort	rpcPort	J	int	0	org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationAttemptHistoryData:setRPCPort(int)
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationAttemptHistoryData	setTrackingURL	trackingURL	J	java.lang.String	0	org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationAttemptHistoryData:setTrackingURL(java.lang.String)
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationAttemptHistoryData	setDiagnosticsInfo	diagnosticsInfo	J	java.lang.String	0	org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationAttemptHistoryData:setDiagnosticsInfo(java.lang.String)
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationAttemptHistoryData	setFinalApplicationStatus	finalApplicationStatus	C	org.apache.hadoop.yarn.api.records.FinalApplicationStatus	0	org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationAttemptHistoryData:setFinalApplicationStatus(org.apache.hadoop.yarn.api.records.FinalApplicationStatus)
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationAttemptHistoryData	setMasterContainerId	masterContainerId	C	org.apache.hadoop.yarn.api.records.ContainerId	0	org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationAttemptHistoryData:setMasterContainerId(org.apache.hadoop.yarn.api.records.ContainerId)
org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationAttemptHistoryData	setYarnApplicationAttemptState	yarnApplicationAttemptState	C	org.apache.hadoop.yarn.api.records.YarnApplicationAttemptState	0	org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationAttemptHistoryData:setYarnApplicationAttemptState(org.apache.hadoop.yarn.api.records.YarnApplicationAttemptState)
org.apache.hadoop.yarn.server.applicationhistoryservice.records.impl.pb.ApplicationStartDataPBImpl	setApplicationId	applicationId	C	org.apache.hadoop.yarn.api.records.ApplicationId	0	org.apache.hadoop.yarn.server.applicationhistoryservice.records.impl.pb.ApplicationStartDataPBImpl:setApplicationId(org.apache.hadoop.yarn.api.records.ApplicationId)
org.apache.hadoop.yarn.server.applicationhistoryservice.records.impl.pb.ApplicationAttemptFinishDataPBImpl	setApplicationAttemptId	applicationAttemptId	C	org.apache.hadoop.yarn.api.records.ApplicationAttemptId	0	org.apache.hadoop.yarn.server.applicationhistoryservice.records.impl.pb.ApplicationAttemptFinishDataPBImpl:setApplicationAttemptId(org.apache.hadoop.yarn.api.records.ApplicationAttemptId)
org.apache.hadoop.yarn.server.applicationhistoryservice.records.impl.pb.ContainerFinishDataPBImpl	setContainerId	containerId	C	org.apache.hadoop.yarn.api.records.ContainerId	0	org.apache.hadoop.yarn.server.applicationhistoryservice.records.impl.pb.ContainerFinishDataPBImpl:setContainerId(org.apache.hadoop.yarn.api.records.ContainerId)
org.apache.hadoop.yarn.server.applicationhistoryservice.records.impl.pb.ApplicationFinishDataPBImpl	setApplicationId	applicationId	C	org.apache.hadoop.yarn.api.records.ApplicationId	0	org.apache.hadoop.yarn.server.applicationhistoryservice.records.impl.pb.ApplicationFinishDataPBImpl:setApplicationId(org.apache.hadoop.yarn.api.records.ApplicationId)
org.apache.hadoop.yarn.server.applicationhistoryservice.records.impl.pb.ApplicationAttemptStartDataPBImpl	setApplicationAttemptId	applicationAttemptId	C	org.apache.hadoop.yarn.api.records.ApplicationAttemptId	0	org.apache.hadoop.yarn.server.applicationhistoryservice.records.impl.pb.ApplicationAttemptStartDataPBImpl:setApplicationAttemptId(org.apache.hadoop.yarn.api.records.ApplicationAttemptId)
org.apache.hadoop.yarn.server.applicationhistoryservice.records.impl.pb.ApplicationAttemptStartDataPBImpl	setMasterContainerId	masterContainerId	C	org.apache.hadoop.yarn.api.records.ContainerId	0	org.apache.hadoop.yarn.server.applicationhistoryservice.records.impl.pb.ApplicationAttemptStartDataPBImpl:setMasterContainerId(org.apache.hadoop.yarn.api.records.ContainerId)
org.apache.hadoop.yarn.server.applicationhistoryservice.records.impl.pb.ContainerStartDataPBImpl	setContainerId	containerId	C	org.apache.hadoop.yarn.api.records.ContainerId	0	org.apache.hadoop.yarn.server.applicationhistoryservice.records.impl.pb.ContainerStartDataPBImpl:setContainerId(org.apache.hadoop.yarn.api.records.ContainerId)
org.apache.hadoop.yarn.server.applicationhistoryservice.records.impl.pb.ContainerStartDataPBImpl	setAllocatedResource	resource	C	org.apache.hadoop.yarn.api.records.Resource	0	org.apache.hadoop.yarn.server.applicationhistoryservice.records.impl.pb.ContainerStartDataPBImpl:setAllocatedResource(org.apache.hadoop.yarn.api.records.Resource)
org.apache.hadoop.yarn.server.applicationhistoryservice.records.impl.pb.ContainerStartDataPBImpl	setAssignedNode	nodeId	C	org.apache.hadoop.yarn.api.records.NodeId	0	org.apache.hadoop.yarn.server.applicationhistoryservice.records.impl.pb.ContainerStartDataPBImpl:setAssignedNode(org.apache.hadoop.yarn.api.records.NodeId)
org.apache.hadoop.yarn.server.applicationhistoryservice.records.impl.pb.ContainerStartDataPBImpl	setPriority	priority	C	org.apache.hadoop.yarn.api.records.Priority	0	org.apache.hadoop.yarn.server.applicationhistoryservice.records.impl.pb.ContainerStartDataPBImpl:setPriority(org.apache.hadoop.yarn.api.records.Priority)
org.apache.hadoop.yarn.server.applicationhistoryservice.webapp.AHSWebServices	setLogServlet	logServlet	C	org.apache.hadoop.yarn.server.webapp.LogServlet	0	org.apache.hadoop.yarn.server.applicationhistoryservice.webapp.AHSWebServices:setLogServlet(org.apache.hadoop.yarn.server.webapp.LogServlet)
org.apache.hadoop.yarn.server.timeline.RollingLevelDBTimelineStore	setFactory	factory	C	org.fusesource.leveldbjni.JniDBFactory	0	org.apache.hadoop.yarn.server.timeline.RollingLevelDBTimelineStore:setFactory(org.fusesource.leveldbjni.JniDBFactory)
org.apache.hadoop.yarn.server.timeline.LeveldbTimelineStore	setFactory	factory	C	org.fusesource.leveldbjni.JniDBFactory	0	org.apache.hadoop.yarn.server.timeline.LeveldbTimelineStore:setFactory(org.fusesource.leveldbjni.JniDBFactory)
org.apache.hadoop.yarn.server.timeline.security.TimelineACLsManager	setTimelineStore	store	C	org.apache.hadoop.yarn.server.timeline.TimelineStore	0	org.apache.hadoop.yarn.server.timeline.security.TimelineACLsManager:setTimelineStore(org.apache.hadoop.yarn.server.timeline.TimelineStore)
org.apache.hadoop.yarn.server.timeline.security.TimelineACLsManager	setAdminACLsManager	adminAclsManager	C	org.apache.hadoop.yarn.security.AdminACLsManager	0	org.apache.hadoop.yarn.server.timeline.security.TimelineACLsManager:setAdminACLsManager(org.apache.hadoop.yarn.security.AdminACLsManager)
org.apache.hadoop.yarn.federation.proto.YarnServerFederationProtos$SubClusterPolicyConfigurationProto$Builder	setQueue	queue_	J	java.lang.Object	0	org.apache.hadoop.yarn.federation.proto.YarnServerFederationProtos$SubClusterPolicyConfigurationProto$Builder:setQueue(java.lang.String)
org.apache.hadoop.yarn.federation.proto.YarnServerFederationProtos$SubClusterPolicyConfigurationProto$Builder	setQueueBytes	queue_	J	java.lang.Object	0	org.apache.hadoop.yarn.federation.proto.YarnServerFederationProtos$SubClusterPolicyConfigurationProto$Builder:setQueueBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.federation.proto.YarnServerFederationProtos$SubClusterPolicyConfigurationProto$Builder	setType	type_	J	java.lang.Object	0	org.apache.hadoop.yarn.federation.proto.YarnServerFederationProtos$SubClusterPolicyConfigurationProto$Builder:setType(java.lang.String)
org.apache.hadoop.yarn.federation.proto.YarnServerFederationProtos$SubClusterPolicyConfigurationProto$Builder	setTypeBytes	type_	J	java.lang.Object	0	org.apache.hadoop.yarn.federation.proto.YarnServerFederationProtos$SubClusterPolicyConfigurationProto$Builder:setTypeBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.federation.proto.YarnServerFederationProtos$SubClusterPolicyConfigurationProto$Builder	setParams	params_	C	org.apache.hadoop.thirdparty.protobuf.ByteString	0	org.apache.hadoop.yarn.federation.proto.YarnServerFederationProtos$SubClusterPolicyConfigurationProto$Builder:setParams(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.federation.proto.YarnServerFederationProtos$SubClusterHeartbeatRequestProto$Builder	setLastHeartBeat	lastHeartBeat_	J	long	0	org.apache.hadoop.yarn.federation.proto.YarnServerFederationProtos$SubClusterHeartbeatRequestProto$Builder:setLastHeartBeat(long)
org.apache.hadoop.yarn.federation.proto.YarnServerFederationProtos$SubClusterHeartbeatRequestProto$Builder	setCapability	capability_	J	java.lang.Object	0	org.apache.hadoop.yarn.federation.proto.YarnServerFederationProtos$SubClusterHeartbeatRequestProto$Builder:setCapability(java.lang.String)
org.apache.hadoop.yarn.federation.proto.YarnServerFederationProtos$SubClusterHeartbeatRequestProto$Builder	setCapabilityBytes	capability_	J	java.lang.Object	0	org.apache.hadoop.yarn.federation.proto.YarnServerFederationProtos$SubClusterHeartbeatRequestProto$Builder:setCapabilityBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.federation.proto.YarnServerFederationProtos$SubClusterIdProto$Builder	setId	id_	J	java.lang.Object	0	org.apache.hadoop.yarn.federation.proto.YarnServerFederationProtos$SubClusterIdProto$Builder:setId(java.lang.String)
org.apache.hadoop.yarn.federation.proto.YarnServerFederationProtos$SubClusterIdProto$Builder	setIdBytes	id_	J	java.lang.Object	0	org.apache.hadoop.yarn.federation.proto.YarnServerFederationProtos$SubClusterIdProto$Builder:setIdBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.federation.proto.YarnServerFederationProtos$GetSubClustersInfoRequestProto$Builder	setFilterInactiveSubclusters	filterInactiveSubclusters_	J	boolean	0	org.apache.hadoop.yarn.federation.proto.YarnServerFederationProtos$GetSubClustersInfoRequestProto$Builder:setFilterInactiveSubclusters(boolean)
org.apache.hadoop.yarn.federation.proto.YarnServerFederationProtos$GetSubClusterPolicyConfigurationRequestProto$Builder	setQueue	queue_	J	java.lang.Object	0	org.apache.hadoop.yarn.federation.proto.YarnServerFederationProtos$GetSubClusterPolicyConfigurationRequestProto$Builder:setQueue(java.lang.String)
org.apache.hadoop.yarn.federation.proto.YarnServerFederationProtos$GetSubClusterPolicyConfigurationRequestProto$Builder	setQueueBytes	queue_	J	java.lang.Object	0	org.apache.hadoop.yarn.federation.proto.YarnServerFederationProtos$GetSubClusterPolicyConfigurationRequestProto$Builder:setQueueBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.federation.proto.YarnServerFederationProtos$SubClusterInfoProto$Builder	setAMRMServiceAddress	aMRMServiceAddress_	J	java.lang.Object	0	org.apache.hadoop.yarn.federation.proto.YarnServerFederationProtos$SubClusterInfoProto$Builder:setAMRMServiceAddress(java.lang.String)
org.apache.hadoop.yarn.federation.proto.YarnServerFederationProtos$SubClusterInfoProto$Builder	setAMRMServiceAddressBytes	aMRMServiceAddress_	J	java.lang.Object	0	org.apache.hadoop.yarn.federation.proto.YarnServerFederationProtos$SubClusterInfoProto$Builder:setAMRMServiceAddressBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.federation.proto.YarnServerFederationProtos$SubClusterInfoProto$Builder	setClientRMServiceAddress	clientRMServiceAddress_	J	java.lang.Object	0	org.apache.hadoop.yarn.federation.proto.YarnServerFederationProtos$SubClusterInfoProto$Builder:setClientRMServiceAddress(java.lang.String)
org.apache.hadoop.yarn.federation.proto.YarnServerFederationProtos$SubClusterInfoProto$Builder	setClientRMServiceAddressBytes	clientRMServiceAddress_	J	java.lang.Object	0	org.apache.hadoop.yarn.federation.proto.YarnServerFederationProtos$SubClusterInfoProto$Builder:setClientRMServiceAddressBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.federation.proto.YarnServerFederationProtos$SubClusterInfoProto$Builder	setRMAdminServiceAddress	rMAdminServiceAddress_	J	java.lang.Object	0	org.apache.hadoop.yarn.federation.proto.YarnServerFederationProtos$SubClusterInfoProto$Builder:setRMAdminServiceAddress(java.lang.String)
org.apache.hadoop.yarn.federation.proto.YarnServerFederationProtos$SubClusterInfoProto$Builder	setRMAdminServiceAddressBytes	rMAdminServiceAddress_	J	java.lang.Object	0	org.apache.hadoop.yarn.federation.proto.YarnServerFederationProtos$SubClusterInfoProto$Builder:setRMAdminServiceAddressBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.federation.proto.YarnServerFederationProtos$SubClusterInfoProto$Builder	setRMWebServiceAddress	rMWebServiceAddress_	J	java.lang.Object	0	org.apache.hadoop.yarn.federation.proto.YarnServerFederationProtos$SubClusterInfoProto$Builder:setRMWebServiceAddress(java.lang.String)
org.apache.hadoop.yarn.federation.proto.YarnServerFederationProtos$SubClusterInfoProto$Builder	setRMWebServiceAddressBytes	rMWebServiceAddress_	J	java.lang.Object	0	org.apache.hadoop.yarn.federation.proto.YarnServerFederationProtos$SubClusterInfoProto$Builder:setRMWebServiceAddressBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.federation.proto.YarnServerFederationProtos$SubClusterInfoProto$Builder	setLastHeartBeat	lastHeartBeat_	J	long	0	org.apache.hadoop.yarn.federation.proto.YarnServerFederationProtos$SubClusterInfoProto$Builder:setLastHeartBeat(long)
org.apache.hadoop.yarn.federation.proto.YarnServerFederationProtos$SubClusterInfoProto$Builder	setLastStartTime	lastStartTime_	J	long	0	org.apache.hadoop.yarn.federation.proto.YarnServerFederationProtos$SubClusterInfoProto$Builder:setLastStartTime(long)
org.apache.hadoop.yarn.federation.proto.YarnServerFederationProtos$SubClusterInfoProto$Builder	setCapability	capability_	J	java.lang.Object	0	org.apache.hadoop.yarn.federation.proto.YarnServerFederationProtos$SubClusterInfoProto$Builder:setCapability(java.lang.String)
org.apache.hadoop.yarn.federation.proto.YarnServerFederationProtos$SubClusterInfoProto$Builder	setCapabilityBytes	capability_	J	java.lang.Object	0	org.apache.hadoop.yarn.federation.proto.YarnServerFederationProtos$SubClusterInfoProto$Builder:setCapabilityBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnServerCommonProtos$MasterKeyProto$Builder	setKeyId	keyId_	J	int	0	org.apache.hadoop.yarn.proto.YarnServerCommonProtos$MasterKeyProto$Builder:setKeyId(int)
org.apache.hadoop.yarn.proto.YarnServerCommonProtos$MasterKeyProto$Builder	setBytes	bytes_	C	org.apache.hadoop.thirdparty.protobuf.ByteString	0	org.apache.hadoop.yarn.proto.YarnServerCommonProtos$MasterKeyProto$Builder:setBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$RemoteNodeProto$Builder	setHttpAddress	httpAddress_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$RemoteNodeProto$Builder:setHttpAddress(java.lang.String)
org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$RemoteNodeProto$Builder	setHttpAddressBytes	httpAddress_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$RemoteNodeProto$Builder:setHttpAddressBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$RemoteNodeProto$Builder	setRackName	rackName_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$RemoteNodeProto$Builder:setRackName(java.lang.String)
org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$RemoteNodeProto$Builder	setRackNameBytes	rackName_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$RemoteNodeProto$Builder:setRackNameBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$RemoteNodeProto$Builder	setNodePartition	nodePartition_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$RemoteNodeProto$Builder:setNodePartition(java.lang.String)
org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$RemoteNodeProto$Builder	setNodePartitionBytes	nodePartition_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$RemoteNodeProto$Builder:setNodePartitionBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$SCMUploaderNotifyResponseProto$Builder	setAccepted	accepted_	J	boolean	0	org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$SCMUploaderNotifyResponseProto$Builder:setAccepted(boolean)
org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$NMContainerStatusProto$Builder	setDiagnostics	diagnostics_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$NMContainerStatusProto$Builder:setDiagnostics(java.lang.String)
org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$NMContainerStatusProto$Builder	setDiagnosticsBytes	diagnostics_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$NMContainerStatusProto$Builder:setDiagnosticsBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$NMContainerStatusProto$Builder	setContainerExitStatus	containerExitStatus_	J	int	0	org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$NMContainerStatusProto$Builder:setContainerExitStatus(int)
org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$NMContainerStatusProto$Builder	setCreationTime	creationTime_	J	long	0	org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$NMContainerStatusProto$Builder:setCreationTime(long)
org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$NMContainerStatusProto$Builder	setNodeLabelExpression	nodeLabelExpression_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$NMContainerStatusProto$Builder:setNodeLabelExpression(java.lang.String)
org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$NMContainerStatusProto$Builder	setNodeLabelExpressionBytes	nodeLabelExpression_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$NMContainerStatusProto$Builder:setNodeLabelExpressionBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$NMContainerStatusProto$Builder	setVersion	version_	J	int	0	org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$NMContainerStatusProto$Builder:setVersion(int)
org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$NMContainerStatusProto$Builder	setAllocationRequestId	allocationRequestId_	J	long	0	org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$NMContainerStatusProto$Builder:setAllocationRequestId(long)
org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$SCMUploaderCanUploadResponseProto$Builder	setUploadable	uploadable_	J	boolean	0	org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$SCMUploaderCanUploadResponseProto$Builder:setUploadable(boolean)
org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$NodeHeartbeatResponseProto$Builder	setResponseId	responseId_	J	int	0	org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$NodeHeartbeatResponseProto$Builder:setResponseId(int)
org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$NodeHeartbeatResponseProto$Builder	setNextHeartBeatInterval	nextHeartBeatInterval_	J	long	0	org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$NodeHeartbeatResponseProto$Builder:setNextHeartBeatInterval(long)
org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$NodeHeartbeatResponseProto$Builder	setDiagnosticsMessage	diagnosticsMessage_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$NodeHeartbeatResponseProto$Builder:setDiagnosticsMessage(java.lang.String)
org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$NodeHeartbeatResponseProto$Builder	setDiagnosticsMessageBytes	diagnosticsMessage_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$NodeHeartbeatResponseProto$Builder:setDiagnosticsMessageBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$NodeHeartbeatResponseProto$Builder	setAreNodeLabelsAcceptedByRM	areNodeLabelsAcceptedByRM_	J	boolean	0	org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$NodeHeartbeatResponseProto$Builder:setAreNodeLabelsAcceptedByRM(boolean)
org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$NodeHeartbeatResponseProto$Builder	setAreNodeAttributesAcceptedByRM	areNodeAttributesAcceptedByRM_	J	boolean	0	org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$NodeHeartbeatResponseProto$Builder:setAreNodeAttributesAcceptedByRM(boolean)
org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$NodeHeartbeatResponseProto$Builder	setTokenSequenceNo	tokenSequenceNo_	J	long	0	org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$NodeHeartbeatResponseProto$Builder:setTokenSequenceNo(long)
org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$RegisterNodeManagerRequestProto$Builder	setHttpPort	httpPort_	J	int	0	org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$RegisterNodeManagerRequestProto$Builder:setHttpPort(int)
org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$RegisterNodeManagerRequestProto$Builder	setNmVersion	nmVersion_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$RegisterNodeManagerRequestProto$Builder:setNmVersion(java.lang.String)
org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$RegisterNodeManagerRequestProto$Builder	setNmVersionBytes	nmVersion_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$RegisterNodeManagerRequestProto$Builder:setNmVersionBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$RegisterNodeManagerResponseProto$Builder	setRmIdentifier	rmIdentifier_	J	long	0	org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$RegisterNodeManagerResponseProto$Builder:setRmIdentifier(long)
org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$RegisterNodeManagerResponseProto$Builder	setDiagnosticsMessage	diagnosticsMessage_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$RegisterNodeManagerResponseProto$Builder:setDiagnosticsMessage(java.lang.String)
org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$RegisterNodeManagerResponseProto$Builder	setDiagnosticsMessageBytes	diagnosticsMessage_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$RegisterNodeManagerResponseProto$Builder:setDiagnosticsMessageBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$RegisterNodeManagerResponseProto$Builder	setRmVersion	rmVersion_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$RegisterNodeManagerResponseProto$Builder:setRmVersion(java.lang.String)
org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$RegisterNodeManagerResponseProto$Builder	setRmVersionBytes	rmVersion_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$RegisterNodeManagerResponseProto$Builder:setRmVersionBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$RegisterNodeManagerResponseProto$Builder	setAreNodeLabelsAcceptedByRM	areNodeLabelsAcceptedByRM_	J	boolean	0	org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$RegisterNodeManagerResponseProto$Builder:setAreNodeLabelsAcceptedByRM(boolean)
org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$RegisterNodeManagerResponseProto$Builder	setAreNodeAttributesAcceptedByRM	areNodeAttributesAcceptedByRM_	J	boolean	0	org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$RegisterNodeManagerResponseProto$Builder:setAreNodeAttributesAcceptedByRM(boolean)
org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$RegisterDistributedSchedulingAMResponseProto$Builder	setContainerTokenExpiryInterval	containerTokenExpiryInterval_	J	int	0	org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$RegisterDistributedSchedulingAMResponseProto$Builder:setContainerTokenExpiryInterval(int)
org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$RegisterDistributedSchedulingAMResponseProto$Builder	setContainerIdStart	containerIdStart_	J	long	0	org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$RegisterDistributedSchedulingAMResponseProto$Builder:setContainerIdStart(long)
org.apache.hadoop.yarn.proto.YarnServerCommonProtos$VersionProto$Builder	setMajorVersion	majorVersion_	J	int	0	org.apache.hadoop.yarn.proto.YarnServerCommonProtos$VersionProto$Builder:setMajorVersion(int)
org.apache.hadoop.yarn.proto.YarnServerCommonProtos$VersionProto$Builder	setMinorVersion	minorVersion_	J	int	0	org.apache.hadoop.yarn.proto.YarnServerCommonProtos$VersionProto$Builder:setMinorVersion(int)
org.apache.hadoop.yarn.proto.YarnServerCommonProtos$NodeStatusProto$Builder	setResponseId	responseId_	J	int	0	org.apache.hadoop.yarn.proto.YarnServerCommonProtos$NodeStatusProto$Builder:setResponseId(int)
org.apache.hadoop.yarn.proto.YarnServerCommonProtos$OpportunisticContainersStatusProto$Builder	setRunningOpportContainers	runningOpportContainers_	J	int	0	org.apache.hadoop.yarn.proto.YarnServerCommonProtos$OpportunisticContainersStatusProto$Builder:setRunningOpportContainers(int)
org.apache.hadoop.yarn.proto.YarnServerCommonProtos$OpportunisticContainersStatusProto$Builder	setOpportMemoryUsed	opportMemoryUsed_	J	long	0	org.apache.hadoop.yarn.proto.YarnServerCommonProtos$OpportunisticContainersStatusProto$Builder:setOpportMemoryUsed(long)
org.apache.hadoop.yarn.proto.YarnServerCommonProtos$OpportunisticContainersStatusProto$Builder	setOpportCoresUsed	opportCoresUsed_	J	int	0	org.apache.hadoop.yarn.proto.YarnServerCommonProtos$OpportunisticContainersStatusProto$Builder:setOpportCoresUsed(int)
org.apache.hadoop.yarn.proto.YarnServerCommonProtos$OpportunisticContainersStatusProto$Builder	setQueuedOpportContainers	queuedOpportContainers_	J	int	0	org.apache.hadoop.yarn.proto.YarnServerCommonProtos$OpportunisticContainersStatusProto$Builder:setQueuedOpportContainers(int)
org.apache.hadoop.yarn.proto.YarnServerCommonProtos$OpportunisticContainersStatusProto$Builder	setWaitQueueLength	waitQueueLength_	J	int	0	org.apache.hadoop.yarn.proto.YarnServerCommonProtos$OpportunisticContainersStatusProto$Builder:setWaitQueueLength(int)
org.apache.hadoop.yarn.proto.YarnServerCommonProtos$OpportunisticContainersStatusProto$Builder	setEstimatedQueueWaitTime	estimatedQueueWaitTime_	J	int	0	org.apache.hadoop.yarn.proto.YarnServerCommonProtos$OpportunisticContainersStatusProto$Builder:setEstimatedQueueWaitTime(int)
org.apache.hadoop.yarn.proto.YarnServerCommonProtos$OpportunisticContainersStatusProto$Builder	setOpportQueueCapacity	opportQueueCapacity_	J	int	0	org.apache.hadoop.yarn.proto.YarnServerCommonProtos$OpportunisticContainersStatusProto$Builder:setOpportQueueCapacity(int)
org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$NodeHeartbeatRequestProto$Builder	setTokenSequenceNo	tokenSequenceNo_	J	long	0	org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$NodeHeartbeatRequestProto$Builder:setTokenSequenceNo(long)
org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$AppCollectorDataProto$Builder	setAppCollectorAddr	appCollectorAddr_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$AppCollectorDataProto$Builder:setAppCollectorAddr(java.lang.String)
org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$AppCollectorDataProto$Builder	setAppCollectorAddrBytes	appCollectorAddr_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$AppCollectorDataProto$Builder:setAppCollectorAddrBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$AppCollectorDataProto$Builder	setRmIdentifier	rmIdentifier_	J	long	0	org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$AppCollectorDataProto$Builder:setRmIdentifier(long)
org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$AppCollectorDataProto$Builder	setVersion	version_	J	long	0	org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$AppCollectorDataProto$Builder:setVersion(long)
org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$SCMUploaderCanUploadRequestProto$Builder	setResourceKey	resourceKey_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$SCMUploaderCanUploadRequestProto$Builder:setResourceKey(java.lang.String)
org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$SCMUploaderCanUploadRequestProto$Builder	setResourceKeyBytes	resourceKey_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$SCMUploaderCanUploadRequestProto$Builder:setResourceKeyBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$SystemCredentialsForAppsProto$Builder	setCredentialsForApp	credentialsForApp_	C	org.apache.hadoop.thirdparty.protobuf.ByteString	0	org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$SystemCredentialsForAppsProto$Builder:setCredentialsForApp(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$GetTimelineCollectorContextResponseProto$Builder	setUserId	userId_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$GetTimelineCollectorContextResponseProto$Builder:setUserId(java.lang.String)
org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$GetTimelineCollectorContextResponseProto$Builder	setUserIdBytes	userId_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$GetTimelineCollectorContextResponseProto$Builder:setUserIdBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$GetTimelineCollectorContextResponseProto$Builder	setFlowName	flowName_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$GetTimelineCollectorContextResponseProto$Builder:setFlowName(java.lang.String)
org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$GetTimelineCollectorContextResponseProto$Builder	setFlowNameBytes	flowName_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$GetTimelineCollectorContextResponseProto$Builder:setFlowNameBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$GetTimelineCollectorContextResponseProto$Builder	setFlowVersion	flowVersion_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$GetTimelineCollectorContextResponseProto$Builder:setFlowVersion(java.lang.String)
org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$GetTimelineCollectorContextResponseProto$Builder	setFlowVersionBytes	flowVersion_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$GetTimelineCollectorContextResponseProto$Builder:setFlowVersionBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$GetTimelineCollectorContextResponseProto$Builder	setFlowRunId	flowRunId_	J	long	0	org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$GetTimelineCollectorContextResponseProto$Builder:setFlowRunId(long)
org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$LogAggregationReportProto$Builder	setDiagnostics	diagnostics_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$LogAggregationReportProto$Builder:setDiagnostics(java.lang.String)
org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$LogAggregationReportProto$Builder	setDiagnosticsBytes	diagnostics_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$LogAggregationReportProto$Builder:setDiagnosticsBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnServerCommonProtos$NodeHealthStatusProto$Builder	setIsNodeHealthy	isNodeHealthy_	J	boolean	0	org.apache.hadoop.yarn.proto.YarnServerCommonProtos$NodeHealthStatusProto$Builder:setIsNodeHealthy(boolean)
org.apache.hadoop.yarn.proto.YarnServerCommonProtos$NodeHealthStatusProto$Builder	setHealthReport	healthReport_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServerCommonProtos$NodeHealthStatusProto$Builder:setHealthReport(java.lang.String)
org.apache.hadoop.yarn.proto.YarnServerCommonProtos$NodeHealthStatusProto$Builder	setHealthReportBytes	healthReport_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServerCommonProtos$NodeHealthStatusProto$Builder:setHealthReportBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnServerCommonProtos$NodeHealthStatusProto$Builder	setLastHealthReportTime	lastHealthReportTime_	J	long	0	org.apache.hadoop.yarn.proto.YarnServerCommonProtos$NodeHealthStatusProto$Builder:setLastHealthReportTime(long)
org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$SCMUploaderNotifyRequestProto$Builder	setResourceKey	resourceKey_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$SCMUploaderNotifyRequestProto$Builder:setResourceKey(java.lang.String)
org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$SCMUploaderNotifyRequestProto$Builder	setResourceKeyBytes	resourceKey_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$SCMUploaderNotifyRequestProto$Builder:setResourceKeyBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$SCMUploaderNotifyRequestProto$Builder	setFilename	filename_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$SCMUploaderNotifyRequestProto$Builder:setFilename(java.lang.String)
org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$SCMUploaderNotifyRequestProto$Builder	setFilenameBytes	filename_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$SCMUploaderNotifyRequestProto$Builder:setFilenameBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$ContainerQueuingLimitProto$Builder	setMaxQueueLength	maxQueueLength_	J	int	0	org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$ContainerQueuingLimitProto$Builder:setMaxQueueLength(int)
org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$ContainerQueuingLimitProto$Builder	setMaxQueueWaitTimeInMs	maxQueueWaitTimeInMs_	J	int	0	org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos$ContainerQueuingLimitProto$Builder:setMaxQueueWaitTimeInMs(int)
org.apache.hadoop.yarn.server.AMHeartbeatRequestHandler	setUGI	userUgi	C	org.apache.hadoop.security.UserGroupInformation	0	org.apache.hadoop.yarn.server.AMHeartbeatRequestHandler:setUGI(org.apache.hadoop.security.UserGroupInformation)
org.apache.hadoop.yarn.server.volume.csi.VolumeMetaData	setVolumeId	volumeId	C	org.apache.hadoop.yarn.server.volume.csi.VolumeId	0	org.apache.hadoop.yarn.server.volume.csi.VolumeMetaData:setVolumeId(org.apache.hadoop.yarn.server.volume.csi.VolumeId)
org.apache.hadoop.yarn.server.volume.csi.VolumeMetaData	setVolumeName	volumeName	J	java.lang.String	0	org.apache.hadoop.yarn.server.volume.csi.VolumeMetaData:setVolumeName(java.lang.String)
org.apache.hadoop.yarn.server.volume.csi.VolumeMetaData	setVolumeCapabilityRange	volumeCapabilityRange	C	org.apache.hadoop.yarn.server.volume.csi.VolumeCapabilityRange	0	org.apache.hadoop.yarn.server.volume.csi.VolumeMetaData:setVolumeCapabilityRange(org.apache.hadoop.yarn.server.volume.csi.VolumeCapabilityRange)
org.apache.hadoop.yarn.server.volume.csi.VolumeMetaData	setDriverName	driverName	J	java.lang.String	0	org.apache.hadoop.yarn.server.volume.csi.VolumeMetaData:setDriverName(java.lang.String)
org.apache.hadoop.yarn.server.volume.csi.VolumeMetaData	setMountPoint	mountPoint	J	java.lang.String	0	org.apache.hadoop.yarn.server.volume.csi.VolumeMetaData:setMountPoint(java.lang.String)
org.apache.hadoop.yarn.server.federation.policies.FederationPolicyInitializationContext	setSubClusterPolicyConfiguration	federationPolicyConfiguration	C	org.apache.hadoop.yarn.server.federation.store.records.SubClusterPolicyConfiguration	0	org.apache.hadoop.yarn.server.federation.policies.FederationPolicyInitializationContext:setSubClusterPolicyConfiguration(org.apache.hadoop.yarn.server.federation.store.records.SubClusterPolicyConfiguration)
org.apache.hadoop.yarn.server.federation.policies.FederationPolicyInitializationContext	setFederationSubclusterResolver	federationSubclusterResolver	C	org.apache.hadoop.yarn.server.federation.resolver.SubClusterResolver	0	org.apache.hadoop.yarn.server.federation.policies.FederationPolicyInitializationContext:setFederationSubclusterResolver(org.apache.hadoop.yarn.server.federation.resolver.SubClusterResolver)
org.apache.hadoop.yarn.server.federation.policies.FederationPolicyInitializationContext	setFederationStateStoreFacade	federationStateStoreFacade	C	org.apache.hadoop.yarn.server.federation.utils.FederationStateStoreFacade	0	org.apache.hadoop.yarn.server.federation.policies.FederationPolicyInitializationContext:setFederationStateStoreFacade(org.apache.hadoop.yarn.server.federation.utils.FederationStateStoreFacade)
org.apache.hadoop.yarn.server.federation.policies.FederationPolicyInitializationContext	setHomeSubcluster	homeSubcluster	C	org.apache.hadoop.yarn.server.federation.store.records.SubClusterId	0	org.apache.hadoop.yarn.server.federation.policies.FederationPolicyInitializationContext:setHomeSubcluster(org.apache.hadoop.yarn.server.federation.store.records.SubClusterId)
org.apache.hadoop.yarn.server.federation.policies.manager.AbstractPolicyManager	setQueue	queue	J	java.lang.String	0	org.apache.hadoop.yarn.server.federation.policies.manager.AbstractPolicyManager:setQueue(java.lang.String)
org.apache.hadoop.yarn.server.federation.policies.manager.WeightedLocalityPolicyManager	setWeightedPolicyInfo	weightedPolicyInfo	C	org.apache.hadoop.yarn.server.federation.policies.dao.WeightedPolicyInfo	0	org.apache.hadoop.yarn.server.federation.policies.manager.WeightedLocalityPolicyManager:setWeightedPolicyInfo(org.apache.hadoop.yarn.server.federation.policies.dao.WeightedPolicyInfo)
org.apache.hadoop.yarn.server.federation.policies.manager.PriorityBroadcastPolicyManager	setWeightedPolicyInfo	weightedPolicyInfo	C	org.apache.hadoop.yarn.server.federation.policies.dao.WeightedPolicyInfo	0	org.apache.hadoop.yarn.server.federation.policies.manager.PriorityBroadcastPolicyManager:setWeightedPolicyInfo(org.apache.hadoop.yarn.server.federation.policies.dao.WeightedPolicyInfo)
org.apache.hadoop.yarn.server.federation.policies.dao.WeightedPolicyInfo	setRouterPolicyWeights	routerPolicyWeights	GC	java.util.Map	0	org.apache.hadoop.yarn.server.federation.policies.dao.WeightedPolicyInfo:setRouterPolicyWeights(java.util.Map)
org.apache.hadoop.yarn.server.federation.policies.dao.WeightedPolicyInfo	setAMRMPolicyWeights	amrmPolicyWeights	GC	java.util.Map	0	org.apache.hadoop.yarn.server.federation.policies.dao.WeightedPolicyInfo:setAMRMPolicyWeights(java.util.Map)
org.apache.hadoop.yarn.server.federation.policies.dao.WeightedPolicyInfo	setHeadroomAlpha	headroomAlpha	J	float	0	org.apache.hadoop.yarn.server.federation.policies.dao.WeightedPolicyInfo:setHeadroomAlpha(float)
org.apache.hadoop.yarn.server.federation.policies.AbstractConfigurableFederationPolicy	setPolicyInfo	policyInfo	C	org.apache.hadoop.yarn.server.federation.policies.dao.WeightedPolicyInfo	0	org.apache.hadoop.yarn.server.federation.policies.AbstractConfigurableFederationPolicy:setPolicyInfo(org.apache.hadoop.yarn.server.federation.policies.dao.WeightedPolicyInfo)
org.apache.hadoop.yarn.server.federation.policies.AbstractConfigurableFederationPolicy	setPolicyContext	policyContext	C	org.apache.hadoop.yarn.server.federation.policies.FederationPolicyInitializationContext	0	org.apache.hadoop.yarn.server.federation.policies.AbstractConfigurableFederationPolicy:setPolicyContext(org.apache.hadoop.yarn.server.federation.policies.FederationPolicyInitializationContext)
org.apache.hadoop.yarn.server.federation.resolver.DefaultSubClusterResolverImpl	setConf	conf	C	org.apache.hadoop.conf.Configuration	0	org.apache.hadoop.yarn.server.federation.resolver.DefaultSubClusterResolverImpl:setConf(org.apache.hadoop.conf.Configuration)
org.apache.hadoop.yarn.server.federation.store.records.impl.pb.SubClusterHeartbeatRequestPBImpl	setSubClusterId	subClusterId	C	org.apache.hadoop.yarn.server.federation.store.records.SubClusterId	0	org.apache.hadoop.yarn.server.federation.store.records.impl.pb.SubClusterHeartbeatRequestPBImpl:setSubClusterId(org.apache.hadoop.yarn.server.federation.store.records.SubClusterId)
org.apache.hadoop.yarn.server.federation.store.records.impl.pb.SetSubClusterPolicyConfigurationRequestPBImpl	setPolicyConfiguration	subClusterPolicy	C	org.apache.hadoop.yarn.server.federation.store.records.SubClusterPolicyConfiguration	0	org.apache.hadoop.yarn.server.federation.store.records.impl.pb.SetSubClusterPolicyConfigurationRequestPBImpl:setPolicyConfiguration(org.apache.hadoop.yarn.server.federation.store.records.SubClusterPolicyConfiguration)
org.apache.hadoop.yarn.server.federation.store.records.impl.pb.GetSubClusterInfoResponsePBImpl	setSubClusterInfo	subClusterInfo	C	org.apache.hadoop.yarn.server.federation.store.records.SubClusterInfo	0	org.apache.hadoop.yarn.server.federation.store.records.impl.pb.GetSubClusterInfoResponsePBImpl:setSubClusterInfo(org.apache.hadoop.yarn.server.federation.store.records.SubClusterInfo)
org.apache.hadoop.yarn.server.federation.store.records.impl.pb.ApplicationHomeSubClusterPBImpl	setApplicationId	applicationId	C	org.apache.hadoop.yarn.api.records.ApplicationId	0	org.apache.hadoop.yarn.server.federation.store.records.impl.pb.ApplicationHomeSubClusterPBImpl:setApplicationId(org.apache.hadoop.yarn.api.records.ApplicationId)
org.apache.hadoop.yarn.server.federation.store.records.impl.pb.ApplicationHomeSubClusterPBImpl	setHomeSubCluster	homeSubCluster	C	org.apache.hadoop.yarn.server.federation.store.records.SubClusterId	0	org.apache.hadoop.yarn.server.federation.store.records.impl.pb.ApplicationHomeSubClusterPBImpl:setHomeSubCluster(org.apache.hadoop.yarn.server.federation.store.records.SubClusterId)
org.apache.hadoop.yarn.server.federation.store.records.impl.pb.GetApplicationsHomeSubClusterResponsePBImpl	setAppsHomeSubClusters	appsHomeSubCluster	GC	java.util.List	0	org.apache.hadoop.yarn.server.federation.store.records.impl.pb.GetApplicationsHomeSubClusterResponsePBImpl:setAppsHomeSubClusters(java.util.List)
org.apache.hadoop.yarn.server.federation.store.records.impl.pb.GetSubClusterPoliciesConfigurationsResponsePBImpl	setPoliciesConfigs	subClusterPolicies	GC	java.util.List	0	org.apache.hadoop.yarn.server.federation.store.records.impl.pb.GetSubClusterPoliciesConfigurationsResponsePBImpl:setPoliciesConfigs(java.util.List)
org.apache.hadoop.yarn.server.federation.store.records.impl.pb.GetApplicationHomeSubClusterRequestPBImpl	setApplicationId	applicationId	C	org.apache.hadoop.yarn.api.records.ApplicationId	0	org.apache.hadoop.yarn.server.federation.store.records.impl.pb.GetApplicationHomeSubClusterRequestPBImpl:setApplicationId(org.apache.hadoop.yarn.api.records.ApplicationId)
org.apache.hadoop.yarn.server.federation.store.records.impl.pb.GetSubClustersInfoResponsePBImpl	setSubClusters	subClusterInfos	GC	java.util.List	0	org.apache.hadoop.yarn.server.federation.store.records.impl.pb.GetSubClustersInfoResponsePBImpl:setSubClusters(java.util.List)
org.apache.hadoop.yarn.server.federation.store.records.impl.pb.GetSubClusterPolicyConfigurationResponsePBImpl	setPolicyConfiguration	subClusterPolicy	C	org.apache.hadoop.yarn.server.federation.store.records.SubClusterPolicyConfiguration	0	org.apache.hadoop.yarn.server.federation.store.records.impl.pb.GetSubClusterPolicyConfigurationResponsePBImpl:setPolicyConfiguration(org.apache.hadoop.yarn.server.federation.store.records.SubClusterPolicyConfiguration)
org.apache.hadoop.yarn.server.federation.store.records.impl.pb.SubClusterInfoPBImpl	setSubClusterId	subClusterId	C	org.apache.hadoop.yarn.server.federation.store.records.SubClusterId	0	org.apache.hadoop.yarn.server.federation.store.records.impl.pb.SubClusterInfoPBImpl:setSubClusterId(org.apache.hadoop.yarn.server.federation.store.records.SubClusterId)
org.apache.hadoop.yarn.server.federation.store.records.impl.pb.SubClusterRegisterRequestPBImpl	setSubClusterInfo	subClusterInfo	C	org.apache.hadoop.yarn.server.federation.store.records.SubClusterInfo	0	org.apache.hadoop.yarn.server.federation.store.records.impl.pb.SubClusterRegisterRequestPBImpl:setSubClusterInfo(org.apache.hadoop.yarn.server.federation.store.records.SubClusterInfo)
org.apache.hadoop.yarn.server.AMRMClientRelayer	setAMRegistrationRequest	amRegistrationRequest	C	org.apache.hadoop.yarn.api.protocolrecords.RegisterApplicationMasterRequest	0	org.apache.hadoop.yarn.server.AMRMClientRelayer:setAMRegistrationRequest(org.apache.hadoop.yarn.api.protocolrecords.RegisterApplicationMasterRequest)
org.apache.hadoop.yarn.server.AMRMClientRelayer	setRMClient	rmClient	C	org.apache.hadoop.yarn.api.ApplicationMasterProtocol	0	org.apache.hadoop.yarn.server.AMRMClientRelayer:setRMClient(org.apache.hadoop.yarn.api.ApplicationMasterProtocol)
org.apache.hadoop.yarn.server.scheduler.OpportunisticContainerAllocator	setMaxAllocationsPerAMHeartbeat	maxAllocationsPerAMHeartbeat	J	int	0	org.apache.hadoop.yarn.server.scheduler.OpportunisticContainerAllocator:setMaxAllocationsPerAMHeartbeat(int)
org.apache.hadoop.yarn.server.scheduler.OpportunisticContainerContext	setContainerIdGenerator	containerIdGenerator	C	org.apache.hadoop.yarn.server.scheduler.OpportunisticContainerAllocator$ContainerIdGenerator	0	org.apache.hadoop.yarn.server.scheduler.OpportunisticContainerContext:setContainerIdGenerator(org.apache.hadoop.yarn.server.scheduler.OpportunisticContainerAllocator$ContainerIdGenerator)
org.apache.hadoop.yarn.server.scheduler.OpportunisticContainerAllocator$AllocationParams	setMaxResource	maxResource	C	org.apache.hadoop.yarn.api.records.Resource	0	org.apache.hadoop.yarn.server.scheduler.OpportunisticContainerAllocator$AllocationParams:setMaxResource(org.apache.hadoop.yarn.api.records.Resource)
org.apache.hadoop.yarn.server.scheduler.OpportunisticContainerAllocator$AllocationParams	setMinResource	minResource	C	org.apache.hadoop.yarn.api.records.Resource	0	org.apache.hadoop.yarn.server.scheduler.OpportunisticContainerAllocator$AllocationParams:setMinResource(org.apache.hadoop.yarn.api.records.Resource)
org.apache.hadoop.yarn.server.scheduler.OpportunisticContainerAllocator$AllocationParams	setIncrementResource	incrementResource	C	org.apache.hadoop.yarn.api.records.Resource	0	org.apache.hadoop.yarn.server.scheduler.OpportunisticContainerAllocator$AllocationParams:setIncrementResource(org.apache.hadoop.yarn.api.records.Resource)
org.apache.hadoop.yarn.server.scheduler.OpportunisticContainerAllocator$AllocationParams	setContainerTokenExpiryInterval	containerTokenExpiryInterval	J	int	0	org.apache.hadoop.yarn.server.scheduler.OpportunisticContainerAllocator$AllocationParams:setContainerTokenExpiryInterval(int)
org.apache.hadoop.yarn.server.scheduler.OpportunisticContainerAllocator$AllocationParams	setMaxAllocationsPerSchedulerKeyPerRound	maxAllocationsPerSchedulerKeyPerRound	J	int	0	org.apache.hadoop.yarn.server.scheduler.OpportunisticContainerAllocator$AllocationParams:setMaxAllocationsPerSchedulerKeyPerRound(int)
org.apache.hadoop.yarn.server.api.protocolrecords.impl.pb.DistributedSchedulingAllocateRequestPBImpl	setAllocateRequest	allocateRequest	C	org.apache.hadoop.yarn.api.protocolrecords.AllocateRequest	0	org.apache.hadoop.yarn.server.api.protocolrecords.impl.pb.DistributedSchedulingAllocateRequestPBImpl:setAllocateRequest(org.apache.hadoop.yarn.api.protocolrecords.AllocateRequest)
org.apache.hadoop.yarn.server.api.protocolrecords.impl.pb.RegisterNodeManagerResponsePBImpl	setResource	resource	C	org.apache.hadoop.yarn.api.records.Resource	0	org.apache.hadoop.yarn.server.api.protocolrecords.impl.pb.RegisterNodeManagerResponsePBImpl:setResource(org.apache.hadoop.yarn.api.records.Resource)
org.apache.hadoop.yarn.server.api.protocolrecords.impl.pb.RegisterNodeManagerResponsePBImpl	setContainerTokenMasterKey	containerTokenMasterKey	C	org.apache.hadoop.yarn.server.api.records.MasterKey	0	org.apache.hadoop.yarn.server.api.protocolrecords.impl.pb.RegisterNodeManagerResponsePBImpl:setContainerTokenMasterKey(org.apache.hadoop.yarn.server.api.records.MasterKey)
org.apache.hadoop.yarn.server.api.protocolrecords.impl.pb.RegisterNodeManagerResponsePBImpl	setNMTokenMasterKey	nmTokenMasterKey	C	org.apache.hadoop.yarn.server.api.records.MasterKey	0	org.apache.hadoop.yarn.server.api.protocolrecords.impl.pb.RegisterNodeManagerResponsePBImpl:setNMTokenMasterKey(org.apache.hadoop.yarn.server.api.records.MasterKey)
org.apache.hadoop.yarn.server.api.protocolrecords.impl.pb.NMContainerStatusPBImpl	setAllocatedResource	resource	C	org.apache.hadoop.yarn.api.records.Resource	0	org.apache.hadoop.yarn.server.api.protocolrecords.impl.pb.NMContainerStatusPBImpl:setAllocatedResource(org.apache.hadoop.yarn.api.records.Resource)
org.apache.hadoop.yarn.server.api.protocolrecords.impl.pb.NMContainerStatusPBImpl	setContainerId	containerId	C	org.apache.hadoop.yarn.api.records.ContainerId	0	org.apache.hadoop.yarn.server.api.protocolrecords.impl.pb.NMContainerStatusPBImpl:setContainerId(org.apache.hadoop.yarn.api.records.ContainerId)
org.apache.hadoop.yarn.server.api.protocolrecords.impl.pb.NMContainerStatusPBImpl	setPriority	priority	C	org.apache.hadoop.yarn.api.records.Priority	0	org.apache.hadoop.yarn.server.api.protocolrecords.impl.pb.NMContainerStatusPBImpl:setPriority(org.apache.hadoop.yarn.api.records.Priority)
org.apache.hadoop.yarn.server.api.protocolrecords.impl.pb.NMContainerStatusPBImpl	setAllocationTags	allocationTags	GJ	java.util.Set	0	org.apache.hadoop.yarn.server.api.protocolrecords.impl.pb.NMContainerStatusPBImpl:setAllocationTags(java.util.Set)
org.apache.hadoop.yarn.server.api.protocolrecords.impl.pb.NodeHeartbeatRequestPBImpl	setNodeStatus	nodeStatus	C	org.apache.hadoop.yarn.server.api.records.NodeStatus	0	org.apache.hadoop.yarn.server.api.protocolrecords.impl.pb.NodeHeartbeatRequestPBImpl:setNodeStatus(org.apache.hadoop.yarn.server.api.records.NodeStatus)
org.apache.hadoop.yarn.server.api.protocolrecords.impl.pb.NodeHeartbeatRequestPBImpl	setLastKnownContainerTokenMasterKey	lastKnownContainerTokenMasterKey	C	org.apache.hadoop.yarn.server.api.records.MasterKey	0	org.apache.hadoop.yarn.server.api.protocolrecords.impl.pb.NodeHeartbeatRequestPBImpl:setLastKnownContainerTokenMasterKey(org.apache.hadoop.yarn.server.api.records.MasterKey)
org.apache.hadoop.yarn.server.api.protocolrecords.impl.pb.NodeHeartbeatRequestPBImpl	setLastKnownNMTokenMasterKey	lastKnownNMTokenMasterKey	C	org.apache.hadoop.yarn.server.api.records.MasterKey	0	org.apache.hadoop.yarn.server.api.protocolrecords.impl.pb.NodeHeartbeatRequestPBImpl:setLastKnownNMTokenMasterKey(org.apache.hadoop.yarn.server.api.records.MasterKey)
org.apache.hadoop.yarn.server.api.protocolrecords.impl.pb.NodeHeartbeatRequestPBImpl	setNodeLabels	labels	GC	java.util.Set	0	org.apache.hadoop.yarn.server.api.protocolrecords.impl.pb.NodeHeartbeatRequestPBImpl:setNodeLabels(java.util.Set)
org.apache.hadoop.yarn.server.api.protocolrecords.impl.pb.NodeHeartbeatRequestPBImpl	setNodeAttributes	attributes	GC	java.util.Set	0	org.apache.hadoop.yarn.server.api.protocolrecords.impl.pb.NodeHeartbeatRequestPBImpl:setNodeAttributes(java.util.Set)
org.apache.hadoop.yarn.server.api.protocolrecords.impl.pb.NodeHeartbeatRequestPBImpl	setLogAggregationReportsForApps	logAggregationReportsForApps	GC	java.util.List	0	org.apache.hadoop.yarn.server.api.protocolrecords.impl.pb.NodeHeartbeatRequestPBImpl:setLogAggregationReportsForApps(java.util.List)
org.apache.hadoop.yarn.server.api.protocolrecords.impl.pb.DistributedSchedulingAllocateResponsePBImpl	setAllocateResponse	allocateResponse	C	org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse	0	org.apache.hadoop.yarn.server.api.protocolrecords.impl.pb.DistributedSchedulingAllocateResponsePBImpl:setAllocateResponse(org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse)
org.apache.hadoop.yarn.server.api.protocolrecords.impl.pb.GetTimelineCollectorContextRequestPBImpl	setApplicationId	appId	C	org.apache.hadoop.yarn.api.records.ApplicationId	0	org.apache.hadoop.yarn.server.api.protocolrecords.impl.pb.GetTimelineCollectorContextRequestPBImpl:setApplicationId(org.apache.hadoop.yarn.api.records.ApplicationId)
org.apache.hadoop.yarn.server.api.protocolrecords.impl.pb.LogAggregationReportPBImpl	setApplicationId	applicationId	C	org.apache.hadoop.yarn.api.records.ApplicationId	0	org.apache.hadoop.yarn.server.api.protocolrecords.impl.pb.LogAggregationReportPBImpl:setApplicationId(org.apache.hadoop.yarn.api.records.ApplicationId)
org.apache.hadoop.yarn.server.api.protocolrecords.impl.pb.ReportNewCollectorInfoRequestPBImpl	setAppCollectorsList	collectorsList	GC	java.util.List	0	org.apache.hadoop.yarn.server.api.protocolrecords.impl.pb.ReportNewCollectorInfoRequestPBImpl:setAppCollectorsList(java.util.List)
org.apache.hadoop.yarn.server.api.protocolrecords.impl.pb.RemoteNodePBImpl	setNodeId	nodeId	C	org.apache.hadoop.yarn.api.records.NodeId	0	org.apache.hadoop.yarn.server.api.protocolrecords.impl.pb.RemoteNodePBImpl:setNodeId(org.apache.hadoop.yarn.api.records.NodeId)
org.apache.hadoop.yarn.server.api.protocolrecords.impl.pb.UnRegisterNodeManagerRequestPBImpl	setNodeId	nodeId	C	org.apache.hadoop.yarn.api.records.NodeId	0	org.apache.hadoop.yarn.server.api.protocolrecords.impl.pb.UnRegisterNodeManagerRequestPBImpl:setNodeId(org.apache.hadoop.yarn.api.records.NodeId)
org.apache.hadoop.yarn.server.api.protocolrecords.impl.pb.RegisterNodeManagerRequestPBImpl	setResource	resource	C	org.apache.hadoop.yarn.api.records.Resource	0	org.apache.hadoop.yarn.server.api.protocolrecords.impl.pb.RegisterNodeManagerRequestPBImpl:setResource(org.apache.hadoop.yarn.api.records.Resource)
org.apache.hadoop.yarn.server.api.protocolrecords.impl.pb.RegisterNodeManagerRequestPBImpl	setNodeId	nodeId	C	org.apache.hadoop.yarn.api.records.NodeId	0	org.apache.hadoop.yarn.server.api.protocolrecords.impl.pb.RegisterNodeManagerRequestPBImpl:setNodeId(org.apache.hadoop.yarn.api.records.NodeId)
org.apache.hadoop.yarn.server.api.protocolrecords.impl.pb.RegisterNodeManagerRequestPBImpl	setPhysicalResource	physicalResource	C	org.apache.hadoop.yarn.api.records.Resource	0	org.apache.hadoop.yarn.server.api.protocolrecords.impl.pb.RegisterNodeManagerRequestPBImpl:setPhysicalResource(org.apache.hadoop.yarn.api.records.Resource)
org.apache.hadoop.yarn.server.api.protocolrecords.impl.pb.RegisterNodeManagerRequestPBImpl	setNodeStatus	nodeStatus	C	org.apache.hadoop.yarn.server.api.records.NodeStatus	0	org.apache.hadoop.yarn.server.api.protocolrecords.impl.pb.RegisterNodeManagerRequestPBImpl:setNodeStatus(org.apache.hadoop.yarn.server.api.records.NodeStatus)
org.apache.hadoop.yarn.server.api.protocolrecords.impl.pb.RegisterNodeManagerRequestPBImpl	setNodeLabels	labels	GC	java.util.Set	0	org.apache.hadoop.yarn.server.api.protocolrecords.impl.pb.RegisterNodeManagerRequestPBImpl:setNodeLabels(java.util.Set)
org.apache.hadoop.yarn.server.api.protocolrecords.impl.pb.RegisterNodeManagerRequestPBImpl	setNodeAttributes	attributes	GC	java.util.Set	0	org.apache.hadoop.yarn.server.api.protocolrecords.impl.pb.RegisterNodeManagerRequestPBImpl:setNodeAttributes(java.util.Set)
org.apache.hadoop.yarn.server.api.protocolrecords.impl.pb.RegisterNodeManagerRequestPBImpl	setLogAggregationReportsForApps	logAggregationReportsForApps	GC	java.util.List	0	org.apache.hadoop.yarn.server.api.protocolrecords.impl.pb.RegisterNodeManagerRequestPBImpl:setLogAggregationReportsForApps(java.util.List)
org.apache.hadoop.yarn.server.api.protocolrecords.impl.pb.RegisterDistributedSchedulingAMResponsePBImpl	setRegisterResponse	registerApplicationMasterResponse	C	org.apache.hadoop.yarn.api.protocolrecords.RegisterApplicationMasterResponse	0	org.apache.hadoop.yarn.server.api.protocolrecords.impl.pb.RegisterDistributedSchedulingAMResponsePBImpl:setRegisterResponse(org.apache.hadoop.yarn.api.protocolrecords.RegisterApplicationMasterResponse)
org.apache.hadoop.yarn.server.api.protocolrecords.impl.pb.RegisterDistributedSchedulingAMResponsePBImpl	setMaxContainerResource	maxContainerResource	C	org.apache.hadoop.yarn.api.records.Resource	0	org.apache.hadoop.yarn.server.api.protocolrecords.impl.pb.RegisterDistributedSchedulingAMResponsePBImpl:setMaxContainerResource(org.apache.hadoop.yarn.api.records.Resource)
org.apache.hadoop.yarn.server.api.protocolrecords.impl.pb.RegisterDistributedSchedulingAMResponsePBImpl	setMinContainerResource	minContainerResource	C	org.apache.hadoop.yarn.api.records.Resource	0	org.apache.hadoop.yarn.server.api.protocolrecords.impl.pb.RegisterDistributedSchedulingAMResponsePBImpl:setMinContainerResource(org.apache.hadoop.yarn.api.records.Resource)
org.apache.hadoop.yarn.server.api.protocolrecords.impl.pb.RegisterDistributedSchedulingAMResponsePBImpl	setIncrContainerResource	incrContainerResource	C	org.apache.hadoop.yarn.api.records.Resource	0	org.apache.hadoop.yarn.server.api.protocolrecords.impl.pb.RegisterDistributedSchedulingAMResponsePBImpl:setIncrContainerResource(org.apache.hadoop.yarn.api.records.Resource)
org.apache.hadoop.yarn.server.api.protocolrecords.impl.pb.NodeHeartbeatResponsePBImpl	setResource	resource	C	org.apache.hadoop.yarn.api.records.Resource	0	org.apache.hadoop.yarn.server.api.protocolrecords.impl.pb.NodeHeartbeatResponsePBImpl:setResource(org.apache.hadoop.yarn.api.records.Resource)
org.apache.hadoop.yarn.server.api.protocolrecords.impl.pb.NodeHeartbeatResponsePBImpl	setContainerTokenMasterKey	containerTokenMasterKey	C	org.apache.hadoop.yarn.server.api.records.MasterKey	0	org.apache.hadoop.yarn.server.api.protocolrecords.impl.pb.NodeHeartbeatResponsePBImpl:setContainerTokenMasterKey(org.apache.hadoop.yarn.server.api.records.MasterKey)
org.apache.hadoop.yarn.server.api.protocolrecords.impl.pb.NodeHeartbeatResponsePBImpl	setNMTokenMasterKey	nmTokenMasterKey	C	org.apache.hadoop.yarn.server.api.records.MasterKey	0	org.apache.hadoop.yarn.server.api.protocolrecords.impl.pb.NodeHeartbeatResponsePBImpl:setNMTokenMasterKey(org.apache.hadoop.yarn.server.api.records.MasterKey)
org.apache.hadoop.yarn.server.api.protocolrecords.impl.pb.NodeHeartbeatResponsePBImpl	setContainerQueuingLimit	containerQueuingLimit	C	org.apache.hadoop.yarn.server.api.records.ContainerQueuingLimit	0	org.apache.hadoop.yarn.server.api.protocolrecords.impl.pb.NodeHeartbeatResponsePBImpl:setContainerQueuingLimit(org.apache.hadoop.yarn.server.api.records.ContainerQueuingLimit)
org.apache.hadoop.yarn.server.api.records.impl.pb.AppCollectorDataPBImpl	setApplicationId	appId	C	org.apache.hadoop.yarn.api.records.ApplicationId	0	org.apache.hadoop.yarn.server.api.records.impl.pb.AppCollectorDataPBImpl:setApplicationId(org.apache.hadoop.yarn.api.records.ApplicationId)
org.apache.hadoop.yarn.server.api.records.impl.pb.AppCollectorDataPBImpl	setCollectorAddr	collectorAddr	J	java.lang.String	0	org.apache.hadoop.yarn.server.api.records.impl.pb.AppCollectorDataPBImpl:setCollectorAddr(java.lang.String)
org.apache.hadoop.yarn.server.api.records.impl.pb.AppCollectorDataPBImpl	setCollectorToken	collectorToken	C	org.apache.hadoop.yarn.api.records.Token	0	org.apache.hadoop.yarn.server.api.records.impl.pb.AppCollectorDataPBImpl:setCollectorToken(org.apache.hadoop.yarn.api.records.Token)
org.apache.hadoop.yarn.server.api.records.impl.pb.NodeStatusPBImpl	setNodeId	nodeId	C	org.apache.hadoop.yarn.api.records.NodeId	0	org.apache.hadoop.yarn.server.api.records.impl.pb.NodeStatusPBImpl:setNodeId(org.apache.hadoop.yarn.api.records.NodeId)
org.apache.hadoop.yarn.server.api.records.impl.pb.NodeStatusPBImpl	setContainersStatuses	containers	GC	java.util.List	0	org.apache.hadoop.yarn.server.api.records.impl.pb.NodeStatusPBImpl:setContainersStatuses(java.util.List)
org.apache.hadoop.yarn.server.api.records.impl.pb.NodeStatusPBImpl	setKeepAliveApplications	keepAliveApplications	GC	java.util.List	0	org.apache.hadoop.yarn.server.api.records.impl.pb.NodeStatusPBImpl:setKeepAliveApplications(java.util.List)
org.apache.hadoop.yarn.server.api.records.impl.pb.NodeStatusPBImpl	setNodeHealthStatus	nodeHealthStatus	C	org.apache.hadoop.yarn.server.api.records.NodeHealthStatus	0	org.apache.hadoop.yarn.server.api.records.impl.pb.NodeStatusPBImpl:setNodeHealthStatus(org.apache.hadoop.yarn.server.api.records.NodeHealthStatus)
org.apache.hadoop.yarn.server.api.records.impl.pb.NodeStatusPBImpl	setIncreasedContainers	increasedContainers	GC	java.util.List	0	org.apache.hadoop.yarn.server.api.records.impl.pb.NodeStatusPBImpl:setIncreasedContainers(java.util.List)
org.apache.hadoop.yarn.server.webapp.WrappedLogMetaRequest$Builder	setFactory	factory	C	org.apache.hadoop.yarn.logaggregation.filecontroller.LogAggregationFileControllerFactory	0	org.apache.hadoop.yarn.server.webapp.WrappedLogMetaRequest$Builder:setFactory(org.apache.hadoop.yarn.logaggregation.filecontroller.LogAggregationFileControllerFactory)
org.apache.hadoop.yarn.server.webapp.WrappedLogMetaRequest$Builder	setApplicationId	appId	C	org.apache.hadoop.yarn.api.records.ApplicationId	0	org.apache.hadoop.yarn.server.webapp.WrappedLogMetaRequest$Builder:setApplicationId(org.apache.hadoop.yarn.api.records.ApplicationId)
org.apache.hadoop.yarn.server.webapp.WrappedLogMetaRequest$Builder	setNodeId	nodeId	J	java.lang.String	0	org.apache.hadoop.yarn.server.webapp.WrappedLogMetaRequest$Builder:setNodeId(java.lang.String)
org.apache.hadoop.yarn.server.webapp.WrappedLogMetaRequest$Builder	setAppOwner	appOwner	J	java.lang.String	0	org.apache.hadoop.yarn.server.webapp.WrappedLogMetaRequest$Builder:setAppOwner(java.lang.String)
org.apache.hadoop.yarn.server.webapp.WrappedLogMetaRequest$Builder	setApplicationAttemptId	applicationAttemptId	C	org.apache.hadoop.yarn.api.records.ApplicationAttemptId	0	org.apache.hadoop.yarn.server.webapp.WrappedLogMetaRequest$Builder:setApplicationAttemptId(org.apache.hadoop.yarn.api.records.ApplicationAttemptId)
org.apache.hadoop.yarn.proto.YarnServerNodemanagerRecoveryProtos$DeletionServiceDeleteTaskProto$Builder	setId	id_	J	int	0	org.apache.hadoop.yarn.proto.YarnServerNodemanagerRecoveryProtos$DeletionServiceDeleteTaskProto$Builder:setId(int)
org.apache.hadoop.yarn.proto.YarnServerNodemanagerRecoveryProtos$DeletionServiceDeleteTaskProto$Builder	setUser	user_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServerNodemanagerRecoveryProtos$DeletionServiceDeleteTaskProto$Builder:setUser(java.lang.String)
org.apache.hadoop.yarn.proto.YarnServerNodemanagerRecoveryProtos$DeletionServiceDeleteTaskProto$Builder	setUserBytes	user_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServerNodemanagerRecoveryProtos$DeletionServiceDeleteTaskProto$Builder:setUserBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnServerNodemanagerRecoveryProtos$DeletionServiceDeleteTaskProto$Builder	setSubdir	subdir_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServerNodemanagerRecoveryProtos$DeletionServiceDeleteTaskProto$Builder:setSubdir(java.lang.String)
org.apache.hadoop.yarn.proto.YarnServerNodemanagerRecoveryProtos$DeletionServiceDeleteTaskProto$Builder	setSubdirBytes	subdir_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServerNodemanagerRecoveryProtos$DeletionServiceDeleteTaskProto$Builder:setSubdirBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnServerNodemanagerRecoveryProtos$DeletionServiceDeleteTaskProto$Builder	setDeletionTime	deletionTime_	J	long	0	org.apache.hadoop.yarn.proto.YarnServerNodemanagerRecoveryProtos$DeletionServiceDeleteTaskProto$Builder:setDeletionTime(long)
org.apache.hadoop.yarn.proto.YarnServerNodemanagerRecoveryProtos$DeletionServiceDeleteTaskProto$Builder	setTaskType	taskType_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServerNodemanagerRecoveryProtos$DeletionServiceDeleteTaskProto$Builder:setTaskType(java.lang.String)
org.apache.hadoop.yarn.proto.YarnServerNodemanagerRecoveryProtos$DeletionServiceDeleteTaskProto$Builder	setTaskTypeBytes	taskType_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServerNodemanagerRecoveryProtos$DeletionServiceDeleteTaskProto$Builder:setTaskTypeBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnServerNodemanagerRecoveryProtos$DeletionServiceDeleteTaskProto$Builder	setDockerContainerId	dockerContainerId_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServerNodemanagerRecoveryProtos$DeletionServiceDeleteTaskProto$Builder:setDockerContainerId(java.lang.String)
org.apache.hadoop.yarn.proto.YarnServerNodemanagerRecoveryProtos$DeletionServiceDeleteTaskProto$Builder	setDockerContainerIdBytes	dockerContainerId_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServerNodemanagerRecoveryProtos$DeletionServiceDeleteTaskProto$Builder:setDockerContainerIdBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnServerNodemanagerRecoveryProtos$LogDeleterProto$Builder	setUser	user_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServerNodemanagerRecoveryProtos$LogDeleterProto$Builder:setUser(java.lang.String)
org.apache.hadoop.yarn.proto.YarnServerNodemanagerRecoveryProtos$LogDeleterProto$Builder	setUserBytes	user_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServerNodemanagerRecoveryProtos$LogDeleterProto$Builder:setUserBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnServerNodemanagerRecoveryProtos$LogDeleterProto$Builder	setDeletionTime	deletionTime_	J	long	0	org.apache.hadoop.yarn.proto.YarnServerNodemanagerRecoveryProtos$LogDeleterProto$Builder:setDeletionTime(long)
org.apache.hadoop.yarn.proto.YarnServerNodemanagerRecoveryProtos$ContainerManagerApplicationProto$Builder	setUser	user_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServerNodemanagerRecoveryProtos$ContainerManagerApplicationProto$Builder:setUser(java.lang.String)
org.apache.hadoop.yarn.proto.YarnServerNodemanagerRecoveryProtos$ContainerManagerApplicationProto$Builder	setUserBytes	user_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServerNodemanagerRecoveryProtos$ContainerManagerApplicationProto$Builder:setUserBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnServerNodemanagerRecoveryProtos$ContainerManagerApplicationProto$Builder	setCredentials	credentials_	C	org.apache.hadoop.thirdparty.protobuf.ByteString	0	org.apache.hadoop.yarn.proto.YarnServerNodemanagerRecoveryProtos$ContainerManagerApplicationProto$Builder:setCredentials(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnServerNodemanagerRecoveryProtos$ContainerManagerApplicationProto$Builder	setAppLogAggregationInitedTime	appLogAggregationInitedTime_	J	long	0	org.apache.hadoop.yarn.proto.YarnServerNodemanagerRecoveryProtos$ContainerManagerApplicationProto$Builder:setAppLogAggregationInitedTime(long)
org.apache.hadoop.yarn.proto.YarnServerNodemanagerServiceProtos$LocalResourceStatusProto$Builder	setLocalSize	localSize_	J	long	0	org.apache.hadoop.yarn.proto.YarnServerNodemanagerServiceProtos$LocalResourceStatusProto$Builder:setLocalSize(long)
org.apache.hadoop.yarn.proto.YarnServerNodemanagerServiceProtos$LocalizerStatusProto$Builder	setLocalizerId	localizerId_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServerNodemanagerServiceProtos$LocalizerStatusProto$Builder:setLocalizerId(java.lang.String)
org.apache.hadoop.yarn.proto.YarnServerNodemanagerServiceProtos$LocalizerStatusProto$Builder	setLocalizerIdBytes	localizerId_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServerNodemanagerServiceProtos$LocalizerStatusProto$Builder:setLocalizerIdBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnServerNodemanagerRecoveryProtos$FlowContextProto$Builder	setFlowName	flowName_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServerNodemanagerRecoveryProtos$FlowContextProto$Builder:setFlowName(java.lang.String)
org.apache.hadoop.yarn.proto.YarnServerNodemanagerRecoveryProtos$FlowContextProto$Builder	setFlowNameBytes	flowName_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServerNodemanagerRecoveryProtos$FlowContextProto$Builder:setFlowNameBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnServerNodemanagerRecoveryProtos$FlowContextProto$Builder	setFlowVersion	flowVersion_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServerNodemanagerRecoveryProtos$FlowContextProto$Builder:setFlowVersion(java.lang.String)
org.apache.hadoop.yarn.proto.YarnServerNodemanagerRecoveryProtos$FlowContextProto$Builder	setFlowVersionBytes	flowVersion_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServerNodemanagerRecoveryProtos$FlowContextProto$Builder:setFlowVersionBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnServerNodemanagerRecoveryProtos$FlowContextProto$Builder	setFlowRunId	flowRunId_	J	long	0	org.apache.hadoop.yarn.proto.YarnServerNodemanagerRecoveryProtos$FlowContextProto$Builder:setFlowRunId(long)
org.apache.hadoop.yarn.proto.YarnServerNodemanagerRecoveryProtos$LocalizedResourceProto$Builder	setLocalPath	localPath_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServerNodemanagerRecoveryProtos$LocalizedResourceProto$Builder:setLocalPath(java.lang.String)
org.apache.hadoop.yarn.proto.YarnServerNodemanagerRecoveryProtos$LocalizedResourceProto$Builder	setLocalPathBytes	localPath_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServerNodemanagerRecoveryProtos$LocalizedResourceProto$Builder:setLocalPathBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnServerNodemanagerRecoveryProtos$LocalizedResourceProto$Builder	setSize	size_	J	long	0	org.apache.hadoop.yarn.proto.YarnServerNodemanagerRecoveryProtos$LocalizedResourceProto$Builder:setSize(long)
org.apache.hadoop.yarn.server.nodemanager.DirectoryCollection	setDiskUtilizationThresholdEnabled	diskUtilizationThresholdEnabled	J	boolean	0	org.apache.hadoop.yarn.server.nodemanager.DirectoryCollection:setDiskUtilizationThresholdEnabled(boolean)
org.apache.hadoop.yarn.server.nodemanager.DirectoryCollection	setDiskFreeSpaceThresholdEnabled	diskFreeSpaceThresholdEnabled	J	boolean	0	org.apache.hadoop.yarn.server.nodemanager.DirectoryCollection:setDiskFreeSpaceThresholdEnabled(boolean)
org.apache.hadoop.yarn.server.nodemanager.nodelabels.AbstractNodeDescriptorsProvider	setIntervalTime	intervalTime	J	long	0	org.apache.hadoop.yarn.server.nodemanager.nodelabels.AbstractNodeDescriptorsProvider:setIntervalTime(long)
org.apache.hadoop.yarn.server.nodemanager.nodelabels.AbstractNodeDescriptorsProvider	setDescriptors	nodeDescriptors	GC	java.util.Set	0	org.apache.hadoop.yarn.server.nodemanager.nodelabels.AbstractNodeDescriptorsProvider:setDescriptors(java.util.Set)
org.apache.hadoop.yarn.server.nodemanager.amrmproxy.DefaultRequestInterceptor	setRMClient	rmClient	C	org.apache.hadoop.yarn.api.ApplicationMasterProtocol	0	org.apache.hadoop.yarn.server.nodemanager.amrmproxy.DefaultRequestInterceptor:setRMClient(org.apache.hadoop.yarn.api.ApplicationMasterProtocol)
org.apache.hadoop.yarn.server.nodemanager.amrmproxy.AMRMProxyTokenSecretManager	setNMStateStoreService	nmStateStore	C	org.apache.hadoop.yarn.server.nodemanager.recovery.NMStateStoreService	0	org.apache.hadoop.yarn.server.nodemanager.amrmproxy.AMRMProxyTokenSecretManager:setNMStateStoreService(org.apache.hadoop.yarn.server.nodemanager.recovery.NMStateStoreService)
org.apache.hadoop.yarn.server.nodemanager.amrmproxy.AbstractRequestInterceptor	setNextInterceptor	nextInterceptor	C	org.apache.hadoop.yarn.server.nodemanager.amrmproxy.RequestInterceptor	0	org.apache.hadoop.yarn.server.nodemanager.amrmproxy.AbstractRequestInterceptor:setNextInterceptor(org.apache.hadoop.yarn.server.nodemanager.amrmproxy.RequestInterceptor)
org.apache.hadoop.yarn.server.nodemanager.amrmproxy.AbstractRequestInterceptor	setConf	conf	C	org.apache.hadoop.conf.Configuration	0	org.apache.hadoop.yarn.server.nodemanager.amrmproxy.AbstractRequestInterceptor:setConf(org.apache.hadoop.conf.Configuration)
org.apache.hadoop.yarn.server.nodemanager.amrmproxy.AMRMProxyApplicationContextImpl	setAMRMToken	amrmToken	GC	org.apache.hadoop.security.token.Token	0	org.apache.hadoop.yarn.server.nodemanager.amrmproxy.AMRMProxyApplicationContextImpl:setAMRMToken(org.apache.hadoop.security.token.Token)
org.apache.hadoop.yarn.server.nodemanager.amrmproxy.AMRMProxyApplicationContextImpl	setLocalAMRMToken	localToken	GC	org.apache.hadoop.security.token.Token	0	org.apache.hadoop.yarn.server.nodemanager.amrmproxy.AMRMProxyApplicationContextImpl:setLocalAMRMToken(org.apache.hadoop.security.token.Token)
org.apache.hadoop.yarn.server.nodemanager.NodeManager$NMContext	setNodeResourceMonitor	nodeResourceMonitor	C	org.apache.hadoop.yarn.server.nodemanager.NodeResourceMonitor	0	org.apache.hadoop.yarn.server.nodemanager.NodeManager$NMContext:setNodeResourceMonitor(org.apache.hadoop.yarn.server.nodemanager.NodeResourceMonitor)
org.apache.hadoop.yarn.server.nodemanager.NodeManager$NMContext	setContainerManager	containerManager	C	org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManager	0	org.apache.hadoop.yarn.server.nodemanager.NodeManager$NMContext:setContainerManager(org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManager)
org.apache.hadoop.yarn.server.nodemanager.NodeManager$NMContext	setWebServer	webServer	C	org.apache.hadoop.yarn.server.nodemanager.webapp.WebServer	0	org.apache.hadoop.yarn.server.nodemanager.NodeManager$NMContext:setWebServer(org.apache.hadoop.yarn.server.nodemanager.webapp.WebServer)
org.apache.hadoop.yarn.server.nodemanager.NodeManager$NMContext	setNodeId	nodeId	C	org.apache.hadoop.yarn.api.records.NodeId	0	org.apache.hadoop.yarn.server.nodemanager.NodeManager$NMContext:setNodeId(org.apache.hadoop.yarn.api.records.NodeId)
org.apache.hadoop.yarn.server.nodemanager.NodeManager$NMContext	setDecommissioned	isDecommissioned	J	boolean	0	org.apache.hadoop.yarn.server.nodemanager.NodeManager$NMContext:setDecommissioned(boolean)
org.apache.hadoop.yarn.server.nodemanager.NodeManager$NMContext	setSystemCrendentialsForApps	systemCredentials	GC	java.util.Map	0	org.apache.hadoop.yarn.server.nodemanager.NodeManager$NMContext:setSystemCrendentialsForApps(java.util.Map)
org.apache.hadoop.yarn.server.nodemanager.NodeManager$NMContext	setNodeStatusUpdater	nodeStatusUpdater	C	org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdater	0	org.apache.hadoop.yarn.server.nodemanager.NodeManager$NMContext:setNodeStatusUpdater(org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdater)
org.apache.hadoop.yarn.server.nodemanager.NodeManager$NMContext	setQueueableContainerAllocator	containerAllocator	C	org.apache.hadoop.yarn.server.scheduler.OpportunisticContainerAllocator	0	org.apache.hadoop.yarn.server.nodemanager.NodeManager$NMContext:setQueueableContainerAllocator(org.apache.hadoop.yarn.server.scheduler.OpportunisticContainerAllocator)
org.apache.hadoop.yarn.server.nodemanager.NodeManager$NMContext	setNMTimelinePublisher	nmTimelinePublisher	C	org.apache.hadoop.yarn.server.nodemanager.timelineservice.NMTimelinePublisher	0	org.apache.hadoop.yarn.server.nodemanager.NodeManager$NMContext:setNMTimelinePublisher(org.apache.hadoop.yarn.server.nodemanager.timelineservice.NMTimelinePublisher)
org.apache.hadoop.yarn.server.nodemanager.NodeManager$NMContext	setContainerExecutor	executor	C	org.apache.hadoop.yarn.server.nodemanager.ContainerExecutor	0	org.apache.hadoop.yarn.server.nodemanager.NodeManager$NMContext:setContainerExecutor(org.apache.hadoop.yarn.server.nodemanager.ContainerExecutor)
org.apache.hadoop.yarn.server.nodemanager.NodeManager$NMContext	setContainerStateTransitionListener	containerStateTransitionListener	C	org.apache.hadoop.yarn.server.nodemanager.ContainerStateTransitionListener	0	org.apache.hadoop.yarn.server.nodemanager.NodeManager$NMContext:setContainerStateTransitionListener(org.apache.hadoop.yarn.server.nodemanager.ContainerStateTransitionListener)
org.apache.hadoop.yarn.server.nodemanager.NodeManager$NMContext	setNodeManagerMetrics	metrics	C	org.apache.hadoop.yarn.server.nodemanager.metrics.NodeManagerMetrics	0	org.apache.hadoop.yarn.server.nodemanager.NodeManager$NMContext:setNodeManagerMetrics(org.apache.hadoop.yarn.server.nodemanager.metrics.NodeManagerMetrics)
org.apache.hadoop.yarn.server.nodemanager.NodeManager$NMContext	setResourcePluginManager	resourcePluginManager	C	org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.ResourcePluginManager	0	org.apache.hadoop.yarn.server.nodemanager.NodeManager$NMContext:setResourcePluginManager(org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.ResourcePluginManager)
org.apache.hadoop.yarn.server.nodemanager.NodeManager$NMContext	setDeletionService	deletionService	C	org.apache.hadoop.yarn.server.nodemanager.DeletionService	0	org.apache.hadoop.yarn.server.nodemanager.NodeManager$NMContext:setDeletionService(org.apache.hadoop.yarn.server.nodemanager.DeletionService)
org.apache.hadoop.yarn.server.nodemanager.NodeManager$NMContext	setNMLogAggregationStatusTracker	nmLogAggregationStatusTracker	C	org.apache.hadoop.yarn.server.nodemanager.logaggregation.tracker.NMLogAggregationStatusTracker	0	org.apache.hadoop.yarn.server.nodemanager.NodeManager$NMContext:setNMLogAggregationStatusTracker(org.apache.hadoop.yarn.server.nodemanager.logaggregation.tracker.NMLogAggregationStatusTracker)
org.apache.hadoop.yarn.server.nodemanager.NodeManager$NMContext	setAuxServices	auxServices	C	org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices	0	org.apache.hadoop.yarn.server.nodemanager.NodeManager$NMContext:setAuxServices(org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices)
org.apache.hadoop.yarn.server.nodemanager.executor.ContainerLivenessContext$Builder	setContainer	container	C	org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container	0	org.apache.hadoop.yarn.server.nodemanager.executor.ContainerLivenessContext$Builder:setContainer(org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container)
org.apache.hadoop.yarn.server.nodemanager.executor.ContainerLivenessContext$Builder	setUser	user	J	java.lang.String	0	org.apache.hadoop.yarn.server.nodemanager.executor.ContainerLivenessContext$Builder:setUser(java.lang.String)
org.apache.hadoop.yarn.server.nodemanager.executor.ContainerLivenessContext$Builder	setPid	pid	J	java.lang.String	0	org.apache.hadoop.yarn.server.nodemanager.executor.ContainerLivenessContext$Builder:setPid(java.lang.String)
org.apache.hadoop.yarn.server.nodemanager.executor.ContainerPrepareContext$Builder	setContainer	container	C	org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container	0	org.apache.hadoop.yarn.server.nodemanager.executor.ContainerPrepareContext$Builder:setContainer(org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container)
org.apache.hadoop.yarn.server.nodemanager.executor.ContainerPrepareContext$Builder	setLocalizedResources	localizedResources	GC	java.util.Map	0	org.apache.hadoop.yarn.server.nodemanager.executor.ContainerPrepareContext$Builder:setLocalizedResources(java.util.Map)
org.apache.hadoop.yarn.server.nodemanager.executor.ContainerPrepareContext$Builder	setUser	user	J	java.lang.String	0	org.apache.hadoop.yarn.server.nodemanager.executor.ContainerPrepareContext$Builder:setUser(java.lang.String)
org.apache.hadoop.yarn.server.nodemanager.executor.ContainerPrepareContext$Builder	setContainerLocalDirs	containerLocalDirs	GJ	java.util.List	0	org.apache.hadoop.yarn.server.nodemanager.executor.ContainerPrepareContext$Builder:setContainerLocalDirs(java.util.List)
org.apache.hadoop.yarn.server.nodemanager.executor.ContainerPrepareContext$Builder	setCommands	commands	GJ	java.util.List	0	org.apache.hadoop.yarn.server.nodemanager.executor.ContainerPrepareContext$Builder:setCommands(java.util.List)
org.apache.hadoop.yarn.server.nodemanager.executor.ContainerReacquisitionContext$Builder	setContainer	container	C	org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container	0	org.apache.hadoop.yarn.server.nodemanager.executor.ContainerReacquisitionContext$Builder:setContainer(org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container)
org.apache.hadoop.yarn.server.nodemanager.executor.ContainerReacquisitionContext$Builder	setUser	user	J	java.lang.String	0	org.apache.hadoop.yarn.server.nodemanager.executor.ContainerReacquisitionContext$Builder:setUser(java.lang.String)
org.apache.hadoop.yarn.server.nodemanager.executor.ContainerReacquisitionContext$Builder	setContainerId	containerId	C	org.apache.hadoop.yarn.api.records.ContainerId	0	org.apache.hadoop.yarn.server.nodemanager.executor.ContainerReacquisitionContext$Builder:setContainerId(org.apache.hadoop.yarn.api.records.ContainerId)
org.apache.hadoop.yarn.server.nodemanager.executor.ContainerStartContext$Builder	setContainer	container	C	org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container	0	org.apache.hadoop.yarn.server.nodemanager.executor.ContainerStartContext$Builder:setContainer(org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container)
org.apache.hadoop.yarn.server.nodemanager.executor.ContainerStartContext$Builder	setLocalizedResources	localizedResources	GC	java.util.Map	0	org.apache.hadoop.yarn.server.nodemanager.executor.ContainerStartContext$Builder:setLocalizedResources(java.util.Map)
org.apache.hadoop.yarn.server.nodemanager.executor.ContainerStartContext$Builder	setNmPrivateContainerScriptPath	nmPrivateContainerScriptPath	C	org.apache.hadoop.fs.Path	0	org.apache.hadoop.yarn.server.nodemanager.executor.ContainerStartContext$Builder:setNmPrivateContainerScriptPath(org.apache.hadoop.fs.Path)
org.apache.hadoop.yarn.server.nodemanager.executor.ContainerStartContext$Builder	setNmPrivateTokensPath	nmPrivateTokensPath	C	org.apache.hadoop.fs.Path	0	org.apache.hadoop.yarn.server.nodemanager.executor.ContainerStartContext$Builder:setNmPrivateTokensPath(org.apache.hadoop.fs.Path)
org.apache.hadoop.yarn.server.nodemanager.executor.ContainerStartContext$Builder	setNmPrivateKeystorePath	nmPrivateKeystorePath	C	org.apache.hadoop.fs.Path	0	org.apache.hadoop.yarn.server.nodemanager.executor.ContainerStartContext$Builder:setNmPrivateKeystorePath(org.apache.hadoop.fs.Path)
org.apache.hadoop.yarn.server.nodemanager.executor.ContainerStartContext$Builder	setNmPrivateTruststorePath	nmPrivateTruststorePath	C	org.apache.hadoop.fs.Path	0	org.apache.hadoop.yarn.server.nodemanager.executor.ContainerStartContext$Builder:setNmPrivateTruststorePath(org.apache.hadoop.fs.Path)
org.apache.hadoop.yarn.server.nodemanager.executor.ContainerStartContext$Builder	setUser	user	J	java.lang.String	0	org.apache.hadoop.yarn.server.nodemanager.executor.ContainerStartContext$Builder:setUser(java.lang.String)
org.apache.hadoop.yarn.server.nodemanager.executor.ContainerStartContext$Builder	setAppId	appId	J	java.lang.String	0	org.apache.hadoop.yarn.server.nodemanager.executor.ContainerStartContext$Builder:setAppId(java.lang.String)
org.apache.hadoop.yarn.server.nodemanager.executor.ContainerStartContext$Builder	setContainerCsiVolumesRootDir	csiVolumesRoot	C	org.apache.hadoop.fs.Path	0	org.apache.hadoop.yarn.server.nodemanager.executor.ContainerStartContext$Builder:setContainerCsiVolumesRootDir(org.apache.hadoop.fs.Path)
org.apache.hadoop.yarn.server.nodemanager.executor.ContainerStartContext$Builder	setContainerWorkDir	containerWorkDir	C	org.apache.hadoop.fs.Path	0	org.apache.hadoop.yarn.server.nodemanager.executor.ContainerStartContext$Builder:setContainerWorkDir(org.apache.hadoop.fs.Path)
org.apache.hadoop.yarn.server.nodemanager.executor.ContainerStartContext$Builder	setLocalDirs	localDirs	GJ	java.util.List	0	org.apache.hadoop.yarn.server.nodemanager.executor.ContainerStartContext$Builder:setLocalDirs(java.util.List)
org.apache.hadoop.yarn.server.nodemanager.executor.ContainerStartContext$Builder	setLogDirs	logDirs	GJ	java.util.List	0	org.apache.hadoop.yarn.server.nodemanager.executor.ContainerStartContext$Builder:setLogDirs(java.util.List)
org.apache.hadoop.yarn.server.nodemanager.executor.ContainerStartContext$Builder	setFilecacheDirs	filecacheDirs	GJ	java.util.List	0	org.apache.hadoop.yarn.server.nodemanager.executor.ContainerStartContext$Builder:setFilecacheDirs(java.util.List)
org.apache.hadoop.yarn.server.nodemanager.executor.ContainerStartContext$Builder	setUserLocalDirs	userLocalDirs	GJ	java.util.List	0	org.apache.hadoop.yarn.server.nodemanager.executor.ContainerStartContext$Builder:setUserLocalDirs(java.util.List)
org.apache.hadoop.yarn.server.nodemanager.executor.ContainerStartContext$Builder	setContainerLocalDirs	containerLocalDirs	GJ	java.util.List	0	org.apache.hadoop.yarn.server.nodemanager.executor.ContainerStartContext$Builder:setContainerLocalDirs(java.util.List)
org.apache.hadoop.yarn.server.nodemanager.executor.ContainerStartContext$Builder	setContainerLogDirs	containerLogDirs	GJ	java.util.List	0	org.apache.hadoop.yarn.server.nodemanager.executor.ContainerStartContext$Builder:setContainerLogDirs(java.util.List)
org.apache.hadoop.yarn.server.nodemanager.executor.ContainerStartContext$Builder	setUserFilecacheDirs	userFilecacheDirs	GJ	java.util.List	0	org.apache.hadoop.yarn.server.nodemanager.executor.ContainerStartContext$Builder:setUserFilecacheDirs(java.util.List)
org.apache.hadoop.yarn.server.nodemanager.executor.ContainerStartContext$Builder	setApplicationLocalDirs	applicationLocalDirs	GJ	java.util.List	0	org.apache.hadoop.yarn.server.nodemanager.executor.ContainerStartContext$Builder:setApplicationLocalDirs(java.util.List)
org.apache.hadoop.yarn.server.nodemanager.executor.DeletionAsUserContext$Builder	setUser	user	J	java.lang.String	0	org.apache.hadoop.yarn.server.nodemanager.executor.DeletionAsUserContext$Builder:setUser(java.lang.String)
org.apache.hadoop.yarn.server.nodemanager.executor.DeletionAsUserContext$Builder	setSubDir	subDir	C	org.apache.hadoop.fs.Path	0	org.apache.hadoop.yarn.server.nodemanager.executor.DeletionAsUserContext$Builder:setSubDir(org.apache.hadoop.fs.Path)
org.apache.hadoop.yarn.server.nodemanager.executor.LocalizerStartContext$Builder	setNmPrivateContainerTokens	nmPrivateContainerTokens	C	org.apache.hadoop.fs.Path	0	org.apache.hadoop.yarn.server.nodemanager.executor.LocalizerStartContext$Builder:setNmPrivateContainerTokens(org.apache.hadoop.fs.Path)
org.apache.hadoop.yarn.server.nodemanager.executor.LocalizerStartContext$Builder	setNmAddr	nmAddr	J	java.net.InetSocketAddress	0	org.apache.hadoop.yarn.server.nodemanager.executor.LocalizerStartContext$Builder:setNmAddr(java.net.InetSocketAddress)
org.apache.hadoop.yarn.server.nodemanager.executor.LocalizerStartContext$Builder	setUser	user	J	java.lang.String	0	org.apache.hadoop.yarn.server.nodemanager.executor.LocalizerStartContext$Builder:setUser(java.lang.String)
org.apache.hadoop.yarn.server.nodemanager.executor.LocalizerStartContext$Builder	setAppId	appId	J	java.lang.String	0	org.apache.hadoop.yarn.server.nodemanager.executor.LocalizerStartContext$Builder:setAppId(java.lang.String)
org.apache.hadoop.yarn.server.nodemanager.executor.LocalizerStartContext$Builder	setLocId	locId	J	java.lang.String	0	org.apache.hadoop.yarn.server.nodemanager.executor.LocalizerStartContext$Builder:setLocId(java.lang.String)
org.apache.hadoop.yarn.server.nodemanager.executor.LocalizerStartContext$Builder	setDirsHandler	dirsHandler	C	org.apache.hadoop.yarn.server.nodemanager.LocalDirsHandlerService	0	org.apache.hadoop.yarn.server.nodemanager.executor.LocalizerStartContext$Builder:setDirsHandler(org.apache.hadoop.yarn.server.nodemanager.LocalDirsHandlerService)
org.apache.hadoop.yarn.server.nodemanager.executor.ContainerSignalContext$Builder	setContainer	container	C	org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container	0	org.apache.hadoop.yarn.server.nodemanager.executor.ContainerSignalContext$Builder:setContainer(org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container)
org.apache.hadoop.yarn.server.nodemanager.executor.ContainerSignalContext$Builder	setUser	user	J	java.lang.String	0	org.apache.hadoop.yarn.server.nodemanager.executor.ContainerSignalContext$Builder:setUser(java.lang.String)
org.apache.hadoop.yarn.server.nodemanager.executor.ContainerSignalContext$Builder	setPid	pid	J	java.lang.String	0	org.apache.hadoop.yarn.server.nodemanager.executor.ContainerSignalContext$Builder:setPid(java.lang.String)
org.apache.hadoop.yarn.server.nodemanager.executor.ContainerSignalContext$Builder	setSignal	signal	C	org.apache.hadoop.yarn.server.nodemanager.ContainerExecutor$Signal	0	org.apache.hadoop.yarn.server.nodemanager.executor.ContainerSignalContext$Builder:setSignal(org.apache.hadoop.yarn.server.nodemanager.ContainerExecutor$Signal)
org.apache.hadoop.yarn.server.nodemanager.executor.ContainerReapContext$Builder	setContainer	builderContainer	C	org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container	0	org.apache.hadoop.yarn.server.nodemanager.executor.ContainerReapContext$Builder:setContainer(org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container)
org.apache.hadoop.yarn.server.nodemanager.executor.ContainerReapContext$Builder	setUser	builderUser	J	java.lang.String	0	org.apache.hadoop.yarn.server.nodemanager.executor.ContainerReapContext$Builder:setUser(java.lang.String)
org.apache.hadoop.yarn.server.nodemanager.executor.ContainerExecContext$Builder	setContainer	container	C	org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container	0	org.apache.hadoop.yarn.server.nodemanager.executor.ContainerExecContext$Builder:setContainer(org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container)
org.apache.hadoop.yarn.server.nodemanager.executor.ContainerExecContext$Builder	setUser	user	J	java.lang.String	0	org.apache.hadoop.yarn.server.nodemanager.executor.ContainerExecContext$Builder:setUser(java.lang.String)
org.apache.hadoop.yarn.server.nodemanager.executor.ContainerExecContext$Builder	setAppId	appId	J	java.lang.String	0	org.apache.hadoop.yarn.server.nodemanager.executor.ContainerExecContext$Builder:setAppId(java.lang.String)
org.apache.hadoop.yarn.server.nodemanager.executor.ContainerExecContext$Builder	setNMLocalPath	localDirsHandler	C	org.apache.hadoop.yarn.server.nodemanager.LocalDirsHandlerService	0	org.apache.hadoop.yarn.server.nodemanager.executor.ContainerExecContext$Builder:setNMLocalPath(org.apache.hadoop.yarn.server.nodemanager.LocalDirsHandlerService)
org.apache.hadoop.yarn.server.nodemanager.executor.ContainerExecContext$Builder	setShell	command	J	java.lang.String	0	org.apache.hadoop.yarn.server.nodemanager.executor.ContainerExecContext$Builder:setShell(java.lang.String)
org.apache.hadoop.yarn.server.nodemanager.recovery.NMLeveldbStateStoreService	setDB	db	C	org.iq80.leveldb.DB	0	org.apache.hadoop.yarn.server.nodemanager.recovery.NMLeveldbStateStoreService:setDB(org.iq80.leveldb.DB)
org.apache.hadoop.yarn.server.nodemanager.recovery.NMStateStoreService$RecoveredAMRMProxyState	setCurrentMasterKey	currentMasterKey	C	org.apache.hadoop.yarn.server.api.records.MasterKey	0	org.apache.hadoop.yarn.server.nodemanager.recovery.NMStateStoreService$RecoveredAMRMProxyState:setCurrentMasterKey(org.apache.hadoop.yarn.server.api.records.MasterKey)
org.apache.hadoop.yarn.server.nodemanager.recovery.NMStateStoreService$RecoveredAMRMProxyState	setNextMasterKey	nextMasterKey	C	org.apache.hadoop.yarn.server.api.records.MasterKey	0	org.apache.hadoop.yarn.server.nodemanager.recovery.NMStateStoreService$RecoveredAMRMProxyState:setNextMasterKey(org.apache.hadoop.yarn.server.api.records.MasterKey)
org.apache.hadoop.yarn.server.nodemanager.recovery.NMStateStoreService$RecoveredContainerState	setStartTime	startTime	J	long	0	org.apache.hadoop.yarn.server.nodemanager.recovery.NMStateStoreService$RecoveredContainerState:setStartTime(long)
org.apache.hadoop.yarn.server.nodemanager.recovery.NMStateStoreService$RecoveredContainerState	setRemainingRetryAttempts	remainingRetryAttempts	J	int	0	org.apache.hadoop.yarn.server.nodemanager.recovery.NMStateStoreService$RecoveredContainerState:setRemainingRetryAttempts(int)
org.apache.hadoop.yarn.server.nodemanager.recovery.NMStateStoreService$RecoveredContainerState	setRestartTimes	restartTimes	GJ	java.util.List	0	org.apache.hadoop.yarn.server.nodemanager.recovery.NMStateStoreService$RecoveredContainerState:setRestartTimes(java.util.List)
org.apache.hadoop.yarn.server.nodemanager.recovery.NMStateStoreService$RecoveredContainerState	setWorkDir	workDir	J	java.lang.String	0	org.apache.hadoop.yarn.server.nodemanager.recovery.NMStateStoreService$RecoveredContainerState:setWorkDir(java.lang.String)
org.apache.hadoop.yarn.server.nodemanager.recovery.NMStateStoreService$RecoveredContainerState	setLogDir	logDir	J	java.lang.String	0	org.apache.hadoop.yarn.server.nodemanager.recovery.NMStateStoreService$RecoveredContainerState:setLogDir(java.lang.String)
org.apache.hadoop.yarn.server.nodemanager.recovery.NMStateStoreService$RecoveredContainerState	setRecoveryType	recoveryType	C	org.apache.hadoop.yarn.server.nodemanager.recovery.NMStateStoreService$RecoveredContainerType	0	org.apache.hadoop.yarn.server.nodemanager.recovery.NMStateStoreService$RecoveredContainerState:setRecoveryType(org.apache.hadoop.yarn.server.nodemanager.recovery.NMStateStoreService$RecoveredContainerType)
org.apache.hadoop.yarn.server.nodemanager.recovery.NMStateStoreService$RecoveredContainerState	setResourceMappings	resMappings	C	org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ResourceMappings	0	org.apache.hadoop.yarn.server.nodemanager.recovery.NMStateStoreService$RecoveredContainerState:setResourceMappings(org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ResourceMappings)
org.apache.hadoop.yarn.server.nodemanager.recovery.NMStateStoreService	setNodeStatusUpdater	nodeStatusUpdater	C	org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdater	0	org.apache.hadoop.yarn.server.nodemanager.recovery.NMStateStoreService:setNodeStatusUpdater(org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdater)
org.apache.hadoop.yarn.server.nodemanager.api.deviceplugin.VolumeSpec$Builder	setVolumeDriver	volumeDriver	J	java.lang.String	0	org.apache.hadoop.yarn.server.nodemanager.api.deviceplugin.VolumeSpec$Builder:setVolumeDriver(java.lang.String)
org.apache.hadoop.yarn.server.nodemanager.api.deviceplugin.VolumeSpec$Builder	setVolumeName	volumeName	J	java.lang.String	0	org.apache.hadoop.yarn.server.nodemanager.api.deviceplugin.VolumeSpec$Builder:setVolumeName(java.lang.String)
org.apache.hadoop.yarn.server.nodemanager.api.deviceplugin.VolumeSpec$Builder	setVolumeOperation	volumeOperation	J	java.lang.String	0	org.apache.hadoop.yarn.server.nodemanager.api.deviceplugin.VolumeSpec$Builder:setVolumeOperation(java.lang.String)
org.apache.hadoop.yarn.server.nodemanager.api.deviceplugin.MountVolumeSpec$Builder	setHostPath	hostPath	J	java.lang.String	0	org.apache.hadoop.yarn.server.nodemanager.api.deviceplugin.MountVolumeSpec$Builder:setHostPath(java.lang.String)
org.apache.hadoop.yarn.server.nodemanager.api.deviceplugin.MountVolumeSpec$Builder	setMountPath	mountPath	J	java.lang.String	0	org.apache.hadoop.yarn.server.nodemanager.api.deviceplugin.MountVolumeSpec$Builder:setMountPath(java.lang.String)
org.apache.hadoop.yarn.server.nodemanager.api.deviceplugin.MountVolumeSpec$Builder	setReadOnly	isReadOnly	J	java.lang.Boolean	0	org.apache.hadoop.yarn.server.nodemanager.api.deviceplugin.MountVolumeSpec$Builder:setReadOnly(java.lang.Boolean)
org.apache.hadoop.yarn.server.nodemanager.api.deviceplugin.Device$Builder	setId	id	J	int	0	org.apache.hadoop.yarn.server.nodemanager.api.deviceplugin.Device$Builder:setId(int)
org.apache.hadoop.yarn.server.nodemanager.api.deviceplugin.Device$Builder	setDevPath	devPath	J	java.lang.String	0	org.apache.hadoop.yarn.server.nodemanager.api.deviceplugin.Device$Builder:setDevPath(java.lang.String)
org.apache.hadoop.yarn.server.nodemanager.api.deviceplugin.Device$Builder	setMajorNumber	majorNumber	J	int	0	org.apache.hadoop.yarn.server.nodemanager.api.deviceplugin.Device$Builder:setMajorNumber(int)
org.apache.hadoop.yarn.server.nodemanager.api.deviceplugin.Device$Builder	setMinorNumber	minorNumber	J	int	0	org.apache.hadoop.yarn.server.nodemanager.api.deviceplugin.Device$Builder:setMinorNumber(int)
org.apache.hadoop.yarn.server.nodemanager.api.deviceplugin.Device$Builder	setBusID	busID	J	java.lang.String	0	org.apache.hadoop.yarn.server.nodemanager.api.deviceplugin.Device$Builder:setBusID(java.lang.String)
org.apache.hadoop.yarn.server.nodemanager.api.deviceplugin.Device$Builder	setHealthy	isHealthy	J	boolean	0	org.apache.hadoop.yarn.server.nodemanager.api.deviceplugin.Device$Builder:setHealthy(boolean)
org.apache.hadoop.yarn.server.nodemanager.api.deviceplugin.Device$Builder	setStatus	status	J	java.lang.String	0	org.apache.hadoop.yarn.server.nodemanager.api.deviceplugin.Device$Builder:setStatus(java.lang.String)
org.apache.hadoop.yarn.server.nodemanager.api.deviceplugin.DeviceRuntimeSpec$Builder	setContainerRuntime	containerRuntime	J	java.lang.String	0	org.apache.hadoop.yarn.server.nodemanager.api.deviceplugin.DeviceRuntimeSpec$Builder:setContainerRuntime(java.lang.String)
org.apache.hadoop.yarn.server.nodemanager.api.deviceplugin.DeviceRegisterRequest$Builder	setResourceName	resourceName	J	java.lang.String	0	org.apache.hadoop.yarn.server.nodemanager.api.deviceplugin.DeviceRegisterRequest$Builder:setResourceName(java.lang.String)
org.apache.hadoop.yarn.server.nodemanager.api.deviceplugin.DeviceRegisterRequest$Builder	setPluginVersion	pluginVersion	J	java.lang.String	0	org.apache.hadoop.yarn.server.nodemanager.api.deviceplugin.DeviceRegisterRequest$Builder:setPluginVersion(java.lang.String)
org.apache.hadoop.yarn.server.nodemanager.api.deviceplugin.MountDeviceSpec$Builder	setDevicePermission	devicePermission	J	java.lang.String	0	org.apache.hadoop.yarn.server.nodemanager.api.deviceplugin.MountDeviceSpec$Builder:setDevicePermission(java.lang.String)
org.apache.hadoop.yarn.server.nodemanager.api.deviceplugin.MountDeviceSpec$Builder	setDevicePathInContainer	devicePathInContainer	J	java.lang.String	0	org.apache.hadoop.yarn.server.nodemanager.api.deviceplugin.MountDeviceSpec$Builder:setDevicePathInContainer(java.lang.String)
org.apache.hadoop.yarn.server.nodemanager.api.deviceplugin.MountDeviceSpec$Builder	setDevicePathInHost	devicePathInHost	J	java.lang.String	0	org.apache.hadoop.yarn.server.nodemanager.api.deviceplugin.MountDeviceSpec$Builder:setDevicePathInHost(java.lang.String)
org.apache.hadoop.yarn.server.nodemanager.api.protocolrecords.impl.pb.LocalResourceStatusPBImpl	setResource	resource	C	org.apache.hadoop.yarn.api.records.LocalResource	0	org.apache.hadoop.yarn.server.nodemanager.api.protocolrecords.impl.pb.LocalResourceStatusPBImpl:setResource(org.apache.hadoop.yarn.api.records.LocalResource)
org.apache.hadoop.yarn.server.nodemanager.api.protocolrecords.impl.pb.LocalResourceStatusPBImpl	setLocalPath	localPath	C	org.apache.hadoop.yarn.api.records.URL	0	org.apache.hadoop.yarn.server.nodemanager.api.protocolrecords.impl.pb.LocalResourceStatusPBImpl:setLocalPath(org.apache.hadoop.yarn.api.records.URL)
org.apache.hadoop.yarn.server.nodemanager.api.protocolrecords.impl.pb.LocalResourceStatusPBImpl	setException	exception	C	org.apache.hadoop.yarn.api.records.SerializedException	0	org.apache.hadoop.yarn.server.nodemanager.api.protocolrecords.impl.pb.LocalResourceStatusPBImpl:setException(org.apache.hadoop.yarn.api.records.SerializedException)
org.apache.hadoop.yarn.server.nodemanager.api.protocolrecords.impl.pb.LocalizerHeartbeatResponsePBImpl	setResourceSpecs	resourceSpecs	GC	java.util.List	0	org.apache.hadoop.yarn.server.nodemanager.api.protocolrecords.impl.pb.LocalizerHeartbeatResponsePBImpl:setResourceSpecs(java.util.List)
org.apache.hadoop.yarn.server.nodemanager.api.impl.pb.ResourceLocalizationSpecPBImpl	setResource	resource	C	org.apache.hadoop.yarn.api.records.LocalResource	0	org.apache.hadoop.yarn.server.nodemanager.api.impl.pb.ResourceLocalizationSpecPBImpl:setResource(org.apache.hadoop.yarn.api.records.LocalResource)
org.apache.hadoop.yarn.server.nodemanager.api.impl.pb.ResourceLocalizationSpecPBImpl	setDestinationDirectory	destinationDirectory	C	org.apache.hadoop.yarn.api.records.URL	0	org.apache.hadoop.yarn.server.nodemanager.api.impl.pb.ResourceLocalizationSpecPBImpl:setDestinationDirectory(org.apache.hadoop.yarn.api.records.URL)
org.apache.hadoop.yarn.server.nodemanager.ContainerExecutor	setConf	conf	C	org.apache.hadoop.conf.Configuration	0	org.apache.hadoop.yarn.server.nodemanager.ContainerExecutor:setConf(org.apache.hadoop.conf.Configuration)
org.apache.hadoop.yarn.server.nodemanager.health.TimedHealthReporterService	setTimerTask	task	J	java.util.TimerTask	0	org.apache.hadoop.yarn.server.nodemanager.health.TimedHealthReporterService:setTimerTask(java.util.TimerTask)
org.apache.hadoop.yarn.server.nodemanager.health.TimedHealthReporterService	setHealthy	isHealthy	J	boolean	0	org.apache.hadoop.yarn.server.nodemanager.health.TimedHealthReporterService:setHealthy(boolean)
org.apache.hadoop.yarn.server.nodemanager.health.TimedHealthReporterService	setHealthReport	healthReport	J	java.lang.String	0	org.apache.hadoop.yarn.server.nodemanager.health.TimedHealthReporterService:setHealthReport(java.lang.String)
org.apache.hadoop.yarn.server.nodemanager.health.TimedHealthReporterService	setLastReportedTime	lastReportedTime	J	long	0	org.apache.hadoop.yarn.server.nodemanager.health.TimedHealthReporterService:setLastReportedTime(long)
org.apache.hadoop.yarn.server.nodemanager.webapp.dao.gpu.NMGpuResourceInfo	setGpuDeviceInformation	gpuDeviceInformation	C	org.apache.hadoop.yarn.server.nodemanager.webapp.dao.gpu.GpuDeviceInformation	0	org.apache.hadoop.yarn.server.nodemanager.webapp.dao.gpu.NMGpuResourceInfo:setGpuDeviceInformation(org.apache.hadoop.yarn.server.nodemanager.webapp.dao.gpu.GpuDeviceInformation)
org.apache.hadoop.yarn.server.nodemanager.webapp.dao.gpu.NMGpuResourceInfo	setTotalGpuDevices	totalGpuDevices	GC	java.util.List	0	org.apache.hadoop.yarn.server.nodemanager.webapp.dao.gpu.NMGpuResourceInfo:setTotalGpuDevices(java.util.List)
org.apache.hadoop.yarn.server.nodemanager.webapp.dao.gpu.NMGpuResourceInfo	setAssignedGpuDevices	assignedGpuDevices	GC	java.util.List	0	org.apache.hadoop.yarn.server.nodemanager.webapp.dao.gpu.NMGpuResourceInfo:setAssignedGpuDevices(java.util.List)
org.apache.hadoop.yarn.server.nodemanager.webapp.dao.gpu.GpuDeviceInformation	setGpus	gpus	GC	java.util.List	0	org.apache.hadoop.yarn.server.nodemanager.webapp.dao.gpu.GpuDeviceInformation:setGpus(java.util.List)
org.apache.hadoop.yarn.server.nodemanager.webapp.dao.gpu.GpuDeviceInformation	setDriverVersion	driverVersion	J	java.lang.String	0	org.apache.hadoop.yarn.server.nodemanager.webapp.dao.gpu.GpuDeviceInformation:setDriverVersion(java.lang.String)
org.apache.hadoop.yarn.server.nodemanager.webapp.dao.gpu.PerGpuDeviceInformation	setTemperature	temperature	C	org.apache.hadoop.yarn.server.nodemanager.webapp.dao.gpu.PerGpuTemperature	0	org.apache.hadoop.yarn.server.nodemanager.webapp.dao.gpu.PerGpuDeviceInformation:setTemperature(org.apache.hadoop.yarn.server.nodemanager.webapp.dao.gpu.PerGpuTemperature)
org.apache.hadoop.yarn.server.nodemanager.webapp.dao.gpu.PerGpuDeviceInformation	setUuid	uuid	J	java.lang.String	0	org.apache.hadoop.yarn.server.nodemanager.webapp.dao.gpu.PerGpuDeviceInformation:setUuid(java.lang.String)
org.apache.hadoop.yarn.server.nodemanager.webapp.dao.gpu.PerGpuDeviceInformation	setProductName	productName	J	java.lang.String	0	org.apache.hadoop.yarn.server.nodemanager.webapp.dao.gpu.PerGpuDeviceInformation:setProductName(java.lang.String)
org.apache.hadoop.yarn.server.nodemanager.webapp.dao.gpu.PerGpuDeviceInformation	setMinorNumber	minorNumber	J	int	0	org.apache.hadoop.yarn.server.nodemanager.webapp.dao.gpu.PerGpuDeviceInformation:setMinorNumber(int)
org.apache.hadoop.yarn.server.nodemanager.webapp.dao.gpu.PerGpuDeviceInformation	setGpuUtilizations	gpuUtilizations	C	org.apache.hadoop.yarn.server.nodemanager.webapp.dao.gpu.PerGpuUtilizations	0	org.apache.hadoop.yarn.server.nodemanager.webapp.dao.gpu.PerGpuDeviceInformation:setGpuUtilizations(org.apache.hadoop.yarn.server.nodemanager.webapp.dao.gpu.PerGpuUtilizations)
org.apache.hadoop.yarn.server.nodemanager.webapp.dao.gpu.PerGpuDeviceInformation	setGpuMemoryUsage	gpuMemoryUsage	C	org.apache.hadoop.yarn.server.nodemanager.webapp.dao.gpu.PerGpuMemoryUsage	0	org.apache.hadoop.yarn.server.nodemanager.webapp.dao.gpu.PerGpuDeviceInformation:setGpuMemoryUsage(org.apache.hadoop.yarn.server.nodemanager.webapp.dao.gpu.PerGpuMemoryUsage)
org.apache.hadoop.yarn.server.nodemanager.webapp.dao.NMDeviceResourceInfo	setTotalDevices	totalDevices	GC	java.util.List	0	org.apache.hadoop.yarn.server.nodemanager.webapp.dao.NMDeviceResourceInfo:setTotalDevices(java.util.List)
org.apache.hadoop.yarn.server.nodemanager.webapp.dao.NMDeviceResourceInfo	setAssignedDevices	assignedDevices	GC	java.util.List	0	org.apache.hadoop.yarn.server.nodemanager.webapp.dao.NMDeviceResourceInfo:setAssignedDevices(java.util.List)
org.apache.hadoop.yarn.server.nodemanager.logaggregation.tracker.NMLogAggregationStatusTracker$AppLogAggregationStatusForRMRecovery	setLogAggregationStatus	logAggregationStatus	C	org.apache.hadoop.yarn.api.records.LogAggregationStatus	0	org.apache.hadoop.yarn.server.nodemanager.logaggregation.tracker.NMLogAggregationStatusTracker$AppLogAggregationStatusForRMRecovery:setLogAggregationStatus(org.apache.hadoop.yarn.api.records.LogAggregationStatus)
org.apache.hadoop.yarn.server.nodemanager.logaggregation.tracker.NMLogAggregationStatusTracker$AppLogAggregationStatusForRMRecovery	setLastModifiedTime	lastModifiedTime	J	long	0	org.apache.hadoop.yarn.server.nodemanager.logaggregation.tracker.NMLogAggregationStatusTracker$AppLogAggregationStatusForRMRecovery:setLastModifiedTime(long)
org.apache.hadoop.yarn.server.nodemanager.logaggregation.tracker.NMLogAggregationStatusTracker$AppLogAggregationStatusForRMRecovery	setFinalized	finalized	J	boolean	0	org.apache.hadoop.yarn.server.nodemanager.logaggregation.tracker.NMLogAggregationStatusTracker$AppLogAggregationStatusForRMRecovery:setFinalized(boolean)
org.apache.hadoop.yarn.server.nodemanager.logaggregation.tracker.NMLogAggregationStatusTracker$AppLogAggregationStatusForRMRecovery	setDiagnosis	diagnosis	J	java.lang.String	0	org.apache.hadoop.yarn.server.nodemanager.logaggregation.tracker.NMLogAggregationStatusTracker$AppLogAggregationStatusForRMRecovery:setDiagnosis(java.lang.String)
org.apache.hadoop.yarn.server.nodemanager.security.NMTokenSecretManagerInNM	setNodeId	nodeId	C	org.apache.hadoop.yarn.api.records.NodeId	0	org.apache.hadoop.yarn.server.nodemanager.security.NMTokenSecretManagerInNM:setNodeId(org.apache.hadoop.yarn.api.records.NodeId)
org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl	setNodeAttributesProvider	nodeAttributesProvider	C	org.apache.hadoop.yarn.server.nodemanager.nodelabels.NodeAttributesProvider	0	org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl:setNodeAttributesProvider(org.apache.hadoop.yarn.server.nodemanager.nodelabels.NodeAttributesProvider)
org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl	setNodeLabelsProvider	nodeLabelsProvider	C	org.apache.hadoop.yarn.server.nodemanager.nodelabels.NodeLabelsProvider	0	org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl:setNodeLabelsProvider(org.apache.hadoop.yarn.server.nodemanager.nodelabels.NodeLabelsProvider)
org.apache.hadoop.yarn.server.nodemanager.util.DefaultLCEResourcesHandler	setConf	conf	C	org.apache.hadoop.conf.Configuration	0	org.apache.hadoop.yarn.server.nodemanager.util.DefaultLCEResourcesHandler:setConf(org.apache.hadoop.conf.Configuration)
org.apache.hadoop.yarn.server.nodemanager.util.CgroupsLCEResourcesHandler	setConf	conf	C	org.apache.hadoop.conf.Configuration	0	org.apache.hadoop.yarn.server.nodemanager.util.CgroupsLCEResourcesHandler:setConf(org.apache.hadoop.conf.Configuration)
org.apache.hadoop.yarn.server.nodemanager.containermanager.deletion.task.DeletionTask	setTaskId	taskId	J	int	0	org.apache.hadoop.yarn.server.nodemanager.containermanager.deletion.task.DeletionTask:setTaskId(int)
org.apache.hadoop.yarn.server.nodemanager.containermanager.deletion.task.DeletionTask	setSuccess	success	J	boolean	0	org.apache.hadoop.yarn.server.nodemanager.containermanager.deletion.task.DeletionTask:setSuccess(boolean)
org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationImpl	setAppLogInitedTimestamp	applicationLogInitedTimestamp	J	long	0	org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationImpl:setAppLogInitedTimestamp(long)
org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationImpl	setFlowContext	flowContext	C	org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationImpl$FlowContext	0	org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationImpl:setFlowContext(org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationImpl$FlowContext)
org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.deviceframework.DevicePluginAdapter	setDeviceResourceHandler	deviceResourceHandler	C	org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.deviceframework.DeviceResourceHandlerImpl	0	org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.deviceframework.DevicePluginAdapter:setDeviceResourceHandler(org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.deviceframework.DeviceResourceHandlerImpl)
org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.fpga.FpgaDiscoverer	setScriptRunner	scriptRunner	GJ	java.util.function.Function	0	org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.fpga.FpgaDiscoverer:setScriptRunner(java.util.function.Function)
org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.fpga.FpgaDiscoverer	setResourceHanderPlugin	plugin	C	org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.fpga.AbstractFpgaVendorPlugin	0	org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.fpga.FpgaDiscoverer:setResourceHanderPlugin(org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.fpga.AbstractFpgaVendorPlugin)
org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.fpga.IntelFpgaOpenclPlugin	setInnerShellExecutor	shell	C	org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.fpga.IntelFpgaOpenclPlugin$InnerShellExecutor	0	org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.fpga.IntelFpgaOpenclPlugin:setInnerShellExecutor(org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.fpga.IntelFpgaOpenclPlugin$InnerShellExecutor)
org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.fpga.IntelFpgaOpenclPlugin	setEnvProvider	envProvider	GJ	java.util.function.Function	0	org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.fpga.IntelFpgaOpenclPlugin:setEnvProvider(java.util.function.Function)
org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.fpga.FpgaDevice	setAocxHash	aocxHash	J	java.lang.String	0	org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.fpga.FpgaDevice:setAocxHash(java.lang.String)
org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.fpga.FpgaDevice	setIPID	IPID	J	java.lang.String	0	org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.fpga.FpgaDevice:setIPID(java.lang.String)
org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.gpu.AssignedGpuDevice	setContainerId	containerId	J	java.lang.String	0	org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.gpu.AssignedGpuDevice:setContainerId(java.lang.String)
org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.com.nec.NECVEPlugin	setCommandExecutorProvider	commandExecutorProvider	GC	java.util.function.Function	0	org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.com.nec.NECVEPlugin:setCommandExecutorProvider(java.util.function.Function)
org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.com.nec.NECVEPlugin	setVeDeviceDiscoverer	discoverer	C	org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.com.nec.VEDeviceDiscoverer	0	org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.com.nec.NECVEPlugin:setVeDeviceDiscoverer(org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.com.nec.VEDeviceDiscoverer)
org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.com.nec.VEDeviceDiscoverer	setCommandExecutorProvider	commandExecutorProvider	GC	java.util.function.Function	0	org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.com.nec.VEDeviceDiscoverer:setCommandExecutorProvider(java.util.function.Function)
org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.com.nvidia.NvidiaGPUPluginForRuntimeV2	setPathOfGpuBinary	pathOfGpuBinary	J	java.lang.String	0	org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.com.nvidia.NvidiaGPUPluginForRuntimeV2:setPathOfGpuBinary(java.lang.String)
org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.com.nvidia.NvidiaGPUPluginForRuntimeV2	setShellExecutor	shellExecutor	C	org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.com.nvidia.NvidiaGPUPluginForRuntimeV2$NvidiaCommandExecutor	0	org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.com.nvidia.NvidiaGPUPluginForRuntimeV2:setShellExecutor(org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.com.nvidia.NvidiaGPUPluginForRuntimeV2$NvidiaCommandExecutor)
org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.ResourcePluginManager	setDeviceMappingManager	deviceMappingManager	C	org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.deviceframework.DeviceMappingManager	0	org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.ResourcePluginManager:setDeviceMappingManager(org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.deviceframework.DeviceMappingManager)
org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl	setAMRMProxyService	amrmProxyService	C	org.apache.hadoop.yarn.server.nodemanager.amrmproxy.AMRMProxyService	0	org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl:setAMRMProxyService(org.apache.hadoop.yarn.server.nodemanager.amrmproxy.AMRMProxyService)
org.apache.hadoop.yarn.server.nodemanager.containermanager.records.AuxServiceRecord	setName	name	J	java.lang.String	0	org.apache.hadoop.yarn.server.nodemanager.containermanager.records.AuxServiceRecord:setName(java.lang.String)
org.apache.hadoop.yarn.server.nodemanager.containermanager.records.AuxServiceRecord	setVersion	version	J	java.lang.String	0	org.apache.hadoop.yarn.server.nodemanager.containermanager.records.AuxServiceRecord:setVersion(java.lang.String)
org.apache.hadoop.yarn.server.nodemanager.containermanager.records.AuxServiceRecord	setDescription	description	J	java.lang.String	0	org.apache.hadoop.yarn.server.nodemanager.containermanager.records.AuxServiceRecord:setDescription(java.lang.String)
org.apache.hadoop.yarn.server.nodemanager.containermanager.records.AuxServiceRecord	setLaunchTime	launchTime	J	java.util.Date	0	org.apache.hadoop.yarn.server.nodemanager.containermanager.records.AuxServiceRecord:setLaunchTime(java.util.Date)
org.apache.hadoop.yarn.server.nodemanager.containermanager.records.AuxServiceRecord	setConfiguration	configuration	C	org.apache.hadoop.yarn.server.nodemanager.containermanager.records.AuxServiceConfiguration	0	org.apache.hadoop.yarn.server.nodemanager.containermanager.records.AuxServiceRecord:setConfiguration(org.apache.hadoop.yarn.server.nodemanager.containermanager.records.AuxServiceConfiguration)
org.apache.hadoop.yarn.server.nodemanager.containermanager.records.AuxServiceFile	setType	type	C	org.apache.hadoop.yarn.server.nodemanager.containermanager.records.AuxServiceFile$TypeEnum	0	org.apache.hadoop.yarn.server.nodemanager.containermanager.records.AuxServiceFile:setType(org.apache.hadoop.yarn.server.nodemanager.containermanager.records.AuxServiceFile$TypeEnum)
org.apache.hadoop.yarn.server.nodemanager.containermanager.records.AuxServiceFile	setSrcFile	srcFile	J	java.lang.String	0	org.apache.hadoop.yarn.server.nodemanager.containermanager.records.AuxServiceFile:setSrcFile(java.lang.String)
org.apache.hadoop.yarn.server.nodemanager.containermanager.records.AuxServiceConfiguration	setProperties	properties	GJ	java.util.Map	0	org.apache.hadoop.yarn.server.nodemanager.containermanager.records.AuxServiceConfiguration:setProperties(java.util.Map)
org.apache.hadoop.yarn.server.nodemanager.containermanager.records.AuxServiceConfiguration	setFiles	files	GC	java.util.List	0	org.apache.hadoop.yarn.server.nodemanager.containermanager.records.AuxServiceConfiguration:setFiles(java.util.List)
org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl	setContainersUtilization	containersUtilization	C	org.apache.hadoop.yarn.api.records.ResourceUtilization	0	org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl:setContainersUtilization(org.apache.hadoop.yarn.api.records.ResourceUtilization)
org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl$ProcessTreeInfo	setPid	pid	J	java.lang.String	0	org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl$ProcessTreeInfo:setPid(java.lang.String)
org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl$ProcessTreeInfo	setProcessTree	pTree	C	org.apache.hadoop.yarn.util.ResourceCalculatorProcessTree	0	org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl$ProcessTreeInfo:setProcessTree(org.apache.hadoop.yarn.util.ResourceCalculatorProcessTree)
org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource	setLocalPath	localPath	C	org.apache.hadoop.fs.Path	0	org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource:setLocalPath(org.apache.hadoop.fs.Path)
org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.NetworkTagMappingJsonManager$Group	setGroupName	groupName	J	java.lang.String	0	org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.NetworkTagMappingJsonManager$Group:setGroupName(java.lang.String)
org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.NetworkTagMappingJsonManager$Group	setNetworkTagID	networkTagID	J	java.lang.String	0	org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.NetworkTagMappingJsonManager$Group:setNetworkTagID(java.lang.String)
org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.NetworkTagMappingJsonManager$NetworkTagMapping	setUsers	users	GC	java.util.List	0	org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.NetworkTagMappingJsonManager$NetworkTagMapping:setUsers(java.util.List)
org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.NetworkTagMappingJsonManager$NetworkTagMapping	setGroups	groups	GC	java.util.List	0	org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.NetworkTagMappingJsonManager$NetworkTagMapping:setGroups(java.util.List)
org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.NetworkTagMappingJsonManager$NetworkTagMapping	setDefaultNetworkTagID	defaultNetworkTagID	J	java.lang.String	0	org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.NetworkTagMappingJsonManager$NetworkTagMapping:setDefaultNetworkTagID(java.lang.String)
org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.NetworkTagMappingJsonManager$User	setUserName	userName	J	java.lang.String	0	org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.NetworkTagMappingJsonManager$User:setUserName(java.lang.String)
org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.NetworkTagMappingJsonManager$User	setNetworkTagID	networkTagID	J	java.lang.String	0	org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.NetworkTagMappingJsonManager$User:setNetworkTagID(java.lang.String)
org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.runtime.docker.DockerVolumeCommand	setVolumeName	volumeName	J	java.lang.String	0	org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.runtime.docker.DockerVolumeCommand:setVolumeName(java.lang.String)
org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.runtime.docker.DockerVolumeCommand	setDriverName	driverName	J	java.lang.String	0	org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.runtime.docker.DockerVolumeCommand:setDriverName(java.lang.String)
org.apache.hadoop.yarn.server.nodemanager.containermanager.container.SlidingWindowRetryPolicy$RetryContext	setRemainingRetries	remainingRetries	J	int	0	org.apache.hadoop.yarn.server.nodemanager.containermanager.container.SlidingWindowRetryPolicy$RetryContext:setRemainingRetries(int)
org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl	setContainerTokenIdentifier	containerTokenIdentifier	C	org.apache.hadoop.yarn.security.ContainerTokenIdentifier	0	org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl:setContainerTokenIdentifier(org.apache.hadoop.yarn.security.ContainerTokenIdentifier)
org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl	setWorkDir	workDir	J	java.lang.String	0	org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl:setWorkDir(java.lang.String)
org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl	setCsiVolumesRootDir	csiVolumesRootDir	J	java.lang.String	0	org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl:setCsiVolumesRootDir(java.lang.String)
org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl	setLogDir	logDir	J	java.lang.String	0	org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl:setLogDir(java.lang.String)
org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl	setIsPaused	wasPaused	J	boolean	0	org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl:setIsPaused(boolean)
org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl	setIsReInitializing	isReInitializing	J	boolean	0	org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl:setIsReInitializing(boolean)
org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl	setExposedPorts	exposedPorts	J	java.lang.String	0	org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl:setExposedPorts(java.lang.String)
org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl	setContainerRuntimeData	containerRuntimeData	J	java.lang.Object	0	org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl:setContainerRuntimeData(java.lang.Object)
org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerResourceLocalizedEvent	setSize	size	J	long	0	org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerResourceLocalizedEvent:setSize(long)
org.apache.hadoop.yarn.server.nodemanager.containermanager.container.SlidingWindowRetryPolicy	setClock	clock	C	org.apache.hadoop.yarn.util.Clock	0	org.apache.hadoop.yarn.server.nodemanager.containermanager.container.SlidingWindowRetryPolicy:setClock(org.apache.hadoop.yarn.util.Clock)
org.apache.hadoop.yarn.proto.YarnServerResourceManagerRecoveryProtos$EpochProto$Builder	setEpoch	epoch_	J	long	0	org.apache.hadoop.yarn.proto.YarnServerResourceManagerRecoveryProtos$EpochProto$Builder:setEpoch(long)
org.apache.hadoop.yarn.proto.YarnServerResourceManagerRecoveryProtos$ApplicationStateDataProto$Builder	setSubmitTime	submitTime_	J	long	0	org.apache.hadoop.yarn.proto.YarnServerResourceManagerRecoveryProtos$ApplicationStateDataProto$Builder:setSubmitTime(long)
org.apache.hadoop.yarn.proto.YarnServerResourceManagerRecoveryProtos$ApplicationStateDataProto$Builder	setUser	user_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServerResourceManagerRecoveryProtos$ApplicationStateDataProto$Builder:setUser(java.lang.String)
org.apache.hadoop.yarn.proto.YarnServerResourceManagerRecoveryProtos$ApplicationStateDataProto$Builder	setUserBytes	user_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServerResourceManagerRecoveryProtos$ApplicationStateDataProto$Builder:setUserBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnServerResourceManagerRecoveryProtos$ApplicationStateDataProto$Builder	setStartTime	startTime_	J	long	0	org.apache.hadoop.yarn.proto.YarnServerResourceManagerRecoveryProtos$ApplicationStateDataProto$Builder:setStartTime(long)
org.apache.hadoop.yarn.proto.YarnServerResourceManagerRecoveryProtos$ApplicationStateDataProto$Builder	setDiagnostics	diagnostics_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServerResourceManagerRecoveryProtos$ApplicationStateDataProto$Builder:setDiagnostics(java.lang.String)
org.apache.hadoop.yarn.proto.YarnServerResourceManagerRecoveryProtos$ApplicationStateDataProto$Builder	setDiagnosticsBytes	diagnostics_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServerResourceManagerRecoveryProtos$ApplicationStateDataProto$Builder:setDiagnosticsBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnServerResourceManagerRecoveryProtos$ApplicationStateDataProto$Builder	setFinishTime	finishTime_	J	long	0	org.apache.hadoop.yarn.proto.YarnServerResourceManagerRecoveryProtos$ApplicationStateDataProto$Builder:setFinishTime(long)
org.apache.hadoop.yarn.proto.YarnServerResourceManagerRecoveryProtos$ApplicationStateDataProto$Builder	setLaunchTime	launchTime_	J	long	0	org.apache.hadoop.yarn.proto.YarnServerResourceManagerRecoveryProtos$ApplicationStateDataProto$Builder:setLaunchTime(long)
org.apache.hadoop.yarn.proto.YarnServerResourceManagerRecoveryProtos$ApplicationStateDataProto$Builder	setRealUser	realUser_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServerResourceManagerRecoveryProtos$ApplicationStateDataProto$Builder:setRealUser(java.lang.String)
org.apache.hadoop.yarn.proto.YarnServerResourceManagerRecoveryProtos$ApplicationStateDataProto$Builder	setRealUserBytes	realUser_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServerResourceManagerRecoveryProtos$ApplicationStateDataProto$Builder:setRealUserBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnServerResourceManagerRecoveryProtos$RMDelegationTokenIdentifierDataProto$Builder	setRenewDate	renewDate_	J	long	0	org.apache.hadoop.yarn.proto.YarnServerResourceManagerRecoveryProtos$RMDelegationTokenIdentifierDataProto$Builder:setRenewDate(long)
org.apache.hadoop.yarn.proto.YarnServerResourceManagerRecoveryProtos$ApplicationAttemptStateDataProto$Builder	setAppAttemptTokens	appAttemptTokens_	C	org.apache.hadoop.thirdparty.protobuf.ByteString	0	org.apache.hadoop.yarn.proto.YarnServerResourceManagerRecoveryProtos$ApplicationAttemptStateDataProto$Builder:setAppAttemptTokens(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnServerResourceManagerRecoveryProtos$ApplicationAttemptStateDataProto$Builder	setFinalTrackingUrl	finalTrackingUrl_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServerResourceManagerRecoveryProtos$ApplicationAttemptStateDataProto$Builder:setFinalTrackingUrl(java.lang.String)
org.apache.hadoop.yarn.proto.YarnServerResourceManagerRecoveryProtos$ApplicationAttemptStateDataProto$Builder	setFinalTrackingUrlBytes	finalTrackingUrl_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServerResourceManagerRecoveryProtos$ApplicationAttemptStateDataProto$Builder:setFinalTrackingUrlBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnServerResourceManagerRecoveryProtos$ApplicationAttemptStateDataProto$Builder	setDiagnostics	diagnostics_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServerResourceManagerRecoveryProtos$ApplicationAttemptStateDataProto$Builder:setDiagnostics(java.lang.String)
org.apache.hadoop.yarn.proto.YarnServerResourceManagerRecoveryProtos$ApplicationAttemptStateDataProto$Builder	setDiagnosticsBytes	diagnostics_	J	java.lang.Object	0	org.apache.hadoop.yarn.proto.YarnServerResourceManagerRecoveryProtos$ApplicationAttemptStateDataProto$Builder:setDiagnosticsBytes(org.apache.hadoop.thirdparty.protobuf.ByteString)
org.apache.hadoop.yarn.proto.YarnServerResourceManagerRecoveryProtos$ApplicationAttemptStateDataProto$Builder	setStartTime	startTime_	J	long	0	org.apache.hadoop.yarn.proto.YarnServerResourceManagerRecoveryProtos$ApplicationAttemptStateDataProto$Builder:setStartTime(long)
org.apache.hadoop.yarn.proto.YarnServerResourceManagerRecoveryProtos$ApplicationAttemptStateDataProto$Builder	setAmContainerExitStatus	amContainerExitStatus_	J	int	0	org.apache.hadoop.yarn.proto.YarnServerResourceManagerRecoveryProtos$ApplicationAttemptStateDataProto$Builder:setAmContainerExitStatus(int)
org.apache.hadoop.yarn.proto.YarnServerResourceManagerRecoveryProtos$ApplicationAttemptStateDataProto$Builder	setMemorySeconds	memorySeconds_	J	long	0	org.apache.hadoop.yarn.proto.YarnServerResourceManagerRecoveryProtos$ApplicationAttemptStateDataProto$Builder:setMemorySeconds(long)
org.apache.hadoop.yarn.proto.YarnServerResourceManagerRecoveryProtos$ApplicationAttemptStateDataProto$Builder	setVcoreSeconds	vcoreSeconds_	J	long	0	org.apache.hadoop.yarn.proto.YarnServerResourceManagerRecoveryProtos$ApplicationAttemptStateDataProto$Builder:setVcoreSeconds(long)
org.apache.hadoop.yarn.proto.YarnServerResourceManagerRecoveryProtos$ApplicationAttemptStateDataProto$Builder	setFinishTime	finishTime_	J	long	0	org.apache.hadoop.yarn.proto.YarnServerResourceManagerRecoveryProtos$ApplicationAttemptStateDataProto$Builder:setFinishTime(long)
org.apache.hadoop.yarn.proto.YarnServerResourceManagerRecoveryProtos$ApplicationAttemptStateDataProto$Builder	setPreemptedMemorySeconds	preemptedMemorySeconds_	J	long	0	org.apache.hadoop.yarn.proto.YarnServerResourceManagerRecoveryProtos$ApplicationAttemptStateDataProto$Builder:setPreemptedMemorySeconds(long)
org.apache.hadoop.yarn.proto.YarnServerResourceManagerRecoveryProtos$ApplicationAttemptStateDataProto$Builder	setPreemptedVcoreSeconds	preemptedVcoreSeconds_	J	long	0	org.apache.hadoop.yarn.proto.YarnServerResourceManagerRecoveryProtos$ApplicationAttemptStateDataProto$Builder:setPreemptedVcoreSeconds(long)
org.apache.hadoop.yarn.proto.YarnServerResourceManagerRecoveryProtos$ApplicationAttemptStateDataProto$Builder	setTotalAllocatedContainers	totalAllocatedContainers_	J	int	0	org.apache.hadoop.yarn.proto.YarnServerResourceManagerRecoveryProtos$ApplicationAttemptStateDataProto$Builder:setTotalAllocatedContainers(int)
org.apache.hadoop.yarn.server.resourcemanager.nodelabels.NodeAttributesManagerImpl	setRMContext	rmContext	C	org.apache.hadoop.yarn.server.resourcemanager.RMContext	0	org.apache.hadoop.yarn.server.resourcemanager.nodelabels.NodeAttributesManagerImpl:setRMContext(org.apache.hadoop.yarn.server.resourcemanager.RMContext)
org.apache.hadoop.yarn.server.resourcemanager.nodelabels.NodeAttributesManagerImpl$Host	setAttributes	attributes	GC	java.util.Map	0	org.apache.hadoop.yarn.server.resourcemanager.nodelabels.NodeAttributesManagerImpl$Host:setAttributes(java.util.Map)
org.apache.hadoop.yarn.server.resourcemanager.nodelabels.NodeAttributesManagerImpl$Host	setResource	resource	C	org.apache.hadoop.yarn.api.records.Resource	0	org.apache.hadoop.yarn.server.resourcemanager.nodelabels.NodeAttributesManagerImpl$Host:setResource(org.apache.hadoop.yarn.api.records.Resource)
org.apache.hadoop.yarn.server.resourcemanager.nodelabels.NodeAttributesManagerImpl$Host	setHostName	hostName	J	java.lang.String	0	org.apache.hadoop.yarn.server.resourcemanager.nodelabels.NodeAttributesManagerImpl$Host:setHostName(java.lang.String)
org.apache.hadoop.yarn.server.resourcemanager.nodelabels.RMNodeLabelsManager	setRMContext	rmContext	C	org.apache.hadoop.yarn.server.resourcemanager.RMContext	0	org.apache.hadoop.yarn.server.resourcemanager.nodelabels.RMNodeLabelsManager:setRMContext(org.apache.hadoop.yarn.server.resourcemanager.RMContext)
org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl	setContainer	container	C	org.apache.hadoop.yarn.api.records.Container	0	org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl:setContainer(org.apache.hadoop.yarn.api.records.Container)
org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl	setContainerRequest	containerRequestForRecovery	C	org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.ContainerRequest	0	org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl:setContainerRequest(org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.ContainerRequest)
org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl	setAllocationTags	allocationTags	GJ	java.util.Set	0	org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl:setAllocationTags(java.util.Set)
org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl	setQueueName	queueName	J	java.lang.String	0	org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl:setQueueName(java.lang.String)
org.apache.hadoop.yarn.server.resourcemanager.NodesListManager	setNodeRemovalCheckInterval	nodeRemovalCheckInterval	J	int	0	org.apache.hadoop.yarn.server.resourcemanager.NodesListManager:setNodeRemovalCheckInterval(int)
org.apache.hadoop.yarn.server.resourcemanager.NodesListManager$UnknownNode	setHost	host	J	java.lang.String	0	org.apache.hadoop.yarn.server.resourcemanager.NodesListManager$UnknownNode:setHost(java.lang.String)
org.apache.hadoop.yarn.server.resourcemanager.placement.FSPlacementRule	setParentRule	parentRule	C	org.apache.hadoop.yarn.server.resourcemanager.placement.PlacementRule	0	org.apache.hadoop.yarn.server.resourcemanager.placement.FSPlacementRule:setParentRule(org.apache.hadoop.yarn.server.resourcemanager.placement.PlacementRule)
org.apache.hadoop.yarn.server.resourcemanager.placement.UserGroupMappingPlacementRule	setQueueManager	queueManager	C	org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerQueueManager	0	org.apache.hadoop.yarn.server.resourcemanager.placement.UserGroupMappingPlacementRule:setQueueManager(org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerQueueManager)
org.apache.hadoop.yarn.server.resourcemanager.volume.csi.lifecycle.VolumeImpl	setClient	adaptorClient	C	org.apache.hadoop.yarn.api.CsiAdaptorProtocol	0	org.apache.hadoop.yarn.server.resourcemanager.volume.csi.lifecycle.VolumeImpl:setClient(org.apache.hadoop.yarn.api.CsiAdaptorProtocol)
org.apache.hadoop.yarn.server.resourcemanager.RMServiceContext	setResourceManager	resourceManager	C	org.apache.hadoop.yarn.server.resourcemanager.ResourceManager	0	org.apache.hadoop.yarn.server.resourcemanager.RMServiceContext:setResourceManager(org.apache.hadoop.yarn.server.resourcemanager.ResourceManager)
org.apache.hadoop.yarn.server.resourcemanager.RMServiceContext	setConfigurationProvider	configurationProvider	C	org.apache.hadoop.yarn.conf.ConfigurationProvider	0	org.apache.hadoop.yarn.server.resourcemanager.RMServiceContext:setConfigurationProvider(org.apache.hadoop.yarn.conf.ConfigurationProvider)
org.apache.hadoop.yarn.server.resourcemanager.RMServiceContext	setDispatcher	rmDispatcher	C	org.apache.hadoop.yarn.event.Dispatcher	0	org.apache.hadoop.yarn.server.resourcemanager.RMServiceContext:setDispatcher(org.apache.hadoop.yarn.event.Dispatcher)
org.apache.hadoop.yarn.server.resourcemanager.RMServiceContext	setLeaderElectorService	elector	C	org.apache.hadoop.yarn.server.resourcemanager.EmbeddedElector	0	org.apache.hadoop.yarn.server.resourcemanager.RMServiceContext:setLeaderElectorService(org.apache.hadoop.yarn.server.resourcemanager.EmbeddedElector)
org.apache.hadoop.yarn.server.resourcemanager.RMServiceContext	setRMAdminService	adminService	C	org.apache.hadoop.yarn.server.resourcemanager.AdminService	0	org.apache.hadoop.yarn.server.resourcemanager.RMServiceContext:setRMAdminService(org.apache.hadoop.yarn.server.resourcemanager.AdminService)
org.apache.hadoop.yarn.server.resourcemanager.RMServiceContext	setHAEnabled	isHAEnabled	J	boolean	0	org.apache.hadoop.yarn.server.resourcemanager.RMServiceContext:setHAEnabled(boolean)
org.apache.hadoop.yarn.server.resourcemanager.RMServiceContext	setHAServiceState	haServiceState	C	org.apache.hadoop.ha.HAServiceProtocol$HAServiceState	0	org.apache.hadoop.yarn.server.resourcemanager.RMServiceContext:setHAServiceState(org.apache.hadoop.ha.HAServiceProtocol$HAServiceState)
org.apache.hadoop.yarn.server.resourcemanager.RMServiceContext	setRMApplicationHistoryWriter	rmApplicationHistoryWriter	C	org.apache.hadoop.yarn.server.resourcemanager.ahs.RMApplicationHistoryWriter	0	org.apache.hadoop.yarn.server.resourcemanager.RMServiceContext:setRMApplicationHistoryWriter(org.apache.hadoop.yarn.server.resourcemanager.ahs.RMApplicationHistoryWriter)
org.apache.hadoop.yarn.server.resourcemanager.RMServiceContext	setSystemMetricsPublisher	systemMetricsPublisher	C	org.apache.hadoop.yarn.server.resourcemanager.metrics.SystemMetricsPublisher	0	org.apache.hadoop.yarn.server.resourcemanager.RMServiceContext:setSystemMetricsPublisher(org.apache.hadoop.yarn.server.resourcemanager.metrics.SystemMetricsPublisher)
org.apache.hadoop.yarn.server.resourcemanager.RMServiceContext	setYarnConfiguration	yarnConfiguration	C	org.apache.hadoop.conf.Configuration	0	org.apache.hadoop.yarn.server.resourcemanager.RMServiceContext:setYarnConfiguration(org.apache.hadoop.conf.Configuration)
org.apache.hadoop.yarn.server.resourcemanager.RMServiceContext	setRMTimelineCollectorManager	timelineCollectorManager	C	org.apache.hadoop.yarn.server.resourcemanager.timelineservice.RMTimelineCollectorManager	0	org.apache.hadoop.yarn.server.resourcemanager.RMServiceContext:setRMTimelineCollectorManager(org.apache.hadoop.yarn.server.resourcemanager.timelineservice.RMTimelineCollectorManager)
org.apache.hadoop.yarn.server.resourcemanager.DBManager	setDb	db	C	org.iq80.leveldb.DB	0	org.apache.hadoop.yarn.server.resourcemanager.DBManager:setDb(org.iq80.leveldb.DB)
org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.QueueEntitlement	setMaxCapacity	maxCapacity	J	float	0	org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.QueueEntitlement:setMaxCapacity(float)
org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.QueueEntitlement	setCapacity	capacity	J	float	0	org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.QueueEntitlement:setCapacity(float)
org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp	setHeadroomProvider	headroomProvider	C	org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityHeadroomProvider	0	org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp:setHeadroomProvider(org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityHeadroomProvider)
org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp	setRunnable	runnable	J	boolean	0	org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp:setRunnable(boolean)
org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo	setQueue	queue	C	org.apache.hadoop.yarn.server.resourcemanager.scheduler.Queue	0	org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo:setQueue(org.apache.hadoop.yarn.server.resourcemanager.scheduler.Queue)
org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode	setReservedContainer	reservedContainer	C	org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainer	0	org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode:setReservedContainer(org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainer)
org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode	setAggregatedContainersUtilization	containersUtilization	C	org.apache.hadoop.yarn.api.records.ResourceUtilization	0	org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode:setAggregatedContainersUtilization(org.apache.hadoop.yarn.api.records.ResourceUtilization)
org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode	setNodeUtilization	nodeUtilization	C	org.apache.hadoop.yarn.api.records.ResourceUtilization	0	org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode:setNodeUtilization(org.apache.hadoop.yarn.api.records.ResourceUtilization)
org.apache.hadoop.yarn.server.resourcemanager.scheduler.placement.MultiNodePolicySpec	setSortingInterval	sortingInterval	J	long	0	org.apache.hadoop.yarn.server.resourcemanager.scheduler.placement.MultiNodePolicySpec:setSortingInterval(long)
org.apache.hadoop.yarn.server.resourcemanager.scheduler.placement.MultiNodePolicySpec	setPolicyName	policyName	J	java.lang.String	0	org.apache.hadoop.yarn.server.resourcemanager.scheduler.placement.MultiNodePolicySpec:setPolicyName(java.lang.String)
org.apache.hadoop.yarn.server.resourcemanager.scheduler.placement.MultiNodeSortingManager	setRMContext	rmContext	C	org.apache.hadoop.yarn.server.resourcemanager.RMContext	0	org.apache.hadoop.yarn.server.resourcemanager.scheduler.placement.MultiNodeSortingManager:setRMContext(org.apache.hadoop.yarn.server.resourcemanager.RMContext)
org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerApplicationAttempt	setOpportunisticContainerContext	oppContainerContext	C	org.apache.hadoop.yarn.server.scheduler.OpportunisticContainerContext	0	org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerApplicationAttempt:setOpportunisticContainerContext(org.apache.hadoop.yarn.server.scheduler.OpportunisticContainerContext)
org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerApplicationAttempt	setAmRunning	amRunning	J	boolean	0	org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerApplicationAttempt:setAmRunning(boolean)
org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerApplicationAttempt	setHeadroom	resourceLimit	C	org.apache.hadoop.yarn.api.records.Resource	0	org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerApplicationAttempt:setHeadroom(org.apache.hadoop.yarn.api.records.Resource)
org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerApplicationAttempt	setPriority	appPriority	C	org.apache.hadoop.yarn.api.records.Priority	0	org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerApplicationAttempt:setPriority(org.apache.hadoop.yarn.api.records.Priority)
org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerApplicationAttempt	setAppAMNodePartitionName	appAMNodePartitionName	J	java.lang.String	0	org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerApplicationAttempt:setAppAMNodePartitionName(java.lang.String)
org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerApplicationAttempt	setAttemptRecovering	isAttemptRecovering	J	boolean	0	org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerApplicationAttempt:setAttemptRecovering(boolean)
org.apache.hadoop.yarn.server.resourcemanager.scheduler.QueueMetrics	setQueueMetricsForCustomResources	queueMetricsForCustomResources	C	org.apache.hadoop.yarn.server.resourcemanager.scheduler.QueueMetricsForCustomResources	0	org.apache.hadoop.yarn.server.resourcemanager.scheduler.QueueMetrics:setQueueMetricsForCustomResources(org.apache.hadoop.yarn.server.resourcemanager.scheduler.QueueMetricsForCustomResources)
org.apache.hadoop.yarn.server.resourcemanager.scheduler.QueueMetrics	setParent	parent	C	org.apache.hadoop.yarn.server.resourcemanager.scheduler.QueueMetrics	0	org.apache.hadoop.yarn.server.resourcemanager.scheduler.QueueMetrics:setParent(org.apache.hadoop.yarn.server.resourcemanager.scheduler.QueueMetrics)
org.apache.hadoop.yarn.server.resourcemanager.scheduler.Allocation	setResourceLimit	resourceLimit	C	org.apache.hadoop.yarn.api.records.Resource	0	org.apache.hadoop.yarn.server.resourcemanager.scheduler.Allocation:setResourceLimit(org.apache.hadoop.yarn.api.records.Resource)
org.apache.hadoop.yarn.server.resourcemanager.scheduler.ClusterNodeTracker	setConfiguredMaxAllocation	configuredMaxAllocation	C	org.apache.hadoop.yarn.api.records.Resource	0	org.apache.hadoop.yarn.server.resourcemanager.scheduler.ClusterNodeTracker:setConfiguredMaxAllocation(org.apache.hadoop.yarn.api.records.Resource)
org.apache.hadoop.yarn.server.resourcemanager.scheduler.ClusterNodeTracker	setConfiguredMaxAllocationWaitTime	configuredMaxAllocationWaitTime	J	long	0	org.apache.hadoop.yarn.server.resourcemanager.scheduler.ClusterNodeTracker:setConfiguredMaxAllocationWaitTime(long)
org.apache.hadoop.yarn.server.resourcemanager.scheduler.ClusterNodeTracker	setForceConfiguredMaxAllocation	forceConfiguredMaxAllocation	J	boolean	0	org.apache.hadoop.yarn.server.resourcemanager.scheduler.ClusterNodeTracker:setForceConfiguredMaxAllocation(boolean)
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.UsersManager	setUserLimit	userLimit	J	int	0	org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.UsersManager:setUserLimit(int)
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.UsersManager	setUserLimitFactor	userLimitFactor	J	float	0	org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.UsersManager:setUserLimitFactor(float)
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler	setConf	yarnConf	C	org.apache.hadoop.conf.Configuration	0	org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler:setConf(org.apache.hadoop.conf.Configuration)
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler	setResourceCalculator	calculator	C	org.apache.hadoop.yarn.util.resource.ResourceCalculator	0	org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler:setResourceCalculator(org.apache.hadoop.yarn.util.resource.ResourceCalculator)
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler	setMaxRunningAppsEnforcer	maxRunningEnforcer	C	org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CSMaxRunningAppsEnforcer	0	org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler:setMaxRunningAppsEnforcer(org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CSMaxRunningAppsEnforcer)
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler	setQueueManager	queueManager	C	org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerQueueManager	0	org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler:setQueueManager(org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerQueueManager)
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CSAssignment	setResource	resource	C	org.apache.hadoop.yarn.api.records.Resource	0	org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CSAssignment:setResource(org.apache.hadoop.yarn.api.records.Resource)
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CSAssignment	setType	type	C	org.apache.hadoop.yarn.server.resourcemanager.scheduler.NodeType	0	org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CSAssignment:setType(org.apache.hadoop.yarn.server.resourcemanager.scheduler.NodeType)
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CSAssignment	setApplication	application	C	org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp	0	org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CSAssignment:setApplication(org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp)
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CSAssignment	setExcessReservation	excessReservation	C	org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainer	0	org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CSAssignment:setExcessReservation(org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainer)
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CSAssignment	setSkippedType	skipped	C	org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CSAssignment$SkippedType	0	org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CSAssignment:setSkippedType(org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CSAssignment$SkippedType)
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CSAssignment	setFulfilledReservation	fulfilledReservation	J	boolean	0	org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CSAssignment:setFulfilledReservation(boolean)
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CSAssignment	setIncreasedAllocation	increaseAllocation	J	boolean	0	org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CSAssignment:setIncreasedAllocation(boolean)
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CSAssignment	setContainersToKill	containersToKill	GC	java.util.List	0	org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CSAssignment:setContainersToKill(java.util.List)
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CSAssignment	setFulfilledReservedContainer	fulfilledReservedContainer	C	org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainer	0	org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CSAssignment:setFulfilledReservedContainer(org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainer)
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CSAssignment	setSchedulingMode	schedulingMode	C	org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.SchedulingMode	0	org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CSAssignment:setSchedulingMode(org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.SchedulingMode)
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CSAssignment	setRequestLocalityType	requestLocalityType	C	org.apache.hadoop.yarn.server.resourcemanager.scheduler.NodeType	0	org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CSAssignment:setRequestLocalityType(org.apache.hadoop.yarn.server.resourcemanager.scheduler.NodeType)
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerQueueManager	setCapacitySchedulerContext	csContext	C	org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerContext	0	org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerQueueManager:setCapacitySchedulerContext(org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerContext)
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.policy.PriorityUtilizationQueueOrderingPolicy	setQueues	queues	GC	java.util.List	0	org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.policy.PriorityUtilizationQueueOrderingPolicy:setQueues(java.util.List)
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.AppPriorityACLGroup	setMaxPriority	maxPriority	C	org.apache.hadoop.yarn.api.records.Priority	0	org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.AppPriorityACLGroup:setMaxPriority(org.apache.hadoop.yarn.api.records.Priority)
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.AppPriorityACLGroup	setDefaultPriority	defaultPriority	C	org.apache.hadoop.yarn.api.records.Priority	0	org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.AppPriorityACLGroup:setDefaultPriority(org.apache.hadoop.yarn.api.records.Priority)
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.AppPriorityACLGroup	setACLList	aclList	C	org.apache.hadoop.security.authorize.AccessControlList	0	org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.AppPriorityACLGroup:setACLList(org.apache.hadoop.security.authorize.AccessControlList)
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.UsersManager$User	setUserResourceLimit	userResourceLimit	C	org.apache.hadoop.yarn.api.records.Resource	0	org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.UsersManager$User:setUserResourceLimit(org.apache.hadoop.yarn.api.records.Resource)
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.UsersManager$User	setResourceUsage	userResourceUsage	C	org.apache.hadoop.yarn.server.resourcemanager.scheduler.ResourceUsage	0	org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.UsersManager$User:setResourceUsage(org.apache.hadoop.yarn.server.resourcemanager.scheduler.ResourceUsage)
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.UsersManager$User	setWeight	weight	J	float	0	org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.UsersManager$User:setWeight(float)
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.AbstractCSQueue	setParent	parent	C	org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CSQueue	0	org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.AbstractCSQueue:setParent(org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CSQueue)
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.AbstractCSQueue	setMultiNodeSortingPolicyName	multiNodeSortingPolicyName	J	java.lang.String	0	org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.AbstractCSQueue:setMultiNodeSortingPolicyName(java.lang.String)
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.AbstractCSQueue	setMaxParallelApps	maxParallelApps	J	int	0	org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.AbstractCSQueue:setMaxParallelApps(int)
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.ContainerAllocation	setToKillContainers	toKillContainers	GC	java.util.List	0	org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.ContainerAllocation:setToKillContainers(java.util.List)
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue$QueueResourceLimitsInfo	setQueueCurrentLimit	queueCurrentLimit	C	org.apache.hadoop.yarn.api.records.Resource	0	org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue$QueueResourceLimitsInfo:setQueueCurrentLimit(org.apache.hadoop.yarn.api.records.Resource)
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue$QueueResourceLimitsInfo	setClusterResource	clusterResource	C	org.apache.hadoop.yarn.api.records.Resource	0	org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue$QueueResourceLimitsInfo:setClusterResource(org.apache.hadoop.yarn.api.records.Resource)
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue	setMaxApplicationsPerUser	maxApplicationsPerUser	J	int	0	org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue:setMaxApplicationsPerUser(int)
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue	setMaxApplications	maxApplications	J	int	0	org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue:setMaxApplications(int)
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue	setMaxAMResourcePerQueuePercent	maxAMResourcePerQueuePercent	J	float	0	org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue:setMaxAMResourcePerQueuePercent(float)
org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSQueue	setPolicy	policy	C	org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.SchedulingPolicy	0	org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSQueue:setPolicy(org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.SchedulingPolicy)
org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSQueue	setWeights	weights	J	float	0	org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSQueue:setWeights(float)
org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSQueue	setMinShare	minShare	C	org.apache.hadoop.yarn.api.records.Resource	0	org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSQueue:setMinShare(org.apache.hadoop.yarn.api.records.Resource)
org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSQueue	setMaxShare	maxShare	C	org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.ConfigurableResource	0	org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSQueue:setMaxShare(org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.ConfigurableResource)
org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSQueue	setMaxContainerAllocation	maxContainerAllocation	C	org.apache.hadoop.yarn.api.records.Resource	0	org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSQueue:setMaxContainerAllocation(org.apache.hadoop.yarn.api.records.Resource)
org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSQueue	setMaxChildQueueResource	maxChildQueueResource	C	org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.ConfigurableResource	0	org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSQueue:setMaxChildQueueResource(org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.ConfigurableResource)
org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSQueue	setMaxRunningApps	maxRunningApps	J	int	0	org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSQueue:setMaxRunningApps(int)
org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSQueue	setMaxAMShare	maxAMShare	J	float	0	org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSQueue:setMaxAMShare(float)
org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSQueue	setFairShare	fairShare	C	org.apache.hadoop.yarn.api.records.Resource	0	org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSQueue:setFairShare(org.apache.hadoop.yarn.api.records.Resource)
org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSQueue	setSteadyFairShare	steadyFairShare	C	org.apache.hadoop.yarn.api.records.Resource	0	org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSQueue:setSteadyFairShare(org.apache.hadoop.yarn.api.records.Resource)
org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSQueue	setFairSharePreemptionTimeout	fairSharePreemptionTimeout	J	long	0	org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSQueue:setFairSharePreemptionTimeout(long)
org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSQueue	setMinSharePreemptionTimeout	minSharePreemptionTimeout	J	long	0	org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSQueue:setMinSharePreemptionTimeout(long)
org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSQueue	setFairSharePreemptionThreshold	fairSharePreemptionThreshold	J	float	0	org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSQueue:setFairSharePreemptionThreshold(float)
org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSQueue	setDynamic	isDynamic	J	boolean	0	org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSQueue:setDynamic(boolean)
org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.AllocationFileLoaderService	setReloadListener	reloadListener	C	org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.AllocationFileLoaderService$Listener	0	org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.AllocationFileLoaderService:setReloadListener(org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.AllocationFileLoaderService$Listener)
org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSLeafQueue	setLastTimeAtMinShare	lastTimeAtMinShare	J	long	0	org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSLeafQueue:setLastTimeAtMinShare(long)
org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSContext	setPreemptionUtilizationThreshold	preemptionUtilizationThreshold	J	float	0	org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSContext:setPreemptionUtilizationThreshold(float)
org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.DominantResourceFairnessPolicy$DominantResourceFairnessComparator	setFSContext	fsContext	C	org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSContext	0	org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.DominantResourceFairnessPolicy$DominantResourceFairnessComparator:setFSContext(org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSContext)
org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.converter.FSConfigToCSConfigConverter	setClusterResource	clusterResource	C	org.apache.hadoop.yarn.api.records.Resource	0	org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.converter.FSConfigToCSConfigConverter:setClusterResource(org.apache.hadoop.yarn.api.records.Resource)
org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.converter.FSConfigToCSConfigConverter	setConvertPlacementRules	convertPlacementRules	J	boolean	0	org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.converter.FSConfigToCSConfigConverter:setConvertPlacementRules(boolean)
org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.converter.FSConfigToCSConfigConverter	setPlacementConverter	placementConverter	C	org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.converter.QueuePlacementConverter	0	org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.converter.FSConfigToCSConfigConverter:setPlacementConverter(org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.converter.QueuePlacementConverter)
org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.converter.ConversionOptions	setDryRun	dryRun	J	boolean	0	org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.converter.ConversionOptions:setDryRun(boolean)
org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.converter.ConversionOptions	setNoTerminalRuleCheck	noTerminalRuleCheck	J	boolean	0	org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.converter.ConversionOptions:setNoTerminalRuleCheck(boolean)
org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.converter.ConversionOptions	setEnableAsyncScheduler	enableAsyncScheduler	J	boolean	0	org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.converter.ConversionOptions:setEnableAsyncScheduler(boolean)
org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.converter.FSConfigToCSConfigArgumentHandler	setConverterSupplier	converterFunc	GC	java.util.function.Supplier	0	org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.converter.FSConfigToCSConfigArgumentHandler:setConverterSupplier(java.util.function.Supplier)
org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSQueueMetrics	setSchedulingPolicy	schedulingPolicy	J	java.lang.String	0	org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSQueueMetrics:setSchedulingPolicy(java.lang.String)
org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt	setMinshareStarvation	minshareStarvation	C	org.apache.hadoop.yarn.api.records.Resource	0	org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt:setMinshareStarvation(org.apache.hadoop.yarn.api.records.Resource)
org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt	setFairShare	fairShare	C	org.apache.hadoop.yarn.api.records.Resource	0	org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt:setFairShare(org.apache.hadoop.yarn.api.records.Resource)
org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt	setEnableAMPreemption	enableAMPreemption	J	boolean	0	org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt:setEnableAMPreemption(boolean)
org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.ReservationQueueConfiguration	setPlanner	planner	J	java.lang.String	0	org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.ReservationQueueConfiguration:setPlanner(java.lang.String)
org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.ReservationQueueConfiguration	setReservationAdmissionPolicy	reservationAdmissionPolicy	J	java.lang.String	0	org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.ReservationQueueConfiguration:setReservationAdmissionPolicy(java.lang.String)
org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.ReservationQueueConfiguration	setReservationAgent	reservationAgent	J	java.lang.String	0	org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.ReservationQueueConfiguration:setReservationAgent(java.lang.String)
org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.ReservationQueueConfiguration	setReservationWindow	reservationWindow	J	long	0	org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.ReservationQueueConfiguration:setReservationWindow(long)
org.apache.hadoop.yarn.server.resourcemanager.scheduler.policy.IteratorSelector	setPartition	partition	J	java.lang.String	0	org.apache.hadoop.yarn.server.resourcemanager.scheduler.policy.IteratorSelector:setPartition(java.lang.String)
org.apache.hadoop.yarn.server.resourcemanager.scheduler.policy.FairOrderingPolicy	setSizeBasedWeight	sizeBasedWeight	J	boolean	0	org.apache.hadoop.yarn.server.resourcemanager.scheduler.policy.FairOrderingPolicy:setSizeBasedWeight(boolean)
org.apache.hadoop.yarn.server.resourcemanager.scheduler.activities.AppAllocation	setAllocationAttempts	allocationAttempts	GC	java.util.List	0	org.apache.hadoop.yarn.server.resourcemanager.scheduler.activities.AppAllocation:setAllocationAttempts(java.util.List)
org.apache.hadoop.yarn.server.resourcemanager.scheduler.activities.NodeAllocation	setTimestamp	timestamp	J	long	0	org.apache.hadoop.yarn.server.resourcemanager.scheduler.activities.NodeAllocation:setTimestamp(long)
org.apache.hadoop.yarn.server.resourcemanager.scheduler.activities.NodeAllocation	setPartition	partition	J	java.lang.String	0	org.apache.hadoop.yarn.server.resourcemanager.scheduler.activities.NodeAllocation:setPartition(java.lang.String)
org.apache.hadoop.yarn.server.resourcemanager.scheduler.fifo.FifoScheduler	setConf	conf	C	org.apache.hadoop.conf.Configuration	0	org.apache.hadoop.yarn.server.resourcemanager.scheduler.fifo.FifoScheduler:setConf(org.apache.hadoop.conf.Configuration)
org.apache.hadoop.yarn.server.resourcemanager.scheduler.constraint.TargetApplicationsNamespace$NotSelf	setApplicationId	applicationId	C	org.apache.hadoop.yarn.api.records.ApplicationId	0	org.apache.hadoop.yarn.server.resourcemanager.scheduler.constraint.TargetApplicationsNamespace$NotSelf:setApplicationId(org.apache.hadoop.yarn.api.records.ApplicationId)
org.apache.hadoop.yarn.server.resourcemanager.scheduler.constraint.TargetApplicationsNamespace	setScopeIfNotNull	nsScope	GC	java.util.Set	0	org.apache.hadoop.yarn.server.resourcemanager.scheduler.constraint.TargetApplicationsNamespace:setScopeIfNotNull(java.util.Set)
org.apache.hadoop.yarn.server.resourcemanager.scheduler.constraint.api.PlacedSchedulingRequest	setPlacementAttempt	placementAttempt	J	int	0	org.apache.hadoop.yarn.server.resourcemanager.scheduler.constraint.api.PlacedSchedulingRequest:setPlacementAttempt(int)
org.apache.hadoop.yarn.server.resourcemanager.scheduler.distributed.NodeQueueLoadMonitor$ClusterNode	setQueueCapacity	queueCapacity	J	int	0	org.apache.hadoop.yarn.server.resourcemanager.scheduler.distributed.NodeQueueLoadMonitor$ClusterNode:setQueueCapacity(int)
org.apache.hadoop.yarn.server.resourcemanager.scheduler.distributed.CentralizedOpportunisticContainerAllocator	setNodeQueueLoadMonitor	nodeQueueLoadMonitor	C	org.apache.hadoop.yarn.server.resourcemanager.scheduler.distributed.NodeQueueLoadMonitor	0	org.apache.hadoop.yarn.server.resourcemanager.scheduler.distributed.CentralizedOpportunisticContainerAllocator:setNodeQueueLoadMonitor(org.apache.hadoop.yarn.server.resourcemanager.scheduler.distributed.NodeQueueLoadMonitor)
org.apache.hadoop.yarn.server.resourcemanager.scheduler.ResourceLimits	setHeadroom	headroom	C	org.apache.hadoop.yarn.api.records.Resource	0	org.apache.hadoop.yarn.server.resourcemanager.scheduler.ResourceLimits:setHeadroom(org.apache.hadoop.yarn.api.records.Resource)
org.apache.hadoop.yarn.server.resourcemanager.scheduler.ResourceLimits	setLimit	limit	C	org.apache.hadoop.yarn.api.records.Resource	0	org.apache.hadoop.yarn.server.resourcemanager.scheduler.ResourceLimits:setLimit(org.apache.hadoop.yarn.api.records.Resource)
org.apache.hadoop.yarn.server.resourcemanager.scheduler.ResourceLimits	setAmountNeededUnreserve	amountNeededUnreserve	C	org.apache.hadoop.yarn.api.records.Resource	0	org.apache.hadoop.yarn.server.resourcemanager.scheduler.ResourceLimits:setAmountNeededUnreserve(org.apache.hadoop.yarn.api.records.Resource)
org.apache.hadoop.yarn.server.resourcemanager.scheduler.ResourceLimits	setIsAllowPreemption	allowPreempt	J	boolean	0	org.apache.hadoop.yarn.server.resourcemanager.scheduler.ResourceLimits:setIsAllowPreemption(boolean)
org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler	setLastNodeUpdateTime	lastNodeUpdateTime	J	long	0	org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler:setLastNodeUpdateTime(long)
org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler	setClock	clock	C	org.apache.hadoop.yarn.util.Clock	0	org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler:setClock(org.apache.hadoop.yarn.util.Clock)
org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerApplication	setQueue	queue	C	org.apache.hadoop.yarn.server.resourcemanager.scheduler.Queue	0	org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerApplication:setQueue(org.apache.hadoop.yarn.server.resourcemanager.scheduler.Queue)
org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerApplication	setCurrentAppAttempt	currentAttempt	GC	org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerApplicationAttempt	0	org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerApplication:setCurrentAppAttempt(org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerApplicationAttempt)
org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerApplication	setPriority	priority	C	org.apache.hadoop.yarn.api.records.Priority	0	org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerApplication:setPriority(org.apache.hadoop.yarn.api.records.Priority)
org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore	setRMDispatcher	rmDispatcher	C	org.apache.hadoop.yarn.event.Dispatcher	0	org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore:setRMDispatcher(org.apache.hadoop.yarn.event.Dispatcher)
org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore	setResourceManager	resourceManager	C	org.apache.hadoop.yarn.server.resourcemanager.ResourceManager	0	org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore:setResourceManager(org.apache.hadoop.yarn.server.resourcemanager.ResourceManager)
org.apache.hadoop.yarn.server.resourcemanager.recovery.records.impl.pb.ApplicationAttemptStateDataPBImpl	setAttemptId	attemptId	C	org.apache.hadoop.yarn.api.records.ApplicationAttemptId	0	org.apache.hadoop.yarn.server.resourcemanager.recovery.records.impl.pb.ApplicationAttemptStateDataPBImpl:setAttemptId(org.apache.hadoop.yarn.api.records.ApplicationAttemptId)
org.apache.hadoop.yarn.server.resourcemanager.recovery.records.impl.pb.ApplicationAttemptStateDataPBImpl	setMasterContainer	masterContainer	C	org.apache.hadoop.yarn.api.records.Container	0	org.apache.hadoop.yarn.server.resourcemanager.recovery.records.impl.pb.ApplicationAttemptStateDataPBImpl:setMasterContainer(org.apache.hadoop.yarn.api.records.Container)
org.apache.hadoop.yarn.server.resourcemanager.recovery.records.impl.pb.ApplicationAttemptStateDataPBImpl	setResourceSecondsMap	resourceSecondsMap	GJ	java.util.Map	0	org.apache.hadoop.yarn.server.resourcemanager.recovery.records.impl.pb.ApplicationAttemptStateDataPBImpl:setResourceSecondsMap(java.util.Map)
org.apache.hadoop.yarn.server.resourcemanager.recovery.records.impl.pb.ApplicationAttemptStateDataPBImpl	setPreemptedResourceSecondsMap	preemptedResourceSecondsMap	GJ	java.util.Map	0	org.apache.hadoop.yarn.server.resourcemanager.recovery.records.impl.pb.ApplicationAttemptStateDataPBImpl:setPreemptedResourceSecondsMap(java.util.Map)
org.apache.hadoop.yarn.server.resourcemanager.recovery.records.impl.pb.ApplicationStateDataPBImpl	setApplicationSubmissionContext	applicationSubmissionContext	C	org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext	0	org.apache.hadoop.yarn.server.resourcemanager.recovery.records.impl.pb.ApplicationStateDataPBImpl:setApplicationSubmissionContext(org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext)
org.apache.hadoop.yarn.server.resourcemanager.recovery.records.impl.pb.AMRMTokenSecretManagerStatePBImpl	setCurrentMasterKey	currentMasterKey	C	org.apache.hadoop.yarn.server.api.records.MasterKey	0	org.apache.hadoop.yarn.server.resourcemanager.recovery.records.impl.pb.AMRMTokenSecretManagerStatePBImpl:setCurrentMasterKey(org.apache.hadoop.yarn.server.api.records.MasterKey)
org.apache.hadoop.yarn.server.resourcemanager.recovery.records.impl.pb.AMRMTokenSecretManagerStatePBImpl	setNextMasterKey	nextMasterKey	C	org.apache.hadoop.yarn.server.api.records.MasterKey	0	org.apache.hadoop.yarn.server.resourcemanager.recovery.records.impl.pb.AMRMTokenSecretManagerStatePBImpl:setNextMasterKey(org.apache.hadoop.yarn.server.api.records.MasterKey)
org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$ProxyCAState	setCaCert	caCert	J	java.security.cert.X509Certificate	0	org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$ProxyCAState:setCaCert(java.security.cert.X509Certificate)
org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$ProxyCAState	setCaPrivateKey	caPrivateKey	J	java.security.PrivateKey	0	org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$ProxyCAState:setCaPrivateKey(java.security.PrivateKey)
org.apache.hadoop.yarn.server.resourcemanager.recovery.LeveldbRMStateStore	setDbManager	dbManager	C	org.apache.hadoop.yarn.server.resourcemanager.DBManager	0	org.apache.hadoop.yarn.server.resourcemanager.recovery.LeveldbRMStateStore:setDbManager(org.apache.hadoop.yarn.server.resourcemanager.DBManager)
org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl	setQueue	queue	J	java.lang.String	0	org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl:setQueue(java.lang.String)
org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl	setCollectorData	collectorData	C	org.apache.hadoop.yarn.server.api.records.AppCollectorData	0	org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl:setCollectorData(org.apache.hadoop.yarn.server.api.records.AppCollectorData)
org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl	setSystemClock	systemClock	C	org.apache.hadoop.yarn.util.Clock	0	org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl:setSystemClock(org.apache.hadoop.yarn.util.Clock)
org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl	setApplicationPriority	applicationPriority	C	org.apache.hadoop.yarn.api.records.Priority	0	org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl:setApplicationPriority(org.apache.hadoop.yarn.api.records.Priority)
org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl	setAMRMToken	amrmToken	GC	org.apache.hadoop.security.token.Token	0	org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl:setAMRMToken(org.apache.hadoop.security.token.Token)
org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl	setMasterContainer	masterContainer	C	org.apache.hadoop.yarn.api.records.Container	0	org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl:setMasterContainer(org.apache.hadoop.yarn.api.records.Container)
org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl	setFinishTime	finishTime	J	long	0	org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl:setFinishTime(long)
org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl	setRecoveredFinalState	recoveredFinalState	C	org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptState	0	org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl:setRecoveredFinalState(org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptState)
org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptMetrics	setTotalAllocatedContainers	totalAllocatedContainers	J	int	0	org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptMetrics:setTotalAllocatedContainers(int)
org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptMetrics	setApplicationAttemptHeadRoom	applicationHeadroom	C	org.apache.hadoop.yarn.api.records.Resource	0	org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptMetrics:setApplicationAttemptHeadRoom(org.apache.hadoop.yarn.api.records.Resource)
org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl	setHttpPort	httpPort	J	int	0	org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl:setHttpPort(int)
org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl	setHealthReport	healthReport	J	java.lang.String	0	org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl:setHealthReport(java.lang.String)
org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl	setLastHealthReportTime	lastHealthReportTime	J	long	0	org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl:setLastHealthReportTime(long)
org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl	setAggregatedContainersUtilization	containersUtilization	C	org.apache.hadoop.yarn.api.records.ResourceUtilization	0	org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl:setAggregatedContainersUtilization(org.apache.hadoop.yarn.api.records.ResourceUtilization)
org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl	setNodeUtilization	nodeUtilization	C	org.apache.hadoop.yarn.api.records.ResourceUtilization	0	org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl:setNodeUtilization(org.apache.hadoop.yarn.api.records.ResourceUtilization)
org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl	setPhysicalResource	physicalResource	C	org.apache.hadoop.yarn.api.records.Resource	0	org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl:setPhysicalResource(org.apache.hadoop.yarn.api.records.Resource)
org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl	setNextHeartBeat	nextHeartBeat	J	boolean	0	org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl:setNextHeartBeat(boolean)
org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl	setOpportunisticContainersStatus	opportunisticContainersStatus	C	org.apache.hadoop.yarn.server.api.records.OpportunisticContainersStatus	0	org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl:setOpportunisticContainersStatus(org.apache.hadoop.yarn.server.api.records.OpportunisticContainersStatus)
org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl	setUntrackedTimeStamp	timeStamp	J	long	0	org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl:setUntrackedTimeStamp(long)
org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeStartedEvent	setLogAggregationReportsForApps	logAggregationReportsForApps	GC	java.util.List	0	org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeStartedEvent:setLogAggregationReportsForApps(java.util.List)
org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeStatusEvent	setLogAggregationReportsForApps	logAggregationReportsForApps	GC	java.util.List	0	org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeStatusEvent:setLogAggregationReportsForApps(java.util.List)
org.apache.hadoop.yarn.server.resourcemanager.monitor.capacity.AbstractPreemptionEntity	setActuallyToBePreempted	actuallyToBePreempted	C	org.apache.hadoop.yarn.api.records.Resource	0	org.apache.hadoop.yarn.server.resourcemanager.monitor.capacity.AbstractPreemptionEntity:setActuallyToBePreempted(org.apache.hadoop.yarn.api.records.Resource)
org.apache.hadoop.yarn.server.resourcemanager.monitor.capacity.AbstractPreemptionEntity	setToBePreemptFromOther	toBePreemptFromOther	C	org.apache.hadoop.yarn.api.records.Resource	0	org.apache.hadoop.yarn.server.resourcemanager.monitor.capacity.AbstractPreemptionEntity:setToBePreemptFromOther(org.apache.hadoop.yarn.api.records.Resource)
org.apache.hadoop.yarn.server.resourcemanager.monitor.capacity.TempAppPerPartition	setTempUserPerPartition	tempUser	C	org.apache.hadoop.yarn.server.resourcemanager.monitor.capacity.TempUserPerPartition	0	org.apache.hadoop.yarn.server.resourcemanager.monitor.capacity.TempAppPerPartition:setTempUserPerPartition(org.apache.hadoop.yarn.server.resourcemanager.monitor.capacity.TempUserPerPartition)
org.apache.hadoop.yarn.server.resourcemanager.monitor.capacity.TempSchedulerNode	setRunningContainers	runningContainers	GC	java.util.List	0	org.apache.hadoop.yarn.server.resourcemanager.monitor.capacity.TempSchedulerNode:setRunningContainers(java.util.List)
org.apache.hadoop.yarn.server.resourcemanager.monitor.capacity.TempSchedulerNode	setReservedContainer	reservedContainer	C	org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainer	0	org.apache.hadoop.yarn.server.resourcemanager.monitor.capacity.TempSchedulerNode:setReservedContainer(org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainer)
org.apache.hadoop.yarn.server.resourcemanager.monitor.capacity.TempSchedulerNode	setTotalResource	totalResource	C	org.apache.hadoop.yarn.api.records.Resource	0	org.apache.hadoop.yarn.server.resourcemanager.monitor.capacity.TempSchedulerNode:setTotalResource(org.apache.hadoop.yarn.api.records.Resource)
org.apache.hadoop.yarn.server.resourcemanager.monitor.capacity.TempSchedulerNode	setAllocatedResource	allocatedResource	C	org.apache.hadoop.yarn.api.records.Resource	0	org.apache.hadoop.yarn.server.resourcemanager.monitor.capacity.TempSchedulerNode:setAllocatedResource(org.apache.hadoop.yarn.api.records.Resource)
org.apache.hadoop.yarn.server.resourcemanager.monitor.capacity.TempSchedulerNode	setAvailableResource	availableResource	C	org.apache.hadoop.yarn.api.records.Resource	0	org.apache.hadoop.yarn.server.resourcemanager.monitor.capacity.TempSchedulerNode:setAvailableResource(org.apache.hadoop.yarn.api.records.Resource)
org.apache.hadoop.yarn.server.resourcemanager.monitor.capacity.TempSchedulerNode	setReservedResource	reservedResource	C	org.apache.hadoop.yarn.api.records.Resource	0	org.apache.hadoop.yarn.server.resourcemanager.monitor.capacity.TempSchedulerNode:setReservedResource(org.apache.hadoop.yarn.api.records.Resource)
org.apache.hadoop.yarn.server.resourcemanager.monitor.capacity.TempUserPerPartition	setUserLimit	userLimit	C	org.apache.hadoop.yarn.api.records.Resource	0	org.apache.hadoop.yarn.server.resourcemanager.monitor.capacity.TempUserPerPartition:setUserLimit(org.apache.hadoop.yarn.api.records.Resource)
org.apache.hadoop.yarn.server.resourcemanager.monitor.capacity.PreemptionCandidatesSelector	setMaximumKillWaitTime	maximumKillWaitTime	J	long	0	org.apache.hadoop.yarn.server.resourcemanager.monitor.capacity.PreemptionCandidatesSelector:setMaximumKillWaitTime(long)
org.apache.hadoop.yarn.server.resourcemanager.monitor.capacity.TempQueuePerPartition	setLeafQueue	leafQueue	C	org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue	0	org.apache.hadoop.yarn.server.resourcemanager.monitor.capacity.TempQueuePerPartition:setLeafQueue(org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.PartitionQueueCapacitiesInfo	setCapacity	capacity	J	float	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.PartitionQueueCapacitiesInfo:setCapacity(float)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.PartitionQueueCapacitiesInfo	setUsedCapacity	usedCapacity	J	float	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.PartitionQueueCapacitiesInfo:setUsedCapacity(float)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.PartitionQueueCapacitiesInfo	setMaxCapacity	maxCapacity	J	float	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.PartitionQueueCapacitiesInfo:setMaxCapacity(float)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.PartitionQueueCapacitiesInfo	setPartitionName	partitionName	J	java.lang.String	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.PartitionQueueCapacitiesInfo:setPartitionName(java.lang.String)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.PartitionQueueCapacitiesInfo	setAbsoluteCapacity	absoluteCapacity	J	float	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.PartitionQueueCapacitiesInfo:setAbsoluteCapacity(float)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.PartitionQueueCapacitiesInfo	setAbsoluteUsedCapacity	absoluteUsedCapacity	J	float	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.PartitionQueueCapacitiesInfo:setAbsoluteUsedCapacity(float)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.PartitionQueueCapacitiesInfo	setAbsoluteMaxCapacity	absoluteMaxCapacity	J	float	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.PartitionQueueCapacitiesInfo:setAbsoluteMaxCapacity(float)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.PartitionQueueCapacitiesInfo	setMaxAMLimitPercentage	maxAMLimitPercentage	J	float	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.PartitionQueueCapacitiesInfo:setMaxAMLimitPercentage(float)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.LocalResourceInfo	setUrl	url	J	java.net.URI	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.LocalResourceInfo:setUrl(java.net.URI)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.LocalResourceInfo	setType	type	C	org.apache.hadoop.yarn.api.records.LocalResourceType	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.LocalResourceInfo:setType(org.apache.hadoop.yarn.api.records.LocalResourceType)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.LocalResourceInfo	setVisibility	visibility	C	org.apache.hadoop.yarn.api.records.LocalResourceVisibility	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.LocalResourceInfo:setVisibility(org.apache.hadoop.yarn.api.records.LocalResourceVisibility)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.LocalResourceInfo	setSize	size	J	long	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.LocalResourceInfo:setSize(long)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.LocalResourceInfo	setTimestamp	timestamp	J	long	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.LocalResourceInfo:setTimestamp(long)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.LocalResourceInfo	setPattern	pattern	J	java.lang.String	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.LocalResourceInfo:setPattern(java.lang.String)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ApplicationSubmissionContextInfo	setApplicationId	applicationId	J	java.lang.String	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ApplicationSubmissionContextInfo:setApplicationId(java.lang.String)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ApplicationSubmissionContextInfo	setApplicationName	applicationName	J	java.lang.String	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ApplicationSubmissionContextInfo:setApplicationName(java.lang.String)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ApplicationSubmissionContextInfo	setQueue	queue	J	java.lang.String	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ApplicationSubmissionContextInfo:setQueue(java.lang.String)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ApplicationSubmissionContextInfo	setPriority	priority	J	int	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ApplicationSubmissionContextInfo:setPriority(int)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ApplicationSubmissionContextInfo	setContainerLaunchContextInfo	containerInfo	C	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ContainerLaunchContextInfo	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ApplicationSubmissionContextInfo:setContainerLaunchContextInfo(org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ContainerLaunchContextInfo)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ApplicationSubmissionContextInfo	setUnmanagedAM	isUnmanagedAM	J	boolean	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ApplicationSubmissionContextInfo:setUnmanagedAM(boolean)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ApplicationSubmissionContextInfo	setCancelTokensWhenComplete	cancelTokensWhenComplete	J	boolean	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ApplicationSubmissionContextInfo:setCancelTokensWhenComplete(boolean)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ApplicationSubmissionContextInfo	setMaxAppAttempts	maxAppAttempts	J	int	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ApplicationSubmissionContextInfo:setMaxAppAttempts(int)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ApplicationSubmissionContextInfo	setResource	resource	C	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ResourceInfo	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ApplicationSubmissionContextInfo:setResource(org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ResourceInfo)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ApplicationSubmissionContextInfo	setApplicationType	applicationType	J	java.lang.String	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ApplicationSubmissionContextInfo:setApplicationType(java.lang.String)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ApplicationSubmissionContextInfo	setKeepContainersAcrossApplicationAttempts	keepContainers	J	boolean	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ApplicationSubmissionContextInfo:setKeepContainersAcrossApplicationAttempts(boolean)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ApplicationSubmissionContextInfo	setApplicationTags	tags	GJ	java.util.Set	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ApplicationSubmissionContextInfo:setApplicationTags(java.util.Set)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ApplicationSubmissionContextInfo	setAppNodeLabelExpression	appNodeLabelExpression	J	java.lang.String	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ApplicationSubmissionContextInfo:setAppNodeLabelExpression(java.lang.String)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ApplicationSubmissionContextInfo	setAMContainerNodeLabelExpression	amContainerNodeLabelExpression	J	java.lang.String	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ApplicationSubmissionContextInfo:setAMContainerNodeLabelExpression(java.lang.String)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ApplicationSubmissionContextInfo	setLogAggregationContextInfo	logAggregationContextInfo	C	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.LogAggregationContextInfo	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ApplicationSubmissionContextInfo:setLogAggregationContextInfo(org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.LogAggregationContextInfo)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ApplicationSubmissionContextInfo	setAttemptFailuresValidityInterval	attemptFailuresValidityInterval	J	long	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ApplicationSubmissionContextInfo:setAttemptFailuresValidityInterval(long)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ApplicationSubmissionContextInfo	setReservationId	reservationId	J	java.lang.String	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ApplicationSubmissionContextInfo:setReservationId(java.lang.String)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.PartitionResourcesInfo	setPartitionName	partitionName	J	java.lang.String	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.PartitionResourcesInfo:setPartitionName(java.lang.String)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.PartitionResourcesInfo	setUsed	used	C	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ResourceInfo	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.PartitionResourcesInfo:setUsed(org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ResourceInfo)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.PartitionResourcesInfo	setReserved	reserved	C	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ResourceInfo	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.PartitionResourcesInfo:setReserved(org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ResourceInfo)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.PartitionResourcesInfo	setPending	pending	C	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ResourceInfo	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.PartitionResourcesInfo:setPending(org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ResourceInfo)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.PartitionResourcesInfo	setAmUsed	amUsed	C	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ResourceInfo	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.PartitionResourcesInfo:setAmUsed(org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ResourceInfo)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.PartitionResourcesInfo	setAMLimit	amLimit	C	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ResourceInfo	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.PartitionResourcesInfo:setAMLimit(org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ResourceInfo)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.PartitionResourcesInfo	setUserAmLimit	userAmLimit	C	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ResourceInfo	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.PartitionResourcesInfo:setUserAmLimit(org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ResourceInfo)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.QueueCapacitiesInfo	setQueueCapacitiesByPartition	queueCapacitiesByPartition	GC	java.util.List	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.QueueCapacitiesInfo:setQueueCapacitiesByPartition(java.util.List)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.RMQueueAclInfo	setAllowed	allowed	J	boolean	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.RMQueueAclInfo:setAllowed(boolean)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.RMQueueAclInfo	setUser	user	J	java.lang.String	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.RMQueueAclInfo:setUser(java.lang.String)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.RMQueueAclInfo	setDiagnostics	diagnostics	J	java.lang.String	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.RMQueueAclInfo:setDiagnostics(java.lang.String)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ResourceRequestInfo	setResourceName	resourceName	J	java.lang.String	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ResourceRequestInfo:setResourceName(java.lang.String)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ResourceRequestInfo	setCapability	capability	C	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ResourceInfo	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ResourceRequestInfo:setCapability(org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ResourceInfo)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ResourceRequestInfo	setNumContainers	numContainers	J	int	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ResourceRequestInfo:setNumContainers(int)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ResourceRequestInfo	setRelaxLocality	relaxLocality	J	boolean	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ResourceRequestInfo:setRelaxLocality(boolean)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ResourceRequestInfo	setNodeLabelExpression	nodeLabelExpression	J	java.lang.String	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ResourceRequestInfo:setNodeLabelExpression(java.lang.String)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ResourceRequestInfo	setPlacementConstraint	placementConstraint	J	java.lang.String	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ResourceRequestInfo:setPlacementConstraint(java.lang.String)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ResourceRequestInfo	setAllocationTags	allocationTags	GJ	java.util.Set	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ResourceRequestInfo:setAllocationTags(java.util.Set)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ResourceRequestInfo	setAllocationRequestId	allocationRequestId	J	long	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ResourceRequestInfo:setAllocationRequestId(long)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.DelegationToken	setToken	token	J	java.lang.String	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.DelegationToken:setToken(java.lang.String)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.DelegationToken	setRenewer	renewer	J	java.lang.String	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.DelegationToken:setRenewer(java.lang.String)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.DelegationToken	setOwner	owner	J	java.lang.String	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.DelegationToken:setOwner(java.lang.String)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.DelegationToken	setKind	kind	J	java.lang.String	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.DelegationToken:setKind(java.lang.String)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.DelegationToken	setMaxValidity	maxValidity	J	java.lang.Long	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.DelegationToken:setMaxValidity(java.lang.Long)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ContainerLaunchContextInfo	setResources	local_resources	GC	java.util.HashMap	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ContainerLaunchContextInfo:setResources(java.util.HashMap)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ContainerLaunchContextInfo	setEnvironment	environment	GJ	java.util.HashMap	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ContainerLaunchContextInfo:setEnvironment(java.util.HashMap)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ContainerLaunchContextInfo	setCommands	commands	GJ	java.util.List	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ContainerLaunchContextInfo:setCommands(java.util.List)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ContainerLaunchContextInfo	setAuxillaryServiceData	servicedata	GJ	java.util.HashMap	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ContainerLaunchContextInfo:setAuxillaryServiceData(java.util.HashMap)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ContainerLaunchContextInfo	setCredentials	credentials	C	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.CredentialsInfo	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ContainerLaunchContextInfo:setCredentials(org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.CredentialsInfo)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ContainerLaunchContextInfo	setAcls	acls	GC	java.util.HashMap	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ContainerLaunchContextInfo:setAcls(java.util.HashMap)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ResourceInfo	setvCores	vCores	J	int	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ResourceInfo:setvCores(int)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ClusterMetricsInfo	setContainersReserved	containersReserved	J	int	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ClusterMetricsInfo:setContainersReserved(int)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ClusterMetricsInfo	setContainersPending	containersPending	J	int	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ClusterMetricsInfo:setContainersPending(int)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ClusterMetricsInfo	setAppsSubmitted	appsSubmitted	J	int	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ClusterMetricsInfo:setAppsSubmitted(int)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ClusterMetricsInfo	setAppsCompleted	appsCompleted	J	int	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ClusterMetricsInfo:setAppsCompleted(int)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ClusterMetricsInfo	setAppsPending	appsPending	J	int	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ClusterMetricsInfo:setAppsPending(int)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ClusterMetricsInfo	setAppsRunning	appsRunning	J	int	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ClusterMetricsInfo:setAppsRunning(int)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ClusterMetricsInfo	setAppsFailed	appsFailed	J	int	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ClusterMetricsInfo:setAppsFailed(int)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ClusterMetricsInfo	setAppsKilled	appsKilled	J	int	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ClusterMetricsInfo:setAppsKilled(int)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ClusterMetricsInfo	setReservedMB	reservedMB	J	long	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ClusterMetricsInfo:setReservedMB(long)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ClusterMetricsInfo	setAvailableMB	availableMB	J	long	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ClusterMetricsInfo:setAvailableMB(long)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ClusterMetricsInfo	setAllocatedMB	allocatedMB	J	long	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ClusterMetricsInfo:setAllocatedMB(long)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ClusterMetricsInfo	setReservedVirtualCores	reservedVirtualCores	J	long	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ClusterMetricsInfo:setReservedVirtualCores(long)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ClusterMetricsInfo	setAvailableVirtualCores	availableVirtualCores	J	long	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ClusterMetricsInfo:setAvailableVirtualCores(long)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ClusterMetricsInfo	setAllocatedVirtualCores	allocatedVirtualCores	J	long	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ClusterMetricsInfo:setAllocatedVirtualCores(long)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ClusterMetricsInfo	setContainersAllocated	containersAllocated	J	int	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ClusterMetricsInfo:setContainersAllocated(int)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ClusterMetricsInfo	setTotalMB	totalMB	J	long	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ClusterMetricsInfo:setTotalMB(long)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ClusterMetricsInfo	setTotalVirtualCores	totalVirtualCores	J	long	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ClusterMetricsInfo:setTotalVirtualCores(long)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ClusterMetricsInfo	setTotalNodes	totalNodes	J	int	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ClusterMetricsInfo:setTotalNodes(int)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ClusterMetricsInfo	setLostNodes	lostNodes	J	int	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ClusterMetricsInfo:setLostNodes(int)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ClusterMetricsInfo	setUnhealthyNodes	unhealthyNodes	J	int	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ClusterMetricsInfo:setUnhealthyNodes(int)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ClusterMetricsInfo	setDecommissioningNodes	decommissioningNodes	J	int	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ClusterMetricsInfo:setDecommissioningNodes(int)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ClusterMetricsInfo	setDecommissionedNodes	decommissionedNodes	J	int	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ClusterMetricsInfo:setDecommissionedNodes(int)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ClusterMetricsInfo	setRebootedNodes	rebootedNodes	J	int	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ClusterMetricsInfo:setRebootedNodes(int)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ClusterMetricsInfo	setActiveNodes	activeNodes	J	int	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ClusterMetricsInfo:setActiveNodes(int)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ClusterMetricsInfo	setShutdownNodes	shutdownNodes	J	int	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ClusterMetricsInfo:setShutdownNodes(int)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ClusterMetricsInfo	setUtilizedMBPercent	utilizedMBPercent	J	int	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ClusterMetricsInfo:setUtilizedMBPercent(int)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ClusterMetricsInfo	setUtilizedVirtualCoresPercent	utilizedVirtualCoresPercent	J	int	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ClusterMetricsInfo:setUtilizedVirtualCoresPercent(int)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ClusterMetricsInfo	setRmSchedulerBusyPercent	rmSchedulerBusyPercent	J	int	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ClusterMetricsInfo:setRmSchedulerBusyPercent(int)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationRequestsInfo	setReservationRequestsInterpreter	reservationRequestsInterpreter	J	int	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationRequestsInfo:setReservationRequestsInterpreter(int)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationRequestsInfo	setReservationRequest	reservationRequest	GC	java.util.ArrayList	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationRequestsInfo:setReservationRequest(java.util.ArrayList)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppInfo	setNote	diagnostics	J	java.lang.String	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppInfo:setNote(java.lang.String)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppInfo	setResourceRequests	resourceRequests	GC	java.util.List	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppInfo:setResourceRequests(java.util.List)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppInfo	setPreemptedResourceMB	preemptedResourceMB	J	long	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppInfo:setPreemptedResourceMB(long)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppInfo	setPreemptedResourceVCores	preemptedResourceVCores	J	long	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppInfo:setPreemptedResourceVCores(long)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppInfo	setNumNonAMContainerPreempted	numNonAMContainerPreempted	J	int	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppInfo:setNumNonAMContainerPreempted(int)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppInfo	setNumAMContainerPreempted	numAMContainerPreempted	J	int	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppInfo:setNumAMContainerPreempted(int)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppInfo	setPreemptedMemorySeconds	preemptedMemorySeconds	J	long	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppInfo:setPreemptedMemorySeconds(long)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppInfo	setPreemptedVcoreSeconds	preemptedVcoreSeconds	J	long	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppInfo:setPreemptedVcoreSeconds(long)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppInfo	setAllocatedMB	allocatedMB	J	long	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppInfo:setAllocatedMB(long)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppInfo	setAllocatedVCores	allocatedVCores	J	long	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppInfo:setAllocatedVCores(long)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppInfo	setReservedMB	reservedMB	J	long	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppInfo:setReservedMB(long)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppInfo	setReservedVCores	reservedVCores	J	long	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppInfo:setReservedVCores(long)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppInfo	setRunningContainers	runningContainers	J	int	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppInfo:setRunningContainers(int)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppInfo	setMemorySeconds	memorySeconds	J	long	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppInfo:setMemorySeconds(long)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppInfo	setVcoreSeconds	vcoreSeconds	J	long	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppInfo:setVcoreSeconds(long)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppInfo	setAppId	id	J	java.lang.String	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppInfo:setAppId(java.lang.String)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppInfo	setAMHostHttpAddress	amHostHttpAddress	J	java.lang.String	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppInfo:setAMHostHttpAddress(java.lang.String)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppInfo	setState	state	C	org.apache.hadoop.yarn.api.records.YarnApplicationState	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppInfo:setState(org.apache.hadoop.yarn.api.records.YarnApplicationState)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppInfo	setName	name	J	java.lang.String	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppInfo:setName(java.lang.String)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppInfo	setMasterNodeId	masterNodeId	J	java.lang.String	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppInfo:setMasterNodeId(java.lang.String)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ResourcesInfo	setPartitionResourceUsages	resourceUsagesByPartition	GC	java.util.List	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ResourcesInfo:setPartitionResourceUsages(java.util.List)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppQueue	setQueue	queue	J	java.lang.String	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppQueue:setQueue(java.lang.String)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppPriority	setPriority	priority	J	int	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppPriority:setPriority(int)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationUpdateRequestInfo	setReservationId	reservationId	J	java.lang.String	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationUpdateRequestInfo:setReservationId(java.lang.String)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationUpdateRequestInfo	setReservationDefinition	reservationDefinition	C	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationDefinitionInfo	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationUpdateRequestInfo:setReservationDefinition(org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationDefinitionInfo)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodeLabelsInfo	setNodeLabelsInfo	nodeLabelsInfo	GC	java.util.ArrayList	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodeLabelsInfo:setNodeLabelsInfo(java.util.ArrayList)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationRequestInfo	setCapability	capability	C	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ResourceInfo	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationRequestInfo:setCapability(org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ResourceInfo)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationRequestInfo	setMinConcurrency	minConcurrency	J	int	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationRequestInfo:setMinConcurrency(int)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationRequestInfo	setNumContainers	numContainers	J	int	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationRequestInfo:setNumContainers(int)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationRequestInfo	setDuration	duration	J	long	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationRequestInfo:setDuration(long)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ResourceAllocationInfo	setStartTime	startTime	J	long	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ResourceAllocationInfo:setStartTime(long)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ResourceAllocationInfo	setEndTime	endTime	J	long	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ResourceAllocationInfo:setEndTime(long)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ResourceAllocationInfo	setResource	resource	C	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ResourceInfo	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ResourceAllocationInfo:setResource(org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ResourceInfo)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationInfo	setUser	user	J	java.lang.String	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationInfo:setUser(java.lang.String)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.LogAggregationContextInfo	setIncludePattern	logIncludePattern	J	java.lang.String	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.LogAggregationContextInfo:setIncludePattern(java.lang.String)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.LogAggregationContextInfo	setExcludePattern	logExcludePattern	J	java.lang.String	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.LogAggregationContextInfo:setExcludePattern(java.lang.String)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.LogAggregationContextInfo	setRolledLogsIncludePattern	rolledLogsIncludePattern	J	java.lang.String	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.LogAggregationContextInfo:setRolledLogsIncludePattern(java.lang.String)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.LogAggregationContextInfo	setRolledLogsExcludePattern	rolledLogsExcludePattern	J	java.lang.String	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.LogAggregationContextInfo:setRolledLogsExcludePattern(java.lang.String)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.LogAggregationContextInfo	setLogAggregationPolicyClassName	policyClassName	J	java.lang.String	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.LogAggregationContextInfo:setLogAggregationPolicyClassName(java.lang.String)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.LogAggregationContextInfo	setLogAggregationPolicyParameters	policyParameters	J	java.lang.String	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.LogAggregationContextInfo:setLogAggregationPolicyParameters(java.lang.String)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodeInfo	setNodeHTTPAddress	nodeHTTPAddress	J	java.lang.String	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodeInfo:setNodeHTTPAddress(java.lang.String)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodeInfo	setUsedResource	usedResource	C	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ResourceInfo	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodeInfo:setUsedResource(org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ResourceInfo)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodeInfo	setAvailableResource	availableResource	C	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ResourceInfo	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodeInfo:setAvailableResource(org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ResourceInfo)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodeInfo	setMemUtilization	memUtilization	J	float	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodeInfo:setMemUtilization(float)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodeInfo	setVcoreUtilization	cpuUtilization	J	float	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodeInfo:setVcoreUtilization(float)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodeInfo	setId	id	J	java.lang.String	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodeInfo:setId(java.lang.String)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodeInfo	setLastHealthUpdate	lastHealthUpdate	J	long	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodeInfo:setLastHealthUpdate(long)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodeInfo	setTotalResource	totalResource	C	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ResourceInfo	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodeInfo:setTotalResource(org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ResourceInfo)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationSubmissionRequestInfo	setQueue	queue	J	java.lang.String	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationSubmissionRequestInfo:setQueue(java.lang.String)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationSubmissionRequestInfo	setReservationId	reservationId	J	java.lang.String	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationSubmissionRequestInfo:setReservationId(java.lang.String)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationSubmissionRequestInfo	setReservationDefinition	reservationDefinition	C	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationDefinitionInfo	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationSubmissionRequestInfo:setReservationDefinition(org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationDefinitionInfo)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppTimeoutInfo	setTimeoutType	timeoutType	C	org.apache.hadoop.yarn.api.records.ApplicationTimeoutType	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppTimeoutInfo:setTimeoutType(org.apache.hadoop.yarn.api.records.ApplicationTimeoutType)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppTimeoutInfo	setExpiryTime	expiryTime	J	java.lang.String	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppTimeoutInfo:setExpiryTime(java.lang.String)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppTimeoutInfo	setRemainingTime	remainingTimeInSec	J	long	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppTimeoutInfo:setRemainingTime(long)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ExecutionTypeRequestInfo	setEnforceExecutionType	enforceExecutionType	J	boolean	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ExecutionTypeRequestInfo:setEnforceExecutionType(boolean)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationDefinitionInfo	setArrival	arrival	J	long	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationDefinitionInfo:setArrival(long)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationDefinitionInfo	setDeadline	deadline	J	long	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationDefinitionInfo:setDeadline(long)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationDefinitionInfo	setReservationRequests	reservationRequests	C	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationRequestsInfo	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationDefinitionInfo:setReservationRequests(org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationRequestsInfo)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationDefinitionInfo	setReservationName	reservationName	J	java.lang.String	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationDefinitionInfo:setReservationName(java.lang.String)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationDefinitionInfo	setPriority	priority	J	int	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationDefinitionInfo:setPriority(int)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationDefinitionInfo	setRecurrenceExpression	recurrenceExpression	J	java.lang.String	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationDefinitionInfo:setRecurrenceExpression(java.lang.String)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ActivityNodeInfo	setNodeIds	nodeIds	GJ	java.util.List	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ActivityNodeInfo:setNodeIds(java.util.List)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationDeleteRequestInfo	setReservationId	reservationId	J	java.lang.String	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationDeleteRequestInfo:setReservationId(java.lang.String)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.CredentialsInfo	setTokens	tokens	GJ	java.util.HashMap	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.CredentialsInfo:setTokens(java.util.HashMap)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.CredentialsInfo	setSecrets	secrets	GJ	java.util.HashMap	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.CredentialsInfo:setSecrets(java.util.HashMap)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppState	setState	state	J	java.lang.String	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppState:setState(java.lang.String)
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppState	setDiagnostics	diagnostics	J	java.lang.String	0	org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppState:setDiagnostics(java.lang.String)
org.apache.hadoop.yarn.server.resourcemanager.ClusterMetrics	setRmEventProcMonitorEnable	rmEventProcMonitorEnable	J	boolean	0	org.apache.hadoop.yarn.server.resourcemanager.ClusterMetrics:setRmEventProcMonitorEnable(boolean)
org.apache.hadoop.yarn.server.resourcemanager.ClientRMService	setDisplayPerUserApps	filterAppsByUser	J	boolean	0	org.apache.hadoop.yarn.server.resourcemanager.ClientRMService:setDisplayPerUserApps(boolean)
org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService$AllocateResponseLock	setAllocateResponse	response	C	org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse	0	org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService$AllocateResponseLock:setAllocateResponse(org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse)
org.apache.hadoop.yarn.server.resourcemanager.security.DelegationTokenRenewer	setRMContext	rmContext	C	org.apache.hadoop.yarn.server.resourcemanager.RMContext	0	org.apache.hadoop.yarn.server.resourcemanager.security.DelegationTokenRenewer:setRMContext(org.apache.hadoop.yarn.server.resourcemanager.RMContext)
org.apache.hadoop.yarn.server.resourcemanager.security.DelegationTokenRenewer	setDelegationTokenRenewerPoolTracker	delegationTokenRenewerPoolTrackerFlag	J	boolean	0	org.apache.hadoop.yarn.server.resourcemanager.security.DelegationTokenRenewer:setDelegationTokenRenewerPoolTracker(boolean)
org.apache.hadoop.yarn.server.resourcemanager.security.DelegationTokenRenewer$DelegationTokenRenewerEvent	setAttempt	attempt	J	int	0	org.apache.hadoop.yarn.server.resourcemanager.security.DelegationTokenRenewer$DelegationTokenRenewerEvent:setAttempt(int)
org.apache.hadoop.yarn.server.resourcemanager.security.DelegationTokenRenewer$DelegationTokenToRenew	setTimerTask	timerTask	C	org.apache.hadoop.yarn.server.resourcemanager.security.DelegationTokenRenewer$RenewalTimerTask	0	org.apache.hadoop.yarn.server.resourcemanager.security.DelegationTokenRenewer$DelegationTokenToRenew:setTimerTask(org.apache.hadoop.yarn.server.resourcemanager.security.DelegationTokenRenewer$RenewalTimerTask)
org.apache.hadoop.yarn.server.resourcemanager.security.AppPriorityACLsManager$PriorityACL	setPriority	priority	C	org.apache.hadoop.yarn.api.records.Priority	0	org.apache.hadoop.yarn.server.resourcemanager.security.AppPriorityACLsManager$PriorityACL:setPriority(org.apache.hadoop.yarn.api.records.Priority)
org.apache.hadoop.yarn.server.resourcemanager.security.AppPriorityACLsManager$PriorityACL	setDefaultPriority	defaultPriority	C	org.apache.hadoop.yarn.api.records.Priority	0	org.apache.hadoop.yarn.server.resourcemanager.security.AppPriorityACLsManager$PriorityACL:setDefaultPriority(org.apache.hadoop.yarn.api.records.Priority)
org.apache.hadoop.yarn.server.resourcemanager.security.AppPriorityACLsManager$PriorityACL	setAcl	acl	C	org.apache.hadoop.security.authorize.AccessControlList	0	org.apache.hadoop.yarn.server.resourcemanager.security.AppPriorityACLsManager$PriorityACL:setAcl(org.apache.hadoop.security.authorize.AccessControlList)
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext	setStateStore	stateStore	C	org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore	0	org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:setStateStore(org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore)
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext	setClientRMService	clientRMService	C	org.apache.hadoop.yarn.server.resourcemanager.ClientRMService	0	org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:setClientRMService(org.apache.hadoop.yarn.server.resourcemanager.ClientRMService)
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext	setRMDelegationTokenSecretManager	rmDelegationTokenSecretManager	C	org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager	0	org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:setRMDelegationTokenSecretManager(org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager)
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext	setContainerAllocationExpirer	containerAllocationExpirer	C	org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.ContainerAllocationExpirer	0	org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:setContainerAllocationExpirer(org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.ContainerAllocationExpirer)
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext	setAMLivelinessMonitor	amLivelinessMonitor	C	org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.AMLivelinessMonitor	0	org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:setAMLivelinessMonitor(org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.AMLivelinessMonitor)
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext	setAMFinishingMonitor	amFinishingMonitor	C	org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.AMLivelinessMonitor	0	org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:setAMFinishingMonitor(org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.AMLivelinessMonitor)
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext	setContainerTokenSecretManager	containerTokenSecretManager	C	org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager	0	org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:setContainerTokenSecretManager(org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager)
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext	setNMTokenSecretManager	nmTokenSecretManager	C	org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM	0	org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:setNMTokenSecretManager(org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM)
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext	setScheduler	scheduler	C	org.apache.hadoop.yarn.server.resourcemanager.scheduler.ResourceScheduler	0	org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:setScheduler(org.apache.hadoop.yarn.server.resourcemanager.scheduler.ResourceScheduler)
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext	setReservationSystem	reservationSystem	C	org.apache.hadoop.yarn.server.resourcemanager.reservation.ReservationSystem	0	org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:setReservationSystem(org.apache.hadoop.yarn.server.resourcemanager.reservation.ReservationSystem)
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext	setDelegationTokenRenewer	delegationTokenRenewer	C	org.apache.hadoop.yarn.server.resourcemanager.security.DelegationTokenRenewer	0	org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:setDelegationTokenRenewer(org.apache.hadoop.yarn.server.resourcemanager.security.DelegationTokenRenewer)
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext	setClientToAMTokenSecretManager	clientToAMTokenSecretManager	C	org.apache.hadoop.yarn.server.resourcemanager.security.ClientToAMTokenSecretManagerInRM	0	org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:setClientToAMTokenSecretManager(org.apache.hadoop.yarn.server.resourcemanager.security.ClientToAMTokenSecretManagerInRM)
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext	setAMRMTokenSecretManager	amRMTokenSecretManager	C	org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager	0	org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:setAMRMTokenSecretManager(org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager)
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext	setNodesListManager	nodesListManager	C	org.apache.hadoop.yarn.server.resourcemanager.NodesListManager	0	org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:setNodesListManager(org.apache.hadoop.yarn.server.resourcemanager.NodesListManager)
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext	setApplicationMasterService	applicationMasterService	C	org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService	0	org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:setApplicationMasterService(org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService)
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext	setResourceTrackerService	resourceTrackerService	C	org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService	0	org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:setResourceTrackerService(org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService)
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext	setWorkPreservingRecoveryEnabled	isWorkPreservingRecoveryEnabled	J	boolean	0	org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:setWorkPreservingRecoveryEnabled(boolean)
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext	setEpoch	epoch	J	long	0	org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:setEpoch(long)
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext	setNodeLabelManager	nodeLabelManager	C	org.apache.hadoop.yarn.server.resourcemanager.nodelabels.RMNodeLabelsManager	0	org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:setNodeLabelManager(org.apache.hadoop.yarn.server.resourcemanager.nodelabels.RMNodeLabelsManager)
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext	setNodeAttributesManager	nodeAttributesManager	C	org.apache.hadoop.yarn.nodelabels.NodeAttributesManager	0	org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:setNodeAttributesManager(org.apache.hadoop.yarn.nodelabels.NodeAttributesManager)
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext	setAllocationTagsManager	allocationTagsManager	C	org.apache.hadoop.yarn.server.resourcemanager.scheduler.constraint.AllocationTagsManager	0	org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:setAllocationTagsManager(org.apache.hadoop.yarn.server.resourcemanager.scheduler.constraint.AllocationTagsManager)
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext	setPlacementConstraintManager	placementConstraintManager	C	org.apache.hadoop.yarn.server.resourcemanager.scheduler.constraint.PlacementConstraintManager	0	org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:setPlacementConstraintManager(org.apache.hadoop.yarn.server.resourcemanager.scheduler.constraint.PlacementConstraintManager)
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext	setRMDelegatedNodeLabelsUpdater	rmDelegatedNodeLabelsUpdater	C	org.apache.hadoop.yarn.server.resourcemanager.nodelabels.RMDelegatedNodeLabelsUpdater	0	org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:setRMDelegatedNodeLabelsUpdater(org.apache.hadoop.yarn.server.resourcemanager.nodelabels.RMDelegatedNodeLabelsUpdater)
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext	setMultiNodeSortingManager	multiNodeSortingManager	GC	org.apache.hadoop.yarn.server.resourcemanager.scheduler.placement.MultiNodeSortingManager	0	org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:setMultiNodeSortingManager(org.apache.hadoop.yarn.server.resourcemanager.scheduler.placement.MultiNodeSortingManager)
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext	setSchedulerRecoveryStartAndWaitTime	schedulerRecoveryWaitTime	J	long	0	org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:setSchedulerRecoveryStartAndWaitTime(long)
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext	setSystemClock	systemClock	C	org.apache.hadoop.yarn.util.Clock	0	org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:setSystemClock(org.apache.hadoop.yarn.util.Clock)
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext	setQueuePlacementManager	queuePlacementManager	C	org.apache.hadoop.yarn.server.resourcemanager.placement.PlacementManager	0	org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:setQueuePlacementManager(org.apache.hadoop.yarn.server.resourcemanager.placement.PlacementManager)
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext	setRMAppLifetimeMonitor	rmAppLifetimeMonitor	C	org.apache.hadoop.yarn.server.resourcemanager.rmapp.monitor.RMAppLifetimeMonitor	0	org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:setRMAppLifetimeMonitor(org.apache.hadoop.yarn.server.resourcemanager.rmapp.monitor.RMAppLifetimeMonitor)
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext	setContainerQueueLimitCalculator	queueLimitCalculator	C	org.apache.hadoop.yarn.server.resourcemanager.scheduler.distributed.QueueLimitCalculator	0	org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:setContainerQueueLimitCalculator(org.apache.hadoop.yarn.server.resourcemanager.scheduler.distributed.QueueLimitCalculator)
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext	setResourceProfilesManager	resourceProfilesManager	C	org.apache.hadoop.yarn.server.resourcemanager.resource.ResourceProfilesManager	0	org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:setResourceProfilesManager(org.apache.hadoop.yarn.server.resourcemanager.resource.ResourceProfilesManager)
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext	setProxyCAManager	proxyCAManager	C	org.apache.hadoop.yarn.server.resourcemanager.security.ProxyCAManager	0	org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:setProxyCAManager(org.apache.hadoop.yarn.server.resourcemanager.security.ProxyCAManager)
org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext	setVolumeManager	volumeManager	C	org.apache.hadoop.yarn.server.resourcemanager.volume.csi.VolumeManager	0	org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext:setVolumeManager(org.apache.hadoop.yarn.server.resourcemanager.volume.csi.VolumeManager)
org.apache.hadoop.yarn.server.resourcemanager.reservation.InMemoryReservationAllocation	setAcceptanceTimestamp	acceptedAt	J	long	0	org.apache.hadoop.yarn.server.resourcemanager.reservation.InMemoryReservationAllocation:setAcceptanceTimestamp(long)
org.apache.hadoop.yarn.server.resourcemanager.reservation.InMemoryReservationAllocation	setPeriodicity	periodicity	J	long	0	org.apache.hadoop.yarn.server.resourcemanager.reservation.InMemoryReservationAllocation:setPeriodicity(long)
org.apache.hadoop.yarn.server.resourcemanager.reservation.AbstractReservationSystem	setRMContext	rmContext	C	org.apache.hadoop.yarn.server.resourcemanager.RMContext	0	org.apache.hadoop.yarn.server.resourcemanager.reservation.AbstractReservationSystem:setRMContext(org.apache.hadoop.yarn.server.resourcemanager.RMContext)
org.apache.hadoop.yarn.server.resourcemanager.reservation.planning.IterativePlanner	setAlgStageExecutionInterval	algStageExecutionInterval	C	org.apache.hadoop.yarn.server.resourcemanager.reservation.planning.StageExecutionInterval	0	org.apache.hadoop.yarn.server.resourcemanager.reservation.planning.IterativePlanner:setAlgStageExecutionInterval(org.apache.hadoop.yarn.server.resourcemanager.reservation.planning.StageExecutionInterval)
org.apache.hadoop.yarn.server.resourcemanager.reservation.planning.IterativePlanner	setAlgStageAllocator	algStageAllocator	C	org.apache.hadoop.yarn.server.resourcemanager.reservation.planning.StageAllocator	0	org.apache.hadoop.yarn.server.resourcemanager.reservation.planning.IterativePlanner:setAlgStageAllocator(org.apache.hadoop.yarn.server.resourcemanager.reservation.planning.StageAllocator)
org.apache.hadoop.yarn.server.resourcemanager.reservation.planning.StageAllocatorLowCostAligned$DurationInterval	setStartTime	startTime	J	long	0	org.apache.hadoop.yarn.server.resourcemanager.reservation.planning.StageAllocatorLowCostAligned$DurationInterval:setStartTime(long)
org.apache.hadoop.yarn.server.resourcemanager.reservation.planning.StageAllocatorLowCostAligned$DurationInterval	setEndTime	endTime	J	long	0	org.apache.hadoop.yarn.server.resourcemanager.reservation.planning.StageAllocatorLowCostAligned$DurationInterval:setEndTime(long)
org.apache.hadoop.yarn.server.resourcemanager.reservation.planning.StageAllocatorLowCostAligned$DurationInterval	setTotalCost	cost	J	double	0	org.apache.hadoop.yarn.server.resourcemanager.reservation.planning.StageAllocatorLowCostAligned$DurationInterval:setTotalCost(double)
org.apache.hadoop.yarn.server.resourcemanager.reservation.InMemoryPlan	setTotalCapacity	totalCapacity	C	org.apache.hadoop.yarn.api.records.Resource	0	org.apache.hadoop.yarn.server.resourcemanager.reservation.InMemoryPlan:setTotalCapacity(org.apache.hadoop.yarn.api.records.Resource)
org.apache.hadoop.yarn.server.resourcemanager.RMContextImpl	setServiceContext	serviceContext	C	org.apache.hadoop.yarn.server.resourcemanager.RMServiceContext	0	org.apache.hadoop.yarn.server.resourcemanager.RMContextImpl:setServiceContext(org.apache.hadoop.yarn.server.resourcemanager.RMServiceContext)
org.apache.hadoop.yarn.server.resourcemanager.RMContextImpl	setActiveServiceContext	activeServiceContext	C	org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext	0	org.apache.hadoop.yarn.server.resourcemanager.RMContextImpl:setActiveServiceContext(org.apache.hadoop.yarn.server.resourcemanager.RMActiveServiceContext)
org.apache.hadoop.yarn.server.router.rmadmin.DefaultRMAdminRequestInterceptor	setRMAdmin	rmAdminProxy	C	org.apache.hadoop.yarn.server.api.ResourceManagerAdministrationProtocol	0	org.apache.hadoop.yarn.server.router.rmadmin.DefaultRMAdminRequestInterceptor:setRMAdmin(org.apache.hadoop.yarn.server.api.ResourceManagerAdministrationProtocol)
org.apache.hadoop.yarn.server.router.rmadmin.AbstractRMAdminRequestInterceptor	setNextInterceptor	nextInterceptor	C	org.apache.hadoop.yarn.server.router.rmadmin.RMAdminRequestInterceptor	0	org.apache.hadoop.yarn.server.router.rmadmin.AbstractRMAdminRequestInterceptor:setNextInterceptor(org.apache.hadoop.yarn.server.router.rmadmin.RMAdminRequestInterceptor)
org.apache.hadoop.yarn.server.router.rmadmin.AbstractRMAdminRequestInterceptor	setConf	conf	C	org.apache.hadoop.conf.Configuration	0	org.apache.hadoop.yarn.server.router.rmadmin.AbstractRMAdminRequestInterceptor:setConf(org.apache.hadoop.conf.Configuration)
org.apache.hadoop.yarn.server.router.clientrm.DefaultClientRequestInterceptor	setRMClient	clientRMProxy	C	org.apache.hadoop.yarn.api.ApplicationClientProtocol	0	org.apache.hadoop.yarn.server.router.clientrm.DefaultClientRequestInterceptor:setRMClient(org.apache.hadoop.yarn.api.ApplicationClientProtocol)
org.apache.hadoop.yarn.server.router.clientrm.AbstractClientRequestInterceptor	setNextInterceptor	nextInterceptor	C	org.apache.hadoop.yarn.server.router.clientrm.ClientRequestInterceptor	0	org.apache.hadoop.yarn.server.router.clientrm.AbstractClientRequestInterceptor:setNextInterceptor(org.apache.hadoop.yarn.server.router.clientrm.ClientRequestInterceptor)
org.apache.hadoop.yarn.server.router.clientrm.AbstractClientRequestInterceptor	setConf	conf	C	org.apache.hadoop.conf.Configuration	0	org.apache.hadoop.yarn.server.router.clientrm.AbstractClientRequestInterceptor:setConf(org.apache.hadoop.conf.Configuration)
org.apache.hadoop.yarn.server.router.webapp.AbstractRESTRequestInterceptor	setNextInterceptor	nextInterceptor	C	org.apache.hadoop.yarn.server.router.webapp.RESTRequestInterceptor	0	org.apache.hadoop.yarn.server.router.webapp.AbstractRESTRequestInterceptor:setNextInterceptor(org.apache.hadoop.yarn.server.router.webapp.RESTRequestInterceptor)
org.apache.hadoop.yarn.server.router.webapp.AbstractRESTRequestInterceptor	setConf	conf	C	org.apache.hadoop.conf.Configuration	0	org.apache.hadoop.yarn.server.router.webapp.AbstractRESTRequestInterceptor:setConf(org.apache.hadoop.conf.Configuration)
org.apache.hadoop.yarn.server.router.webapp.DefaultRequestInterceptorREST	setWebAppAddress	webAppAddress	J	java.lang.String	0	org.apache.hadoop.yarn.server.router.webapp.DefaultRequestInterceptorREST:setWebAppAddress(java.lang.String)
org.apache.hadoop.yarn.server.router.webapp.DefaultRequestInterceptorREST	setSubClusterId	subClusterId	C	org.apache.hadoop.yarn.server.federation.store.records.SubClusterId	0	org.apache.hadoop.yarn.server.router.webapp.DefaultRequestInterceptorREST:setSubClusterId(org.apache.hadoop.yarn.server.federation.store.records.SubClusterId)
org.apache.hadoop.yarn.server.router.webapp.RouterWebServices	setResponse	response	J	javax.servlet.http.HttpServletResponse	0	org.apache.hadoop.yarn.server.router.webapp.RouterWebServices:setResponse(javax.servlet.http.HttpServletResponse)
org.apache.hadoop.yarn.server.timeline.EntityGroupFSTimelineStore	setFs	fs	C	org.apache.hadoop.fs.FileSystem	0	org.apache.hadoop.yarn.server.timeline.EntityGroupFSTimelineStore:setFs(org.apache.hadoop.fs.FileSystem)
org.apache.hadoop.yarn.server.timeline.LogInfo	setOffset	offset	J	long	0	org.apache.hadoop.yarn.server.timeline.LogInfo:setOffset(long)
org.apache.hadoop.yarn.server.timeline.EntityCacheItem	setAppLogs	appLogs	C	org.apache.hadoop.yarn.server.timeline.EntityGroupFSTimelineStore$AppLogs	0	org.apache.hadoop.yarn.server.timeline.EntityCacheItem:setAppLogs(org.apache.hadoop.yarn.server.timeline.EntityGroupFSTimelineStore$AppLogs)
org.apache.hadoop.yarn.server.timelineservice.documentstore.collection.document.flowrun.FlowRunDocument	setId	id	J	java.lang.String	0	org.apache.hadoop.yarn.server.timelineservice.documentstore.collection.document.flowrun.FlowRunDocument:setId(java.lang.String)
org.apache.hadoop.yarn.server.timelineservice.documentstore.collection.document.flowrun.FlowRunDocument	setClusterId	clusterId	J	java.lang.String	0	org.apache.hadoop.yarn.server.timelineservice.documentstore.collection.document.flowrun.FlowRunDocument:setClusterId(java.lang.String)
org.apache.hadoop.yarn.server.timelineservice.documentstore.collection.document.flowrun.FlowRunDocument	setUsername	username	J	java.lang.String	0	org.apache.hadoop.yarn.server.timelineservice.documentstore.collection.document.flowrun.FlowRunDocument:setUsername(java.lang.String)
org.apache.hadoop.yarn.server.timelineservice.documentstore.collection.document.flowrun.FlowRunDocument	setFlowName	flowName	J	java.lang.String	0	org.apache.hadoop.yarn.server.timelineservice.documentstore.collection.document.flowrun.FlowRunDocument:setFlowName(java.lang.String)
org.apache.hadoop.yarn.server.timelineservice.documentstore.collection.document.flowrun.FlowRunDocument	setFlowRunId	flowRunId	J	java.lang.Long	0	org.apache.hadoop.yarn.server.timelineservice.documentstore.collection.document.flowrun.FlowRunDocument:setFlowRunId(java.lang.Long)
org.apache.hadoop.yarn.server.timelineservice.documentstore.collection.document.flowrun.FlowRunDocument	setMinStartTime	minStartTime	J	long	0	org.apache.hadoop.yarn.server.timelineservice.documentstore.collection.document.flowrun.FlowRunDocument:setMinStartTime(long)
org.apache.hadoop.yarn.server.timelineservice.documentstore.collection.document.flowrun.FlowRunDocument	setMaxEndTime	maxEndTime	J	long	0	org.apache.hadoop.yarn.server.timelineservice.documentstore.collection.document.flowrun.FlowRunDocument:setMaxEndTime(long)
org.apache.hadoop.yarn.server.timelineservice.documentstore.collection.document.flowrun.FlowRunDocument	setCreatedTime	minStartTime	J	long	0	org.apache.hadoop.yarn.server.timelineservice.documentstore.collection.document.flowrun.FlowRunDocument:setCreatedTime(long)
org.apache.hadoop.yarn.server.timelineservice.documentstore.collection.document.flowrun.FlowRunDocument	setFlowVersion	flowVersion	J	java.lang.String	0	org.apache.hadoop.yarn.server.timelineservice.documentstore.collection.document.flowrun.FlowRunDocument:setFlowVersion(java.lang.String)
org.apache.hadoop.yarn.server.timelineservice.documentstore.collection.document.flowactivity.FlowActivityDocument	setId	id	J	java.lang.String	0	org.apache.hadoop.yarn.server.timelineservice.documentstore.collection.document.flowactivity.FlowActivityDocument:setId(java.lang.String)
org.apache.hadoop.yarn.server.timelineservice.documentstore.collection.document.flowactivity.FlowActivityDocument	setFlowActivities	flowActivities	GC	java.util.Set	0	org.apache.hadoop.yarn.server.timelineservice.documentstore.collection.document.flowactivity.FlowActivityDocument:setFlowActivities(java.util.Set)
org.apache.hadoop.yarn.server.timelineservice.documentstore.collection.document.flowactivity.FlowActivityDocument	setDayTimestamp	dayTimestamp	J	long	0	org.apache.hadoop.yarn.server.timelineservice.documentstore.collection.document.flowactivity.FlowActivityDocument:setDayTimestamp(long)
org.apache.hadoop.yarn.server.timelineservice.documentstore.collection.document.flowactivity.FlowActivityDocument	setUser	user	J	java.lang.String	0	org.apache.hadoop.yarn.server.timelineservice.documentstore.collection.document.flowactivity.FlowActivityDocument:setUser(java.lang.String)
org.apache.hadoop.yarn.server.timelineservice.documentstore.collection.document.flowactivity.FlowActivityDocument	setFlowName	flowName	J	java.lang.String	0	org.apache.hadoop.yarn.server.timelineservice.documentstore.collection.document.flowactivity.FlowActivityDocument:setFlowName(java.lang.String)
org.apache.hadoop.yarn.server.timelineservice.documentstore.collection.document.entity.TimelineEntityDocument	setFlowVersion	flowVersion	J	java.lang.String	0	org.apache.hadoop.yarn.server.timelineservice.documentstore.collection.document.entity.TimelineEntityDocument:setFlowVersion(java.lang.String)
org.apache.hadoop.yarn.server.timelineservice.documentstore.collection.document.entity.TimelineEntityDocument	setSubApplicationUser	subApplicationUser	J	java.lang.String	0	org.apache.hadoop.yarn.server.timelineservice.documentstore.collection.document.entity.TimelineEntityDocument:setSubApplicationUser(java.lang.String)
org.apache.hadoop.yarn.server.timelineservice.documentstore.collection.document.entity.TimelineEntityDocument	setContext	context	C	org.apache.hadoop.yarn.server.timelineservice.TimelineContext	0	org.apache.hadoop.yarn.server.timelineservice.documentstore.collection.document.entity.TimelineEntityDocument:setContext(org.apache.hadoop.yarn.server.timelineservice.TimelineContext)
org.apache.hadoop.yarn.server.timelineservice.documentstore.collection.document.entity.TimelineMetricSubDoc	setSingleDataTimestamp	singleDataTimestamp	J	long	0	org.apache.hadoop.yarn.server.timelineservice.documentstore.collection.document.entity.TimelineMetricSubDoc:setSingleDataTimestamp(long)
org.apache.hadoop.yarn.server.timelineservice.documentstore.collection.document.entity.TimelineMetricSubDoc	setSingleDataValue	singleDataValue	J	java.lang.Number	0	org.apache.hadoop.yarn.server.timelineservice.documentstore.collection.document.entity.TimelineMetricSubDoc:setSingleDataValue(java.lang.Number)
org.apache.hadoop.yarn.server.timelineservice.storage.reader.TimelineEntityReader	setTable	table	GC	org.apache.hadoop.yarn.server.timelineservice.storage.common.BaseTableRW	0	org.apache.hadoop.yarn.server.timelineservice.storage.reader.TimelineEntityReader:setTable(org.apache.hadoop.yarn.server.timelineservice.storage.common.BaseTableRW)
org.apache.hadoop.yarn.server.timelineservice.collector.AppLevelTimelineCollector	setRenewalOrRegenerationFutureForApp	renewalOrRegenerationFuture	GC	java.util.concurrent.Future	0	org.apache.hadoop.yarn.server.timelineservice.collector.AppLevelTimelineCollector:setRenewalOrRegenerationFutureForApp(java.util.concurrent.Future)
org.apache.hadoop.yarn.server.timelineservice.collector.TimelineCollectorContext	setFlowVersion	flowVersion	J	java.lang.String	0	org.apache.hadoop.yarn.server.timelineservice.collector.TimelineCollectorContext:setFlowVersion(java.lang.String)
org.apache.hadoop.yarn.server.timelineservice.collector.TimelineCollectorWebService$AboutInfo	setAbout	about	J	java.lang.String	0	org.apache.hadoop.yarn.server.timelineservice.collector.TimelineCollectorWebService$AboutInfo:setAbout(java.lang.String)
org.apache.hadoop.yarn.server.timelineservice.collector.TimelineCollector	setWriter	writer	C	org.apache.hadoop.yarn.server.timelineservice.storage.TimelineWriter	0	org.apache.hadoop.yarn.server.timelineservice.collector.TimelineCollector:setWriter(org.apache.hadoop.yarn.server.timelineservice.storage.TimelineWriter)
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineDataToRetrieve	setConfsToRetrieve	confsToRetrieve	C	org.apache.hadoop.yarn.server.timelineservice.reader.filter.TimelineFilterList	0	org.apache.hadoop.yarn.server.timelineservice.reader.TimelineDataToRetrieve:setConfsToRetrieve(org.apache.hadoop.yarn.server.timelineservice.reader.filter.TimelineFilterList)
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineDataToRetrieve	setMetricsToRetrieve	metricsToRetrieve	C	org.apache.hadoop.yarn.server.timelineservice.reader.filter.TimelineFilterList	0	org.apache.hadoop.yarn.server.timelineservice.reader.TimelineDataToRetrieve:setMetricsToRetrieve(org.apache.hadoop.yarn.server.timelineservice.reader.filter.TimelineFilterList)
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineDataToRetrieve	setFieldsToRetrieve	fieldsToRetrieve	GC	java.util.EnumSet	0	org.apache.hadoop.yarn.server.timelineservice.reader.TimelineDataToRetrieve:setFieldsToRetrieve(java.util.EnumSet)
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineDataToRetrieve	setMetricsLimit	metricsLimit	J	java.lang.Integer	0	org.apache.hadoop.yarn.server.timelineservice.reader.TimelineDataToRetrieve:setMetricsLimit(java.lang.Integer)
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderContext	setEntityType	entityType	J	java.lang.String	0	org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderContext:setEntityType(java.lang.String)
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderContext	setEntityId	entityId	J	java.lang.String	0	org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderContext:setEntityId(java.lang.String)
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderContext	setEntityIdPrefix	entityIdPrefix	J	java.lang.Long	0	org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderContext:setEntityIdPrefix(java.lang.Long)
org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderContext	setDoAsUser	doAsUser	J	java.lang.String	0	org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderContext:setDoAsUser(java.lang.String)
org.apache.hadoop.yarn.server.timelineservice.reader.filter.TimelineCompareFilter	setKey	key	J	java.lang.String	0	org.apache.hadoop.yarn.server.timelineservice.reader.filter.TimelineCompareFilter:setKey(java.lang.String)
org.apache.hadoop.yarn.server.timelineservice.reader.filter.TimelineCompareFilter	setValue	value	J	java.lang.Object	0	org.apache.hadoop.yarn.server.timelineservice.reader.filter.TimelineCompareFilter:setValue(java.lang.Object)
org.apache.hadoop.yarn.server.timelineservice.reader.filter.TimelineKeyValuesFilter	setCompareOp	compareOp	C	org.apache.hadoop.yarn.server.timelineservice.reader.filter.TimelineCompareOp	0	org.apache.hadoop.yarn.server.timelineservice.reader.filter.TimelineKeyValuesFilter:setCompareOp(org.apache.hadoop.yarn.server.timelineservice.reader.filter.TimelineCompareOp)
org.apache.hadoop.yarn.server.timelineservice.reader.filter.TimelineExistsFilter	setValue	value	J	java.lang.String	0	org.apache.hadoop.yarn.server.timelineservice.reader.filter.TimelineExistsFilter:setValue(java.lang.String)
org.apache.hadoop.yarn.server.timelineservice.reader.filter.TimelineExistsFilter	setCompareOp	compareOp	C	org.apache.hadoop.yarn.server.timelineservice.reader.filter.TimelineCompareOp	0	org.apache.hadoop.yarn.server.timelineservice.reader.filter.TimelineExistsFilter:setCompareOp(org.apache.hadoop.yarn.server.timelineservice.reader.filter.TimelineCompareOp)
org.apache.hadoop.yarn.server.timelineservice.reader.filter.TimelineFilterList	setOperator	operator	C	org.apache.hadoop.yarn.server.timelineservice.reader.filter.TimelineFilterList$Operator	0	org.apache.hadoop.yarn.server.timelineservice.reader.filter.TimelineFilterList:setOperator(org.apache.hadoop.yarn.server.timelineservice.reader.filter.TimelineFilterList$Operator)
org.apache.hadoop.yarn.server.timelineservice.TimelineContext	setClusterId	clusterId	J	java.lang.String	0	org.apache.hadoop.yarn.server.timelineservice.TimelineContext:setClusterId(java.lang.String)
org.apache.hadoop.yarn.server.timelineservice.TimelineContext	setUserId	userId	J	java.lang.String	0	org.apache.hadoop.yarn.server.timelineservice.TimelineContext:setUserId(java.lang.String)
org.apache.hadoop.yarn.server.timelineservice.TimelineContext	setFlowName	flowName	J	java.lang.String	0	org.apache.hadoop.yarn.server.timelineservice.TimelineContext:setFlowName(java.lang.String)
org.apache.hadoop.yarn.server.timelineservice.TimelineContext	setAppId	appId	J	java.lang.String	0	org.apache.hadoop.yarn.server.timelineservice.TimelineContext:setAppId(java.lang.String)
org.apache.hadoop.yarn.server.webproxy.ProxyCA	setDefaultTrustManager	defaultTrustManager	J	javax.net.ssl.X509TrustManager	0	org.apache.hadoop.yarn.server.webproxy.ProxyCA:setDefaultTrustManager(javax.net.ssl.X509TrustManager)
org.apache.hadoop.yarn.server.webproxy.WebAppProxyServlet	setConf	conf	C	org.apache.hadoop.yarn.conf.YarnConfiguration	0	org.apache.hadoop.yarn.server.webproxy.WebAppProxyServlet:setConf(org.apache.hadoop.yarn.conf.YarnConfiguration)
