{
    "org.apache.hadoop.hdfs.server.datanode.DataNode:transferBlock(org.apache.hadoop.hdfs.protocol.ExtendedBlock,org.apache.hadoop.hdfs.protocol.DatanodeInfo[],org.apache.hadoop.fs.StorageType[],java.lang.String[])": {
        "source_code": "@VisibleForTesting\nvoid transferBlock(ExtendedBlock block, DatanodeInfo[] xferTargets, StorageType[] xferTargetStorageTypes, String[] xferTargetStorageIDs) throws IOException {\n    BPOfferService bpos = getBPOSForBlock(block);\n    DatanodeRegistration bpReg = getDNRegistrationForBP(block.getBlockPoolId());\n    boolean replicaNotExist = false;\n    boolean replicaStateNotFinalized = false;\n    boolean blockFileNotExist = false;\n    boolean lengthTooShort = false;\n    try {\n        data.checkBlock(block, block.getNumBytes(), ReplicaState.FINALIZED);\n    } catch (ReplicaNotFoundException e) {\n        replicaNotExist = true;\n    } catch (UnexpectedReplicaStateException e) {\n        replicaStateNotFinalized = true;\n    } catch (FileNotFoundException e) {\n        blockFileNotExist = true;\n    } catch (EOFException e) {\n        lengthTooShort = true;\n    } catch (IOException e) {\n        // The IOException indicates not being able to access block file,\n        // treat it the same here as blockFileNotExist, to trigger\n        // reporting it as a bad block\n        blockFileNotExist = true;\n    }\n    if (replicaNotExist || replicaStateNotFinalized) {\n        String errStr = \"Can't send invalid block \" + block;\n        LOG.info(errStr);\n        bpos.trySendErrorReport(DatanodeProtocol.INVALID_BLOCK, errStr);\n        return;\n    }\n    if (blockFileNotExist) {\n        // Report back to NN bad block caused by non-existent block file.\n        reportBadBlock(bpos, block, \"Can't replicate block \" + block + \" because the block file doesn't exist, or is not accessible\");\n        return;\n    }\n    if (lengthTooShort) {\n        // Check if NN recorded length matches on-disk length\n        // Shorter on-disk len indicates corruption so report NN the corrupt block\n        reportBadBlock(bpos, block, \"Can't replicate block \" + block + \" because on-disk length \" + data.getLength(block) + \" is shorter than NameNode recorded length \" + block.getNumBytes());\n        return;\n    }\n    int numTargets = xferTargets.length;\n    if (numTargets > 0) {\n        final String xferTargetsString = StringUtils.join(\" \", Arrays.asList(xferTargets));\n        LOG.info(\"{} Starting thread to transfer {} to {}\", bpReg, block, xferTargetsString);\n        final DataTransfer dataTransferTask = new DataTransfer(xferTargets, xferTargetStorageTypes, xferTargetStorageIDs, block, BlockConstructionStage.PIPELINE_SETUP_CREATE, \"\");\n        this.xferService.execute(dataTransferTask);\n    }\n}",
        "file_path": "hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java"
    },
    "org.apache.hadoop.hdfs.server.datanode.DataNode:reportBadBlock(org.apache.hadoop.hdfs.server.datanode.BPOfferService,org.apache.hadoop.hdfs.protocol.ExtendedBlock,java.lang.String)": {
        "source_code": "private void reportBadBlock(final BPOfferService bpos, final ExtendedBlock block, final String msg) {\n    FsVolumeSpi volume = getFSDataset().getVolume(block);\n    if (volume == null) {\n        LOG.warn(\"Cannot find FsVolumeSpi to report bad block: {}\", block);\n        return;\n    }\n    bpos.reportBadBlocks(block, volume.getStorageID(), volume.getStorageType());\n    LOG.warn(msg);\n}",
        "file_path": "hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java"
    },
    "org.apache.hadoop.hdfs.server.datanode.DataNode:transferBlocks(java.lang.String,org.apache.hadoop.hdfs.protocol.Block[],org.apache.hadoop.hdfs.protocol.DatanodeInfo[][],org.apache.hadoop.fs.StorageType[][],java.lang.String[][])": {
        "source_code": "void transferBlocks(String poolId, Block[] blocks, DatanodeInfo[][] xferTargets, StorageType[][] xferTargetStorageTypes, String[][] xferTargetStorageIDs) {\n    for (int i = 0; i < blocks.length; i++) {\n        try {\n            transferBlock(new ExtendedBlock(poolId, blocks[i]), xferTargets[i], xferTargetStorageTypes[i], xferTargetStorageIDs[i]);\n        } catch (IOException ie) {\n            LOG.warn(\"Failed to transfer block {}\", blocks[i], ie);\n        }\n    }\n}",
        "file_path": "hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java"
    },
    "org.apache.hadoop.hdfs.server.datanode.BPOfferService:trySendErrorReport(int,java.lang.String)": {
        "source_code": "/**\n * Called by the DN to report an error to the NNs.\n */\nvoid trySendErrorReport(int errCode, String errMsg) {\n    for (BPServiceActor actor : bpServices) {\n        ErrorReportAction errorReportAction = new ErrorReportAction(errCode, errMsg);\n        actor.bpThreadEnqueue(errorReportAction);\n    }\n}",
        "file_path": "hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BPOfferService.java"
    }
}